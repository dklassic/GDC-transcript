1
00:00:06,351 --> 00:00:06,671
All right.

2
00:00:07,692 --> 00:00:08,372
Welcome everyone.

3
00:00:08,392 --> 00:00:10,034
I'm gonna get going right on time here

4
00:00:10,534 --> 00:00:13,576
because it's 30 minutes and it's full of stuff.

5
00:00:14,136 --> 00:00:15,417
So please turn off your cell phones

6
00:00:15,457 --> 00:00:17,819
and don't forget to fill in your surveys.

7
00:00:20,481 --> 00:00:21,802
If you don't know me, my name is Andreas.

8
00:00:22,222 --> 00:00:24,063
I head up the tools and infrastructure team

9
00:00:24,263 --> 00:00:25,004
at Insomniac Games.

10
00:00:26,785 --> 00:00:27,866
And today I'm here to talk to you

11
00:00:27,886 --> 00:00:30,368
about our cache simulator called CacheSim.

12
00:00:30,848 --> 00:00:32,449
So this is a tool that we've developed

13
00:00:32,509 --> 00:00:33,870
for programmers to use to measure

14
00:00:33,910 --> 00:00:35,011
how well they're using the cache.

15
00:00:36,203 --> 00:00:37,623
And I'm excited to announce today that we're going to

16
00:00:37,703 --> 00:00:41,684
open source this tech and that you can all, well, in fact,

17
00:00:41,704 --> 00:00:44,045
you already have access to it if you had only known the URL.

18
00:00:45,745 --> 00:00:47,905
So the thing I want to show you first, what we're going to

19
00:00:47,925 --> 00:00:51,526
talk about here, just in case you woke up frozen in a time

20
00:00:51,546 --> 00:00:55,067
machine or something, memory sizes and cache sizes.

21
00:00:55,207 --> 00:00:57,708
So I hadn't really seen a 2D breakdown of things.

22
00:00:57,848 --> 00:01:01,028
So if you think about a big block of memory like this, and

23
00:01:01,048 --> 00:01:03,569
then you put the L2 from a Jaguar next to it.

24
00:01:05,010 --> 00:01:05,990
It's kind of tiny.

25
00:01:06,131 --> 00:01:10,174
And then if you put the L1 next to it, yeah.

26
00:01:11,895 --> 00:01:14,477
But if you think about this, why are we making these

27
00:01:14,497 --> 00:01:15,177
caches so small?

28
00:01:15,217 --> 00:01:16,158
Well, they're really fast.

29
00:01:16,678 --> 00:01:19,921
That's the thing that goes along with this, is that if

30
00:01:19,941 --> 00:01:24,084
you can hit the smaller thing, it's a lot faster.

31
00:01:24,104 --> 00:01:25,985
We're talking about orders of magnitude.

32
00:01:26,486 --> 00:01:28,827
And we forget this too much as programmers.

33
00:01:29,168 --> 00:01:31,309
But it's really when we can hit these orders of magnitude

34
00:01:31,329 --> 00:01:33,411
improvements that we get the really big payoffs.

35
00:01:34,684 --> 00:01:41,229
And I think it is true personally that most programming languages make it really easy to screw up.

36
00:01:41,289 --> 00:01:44,912
You can add memory operations that you didn't even realize were memory operations

37
00:01:44,952 --> 00:01:47,594
because programming languages like to abstract this stuff.

38
00:01:48,115 --> 00:01:50,396
They make it easy for you to destroy performance.

39
00:01:52,253 --> 00:01:54,495
So as programmers trying to fix performance problems,

40
00:01:55,075 --> 00:01:57,116
typically with working on the cache,

41
00:01:57,297 --> 00:01:59,198
we just need access pattern information.

42
00:01:59,638 --> 00:02:01,939
And that's not something that is easily

43
00:02:03,240 --> 00:02:04,261
gleanable from the code.

44
00:02:04,301 --> 00:02:05,321
Like, you actually have to dig in.

45
00:02:06,732 --> 00:02:07,372
So what are we going to do?

46
00:02:07,532 --> 00:02:09,513
Well, if you're doing anything like this, you're probably

47
00:02:09,593 --> 00:02:11,033
using a sampling profiler, right?

48
00:02:11,093 --> 00:02:12,394
Because they've basically won.

49
00:02:12,914 --> 00:02:15,174
Something happened 10 years ago, and everything else just

50
00:02:15,214 --> 00:02:15,674
disappeared.

51
00:02:16,154 --> 00:02:17,635
And it's easy to see why this is true.

52
00:02:17,855 --> 00:02:19,275
They're non-intrusive.

53
00:02:19,295 --> 00:02:21,796
You can just run them, and they tell you with a pretty

54
00:02:21,816 --> 00:02:23,036
good guess about what's going on.

55
00:02:24,296 --> 00:02:27,277
And they can also give you hardware statistics, like the

56
00:02:27,297 --> 00:02:28,437
number of cache misses and things.

57
00:02:29,278 --> 00:02:30,978
And they use hardware statistics to do so.

58
00:02:31,018 --> 00:02:32,398
So they're actually pretty accurate.

59
00:02:32,578 --> 00:02:35,319
But, and that's a big but, they have a big limitation.

60
00:02:36,099 --> 00:02:38,401
They interrupt your program every so often.

61
00:02:39,061 --> 00:02:40,882
N instructions, and that N is pretty big.

62
00:02:40,902 --> 00:02:43,444
And even if you can try to make it smaller, there's

63
00:02:43,724 --> 00:02:44,965
actually quite a big gap.

64
00:02:47,386 --> 00:02:49,668
So now you have something that you're curious about finding

65
00:02:49,728 --> 00:02:51,409
out, why is this taking half a millisecond?

66
00:02:52,029 --> 00:02:54,070
I suspect that there's something bad going on in the

67
00:02:54,110 --> 00:02:57,272
system, but it just pops in two or three samples in there,

68
00:02:57,713 --> 00:02:59,454
and that's essentially useless.

69
00:03:02,115 --> 00:03:04,136
Outside, though, of the sampling space, there are

70
00:03:04,156 --> 00:03:05,117
tools like Valgrind.

71
00:03:06,665 --> 00:03:08,085
that take a completely different approach.

72
00:03:08,425 --> 00:03:10,746
So this is a tool that sets up a synthetic CPU

73
00:03:11,126 --> 00:03:12,807
and then runs your program on that CPU.

74
00:03:13,227 --> 00:03:16,128
And you can instrument and do stuff with the program.

75
00:03:16,148 --> 00:03:18,469
And part of that stuff that they do is cache grint.

76
00:03:18,829 --> 00:03:20,630
So that's a module that you can run on top of Valgrind.

77
00:03:21,250 --> 00:03:23,531
And what this does is it will break down your instructions,

78
00:03:23,631 --> 00:03:25,952
reads and writes, and simulate them on top of a cache.

79
00:03:26,012 --> 00:03:27,993
And then you can get this awesome, sort of super

80
00:03:28,033 --> 00:03:29,233
detailed output at the end.

81
00:03:30,254 --> 00:03:34,563
So, it's easy to see why that will give you a completely different picture because you're

82
00:03:34,583 --> 00:03:38,471
not looking at every end instructions or like that entire block, you're actually pinpointing

83
00:03:38,491 --> 00:03:39,894
everything down to a particular instruction.

84
00:03:41,617 --> 00:03:43,679
But it comes with a bunch of cons for us, right?

85
00:03:44,179 --> 00:03:46,501
Our games don't run on Linux, where this thing runs, and

86
00:03:46,541 --> 00:03:47,321
it's all or nothing.

87
00:03:47,381 --> 00:03:50,564
So you can't decide to do this halfway through.

88
00:03:50,664 --> 00:03:52,925
You're going to be navigating your menus and loading your

89
00:03:52,965 --> 00:03:55,127
level and doing all the things at like a

90
00:03:55,247 --> 00:03:56,328
hundred times slowdown.

91
00:03:57,368 --> 00:03:59,970
Which, needless to say, is not particularly great if you're

92
00:03:59,990 --> 00:04:02,092
trying to get to that particular gameplay thing

93
00:04:02,112 --> 00:04:02,592
you're looking at.

94
00:04:04,604 --> 00:04:06,805
There is a tool that is near and dear to my heart

95
00:04:06,845 --> 00:04:08,226
from the previous generation of consoles

96
00:04:08,266 --> 00:04:09,287
that I won't mention by name.

97
00:04:09,727 --> 00:04:11,468
It allowed you to do something similar

98
00:04:11,748 --> 00:04:14,190
for a short period of time and then run unimpeded again.

99
00:04:15,351 --> 00:04:17,712
And I really felt that we could use a tool like this.

100
00:04:19,953 --> 00:04:21,614
If you have a tool like this, I'm

101
00:04:21,634 --> 00:04:23,695
going to show you just in case you haven't used a tool like

102
00:04:23,715 --> 00:04:24,656
this, why you want them.

103
00:04:25,877 --> 00:04:28,058
Here's some high level rendering code from our push buffer.

104
00:04:28,849 --> 00:04:30,570
So the purpose of this code is to say,

105
00:04:30,650 --> 00:04:31,991
well, I have a bunch of textures,

106
00:04:32,351 --> 00:04:35,713
and I'm going to convert it to lower level data that's

107
00:04:35,733 --> 00:04:37,915
going to be fed into the GPU push buffers on the next frame.

108
00:04:38,635 --> 00:04:40,076
And the details aren't super important,

109
00:04:40,176 --> 00:04:42,978
but what I'm calling out here is that this is a relatively

110
00:04:43,058 --> 00:04:44,659
well-tuned code, something that I wouldn't

111
00:04:44,699 --> 00:04:46,820
expect to be a disaster.

112
00:04:47,100 --> 00:04:49,562
And I found, using tooling, that this particular axis

113
00:04:49,582 --> 00:04:51,363
of 16-bit flag was missing L2 2,800 times in a frame, which

114
00:04:51,443 --> 00:04:51,843
is a huge deal.

115
00:04:59,031 --> 00:05:00,953
And sometimes it's just the small things.

116
00:05:01,013 --> 00:05:01,694
Why did it happen?

117
00:05:01,734 --> 00:05:03,655
Well, it wasn't some sort of ominous bad guy

118
00:05:03,695 --> 00:05:04,336
putting this in.

119
00:05:04,516 --> 00:05:07,559
It happened accidentally because the object it was

120
00:05:07,679 --> 00:05:10,141
accessing had been organized into a hot part and a cold

121
00:05:10,181 --> 00:05:12,403
part, and during maintenance, because something grew or

122
00:05:12,423 --> 00:05:14,345
shrunk or someone added something without thinking it

123
00:05:14,385 --> 00:05:15,726
through, again, programming language

124
00:05:15,766 --> 00:05:16,767
abstracting things for you.

125
00:05:18,148 --> 00:05:20,691
This little poor guy had dropped from the hot cache

126
00:05:20,731 --> 00:05:22,032
line into the cold cache line.

127
00:05:23,153 --> 00:05:23,673
How do you fix it?

128
00:05:24,274 --> 00:05:25,755
You swap two lines in the header file.

129
00:05:27,764 --> 00:05:29,926
And you save up to a quarter millisecond depending on view.

130
00:05:31,088 --> 00:05:31,988
That's what I'm talking about.

131
00:05:33,710 --> 00:05:36,133
And your time investment to do something like this is like

132
00:05:36,213 --> 00:05:36,673
half an hour.

133
00:05:39,070 --> 00:05:42,391
And there are other reasons that you want tooling that help you along the right path.

134
00:05:42,591 --> 00:05:44,752
Sometimes you have utility functions.

135
00:05:44,792 --> 00:05:48,733
Like I'm sure if you look at a profile for any random game, you'll see things like mem

136
00:05:48,793 --> 00:05:50,873
compare standing out when it really shouldn't.

137
00:05:51,174 --> 00:05:56,115
Or just accessing a position will show up in the profile output.

138
00:05:56,635 --> 00:06:00,916
So in this case, what I'm showing here is that our scene object class has a way to query

139
00:06:00,956 --> 00:06:02,537
for, hey, what's the position of this thing?

140
00:06:02,957 --> 00:06:04,237
And it's pretty easy to see what it's going to do.

141
00:06:04,297 --> 00:06:06,438
It's just going to access a row from a matrix.

142
00:06:07,818 --> 00:06:11,461
And if you see this sort of thing showing up in the cache report,

143
00:06:11,481 --> 00:06:14,123
you're going to be like, I can't optimize this, it's just a return statement.

144
00:06:14,183 --> 00:06:14,763
What are we going to do?

145
00:06:16,304 --> 00:06:17,565
Well, that's the wrong way to think about it.

146
00:06:17,585 --> 00:06:21,107
What we need to optimize are the people who are giving this poor guy

147
00:06:21,207 --> 00:06:22,328
cold this pointers.

148
00:06:23,149 --> 00:06:24,289
They should be doing something else.

149
00:06:24,690 --> 00:06:27,672
But in order to do that, you have to figure out who is calling this guy

150
00:06:27,712 --> 00:06:30,954
with all these cold pointers and propagate the blame up the stack.

151
00:06:32,851 --> 00:06:34,232
So I did that, and our tool does this.

152
00:06:34,932 --> 00:06:38,193
And I have found that one particular programmer was

153
00:06:38,233 --> 00:06:41,034
responsible for 12,000 out of the 14,000 L2

154
00:06:41,474 --> 00:06:42,555
misses in getPosition.

155
00:06:43,755 --> 00:06:46,396
So again, I'm not going to bore you with all the details

156
00:06:46,416 --> 00:06:47,017
of the code here.

157
00:06:47,057 --> 00:06:51,098
But basically, it was a loop like this that said, I am

158
00:06:51,138 --> 00:06:53,919
going to go through and do a broad face, is what the

159
00:06:53,939 --> 00:06:55,340
comment said, to quickly.

160
00:06:56,364 --> 00:06:59,165
get to the set of things that I need to look at,

161
00:06:59,465 --> 00:07:00,885
the things that are around the camera.

162
00:07:01,506 --> 00:07:03,446
Very prototype-y, very sort of first pass,

163
00:07:03,466 --> 00:07:04,947
but like, you know, things like this happen.

164
00:07:05,447 --> 00:07:08,628
Okay, so it's burning through 10,000 or so,

165
00:07:09,648 --> 00:07:12,169
12,000 in fact, placed things by designers,

166
00:07:12,289 --> 00:07:13,449
and then figuring out which ones

167
00:07:13,489 --> 00:07:14,449
are actually near the camera.

168
00:07:15,510 --> 00:07:18,530
This thing, 12,000 L2 misses in the frame

169
00:07:18,550 --> 00:07:20,171
from this one particular location.

170
00:07:21,582 --> 00:07:25,222
I mean, to put things in perspective here, this is like one millisecond.

171
00:07:25,703 --> 00:07:28,003
This entire system was one millisecond per frame on PC.

172
00:07:29,183 --> 00:07:32,184
So if you've done any console dev, yeah, it's not one millisecond.

173
00:07:33,624 --> 00:07:35,905
So looking at this thing, I'm like, wait, what's going on?

174
00:07:35,945 --> 00:07:36,645
I need to fix this.

175
00:07:38,005 --> 00:07:41,246
Well it's good that these things that it's accessing over and over again with these super

176
00:07:41,286 --> 00:07:45,107
expensive L2 misses, they always return the same result because these things never move.

177
00:07:46,681 --> 00:07:49,023
So my fix for this particular problem then was to say, well,

178
00:07:49,083 --> 00:07:51,785
because they never move, I only need to update this array

179
00:07:51,825 --> 00:07:54,667
when these things come and go, which is super, super rare.

180
00:07:55,308 --> 00:07:57,870
And I can then get rid of this getPosition call entirely.

181
00:07:58,470 --> 00:08:01,913
And that saves you 650 micres per frame on an i7.

182
00:08:04,735 --> 00:08:05,596
It's a bigger project.

183
00:08:05,996 --> 00:08:08,438
It takes a couple hours maybe to reorganize it.

184
00:08:08,939 --> 00:08:09,980
But there are real wins.

185
00:08:13,773 --> 00:08:16,594
So to do something like this, to actually simulate what is

186
00:08:16,614 --> 00:08:20,275
going on in a program, it seems so easy if we could just

187
00:08:20,675 --> 00:08:21,536
be superhuman.

188
00:08:21,896 --> 00:08:23,857
Because it's all there in the instruction stream.

189
00:08:23,877 --> 00:08:25,837
Like all we have to do is look at what the instructions are

190
00:08:25,857 --> 00:08:27,918
doing, and looking at the addresses and the operands,

191
00:08:27,958 --> 00:08:31,299
and saying, if this was cached, and if this was not

192
00:08:31,339 --> 00:08:33,440
cached, and somehow count that up.

193
00:08:34,725 --> 00:08:37,887
So to do that, we would basically flip a switch when

194
00:08:37,927 --> 00:08:40,988
we have gotten at full speed to some point of interest, and

195
00:08:41,008 --> 00:08:43,649
then start single-stepping the instructions and seeing what

196
00:08:43,669 --> 00:08:46,671
are they doing, update some cache simulation, and then

197
00:08:46,831 --> 00:08:48,371
turn off the trace and report.

198
00:08:48,671 --> 00:08:50,312
And we'd live happily ever after.

199
00:08:50,912 --> 00:08:51,813
How do you even do this?

200
00:08:53,946 --> 00:08:59,289
So, at Insomniac we pitch things and we practice, you know, explaining the value of things.

201
00:08:59,929 --> 00:09:01,830
And it helps if your boss understands you.

202
00:09:03,110 --> 00:09:03,731
This is my boss.

203
00:09:04,011 --> 00:09:04,771
He doesn't understand me.

204
00:09:05,492 --> 00:09:07,052
And so I said to him, I think there's something here.

205
00:09:07,132 --> 00:09:10,334
We should have our own cache simulator that we can apply for all these things that there's

206
00:09:10,374 --> 00:09:11,314
no off-the-shelf tooling.

207
00:09:12,015 --> 00:09:14,536
And I think my subject was, I can see CrazyTown from here.

208
00:09:15,336 --> 00:09:15,876
He said, sure.

209
00:09:17,608 --> 00:09:18,648
So I did that.

210
00:09:19,228 --> 00:09:21,569
And my first approach, which went nowhere, really, but

211
00:09:21,609 --> 00:09:24,470
we'll see why, I started looking at binary

212
00:09:24,510 --> 00:09:25,590
instrumentation frameworks.

213
00:09:25,830 --> 00:09:27,771
So if you're not familiar, these are tools that will

214
00:09:28,871 --> 00:09:30,752
allow you to sort of muck with your executable

215
00:09:30,832 --> 00:09:31,352
as it's running.

216
00:09:31,712 --> 00:09:33,253
So you can say, oh, go find this function.

217
00:09:33,273 --> 00:09:34,513
I'm going to rewrite it to look like this.

218
00:09:34,553 --> 00:09:36,094
And you can actually go way lower level, too.

219
00:09:36,134 --> 00:09:39,235
You can say, oh, let me patch up all these SSE instructions

220
00:09:39,255 --> 00:09:40,355
to do something else or whatever.

221
00:09:41,495 --> 00:09:44,056
There's Dynamo Rio is one popular one, and Intel has one

222
00:09:44,076 --> 00:09:44,556
called Pin.

223
00:09:46,829 --> 00:09:48,650
But remember the scope of what we're trying to do here.

224
00:09:48,710 --> 00:09:50,571
We're trying to look at every single instruction

225
00:09:50,611 --> 00:09:51,332
that touches memory.

226
00:09:51,852 --> 00:09:53,433
Let's just say that that's not really

227
00:09:53,453 --> 00:09:55,294
in the design wheelhouse of these frameworks,

228
00:09:55,314 --> 00:09:57,195
because the metadata that they need to track

229
00:09:57,215 --> 00:09:58,956
to undo these patches and all the things,

230
00:09:59,396 --> 00:10:00,957
it's hundreds and hundreds of megabytes.

231
00:10:01,317 --> 00:10:01,977
I don't know about you,

232
00:10:02,017 --> 00:10:04,599
but executable is kind of big, right?

233
00:10:04,719 --> 00:10:05,319
Triple A games.

234
00:10:06,992 --> 00:10:08,973
But I think I was interested in this space.

235
00:10:08,993 --> 00:10:10,895
And if you're going to look at these frameworks, I would

236
00:10:10,935 --> 00:10:14,438
encourage you to look at them for how can I put cheap

237
00:10:14,558 --> 00:10:18,682
D-trace-style probes into the game that I can enable, and

238
00:10:18,702 --> 00:10:20,763
they're zero cost when they're not there.

239
00:10:20,783 --> 00:10:22,225
Things like how often is this zero?

240
00:10:22,245 --> 00:10:24,907
How often is this min-max value between whatever?

241
00:10:24,987 --> 00:10:27,549
Like if you're doing your own custom stuff without having to

242
00:10:27,589 --> 00:10:28,290
recompile the game.

243
00:10:29,871 --> 00:10:30,792
All right, so that was a bust.

244
00:10:31,052 --> 00:10:31,733
And so I said, OK.

245
00:10:34,656 --> 00:10:36,777
Next approach, I'm going to write a function somehow.

246
00:10:37,938 --> 00:10:38,999
It's going to be called trace function.

247
00:10:39,339 --> 00:10:40,520
You give it a function pointer.

248
00:10:42,020 --> 00:10:45,823
And then, magically, it's going to disassemble each

249
00:10:45,863 --> 00:10:48,945
instruction, it's going to find the memory dereferences

250
00:10:49,025 --> 00:10:50,866
of the instruction, and update the simulated cache.

251
00:10:51,126 --> 00:10:53,828
And then, because I don't want to emulate the entire CPU,

252
00:10:53,908 --> 00:10:56,069
like I'm going to rely on the CPU to do the heavy lifting.

253
00:10:56,109 --> 00:10:57,550
It's going to actually execute the instruction.

254
00:10:57,970 --> 00:11:00,192
And to do that, like isolate the instruction in a temporary

255
00:11:00,232 --> 00:11:02,213
buffer, run it, and then return back to me so I can

256
00:11:02,233 --> 00:11:02,853
keep doing this.

257
00:11:03,313 --> 00:11:04,194
That doesn't sound too bad.

258
00:11:06,280 --> 00:11:06,460
Yeah.

259
00:11:06,921 --> 00:11:09,467
As soon as you hit a branch instruction, your party comes

260
00:11:09,507 --> 00:11:12,233
crashing down because, oh yeah, they're all relative

261
00:11:12,313 --> 00:11:13,034
offset coded.

262
00:11:13,054 --> 00:11:15,219
So if you copy the thing elsewhere and branch, it's

263
00:11:15,239 --> 00:11:16,802
going to just branch into garbage memory.

264
00:11:17,660 --> 00:11:19,281
OK, maybe we need to emulate them.

265
00:11:19,622 --> 00:11:22,123
And then you've got the RIP pointer.

266
00:11:22,203 --> 00:11:25,985
So if you're not familiar with x64 assembly, there are a lot

267
00:11:26,025 --> 00:11:28,646
of places in x64 assembly where you use implicit

268
00:11:28,686 --> 00:11:31,708
references to the instruction pointer with a 32-bit signed

269
00:11:31,768 --> 00:11:32,088
offset.

270
00:11:32,608 --> 00:11:34,289
Now, if you're moving the instruction, let's just say

271
00:11:34,329 --> 00:11:36,370
that those deltas are no longer what you want them to

272
00:11:36,410 --> 00:11:38,191
be, so you'd have to either patch them, which you

273
00:11:38,211 --> 00:11:40,572
sometimes can't if you move it to a different 4 gigabyte

274
00:11:40,612 --> 00:11:43,054
range, and OK.

275
00:11:44,532 --> 00:11:47,593
But on top of this, we're also violating the Win64 ABI,

276
00:11:47,653 --> 00:11:50,453
because in Win64, every non-leaf function

277
00:11:50,553 --> 00:11:54,434
is associated with a stack unwinding data block.

278
00:11:55,014 --> 00:11:56,955
If you don't have that block and you take an exception,

279
00:11:57,195 --> 00:11:59,235
your program dies.

280
00:11:59,275 --> 00:12:01,336
There's no trying to fix that up.

281
00:12:01,376 --> 00:12:02,316
It just goes away.

282
00:12:02,896 --> 00:12:04,016
And you might think, well, that's

283
00:12:04,096 --> 00:12:06,537
just if you divide by 0 or something, which we wouldn't do.

284
00:12:06,657 --> 00:12:09,217
But no, if you've ever used output debug string

285
00:12:09,318 --> 00:12:11,758
or any other number of Win32 internal things,

286
00:12:12,138 --> 00:12:13,478
they use exceptions internally.

287
00:12:15,658 --> 00:12:17,239
Even if we fixed all of those problems,

288
00:12:18,860 --> 00:12:20,621
it's still a pretty intrusive approach, right?

289
00:12:20,861 --> 00:12:22,903
Because even if we had this magical trace function,

290
00:12:23,363 --> 00:12:25,704
we would have to have everyone opt in to being traced.

291
00:12:25,724 --> 00:12:27,065
They would have to start this frame saying,

292
00:12:27,185 --> 00:12:27,946
oh, are we tracing?

293
00:12:28,326 --> 00:12:30,868
Then let me run to this Rube Goldberg machine over here,

294
00:12:31,308 --> 00:12:33,169
or otherwise I'm just gonna do things normally.

295
00:12:33,249 --> 00:12:35,210
So, I was almost ready to give up.

296
00:12:35,751 --> 00:12:36,951
But then, it hit me.

297
00:12:39,173 --> 00:12:39,653
E-flags.

298
00:12:40,610 --> 00:12:43,472
is the flags register of xv6, right?

299
00:12:44,013 --> 00:12:45,534
And if you've done assembly programming,

300
00:12:45,554 --> 00:12:47,415
you know that this is where the carry flag

301
00:12:47,475 --> 00:12:49,197
and the zero flag and all these things are.

302
00:12:49,637 --> 00:12:53,040
There's also this guy, the trap flag.

303
00:12:53,840 --> 00:12:54,561
Intriguing.

304
00:12:56,483 --> 00:12:58,924
This is how your debugger F11 steps, right?

305
00:12:59,065 --> 00:13:00,926
If you're looking at this assembly and you're hitting F11.

306
00:13:02,667 --> 00:13:03,588
it sets the trap bit.

307
00:13:04,489 --> 00:13:05,991
And then the CPU continues running,

308
00:13:06,051 --> 00:13:07,533
but after it's run the instruction,

309
00:13:07,553 --> 00:13:09,836
it's before it runs the next one,

310
00:13:10,217 --> 00:13:11,779
it will actually generate an exception.

311
00:13:13,621 --> 00:13:15,664
So, okay, can we leverage this?

312
00:13:16,264 --> 00:13:18,327
It turns out you can route this exception

313
00:13:18,367 --> 00:13:20,590
through the Windows Structured Exception Handling machinery.

314
00:13:22,208 --> 00:13:24,892
And you can put a handler in for it, which means that if

315
00:13:24,912 --> 00:13:27,396
you set this flag, if you do it in your own thread, you're

316
00:13:27,416 --> 00:13:28,377
going to have little problems.

317
00:13:28,437 --> 00:13:30,540
But you'll basically get called back for every

318
00:13:30,560 --> 00:13:31,001
instruction.

319
00:13:31,101 --> 00:13:33,324
You can choose when you want to do this or not.

320
00:13:34,625 --> 00:13:38,146
But it still seems like it would have the sort of opt-in

321
00:13:38,226 --> 00:13:40,266
problem that I just talked about, where everyone who

322
00:13:40,306 --> 00:13:42,107
wanted to be traced would have to have a structured

323
00:13:42,127 --> 00:13:44,227
exception handler and jump through all this stuff.

324
00:13:44,648 --> 00:13:48,069
But aha, since Windows XP, there's this little known

325
00:13:48,169 --> 00:13:50,429
thing called vector exception handlers that allow you to set

326
00:13:50,469 --> 00:13:52,290
a crossbar handler for the entire app.

327
00:13:53,430 --> 00:13:58,012
So with those crazy building blocks, to do this, we can

328
00:13:58,072 --> 00:14:00,592
install a vector exception handler across the entire app.

329
00:14:00,672 --> 00:14:02,333
And it's going to listen for these trap exceptions.

330
00:14:03,552 --> 00:14:05,874
Then we go find the threads that we want to simulate,

331
00:14:06,374 --> 00:14:07,395
and we set their trap bits.

332
00:14:10,037 --> 00:14:11,898
We're now getting called for every instruction

333
00:14:11,939 --> 00:14:13,440
on all those threads into our handler.

334
00:14:13,860 --> 00:14:14,521
It's trapping us.

335
00:14:15,702 --> 00:14:17,203
So at this point, we disassemble the instruction

336
00:14:17,223 --> 00:14:18,064
from the text segment.

337
00:14:18,364 --> 00:14:19,365
We're not moving it anywhere.

338
00:14:19,865 --> 00:14:23,128
We find the memory operands, and we update our cache simulation.

339
00:14:23,448 --> 00:14:25,630
And then if we want to keep tracing, because this bit ought

340
00:14:25,970 --> 00:14:28,832
to reset, we set it again so that we get called back

341
00:14:28,852 --> 00:14:29,653
for the next instruction.

342
00:14:30,974 --> 00:14:32,255
And then to stop, it's pretty easy.

343
00:14:33,589 --> 00:14:36,555
all we need to do is basically stop setting these trace bits.

344
00:14:38,119 --> 00:14:41,165
So, I was excited to get two integer additions

345
00:14:41,205 --> 00:14:42,047
working with this approach.

346
00:14:44,679 --> 00:14:45,640
There are some other problems.

347
00:14:46,160 --> 00:14:48,702
First of all, your debugger relies on this.

348
00:14:49,002 --> 00:14:50,123
This is its space.

349
00:14:50,503 --> 00:14:53,405
We just barged into its party saying, hey, what's going on?

350
00:14:54,346 --> 00:14:57,008
And because the debugger gets the first chance of trapping

351
00:14:57,028 --> 00:14:59,809
all these exceptions and will, it gets super confused.

352
00:14:59,829 --> 00:15:02,751
You'd have everything from the debugger crashing to doing all

353
00:15:02,832 --> 00:15:03,512
the things.

354
00:15:03,532 --> 00:15:06,114
Remember, it will normally have set these single trace

355
00:15:06,934 --> 00:15:09,256
flags, and so you can take your debugger down very easily.

356
00:15:09,936 --> 00:15:11,918
Just run outside of the debugger was my solution.

357
00:15:13,736 --> 00:15:17,038
The more serious problem is that I had deadlocks in NTDLL

358
00:15:17,098 --> 00:15:20,260
for actually running this on a full game executable.

359
00:15:20,820 --> 00:15:23,722
So there's a lock inside of NTDLL, not to bore you too

360
00:15:23,762 --> 00:15:26,024
much, that protects this vectored exception handler

361
00:15:26,064 --> 00:15:26,764
dispatch list.

362
00:15:27,364 --> 00:15:30,186
And the idea is that while a handler is being run, you have

363
00:15:30,226 --> 00:15:32,768
to protect this list with a lock so that you don't remove

364
00:15:32,788 --> 00:15:34,829
the handler while the list is being traversed and all these

365
00:15:34,869 --> 00:15:35,390
boring things.

366
00:15:35,930 --> 00:15:37,791
And the thing is, all the threads were blocked on this

367
00:15:37,851 --> 00:15:39,152
lock, but no one held the lock.

368
00:15:40,333 --> 00:15:40,853
So that's great.

369
00:15:42,895 --> 00:15:45,276
I'm not really sure, but if we step back and look at what

370
00:15:45,296 --> 00:15:47,458
we're doing here, we're running a full AAA game

371
00:15:47,498 --> 00:15:48,018
executable.

372
00:15:48,438 --> 00:15:51,440
And for every thread, for every instruction, we're

373
00:15:51,540 --> 00:15:55,463
sandwiching in this cache simulation handler on using

374
00:15:55,503 --> 00:15:57,404
the structured exception handling machinery, which is

375
00:15:57,444 --> 00:16:00,947
that it inverts the normal work of the program with cache

376
00:16:00,967 --> 00:16:03,088
simulation by, I don't know, five orders of

377
00:16:03,128 --> 00:16:03,849
magnitude or something.

378
00:16:04,429 --> 00:16:06,891
So let's just say that no one, probably, at Microsoft,

379
00:16:06,931 --> 00:16:08,632
anticipated anyone to use it this way.

380
00:16:09,532 --> 00:16:10,913
And nothing was obviously wrong.

381
00:16:12,001 --> 00:16:16,568
But if I had to mentor a guest, I think it is that critical sections that are in the process of being entered,

382
00:16:17,209 --> 00:16:22,338
if you then take a trap and you go in and take another critical section in the trap handler, I think that is bad news.

383
00:16:24,940 --> 00:16:26,841
Anyway, I wanted to get something done.

384
00:16:26,901 --> 00:16:27,902
So my solution was this.

385
00:16:28,702 --> 00:16:30,684
And you may or may not agree with my reasoning here.

386
00:16:30,824 --> 00:16:32,345
Vector exception handlers are exotic.

387
00:16:33,165 --> 00:16:35,827
We are not shipping this feature outside of, you know,

388
00:16:36,768 --> 00:16:38,569
I used to say office, but that's no longer true.

389
00:16:38,629 --> 00:16:40,390
But I hope you're not shipping this to players

390
00:16:40,430 --> 00:16:41,371
because we certainly aren't.

391
00:16:42,051 --> 00:16:44,893
So what I do is I go find this handler that takes a lock

392
00:16:45,053 --> 00:16:47,375
and will iterate the list of exactly one handler

393
00:16:47,455 --> 00:16:49,616
and call that handler, which is always our handler,

394
00:16:49,956 --> 00:16:50,937
with a jump to our handler.

395
00:16:52,403 --> 00:16:54,824
Yes, it is ugly, but on the other hand, it works.

396
00:16:54,884 --> 00:16:57,365
And I also got rid of all the operating system dependencies

397
00:16:57,385 --> 00:16:59,106
from the cache sim module itself,

398
00:16:59,126 --> 00:17:01,386
so it would never try to do a syscall.

399
00:17:05,468 --> 00:17:07,009
So at this point, it works.

400
00:17:07,769 --> 00:17:09,770
And beautifully, instruction streams

401
00:17:09,790 --> 00:17:11,170
start trickling into these things.

402
00:17:12,111 --> 00:17:13,811
And because we can now inspect them one by one,

403
00:17:13,851 --> 00:17:15,352
the next step is to look at, okay,

404
00:17:15,852 --> 00:17:17,313
what memory addresses are they looking at?

405
00:17:19,003 --> 00:17:21,724
And in terms of disassemblers, I used one called UDIS86,

406
00:17:21,764 --> 00:17:22,264
which is nice.

407
00:17:23,065 --> 00:17:26,146
And there's a fork of it made by the Radar2 project that is

408
00:17:26,246 --> 00:17:28,247
even better, because it gives you the memory access

409
00:17:28,307 --> 00:17:28,767
operands.

410
00:17:29,528 --> 00:17:30,648
So here's what I'm talking about.

411
00:17:30,828 --> 00:17:32,669
You basically, from the context record of the thing

412
00:17:32,689 --> 00:17:34,830
that interrupted you, you get the instruction pointer.

413
00:17:35,650 --> 00:17:37,551
And you disassemble straight from the text segment.

414
00:17:38,052 --> 00:17:40,333
And then you just have to figure out what addresses are

415
00:17:40,373 --> 00:17:41,913
involved in computing this instruction.

416
00:17:44,314 --> 00:17:44,795
It should be easy.

417
00:17:46,754 --> 00:17:48,014
You know, here's a simple example.

418
00:17:48,054 --> 00:17:48,594
There's a move.

419
00:17:48,794 --> 00:17:52,556
Clearly it's moving 32 bits from EBX into the pointer RAX.

420
00:17:54,617 --> 00:17:55,977
Well, that's the theory.

421
00:17:56,738 --> 00:17:58,538
But if you've done x86 assembly, you know that

422
00:17:58,738 --> 00:18:00,759
there's tons of stuff that touches memory but doesn't

423
00:18:00,779 --> 00:18:01,660
have a memory operand.

424
00:18:02,080 --> 00:18:03,761
And there are things that have memory operands but

425
00:18:03,801 --> 00:18:04,441
don't touch memory.

426
00:18:07,642 --> 00:18:10,503
So string instructions are a good example.

427
00:18:10,523 --> 00:18:11,784
It uses implicit registers.

428
00:18:12,795 --> 00:18:15,719
You get your stack traffic, which will also pollute your caches.

429
00:18:16,280 --> 00:18:19,905
Even calling and returning from functions will mutate the stack.

430
00:18:21,227 --> 00:18:22,729
And there's Lea, which is super common.

431
00:18:22,769 --> 00:18:25,072
Your three operands with Arm and I for computing things,

432
00:18:25,492 --> 00:18:27,695
which has a memory operand but doesn't touch memory.

433
00:18:28,256 --> 00:18:31,020
And so if you get this wrong, you just have really bad results.

434
00:18:32,280 --> 00:18:35,485
And there are also crazy things like there are long knobs that you can use to pad

435
00:18:36,326 --> 00:18:38,709
that have memory operands, which I found really interesting.

436
00:18:39,390 --> 00:18:41,574
And there's floating pointer stores and prefetches.

437
00:18:41,934 --> 00:18:45,439
Needless to say, you can take all of this and you can put it in a somewhat awful switch,

438
00:18:45,479 --> 00:18:47,823
but you can handle all of it in like 200 lines of code.

439
00:18:48,432 --> 00:18:49,993
which is better than doing every instruction.

440
00:18:50,993 --> 00:18:52,973
So once we've figured out what the memory accesses are,

441
00:18:53,393 --> 00:18:54,594
we're ready to go poke our cache.

442
00:18:54,914 --> 00:18:57,174
And so the first thing we can do is go poke the cache to say,

443
00:18:57,234 --> 00:18:59,175
well, we know that we're going to execute the instruction,

444
00:18:59,275 --> 00:19:02,335
so make sure that we do an I read from this address.

445
00:19:03,675 --> 00:19:06,516
And then we have our reads, so we poke the cache again,

446
00:19:06,656 --> 00:19:09,917
and we do a read simulation, and then we do write simulation.

447
00:19:12,017 --> 00:19:14,378
Which then opens the question, how do you simulate a cache?

448
00:19:16,515 --> 00:19:19,458
Well, if you're familiar with anything about caches, they

449
00:19:19,498 --> 00:19:21,979
have associativity, set associativity.

450
00:19:22,440 --> 00:19:24,902
And so you can basically break them down as a two-dimensional

451
00:19:24,922 --> 00:19:26,023
array of ways and sets.

452
00:19:27,404 --> 00:19:29,525
So to see if something is in the cache, or indeed entered

453
00:19:29,565 --> 00:19:33,068
into the cache, you take the input address of whatever

454
00:19:33,088 --> 00:19:35,510
you're looking for, and a certain number of bits

455
00:19:35,550 --> 00:19:38,752
depending on the number of sets that you have.

456
00:19:39,152 --> 00:19:41,734
And then you go look at those lines that are associated with

457
00:19:41,774 --> 00:19:42,695
that particular set.

458
00:19:42,895 --> 00:19:43,576
Those are called the ways.

459
00:19:45,377 --> 00:19:48,419
And you run a comparison against all of them.

460
00:19:48,479 --> 00:19:50,660
Hardware thinks that this is a really nice problem, because

461
00:19:50,700 --> 00:19:53,102
all it needs to do is do a parallel comparison, which we

462
00:19:53,222 --> 00:19:54,563
can't do in software.

463
00:19:55,123 --> 00:19:56,464
But anyway, that's the theory.

464
00:19:58,638 --> 00:20:01,640
I was interested in simulating a Jaguar core, because that's

465
00:20:01,660 --> 00:20:04,482
the CPU that we know and love.

466
00:20:05,202 --> 00:20:07,203
So you have two modules.

467
00:20:07,484 --> 00:20:11,086
They both have a shared L2 and four cores, and each core then

468
00:20:11,126 --> 00:20:12,326
has its own D1 and I1.

469
00:20:13,027 --> 00:20:15,008
And a particular quirk is that it's inclusive.

470
00:20:15,068 --> 00:20:19,350
So if you have a line that is for something to be a hit, it

471
00:20:19,390 --> 00:20:22,892
has to be in both L2 and I1, for example, if you need an L1

472
00:20:23,013 --> 00:20:23,093
hit.

473
00:20:25,801 --> 00:20:28,322
So what's left to do is to figure out the associativities,

474
00:20:28,482 --> 00:20:30,123
which are no secret, they're right here.

475
00:20:30,884 --> 00:20:33,966
I want two-way associative, D1 eight-way, for example,

476
00:20:34,126 --> 00:20:35,627
L2 is 16-way, and we have the sizes.

477
00:20:36,427 --> 00:20:37,588
And with a bunch of helper glue

478
00:20:37,628 --> 00:20:39,229
that I'm not gonna show you in this talk,

479
00:20:39,609 --> 00:20:40,610
you can go look at it yourself,

480
00:20:41,790 --> 00:20:44,212
we can declare these two-dimensional array type helpers.

481
00:20:45,913 --> 00:20:47,434
And I set up this module thing that is,

482
00:20:47,794 --> 00:20:50,235
okay, four D1s, four I1s, a level two,

483
00:20:50,416 --> 00:20:51,896
and a pointer to the other module.

484
00:20:53,072 --> 00:20:55,233
And this is important because if you're writing to something,

485
00:20:55,633 --> 00:20:58,975
real hardware is going to do a line reservation of the thing

486
00:20:58,995 --> 00:21:01,676
you're writing, which the cache synchronization protocol is

487
00:21:01,696 --> 00:21:03,037
going to make sure that it's kicked out of

488
00:21:03,057 --> 00:21:03,977
the other guy's L2.

489
00:21:04,358 --> 00:21:05,738
So we need to simulate that, or we're just

490
00:21:05,778 --> 00:21:06,499
lying about things.

491
00:21:08,040 --> 00:21:11,681
So for each cache line we're accessing, depending on

492
00:21:11,761 --> 00:21:14,603
generated from these reads and writes, if you are straddling

493
00:21:14,643 --> 00:21:16,724
a cache line boundary, this will apply for both the cache

494
00:21:16,764 --> 00:21:17,725
lines you're reading.

495
00:21:19,200 --> 00:21:21,962
If we're writing to that cache line, we had better go kick it

496
00:21:22,002 --> 00:21:25,564
out of every other core on our module and the

497
00:21:25,625 --> 00:21:26,485
other module's L2.

498
00:21:28,567 --> 00:21:30,728
And then we can do a lookup plus record.

499
00:21:30,788 --> 00:21:33,170
So I'm treating the CPU here as an in-order CPU for the

500
00:21:33,210 --> 00:21:34,011
purposes of the cache.

501
00:21:34,251 --> 00:21:36,973
So I'm going to pretend that whatever you asked for will be

502
00:21:37,033 --> 00:21:37,774
cached by this.

503
00:21:38,974 --> 00:21:41,536
But what we're also looking up is to see if it's already in

504
00:21:41,556 --> 00:21:43,218
the cache, and that's how we can determine if something is

505
00:21:43,258 --> 00:21:43,838
a hit or a miss.

506
00:21:44,699 --> 00:21:46,520
So we independently hit the L1 and the L2.

507
00:21:49,724 --> 00:21:53,949
And because it is an inclusive hierarchy, it has to be in both to be considered an L1 hit.

508
00:21:55,230 --> 00:21:58,434
If it's only in the L2, it's an L2 hit, and otherwise it's a mess.

509
00:21:59,055 --> 00:22:00,117
So it's reasonably simple.

510
00:22:01,921 --> 00:22:03,262
All right, so with all this stuff,

511
00:22:03,502 --> 00:22:05,483
I now have hooked up to a keyboard shortcut,

512
00:22:05,503 --> 00:22:07,425
but I'm sure you can find other ways of doing it.

513
00:22:07,585 --> 00:22:09,926
And then I run a frame on this in the game.

514
00:22:10,507 --> 00:22:13,569
Like, this is a full AAA game I'm talking about here.

515
00:22:14,329 --> 00:22:16,711
It takes a couple of minutes to do this,

516
00:22:17,051 --> 00:22:18,432
which is still pretty awesome,

517
00:22:18,472 --> 00:22:20,673
given what it's actually doing and how hacky it is.

518
00:22:21,754 --> 00:22:25,576
And, you know, out falls 200 megs, maybe 100 megs,

519
00:22:25,616 --> 00:22:27,578
depending on exactly how much of data.

520
00:22:29,638 --> 00:22:33,663
And I'm so happy to say that the goal is there.

521
00:22:33,723 --> 00:22:37,087
Like it achieved this goal of saying, once it's done this

522
00:22:37,107 --> 00:22:39,189
slow thing, it resumes running at full frame rate.

523
00:22:39,209 --> 00:22:40,911
So if you want to do 15 of these, you can.

524
00:22:41,112 --> 00:22:41,732
There's no problem.

525
00:22:43,314 --> 00:22:46,078
So with the data we get out, as I mentioned, we capture

526
00:22:46,118 --> 00:22:48,000
call slacks too, which is integral to this data.

527
00:22:48,020 --> 00:22:48,721
That's why it's so big.

528
00:22:50,457 --> 00:22:53,400
And we track L1 hits, L2 hits, L2 misses.

529
00:22:53,881 --> 00:22:56,864
And we also put in a special thing to track prefetches,

530
00:22:56,964 --> 00:22:59,868
explicit prefetches, put in by programmers and see if those

531
00:22:59,928 --> 00:23:01,590
prefetches hit things that are in the cache.

532
00:23:02,151 --> 00:23:03,993
So that's a pretty good bullshit detector to say, yeah,

533
00:23:04,514 --> 00:23:07,437
I saw you put these prefetches in, but 95% of the time,

534
00:23:07,517 --> 00:23:08,558
they're prefetching from cache.

535
00:23:11,115 --> 00:23:13,957
So I'll just briefly show the GUI tool that

536
00:23:13,997 --> 00:23:14,638
comes along with this.

537
00:23:15,439 --> 00:23:19,322
This is a flat breakdown of things, which you can use to

538
00:23:19,362 --> 00:23:20,403
scan for anomalies.

539
00:23:20,423 --> 00:23:22,565
Like this should not have this many L2 misses or something.

540
00:23:23,526 --> 00:23:26,348
Because we tracked the call stacks, we can turn this into

541
00:23:26,508 --> 00:23:30,752
a tree that shows you from all the way from this root symbol

542
00:23:30,792 --> 00:23:33,595
across all the threads, like how the L2 misses and hits

543
00:23:33,615 --> 00:23:34,355
and everything breakdown.

544
00:23:35,667 --> 00:23:37,728
And you can reverse the tree, which is helpful when you're

545
00:23:37,748 --> 00:23:41,111
looking for who is to blame for this function missing cache.

546
00:23:42,833 --> 00:23:45,475
And that's how you can find things that are similar to

547
00:23:45,515 --> 00:23:47,196
that gameplay example that I showed previously.

548
00:23:48,798 --> 00:23:51,820
And finally, there's a way to go from symbol to source, and

549
00:23:51,840 --> 00:23:54,482
then see how the L2 misses and everything break down for

550
00:23:54,542 --> 00:23:55,323
those source lines.

551
00:23:58,065 --> 00:23:59,326
That's it for the tooling, really.

552
00:24:01,285 --> 00:24:05,507
A couple of things, like we wanted to make it obvious in the source, and you'll see that in a minute,

553
00:24:05,587 --> 00:24:07,709
how, like, what bad looks like.

554
00:24:08,089 --> 00:24:12,492
So we came up with this badness factor, which is the number of L2 misses squared

555
00:24:12,612 --> 00:24:15,693
divided by the number of instructions to really make it obvious that

556
00:24:16,474 --> 00:24:18,135
this line maybe warrants some attention.

557
00:24:19,776 --> 00:24:22,458
And in general, because it takes a little while to do the captures,

558
00:24:22,618 --> 00:24:25,719
I just found that it's worthwhile to put a bunch of views in here

559
00:24:25,739 --> 00:24:27,961
so you can reuse and go back to dumps after a while.

560
00:24:29,142 --> 00:24:33,371
So you'll see that if you look at the tools, that for example it resolves the symbols and then sticks them in the dump.

561
00:24:33,411 --> 00:24:35,496
So it's independent from the program and things like this.

562
00:24:37,219 --> 00:24:38,001
So just a real quick...

563
00:24:41,058 --> 00:24:43,099
Intro to how I found that first issue, right?

564
00:24:43,440 --> 00:24:46,101
If you look at the flat profile, you see, wait, why

565
00:24:46,141 --> 00:24:48,322
is this relatively well-optimized rendering code

566
00:24:48,342 --> 00:24:50,263
showing up here with 2,800 misses?

567
00:24:50,843 --> 00:24:53,084
When you go to the source view, that's the badness factor.

568
00:24:54,585 --> 00:24:56,445
This line is doing nothing but missing cache.

569
00:24:56,605 --> 00:24:57,546
This needs to be addressed.

570
00:24:57,606 --> 00:24:59,487
And from there on, you can relatively easily

571
00:24:59,527 --> 00:25:00,187
see what's going on.

572
00:25:02,008 --> 00:25:04,369
So to wrap up, the pros of this approach is that you get every

573
00:25:04,409 --> 00:25:05,469
memory access of the program.

574
00:25:06,995 --> 00:25:09,378
It doesn't cost you anything in terms of like you need to

575
00:25:09,458 --> 00:25:10,379
link with crazy things.

576
00:25:10,879 --> 00:25:12,281
It's not encumbered in any way, so you can

577
00:25:12,301 --> 00:25:12,801
just play with it.

578
00:25:13,582 --> 00:25:16,525
And because it works on Windows, you can go all the

579
00:25:16,565 --> 00:25:20,128
way into graphics drivers and the OS code if you want.

580
00:25:20,228 --> 00:25:22,290
It's kind of scary in there.

581
00:25:23,051 --> 00:25:25,894
So that might be interesting if you are a Windows dev and

582
00:25:25,914 --> 00:25:29,437
you're trying to look at some particular problematic PC

583
00:25:29,637 --> 00:25:30,318
architecture cache.

584
00:25:31,190 --> 00:25:32,454
And it's open source, like I mentioned.

585
00:25:32,514 --> 00:25:34,820
So if you need something that walks every instruction and

586
00:25:34,861 --> 00:25:36,846
every thread slowly, you can do this.

587
00:25:39,261 --> 00:25:40,682
As I mentioned, capture speed could be better.

588
00:25:41,022 --> 00:25:42,103
I'm sure we can optimize it.

589
00:25:43,444 --> 00:25:44,665
It only works on Windows.

590
00:25:45,165 --> 00:25:46,186
So yes.

591
00:25:46,647 --> 00:25:49,489
But you can still pretend that you're simulating a Jaguar

592
00:25:49,509 --> 00:25:50,349
cache, which we do.

593
00:25:50,389 --> 00:25:53,852
And it's not as bad as you might think, because if you

594
00:25:53,892 --> 00:25:56,374
ignore DX11 stuff and the operating system stuff, it

595
00:25:56,414 --> 00:25:59,136
doesn't really matter if your high-level rendering code or

596
00:25:59,176 --> 00:26:02,438
gameplay code has been compiled by Clang or MSVC.

597
00:26:02,678 --> 00:26:05,740
The number of memory accesses and where they go is pretty

598
00:26:05,820 --> 00:26:06,401
much the same.

599
00:26:08,310 --> 00:26:11,132
And of course, it's not 100% hardware accurate, right?

600
00:26:11,192 --> 00:26:13,775
Because we are treating the CPU as an in-order CPU here.

601
00:26:13,895 --> 00:26:15,296
It doesn't account for the out-of-order schedule

602
00:26:15,316 --> 00:26:17,418
in the window, which if you saw my talk from last year,

603
00:26:17,458 --> 00:26:19,159
doesn't account for that much anyway.

604
00:26:19,500 --> 00:26:23,703
Like, if you're seeing triple digits worth of L2 misses

605
00:26:23,843 --> 00:26:25,745
in a thing, like, it'll suck on out-of-order too.

606
00:26:25,765 --> 00:26:27,807
Like, it's, there's no magic fix.

607
00:26:29,538 --> 00:26:30,239
But it's a caveat.

608
00:26:30,900 --> 00:26:32,821
And there are a bunch of smaller issues,

609
00:26:32,861 --> 00:26:34,142
like it has to use virtual addresses

610
00:26:34,182 --> 00:26:35,283
to simulate the caches.

611
00:26:36,544 --> 00:26:38,786
The replacement line policy is not perfect.

612
00:26:39,786 --> 00:26:41,548
Array prefetchers are not yet simulated,

613
00:26:41,648 --> 00:26:44,530
so if you have very heavy sort of SIMD code walking arrays,

614
00:26:44,590 --> 00:26:46,712
like it'll over-report them pessimistically.

615
00:26:47,192 --> 00:26:48,933
So yes, some care is required.

616
00:26:50,163 --> 00:26:51,983
And that's what I hope to address in the future,

617
00:26:52,103 --> 00:26:53,304
some of those things, right?

618
00:26:53,344 --> 00:26:57,485
Make it faster and fix some of the prefetching stuff

619
00:26:57,525 --> 00:26:57,985
on the race.

620
00:26:58,586 --> 00:27:00,526
And I would like to implement all of the special things

621
00:27:00,566 --> 00:27:02,187
like non-temporal stores and loads

622
00:27:03,127 --> 00:27:05,068
and then whatever extensions you guys have.

623
00:27:06,908 --> 00:27:08,049
So that's my prepared talk on this.

624
00:27:09,349 --> 00:27:12,450
And you can get this right now at GitHub and play with it.

625
00:27:13,170 --> 00:27:16,592
And we have, I think, three minutes for questions.

626
00:27:30,187 --> 00:27:30,868
There's microphones.

627
00:27:39,251 --> 00:27:40,452
Hi, great stuff.

628
00:27:41,332 --> 00:27:44,254
What's the chances of actually being able to put this on a

629
00:27:44,774 --> 00:27:47,936
console platform if, for example, you didn't actually

630
00:27:47,976 --> 00:27:48,756
have a Windows build?

631
00:27:52,157 --> 00:27:52,758
Can't comment.

632
00:27:54,900 --> 00:27:55,821
All right.

633
00:27:55,881 --> 00:27:56,722
I should talk to some people.

634
00:27:56,742 --> 00:27:58,183
You should know and I should know that we

635
00:27:58,203 --> 00:27:58,904
can't talk about that.

636
00:27:59,024 --> 00:27:59,484
Yeah, I know.

637
00:27:59,604 --> 00:27:59,885
I know.

638
00:27:59,945 --> 00:28:00,965
We can talk about it offline.

639
00:28:01,065 --> 00:28:01,326
All right.

640
00:28:01,446 --> 00:28:01,906
Let's do that.

641
00:28:05,149 --> 00:28:05,529
Anyone else?

642
00:28:13,996 --> 00:28:14,236
All right.

643
00:28:14,596 --> 00:28:14,857
One more.

644
00:28:16,778 --> 00:28:17,399
Hi.

645
00:28:17,439 --> 00:28:20,581
Do you support multi-core interactions and evictions

646
00:28:20,621 --> 00:28:21,502
from the different clusters?

647
00:28:21,922 --> 00:28:22,383
That sort of thing?

648
00:28:23,181 --> 00:28:26,045
So yeah, in case not everyone heard,

649
00:28:26,166 --> 00:28:28,609
it's multi-core interaction supported in here.

650
00:28:29,130 --> 00:28:30,973
Yes, like all the threads are running independently,

651
00:28:31,133 --> 00:28:34,017
but because they're running through the Windows exception

652
00:28:34,057 --> 00:28:39,005
handling machinery, it won't be perfect, but it'll be.

653
00:28:39,725 --> 00:28:41,086
really kind of good.

654
00:28:41,246 --> 00:28:44,227
Like the Win32 scheduler gets all aggressive about this

655
00:28:44,347 --> 00:28:46,667
because all the threads are sort of spin locking and

656
00:28:46,687 --> 00:28:47,468
interrupting each other.

657
00:28:47,508 --> 00:28:49,588
So there's a good mix of things coming through.

658
00:28:50,108 --> 00:28:52,309
And the way the simulator works is that you pin all the

659
00:28:52,349 --> 00:28:54,570
threads that you care about to a particular hardware core.

660
00:28:54,970 --> 00:28:57,910
And then all the accesses that Win32 thread runs, regardless

661
00:28:57,930 --> 00:28:59,491
of physical core on the machine, is going to be

662
00:28:59,571 --> 00:29:03,112
simulated as if it came in always on, for example, core

663
00:29:03,292 --> 00:29:03,872
4 on your Jaguar.

664
00:29:04,032 --> 00:29:04,192
Cool.

665
00:29:04,593 --> 00:29:07,675
Would you see statistics as well for false sharing on

666
00:29:07,695 --> 00:29:08,215
cache lines?

667
00:29:08,235 --> 00:29:10,016
Do you ever expose that in your GUI?

668
00:29:12,478 --> 00:29:14,800
The question is, do we expose false sharing?

669
00:29:14,860 --> 00:29:16,061
No, we don't.

670
00:29:16,301 --> 00:29:17,041
Cool, thank you very much.

671
00:29:20,023 --> 00:29:22,565
How do you think it compares to Linux cache grind, which you

672
00:29:22,605 --> 00:29:23,546
mentioned early on?

673
00:29:25,127 --> 00:29:25,747
Sorry, one more time.

674
00:29:25,947 --> 00:29:28,609
You mentioned Linux cache grind from Valgrind?

675
00:29:28,869 --> 00:29:29,030
Yes.

676
00:29:29,554 --> 00:29:33,937
And how does it compare in terms of results or effectiveness?

677
00:29:34,398 --> 00:29:35,739
It does basically the same thing,

678
00:29:35,779 --> 00:29:38,721
but it does so in an opt-in way, you could say.

679
00:29:40,143 --> 00:29:41,644
So yes, it is comparable.

680
00:29:44,767 --> 00:29:46,048
I was just curious if you had a chance

681
00:29:46,108 --> 00:29:49,831
to look at the Intel hardware counters or anything like that.

682
00:29:50,712 --> 00:29:52,934
I don't know how well they're exposed in anything

683
00:29:52,974 --> 00:29:55,496
except Intel tools, but there's some kind of hooks

684
00:29:56,157 --> 00:29:57,418
into cache performance.

685
00:29:58,831 --> 00:30:00,833
Right, and that's what sampling protocols use.

686
00:30:00,913 --> 00:30:04,638
They're built on those hardware counters to get cache

687
00:30:04,698 --> 00:30:05,018
metrics.

688
00:30:06,340 --> 00:30:09,664
So the question is, how does this relate to hardware cache

689
00:30:09,724 --> 00:30:10,826
metrics you can get from the CPU?

690
00:30:11,313 --> 00:30:13,935
Yeah, I mean, I know things like VTune, I don't think it's

691
00:30:13,955 --> 00:30:16,277
presented very well, but they do have some information about

692
00:30:16,317 --> 00:30:17,398
like L1 and L2 access.

693
00:30:17,438 --> 00:30:19,880
That's what sampling profilers rely on, is sampling those

694
00:30:19,940 --> 00:30:20,640
hardware counters.

695
00:30:21,021 --> 00:30:23,142
I think there are four debug registers you can set, and you

696
00:30:23,162 --> 00:30:24,323
can sample up to four.

697
00:30:24,623 --> 00:30:28,166
There's 30 sensors or so that were things that you can read.

698
00:30:28,727 --> 00:30:31,269
And then the sampling profiler lets you pick a few of them.

699
00:30:31,869 --> 00:30:33,550
But it doesn't really know what instructions

700
00:30:33,610 --> 00:30:34,831
cost the L2 misses.

701
00:30:34,851 --> 00:30:36,212
That's the problem I'm trying to solve here.

702
00:30:36,913 --> 00:30:42,159
But that will give you accurate numbers for a run of instructions on a particular CPU

703
00:30:42,200 --> 00:30:47,186
that is in your machine, whereas this simulates that you're running it on a Jaguar CPU, regardless

704
00:30:47,206 --> 00:30:48,007
of what platform you're on.

705
00:30:50,477 --> 00:30:50,777
Hello.

706
00:30:51,117 --> 00:30:54,679
One question I have is whether you track how many times each

707
00:30:54,739 --> 00:30:56,100
instruction is executed.

708
00:30:56,220 --> 00:30:59,722
Because this sometimes gives valuable insights of whether

709
00:30:59,742 --> 00:31:03,905
you have a lot of cache misses, but also how many times

710
00:31:03,925 --> 00:31:05,206
that instruction was executed.

711
00:31:05,226 --> 00:31:07,427
So you basically have a cache miss rate.

712
00:31:07,847 --> 00:31:10,569
So you can know if there is a tiny loop which is executed

713
00:31:10,629 --> 00:31:12,310
many times and missing many times.

714
00:31:13,251 --> 00:31:15,012
I think the question is, do we count the number of times an

715
00:31:15,032 --> 00:31:15,812
instruction is executed?

716
00:31:15,852 --> 00:31:17,093
Yeah, kind of an instruction trace.

717
00:31:17,573 --> 00:31:17,913
Yes, we do.

718
00:31:18,114 --> 00:31:22,358
And that's the badness factor is actually based on the number of L2 misses squared divided

719
00:31:22,398 --> 00:31:23,819
by the number of instructions executed.

720
00:31:23,840 --> 00:31:24,340
Right?

721
00:31:24,360 --> 00:31:24,560
Okay.

722
00:31:24,780 --> 00:31:25,001
Okay.

723
00:31:25,061 --> 00:31:25,701
That's pretty cool.

724
00:31:25,782 --> 00:31:26,122
Thank you.

725
00:31:26,943 --> 00:31:27,143
Cool.

726
00:31:27,543 --> 00:31:27,824
All right.

727
00:31:28,665 --> 00:31:29,005
That's it.

728
00:31:29,345 --> 00:31:32,949
In case there are additional questions, find me outside in the conference and thank you.

