1
00:00:06,568 --> 00:00:09,490
So welcome to the performance and memory post-mortem

2
00:00:09,570 --> 00:00:11,391
for Middle-Earth Shadow of War.

3
00:00:11,931 --> 00:00:13,272
My name is Piotr Mintus.

4
00:00:13,292 --> 00:00:15,733
I'm a technical director at Monolith Productions.

5
00:00:16,494 --> 00:00:18,955
I've been with Monolith for the past 15 years.

6
00:00:19,455 --> 00:00:21,937
I originally joined the team at Monolith

7
00:00:21,977 --> 00:00:24,938
to work on a game whose code name was Action Movie,

8
00:00:25,759 --> 00:00:30,681
and it ended up shipping as Fear.

9
00:00:30,761 --> 00:00:33,603
Shadow of War uses the Firebird engine.

10
00:00:33,903 --> 00:00:35,564
It's a Monolith proprietary engine.

11
00:00:35,584 --> 00:00:35,964
This is the...

12
00:00:36,463 --> 00:00:38,524
engine that used to be called LifTech.

13
00:00:38,744 --> 00:00:41,325
It has been since rebranded to Firebird.

14
00:00:42,025 --> 00:00:44,285
And I've been working on this engine for the past 15 years

15
00:00:44,325 --> 00:00:44,625
as well.

16
00:00:46,546 --> 00:00:49,886
So Shadow of War is a third-person action adventure

17
00:00:49,906 --> 00:00:50,126
game.

18
00:00:50,987 --> 00:00:53,767
It retailed October 10 of last year.

19
00:00:53,787 --> 00:00:56,588
It sim-shipped on many different platforms.

20
00:00:58,108 --> 00:00:59,689
And from the very beginning, we were always

21
00:01:00,129 --> 00:01:02,609
targeting 30 frames per second on the consoles

22
00:01:03,069 --> 00:01:04,710
and 60 frames a second on the PC.

23
00:01:06,303 --> 00:01:09,787
And for those of you in the room who have not played Shadow of War,

24
00:01:09,847 --> 00:01:12,971
I'm going to play a short clip to kind of introduce you to the game,

25
00:01:13,592 --> 00:01:15,214
to kind of set the stage for this talk.

26
00:01:45,745 --> 00:01:47,867
Death calls to you again, Ranger.

27
00:01:47,907 --> 00:01:48,927
How do you answer?

28
00:01:49,007 --> 00:01:50,389
We bring this war to you.

29
00:02:57,101 --> 00:02:59,282
So Shadow of War uses the Nemesis system.

30
00:02:59,382 --> 00:03:01,383
We're not gonna be talking about the Nemesis system

31
00:03:01,403 --> 00:03:03,123
in this talk, as it's not really relevant

32
00:03:03,143 --> 00:03:05,084
to the performance and memory optimizations.

33
00:03:05,824 --> 00:03:08,866
However, it is a core design pillar of Shadow of War,

34
00:03:09,466 --> 00:03:12,707
and as such, it dictates that every single AI

35
00:03:12,767 --> 00:03:14,348
or character or actor you ever encounter

36
00:03:14,368 --> 00:03:15,328
in the game is unique.

37
00:03:15,988 --> 00:03:18,229
They have unique personalities, they have unique traits,

38
00:03:18,610 --> 00:03:20,790
but what's important to us right now for this talk

39
00:03:20,890 --> 00:03:22,191
is they have unique visuals.

40
00:03:23,191 --> 00:03:24,532
And the other thing I want you to take away

41
00:03:24,572 --> 00:03:26,793
from that last video is that.

42
00:03:27,921 --> 00:03:30,603
From Shadow of Mordor, now in Shadow of War,

43
00:03:30,623 --> 00:03:33,084
we're going to have a war, which really indicates

44
00:03:33,124 --> 00:03:34,005
there's going to be more.

45
00:03:36,186 --> 00:03:38,048
So this talk is broken up into two parts.

46
00:03:38,128 --> 00:03:40,369
We're first going to talk about the performance optimizations

47
00:03:40,389 --> 00:03:43,011
we did on Shadow of War, trying to get it run at a target

48
00:03:43,051 --> 00:03:44,292
frame rate that we were aiming for.

49
00:03:44,852 --> 00:03:46,293
And then after that, we're going to talk

50
00:03:46,333 --> 00:03:47,874
about how we actually got it to fit in memory,

51
00:03:47,894 --> 00:03:50,055
because we also had problems getting this game actually

52
00:03:50,095 --> 00:03:50,796
fitting into memory.

53
00:03:52,397 --> 00:03:54,458
So let's start with performance optimization.

54
00:03:56,200 --> 00:03:58,523
So back on Shadow of Mordor when we were working on the game,

55
00:03:58,543 --> 00:04:01,065
we actually were challenged by the fact

56
00:04:01,105 --> 00:04:05,209
that we moved from eight AI that we had in FEAR 2 over to 60 AI.

57
00:04:05,930 --> 00:04:08,732
There was a console transition that occurred at that time.

58
00:04:08,812 --> 00:04:11,775
However, the hardware did not have an almost 8x increase

59
00:04:11,815 --> 00:04:15,278
in performance, although we did increase our AI count by 8x,

60
00:04:15,899 --> 00:04:16,740
or about 8x.

61
00:04:18,228 --> 00:04:20,309
On Shadow of War, because we're going to do war,

62
00:04:20,389 --> 00:04:23,010
we need more than the 60 we had on Shadow of Mordor.

63
00:04:23,050 --> 00:04:25,050
So we decided, or design decided,

64
00:04:25,090 --> 00:04:26,951
to push the game to 200 AI.

65
00:04:28,351 --> 00:04:30,352
And I also want to emphasize that, once again, this

66
00:04:30,452 --> 00:04:31,572
is the Nemesis system.

67
00:04:31,612 --> 00:04:34,173
So it's 200 AI, but they're unique AI.

68
00:04:34,393 --> 00:04:36,193
And this is an issue for performance,

69
00:04:36,233 --> 00:04:39,954
especially for rendering, where you can't just stamp 200 guys

70
00:04:40,074 --> 00:04:41,275
out using instance rendering.

71
00:04:41,415 --> 00:04:44,295
We have to actually render unique guys every single time.

72
00:04:46,255 --> 00:04:49,718
So a quick table here of facts between Shadow of Mordor

73
00:04:49,738 --> 00:04:50,960
and Shadow of War and what changed.

74
00:04:50,980 --> 00:04:54,183
I already talked about the fact that we increased our AI count

75
00:04:54,203 --> 00:04:55,064
by almost 4x.

76
00:04:55,665 --> 00:04:59,048
But we also, since we moved exclusively

77
00:04:59,088 --> 00:05:01,431
to the current gen consoles, we no longer have a last gen

78
00:05:01,451 --> 00:05:04,314
version of the game, we increased our mesh counts

79
00:05:04,894 --> 00:05:07,457
to push them to a more higher fidelity

80
00:05:07,497 --> 00:05:08,618
than we had in the last project.

81
00:05:09,421 --> 00:05:12,323
And that went up almost 12x in count.

82
00:05:12,443 --> 00:05:14,724
And this is on the highest LOD, so it's the LOD

83
00:05:14,744 --> 00:05:16,225
you see really up close.

84
00:05:17,205 --> 00:05:19,426
Our mesh density went up by about 5x.

85
00:05:20,427 --> 00:05:22,608
We did this because on Shadow of Mordor,

86
00:05:22,708 --> 00:05:25,030
it was, again, cross-gen, and we used tessellation

87
00:05:25,050 --> 00:05:27,731
to tessellate for the current gen consoles.

88
00:05:28,411 --> 00:05:30,132
But now that we didn't have that issue,

89
00:05:30,172 --> 00:05:32,914
we actually increased the mesh density directly.

90
00:05:34,054 --> 00:05:35,635
And then our bone counts also doubled.

91
00:05:36,837 --> 00:05:38,197
We're gonna do some quick math here,

92
00:05:38,217 --> 00:05:39,959
and we're gonna get back to this math later,

93
00:05:40,059 --> 00:05:41,339
but since we're already on the slide,

94
00:05:42,100 --> 00:05:45,962
we got 48 pieces, and we have 64 bones per piece,

95
00:05:47,543 --> 00:05:50,825
and this gives us about 768 bones per character.

96
00:05:51,486 --> 00:05:53,027
We're gonna get back to this number later,

97
00:05:53,047 --> 00:05:55,668
because it is going to be relevant to the talk.

98
00:05:56,989 --> 00:05:59,711
Other systems that we pushed, we took our effects,

99
00:05:59,791 --> 00:06:01,632
and we decided, well, we're gonna need way more effects,

100
00:06:01,672 --> 00:06:05,314
so we actually increased our effects cost

101
00:06:05,334 --> 00:06:06,055
by about almost some.

102
00:06:06,833 --> 00:06:11,316
10X, our GPU particle emitters just skyrocketed.

103
00:06:11,997 --> 00:06:14,819
And our maps are about three times bigger per zone

104
00:06:15,040 --> 00:06:17,181
in Shadow of War versus Shadow of Mordor.

105
00:06:17,241 --> 00:06:19,704
So our nav mesh is three times as big too.

106
00:06:20,184 --> 00:06:23,487
And our nav mesh in both games actually spans the entire world,

107
00:06:23,807 --> 00:06:24,408
the entire level.

108
00:06:26,830 --> 00:06:30,893
So we're approaching beta, and we're

109
00:06:30,913 --> 00:06:33,956
profiling the game on the consoles on a PS4 or an Xbox

110
00:06:34,076 --> 00:06:34,196
One.

111
00:06:35,144 --> 00:06:37,345
And this is the result we get using the Shadow of Mordor

112
00:06:37,405 --> 00:06:37,665
engine.

113
00:06:37,745 --> 00:06:39,086
We pushed everything so far.

114
00:06:39,186 --> 00:06:41,248
We've got 200 guys now instead of the 60.

115
00:06:42,188 --> 00:06:44,330
They're all way more expensive to render.

116
00:06:44,990 --> 00:06:47,752
Just the AI logic and the rendering cost is insane.

117
00:06:48,453 --> 00:06:49,954
And so now we're at 90 milliseconds.

118
00:06:50,414 --> 00:06:52,075
And we're still trying to ship this game.

119
00:06:52,495 --> 00:06:53,976
And everyone's still pushing forward.

120
00:06:55,497 --> 00:06:57,679
So at the time, this was my reaction to it.

121
00:06:59,060 --> 00:07:02,002
And it was basically me running around the office screaming.

122
00:07:04,258 --> 00:07:06,740
So we have to, sorry, actually, I

123
00:07:06,760 --> 00:07:08,760
want to point out that from this point forward,

124
00:07:08,800 --> 00:07:11,121
we're actually going to be kind of going on the journey,

125
00:07:11,261 --> 00:07:14,583
trying to get this 90 milliseconds down to the 33.

126
00:07:15,283 --> 00:07:16,804
And that red line you see right there, that's a 33.

127
00:07:17,104 --> 00:07:18,304
That's our target frame rate.

128
00:07:19,205 --> 00:07:20,525
So for the rest of the performance talk,

129
00:07:20,565 --> 00:07:21,366
we'll be attacking that.

130
00:07:22,406 --> 00:07:24,047
So the first thing we're going to do to attack that

131
00:07:24,767 --> 00:07:26,608
is we're going to thread systems.

132
00:07:27,188 --> 00:07:29,809
The first thought that we had, well, let's thread some more.

133
00:07:29,969 --> 00:07:31,770
We threaded a bunch in Shadow Mortar.

134
00:07:32,251 --> 00:07:33,592
But we could thread more.

135
00:07:33,652 --> 00:07:36,893
We could see how we could offload some systems

136
00:07:36,953 --> 00:07:41,295
to make that performance increase.

137
00:07:42,055 --> 00:07:43,516
So obviously, we had 200 AI.

138
00:07:43,696 --> 00:07:45,877
That's a huge cost for our AI logic.

139
00:07:46,617 --> 00:07:50,559
So one of the systems we had to thread is just our AI logic.

140
00:07:51,260 --> 00:07:53,261
And there was actually a number of game systems

141
00:07:53,301 --> 00:07:54,741
that we ended up threading in the end.

142
00:07:54,941 --> 00:07:56,822
And I'm not really going to go into much detail

143
00:07:56,942 --> 00:07:59,123
on the individual game systems, as they are

144
00:07:59,163 --> 00:08:00,684
very specific to Shadow of War.

145
00:08:02,035 --> 00:08:04,897
But it was a huge undertaking for the engineering team,

146
00:08:04,957 --> 00:08:06,518
and it was a huge performance win.

147
00:08:06,658 --> 00:08:08,359
So it can't be understated.

148
00:08:09,960 --> 00:08:12,182
Here are some of the huge systems

149
00:08:12,202 --> 00:08:14,984
that we did end up threading in Shadow of War

150
00:08:15,004 --> 00:08:16,565
that were not threaded in Shadow of Mordor.

151
00:08:17,005 --> 00:08:19,366
So our effect system, again, we went from 2 milliseconds.

152
00:08:19,606 --> 00:08:20,407
Now it's 20.

153
00:08:20,587 --> 00:08:22,909
It can't just be on the main simulation thread.

154
00:08:23,529 --> 00:08:24,350
So it's been thrown off.

155
00:08:25,850 --> 00:08:27,011
AI, again, trying to.

156
00:08:28,313 --> 00:08:32,016
Control 200 AI for them to have all the logic and so on.

157
00:08:32,396 --> 00:08:34,198
That had to be threaded off to another thread.

158
00:08:35,299 --> 00:08:37,261
Pathfinding, now because we have 200 AI

159
00:08:37,281 --> 00:08:40,423
and the world is three times as big, you got 200 guys

160
00:08:40,583 --> 00:08:43,346
pathing all the time, searching a much bigger nav mesh.

161
00:08:44,046 --> 00:08:45,067
That had to be offloaded.

162
00:08:46,088 --> 00:08:48,850
Path regions, so we have destruction in the game.

163
00:08:50,304 --> 00:08:51,985
Every so often, something gets destroyed

164
00:08:52,105 --> 00:08:53,926
and ends up carving out the nav mesh, which

165
00:08:54,086 --> 00:08:57,288
then requires all the nav mesh regions to be updated.

166
00:08:57,328 --> 00:08:59,088
And that's a pretty significant cost.

167
00:08:59,108 --> 00:09:00,669
So again, that had to be offloaded.

168
00:09:01,750 --> 00:09:04,751
We also added a fire simulation to Shadow of War

169
00:09:04,791 --> 00:09:06,172
that did not exist in Shadow of Mordor.

170
00:09:06,872 --> 00:09:08,453
And we had to offload that, because that, too,

171
00:09:08,493 --> 00:09:09,353
was pretty expensive.

172
00:09:09,674 --> 00:09:12,595
And then finally, player and AI motion

173
00:09:12,635 --> 00:09:16,097
just got more complex since the last game.

174
00:09:16,577 --> 00:09:18,718
And as a result, it, too, had to be pushed off

175
00:09:18,738 --> 00:09:19,658
to a background thread.

176
00:09:21,868 --> 00:09:24,289
Things we could talk about, though, is one of the things

177
00:09:24,349 --> 00:09:26,270
we did in Shadow of Mordor, we started doing in Shadow

178
00:09:26,290 --> 00:09:28,231
of Mordor, is we moved to what we started introducing

179
00:09:28,251 --> 00:09:30,212
a lot of these lightweight atomic spinlocks.

180
00:09:31,432 --> 00:09:33,634
I'm not really going to get into what atomic spinlocks are.

181
00:09:33,694 --> 00:09:35,514
If you don't know what atomic spinlocks are,

182
00:09:35,534 --> 00:09:37,235
you could Google that, and you should

183
00:09:37,255 --> 00:09:40,077
be able to get examples of that pretty quickly.

184
00:09:41,778 --> 00:09:43,899
But what I'm trying to say here is we actually

185
00:09:43,959 --> 00:09:47,440
moved a lot of our systems to just using atomic spinlocks

186
00:09:47,540 --> 00:09:49,081
instead of using kernel parameters,

187
00:09:49,161 --> 00:09:50,502
such as critical section.

188
00:09:50,542 --> 00:09:51,282
So any time we were.

189
00:09:52,162 --> 00:09:55,263
doing any data access protection

190
00:09:55,283 --> 00:09:57,283
that we wanted to protect the data atomically.

191
00:09:57,823 --> 00:09:59,764
We are now using atomic spin locks.

192
00:10:00,364 --> 00:10:01,504
In most of our cases,

193
00:10:01,785 --> 00:10:03,425
there's no contention on those spin locks

194
00:10:03,445 --> 00:10:04,325
and when they do occur,

195
00:10:04,825 --> 00:10:06,146
what we're really looking for

196
00:10:06,286 --> 00:10:08,106
is to avoid a context switch

197
00:10:08,146 --> 00:10:09,807
and having our threads swapped out

198
00:10:10,407 --> 00:10:12,488
because the context switches are very expensive.

199
00:10:15,314 --> 00:10:17,575
the registers of the threads that were getting saved

200
00:10:17,635 --> 00:10:18,796
and restored, that's expensive.

201
00:10:18,856 --> 00:10:21,437
It's the fact that the caches will get evicted

202
00:10:21,477 --> 00:10:23,018
by the time your thread swaps back in,

203
00:10:23,038 --> 00:10:26,560
and you're gonna pay the cost of a cache miss all over again.

204
00:10:27,860 --> 00:10:29,641
And we still use kernel primitives

205
00:10:29,821 --> 00:10:32,062
if we actually do want a context switch.

206
00:10:33,943 --> 00:10:35,084
The other primitive we introduced

207
00:10:35,104 --> 00:10:36,805
that we didn't have at all in Shadow Mortar

208
00:10:37,065 --> 00:10:39,166
is a multiple-reader single-writer primitive.

209
00:10:40,238 --> 00:10:42,280
So what we use in Shadow Mortar for these scenarios

210
00:10:42,500 --> 00:10:44,642
was essentially a semaphore, a kernel semaphore,

211
00:10:44,662 --> 00:10:46,103
and those things are really expensive.

212
00:10:47,204 --> 00:10:49,706
But there are lightweight versions of that.

213
00:10:50,507 --> 00:10:52,809
Microsoft and Sony both have primitives for this.

214
00:10:53,109 --> 00:10:56,572
The Microsoft one is called the Slim Reader Writer lock,

215
00:10:56,932 --> 00:10:59,394
and if you Google that, you'll probably be taken

216
00:10:59,434 --> 00:11:00,535
straight to the MSDN page.

217
00:11:01,556 --> 00:11:03,557
And we use this, for example, for our physics system,

218
00:11:03,617 --> 00:11:06,620
where we have our physics system is written once a frame.

219
00:11:07,202 --> 00:11:08,902
But then for the rest of the frame,

220
00:11:09,142 --> 00:11:12,563
any thread on any core could read into that physics system.

221
00:11:13,803 --> 00:11:16,924
And using a semaphore for that was actually quite costly.

222
00:11:18,804 --> 00:11:20,745
You could also implement this primitive yourself

223
00:11:20,805 --> 00:11:24,126
without using either the Microsoft or Sony implementations

224
00:11:24,166 --> 00:11:25,886
by just using two atomic spinlocks

225
00:11:25,946 --> 00:11:27,767
that guard the reader and the writer,

226
00:11:28,327 --> 00:11:29,367
and then an atomic counter

227
00:11:29,467 --> 00:11:32,388
that counts the current active readers.

228
00:11:35,147 --> 00:11:37,487
The other thing we started looking at is on the consoles,

229
00:11:37,527 --> 00:11:39,108
you have two CPU clusters.

230
00:11:39,308 --> 00:11:41,448
Each CPU cluster has four cores,

231
00:11:42,268 --> 00:11:44,729
and all those four cores show a single L2 cache.

232
00:11:45,589 --> 00:11:48,250
The problem that we started seeing on Shadow of War

233
00:11:48,330 --> 00:11:50,130
is we started threading everything,

234
00:11:50,190 --> 00:11:51,671
and so what ended up happening is,

235
00:11:52,391 --> 00:11:55,111
on the single cluster, all four cores were pegged.

236
00:11:55,171 --> 00:11:57,092
They were all maxed out 100%,

237
00:11:57,952 --> 00:12:00,893
constantly using that shared L2 cache.

238
00:12:01,609 --> 00:12:04,451
And each core was essentially evicting the data

239
00:12:04,511 --> 00:12:05,692
that another core just put in.

240
00:12:05,732 --> 00:12:07,813
And they were all just fighting between this data that

241
00:12:07,853 --> 00:12:10,736
was in and out and just thrashing the cache nonstop.

242
00:12:11,616 --> 00:12:13,558
So we started looking into ways of how could we

243
00:12:13,618 --> 00:12:14,759
avoid all this thrashing?

244
00:12:14,799 --> 00:12:18,582
Can we somehow find solutions where more of our data

245
00:12:18,642 --> 00:12:20,744
remains in the cache without it being evicted?

246
00:12:21,964 --> 00:12:24,907
And so we realized that we could probably segregate the game

247
00:12:24,947 --> 00:12:26,088
logic from the renderer.

248
00:12:26,508 --> 00:12:28,970
And what we ended up doing is we put the entire renderer

249
00:12:29,270 --> 00:12:30,191
on the second cluster.

250
00:12:30,750 --> 00:12:33,290
and we kept all the gameplay logic in the first cluster.

251
00:12:34,971 --> 00:12:36,992
And for Shadow of War, because there was so much stuff going

252
00:12:37,112 --> 00:12:39,793
on, this actually gave us about a 10% performance gain

253
00:12:40,313 --> 00:12:43,674
once we actually achieved this and did it properly.

254
00:12:44,554 --> 00:12:46,194
The problem is actually achieving this,

255
00:12:46,315 --> 00:12:48,935
because we actually tried to do this exact same thing

256
00:12:48,995 --> 00:12:50,876
on Shadow of Mortar a few times, and we

257
00:12:50,956 --> 00:12:52,016
failed every single time.

258
00:12:52,236 --> 00:12:55,097
But we reached our performance target without this,

259
00:12:55,137 --> 00:12:56,778
so we ended up just shelving it.

260
00:12:57,658 --> 00:12:58,858
But on Shadow of War, we were just

261
00:12:59,508 --> 00:13:02,430
performing so poorly that we had to re-evaluate this

262
00:13:02,470 --> 00:13:03,471
and see if we could make it work.

263
00:13:04,232 --> 00:13:08,175
The problem occurs in scenarios where you have data

264
00:13:08,295 --> 00:13:11,458
in both CPU clusters that are in one of the other caches

265
00:13:12,058 --> 00:13:13,679
and they're both being accessed at the same time.

266
00:13:13,740 --> 00:13:15,721
This causes both of the CPU clusters

267
00:13:15,761 --> 00:13:18,123
to do a really expensive sync

268
00:13:18,864 --> 00:13:21,126
and that sync is extremely expensive.

269
00:13:21,186 --> 00:13:24,108
So if you attempt this for the very first time,

270
00:13:24,148 --> 00:13:26,170
you'll probably see a massive negative win

271
00:13:27,431 --> 00:13:29,172
or just a loss in performance.

272
00:13:30,008 --> 00:13:31,469
So it took us a while, and that's

273
00:13:31,489 --> 00:13:34,370
why I'm calling it black magic, because it's basically

274
00:13:34,950 --> 00:13:37,211
looking at your data and trying to figure out

275
00:13:37,372 --> 00:13:40,413
what could possibly be in a cache that is stalling me,

276
00:13:41,193 --> 00:13:42,254
until you figure it out.

277
00:13:42,374 --> 00:13:43,655
And then all of a sudden, oh, look at that.

278
00:13:43,675 --> 00:13:44,915
We got a 10% performance gain.

279
00:13:47,937 --> 00:13:49,638
So at Monolith, when we thread our systems,

280
00:13:50,258 --> 00:13:51,538
our approach to threading our systems

281
00:13:51,578 --> 00:13:54,100
is actually we try to keep our jobs really large.

282
00:13:55,483 --> 00:14:00,106
We no longer have SPUs, so we don't have a hardware limit on the size of our jobs.

283
00:14:01,147 --> 00:14:05,530
And so, because of that, we prefer to keep our jobs large.

284
00:14:05,570 --> 00:14:09,893
And we do that because we have a lot of junior engineers that come in and we're not really...

285
00:14:11,655 --> 00:14:14,357
We don't really trust them with threading a lot of systems.

286
00:14:16,598 --> 00:14:17,059
It takes...

287
00:14:18,240 --> 00:14:21,682
From my personal experience, it takes a few...

288
00:14:22,725 --> 00:14:26,870
years of experience to really know how to properly write threaded code and what the

289
00:14:26,910 --> 00:14:28,812
patterns are and what to look for and so on.

290
00:14:29,653 --> 00:14:32,756
And if you don't do it right, everything might work, but you'll have a race condition that

291
00:14:32,796 --> 00:14:35,920
shows up in a crash once a week or something like that.

292
00:14:35,940 --> 00:14:41,707
And trying to track that back down is such a pain that we just try to avoid that as much

293
00:14:41,747 --> 00:14:42,207
as possible.

294
00:14:44,142 --> 00:14:46,064
By keeping our jobs large, we also

295
00:14:46,144 --> 00:14:47,985
avoid a lot of synchronization.

296
00:14:48,005 --> 00:14:49,827
Because no matter how you synchronize your jobs,

297
00:14:49,867 --> 00:14:53,089
even if it's really fast, the more synchronizations you have,

298
00:14:54,390 --> 00:14:56,092
it's always going to be slower than not having them.

299
00:14:58,314 --> 00:15:02,177
And large jobs also kind of utilize the CPU cache

300
00:15:02,217 --> 00:15:04,959
a little bit better, mostly because if you're

301
00:15:05,420 --> 00:15:07,782
crunching on this data all on a single core,

302
00:15:08,422 --> 00:15:10,064
all your data is in that L2 cache.

303
00:15:10,124 --> 00:15:12,025
It's all in the L1 cache of that single core.

304
00:15:12,045 --> 00:15:12,626
If you split it up.

305
00:15:13,775 --> 00:15:16,856
Obviously, the L1 is not shared, so you might have to go back

306
00:15:16,896 --> 00:15:18,916
to the L2, or you might have to go back to memory

307
00:15:18,956 --> 00:15:19,917
to get the data you need.

308
00:15:20,757 --> 00:15:23,558
It's not a huge win, but it is a pro.

309
00:15:25,598 --> 00:15:29,059
So the way we approach these large jobs is we kind of move

310
00:15:29,139 --> 00:15:30,600
our entire large systems over.

311
00:15:30,640 --> 00:15:33,901
We don't try to thread the individual system.

312
00:15:33,961 --> 00:15:35,161
We just move the entire system.

313
00:15:35,201 --> 00:15:37,742
So for instance, our effects system,

314
00:15:37,942 --> 00:15:39,822
we move the entire effects system over.

315
00:15:39,862 --> 00:15:42,783
We didn't thread individual keys and created a million little

316
00:15:44,397 --> 00:15:48,038
evaluate the keys, we didn't thread the actual effect

317
00:15:48,178 --> 00:15:50,379
at an effect level, we actually did the entire

318
00:15:51,080 --> 00:15:54,201
frame level system of here's the effects for the frame.

319
00:15:54,962 --> 00:15:58,063
They're all gonna execute on a single core elsewhere.

320
00:15:59,084 --> 00:16:02,385
And the way we schedule these across all of our cores

321
00:16:02,405 --> 00:16:05,427
is perhaps a little bit chaotic,

322
00:16:05,467 --> 00:16:08,128
but what we have is a spreadsheet essentially,

323
00:16:08,168 --> 00:16:09,609
where we have here's all of our cores,

324
00:16:09,949 --> 00:16:12,010
here's all of our really heavy duty threads.

325
00:16:12,754 --> 00:16:14,835
We basically map them out onto those cores.

326
00:16:14,875 --> 00:16:16,695
We give them fixed affinities.

327
00:16:18,175 --> 00:16:20,196
And they are not allowed to ever jump cores.

328
00:16:20,236 --> 00:16:22,356
They're always executed on that exact one core.

329
00:16:22,376 --> 00:16:25,797
And if you have two threads that don't fully take

330
00:16:25,837 --> 00:16:27,557
a full frame, or three or four,

331
00:16:27,637 --> 00:16:29,478
we basically map them out on that core.

332
00:16:30,818 --> 00:16:33,199
Every single one of these systems has a budget

333
00:16:33,299 --> 00:16:34,619
that it shouldn't exceed.

334
00:16:35,279 --> 00:16:36,619
And we just kind of have a layout,

335
00:16:36,859 --> 00:16:38,220
core layout of all of our threads.

336
00:16:39,892 --> 00:16:41,653
There's obviously a lot of downsides to this.

337
00:16:42,234 --> 00:16:44,155
Unlike a traditional job system

338
00:16:44,175 --> 00:16:45,816
that has a lot of small cores,

339
00:16:45,936 --> 00:16:49,918
none of these will pack really nicely

340
00:16:49,958 --> 00:16:54,560
into a nice, thin, kind of like a Tetris style

341
00:16:54,620 --> 00:16:56,481
where all the blocks just fit and the line's clear.

342
00:16:57,822 --> 00:16:59,643
The other problem is that,

343
00:17:03,025 --> 00:17:04,726
crap, I actually forgot what the other problem is.

344
00:17:05,126 --> 00:17:07,788
So, we're gonna skip the other problem.

345
00:17:09,031 --> 00:17:10,251
Oh, actually, no, I remember.

346
00:17:10,351 --> 00:17:10,551
Woo!

347
00:17:11,271 --> 00:17:11,571
All right.

348
00:17:11,891 --> 00:17:12,992
If you get a new console,

349
00:17:14,172 --> 00:17:16,052
and it say this time it doesn't have the six cores

350
00:17:16,072 --> 00:17:17,533
that the current consoles have, it has 12,

351
00:17:19,773 --> 00:17:20,533
it's not gonna scale.

352
00:17:20,673 --> 00:17:22,913
It's that we can't just pop Shadow of War into that,

353
00:17:23,094 --> 00:17:23,854
and all of a sudden it's,

354
00:17:23,914 --> 00:17:25,654
yeah, we're taking advantage of all those 12 cores,

355
00:17:25,674 --> 00:17:27,234
because we've mapped these out individually.

356
00:17:28,935 --> 00:17:31,215
So we basically would have to go back,

357
00:17:31,755 --> 00:17:34,236
remap them, probably rethread them,

358
00:17:34,256 --> 00:17:36,156
because each individual one is now too long.

359
00:17:37,031 --> 00:17:39,312
So it doesn't really scale, but for this product

360
00:17:39,472 --> 00:17:41,794
and for the hardware that we had, this worked for us.

361
00:17:43,355 --> 00:17:45,677
So I mentioned our first problem was the CPU gaps.

362
00:17:45,837 --> 00:17:49,239
So the way we approach those gaps on the CPU is we kind

363
00:17:49,279 --> 00:17:51,541
of use the same technique that the GPU does

364
00:17:51,621 --> 00:17:53,102
with asynchronous compute.

365
00:17:54,623 --> 00:17:58,987
So what we have is we have these hard working threads

366
00:17:59,067 --> 00:18:02,169
with these giant systems that are authenticized to these cores.

367
00:18:02,209 --> 00:18:04,150
But then we have low priority threads that could jump

368
00:18:04,230 --> 00:18:04,891
in anytime these.

369
00:18:05,884 --> 00:18:11,706
large systems slow down or basically switch out and sleep.

370
00:18:12,826 --> 00:18:14,886
So we have a bunch of these low priority threads

371
00:18:14,926 --> 00:18:17,827
such as file IO, streaming, audio streaming,

372
00:18:18,367 --> 00:18:20,728
and we have this concept of asynchronous raycasts

373
00:18:20,828 --> 00:18:22,248
where on the very beginning of the frame,

374
00:18:22,949 --> 00:18:26,849
the game might request, oh, I need these 500 raycasts,

375
00:18:27,270 --> 00:18:28,250
but I don't need them now.

376
00:18:28,310 --> 00:18:32,531
I'm gonna get the results 25 milliseconds into the frame.

377
00:18:33,167 --> 00:18:36,347
So you have 25 milliseconds to find some CPU gap somewhere

378
00:18:36,847 --> 00:18:38,648
to gather these raycasts.

379
00:18:40,168 --> 00:18:42,809
So a quick example of that, imagine this is a single core.

380
00:18:43,209 --> 00:18:45,089
It's our whole 33 milliseconds.

381
00:18:46,449 --> 00:18:47,709
We have one giant thread.

382
00:18:47,990 --> 00:18:50,170
Let's just call this the render thread.

383
00:18:50,290 --> 00:18:52,170
So the render threads didn't have any work

384
00:18:52,230 --> 00:18:55,951
in the very beginning because the simulation thread didn't

385
00:18:56,351 --> 00:18:57,371
give it any work to do yet.

386
00:18:58,572 --> 00:19:00,152
Then it had a bunch of work until about maybe

387
00:19:00,172 --> 00:19:01,272
the 80-millisecond mark.

388
00:19:02,544 --> 00:19:04,384
But then it ran out of work, so it went to sleep.

389
00:19:05,465 --> 00:19:08,166
And then it came back at around the 25 millisecond mark.

390
00:19:09,447 --> 00:19:11,448
So then there was a low priority thread just hanging around.

391
00:19:11,728 --> 00:19:13,349
Maybe it was doing our texture streaming.

392
00:19:13,509 --> 00:19:16,950
So it was streaming our textures, but it's low priority.

393
00:19:16,971 --> 00:19:18,311
We don't really care if that texture comes

394
00:19:18,351 --> 00:19:20,332
in this exact frame or the next frame.

395
00:19:21,553 --> 00:19:24,114
So it's executing, it's doing its work.

396
00:19:24,154 --> 00:19:25,495
All of a sudden this render thread came in

397
00:19:25,515 --> 00:19:26,515
and kicked it out of the way.

398
00:19:26,775 --> 00:19:27,896
The render thread executes.

399
00:19:28,636 --> 00:19:30,777
Texture streaming resumes, texture streaming is done.

400
00:19:31,902 --> 00:19:33,243
We have another thread that comes in.

401
00:19:34,364 --> 00:19:35,865
In this case, maybe it's audio streaming.

402
00:19:36,186 --> 00:19:37,146
It does some work.

403
00:19:37,907 --> 00:19:40,569
It gets all its work done.

404
00:19:41,210 --> 00:19:43,852
And then there was a little gap remaining,

405
00:19:43,952 --> 00:19:48,376
so maybe the asynchronous raycast

406
00:19:49,737 --> 00:19:50,858
basically took that little gap.

407
00:19:52,379 --> 00:19:55,701
So I was gonna show you a first-party trace of this

408
00:19:55,802 --> 00:19:57,483
in Shadow of War in the worst-case scenario,

409
00:19:57,623 --> 00:19:59,945
but I wasn't able to get those slides.

410
00:20:01,298 --> 00:20:03,839
You're going to have to trust me.

411
00:20:03,999 --> 00:20:06,360
There are scenarios in Shadow of War, if you ever played it,

412
00:20:06,480 --> 00:20:08,940
you do those Fort Assaults where things get super crazy.

413
00:20:09,641 --> 00:20:11,321
And we have every single core that basically

414
00:20:11,341 --> 00:20:12,921
looks exactly like this, that fills up

415
00:20:12,961 --> 00:20:16,522
to about 99% CPU utilization across every single core

416
00:20:16,542 --> 00:20:17,142
in the consoles.

417
00:20:18,683 --> 00:20:22,724
And we were basically barely running at 30 there.

418
00:20:25,020 --> 00:20:29,001
So this large and powerful approach that we use at Monolith,

419
00:20:29,602 --> 00:20:32,542
we kind of love to call this thing the monolithic approach.

420
00:20:33,843 --> 00:20:34,123
Get it?

421
00:20:38,644 --> 00:20:41,405
So, all jokes aside though, I just want to point out

422
00:20:41,425 --> 00:20:43,466
that we're not really advocating for this approach.

423
00:20:43,526 --> 00:20:45,746
The reason we actually took this approach was,

424
00:20:45,766 --> 00:20:49,047
a lot of it was due to just resource limitations

425
00:20:49,107 --> 00:20:49,987
and time constraints.

426
00:20:50,568 --> 00:20:53,168
It was an easier approach for us to take than to,

427
00:20:53,881 --> 00:20:56,162
invest into, for instance, the effects system,

428
00:20:56,783 --> 00:20:59,845
threading the entire system with a million different jobs.

429
00:21:00,005 --> 00:21:01,866
It was a lot easier to just move the whole thing over.

430
00:21:02,847 --> 00:21:05,168
And inside the system, the entire effects system

431
00:21:05,188 --> 00:21:07,950
remained single threaded, so none of that had to change.

432
00:21:08,090 --> 00:21:10,412
It was just the input and the output of the system

433
00:21:10,432 --> 00:21:11,553
that had to be synchronized.

434
00:21:14,294 --> 00:21:18,197
So the other thing we do on Shadow of War,

435
00:21:18,297 --> 00:21:20,158
and we actually did some of this on Shadow of Mordor,

436
00:21:20,719 --> 00:21:21,439
is we pipeline.

437
00:21:22,683 --> 00:21:25,686
And what pipelining is, is we, as opposed to just spawning

438
00:21:25,706 --> 00:21:27,627
off threads and then joining them back in,

439
00:21:28,027 --> 00:21:30,509
we pipeline our threads out.

440
00:21:30,529 --> 00:21:34,632
We pipeline, we have a water falling pipeline

441
00:21:34,712 --> 00:21:38,655
where we have work, we offload work to another core,

442
00:21:38,675 --> 00:21:41,657
to another thread, and this thread runs on another core

443
00:21:41,757 --> 00:21:43,718
simultaneously as the original thread.

444
00:21:44,479 --> 00:21:47,000
And we use these circular command buffers

445
00:21:47,041 --> 00:21:48,441
to pipeline this work over.

446
00:21:48,462 --> 00:21:49,882
And we do this mostly for the renderer, so.

447
00:21:52,815 --> 00:21:54,975
We do this so that every single one of these stages

448
00:21:55,035 --> 00:21:56,696
in our pipeline gets a full frame

449
00:21:56,816 --> 00:21:58,536
and doesn't have to be synchronized back

450
00:21:58,796 --> 00:22:03,017
in to the first originating thread on the very beginning.

451
00:22:03,337 --> 00:22:04,597
Because then they wouldn't get the full 33

452
00:22:05,177 --> 00:22:06,138
milliseconds of a frame.

453
00:22:07,298 --> 00:22:08,518
So let's take a quick look at this.

454
00:22:10,218 --> 00:22:12,339
So our first stage of our pipeline

455
00:22:12,379 --> 00:22:13,259
is a simulation thread.

456
00:22:14,739 --> 00:22:15,940
It's 33 milliseconds.

457
00:22:16,740 --> 00:22:19,320
Next stage, it pipelines work into the render thread.

458
00:22:21,134 --> 00:22:22,796
it also gets 33 milliseconds.

459
00:22:22,956 --> 00:22:25,598
Then we have a thread that we call the driver thread.

460
00:22:25,878 --> 00:22:28,741
It's, you can think of this as the render thread

461
00:22:28,781 --> 00:22:30,482
being the platform agnostic renderer

462
00:22:31,183 --> 00:22:34,146
and the driver thread being the platform specific renderer.

463
00:22:34,946 --> 00:22:36,348
So the platform specific renderer

464
00:22:36,388 --> 00:22:38,830
now gets a full frame of 33 milliseconds.

465
00:22:39,370 --> 00:22:41,472
It ends up writing out the GPU command buffer.

466
00:22:42,013 --> 00:22:44,014
That ends up getting a full 33 milliseconds

467
00:22:44,034 --> 00:22:45,496
to execute on the GPU now.

468
00:22:46,377 --> 00:22:47,678
Once it's done it for a frame.

469
00:22:48,435 --> 00:22:50,497
It ends up writing out the frame buffer,

470
00:22:50,637 --> 00:22:54,360
and then it puts it into the display queue,

471
00:22:54,500 --> 00:22:55,761
and that is that little block there.

472
00:22:55,781 --> 00:22:56,682
That's the display queue.

473
00:22:57,623 --> 00:23:00,525
Once a V blank occurs, we can now flip,

474
00:23:00,806 --> 00:23:03,028
and now it gets displayed on the screen for, again,

475
00:23:04,009 --> 00:23:04,489
33 milliseconds.

476
00:23:05,870 --> 00:23:07,251
And when you show all the frames,

477
00:23:07,291 --> 00:23:08,512
it looks something like this.

478
00:23:09,053 --> 00:23:10,494
And this is actually, I want to point out,

479
00:23:10,895 --> 00:23:12,896
the best case scenario for pipelining,

480
00:23:13,057 --> 00:23:15,919
because I'm going to show you the worst case in a bit.

481
00:23:17,322 --> 00:23:19,303
So this red line here is only here

482
00:23:19,323 --> 00:23:20,504
to illustrate my point.

483
00:23:21,365 --> 00:23:24,508
If we spawned the render thread off of the simulation thread

484
00:23:24,588 --> 00:23:26,089
and then asked for it to join back

485
00:23:26,149 --> 00:23:27,470
before the simulation thread ended,

486
00:23:28,091 --> 00:23:31,333
then we wouldn't have a full 33 milliseconds

487
00:23:31,353 --> 00:23:32,034
for the render thread.

488
00:23:32,674 --> 00:23:34,116
And then the same thing for the driver thread.

489
00:23:34,176 --> 00:23:35,637
If it spawned from the render thread

490
00:23:35,657 --> 00:23:36,758
and then joined back in,

491
00:23:37,779 --> 00:23:40,301
it would not get the full 33 milliseconds.

492
00:23:40,661 --> 00:23:42,583
And this only applies to the CPU workload,

493
00:23:42,623 --> 00:23:44,324
so only the blue rows.

494
00:23:44,917 --> 00:23:47,379
Because the GPU, that is just how the GPU works,

495
00:23:47,419 --> 00:23:48,620
and we have no control over that.

496
00:23:52,283 --> 00:23:54,505
So when we pipeline our threads, we

497
00:23:55,045 --> 00:23:57,687
make sure that none of these stages in our pipeline

498
00:23:58,168 --> 00:23:59,689
falls behind by more than one frame.

499
00:23:59,729 --> 00:24:02,071
If it does fall behind by more than one frame,

500
00:24:02,912 --> 00:24:05,073
we end up stalling the stages before it.

501
00:24:07,035 --> 00:24:07,235
So.

502
00:24:07,987 --> 00:24:09,728
Ideally, what we want out of our pipeline

503
00:24:09,868 --> 00:24:11,588
is the picture I showed you at the very beginning,

504
00:24:11,668 --> 00:24:14,490
where every single stage executes just maybe

505
00:24:14,530 --> 00:24:16,151
a couple milliseconds after the other.

506
00:24:16,171 --> 00:24:19,953
And as a result, the end user can't really

507
00:24:20,013 --> 00:24:22,414
tell that this pipelining is occurring,

508
00:24:22,434 --> 00:24:26,096
because the entire pipeline is maybe adding at a maximum maybe

509
00:24:26,296 --> 00:24:27,296
10 milliseconds to the frame.

510
00:24:28,117 --> 00:24:29,357
And no one playing the game is going

511
00:24:29,377 --> 00:24:31,559
to notice that there's an extra 10 milliseconds going on.

512
00:24:32,839 --> 00:24:35,140
And all this is great, as long as the first stage is

513
00:24:35,160 --> 00:24:36,201
the stage that you're bound by.

514
00:24:38,437 --> 00:24:41,199
But in retail, we're actually bound by the last stage.

515
00:24:41,239 --> 00:24:43,420
Because in retail, the last stage is the V blank.

516
00:24:43,921 --> 00:24:45,742
The V blank is always taking exactly 33.

517
00:24:46,283 --> 00:24:50,306
And if we did our jobs correctly and we're not dropping frames,

518
00:24:50,466 --> 00:24:55,189
every other stage has to take exactly less than 33 in order

519
00:24:55,249 --> 00:24:58,292
to not drop those frames, which makes that very last stage be

520
00:24:58,312 --> 00:25:00,733
the stage that we're bound by.

521
00:25:01,194 --> 00:25:02,715
When this happens, our entire pipeline

522
00:25:02,735 --> 00:25:04,036
just starts telescoping out.

523
00:25:04,056 --> 00:25:05,677
Because every single stage before it,

524
00:25:06,752 --> 00:25:10,594
is now basically blocked on this one frame behind scenario.

525
00:25:14,256 --> 00:25:17,738
So when this occurs, here's our stages, our six pipeline

526
00:25:17,758 --> 00:25:18,179
stages.

527
00:25:19,239 --> 00:25:21,461
And if every single one of these stages

528
00:25:21,661 --> 00:25:24,683
gets 33 milliseconds, because it's exactly one frame behind,

529
00:25:25,443 --> 00:25:27,844
the net result of this is that now what

530
00:25:27,864 --> 00:25:30,026
you're seeing on the screen is 200 milliseconds

531
00:25:30,086 --> 00:25:31,867
behind the very first stage in our pipeline.

532
00:25:33,428 --> 00:25:36,290
This is a huge problem for us because at that point.

533
00:25:36,705 --> 00:25:39,205
Now we have a 200 milliseconds input latency,

534
00:25:39,225 --> 00:25:42,666
because we actually got their input on that first stage,

535
00:25:43,046 --> 00:25:44,587
and all the rest of the stages are rendering,

536
00:25:44,667 --> 00:25:46,127
and we're not doing input in the renderer.

537
00:25:47,907 --> 00:25:49,388
And 200 milliseconds is something

538
00:25:49,428 --> 00:25:50,868
that is noticeable to the end user.

539
00:25:52,369 --> 00:25:54,669
So in order to solve this telescoping issue,

540
00:25:54,929 --> 00:25:57,830
we implemented a dynamic frame pacing system.

541
00:25:58,770 --> 00:26:00,410
So what we do is, on the consoles,

542
00:26:00,430 --> 00:26:02,111
you could actually monitor display queue.

543
00:26:03,477 --> 00:26:05,718
find out exactly how many frames you have buffered up

544
00:26:05,898 --> 00:26:07,779
in that display queue that are waiting, be blank.

545
00:26:08,500 --> 00:26:10,360
So we're sitting there every single frame,

546
00:26:10,440 --> 00:26:11,721
checking what's going on,

547
00:26:11,801 --> 00:26:13,222
how many frames do we have buffered up.

548
00:26:14,682 --> 00:26:18,984
If we have too many, or if there are frames buffered up,

549
00:26:19,124 --> 00:26:21,945
then we know we are now GPU bound, we're telescoping out.

550
00:26:22,646 --> 00:26:25,907
And when this occurs, we try to basically compensate for that

551
00:26:26,027 --> 00:26:29,489
by going back to the very first stage in the pipelining

552
00:26:29,589 --> 00:26:30,589
into our simulation thread.

553
00:26:31,215 --> 00:26:33,216
and making sure that it takes longer

554
00:26:33,256 --> 00:26:34,537
than any rest of those stages.

555
00:26:34,557 --> 00:26:36,458
So we know the last stage is 33.3,

556
00:26:37,098 --> 00:26:40,260
so we have to have this first stage take longer than 33.3.

557
00:26:40,900 --> 00:26:43,402
So what we do is we basically give it an extra millisecond

558
00:26:43,642 --> 00:26:44,962
every single frame to try to,

559
00:26:45,623 --> 00:26:47,604
and by doing so, it ends up contracting

560
00:26:47,624 --> 00:26:48,504
the entire telescope.

561
00:26:52,466 --> 00:26:53,587
So here's an example of that.

562
00:26:54,467 --> 00:26:55,708
So imagine if our

563
00:26:57,442 --> 00:27:00,084
Actual simulation thread typically just takes 30 milliseconds

564
00:27:00,104 --> 00:27:02,566
because it's not missing frames.

565
00:27:02,927 --> 00:27:05,128
30 milliseconds could be a good number to hit.

566
00:27:06,529 --> 00:27:09,432
And we're going to go and say the render thread is also taking 30.

567
00:27:09,712 --> 00:27:10,953
Driver thread is also taking 30.

568
00:27:11,013 --> 00:27:14,596
The GPU is taking 33.

569
00:27:15,637 --> 00:27:18,099
But then this play queue is now taking a full frame too

570
00:27:18,119 --> 00:27:21,041
because it's full and it's waiting for that next V-blank.

571
00:27:22,142 --> 00:27:23,543
And then it finally gets displayed on the screen.

572
00:27:24,517 --> 00:27:25,998
So as you can see, the entire pipeline

573
00:27:26,058 --> 00:27:27,519
is kind of being telescoped out.

574
00:27:27,539 --> 00:27:28,780
And this is not the worst case.

575
00:27:29,160 --> 00:27:30,861
I tried to do the worst case on the slides,

576
00:27:30,941 --> 00:27:32,522
but it would go way off the slides.

577
00:27:32,782 --> 00:27:34,584
So this is kind of the best you guys are getting.

578
00:27:35,564 --> 00:27:36,985
But you kind of get the idea here.

579
00:27:38,746 --> 00:27:40,627
In the worst case, every single one of these blocks

580
00:27:40,667 --> 00:27:42,769
would basically be connected tip to tail,

581
00:27:42,869 --> 00:27:44,750
and it would telescope way out.

582
00:27:45,470 --> 00:27:47,011
So we detected the display queue was full.

583
00:27:47,832 --> 00:27:50,514
And so for the next frame, we had the simulation artificially

584
00:27:50,554 --> 00:27:52,275
stalled until 34 milliseconds.

585
00:27:53,272 --> 00:27:54,913
We leave all the rest of the stages alone.

586
00:27:56,654 --> 00:27:59,735
First time around, this doesn't really do much to the frame.

587
00:28:01,556 --> 00:28:03,277
And so everything still appears about the same.

588
00:28:05,158 --> 00:28:07,199
But then on the next frame, we're still doing this

589
00:28:07,219 --> 00:28:08,039
because we're still behind.

590
00:28:09,120 --> 00:28:11,521
If you look at the row second from the bottom,

591
00:28:11,541 --> 00:28:13,742
you'll notice that the display queue now is shrinking

592
00:28:13,762 --> 00:28:16,603
because all the frame buffers that we had buffered up

593
00:28:16,644 --> 00:28:18,705
in the display queue, well, they're going away

594
00:28:18,725 --> 00:28:19,045
because we're.

595
00:28:19,654 --> 00:28:22,595
technically dropping frames, but because we have these display

596
00:28:22,615 --> 00:28:28,817
buffers queued, we're still not really dropping frames.

597
00:28:29,857 --> 00:28:30,737
And we just keep doing that.

598
00:28:31,617 --> 00:28:33,038
And our display queue just keeps shrinking.

599
00:28:33,058 --> 00:28:35,759
And eventually, the display queue will go away.

600
00:28:35,779 --> 00:28:39,180
And when it does go away, we just let go and go back

601
00:28:39,200 --> 00:28:39,700
to where we were.

602
00:28:41,302 --> 00:28:43,023
And we do this from the very beginning of the game.

603
00:28:43,283 --> 00:28:46,285
So we never really let this pipeline telescope out,

604
00:28:46,585 --> 00:28:49,868
because the second things show up in the display queue,

605
00:28:50,028 --> 00:28:51,669
we engage this dynamic frame pacer.

606
00:28:52,249 --> 00:28:55,272
And so if you were to do a real-time trace of this,

607
00:28:55,312 --> 00:28:57,373
you'd probably see it kind of wiggle around,

608
00:28:57,433 --> 00:28:59,555
where it's engaged, disengaged, engaged, disengaged.

609
00:29:00,155 --> 00:29:03,397
But this whole wiggling, it only adds maybe

610
00:29:03,437 --> 00:29:04,958
a handful of milliseconds, 2, 3, 4, 5.

611
00:29:07,538 --> 00:29:11,059
So the frames might be five, there might be a five milliseconds difference

612
00:29:11,099 --> 00:29:15,881
between when the input is being really gathered, but that, the end user cannot tell that,

613
00:29:15,981 --> 00:29:20,382
but they could definitely tell the fact with that, if the whole thing was telescoped out

614
00:29:20,422 --> 00:29:22,703
and it was taking an extra 200 milliseconds.

615
00:29:25,184 --> 00:29:27,605
So now that we did all that, we threaded all of our systems,

616
00:29:27,705 --> 00:29:30,166
we got rid of a bunch of kernel primitives.

617
00:29:31,226 --> 00:29:32,707
We did, we pipelined.

618
00:29:34,137 --> 00:29:37,100
By doing so, we shaved off about a good 40 milliseconds

619
00:29:37,160 --> 00:29:38,541
off of that simulation thread.

620
00:29:39,722 --> 00:29:41,483
But we haven't done anything for the renderer yet.

621
00:29:41,803 --> 00:29:45,846
So now we're going to go ahead and try

622
00:29:45,866 --> 00:29:47,888
to get this renderer in line.

623
00:29:52,291 --> 00:29:55,954
Some quick facts on Shadow of Mordor

624
00:29:56,094 --> 00:29:57,075
versus Shadow of War again.

625
00:29:57,775 --> 00:30:00,778
We ended up moving to a much faster first party graphics

626
00:30:00,818 --> 00:30:02,499
APIs on Shadow of War.

627
00:30:03,601 --> 00:30:05,262
So that helped a lot of performance.

628
00:30:05,763 --> 00:30:09,085
On the PC, we actually had to move to D3D11.1.

629
00:30:10,106 --> 00:30:13,669
We shipped on D3D11 because we were a Windows 7 game.

630
00:30:15,531 --> 00:30:18,933
We had to move to 11.1 for performance issues or performance

631
00:30:18,973 --> 00:30:20,354
gains out of 11.1, actually.

632
00:30:20,415 --> 00:30:23,237
We could not stick with just 11.0 on the API level.

633
00:30:24,538 --> 00:30:27,420
And the hardware limit is still feature levels 11.0.

634
00:30:29,490 --> 00:30:32,271
And after all the optimizations we ended up doing on the render

635
00:30:32,311 --> 00:30:36,633
for Shadow of War, we actually got it to use less of the console cores

636
00:30:36,653 --> 00:30:41,414
than it did on Shadow of Mordor, even though Shadow of War does just so much more.

637
00:30:43,255 --> 00:30:45,495
So the first thing we did when we were profiling the renderers,

638
00:30:45,595 --> 00:30:47,056
well, it's taking 90 milliseconds.

639
00:30:47,216 --> 00:30:48,496
Let's do some profiles.

640
00:30:48,536 --> 00:30:49,696
Let's figure out what is going on.

641
00:30:50,397 --> 00:30:51,937
So in Shadow of Mordor, we never used...

642
00:30:51,957 --> 00:30:54,018
It was still a cross-gen game.

643
00:30:54,058 --> 00:30:55,638
It had... The last gen was still D3D9.

644
00:30:55,658 --> 00:30:56,779
Current gen was D3D11.

645
00:30:58,867 --> 00:31:00,607
We didn't have any named constant buffers.

646
00:31:00,688 --> 00:31:04,029
So everything was basically setting out

647
00:31:04,069 --> 00:31:06,070
individual constants and then building up

648
00:31:06,110 --> 00:31:09,032
a global constant buffer and sending that over to the GPU

649
00:31:09,192 --> 00:31:09,972
every single frame.

650
00:31:10,773 --> 00:31:12,994
And not only that, we had a lot of copies along the way

651
00:31:13,014 --> 00:31:14,534
because we had a bunch of abstraction layers.

652
00:31:14,634 --> 00:31:16,435
So we'd have the copy.

653
00:31:16,595 --> 00:31:18,056
The first copy would be the value

654
00:31:18,076 --> 00:31:20,377
the game would send to the platform agnostic renderer.

655
00:31:21,038 --> 00:31:22,478
The platform agnostic renderer would then

656
00:31:22,498 --> 00:31:23,999
set it to the platform-specific renderer,

657
00:31:24,039 --> 00:31:24,900
which would make a copy.

658
00:31:25,741 --> 00:31:28,463
Then at the very end, on the very last stage,

659
00:31:28,483 --> 00:31:31,344
when we're actually generating the draw call,

660
00:31:31,765 --> 00:31:33,646
we would then allocate memory for a constant buffer,

661
00:31:33,766 --> 00:31:36,327
and then mem copy that value to the platform

662
00:31:36,427 --> 00:31:39,129
or specific layer already had into that constant buffer

663
00:31:39,529 --> 00:31:40,850
and send that over to the GPU.

664
00:31:41,951 --> 00:31:43,111
But that was just a lot of copies.

665
00:31:43,291 --> 00:31:44,672
All the mem copies really add up.

666
00:31:47,094 --> 00:31:48,654
So the first thing we did is we basically

667
00:31:48,674 --> 00:31:51,016
introduced named constant buffers into our render.

668
00:31:52,358 --> 00:31:55,080
And this is just a traditional approach of what you would do

669
00:31:55,140 --> 00:31:56,621
when you introduce named constant buffers.

670
00:31:56,661 --> 00:31:58,082
You look on the update frequency.

671
00:31:58,142 --> 00:32:00,183
You probably create like a frame constant buffer,

672
00:32:00,223 --> 00:32:01,284
a view constant buffer.

673
00:32:02,205 --> 00:32:03,806
Frame one only updates once a frame,

674
00:32:03,826 --> 00:32:05,467
so you don't have to touch those constants ever again,

675
00:32:05,487 --> 00:32:06,007
and so on.

676
00:32:07,008 --> 00:32:08,549
The other thing we did to avoid the copies

677
00:32:08,589 --> 00:32:11,311
was we exposed, through accessors,

678
00:32:11,711 --> 00:32:14,153
the actual platform-specific constant buffer

679
00:32:14,193 --> 00:32:15,314
all the way back to frame code.

680
00:32:15,894 --> 00:32:17,675
So instead of making all these copies along the way,

681
00:32:18,810 --> 00:32:22,153
Using accessors when the game code asks to set a value,

682
00:32:22,373 --> 00:32:25,355
it actually ends up writing the value directly

683
00:32:25,455 --> 00:32:27,337
into a constant buffer that is used directly

684
00:32:27,817 --> 00:32:29,018
by the GPU on the consoles.

685
00:32:31,040 --> 00:32:33,322
So we track all our constant buffers

686
00:32:33,382 --> 00:32:34,823
with a dirty state in the frame code.

687
00:32:34,843 --> 00:32:38,226
And we do this because from the very beginning,

688
00:32:38,246 --> 00:32:40,728
we're actually writing final platform-specific constant

689
00:32:40,748 --> 00:32:41,088
buffers.

690
00:32:41,508 --> 00:32:42,709
And we tracked our dirty state.

691
00:32:42,749 --> 00:32:44,511
So the game actually changed the value in it.

692
00:32:44,671 --> 00:32:46,693
Now it's dirty, and the GPU does not know about it.

693
00:32:47,483 --> 00:32:51,426
So when we go to the first draw call that needs to use this constant buffer,

694
00:32:51,506 --> 00:32:56,008
we detect that it's dirty. So we upload it back to the GPU.

695
00:32:56,048 --> 00:33:00,070
So if it's, for instance, a constant buffer one, and it's dirty,

696
00:33:00,130 --> 00:33:01,431
we set constant buffer one again,

697
00:33:01,491 --> 00:33:05,053
but then we don't ever touch constant buffer one again until the next time it's

698
00:33:05,093 --> 00:33:07,534
dirty. So for instance, for the frame constant buffer,

699
00:33:08,694 --> 00:33:09,835
it's dirty once a frame,

700
00:33:09,975 --> 00:33:13,337
we set it once on the very beginning of a frame and we never set that constant

701
00:33:13,357 --> 00:33:15,218
buffer ever again for any draw call following.

702
00:33:17,459 --> 00:33:21,002
And so when it is dirty, we give the GPU that copy,

703
00:33:21,082 --> 00:33:22,864
and then we make another copy for the CPU,

704
00:33:22,984 --> 00:33:25,166
and then the CPU could keep working on this new copy

705
00:33:25,206 --> 00:33:27,427
while the GPU already has this copy we sent to it.

706
00:33:28,108 --> 00:33:31,591
And the copy we sent to the GPU, we mark it with a frame code,

707
00:33:31,691 --> 00:33:34,273
which just means that we cannot touch that memory

708
00:33:34,393 --> 00:33:36,475
until that frame code is cleared by the GPU.

709
00:33:37,535 --> 00:33:38,897
And then we just recycle that memory.

710
00:33:41,382 --> 00:33:44,263
Binding constant buffers is now just on the consoles,

711
00:33:44,303 --> 00:33:45,723
on these super simple, it's just a pointer.

712
00:33:45,763 --> 00:33:48,524
We no longer allocate special memory for a constant buffer,

713
00:33:48,584 --> 00:33:50,485
mem copy everything in, and then upload it.

714
00:33:51,325 --> 00:33:53,646
Now, since we're dealing with platform-specific constant

715
00:33:53,666 --> 00:33:56,787
buffers, it's just a pointer set.

716
00:33:57,567 --> 00:34:00,008
And then we also notice that, well, we

717
00:34:00,048 --> 00:34:01,928
have these materials constant buffers,

718
00:34:02,028 --> 00:34:06,689
or we have basically values that are tools set.

719
00:34:07,150 --> 00:34:09,710
And they're set by artists, so we can't set it in code.

720
00:34:10,853 --> 00:34:13,374
but they're tweaked by artists

721
00:34:14,034 --> 00:34:16,535
and they're tweaked before it ever gets to the game.

722
00:34:16,755 --> 00:34:18,636
So at cook time, we could actually generate

723
00:34:18,676 --> 00:34:19,976
these material constant buffers

724
00:34:20,336 --> 00:34:21,497
and we could generate them to be

725
00:34:22,597 --> 00:34:24,998
100% platform specific constant buffers

726
00:34:25,038 --> 00:34:27,859
and then we set them up and simply again,

727
00:34:27,899 --> 00:34:29,699
just set them using a pointer

728
00:34:30,259 --> 00:34:32,300
to set those material constant buffers

729
00:34:32,320 --> 00:34:35,661
and never really, we don't need to actually even know

730
00:34:35,721 --> 00:34:37,842
what is inside those buffers, they're just a black box

731
00:34:38,082 --> 00:34:40,042
that we know the shader is eventually going to use.

732
00:34:41,701 --> 00:34:43,502
So here's the name constant buffers

733
00:34:43,522 --> 00:34:44,803
we added in Shadow of War.

734
00:34:45,943 --> 00:34:47,684
In Shadow of Mortar, obviously, we only had the global.

735
00:34:49,806 --> 00:34:51,527
I want to point out these two constant buffers.

736
00:34:51,987 --> 00:34:55,229
So we kind of went over the bone count

737
00:34:55,249 --> 00:34:56,449
in the very beginning of this talk.

738
00:34:57,650 --> 00:34:59,611
And I want to point out that we also have a previous bones

739
00:35:00,031 --> 00:35:00,632
constant buffer.

740
00:35:00,652 --> 00:35:02,753
And the reason we have that is because in Shadow of War,

741
00:35:02,793 --> 00:35:04,654
we also introduced temporal anti-aliasing.

742
00:35:04,694 --> 00:35:06,135
And for temporal anti-aliasing, you

743
00:35:06,155 --> 00:35:07,616
need to know about the previous frame

744
00:35:08,156 --> 00:35:09,877
in order to generate your motion vectors.

745
00:35:10,560 --> 00:35:13,481
So now we were sending not just the current frame bones

746
00:35:13,581 --> 00:35:15,442
every single time, we were sending the previous frame

747
00:35:15,502 --> 00:35:16,562
bones every single time.

748
00:35:18,203 --> 00:35:19,403
So we'll do some more math again.

749
00:35:19,543 --> 00:35:21,364
So if you remember the numbers from before,

750
00:35:21,404 --> 00:35:24,245
we had 48 pieces, 64 bones.

751
00:35:25,145 --> 00:35:26,586
But now we have two frames worth of that.

752
00:35:27,746 --> 00:35:29,187
And we have 200 AI on the screen.

753
00:35:30,747 --> 00:35:34,649
So that adds up to about 307,000 bone transforms

754
00:35:34,669 --> 00:35:36,769
that we're trying to send to the GPU every single frame.

755
00:35:38,610 --> 00:35:39,530
But wait, there's more.

756
00:35:41,081 --> 00:35:43,382
We have four render stages, because we have the GBuffer

757
00:35:43,402 --> 00:35:46,203
stage, and then we have three cascading shadow map stages.

758
00:35:46,823 --> 00:35:49,464
And each one of those, the way the renderer worked,

759
00:35:49,685 --> 00:35:52,166
it would regenerate the bone's constant buffer

760
00:35:52,206 --> 00:35:53,326
for every single one of those stages

761
00:35:53,366 --> 00:35:55,787
every time it had to render a skeletal model.

762
00:35:57,648 --> 00:36:01,469
So the net result was 1.2 million bone transforms being

763
00:36:01,549 --> 00:36:03,110
sent to the GPU every frame.

764
00:36:03,790 --> 00:36:07,332
And our bone transforms are made up of two vector 4s, one

765
00:36:07,412 --> 00:36:09,753
for position and one as a rotation quaternion.

766
00:36:10,737 --> 00:36:14,798
So really, it was 2.4 million vector 4s being uploaded

767
00:36:14,838 --> 00:36:16,038
to the GPU every single frame.

768
00:36:17,239 --> 00:36:18,899
So this is why we can't have nice things.

769
00:36:21,800 --> 00:36:24,461
So what we did to solve this is we actually

770
00:36:24,481 --> 00:36:26,762
went for every single one of our constant buffers,

771
00:36:26,782 --> 00:36:28,783
not just the bound ones, but it was really for the bound ones.

772
00:36:29,563 --> 00:36:31,804
And we gathered heuristics on these constants.

773
00:36:32,284 --> 00:36:33,665
We determined two things.

774
00:36:33,945 --> 00:36:34,965
Two things that were important to us.

775
00:36:35,205 --> 00:36:37,526
One was how often was each constant used?

776
00:36:38,502 --> 00:36:41,104
and how often was the constants actually set to zero.

777
00:36:42,785 --> 00:36:44,886
And the constants that were used heavily

778
00:36:44,946 --> 00:36:45,866
by most of our shaders,

779
00:36:46,707 --> 00:36:49,088
they got basically put to the very beginning

780
00:36:49,128 --> 00:36:49,929
of our constant buffer,

781
00:36:50,349 --> 00:36:51,810
and the ones that were very rarely used

782
00:36:52,070 --> 00:36:53,271
basically got pushed down to the bottom.

783
00:36:53,591 --> 00:36:54,531
And the same thing for the ones

784
00:36:54,551 --> 00:36:55,772
that were typically set to zero.

785
00:36:56,713 --> 00:36:58,253
And the reason we did that is

786
00:36:58,353 --> 00:37:00,775
we only now allocate constant buffers big enough

787
00:37:01,015 --> 00:37:02,636
to hold our used constants.

788
00:37:03,785 --> 00:37:06,046
And so any constants that is not used by the shader,

789
00:37:06,086 --> 00:37:07,447
if it's not there in memory, it's

790
00:37:07,487 --> 00:37:09,008
obviously perfectly fine for the shader.

791
00:37:09,568 --> 00:37:12,630
But the other thing we also did is any constant that is zero,

792
00:37:13,870 --> 00:37:15,551
we don't actually have to back it with memory.

793
00:37:15,571 --> 00:37:17,372
Because when the GPU goes ahead and tries

794
00:37:17,392 --> 00:37:19,053
to read the value out of the constant buffer,

795
00:37:19,133 --> 00:37:22,054
the net result is it just returns zero back

796
00:37:22,094 --> 00:37:22,655
to the shader.

797
00:37:23,755 --> 00:37:26,317
So if you're going to allocate memory just

798
00:37:26,337 --> 00:37:27,497
to memcpy a zero in.

799
00:37:28,682 --> 00:37:32,024
then send it to the GPU, then have the GPU dereference

800
00:37:32,044 --> 00:37:34,686
that memory, put it in its cache just to read a zero back.

801
00:37:35,706 --> 00:37:39,768
It's kind of a lot better just to have the GPU return

802
00:37:39,788 --> 00:37:42,890
zero as an error code, which just works out perfectly

803
00:37:42,930 --> 00:37:43,711
for what we're trying to do.

804
00:37:44,791 --> 00:37:48,253
The biggest problem we have with that is all of our first party

805
00:37:48,273 --> 00:37:50,634
graphics APIs just spam like crazy,

806
00:37:51,015 --> 00:37:52,496
saying that we're just doing everything wrong.

807
00:37:54,872 --> 00:37:57,333
Then your game basically runs like a frame a second

808
00:37:57,413 --> 00:37:58,914
because of all the error spam.

809
00:37:59,354 --> 00:38:02,055
Luckily, you could turn that off on absolutely every one

810
00:38:02,096 --> 00:38:03,156
of the APIs.

811
00:38:05,297 --> 00:38:07,118
The other thing we did for the bones specifically

812
00:38:07,198 --> 00:38:09,499
is we actually now cache our constant buffers

813
00:38:09,539 --> 00:38:10,379
with our render nodes.

814
00:38:10,659 --> 00:38:13,441
So if they're encountered in different stages along the way

815
00:38:13,901 --> 00:38:15,482
and they haven't changed, we just

816
00:38:15,542 --> 00:38:17,322
reuse the ones that were built in the previous stage.

817
00:38:17,362 --> 00:38:19,423
So if we built the bones in the gbuffer stage,

818
00:38:19,443 --> 00:38:20,844
we just reuse it in the constant.

819
00:38:21,633 --> 00:38:23,094
the cascading shadow map stages, so we

820
00:38:23,114 --> 00:38:24,894
don't have to actually rebuild them all from scratch

821
00:38:24,934 --> 00:38:25,475
every single time.

822
00:38:27,556 --> 00:38:29,576
And as I mentioned before, we switched to much faster

823
00:38:30,337 --> 00:38:31,577
first-party graphics APIs.

824
00:38:32,298 --> 00:38:34,739
We also removed frame-to-frame reference counters.

825
00:38:35,399 --> 00:38:37,720
So we used to have these atomic reference counters

826
00:38:38,561 --> 00:38:39,201
in our renderer.

827
00:38:39,321 --> 00:38:43,183
And atomic reference counters seem as if they're fast.

828
00:38:43,283 --> 00:38:46,144
All they are is atomic increment, atomic decrement.

829
00:38:46,618 --> 00:38:48,259
a single CPU instruction.

830
00:38:48,519 --> 00:38:49,760
But if you're doing it in a renderer

831
00:38:49,840 --> 00:38:51,881
and you're doing it like 10,000 times a frame,

832
00:38:52,182 --> 00:38:52,962
that really adds up.

833
00:38:53,942 --> 00:38:54,783
So we got rid of all that.

834
00:38:55,303 --> 00:38:57,665
And now we're just using our frame codes

835
00:38:57,685 --> 00:38:59,606
to track absolutely all lifetime.

836
00:39:00,226 --> 00:39:02,087
We were kind of doing a mix of that in the past,

837
00:39:02,227 --> 00:39:03,728
but we basically went through and just

838
00:39:03,768 --> 00:39:05,269
cleaned the whole thing up so that we're not

839
00:39:05,849 --> 00:39:07,550
using any frame-to-frame reference counting.

840
00:39:08,491 --> 00:39:11,012
The other thing we did, which was a significant undertaking,

841
00:39:11,052 --> 00:39:14,494
was actually we cached the graphics API state

842
00:39:14,614 --> 00:39:15,895
on every single one of our platforms.

843
00:39:17,219 --> 00:39:20,061
Because we noticed that if we were doing any redundant state

844
00:39:20,101 --> 00:39:23,382
changes, even though if they looked minor, a lot of times

845
00:39:23,522 --> 00:39:26,524
what would happen, it would invalidate some kind of state

846
00:39:26,564 --> 00:39:29,525
in the graphics API, which would be a lot more expensive

847
00:39:29,545 --> 00:39:30,406
than it actually looks.

848
00:39:31,726 --> 00:39:34,468
So all of our state is completely cached.

849
00:39:35,008 --> 00:39:39,110
And we pretty much just generate these CRCs

850
00:39:39,690 --> 00:39:40,731
for every one of our states.

851
00:39:41,271 --> 00:39:42,392
We check those CRCs.

852
00:39:42,452 --> 00:39:44,633
If the CRCs is the same, then we just never.

853
00:39:45,224 --> 00:39:46,505
set that state if they're different

854
00:39:46,525 --> 00:39:47,465
than we obviously set it.

855
00:39:48,186 --> 00:39:49,446
And a lot of stuff is also pointers,

856
00:39:49,466 --> 00:39:50,667
like a texture is just a pointer,

857
00:39:50,807 --> 00:39:53,789
is that texture already set into texture slot two?

858
00:39:53,869 --> 00:39:55,349
If it is, then just leave it alone.

859
00:39:57,010 --> 00:39:59,051
And this was a huge win, obviously, on PC,

860
00:39:59,071 --> 00:40:01,292
because now we're avoiding all those com calls,

861
00:40:01,472 --> 00:40:03,634
but it was actually also a win on the consoles.

862
00:40:05,715 --> 00:40:07,636
So the next thing we did is we got rid

863
00:40:07,656 --> 00:40:09,176
of a lot of our flushing.

864
00:40:09,457 --> 00:40:11,378
So we used to do a lot of flushing to be safe.

865
00:40:12,018 --> 00:40:14,379
It's a good thing to do, but it's also pretty expensive.

866
00:40:15,917 --> 00:40:20,040
So on the consoles, we got rid of all of our CPU and GPU

867
00:40:20,080 --> 00:40:20,480
flushing.

868
00:40:21,221 --> 00:40:25,444
We did this by using write combined memory on the consoles

869
00:40:25,544 --> 00:40:26,966
for most of our GPU data.

870
00:40:27,506 --> 00:40:29,027
So when we're writing to it on the CPU,

871
00:40:29,067 --> 00:40:31,069
it only takes about 500 cycles before it's

872
00:40:31,089 --> 00:40:32,150
committed into that memory.

873
00:40:32,690 --> 00:40:34,251
And because there's so much stuff going on

874
00:40:34,311 --> 00:40:37,234
in Shadow of War, by the time the GPU ever sees this data,

875
00:40:37,394 --> 00:40:39,175
it's definitely committed into memory.

876
00:40:39,796 --> 00:40:42,178
So we don't really do any tracking

877
00:40:42,198 --> 00:40:44,119
to make sure that 500 cycles have occurred.

878
00:40:44,179 --> 00:40:45,240
We just assume they have.

879
00:40:45,779 --> 00:40:47,981
and we haven't seen any problems with that.

880
00:40:49,042 --> 00:40:51,463
On the GPU though, what we end up doing

881
00:40:51,524 --> 00:40:53,805
is we allocate all the memory we ever sent to the GPU

882
00:40:53,905 --> 00:40:55,166
on a cache line boundary.

883
00:40:55,867 --> 00:40:58,028
So not only is all the memory allocated

884
00:40:58,049 --> 00:40:58,969
on the cache line boundary,

885
00:40:58,989 --> 00:41:01,151
it's also padded out to a cache line boundary.

886
00:41:01,751 --> 00:41:03,373
So if you, for instance, have a constant buffer

887
00:41:03,393 --> 00:41:05,114
that all it has is one vector four,

888
00:41:05,834 --> 00:41:07,776
it's obviously not using the entire cache line.

889
00:41:08,737 --> 00:41:10,558
It's gonna get padded out to the entire cache line

890
00:41:10,598 --> 00:41:12,960
because if we send up that one vector four

891
00:41:13,400 --> 00:41:15,042
to the GPU early on in the frame,

892
00:41:15,543 --> 00:41:16,884
The GPU will put it in its cache.

893
00:41:17,765 --> 00:41:20,647
We then allocate another constant buffer that's maybe,

894
00:41:20,687 --> 00:41:21,788
again, one vector four.

895
00:41:22,068 --> 00:41:24,270
And if it ends up being on the same cache line

896
00:41:24,310 --> 00:41:26,551
as the previous one, we could change it on the CPU.

897
00:41:26,912 --> 00:41:28,773
But without a cache flush, obviously, the GPU

898
00:41:28,793 --> 00:41:29,453
is not going to see it.

899
00:41:30,154 --> 00:41:31,535
Then you're just reading garbage data.

900
00:41:32,195 --> 00:41:34,697
And because we don't want to do that cache flush,

901
00:41:34,917 --> 00:41:37,499
we basically pad everything out to cache line boundaries.

902
00:41:38,320 --> 00:41:39,521
The cache lines are pretty small.

903
00:41:39,601 --> 00:41:41,282
So there is some memory wasted here.

904
00:41:41,402 --> 00:41:44,524
But it's pretty insignificant compared to the five gigabytes

905
00:41:44,564 --> 00:41:45,245
you have on a.

906
00:41:45,908 --> 00:41:46,748
current gen consoles.

907
00:41:48,830 --> 00:41:52,352
And then we have dynamic resolution scaling on the GPU.

908
00:41:52,372 --> 00:41:53,012
And that's great.

909
00:41:53,473 --> 00:41:54,974
And a lot of people have used that.

910
00:41:55,194 --> 00:41:57,115
But that scales the GPU on load.

911
00:41:57,135 --> 00:41:59,857
And we have a somewhat open world game.

912
00:41:59,937 --> 00:42:01,838
We have no idea what the end user is going to be able to do.

913
00:42:02,258 --> 00:42:04,340
They could create scenarios that are just crazy.

914
00:42:04,380 --> 00:42:05,881
So we're looking into ways, well,

915
00:42:05,921 --> 00:42:09,423
how can we dynamically scale the CPU too and not just the GPU?

916
00:42:10,543 --> 00:42:12,004
So we ended up doing two things.

917
00:42:12,164 --> 00:42:14,326
One thing is we're constantly monitoring the CPU

918
00:42:14,346 --> 00:42:15,306
workload of the renderer.

919
00:42:15,797 --> 00:42:19,259
If it gets really heavy, if it gets maybe about 30 milliseconds,

920
00:42:19,359 --> 00:42:23,721
we start throttling, we start pushing out all the LODs of our character models.

921
00:42:24,902 --> 00:42:29,064
And that helps us because the LODs that are further away have less draw calls.

922
00:42:29,284 --> 00:42:32,246
So right away, there's a lot less draw calls to set up on the CPU side.

923
00:42:33,147 --> 00:42:36,729
Also, most of those LODs further away use cheaper shaders

924
00:42:36,749 --> 00:42:38,390
because we typically only use...

925
00:42:41,091 --> 00:42:43,593
We only use tessellation on the LODs that are up close.

926
00:42:44,033 --> 00:42:44,873
Then as you get pushed...

927
00:42:45,170 --> 00:42:47,610
push further away, it's just vertex pixel, nothing else.

928
00:42:47,650 --> 00:42:50,131
So again, it's a lot simpler to set up those draw calls

929
00:42:50,211 --> 00:42:51,371
than tessellated ones.

930
00:42:52,751 --> 00:42:54,451
And then if shit really hits the fan

931
00:42:54,631 --> 00:42:56,892
and we're now dropping frames, we actually end up,

932
00:42:57,572 --> 00:42:59,872
we stop streaming textures.

933
00:42:59,992 --> 00:43:01,473
We stop all textures, high MIPS.

934
00:43:02,553 --> 00:43:05,873
And we do this because it lowers the CPU usage.

935
00:43:06,393 --> 00:43:09,274
Not streaming is basically not doing any additional work.

936
00:43:09,414 --> 00:43:14,115
So that gives us more holes in our CPU timeline.

937
00:43:16,096 --> 00:43:18,478
And it also, there's a lot less memory pressure

938
00:43:18,498 --> 00:43:20,439
because we're pulling all this stuff in and out of memory.

939
00:43:20,559 --> 00:43:23,060
So by basically pausing that for a while

940
00:43:23,180 --> 00:43:26,842
until we regain our frame rate fixes that as well.

941
00:43:26,923 --> 00:43:30,745
And there's also a cost between virtual and physical page

942
00:43:30,805 --> 00:43:31,145
mapping.

943
00:43:32,986 --> 00:43:34,767
So doing all that, got our render thread down now

944
00:43:34,827 --> 00:43:36,148
to 45 milliseconds.

945
00:43:36,608 --> 00:43:37,249
So we're getting there.

946
00:43:38,670 --> 00:43:40,551
So now we're going to look into our memory,

947
00:43:40,591 --> 00:43:42,992
see if we could do anything with memory to get us running faster.

948
00:43:45,687 --> 00:43:47,887
So a huge performance win on Shadow of War

949
00:43:47,967 --> 00:43:49,867
was actually switching to 2 meg pages.

950
00:43:49,887 --> 00:43:53,708
We used to use only 64k pages exclusively on Shadow of War.

951
00:43:53,928 --> 00:43:55,409
Now we're using 2 meg pages.

952
00:43:55,789 --> 00:43:56,989
We're actually using a mix.

953
00:43:57,109 --> 00:44:00,070
I'm sorry, we're using a mix between 2 megs and 64k pages.

954
00:44:00,670 --> 00:44:03,570
And that gave us about a 20% performance gain

955
00:44:04,131 --> 00:44:05,251
over Shadow of War.

956
00:44:06,371 --> 00:44:08,832
A lot of it just came from the, oh sorry, over Shadow of War.

957
00:44:09,392 --> 00:44:10,832
A lot of it actually came from the fact

958
00:44:10,872 --> 00:44:13,353
that there's just so much going on, so much random memory

959
00:44:13,473 --> 00:44:13,873
access.

960
00:44:14,213 --> 00:44:14,653
And this.

961
00:44:15,215 --> 00:44:17,776
This is where the large pages shine.

962
00:44:19,858 --> 00:44:21,859
We actually implemented this on the PC as well.

963
00:44:22,099 --> 00:44:24,181
However, it's not that noticeable to most

964
00:44:24,201 --> 00:44:27,163
of our users on the PC because we're GPU-bound on the PC.

965
00:44:27,263 --> 00:44:30,285
And it does make the CPU faster, but unless you're actually

966
00:44:30,325 --> 00:44:32,807
CPU-bound, you'll not really get much out of this.

967
00:44:34,808 --> 00:44:36,449
So we end up allocating these pages

968
00:44:36,869 --> 00:44:39,311
at when we start the process.

969
00:44:39,751 --> 00:44:40,992
We do this because we have a mix.

970
00:44:41,132 --> 00:44:43,954
There's no way you're going to find a contiguous two-meg page.

971
00:44:45,154 --> 00:44:47,716
So we basically, here's a breakdown of our memory

972
00:44:47,756 --> 00:44:48,536
of Shadow of War.

973
00:44:48,576 --> 00:44:53,479
We allocate 1.5 gigs of GPU memory, 2 gigs of CPU memory,

974
00:44:55,620 --> 00:44:59,022
256 megs of GPU memory that's cached by the CPU.

975
00:44:59,102 --> 00:45:01,203
And then there's that gray block that's split out.

976
00:45:01,404 --> 00:45:03,825
That's about a gig of our 64k pages.

977
00:45:04,385 --> 00:45:06,486
And we actually use that mostly for our textures.

978
00:45:07,584 --> 00:45:11,067
So doing that, switching to the two-meg pages

979
00:45:11,087 --> 00:45:14,350
and getting that 20% performance gain,

980
00:45:14,370 --> 00:45:16,111
we're now down to about 40 milliseconds

981
00:45:16,151 --> 00:45:19,214
on the simulation thread and 36 on the renderer.

982
00:45:20,615 --> 00:45:21,296
So we're almost there.

983
00:45:22,397 --> 00:45:25,740
What can we do to get this game actually running at frame rate?

984
00:45:27,001 --> 00:45:28,862
So in our development builds, we use DOLs.

985
00:45:28,942 --> 00:45:32,345
And we do this because it's great for iteration times.

986
00:45:33,005 --> 00:45:33,986
You could change the CPP file.

987
00:45:34,126 --> 00:45:35,527
All you have to do is build that one DLL.

988
00:45:35,547 --> 00:45:37,129
You don't have to rebuild the entire game.

989
00:45:37,229 --> 00:45:39,450
We have incremental linking turned on, debug, fast link,

990
00:45:39,610 --> 00:45:40,591
all this great stuff.

991
00:45:41,272 --> 00:45:42,573
It's great for iteration times.

992
00:45:42,733 --> 00:45:43,974
It sucks for performance.

993
00:45:45,015 --> 00:45:46,816
And our executable is just a tiny stub

994
00:45:46,856 --> 00:45:48,137
that has absolutely no code in it.

995
00:45:48,237 --> 00:45:49,938
And all it does is it just loads those DLLs.

996
00:45:50,619 --> 00:45:51,840
And this is for a development build.

997
00:45:52,320 --> 00:45:54,622
For a retail build, we convert these DLLs.

998
00:45:55,102 --> 00:45:57,224
We target them to become libs at this point.

999
00:45:57,784 --> 00:46:00,707
We turn off all the things that make iteration times great,

1000
00:46:00,767 --> 00:46:02,268
such as incremental linking and so on.

1001
00:46:02,860 --> 00:46:04,981
And then we use our stub executable

1002
00:46:05,161 --> 00:46:07,762
to now link in those libs as opposed to load those DLLs.

1003
00:46:08,622 --> 00:46:11,543
And the beauty of that is that when you're doing linking,

1004
00:46:12,543 --> 00:46:13,804
the way it works is it only pulls

1005
00:46:13,864 --> 00:46:14,864
in code that is referenced.

1006
00:46:14,884 --> 00:46:17,665
So it's basically, the linker is basically

1007
00:46:17,705 --> 00:46:19,846
dead stripping your code, or getting rid of all the code

1008
00:46:19,866 --> 00:46:20,486
that is dead.

1009
00:46:21,846 --> 00:46:23,367
And since our code base is 20 years old,

1010
00:46:23,967 --> 00:46:24,847
there's a lot of dead code.

1011
00:46:26,068 --> 00:46:29,049
And that alone just gives us about a 10% boost

1012
00:46:29,069 --> 00:46:30,929
in performance by getting rid of all the dead code

1013
00:46:31,049 --> 00:46:32,110
and getting rid of all the DLL.

1014
00:46:33,789 --> 00:46:34,269
boundaries.

1015
00:46:35,849 --> 00:46:39,090
The other thing we do is we have link time code generation

1016
00:46:39,150 --> 00:46:39,611
turned on.

1017
00:46:39,651 --> 00:46:41,611
And we did this actually on Shadow of Mordor as well.

1018
00:46:42,231 --> 00:46:44,572
And we do it for all of our middleware as well.

1019
00:46:44,612 --> 00:46:46,233
So we go into every single middleware package

1020
00:46:46,373 --> 00:46:47,713
and turn on LTCG.

1021
00:46:48,713 --> 00:46:52,515
LTCG on Microsoft platforms gives us about a 10% boost

1022
00:46:52,555 --> 00:46:53,175
in performance.

1023
00:46:53,255 --> 00:46:56,696
And the reason it's greater on the Microsoft platforms

1024
00:46:56,796 --> 00:47:00,137
than on the Sony ones is because of.

1025
00:47:02,057 --> 00:47:03,719
And the way the Microsoft compiler works,

1026
00:47:03,779 --> 00:47:06,322
you can't actually inline between OBJs

1027
00:47:06,562 --> 00:47:08,344
without turning on LTCG.

1028
00:47:09,265 --> 00:47:11,949
We also use PGO, Profile Guided Optimizations,

1029
00:47:12,029 --> 00:47:13,270
on all of our platforms as well.

1030
00:47:13,370 --> 00:47:15,953
And this is the first project we actually shipped with PGO.

1031
00:47:17,035 --> 00:47:20,278
And that we found about a 5% gain on top of LTCG

1032
00:47:20,318 --> 00:47:21,200
by using PGO.

1033
00:47:22,391 --> 00:47:25,714
And a quick pro tip there, at least this works for us.

1034
00:47:25,794 --> 00:47:27,395
If you're using a Microsoft, if you're

1035
00:47:27,415 --> 00:47:28,936
compiling for Microsoft platforms

1036
00:47:29,077 --> 00:47:30,718
and you have comdat folding enabled,

1037
00:47:30,818 --> 00:47:32,039
it will shrink your executable.

1038
00:47:32,920 --> 00:47:35,222
But from what we encountered is it basically

1039
00:47:35,262 --> 00:47:37,484
gets rid of the gains we got out of PGO.

1040
00:47:37,564 --> 00:47:40,046
So we end up turning off comdat folding.

1041
00:47:41,066 --> 00:47:44,169
So doing that, we finally got our game running at frame rate.

1042
00:47:44,529 --> 00:47:47,752
So we could, I mean, it's good to ship frame rate wise.

1043
00:47:48,813 --> 00:47:49,413
I feel great.

1044
00:47:49,734 --> 00:47:50,254
It's awesome.

1045
00:47:52,244 --> 00:47:54,224
So now we're going to try to get it to fit in the memory.

1046
00:47:56,545 --> 00:47:58,705
Because we can't really ship without it actually fitting.

1047
00:48:00,226 --> 00:48:03,186
So modern GPUs use virtual memory.

1048
00:48:03,786 --> 00:48:05,967
We no longer have a last gen console which

1049
00:48:05,987 --> 00:48:07,107
doesn't have virtual memory.

1050
00:48:07,707 --> 00:48:09,587
And so we have this virtual memory.

1051
00:48:09,627 --> 00:48:11,628
We've had it around for the CPUs for a while.

1052
00:48:11,708 --> 00:48:15,149
We no longer have to allocate contiguous memory on the GPU.

1053
00:48:15,589 --> 00:48:17,469
So what can we do to actually get this?

1054
00:48:18,400 --> 00:48:22,563
Can we do anything with this virtual memory to save on memory?

1055
00:48:23,483 --> 00:48:26,485
We know that physical memory can be mapped and unmapped

1056
00:48:26,505 --> 00:48:29,086
into virtual memory on a page granularity.

1057
00:48:30,126 --> 00:48:32,428
And we also know we could take a single physical page

1058
00:48:32,808 --> 00:48:35,149
and map it to multiple locations in virtual memory.

1059
00:48:36,850 --> 00:48:38,911
And a quick example of that, we've

1060
00:48:38,931 --> 00:48:41,172
got virtual memory on the top, physical on the bottom.

1061
00:48:42,033 --> 00:48:43,293
We could allocate a physical page.

1062
00:48:44,344 --> 00:49:06,298
Anywhere in the physical memory range and we can map it anywhere in the virtual memory range. So there it is pretty straightforward. We take another physical memory page and allocated right next or map it right next into the address space of the virtual memory and so from the virtual very perspective. It looks contiguous even though I don't at the physical level it is not and this is OK.

1063
00:49:08,067 --> 00:49:10,528
And then there's another, you could allocate another page,

1064
00:49:11,008 --> 00:49:13,750
and you could actually map it into two completely separate locations

1065
00:49:13,830 --> 00:49:14,731
in virtual memory.

1066
00:49:16,212 --> 00:49:16,832
And this works too.

1067
00:49:18,613 --> 00:49:20,634
So we're going to use 64K pages for this,

1068
00:49:20,654 --> 00:49:23,496
and this is why we have that giant 1Gb 64K block.

1069
00:49:23,556 --> 00:49:26,398
And the reason for that is it's a lot easier to find scenarios

1070
00:49:26,438 --> 00:49:28,799
where you could share a 64K page of data.

1071
00:49:29,359 --> 00:49:31,441
2 megs worth of data is pretty difficult to share.

1072
00:49:32,381 --> 00:49:35,303
It also means that if there's any memory that we...

1073
00:49:37,348 --> 00:49:40,229
don't use out of a 64K page because we want to do some kind

1074
00:49:40,249 --> 00:49:44,591
of memory trick where we're not losing too much out

1075
00:49:44,611 --> 00:49:47,632
of that 64K page, as opposed to a two-meg page

1076
00:49:47,672 --> 00:49:50,213
where there might be a bunch of data left over.

1077
00:49:51,614 --> 00:49:53,374
But obviously, there is a downside to it.

1078
00:49:53,474 --> 00:49:54,055
They're slower.

1079
00:49:54,275 --> 00:49:57,996
So the first thing we started thinking is,

1080
00:49:58,156 --> 00:50:00,938
can we move our mipmaps streaming over to these pages?

1081
00:50:01,898 --> 00:50:02,958
So in Shadow of Mordor, we, um,

1082
00:50:05,307 --> 00:50:07,388
We never, we mip mapped stream, but we actually never

1083
00:50:07,468 --> 00:50:09,549
unloaded those mips, because we moved,

1084
00:50:09,729 --> 00:50:10,729
we were cross gen again.

1085
00:50:10,749 --> 00:50:13,131
We moved to this great new console, had five gigs.

1086
00:50:13,171 --> 00:50:14,852
Oh my god, all the memory in the world.

1087
00:50:15,232 --> 00:50:17,493
What, you know, there's no point of unloading this data.

1088
00:50:17,513 --> 00:50:20,435
The only reason we streamed those mips in,

1089
00:50:20,455 --> 00:50:22,996
in the first place, was to lower load times,

1090
00:50:23,056 --> 00:50:24,717
because our load times were pretty significant.

1091
00:50:25,577 --> 00:50:27,378
But we had all the memory to keep them in memory.

1092
00:50:27,739 --> 00:50:30,020
On Shadow of War, because we were out of memory,

1093
00:50:30,060 --> 00:50:32,701
we started looking at, started looking at our texture

1094
00:50:32,721 --> 00:50:33,402
streaming and think.

1095
00:50:34,078 --> 00:50:40,063
And wondering is there a way to save on memory by maybe moving this these MIPS in and out of memory constantly?

1096
00:50:41,544 --> 00:50:55,234
And this is just a quick reminder that out of any textured high MIP caught it memory wise cost 66% of the rest of the texture. So if you get rid of that high MIT, all you're left with is 33% of the memory usage.

1097
00:50:57,216 --> 00:51:02,120
So we implement a mipmap streaming system at cook time. We analyze every single one of our meshes.

1098
00:51:03,177 --> 00:51:05,359
And we find the largest triangle,

1099
00:51:05,539 --> 00:51:07,060
the worst case scenario triangle that

1100
00:51:07,100 --> 00:51:10,422
has the greatest texel density that would basically

1101
00:51:10,462 --> 00:51:12,224
require that high MIP to come in first.

1102
00:51:12,384 --> 00:51:13,084
And we save it off.

1103
00:51:13,444 --> 00:51:16,126
At runtime, we do some quick math

1104
00:51:16,266 --> 00:51:18,388
to basically project that triangle onto the screen,

1105
00:51:19,088 --> 00:51:21,130
determine what its MIP map value would be,

1106
00:51:21,530 --> 00:51:23,151
and approximate that MIP map value.

1107
00:51:23,211 --> 00:51:25,573
And I highlighted approximate because you don't really

1108
00:51:25,633 --> 00:51:28,075
have to do the exact same math that GPU does here.

1109
00:51:28,479 --> 00:51:30,540
because you're going to be bound by the streaming system

1110
00:51:30,701 --> 00:51:33,242
and not so much by the accuracy of your math.

1111
00:51:34,163 --> 00:51:35,824
So finding the fastest way to do this

1112
00:51:35,964 --> 00:51:37,785
is a lot better than being accurate.

1113
00:51:38,946 --> 00:51:40,747
So a quick example, we have this tribute here

1114
00:51:41,287 --> 00:51:42,048
in the middle of the screen.

1115
00:51:42,988 --> 00:51:45,310
We have a bounding box for every single one of these objects.

1116
00:51:46,390 --> 00:51:48,572
And we take this triangle we saved off at cook time,

1117
00:51:48,872 --> 00:51:52,074
and we simply project it onto that bounding box, camera

1118
00:51:52,114 --> 00:51:56,797
facing the screen space, figure out what the mid value would

1119
00:51:56,817 --> 00:51:57,577
be for that triangle.

1120
00:51:58,426 --> 00:52:00,047
A triangle is obviously not to scale.

1121
00:52:00,127 --> 00:52:01,367
We don't have triangles this big.

1122
00:52:01,828 --> 00:52:03,829
But if I used a real world triangle, you wouldn't see it.

1123
00:52:06,730 --> 00:52:10,112
So the entire streaming system operates on the CPU.

1124
00:52:10,472 --> 00:52:12,593
And it's throttled, so it doesn't take up too much time.

1125
00:52:12,753 --> 00:52:15,134
We only evaluate about 60, well, we

1126
00:52:15,154 --> 00:52:17,415
evaluate exactly 64 of these meshes of frame.

1127
00:52:18,335 --> 00:52:20,176
We have a frame code on it, so we don't evaluate

1128
00:52:20,196 --> 00:52:21,157
the same mesh twice.

1129
00:52:22,137 --> 00:52:24,598
And we put a dampening system in there to avoid.

1130
00:52:25,282 --> 00:52:28,484
thrashing of the MIPS so that we don't pull them in and out

1131
00:52:28,544 --> 00:52:29,405
every single frame.

1132
00:52:30,225 --> 00:52:33,328
And as a result, we could evaluate about 1,920

1133
00:52:33,668 --> 00:52:35,589
of these every second.

1134
00:52:35,870 --> 00:52:38,812
So after a few seconds, we evaluate the entire scene,

1135
00:52:38,852 --> 00:52:40,653
because we're only evaluating this.

1136
00:52:41,574 --> 00:52:43,856
Only the stuff that is being rendered is evaluated.

1137
00:52:45,057 --> 00:52:47,098
And so the CPU cost, as a result,

1138
00:52:47,118 --> 00:52:49,940
is fixed at about 0.1 milliseconds per frame.

1139
00:52:52,089 --> 00:52:55,611
So the high MIPS, they use a memory pool,

1140
00:52:55,651 --> 00:52:58,113
and we pre-allocate these 64k pages the second

1141
00:52:58,153 --> 00:53:00,054
we start the game again so that we always

1142
00:53:00,094 --> 00:53:01,735
have the memory for this pool.

1143
00:53:02,836 --> 00:53:05,638
And we just slow the MIPS in and out until we're out of memory,

1144
00:53:06,018 --> 00:53:07,879
or until the high MIPS are depleted.

1145
00:53:08,159 --> 00:53:10,601
And then we just don't give them the texture

1146
00:53:10,701 --> 00:53:12,502
a MIP if it requests one.

1147
00:53:14,931 --> 00:53:17,673
And so every single one of our textures we create without a high MIPS.

1148
00:53:17,693 --> 00:53:19,915
So virtual memory is mapped out for entire texture,

1149
00:53:19,975 --> 00:53:24,018
but it's only backed by physical memory all the way up to the high MIPS

1150
00:53:24,098 --> 00:53:25,079
and the high MIPS is ignored.

1151
00:53:26,480 --> 00:53:27,981
So a quick demo of that.

1152
00:53:28,242 --> 00:53:29,342
Imagine this texture here.

1153
00:53:29,382 --> 00:53:32,325
That's a virtual memory layout of a regular texture 2D.

1154
00:53:33,266 --> 00:53:36,548
And then we have our base memory, which is just memory that if we run out of that,

1155
00:53:36,848 --> 00:53:38,510
it's a error that we're out of memory.

1156
00:53:39,410 --> 00:53:42,253
But if we run out of a high MIPS memory pool, that's OK.

1157
00:53:42,273 --> 00:53:42,873
We'll just never...

1158
00:53:43,753 --> 00:53:45,395
displayed a high mip to the end user.

1159
00:53:45,475 --> 00:53:48,597
It's still more of a warning to the game developers

1160
00:53:48,657 --> 00:53:50,898
than an error to us.

1161
00:53:52,239 --> 00:53:54,701
So every one of these blocks is a 64k block.

1162
00:53:54,961 --> 00:53:58,384
We end up basically assigning the 64k blocks

1163
00:53:58,404 --> 00:53:59,344
to all these different mips.

1164
00:54:00,685 --> 00:54:02,126
And we're doing this manually.

1165
00:54:02,166 --> 00:54:05,569
We're mapping the physical memory to virtual memory here.

1166
00:54:06,069 --> 00:54:08,951
At this stage, the texture would be considered loaded by the game

1167
00:54:09,071 --> 00:54:10,352
and would be handed off until.

1168
00:54:11,182 --> 00:54:13,703
the Mipmap streaming system determines it needs a high MIP.

1169
00:54:14,123 --> 00:54:15,464
Once it determines it needs a high MIP,

1170
00:54:16,564 --> 00:54:18,766
all the 64k pages from the high MIP pool

1171
00:54:18,926 --> 00:54:20,527
are now assigned to this high MIP

1172
00:54:21,367 --> 00:54:22,568
until it doesn't need it anymore.

1173
00:54:22,688 --> 00:54:25,889
And then they're just thrown back into the high MIP memory

1174
00:54:25,909 --> 00:54:26,110
pool.

1175
00:54:28,331 --> 00:54:31,092
So doing this actually saved us about a gig of memory

1176
00:54:31,272 --> 00:54:34,814
over keeping all the high MIPS in memory for Shadow of War.

1177
00:54:37,295 --> 00:54:39,076
So the next thing we started thinking about

1178
00:54:39,176 --> 00:54:40,577
is texture 2D arrays.

1179
00:54:42,607 --> 00:54:44,669
We actually use a bunch of these texture 2D arrays

1180
00:54:44,729 --> 00:54:45,449
on Shadow of War.

1181
00:54:46,550 --> 00:54:48,772
We use them for terrain, we use them for character models,

1182
00:54:49,872 --> 00:54:51,434
we use them for a lot of our structures,

1183
00:54:51,834 --> 00:54:54,156
and we use it for our effects flip books.

1184
00:54:55,617 --> 00:54:57,958
So the benefits of using these texture 2D arrays

1185
00:54:58,018 --> 00:54:59,439
is we use them for blending a lot.

1186
00:54:59,519 --> 00:55:01,301
So it's great for blending,

1187
00:55:01,341 --> 00:55:02,722
because when you sample them in the shader,

1188
00:55:02,742 --> 00:55:04,783
you're guaranteed that every single one of your slices

1189
00:55:04,803 --> 00:55:06,585
is gonna be the exact same mip level.

1190
00:55:07,485 --> 00:55:09,187
It also kind of simplified our shaders,

1191
00:55:09,207 --> 00:55:10,507
because we didn't have to do as many

1192
00:55:11,598 --> 00:55:13,880
brenching in our shaders, checking

1193
00:55:13,980 --> 00:55:16,401
if the regular texture 2Ds were valid or not.

1194
00:55:16,701 --> 00:55:20,564
And at this point, we're just calculating indices

1195
00:55:20,744 --> 00:55:22,204
into the texture 2D array.

1196
00:55:23,845 --> 00:55:25,686
But there are issues with texture 2D arrays.

1197
00:55:26,307 --> 00:55:27,207
First one is padding.

1198
00:55:27,648 --> 00:55:30,949
So on the AMD hardware that exists on the consoles,

1199
00:55:31,009 --> 00:55:32,851
the texture 2D arrays are always padded.

1200
00:55:32,991 --> 00:55:34,792
The slice count is always padded to a power of 2.

1201
00:55:35,852 --> 00:55:38,594
So if you requested a three-slice texture array,

1202
00:55:39,254 --> 00:55:41,195
the return memory layout will contain four.

1203
00:55:42,818 --> 00:55:45,200
3 and 4 is not so bad, but since it's a power of 2,

1204
00:55:45,280 --> 00:55:48,302
imagine you wanted 17 slices in your texture 2D array.

1205
00:55:49,082 --> 00:55:51,044
The return memory layout would contain 32,

1206
00:55:51,124 --> 00:55:52,445
and you'd be paying the cost for all 32.

1207
00:55:52,505 --> 00:55:56,027
The next issue is duplication.

1208
00:55:56,828 --> 00:55:59,650
So we're using texture 2D arrays everywhere, and this is great.

1209
00:56:00,290 --> 00:56:02,051
But we're using it for blending.

1210
00:56:02,131 --> 00:56:05,974
So in our snow level, for example, every.

1211
00:56:06,525 --> 00:56:09,326
artist that creates a texture 2D array wants a blend of snow,

1212
00:56:09,346 --> 00:56:12,207
so they're always going to add that same exact snow slice

1213
00:56:12,427 --> 00:56:13,707
into their texture 2D array.

1214
00:56:14,447 --> 00:56:15,968
And traditionally, what would end up happening

1215
00:56:16,008 --> 00:56:17,868
is you're just baking this texture 2D array down

1216
00:56:17,908 --> 00:56:19,789
at cook time, and the snow is just

1217
00:56:19,829 --> 00:56:22,429
duplicated in every single one of your texture 2D arrays.

1218
00:56:24,590 --> 00:56:27,171
So in order to get around the padding, what we end up doing

1219
00:56:27,611 --> 00:56:30,331
is we're already mapping 64k pages for all

1220
00:56:30,371 --> 00:56:33,092
of our texture loading anyways, so we

1221
00:56:34,062 --> 00:56:38,223
analyze the texture array and just ignore all the areas

1222
00:56:38,263 --> 00:56:38,904
that are padded.

1223
00:56:38,964 --> 00:56:45,225
So in the case of the 17 slices going all the way to 32,

1224
00:56:45,285 --> 00:56:46,446
you get 15 slices.

1225
00:56:46,466 --> 00:56:50,127
You're basically useless, taking up memory.

1226
00:56:50,147 --> 00:56:52,427
We just never actually back them with any physical memory.

1227
00:56:52,547 --> 00:56:53,788
The virtual memory is still there.

1228
00:56:55,588 --> 00:56:57,709
Textures have this concept called pack MIPS.

1229
00:56:58,289 --> 00:57:00,269
This is actually a direct 3D term.

1230
00:57:00,429 --> 00:57:01,510
These are the MIPS.

1231
00:57:01,900 --> 00:57:04,422
that are smaller than one 64K page.

1232
00:57:05,322 --> 00:57:07,564
And since they're smaller than one 64K page,

1233
00:57:08,364 --> 00:57:10,266
we actually just give them a 64K page.

1234
00:57:10,546 --> 00:57:13,228
And for texture 2D arrays, it gets even more complicated

1235
00:57:13,248 --> 00:57:15,229
because typically what happens is you have all your tail mips

1236
00:57:15,309 --> 00:57:17,211
in this one last 64K page.

1237
00:57:17,851 --> 00:57:20,954
In texture 2D arrays, you'll have the tail mips

1238
00:57:20,994 --> 00:57:23,055
of multiple slices in that one page,

1239
00:57:23,896 --> 00:57:26,337
which gets really complicated with texture 2D arrays.

1240
00:57:26,398 --> 00:57:29,580
So because it's one 64K page, we don't really care about it

1241
00:57:29,720 --> 00:57:30,140
and we just...

1242
00:57:31,154 --> 00:57:34,076
always have physical memory backing for packed MIPS.

1243
00:57:35,997 --> 00:57:38,838
So an example of this, here we have a texture array.

1244
00:57:39,699 --> 00:57:41,920
So this is the virtual memory layout of a texture array.

1245
00:57:42,400 --> 00:57:44,961
On top left corner, where we have the wood texture

1246
00:57:44,981 --> 00:57:49,744
and the high MIP, that's where the virtual memory layout

1247
00:57:49,764 --> 00:57:51,425
of a texture to the array starts.

1248
00:57:52,165 --> 00:57:53,726
It goes through all its high MIPS first,

1249
00:57:54,426 --> 00:57:55,827
including, so in this scenario,

1250
00:57:55,867 --> 00:57:58,008
I'm doing the three slices that we're using

1251
00:57:58,068 --> 00:57:59,449
and we're paying the cost for four.

1252
00:58:00,318 --> 00:58:03,619
So this is where if I asked on the consoles

1253
00:58:03,639 --> 00:58:05,320
to allocate a three-slice texture array,

1254
00:58:05,340 --> 00:58:06,340
this is the layout I would get.

1255
00:58:07,381 --> 00:58:08,842
So you go from MIP to MIP.

1256
00:58:09,482 --> 00:58:10,983
You basically do all the high MIPs first,

1257
00:58:11,003 --> 00:58:12,443
then the next slid of MIPs, and so on,

1258
00:58:12,503 --> 00:58:13,584
and then you have the packed MIPs.

1259
00:58:14,364 --> 00:58:16,345
And so when we map things out, we're always

1260
00:58:16,365 --> 00:58:19,686
going to give the packed MIPs physical backing,

1261
00:58:19,766 --> 00:58:21,327
because we don't really want to look into that,

1262
00:58:22,247 --> 00:58:23,728
how they are really packed in there.

1263
00:58:24,568 --> 00:58:26,069
But then when we get to this point

1264
00:58:26,109 --> 00:58:27,890
where a MIP is actually using a 64K page.

1265
00:58:29,242 --> 00:58:30,702
We never back that very last mip.

1266
00:58:31,302 --> 00:58:32,223
So we just leave it blank.

1267
00:58:32,803 --> 00:58:35,984
And we just keep doing that for the rest of our mips.

1268
00:58:36,224 --> 00:58:38,925
And then we do the same thing with our high mip memory pool.

1269
00:58:39,726 --> 00:58:41,486
Only the slices that we use are back.

1270
00:58:41,506 --> 00:58:42,187
The rest are blank.

1271
00:58:42,227 --> 00:58:44,868
GPU never reads the memory that's blank.

1272
00:58:44,988 --> 00:58:46,348
And everyone's happy at the end.

1273
00:58:48,669 --> 00:58:52,931
Duplication, we solve that by sharing our 64k pages.

1274
00:58:54,992 --> 00:58:57,453
So all of our texture 2D arrays, they just contain references.

1275
00:58:58,150 --> 00:59:01,273
And at runtime, we map those references back and build

1276
00:59:01,334 --> 00:59:02,795
a texture 2D array at runtime.

1277
00:59:02,815 --> 00:59:04,897
So at cook time, our texture 2D arrays

1278
00:59:05,237 --> 00:59:08,460
have references to regular texture 2Ds.

1279
00:59:09,261 --> 00:59:11,203
And then we reference count those slices.

1280
00:59:13,946 --> 00:59:16,928
So again, packed MIPS, we just duplicate them.

1281
00:59:18,428 --> 00:59:21,291
And then the solution of actually sharing these slices

1282
00:59:21,411 --> 00:59:23,452
by using references has the benefit

1283
00:59:23,472 --> 00:59:25,814
that we could also use that entire slice

1284
00:59:26,074 --> 00:59:27,375
as a regular texture 2D.

1285
00:59:27,436 --> 00:59:29,537
So if you have another shader that uses the texture 2D,

1286
00:59:29,597 --> 00:59:30,098
we could do that.

1287
00:59:31,879 --> 00:59:33,861
And it also helped our cook times

1288
00:59:33,881 --> 00:59:36,603
because before we had to cook the entire texture 2D.

1289
00:59:36,763 --> 00:59:38,805
Now we're actually just cooking one slice at a time

1290
00:59:38,825 --> 00:59:40,546
because we're just referencing it at runtime.

1291
00:59:42,992 --> 00:59:44,333
So here's a quick example of that.

1292
00:59:44,393 --> 00:59:47,715
We have one texture array that uses stone and then

1293
00:59:47,835 --> 00:59:50,637
wood for the next slice, and one that uses wood and then stone.

1294
00:59:51,158 --> 00:59:53,119
Typically, if you were just cooking this offline,

1295
00:59:53,159 --> 00:59:55,361
it would be two completely separate texture arrays.

1296
00:59:55,881 --> 00:59:57,042
And when you load them at runtime,

1297
00:59:57,082 --> 00:59:59,303
you'd just be duplicating all those bits and data.

1298
00:59:59,904 --> 01:00:01,065
But since we're using references,

1299
01:00:01,165 --> 01:00:03,166
we know it's the exact same slice.

1300
01:00:03,426 --> 01:00:05,028
So we're only going to pay the cost for one.

1301
01:00:05,668 --> 01:00:07,690
So for the packed MIPS, again, we don't do anything.

1302
01:00:08,010 --> 01:00:09,451
We're going to back them with 64k pages.

1303
01:00:12,311 --> 01:00:14,452
So that's done, but now what we're going to do

1304
01:00:14,492 --> 01:00:16,193
is we're going to take one 64K page,

1305
01:00:16,813 --> 01:00:19,975
put in the bits for this stone texture,

1306
01:00:20,836 --> 01:00:22,657
and bind it to two virtual addresses,

1307
01:00:23,577 --> 01:00:24,457
and share them that way.

1308
01:00:25,218 --> 01:00:26,278
And we just keep doing that.

1309
01:00:26,459 --> 01:00:28,860
We just keep sharing and only using the memory

1310
01:00:28,900 --> 01:00:30,801
for one texture array and not for both.

1311
01:00:32,122 --> 01:00:34,723
And again, this basically saves us all the memory of,

1312
01:00:34,743 --> 01:00:39,045
it basically avoids the duplication costs completely.

1313
01:00:41,332 --> 01:00:42,832
And we do the same thing with the high MIPS.

1314
01:00:44,693 --> 01:00:48,494
So by doing this, by avoiding the duplication,

1315
01:00:48,514 --> 01:00:51,294
we saved about 300 megs of memory.

1316
01:00:51,754 --> 01:00:53,555
But it's really scene dependent, because it all depends

1317
01:00:53,615 --> 01:00:54,755
on how much duplication there is.

1318
01:00:56,196 --> 01:00:59,497
The padding, I can't really claim that we saved memory,

1319
01:00:59,517 --> 01:01:03,538
because what we would have done if we didn't have support

1320
01:01:03,618 --> 01:01:06,258
for non-power of two textures is we would just not

1321
01:01:06,298 --> 01:01:08,479
allow the artist to ever have non-power of two

1322
01:01:09,699 --> 01:01:10,680
texture array slices.

1323
01:01:11,349 --> 01:01:13,210
So if they wanted to do 17 slices,

1324
01:01:13,911 --> 01:01:16,172
we would just have the cooker return an error saying,

1325
01:01:16,192 --> 01:01:17,773
you either have to do 16 or 32.

1326
01:01:20,594 --> 01:01:21,215
And thank you.

1327
01:01:21,415 --> 01:01:22,636
And we're hiring.

1328
01:01:23,556 --> 01:01:26,658
And if you like what you saw, please come join us.

1329
01:01:27,418 --> 01:01:29,240
If you didn't like what you saw and you thought

1330
01:01:29,280 --> 01:01:31,161
it was really bad and you want to come and fix it,

1331
01:01:31,361 --> 01:01:32,341
well, we're hiring as well.

1332
01:01:43,658 --> 01:01:47,042
And we have four other talks here at GDC on Shadow of War.

1333
01:01:47,082 --> 01:01:48,563
So if you're interested in Shadow of War,

1334
01:01:48,584 --> 01:01:50,766
I would highly recommend you go see them.

1335
01:01:50,926 --> 01:01:52,688
The last two talks are still to come.

1336
01:01:52,888 --> 01:01:54,169
One is actually today at 4.

1337
01:01:56,311 --> 01:01:57,092
In order, any questions?

1338
01:02:13,035 --> 01:02:14,616
Yeah, I have a quick question.

1339
01:02:15,056 --> 01:02:19,921
In DirectX 12, they support bindless buffers.

1340
01:02:20,441 --> 01:02:23,083
Now, did you look into that at all for the PC?

1341
01:02:23,223 --> 01:02:24,565
And would that give you any savings?

1342
01:02:26,947 --> 01:02:29,589
So on PC, we were still all 11 on Shadow of War.

1343
01:02:29,609 --> 01:02:31,891
So we're now really looking at 12 at this point.

1344
01:02:33,192 --> 01:02:35,734
We did try to, so I actually had a bunch of PC slides

1345
01:02:35,774 --> 01:02:36,234
in this deck.

1346
01:02:36,355 --> 01:02:38,356
But as you could tell, it runs really long.

1347
01:02:38,817 --> 01:02:41,099
And so having another 30 minutes of PC slides

1348
01:02:41,179 --> 01:02:41,699
is way too long.

1349
01:02:42,886 --> 01:02:45,468
So on PC, we actually tried to use tiled resources

1350
01:02:45,528 --> 01:02:47,929
for a lot of things, because it's kind of the same idea.

1351
01:02:47,989 --> 01:02:50,110
You're mapping 64k pages at a time.

1352
01:02:50,290 --> 01:02:52,732
But with D311, there was a lot of limitations.

1353
01:02:53,772 --> 01:02:56,294
For instance, you could only have one memory pool

1354
01:02:56,434 --> 01:02:58,275
per resource, so it couldn't really

1355
01:02:58,315 --> 01:03:01,137
separate a high memory pool or a high MIP pool

1356
01:03:01,157 --> 01:03:02,177
with the rest of the pools.

1357
01:03:03,038 --> 01:03:06,019
And in addition to that, tiled resources

1358
01:03:06,059 --> 01:03:08,621
don't actually work with texture 2D arrays.

1359
01:03:09,581 --> 01:03:12,203
Basically, all those packed MIPs I was showing.

1360
01:03:13,096 --> 01:03:15,237
For texture 2D arrays, they're just unsupported.

1361
01:03:16,198 --> 01:03:18,039
So you could have texture 2D arrays.

1362
01:03:18,079 --> 01:03:19,400
You just can't have tail MIPS.

1363
01:03:19,720 --> 01:03:21,241
And for us, that's kind of useless.

1364
01:03:21,321 --> 01:03:26,905
So on PC, we actually ended up not sharing any of that memory

1365
01:03:26,945 --> 01:03:30,947
and just duplicating it all and just loading

1366
01:03:30,988 --> 01:03:33,069
high MIPS the traditional way and not

1367
01:03:33,209 --> 01:03:36,091
trying to exchange memory back and forth.

1368
01:03:37,612 --> 01:03:37,772
Yeah.

1369
01:03:41,815 --> 01:03:42,015
Hello.

1370
01:03:43,845 --> 01:03:50,910
So my questions in in terms of quality assurance so when you talk about the was it the dynamic frame pacing

1371
01:03:51,310 --> 01:03:55,993
So you mentioned how it was basically like dropping a frame so in terms of quality assurance

1372
01:03:56,033 --> 01:04:01,136
How do you distinguish between those frame rate drops and actual frame rate drop?

1373
01:04:01,557 --> 01:04:06,740
Well, it doesn't really drop a frame because our pipeline buffers out enough frames ahead

1374
01:04:07,020 --> 01:04:07,841
so it's

1375
01:04:08,486 --> 01:04:13,027
I only said that because we're going beyond 33 milliseconds.

1376
01:04:13,127 --> 01:04:18,528
And traditionally, in our older games, if we went beyond 33,

1377
01:04:19,028 --> 01:04:20,288
we would be dropping frames.

1378
01:04:20,368 --> 01:04:21,849
But because we're buffered out and you

1379
01:04:21,889 --> 01:04:23,549
have multiple stages in that pipeline,

1380
01:04:24,049 --> 01:04:27,270
those other stages absorb the fact that you went beyond 33.

1381
01:04:28,270 --> 01:04:29,250
So we're at 34.

1382
01:04:29,970 --> 01:04:33,151
We then start, because we're telescoped out,

1383
01:04:33,691 --> 01:04:35,532
that actually kind of also means we're buffered out.

1384
01:04:36,228 --> 01:04:38,930
which means these buffers could absorb the fact

1385
01:04:38,970 --> 01:04:41,392
that we just lost a millisecond in the first stage,

1386
01:04:42,052 --> 01:04:43,833
but we didn't lose a millisecond at the very end.

1387
01:04:43,873 --> 01:04:46,635
So there's actually no frame drop at the very end.

1388
01:04:46,915 --> 01:04:47,795
Figure of speech then.

1389
01:04:48,276 --> 01:04:49,416
Yeah, it's more like a figure of speech.

1390
01:04:49,436 --> 01:04:49,656
Thanks.

1391
01:04:51,558 --> 01:04:55,480
Hi, you said you were at 90 milliseconds at beta.

1392
01:04:56,100 --> 01:04:59,362
How many months before ship was that?

1393
01:05:00,843 --> 01:05:02,484
A lot less than I would want.

1394
01:05:03,825 --> 01:05:04,205
That was,

1395
01:05:06,887 --> 01:05:08,768
I mean that was probably let's see.

1396
01:05:10,088 --> 01:05:11,809
It's probably a year maybe.

1397
01:05:13,750 --> 01:05:14,410
OK, thanks.

1398
01:05:19,732 --> 01:05:22,993
With your threading model with a low priority tasks,

1399
01:05:23,133 --> 01:05:24,913
are they floating between the different cores?

1400
01:05:25,214 --> 01:05:26,894
And if so, did you ever have problems

1401
01:05:26,954 --> 01:05:28,415
where a low priority task would be

1402
01:05:28,435 --> 01:05:29,975
interrupted by a high priority task

1403
01:05:29,995 --> 01:05:31,516
for a long time before it finishes?

1404
01:05:32,596 --> 01:05:34,337
Yeah, we also had yes we did so.

1405
01:05:37,887 --> 01:05:41,689
So the low priority tasks being interrupted for too long,

1406
01:05:41,729 --> 01:05:43,591
we didn't have, but we did run into issues where,

1407
01:05:43,651 --> 01:05:46,673
for instance, a low priority task might take

1408
01:05:46,933 --> 01:05:48,995
the lock on the allocator,

1409
01:05:49,975 --> 01:05:51,897
then get swapped out for a high priority task.

1410
01:05:53,098 --> 01:05:54,999
And now the high priority task wants the allocator,

1411
01:05:55,179 --> 01:05:55,660
and now what?

1412
01:05:57,421 --> 01:05:59,462
And luckily, it almost never happens.

1413
01:05:59,903 --> 01:06:02,985
And so all of our spin locks that I mentioned we used,

1414
01:06:03,125 --> 01:06:05,527
eventually they go into a kernel primitive anyway,

1415
01:06:05,587 --> 01:06:07,048
so they will stall out.

1416
01:06:07,789 --> 01:06:10,130
So this high-priority task ever needs something

1417
01:06:10,150 --> 01:06:11,331
from the low-priority task.

1418
01:06:11,511 --> 01:06:12,692
It will spin there for a little bit,

1419
01:06:12,832 --> 01:06:14,153
and then be like, all right, I can't get this.

1420
01:06:14,193 --> 01:06:14,813
I'm going to sleep.

1421
01:06:15,153 --> 01:06:17,154
So it stalls, then this low-priority task

1422
01:06:17,314 --> 01:06:19,195
restarts again, lets go of that,

1423
01:06:21,977 --> 01:06:23,738
the lock on the allocator,

1424
01:06:24,198 --> 01:06:25,619
but then it gets swapped out right away

1425
01:06:25,679 --> 01:06:28,480
because now the other thread could go.

1426
01:06:28,620 --> 01:06:31,662
So it basically wakes and goes back to sleep,

1427
01:06:31,702 --> 01:06:33,103
and then the other thread keeps going.

1428
01:06:35,862 --> 01:06:38,723
So was that a big, did you solve that problem?

1429
01:06:38,863 --> 01:06:42,324
Yeah, I mean, so we solved the problem by eventually,

1430
01:06:42,904 --> 01:06:45,665
so we actually had a bigger problem on the Sony platforms.

1431
01:06:46,426 --> 01:06:48,906
So on the Sony platform, I'm not sure how familiar you are

1432
01:06:48,946 --> 01:06:53,848
with the PS4, but on the PS4, the problems we had

1433
01:06:53,908 --> 01:06:57,149
was the priorities for threads work a little bit differently.

1434
01:06:58,620 --> 01:07:01,961
If you call, for instance, yield on a PS4,

1435
01:07:02,161 --> 01:07:04,582
all that will yield to is to a thread

1436
01:07:04,622 --> 01:07:07,782
that's equal or higher priority, and not one that's lower.

1437
01:07:08,623 --> 01:07:09,923
So if you had a scenario of like,

1438
01:07:09,963 --> 01:07:11,464
well, I have this really high priority thread

1439
01:07:11,484 --> 01:07:14,485
that needs to run, but it can't get the allocator lock

1440
01:07:14,645 --> 01:07:16,485
because this lower one does, well, I'm gonna yield,

1441
01:07:17,705 --> 01:07:18,866
but this one's lower priority,

1442
01:07:18,906 --> 01:07:21,147
so it never gets that CPU slice.

1443
01:07:21,807 --> 01:07:25,128
So we had that problem, and we solved it.

1444
01:07:26,514 --> 01:07:32,799
Trying to remember exactly how we sold you know how we sold that we sold it in a really really bad way eventually what happens is.

1445
01:07:34,660 --> 01:07:41,385
We find out that we're basically stalling out too long here something's wrong alright so instead of calling yield let's just call sleep one.

1446
01:07:42,726 --> 01:07:47,810
So there this thread is completely going to sleep it's letting go of this entire core.

1447
01:07:48,951 --> 01:07:54,936
And then that out the low priority threads could kick in we actually do that on the PS4 because it's not necessary on the Microsoft platforms.

1448
01:07:56,016 --> 01:07:56,277
Thank you.

1449
01:07:58,071 --> 01:08:01,752
Do you do affinity locking on desktop platforms and is it worth it?

1450
01:08:02,933 --> 01:08:04,293
We do not right now.

1451
01:08:05,353 --> 01:08:13,396
There is that whole like new Windows 10 game mode thing that we were considering doing some affinity locking on that.

1452
01:08:14,456 --> 01:08:22,479
But the truth is we basically have to get this game running on the consoles and the CPU on the consoles is frankly not all that great.

1453
01:08:23,079 --> 01:08:26,040
So by the time it runs on the consoles it flies on the PC.

1454
01:08:27,902 --> 01:08:32,768
We basically don't authenticize, we let Windows schedule all the different threads all over the place.

