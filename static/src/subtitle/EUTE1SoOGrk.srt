1
00:00:05,442 --> 00:00:07,303
Hi, my name is Mario Palmero.

2
00:00:07,704 --> 00:00:10,305
I'm lead programmer in a small project at Tequila Works.

3
00:00:11,586 --> 00:00:14,628
And I'm going to talk to you about sampling textures

4
00:00:14,668 --> 00:00:18,650
in Vertex Shader and using that for some cool techniques.

5
00:00:20,491 --> 00:00:23,313
So the techniques I'm going to talk to you about

6
00:00:23,673 --> 00:00:29,236
have been developed by Norman Shar and me together or apart,

7
00:00:29,256 --> 00:00:30,437
depending on the technique.

8
00:00:31,778 --> 00:00:33,379
So let's get started.

9
00:00:35,577 --> 00:00:38,658
This is the team of the project I'm working on right now.

10
00:00:39,118 --> 00:00:43,641
I'm, as I said, lead programmer here, and also tech art.

11
00:00:44,581 --> 00:00:48,103
And I'm going to talk to you about my tech art

12
00:00:48,123 --> 00:00:50,464
part in this presentation.

13
00:00:51,985 --> 00:00:53,465
So what is a vertex shader?

14
00:00:53,786 --> 00:00:55,466
A vertex shader is a programmable part

15
00:00:55,506 --> 00:00:56,627
of the graphic pipeline.

16
00:00:57,047 --> 00:01:01,589
And that means that it's a part of the rendering of images.

17
00:01:02,404 --> 00:01:11,230
where the vertices are modified and we can modify position, normal, vertex color and

18
00:01:11,310 --> 00:01:11,851
UV mapping.

19
00:01:13,252 --> 00:01:23,199
So before having textures in the vertex shader, what we had to do is use mesh attributes to

20
00:01:23,799 --> 00:01:25,621
fit information into the vertex shader.

21
00:01:27,174 --> 00:01:31,076
to modify, for example, the vertex position normals

22
00:01:32,057 --> 00:01:33,597
or creating pivot points.

23
00:01:34,198 --> 00:01:37,219
Pivot points, I'm going to talk about pivot points

24
00:01:37,799 --> 00:01:40,341
because we use them in several techniques.

25
00:01:40,881 --> 00:01:44,283
Pivot points are transformation points

26
00:01:44,803 --> 00:01:48,765
that we can use to transform the position

27
00:01:49,025 --> 00:01:53,968
or rotation on several vertices at the same time on a mesh.

28
00:01:56,704 --> 00:01:59,786
So since they're at x11, we can simply sample textures

29
00:01:59,826 --> 00:02:00,726
in the vertex shader.

30
00:02:01,727 --> 00:02:04,649
And a typical use is this displacement map

31
00:02:05,949 --> 00:02:11,513
that we have the original mesh, but with a texture,

32
00:02:11,933 --> 00:02:16,155
we can create a morph target and blend from the original mesh

33
00:02:16,235 --> 00:02:22,079
to that new geometry, displacing the vertices depending

34
00:02:22,139 --> 00:02:24,680
on an amount set in that texture.

35
00:02:26,678 --> 00:02:32,904
However, I'm going to try to talk about more interesting cases for sampling textures in

36
00:02:32,924 --> 00:02:33,605
the vertex shader.

37
00:02:34,386 --> 00:02:44,115
If you think of textures as matrices of vectors, pixels transform into cells of information,

38
00:02:44,375 --> 00:02:49,600
like vectors of three or four elements, and depending on the number of bits that you are

39
00:02:49,740 --> 00:02:52,162
using will have different levels of precision.

40
00:02:53,487 --> 00:02:57,570
So let's get creative about using those textures.

41
00:03:01,212 --> 00:03:04,474
This is an example where we have a rain animated

42
00:03:05,415 --> 00:03:06,456
by vertex shader.

43
00:03:07,076 --> 00:03:09,938
We are moving the vertices depending

44
00:03:10,038 --> 00:03:14,300
on the pivot point of each drop in the z-axis.

45
00:03:16,202 --> 00:03:20,004
So from top to bottom, they are animated.

46
00:03:21,265 --> 00:03:21,465
But.

47
00:03:22,713 --> 00:03:25,493
how we know where to stop the drain.

48
00:03:26,374 --> 00:03:33,615
In this example, we have a port, and we don't want the drops to get beneath the port, so

49
00:03:33,955 --> 00:03:44,758
what we do is read, we map the drops into a texture, this texture in the bottom of the

50
00:03:44,798 --> 00:03:49,779
slide, we read the height of each drop.

51
00:03:50,593 --> 00:03:58,415
And we know when we have to reset the position of that drop and move and teleport that drop

52
00:03:58,755 --> 00:03:59,475
back to the top.

53
00:04:02,376 --> 00:04:13,799
A similar example is to fix some meshes to the ground and to get them really tight to

54
00:04:13,839 --> 00:04:18,860
the ground so they can deform with our ground level.

55
00:04:20,338 --> 00:04:22,458
Again, we read the same height map.

56
00:04:22,798 --> 00:04:25,099
In fact, in this technique, we are using the same height map

57
00:04:25,859 --> 00:04:30,040
to read the position of each vertex corresponding

58
00:04:30,080 --> 00:04:31,040
to a pixel.

59
00:04:32,120 --> 00:04:34,841
And we read that pixel to know the offset

60
00:04:34,861 --> 00:04:37,321
that we have to apply to that vertex

61
00:04:38,322 --> 00:04:41,622
so it can fit perfectly to the ground.

62
00:04:43,163 --> 00:04:45,863
So it's very easy for artists to place.

63
00:04:47,051 --> 00:04:55,074
their assets. In fact, if there's any artist here, maybe he or she can recall doing something

64
00:04:55,134 --> 00:05:02,197
like in the left part of the slide. Well, I think the right one is easier for everybody.

65
00:05:04,798 --> 00:05:14,523
This is one of my favourite use cases. This is a smoke I did collaborating with Simon

66
00:05:14,543 --> 00:05:14,983
Trompe l'Eau.

67
00:05:17,210 --> 00:05:20,931
It's a smoke animation, so we are baking animation

68
00:05:21,072 --> 00:05:21,772
into a texture.

69
00:05:22,752 --> 00:05:26,514
What we are baking right here is the hand position.

70
00:05:27,675 --> 00:05:31,256
So we transform x, y, z into RGB,

71
00:05:32,457 --> 00:05:35,178
and each pixel is a frame of this animation

72
00:05:36,479 --> 00:05:37,719
in an uncompressed texture.

73
00:05:39,500 --> 00:05:42,942
So what we do is for each frame, we

74
00:05:42,982 --> 00:05:46,623
create a pixel in this texture and record the hand animation.

75
00:05:48,520 --> 00:05:51,822
We are normalizing the position between 0 to 1

76
00:05:53,023 --> 00:05:54,924
in the bounding of the whole animation.

77
00:05:56,385 --> 00:06:00,327
And that is scaled back in the shader when it's played.

78
00:06:02,949 --> 00:06:06,571
The smoke that you are seeing has several rings of height.

79
00:06:07,771 --> 00:06:14,755
So from bottom to top, we are reading the current pixel

80
00:06:15,296 --> 00:06:16,496
in the bottom ring.

81
00:06:17,429 --> 00:06:20,971
And as we progress to the top of the smoke,

82
00:06:21,131 --> 00:06:22,612
we are reading previous frames.

83
00:06:24,033 --> 00:06:27,995
So it propagates the movement along the smoke.

84
00:06:31,277 --> 00:06:36,039
So that's cool, but what if we want to bake particle animation

85
00:06:36,220 --> 00:06:37,400
and play it in game?

86
00:06:39,280 --> 00:06:41,585
Well, maybe I would say Alembic.

87
00:06:43,007 --> 00:06:47,134
Alembic was created after, or at least published

88
00:06:47,235 --> 00:06:48,657
after this was made.

89
00:06:48,817 --> 00:06:50,761
This is a technique of Norman Shar.

90
00:06:51,965 --> 00:06:58,486
And we have 4,000 particles in this sample and 180 frames of animation.

91
00:06:58,786 --> 00:07:03,427
And what we do is each pixel of a texture is a position.

92
00:07:03,447 --> 00:07:05,708
Each row is a frame.

93
00:07:06,308 --> 00:07:14,270
So in a row we have all the position of the particles in one frame.

94
00:07:15,050 --> 00:07:18,331
And each column is the position of a vertex along time.

95
00:07:19,480 --> 00:07:24,761
So if we read that texture of 4,000 by 180,

96
00:07:27,922 --> 00:07:30,043
if we read the column of that texture,

97
00:07:30,503 --> 00:07:33,644
we could play one particle animation.

98
00:07:34,104 --> 00:07:37,065
And if we read them all, we have the whole animation.

99
00:07:39,186 --> 00:07:42,867
The thing is that making use of bilinear filtering

100
00:07:43,467 --> 00:07:46,548
of a texture, we can interpolate between positions.

101
00:07:47,977 --> 00:07:54,699
So an optimization of that technique could make that we could delete every other frame

102
00:07:54,759 --> 00:07:56,239
and probably nobody would notice.

103
00:07:58,820 --> 00:08:04,161
So again we are normalizing positions between 0 to 1 because it's better for precision,

104
00:08:05,442 --> 00:08:08,582
but even with that precision is obviously lost.

105
00:08:10,503 --> 00:08:15,364
But what if we want to make rigid object animation?

106
00:08:16,260 --> 00:08:24,302
Of course, we can do vertex cache, but that would mean that we will be storing every pixel

107
00:08:24,442 --> 00:08:25,222
in this animation.

108
00:08:26,742 --> 00:08:27,542
Every vertex, sorry.

109
00:08:28,123 --> 00:08:29,323
But we don't want that.

110
00:08:29,963 --> 00:08:31,643
Because we can create pivot points.

111
00:08:34,884 --> 00:08:42,686
We can group vertices sharing a pivot, so every vertex in a group shares the movement

112
00:08:43,286 --> 00:08:44,426
and the memory improvement.

113
00:08:45,208 --> 00:08:48,971
of brute force is a lot.

114
00:08:49,051 --> 00:08:51,713
32 objects, just recording 32 objects

115
00:08:51,933 --> 00:08:54,335
over the number of vertices that that mesh could have

116
00:08:55,256 --> 00:08:56,257
is a great improvement.

117
00:08:58,058 --> 00:09:02,161
So you can see at the left of the slide,

118
00:09:02,201 --> 00:09:03,742
you can see the position texture.

119
00:09:03,983 --> 00:09:05,824
And at the right is the rotation texture

120
00:09:06,625 --> 00:09:08,086
over 128 frames of animation.

121
00:09:08,126 --> 00:09:08,246
Here.

122
00:09:12,417 --> 00:09:16,597
The rotation is being recorded as quaternions, as RGBA.

123
00:09:18,878 --> 00:09:23,499
Again, we can delete every other frame using bilinear filtering.

124
00:09:26,680 --> 00:09:36,262
So, we have particle animations, we have rigid bodies animations, but what if we want to

125
00:09:36,322 --> 00:09:38,702
have a liquid simulation?

126
00:09:40,538 --> 00:09:45,239
So again, somebody could say Alembic, but this technique was made by Norman Shar again

127
00:09:48,260 --> 00:09:49,360
before it was published.

128
00:09:50,860 --> 00:09:58,142
I thought about Norman Shar before meeting him as the chocolate man because of that gif.

129
00:10:00,363 --> 00:10:02,983
If we split this hell of a long name...

130
00:10:04,095 --> 00:10:10,640
In 2, morph targets means that we have a different morph target for each frame.

131
00:10:11,820 --> 00:10:20,146
And vertex count agnostic means that we don't care of the number of vertices of the mesh

132
00:10:20,866 --> 00:10:21,487
in every frame.

133
00:10:21,787 --> 00:10:27,511
And that means that in a frame we can have 4,000 vertices and in the next frame we can

134
00:10:27,551 --> 00:10:30,613
have 3,000 vertices that we don't care about that.

135
00:10:32,527 --> 00:10:38,729
What we have is this position texture where we are recording the position in every frame.

136
00:10:38,989 --> 00:10:41,410
Again, it's raw, it's a frame.

137
00:10:43,611 --> 00:10:51,234
If we look closely, what we are doing is pairing vertices as triangles.

138
00:10:52,975 --> 00:10:58,917
So we know the position of each triangle of this mesh in every frame.

139
00:10:59,809 --> 00:11:02,672
And if a frame has less triangles than the maximum,

140
00:11:03,392 --> 00:11:06,875
at the right of the texture you can see those black gaps.

141
00:11:07,456 --> 00:11:11,039
That means that the triangle is being collapsed to zero.

142
00:11:11,899 --> 00:11:13,901
And if the triangle is collapsed to zero,

143
00:11:13,941 --> 00:11:15,903
the pixel shader won't notice

144
00:11:16,503 --> 00:11:18,305
and won't process that information.

145
00:11:21,122 --> 00:11:27,286
So, instead of interpolating between positions like in the other techniques, what we are

146
00:11:27,627 --> 00:11:33,551
doing here is teleporting triangles from one position to the other, and that position doesn't

147
00:11:33,591 --> 00:11:36,793
have to be coherent with the previous frame.

148
00:11:38,114 --> 00:11:41,736
So, in the shader, we don't linearly interpolate.

149
00:11:42,857 --> 00:11:45,158
We jump from one morph to the other.

150
00:11:47,480 --> 00:11:49,201
That's an optimization that we can do.

151
00:11:50,104 --> 00:11:51,304
that is triangle pairing.

152
00:11:52,565 --> 00:11:55,025
If instead of storing triangle by triangle,

153
00:11:55,465 --> 00:12:01,087
we store pairs of triangles, we are saving up to 33%,

154
00:12:03,348 --> 00:12:06,408
just storing four vertices instead of six vertices.

155
00:12:10,269 --> 00:12:12,970
But ideally, we should have different options

156
00:12:13,230 --> 00:12:14,290
of geometry compression.

157
00:12:15,331 --> 00:12:17,831
And as John Carmack stated, it's a little surprising

158
00:12:17,851 --> 00:12:18,552
that we don't have

159
00:12:20,277 --> 00:12:25,161
any locality-based vertex compression schemes for static meshes in hardware today.

160
00:12:27,243 --> 00:12:30,725
Maybe somebody will work on that in the future.

161
00:12:32,247 --> 00:12:37,091
So I have some of those techniques before getting to the last one.

162
00:12:39,093 --> 00:12:44,837
But I want to talk before the last one about advantages of these kind of techniques.

163
00:12:47,043 --> 00:12:50,986
The CPU doesn't know anything about what's happening in the GPU.

164
00:12:51,506 --> 00:12:56,449
So the CPU doesn't have to create buffers, doesn't have to communicate in any way with

165
00:12:56,469 --> 00:12:59,271
the GPU to create that kind of techniques.

166
00:13:01,152 --> 00:13:03,994
Just the texture being fed into the GPU.

167
00:13:05,174 --> 00:13:08,576
Second one is we are working with a standard format.

168
00:13:09,788 --> 00:13:12,228
This is not vertex cache.

169
00:13:12,629 --> 00:13:21,471
We can't share our vertex cache animation by WhatsApp or posting it into Instagram, but

170
00:13:21,511 --> 00:13:22,951
we can do that with this.

171
00:13:26,572 --> 00:13:27,892
The third one is the order.

172
00:13:28,292 --> 00:13:29,213
This is an important one.

173
00:13:30,973 --> 00:13:35,974
Textures have an intrinsic spatial coherence that we can use in our favor.

174
00:13:36,174 --> 00:13:38,115
For example, we always know new...

175
00:13:40,787 --> 00:13:46,472
where the previous frame of a vertex will be, just in the row before.

176
00:13:48,514 --> 00:13:50,076
But it has some drawbacks.

177
00:13:52,638 --> 00:13:56,001
We are lacking precision, and that's something that we can't avoid.

178
00:13:56,622 --> 00:14:03,988
We can try to palliate that, normalising, as I said, but it's something that you have

179
00:14:04,028 --> 00:14:04,569
to work with.

180
00:14:08,786 --> 00:14:13,048
I can assure you that the first time that you try something like that, you won't see

181
00:14:13,088 --> 00:14:13,449
the mesh.

182
00:14:14,169 --> 00:14:20,573
The mesh probably will be in the infinite or maybe collapse to zero, and it's a hell

183
00:14:20,973 --> 00:14:23,694
to debug that to know what's happening there.

184
00:14:24,395 --> 00:14:25,015
And creation.

185
00:14:26,716 --> 00:14:31,619
You have to have custom tools to create those textures in your pipeline.

186
00:14:32,439 --> 00:14:35,221
Luckily enough, Houdini is working in...

187
00:14:36,676 --> 00:14:39,078
has worked in implementing those techniques,

188
00:14:39,218 --> 00:14:41,639
the previous one at least, as far as I know.

189
00:14:42,240 --> 00:14:45,022
And now you can play that into Unreal Engine

190
00:14:45,102 --> 00:14:47,143
transparent to the artist.

191
00:14:49,244 --> 00:14:54,268
So we were thinking about, in this project I told you,

192
00:14:54,728 --> 00:14:57,910
Norman and I were thinking about making a lot of animation

193
00:14:57,970 --> 00:15:02,113
and cloth simulation into textures using those techniques.

194
00:15:02,907 --> 00:15:08,091
but that meant that we have a huge amount of vertex data to handle.

195
00:15:09,132 --> 00:15:13,515
So we were thinking about compressing that data depending on the amount of movement,

196
00:15:14,215 --> 00:15:20,620
depending on the animation, but during a break we had a new idea.

197
00:15:20,640 --> 00:15:24,943
And that's the last technique I'm going to talk to you about.

198
00:15:24,963 --> 00:15:30,187
The idea is, what if we transform simulation into bone animation?

199
00:15:31,808 --> 00:15:35,331
What if we put the bone transformation data into a texture?

200
00:15:36,852 --> 00:15:42,697
So the thing is, we were fiddling a little with Hans Goddard's solver.

201
00:15:43,698 --> 00:15:48,202
That's a plugin that transforms simulation into bone animation.

202
00:15:49,002 --> 00:15:56,789
Even morph targets and blending targets into animation.

203
00:15:58,000 --> 00:15:59,520
So into bone animation.

204
00:15:59,620 --> 00:16:03,702
So if we store bone animation instead of vertex animation,

205
00:16:04,622 --> 00:16:11,184
we're saving a lot of data, a lot of texture in the process.

206
00:16:12,985 --> 00:16:14,025
Can we actually do it?

207
00:16:14,666 --> 00:16:16,826
Well, the skinning of the mesh is already

208
00:16:16,886 --> 00:16:17,987
being done in the GPU.

209
00:16:18,367 --> 00:16:19,547
So theoretically, yes.

210
00:16:20,448 --> 00:16:23,509
But we need to have access to all the information in the CPU.

211
00:16:25,548 --> 00:16:35,810
in an unconventional way because we were using Unreal 4 and we didn't want to modify the

212
00:16:35,850 --> 00:16:42,571
pipeline, the engine, to feed that information into the shader.

213
00:16:43,191 --> 00:16:47,172
So through mesh and texture information, we achieved to do everything.

214
00:16:50,272 --> 00:16:54,113
We stored the translation of the bones that we need in a texture.

215
00:16:56,014 --> 00:16:59,557
We store the rotation of bones in another texture,

216
00:17:00,017 --> 00:17:00,558
as you can guess.

217
00:17:02,539 --> 00:17:05,942
But here we have to store the weighting of the vertices.

218
00:17:05,962 --> 00:17:08,344
If you know animation, how it works,

219
00:17:09,545 --> 00:17:12,848
its vertex has some bones affecting it.

220
00:17:12,908 --> 00:17:12,948
So.

221
00:17:16,332 --> 00:17:17,812
We have to store that information,

222
00:17:17,832 --> 00:17:21,333
and we do that into two extra UV channels.

223
00:17:21,794 --> 00:17:26,115
That means that we only have four influences per vertex.

224
00:17:27,816 --> 00:17:31,377
That's the limitation for our implementation,

225
00:17:32,077 --> 00:17:33,258
but can be improved.

226
00:17:35,258 --> 00:17:39,640
Where we store the index, the indices of those bones,

227
00:17:40,640 --> 00:17:43,401
into vertex color, again, another limitation.

228
00:17:43,541 --> 00:17:45,262
That means that we only can have.

229
00:17:48,556 --> 00:17:50,777
256 bones affecting its vertex.

230
00:17:52,337 --> 00:17:57,398
I mean, affecting all the vertices in that texture.

231
00:17:58,678 --> 00:18:01,839
And where we store the initial offset of those bones,

232
00:18:02,059 --> 00:18:04,379
we need the initial position of those bones,

233
00:18:05,259 --> 00:18:07,180
and that's an easy one, more textures,

234
00:18:07,460 --> 00:18:11,401
but what we do, what we really do is store that

235
00:18:11,461 --> 00:18:13,301
in the first row of the position texture.

236
00:18:15,710 --> 00:18:17,631
So the process, how we actually do it,

237
00:18:18,531 --> 00:18:21,251
how we actually play animation into textures.

238
00:18:22,292 --> 00:18:23,192
We have a vertex.

239
00:18:24,132 --> 00:18:25,812
We have a vertex color,

240
00:18:27,973 --> 00:18:30,973
four indices for that vertex,

241
00:18:31,833 --> 00:18:35,614
and two XRUV channels, four weighting values.

242
00:18:37,514 --> 00:18:42,655
We read the index of the bone affecting that vertex.

243
00:18:45,975 --> 00:18:48,976
We read the weighting of that bone.

244
00:18:51,978 --> 00:18:55,379
We read the position and rotation of those bones from both textures.

245
00:18:55,839 --> 00:19:00,281
Knowing the index, we know the column of the texture that we have to read.

246
00:19:01,502 --> 00:19:07,025
And with the time being fed into the vertex shader, we know the current frame.

247
00:19:07,305 --> 00:19:13,388
So we have the pixel position in both textures to be able to transform that vertex.

248
00:19:14,875 --> 00:19:19,316
So we have all what we need to apply the linear skinning

249
00:19:19,377 --> 00:19:19,857
algorithm.

250
00:19:21,377 --> 00:19:26,238
And the result is this, a full animation baked

251
00:19:26,618 --> 00:19:28,239
into two simple textures.

252
00:19:32,300 --> 00:19:33,440
Here's those textures.

253
00:19:36,181 --> 00:19:38,281
So here's the animation through another lens.

254
00:19:40,792 --> 00:19:41,773
But what are the numbers?

255
00:19:42,113 --> 00:19:47,455
Why would somebody do that instead of animating, per se?

256
00:19:48,235 --> 00:19:52,237
Well, it had sense for us because we had simulation.

257
00:19:53,977 --> 00:19:56,959
And we calculate the amount of data

258
00:19:56,999 --> 00:20:00,460
that we could put into textures without the CPU noticing

259
00:20:00,800 --> 00:20:01,941
and was worth it for us.

260
00:20:02,961 --> 00:20:07,163
These techniques meant to be inspirational, not a technique

261
00:20:07,203 --> 00:20:08,723
that everybody should follow.

262
00:20:10,084 --> 00:20:10,284
So.

263
00:20:11,599 --> 00:20:14,560
How much animation can we store in a texture?

264
00:20:15,781 --> 00:20:18,663
Can we handle facial animation for all the cinematics?

265
00:20:19,303 --> 00:20:21,004
Or which frame rate are we talking about?

266
00:20:22,005 --> 00:20:27,829
The numbers for us, 166 minutes of facial animation

267
00:20:29,310 --> 00:20:33,432
in 2K textures, 30 frames per second.

268
00:20:35,394 --> 00:20:36,935
For us, it was a great improvement.

269
00:20:38,828 --> 00:20:43,592
But what if we want awesome facial animation, 450 bones?

270
00:20:44,573 --> 00:20:48,036
Well, 20 minutes, 21 minute, probably more

271
00:20:48,596 --> 00:20:51,499
than what you need in your project

272
00:20:52,540 --> 00:20:55,562
for awesome facial animation.

273
00:20:56,082 --> 00:20:59,225
And the same frame rate and the same size of textures.

274
00:21:02,027 --> 00:21:03,388
And from here.

275
00:21:04,336 --> 00:21:05,337
What can we do with that?

276
00:21:06,117 --> 00:21:09,320
Well, our roadmap for this technique

277
00:21:10,441 --> 00:21:11,662
is to improve normal solving.

278
00:21:11,742 --> 00:21:14,364
Right now we are doing regular normal solving.

279
00:21:14,424 --> 00:21:17,306
That means that we read the normal from the vertex

280
00:21:17,406 --> 00:21:20,188
and we are modifying it by the rotation of the bone.

281
00:21:21,930 --> 00:21:25,713
But there are more accurate solutions to that

282
00:21:26,113 --> 00:21:27,334
that we want to implement.

283
00:21:30,233 --> 00:21:36,875
Implementing animation blending, what we're talking about here is about cinematics or

284
00:21:36,956 --> 00:21:42,558
simulations, but could we use this technique for animation blending?

285
00:21:42,598 --> 00:21:43,398
Yes, we can.

286
00:21:44,138 --> 00:21:51,641
If we store all the animation, different animations of a character into a huge texture, we can,

287
00:21:52,182 --> 00:21:53,562
knowing the raw that we have...

288
00:21:54,476 --> 00:21:57,839
to offset, to read different animations,

289
00:21:58,339 --> 00:22:01,001
we can blend between them just with one sampling.

290
00:22:03,163 --> 00:22:05,205
Support bone scaling, that's an easy one.

291
00:22:05,465 --> 00:22:07,867
Just some more maths in the vertex shader.

292
00:22:08,647 --> 00:22:09,788
And another texture.

293
00:22:12,112 --> 00:22:13,213
and enhanced compression.

294
00:22:13,393 --> 00:22:15,274
As I said, probably we can,

295
00:22:15,434 --> 00:22:17,155
with a smarter compression system,

296
00:22:17,315 --> 00:22:20,176
we can compress animation depending on

297
00:22:21,036 --> 00:22:23,017
the amount of movement of the character

298
00:22:23,918 --> 00:22:27,359
and interpolate between rows.

299
00:22:28,620 --> 00:22:32,721
So, some final thoughts about those techniques.

300
00:22:35,184 --> 00:22:43,691
What we get as output for those techniques when we were doing them is that you have to

301
00:22:43,731 --> 00:22:44,451
know your tools.

302
00:22:45,232 --> 00:22:50,817
You have to know what textures in the vertex shader means, because textures in the vertex

303
00:22:50,837 --> 00:22:57,102
shader is a powerful tool that most people are ignoring.

304
00:22:58,363 --> 00:23:00,785
Textures can be used as data containers.

305
00:23:01,835 --> 00:23:04,916
And we can approach problems from different perspectives.

306
00:23:06,857 --> 00:23:09,937
So from here, I want to thank Hans Goebbels.

307
00:23:11,018 --> 00:23:17,519
You should check this video for his solver, because that was the spark that ignited this

308
00:23:17,579 --> 00:23:17,920
idea.

309
00:23:21,841 --> 00:23:26,942
Also thank Norman, because we worked together in those techniques, but he couldn't make

310
00:23:26,982 --> 00:23:28,162
it to be here today.

311
00:23:30,775 --> 00:23:32,696
More or less, that's it.

312
00:23:33,177 --> 00:23:34,217
Thank you for listening.

313
00:23:34,678 --> 00:23:37,259
So if you have any questions, go ahead.

314
00:23:45,765 --> 00:23:51,109
Anyway, you can contact us for whatever you want about this.

315
00:23:52,390 --> 00:23:53,831
You have our emails there.

316
00:23:57,757 --> 00:23:57,977
Hi.

317
00:23:57,997 --> 00:23:59,159
Hi.

318
00:23:59,579 --> 00:24:08,627
I was wondering, a lot of times you need the positions of bones or vertices on the CPU

319
00:24:09,528 --> 00:24:10,609
for gameplay stuff.

320
00:24:10,689 --> 00:24:20,758
So do you have a parallel implementation for cases when you do need to access stuff on

321
00:24:20,798 --> 00:24:23,581
the CPU or do you just make it work with textures?

322
00:24:25,614 --> 00:24:33,462
So the question is, if I have some kind of metrics to know when to use bones or when

323
00:24:33,502 --> 00:24:34,363
to use texture?

324
00:24:36,706 --> 00:24:37,106
We don't.

325
00:24:38,348 --> 00:24:38,948
I don't have it.

326
00:24:39,309 --> 00:24:40,590
I don't have them.

327
00:24:44,328 --> 00:24:50,490
I would go for try both of them and see what works better for you.

328
00:24:51,070 --> 00:24:56,411
It depends on the amount of animation, it depends on the amount of bones, it depends

329
00:24:56,531 --> 00:24:58,172
on the implementation of both.

330
00:24:58,912 --> 00:25:04,974
So it's like if you ask me, would you use Alembic or these techniques?

331
00:25:05,314 --> 00:25:05,814
It depends.

332
00:25:06,494 --> 00:25:09,795
Alembic has several implementations, different implementations.

333
00:25:11,490 --> 00:25:12,270
It depends a lot.

334
00:25:12,930 --> 00:25:16,771
For us, it made sense because we wanted to implement simulation.

335
00:25:17,611 --> 00:25:19,991
And we couldn't do that with Bones.

336
00:25:21,632 --> 00:25:21,952
Thank you.

337
00:25:22,652 --> 00:25:22,952
Thank you.

338
00:25:24,212 --> 00:25:24,452
Hi.

339
00:25:24,892 --> 00:25:26,633
Hey, thank you so much for the presentation.

340
00:25:26,653 --> 00:25:28,013
It was really cool.

341
00:25:28,113 --> 00:25:31,314
I had a question in regards to the height map-based pipelines,

342
00:25:31,414 --> 00:25:32,954
say for object population.

343
00:25:33,774 --> 00:25:36,275
First of all, obviously, how do you guys deal with precision?

344
00:25:36,315 --> 00:25:37,595
Because whenever we try something

345
00:25:37,635 --> 00:25:39,475
about it in a landscape that's a little bit bigger.

346
00:25:40,136 --> 00:25:43,198
we get stuff that's floating around, but the other part of it is also workflow.

347
00:25:43,579 --> 00:25:47,622
Because even though artists don't have to fit assets anymore to the terrain every time,

348
00:25:48,103 --> 00:25:49,604
anytime they change the terrain,

349
00:25:50,025 --> 00:25:52,527
you have to make sure that the height map is updated appropriately,

350
00:25:52,567 --> 00:25:54,248
otherwise you get weird artifacts.

351
00:25:54,268 --> 00:25:56,911
So have you had any workflow experience in that regard?

352
00:25:57,226 --> 00:26:02,568
Yeah, our workflow is to have the tool ready for the last building.

353
00:26:02,628 --> 00:26:05,290
It's like rebuilding lighting.

354
00:26:05,510 --> 00:26:11,272
Every time that you change something, you have to rebuild it.

355
00:26:11,633 --> 00:26:17,875
We created a tool and we wait until the last build to rebuild all the...

356
00:26:20,577 --> 00:26:28,559
all the texture. The thing is, you can iterate on that and make it easier for artists to

357
00:26:28,619 --> 00:26:38,462
work with that. In our case, the artists aren't changing the topology of the level too much

358
00:26:38,802 --> 00:26:46,485
because animation complained about that and we had to make a compromise.

359
00:26:47,924 --> 00:26:50,845
Cool, well that's good to know that you implemented it as part of the build step.

360
00:26:51,145 --> 00:26:51,485
Thank you.

361
00:26:51,765 --> 00:26:52,085
Thank you.

362
00:26:53,165 --> 00:26:53,305
Hi.

363
00:26:53,925 --> 00:26:54,225
Hi.

364
00:26:54,645 --> 00:27:00,787
You said that when you're using like rigid body backed animation you had instead of storing

365
00:27:00,847 --> 00:27:03,867
every vertex you store a pivot point and you rotate around the pivot point.

366
00:27:05,428 --> 00:27:08,548
How do you, where's the data that relates the vertices to the pivot point?

367
00:27:08,648 --> 00:27:13,169
Is that in the texture itself or is that, does it just use like the mesh origin or something?

368
00:27:13,700 --> 00:27:14,601
Can you repeat the question?

369
00:27:14,641 --> 00:27:17,402
Sorry, I can't hear you.

370
00:27:18,383 --> 00:27:22,765
So when you're storing pivot point animation

371
00:27:22,985 --> 00:27:26,406
rather than each vertex, how do you relate each vertex

372
00:27:26,446 --> 00:27:27,147
to the pivot point?

373
00:27:27,367 --> 00:27:31,289
Is that in the texture, or is that just use the mesh origin?

374
00:27:31,609 --> 00:27:34,190
OK, the pivot point is being, you're

375
00:27:34,230 --> 00:27:36,791
asking about where the pivot point is being stored,

376
00:27:36,971 --> 00:27:37,232
don't you?

377
00:27:37,772 --> 00:27:37,952
Yeah.

378
00:27:38,292 --> 00:27:38,352
OK.

379
00:27:39,519 --> 00:27:45,105
The pivot point here, at least, is being stored in the vertex color, I think.

380
00:27:45,345 --> 00:27:50,270
This is Norman's technique, as I said, and he did it by his own.

381
00:27:50,550 --> 00:27:57,237
But I would store it probably in the vertex color, or if I feel that there's not enough

382
00:27:57,277 --> 00:27:59,440
precision you can do it in extra UV channels.

383
00:28:02,110 --> 00:28:07,813
You have no more option I think, maybe texture but I don't see it happening.

384
00:28:07,833 --> 00:28:08,493
Awesome thanks.

385
00:28:08,653 --> 00:28:10,074
I've just got one more quick question.

386
00:28:10,834 --> 00:28:15,376
You said you store the index of bones in vertex colors as well, why do you have 256 bone limit

387
00:28:15,396 --> 00:28:15,596
there?

388
00:28:16,196 --> 00:28:17,017
Sorry?

389
00:28:17,257 --> 00:28:21,959
Why do you have a 256 bone limit when you store the index of the bones in the vertex

390
00:28:21,979 --> 00:28:22,299
colors?

391
00:28:25,921 --> 00:28:26,601
Your question?

392
00:28:26,621 --> 00:28:29,262
Because surely the vertex colors would be 32 bits.

393
00:28:31,108 --> 00:28:35,156
So I don't quite hear you well.

394
00:28:35,497 --> 00:28:35,958
Sorry.

395
00:28:35,998 --> 00:28:37,961
Am I too quiet or no, no, no.

396
00:28:38,022 --> 00:28:38,543
Is my accent.

397
00:28:39,992 --> 00:28:41,072
It's my English, sorry.

398
00:28:42,673 --> 00:28:45,235
So you store the bone index in vertex colors.

399
00:28:45,475 --> 00:28:46,375
Yeah.

400
00:28:46,435 --> 00:28:49,457
Why do you say that you're limited to 256 bones?

401
00:28:49,597 --> 00:28:53,159
OK, it was enough for us to do that.

402
00:28:53,359 --> 00:28:57,081
But in later implementation of these techniques,

403
00:28:57,382 --> 00:28:59,923
we are thinking about implementing that

404
00:29:00,003 --> 00:29:03,205
into another texture, and a small texture.

405
00:29:04,186 --> 00:29:05,546
And that will give us.

406
00:29:06,955 --> 00:29:11,379
virtually infinite influences to have.

407
00:29:11,940 --> 00:29:12,681
Okay, awesome, thanks.

408
00:29:13,101 --> 00:29:13,401
Thank you.

409
00:29:16,765 --> 00:29:17,906
I have a question and a comment.

410
00:29:17,966 --> 00:29:19,808
One question, did you consider using

411
00:29:19,908 --> 00:29:21,390
principal component analysis,

412
00:29:21,530 --> 00:29:23,552
which is a pretty common technique

413
00:29:23,572 --> 00:29:25,674
to compress these types of vertex animations?

414
00:29:26,074 --> 00:29:26,175
Yeah.

415
00:29:28,541 --> 00:29:30,983
Is it common to compress vertex animation?

416
00:29:31,003 --> 00:29:33,305
With principal component analysis.

417
00:29:33,926 --> 00:29:35,708
It's a technique, mathematical technique.

418
00:29:36,929 --> 00:29:39,851
If you haven't considered it, I would recommend looking it up.

419
00:29:40,192 --> 00:29:43,174
It can be very useful to compress this kind of lengthy

420
00:29:43,835 --> 00:29:46,517
vertex animation into effectively a small number of morph targets

421
00:29:46,537 --> 00:29:48,940
that you then just blend between and mix them in different ways.

422
00:29:49,820 --> 00:29:51,082
Also I had a comment...

423
00:29:52,092 --> 00:29:54,673
you were representing like using this or Alembic, but I

424
00:29:54,713 --> 00:29:57,514
don't think it's necessarily an either or, because Alembic is

425
00:29:57,554 --> 00:29:59,794
more a file format for communicating between tools.

426
00:29:59,874 --> 00:30:01,815
And this is more of a runtime format.

427
00:30:02,035 --> 00:30:04,756
I could definitely imagine a pipeline where you use Alembic

428
00:30:04,836 --> 00:30:07,656
and at the end you bake it down into a texture, unless

429
00:30:07,696 --> 00:30:08,937
you're specifically referring to using

430
00:30:08,997 --> 00:30:10,177
Unreal's Alembic loading.

431
00:30:11,694 --> 00:30:20,719
I agree, as I said, this is meant to be inspirational just to make the people think about the power

432
00:30:20,779 --> 00:30:22,440
of having textures in the vertex shader.

433
00:30:22,460 --> 00:30:26,282
Each one has to know their tools.

434
00:30:26,883 --> 00:30:29,644
I don't quite have used Alembic.

435
00:30:31,886 --> 00:30:40,794
by now, but I'm thinking about implementing some hybrid techniques.

436
00:30:40,934 --> 00:30:48,421
The thing is, it was meant to be inspirational, not just you have to do it like this and like

437
00:30:48,441 --> 00:30:50,423
that, but thank you for the comment, yeah, really.

438
00:30:51,023 --> 00:30:51,464
Thank you.

439
00:30:52,385 --> 00:30:53,085
Any more questions?

440
00:30:54,006 --> 00:30:54,166
No?

441
00:30:54,527 --> 00:30:56,368
Well, thank you for being here.

