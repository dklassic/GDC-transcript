1
00:00:06,143 --> 00:00:09,466
Welcome to this first presentation of this rainy day.

2
00:00:09,466 --> 00:00:13,650
I hope everyone had a good night of sleep.

3
00:00:13,650 --> 00:00:14,991
My name is FranÃ§ois Paradis.

4
00:00:14,991 --> 00:00:16,813
I am a programmer and a team lead

5
00:00:16,813 --> 00:00:18,535
at the Ubisoft Quebec studio.

6
00:00:18,535 --> 00:00:20,817
And I worked on Assassin's Creed Odyssey.

7
00:00:20,817 --> 00:00:23,899
And today I want to present my team's approach

8
00:00:23,899 --> 00:00:25,841
to cinematic dialogues.

9
00:00:25,841 --> 00:00:29,244
How we procedurally generated many elements of our scenes

10
00:00:29,244 --> 00:00:31,927
and how it impacted our workflows and our production.

11
00:00:35,210 --> 00:00:39,755
Assassin's Creed Odyssey is a single player RPG with a strong narrative focus.

12
00:00:39,755 --> 00:00:46,704
It is set in ancient Greece and you go on an adventure to find your family and become a legendary hero.

13
00:00:46,704 --> 00:00:52,811
And the game lets you choose your own destiny and craft your own story through interactive dialogues.

14
00:00:56,725 --> 00:01:05,972
The choices we make, no matter how small, can put us on a path to greatness

15
00:01:05,972 --> 00:01:17,560
or lead us down a road to ruin. The choice to define your own path. To be who you want to be.

16
00:01:17,560 --> 00:01:25,725
Help us! We don't have to die. The choice to be compassionate. Please! Let them go. What? You're no God.

17
00:01:28,415 --> 00:01:30,477
Or to hate.

18
00:01:30,477 --> 00:01:31,217
Peace.

19
00:01:31,217 --> 00:01:41,204
Or war.

20
00:01:41,204 --> 00:01:43,066
To strike from the shadows.

21
00:01:43,066 --> 00:01:46,728
Or attack in the fields of battle.

22
00:01:59,037 --> 00:02:04,100
In this world, there are no wrong paths,

23
00:02:04,100 --> 00:02:08,243
no wrong decisions, only who you choose to become.

24
00:02:08,243 --> 00:02:12,926
This is your Odyssey.

25
00:02:12,926 --> 00:02:14,267
So with Assassin's Creed Odyssey,

26
00:02:14,267 --> 00:02:17,469
we wanted the player to be able to connect to the story

27
00:02:17,469 --> 00:02:22,752
in an even deeper way and make him an active participant

28
00:02:22,752 --> 00:02:28,155
of the narrative using branching cinematic dialogues.

29
00:02:29,302 --> 00:02:31,802
Branching dialogues, they do two things for us.

30
00:02:31,802 --> 00:02:34,083
First, obviously, they allow the player to role play

31
00:02:34,083 --> 00:02:36,384
and make choices that will affect the story.

32
00:02:36,384 --> 00:02:40,225
But also, maybe even more importantly,

33
00:02:40,225 --> 00:02:43,046
they allow his actions in gameplay or in the world

34
00:02:43,046 --> 00:02:44,427
to be reflected in the narrative.

35
00:02:44,427 --> 00:02:49,128
So we invested massively into a new cinematic dialogue system

36
00:02:49,128 --> 00:02:50,389
to support this.

37
00:02:50,389 --> 00:02:53,350
Another big reason for this is that we wanted

38
00:02:53,350 --> 00:02:56,171
to be way more generous with the player in terms of content.

39
00:02:57,348 --> 00:02:59,229
The game features a large amount of quests,

40
00:02:59,229 --> 00:03:00,909
and we wanted each and every one of them

41
00:03:00,909 --> 00:03:04,311
to be supported by an interesting story and cut

42
00:03:04,311 --> 00:03:05,491
scenes.

43
00:03:05,491 --> 00:03:09,513
To give you an idea of the scope of the game,

44
00:03:09,513 --> 00:03:11,854
we ended up with about 30 hours of cinematic content

45
00:03:11,854 --> 00:03:16,496
in the main game, spread across more than 1,000 scenes

46
00:03:16,496 --> 00:03:18,396
and about 25,000 spoken lines.

47
00:03:19,877 --> 00:03:22,537
In comparison, previous installments of Assassin's Creed

48
00:03:22,537 --> 00:03:25,778
had between three to six hours of cinematic content.

49
00:03:25,778 --> 00:03:27,278
It's a pretty big step.

50
00:03:27,278 --> 00:03:31,479
So we knew from the start that a traditional cinematic pipeline

51
00:03:31,479 --> 00:03:33,619
would not be enough, and we needed

52
00:03:33,619 --> 00:03:36,040
to look at new workflows.

53
00:03:36,040 --> 00:03:38,720
And the way we chose to approach this

54
00:03:38,720 --> 00:03:41,581
is to build the scenes using modular assets,

55
00:03:41,581 --> 00:03:44,782
for example, by reusing animations and cameras.

56
00:03:46,685 --> 00:03:49,067
And this approach also means that we can iterate

57
00:03:49,067 --> 00:03:51,408
on the game more easily, and on a game like this,

58
00:03:51,408 --> 00:03:53,810
quests are added, removed, changed,

59
00:03:53,810 --> 00:03:54,831
all along the production,

60
00:03:54,831 --> 00:03:57,153
and the narrative scenes need to be updated.

61
00:03:57,153 --> 00:04:00,255
And those changes are much more costly

62
00:04:00,255 --> 00:04:02,877
if you have to mo-cap every scene.

63
00:04:02,877 --> 00:04:05,519
So I won't spend too much time explaining the basics

64
00:04:05,519 --> 00:04:07,040
of such a dialogue system,

65
00:04:07,040 --> 00:04:08,762
because there's been many presentations

66
00:04:08,762 --> 00:04:09,683
about this in the past,

67
00:04:09,683 --> 00:04:12,164
such as the excellent Witcher 3 presentation

68
00:04:12,164 --> 00:04:14,106
from three years ago, I think.

69
00:04:15,218 --> 00:04:19,280
Instead, I want to focus on a third element that we really wanted to put forward in Assassin's

70
00:04:19,280 --> 00:04:24,623
Creed Odyssey, content generation and procedural systems.

71
00:04:24,623 --> 00:04:30,285
As you'll see, content generation allows us to produce more content and to produce it

72
00:04:30,285 --> 00:04:34,007
in smarter ways.

73
00:04:34,007 --> 00:04:37,709
So in this presentation, I will first show an overview of the general workflows that

74
00:04:37,709 --> 00:04:41,911
the content creators were using to create the dialogues and the various ways in which

75
00:04:41,911 --> 00:04:44,812
procedural generation was integrated in those workflows.

76
00:04:45,695 --> 00:04:49,497
I will also examine more closely how we generate every aspect

77
00:04:49,497 --> 00:04:51,818
of a scene, from staging and animation

78
00:04:51,818 --> 00:04:53,419
to cameras and lighting.

79
00:04:53,419 --> 00:04:56,280
And finally, I'll wrap things up by going

80
00:04:56,280 --> 00:04:58,942
over some interesting issues and topics

81
00:04:58,942 --> 00:05:00,842
related to our experience.

82
00:05:00,842 --> 00:05:06,405
So this is a finished cinematic dialogue from the game.

83
00:05:06,405 --> 00:05:08,626
And I think it's pretty typical in that there

84
00:05:08,626 --> 00:05:12,448
are some generated elements remaining, but also

85
00:05:12,448 --> 00:05:14,870
a lot of handcrafted elements on top.

86
00:05:16,488 --> 00:05:21,274
Socrates! You just make friends wherever you go, don't you?

87
00:05:21,274 --> 00:05:25,639
Cassandra, what a pleasant surprise! What brings you to Thylos?

88
00:05:28,982 --> 00:05:35,069
Once I heard the great Socrates was on Delos, I raced over to hear his words of wisdom.

89
00:05:35,069 --> 00:05:39,874
Ah, but what are words? Can they be wise, or are they simply words?

90
00:05:39,874 --> 00:05:44,540
Oh, no, you don't. I'm not getting sucked into one of these debates again.

91
00:05:44,540 --> 00:05:48,304
Yet right now, there's a situation I would love your opinion on.

92
00:05:48,304 --> 00:05:48,784
Fine.

93
00:05:49,285 --> 00:05:54,068
Soldiers captured the rebel. He stole from the Sanctuary to help finance a rebellion.

94
00:05:54,068 --> 00:05:57,850
When guards attempted to apprehend the man, he killed one of them.

95
00:05:57,850 --> 00:06:01,513
Murder on Delos? They're probably going to kill him.

96
00:06:01,513 --> 00:06:07,997
Indeed. Though it's illegal to end his life here, so he awaits his fate to be transported to Mykonos.

97
00:06:07,997 --> 00:06:09,357
Where do I come in?

98
00:06:09,357 --> 00:06:13,660
Would you say this rebel deserves death? That killing him brings justice?

99
00:06:19,236 --> 00:06:21,938
OK, so this kind of dialogue system was really new to us.

100
00:06:21,938 --> 00:06:24,419
It was the first game that we did that.

101
00:06:24,419 --> 00:06:28,022
And the biggest changes were not only technical, but also

102
00:06:28,022 --> 00:06:31,804
in a lot of ways in the way the content is produced also.

103
00:06:33,010 --> 00:06:35,831
And the biggest change was probably in the content team

104
00:06:35,831 --> 00:06:37,472
structure.

105
00:06:37,472 --> 00:06:40,073
So instead of having a big team of quest designer and a big

106
00:06:40,073 --> 00:06:43,874
team of writers who would work each on their side, we created

107
00:06:43,874 --> 00:06:46,895
small integrated teams to create the content.

108
00:06:46,895 --> 00:06:49,756
And the narrative part of such a team is composed of a quest

109
00:06:49,756 --> 00:06:53,117
designer, a writer, and a cinematic designer.

110
00:06:53,117 --> 00:06:56,278
And together, they are responsible for designing and

111
00:06:56,278 --> 00:06:59,919
realizing the content for a region in the game or a

112
00:06:59,919 --> 00:07:01,500
specific type of content in the game.

113
00:07:03,178 --> 00:07:05,139
Branching dialogues are a lot more intricate,

114
00:07:05,139 --> 00:07:07,560
so these people need to work together a lot more

115
00:07:07,560 --> 00:07:10,682
than with linear cinematics.

116
00:07:10,682 --> 00:07:14,763
The design of the dialogue was mostly

117
00:07:14,763 --> 00:07:16,584
the responsibility of the writer.

118
00:07:16,584 --> 00:07:19,925
In some companies, this is handled by a narrative designer.

119
00:07:19,925 --> 00:07:23,167
At Ubisoft, this role is not very widespread yet.

120
00:07:23,167 --> 00:07:25,608
It's starting, but we were fortunate enough

121
00:07:25,608 --> 00:07:28,449
to have super dedicated writers who were courageous

122
00:07:28,449 --> 00:07:30,770
and took on this new role, which required them

123
00:07:30,770 --> 00:07:32,310
to be a little bit more technical.

124
00:07:35,161 --> 00:07:38,603
The cinematic designer is also a new role within our teams,

125
00:07:38,603 --> 00:07:40,944
and it's the cinematic designer who is responsible

126
00:07:40,944 --> 00:07:44,466
of delivering the final result on the screen.

127
00:07:44,466 --> 00:07:47,148
It was important to us that a single cinematic designer

128
00:07:47,148 --> 00:07:49,149
can own a scene from start to finish

129
00:07:49,149 --> 00:07:51,590
and deliver all its elements.

130
00:07:51,590 --> 00:07:55,552
He kind of becomes the director for his scene.

131
00:07:55,552 --> 00:07:58,314
So, we chose people with very different backgrounds

132
00:07:58,314 --> 00:07:59,715
to fulfill that role.

133
00:07:59,715 --> 00:08:01,936
So, we have animators, camera artists,

134
00:08:01,936 --> 00:08:03,977
scripters, and even some game designers.

135
00:08:05,553 --> 00:08:08,834
Having the cinematic designer embedded early in that team

136
00:08:08,834 --> 00:08:10,834
is super important because it can help the writer

137
00:08:10,834 --> 00:08:14,515
and the quest designer make smarter decisions

138
00:08:14,515 --> 00:08:18,036
about what is and what's not possible with the system.

139
00:08:18,036 --> 00:08:23,797
And they can also iterate on the cinematic content earlier.

140
00:08:23,797 --> 00:08:26,538
And procedural systems act kind of like a wingman

141
00:08:26,538 --> 00:08:28,418
for the cinematic designer.

142
00:08:28,418 --> 00:08:30,879
It helps them create content more efficiently.

143
00:08:33,214 --> 00:08:37,698
And the reasons to use generation are multiple.

144
00:08:37,698 --> 00:08:42,882
The first one is that it makes the content always playable.

145
00:08:42,882 --> 00:08:46,104
So as soon as a Quest designer integrates a scene,

146
00:08:46,104 --> 00:08:50,467
it is immediately fully working, functional cameras, animations,

147
00:08:50,467 --> 00:08:52,569
without needing any initial involvement

148
00:08:52,569 --> 00:08:54,090
by a cinematic designer.

149
00:08:54,090 --> 00:08:59,094
It also means that the scene is updated as the script changes.

150
00:08:59,094 --> 00:09:00,795
And that does happen a lot.

151
00:09:02,776 --> 00:09:06,779
Because of generation, cinematic designers never need to start from scratch.

152
00:09:06,779 --> 00:09:12,825
So even the first time they open a scene, there's already something there and they can start working from there.

153
00:09:12,825 --> 00:09:18,009
And for simple scenes, they can keep the generated result when it works, and the parts that don't work.

154
00:09:18,009 --> 00:09:22,133
That way they can focus on adding value where it really counts.

155
00:09:25,064 --> 00:09:27,586
Generation is also directly available to the cinematic

156
00:09:27,586 --> 00:09:31,229
designer in the tool, meaning that they can regenerate

157
00:09:31,229 --> 00:09:32,670
some elements of their scene at will.

158
00:09:32,670 --> 00:09:35,672
They can change some presets or parameters

159
00:09:35,672 --> 00:09:37,994
to get a different result.

160
00:09:37,994 --> 00:09:40,716
And it becomes another tool in their cinematic toolbox.

161
00:09:40,716 --> 00:09:44,780
And of course, generation is key to produce

162
00:09:44,780 --> 00:09:47,362
the amount of content required for a game

163
00:09:47,362 --> 00:09:50,284
like Assassin's Creed Odyssey.

164
00:09:50,284 --> 00:09:52,826
Around 20% of our ship content is fully generated.

165
00:09:53,819 --> 00:09:55,961
And a vast majority of scenes in the game

166
00:09:55,961 --> 00:09:58,203
still have procedural elements to some degree.

167
00:09:58,203 --> 00:10:02,087
And this is in addition to all the runtime procedural systems

168
00:10:02,087 --> 00:10:05,150
that are still active at runtime in the game at all times.

169
00:10:08,655 --> 00:10:15,163
I know people like to see screenshots of the tool, so that's the only time you'll see it.

170
00:10:15,163 --> 00:10:19,388
So what you can see here is that I am playing the same scene over and over, but between

171
00:10:19,388 --> 00:10:24,073
every time I play it, I click the magic generate button, and the result is slightly different.

172
00:10:28,619 --> 00:10:30,560
You can also see at the bottom, you're

173
00:10:30,560 --> 00:10:32,822
going to see the content of the tracks being changed.

174
00:10:32,822 --> 00:10:35,944
And that's because the output of generation

175
00:10:35,944 --> 00:10:38,206
is simply clips in the appropriate tracks

176
00:10:38,206 --> 00:10:41,689
in the timeline, just as a user would have done it.

177
00:10:41,689 --> 00:10:44,751
And the goal here is to be able to have

178
00:10:44,751 --> 00:10:47,453
and crafted content coexist, live side

179
00:10:47,453 --> 00:10:48,974
by side with generated content.

180
00:10:48,974 --> 00:10:51,155
So what the cinematic designer can do

181
00:10:51,155 --> 00:10:53,337
is just remove stuff that he doesn't want,

182
00:10:53,337 --> 00:10:56,059
or change stuff that was generated.

183
00:10:56,564 --> 00:10:58,785
And then we know what was generated and what was

184
00:10:58,785 --> 00:10:59,726
encrafted.

185
00:10:59,726 --> 00:11:02,028
And on the next generations, we will take that into account

186
00:11:02,028 --> 00:11:04,949
and not erase any work from the cinematic designer.

187
00:11:04,949 --> 00:11:09,933
So this puts the power in the hands of the cinematic designer.

188
00:11:09,933 --> 00:11:12,694
You can take a step back and just drive the generation,

189
00:11:12,694 --> 00:11:13,795
change some parameters.

190
00:11:13,795 --> 00:11:17,538
Or you can dive in and take the complete control over

191
00:11:17,538 --> 00:11:21,080
a cinematic, a scene, using all the tools you would expect

192
00:11:21,080 --> 00:11:22,221
from a cinematic pipeline.

193
00:11:22,221 --> 00:11:25,603
So clips and tracks and a curve editor and a preview window.

194
00:11:29,783 --> 00:11:32,864
A scenario where we found this pipeline to be really useful

195
00:11:32,864 --> 00:11:35,365
is for the creation of post-launch content.

196
00:11:35,365 --> 00:11:38,986
So for Odyssey, in addition to the traditional bigger DLCs,

197
00:11:38,986 --> 00:11:41,226
there are content teams delivering free content

198
00:11:41,226 --> 00:11:42,886
every two weeks.

199
00:11:42,886 --> 00:11:45,707
So for these teams, the time to player is really short.

200
00:11:45,707 --> 00:11:48,988
They only have a few weeks to design and realize the content.

201
00:11:48,988 --> 00:11:52,469
So this makes for a really good case for using and reusing

202
00:11:52,469 --> 00:11:56,650
modular apps in combination with procedural generation.

203
00:12:00,435 --> 00:12:03,416
So given that we have that goal of shipping as much

204
00:12:03,416 --> 00:12:06,477
generated content as possible, how do we decide whether a

205
00:12:06,477 --> 00:12:09,879
scene can be delivered or shipped only by being

206
00:12:09,879 --> 00:12:12,160
generated, or whether it needs more attention from a

207
00:12:12,160 --> 00:12:13,981
cinematic designer?

208
00:12:13,981 --> 00:12:17,782
And our initial naive approach was to consider that all scenes

209
00:12:17,782 --> 00:12:21,064
would start as fully generated, and then the

210
00:12:21,064 --> 00:12:23,765
content team would identify which scenes needed to be

211
00:12:23,765 --> 00:12:26,746
upgraded and improved along the production

212
00:12:26,746 --> 00:12:27,807
as the need arises.

213
00:12:28,842 --> 00:12:34,024
But this didn't work very well because there are lots of things that the generation just won't handle,

214
00:12:34,024 --> 00:12:41,726
like characters needing to move around the scene, or prop handling, or more complex actions.

215
00:12:41,726 --> 00:12:51,130
So writers didn't write with any limitations, so every scene would end up needing some intervention by a cinematic designer.

216
00:12:51,130 --> 00:12:53,991
And that would have led to a big production cost over production.

217
00:12:56,285 --> 00:12:59,487
Instead, what we ended up doing is establishing target levels

218
00:12:59,487 --> 00:13:03,290
for scenes with clear expectations for each level.

219
00:13:03,290 --> 00:13:06,193
So we had the level one scenes, which were fully generated

220
00:13:06,193 --> 00:13:08,254
and were meant to remain untouched

221
00:13:08,254 --> 00:13:10,056
throughout the production.

222
00:13:10,056 --> 00:13:11,517
We had level two scenes.

223
00:13:11,517 --> 00:13:15,480
They had some handcrafted changes, but no custom assets.

224
00:13:15,480 --> 00:13:17,782
Level three scenes had more changes

225
00:13:17,782 --> 00:13:20,964
and usually some custom assets made for them.

226
00:13:20,964 --> 00:13:23,246
And level four scenes are completely custom.

227
00:13:24,877 --> 00:13:26,978
And by doing so, we could establish a budget

228
00:13:26,978 --> 00:13:28,658
for each type of scene,

229
00:13:28,658 --> 00:13:32,079
and it allowed us to control our scope.

230
00:13:32,079 --> 00:13:34,460
It required writers to really understand

231
00:13:34,460 --> 00:13:38,000
the capabilities and limitations of each level, though.

232
00:13:38,000 --> 00:13:41,161
So they had to write the scenes with those in mind.

233
00:13:41,161 --> 00:13:43,882
If a writer is tasked with writing a level one scene,

234
00:13:43,882 --> 00:13:46,302
because that's what we have the budget for,

235
00:13:46,302 --> 00:13:48,303
you couldn't have the characters do everything

236
00:13:48,303 --> 00:13:50,083
that they could do in a level two or three scene.

237
00:13:53,710 --> 00:14:00,857
This is where we land in the end, so a lot of level 2 content.

238
00:14:00,857 --> 00:14:03,900
So what do we use as input for generation?

239
00:14:03,900 --> 00:14:07,283
Of course, we use the text and the videos of the scene.

240
00:14:07,283 --> 00:14:11,347
But in addition, we also allow writers to set up additional attributes that are very

241
00:14:11,347 --> 00:14:13,329
useful for generation.

242
00:14:13,329 --> 00:14:18,574
They can specify a mood for the speaker with what we call the hashtag emotion.

243
00:14:19,735 --> 00:14:22,236
And they can also set up who the line is directed at.

244
00:14:22,236 --> 00:14:24,597
This is especially useful in scenes

245
00:14:24,597 --> 00:14:28,339
with multiple participants.

246
00:14:28,339 --> 00:14:30,700
Finally, every text in VO is analyzed in order

247
00:14:30,700 --> 00:14:33,861
to figure out the timing of every word

248
00:14:33,861 --> 00:14:37,103
and phonemes of the words and align them to the sound.

249
00:14:37,103 --> 00:14:38,763
That's called phoneme alignment.

250
00:14:38,763 --> 00:14:41,905
And this gives us precious timing information

251
00:14:41,905 --> 00:14:44,026
that many procedural elements will use,

252
00:14:44,026 --> 00:14:45,627
both offline and at runtime.

253
00:14:48,338 --> 00:14:52,279
So this is a completely untouched, fully generated scene.

254
00:14:52,279 --> 00:14:55,179
You come to steal from me too, mis dios?

255
00:14:55,179 --> 00:14:57,440
Is that how you greet all your customers?

256
00:14:57,440 --> 00:14:58,080
I'm sorry.

257
00:14:58,080 --> 00:15:02,421
The soldiers have taken everything from me.

258
00:15:02,421 --> 00:15:04,861
Even my beloved Spiro.

259
00:15:04,861 --> 00:15:07,261
Soldiers take what they want.

260
00:15:07,261 --> 00:15:07,862
Who is Spiro?

261
00:15:07,862 --> 00:15:10,702
Only the best horse I ever owned.

262
00:15:10,702 --> 00:15:13,823
You could always get another horse.

263
00:15:14,313 --> 00:15:16,895
These things cost drachmae, you know.

264
00:15:16,895 --> 00:15:19,777
Drachmae you don't have, by the sound of it.

265
00:15:19,777 --> 00:15:22,679
I need him back to cart my shipments.

266
00:15:22,679 --> 00:15:25,220
Once Dracon finds out I can't get him his oil,

267
00:15:25,220 --> 00:15:27,342
I'm as good as dead.

268
00:15:27,342 --> 00:15:30,064
Dracon? The Viotian champion?

269
00:15:30,064 --> 00:15:32,025
He's my biggest customer.

270
00:15:32,025 --> 00:15:33,626
I'm trying to hunt him down.

271
00:15:33,626 --> 00:15:35,628
Save me from Dracon Thrath.

272
00:15:35,628 --> 00:15:38,950
Find my Spearow, please.

273
00:15:38,950 --> 00:15:42,032
If you need him so badly, I'll find your Spearow.

274
00:15:42,312 --> 00:15:44,993
Be quick, please.

275
00:15:44,993 --> 00:15:48,194
I can only imagine what those thieves are doing to him.

276
00:15:48,194 --> 00:15:51,295
So this is the kind of result that you can expect

277
00:15:51,295 --> 00:15:55,337
for any new scene, any new dialogue.

278
00:15:55,337 --> 00:15:57,097
So from the moment the script is first imported,

279
00:15:57,097 --> 00:16:01,379
of course at first it's gonna be robot voice probably.

280
00:16:01,379 --> 00:16:05,701
So you can see the value in this, if only as placeholder.

281
00:16:05,701 --> 00:16:09,502
Now that we've seen how the users could use the system,

282
00:16:09,502 --> 00:16:12,023
let's see what goes into actually generating a scene.

283
00:16:14,303 --> 00:16:18,285
The first thing we're going to do is place the characters on a stage and get them speaking

284
00:16:18,285 --> 00:16:21,047
one after the other so it's very VO-centric.

285
00:16:21,047 --> 00:16:25,529
The VOs are already assembled to form the backbone of the scene.

286
00:16:25,529 --> 00:16:31,752
And the goal of generation is then also to get you camera editing, body and facial animation,

287
00:16:31,752 --> 00:16:35,754
some lighting to highlight the characters, and some look-at behaviors to really bring

288
00:16:35,754 --> 00:16:36,755
them to life.

289
00:16:36,755 --> 00:16:42,158
And some of these elements are generated as clips, as we saw earlier, and others are computed

290
00:16:42,158 --> 00:16:43,558
at run time as the game is running.

291
00:16:45,906 --> 00:16:48,489
So let's start with the stage.

292
00:16:48,489 --> 00:16:51,693
A stage is a real character and camera setup.

293
00:16:51,693 --> 00:16:55,557
So they define the character placement, and they come with

294
00:16:55,557 --> 00:17:00,063
a camera bank that cover all possible angles.

295
00:17:00,063 --> 00:17:02,726
There are many stages to choose from.

296
00:17:02,726 --> 00:17:04,588
So we have a 1v1v1, a 2v2, and a 1v4 here.

297
00:17:06,119 --> 00:17:08,681
And even for the same number of actors,

298
00:17:08,681 --> 00:17:11,123
we have a few variations, like a two-people stage

299
00:17:11,123 --> 00:17:14,665
could be normal, closer, or side-by-side.

300
00:17:14,665 --> 00:17:18,668
And a three-people stage could be more 1v2 or more 1v1v1.

301
00:17:18,668 --> 00:17:24,993
And for cameras, a camera bank for a typical stage

302
00:17:24,993 --> 00:17:27,395
will have between 12 and 65 different cameras,

303
00:17:27,395 --> 00:17:28,395
depending on the complexity.

304
00:17:28,395 --> 00:17:31,478
And they cover all the different shot types and sizes

305
00:17:31,478 --> 00:17:32,698
that we want for the layout.

306
00:17:35,282 --> 00:17:37,984
So typically we'll have standard cameras, side cameras,

307
00:17:37,984 --> 00:17:40,825
and over-the-shoulder cameras in our stages

308
00:17:40,825 --> 00:17:44,107
with various shot types, shot sizes, sorry,

309
00:17:44,107 --> 00:17:49,209
so from close shots to wide shots.

310
00:17:49,209 --> 00:17:52,211
The interesting part is that all these cameras

311
00:17:52,211 --> 00:17:55,152
are 100% procedural, meaning that they can adapt

312
00:17:55,152 --> 00:17:56,533
to the actors or their actions.

313
00:17:56,533 --> 00:17:59,835
So these are not fixed cameras or keyframe cameras.

314
00:17:59,835 --> 00:18:03,076
They don't have animated positions and orientations.

315
00:18:03,936 --> 00:18:07,478
And you can imagine it as a virtual cameraman that

316
00:18:07,478 --> 00:18:11,841
does its best to keep up with the actors and frame them.

317
00:18:11,841 --> 00:18:14,102
And the idea behind this is to try

318
00:18:14,102 --> 00:18:18,645
to keep the characters at specific screen space

319
00:18:18,645 --> 00:18:20,907
positions and compute at runtime where the camera should be

320
00:18:20,907 --> 00:18:23,768
to achieve a specific composition.

321
00:18:23,768 --> 00:18:26,610
This is done by taking into account a few constraints,

322
00:18:26,610 --> 00:18:28,952
like the distance from the characters that we want

323
00:18:28,952 --> 00:18:29,772
and the angle.

324
00:18:31,011 --> 00:18:34,374
to the scene and then we optimize the rest of the parameters

325
00:18:34,374 --> 00:18:37,077
to get those targets as close as possible

326
00:18:37,077 --> 00:18:39,039
to where we want them on the screen.

327
00:18:39,039 --> 00:18:41,842
This also allows the characters to not always be,

328
00:18:41,842 --> 00:18:45,046
they don't need to remain on their slot on the stage.

329
00:18:45,046 --> 00:18:46,047
They can move around the scene

330
00:18:46,047 --> 00:18:47,188
and the camera will still work.

331
00:18:49,773 --> 00:18:51,474
Another advantage of this approach

332
00:18:51,474 --> 00:18:54,017
is that it's a lot more robust.

333
00:18:54,017 --> 00:18:56,799
So you can have tall characters or small characters.

334
00:18:56,799 --> 00:19:00,242
You could have characters in slopes higher or lower,

335
00:19:00,242 --> 00:19:04,286
and the camera will still remain relatively OK

336
00:19:04,286 --> 00:19:05,747
with a good composition.

337
00:19:05,747 --> 00:19:09,491
So that gives a lot of robustness for the scenes.

338
00:19:09,491 --> 00:19:10,912
The scenes will change.

339
00:19:10,912 --> 00:19:12,834
The characters will change along the production.

340
00:19:12,834 --> 00:19:15,796
The animations will change, and the cameras will remain OK.

341
00:19:18,419 --> 00:19:22,062
We also taught the camera how to move with different reflexes

342
00:19:22,062 --> 00:19:24,443
for both position and orientation.

343
00:19:24,443 --> 00:19:28,366
And we do that by adding some damping dynamics to the camera.

344
00:19:28,366 --> 00:19:31,968
So depending on the shot size, we

345
00:19:31,968 --> 00:19:33,990
will need to be more passive or more aggressive.

346
00:19:33,990 --> 00:19:35,811
And typically on closer shots, we

347
00:19:35,811 --> 00:19:38,052
need to be a little more aggressive to remain

348
00:19:38,052 --> 00:19:39,614
tighter on the characters.

349
00:19:39,614 --> 00:19:44,297
And so it will take into account the animations.

350
00:19:48,423 --> 00:19:50,386
And most importantly, it will follow the actors

351
00:19:50,386 --> 00:19:57,298
when they move.

352
00:19:57,298 --> 00:19:59,902
Again, with different reflexes depending on the shot type.

353
00:20:24,128 --> 00:20:26,829
By default, our camera is modeled after an NL camera.

354
00:20:26,829 --> 00:20:31,130
There's a light NL layer that is also procedural and adjusts

355
00:20:31,130 --> 00:20:32,810
itself to the motion of the camera.

356
00:20:32,810 --> 00:20:36,811
But depending on the scene or the needs of a specific shot,

357
00:20:36,811 --> 00:20:42,412
the camera can be transformed into a more normal Steadicam

358
00:20:42,412 --> 00:20:47,673
or even a more fixed tripod camera.

359
00:20:51,107 --> 00:20:53,309
So now we have a good cameraman, but we also

360
00:20:53,309 --> 00:20:56,591
need a good editor that will generate the montage.

361
00:20:56,591 --> 00:20:58,653
And in a dialogue-driven scene, editing

362
00:20:58,653 --> 00:21:02,816
is just as important as framing, if not more.

363
00:21:02,816 --> 00:21:04,858
So we're going to start by looking at each VO

364
00:21:04,858 --> 00:21:08,621
and figuring out who's speaking and who's listening.

365
00:21:08,621 --> 00:21:10,342
And the first thing we want to do

366
00:21:10,342 --> 00:21:13,064
is to generate a basic shot-reverse-shot editing.

367
00:21:13,064 --> 00:21:15,486
So for each VO, we'll use a camera

368
00:21:15,486 --> 00:21:18,808
showing the speaker from the perspective of the listener.

369
00:21:18,808 --> 00:21:19,389
Sorry for my mic.

370
00:21:22,228 --> 00:21:24,248
So for each speaker listener scenario,

371
00:21:24,248 --> 00:21:25,829
the camera bank has a lot of options

372
00:21:25,829 --> 00:21:27,769
to choose from in terms of shot type and shot size.

373
00:21:27,769 --> 00:21:31,050
And the generator will choose one randomly

374
00:21:31,050 --> 00:21:34,791
according to some rules that we have established.

375
00:21:34,791 --> 00:21:37,271
Some rules will be about changing the probability

376
00:21:37,271 --> 00:21:40,272
of making a certain choice.

377
00:21:40,272 --> 00:21:41,672
Other rules might be about trying

378
00:21:41,672 --> 00:21:43,912
to establish a nice progression within the scene.

379
00:21:43,912 --> 00:21:46,693
So we might want to go from wide shots to closer shots

380
00:21:46,693 --> 00:21:49,574
during the scene, or the inverse,

381
00:21:49,574 --> 00:21:51,274
going from close shots to wider shots.

382
00:21:54,178 --> 00:21:56,520
The amplitude of the gestures will also have an impact

383
00:21:56,520 --> 00:21:59,402
on the final decision.

384
00:21:59,402 --> 00:22:04,605
Typically, we need to be wider when the gestures are big.

385
00:22:04,605 --> 00:22:06,506
For a scene with multiple characters,

386
00:22:06,506 --> 00:22:10,409
we have additional options to consider.

387
00:22:10,409 --> 00:22:13,331
So for example here, this same wide shot

388
00:22:13,331 --> 00:22:16,853
could be chosen when either character is speaking,

389
00:22:16,853 --> 00:22:18,194
in addition to their single shots.

390
00:22:18,194 --> 00:22:21,676
And we can even keep this shot for a longer sequence

391
00:22:21,676 --> 00:22:22,977
when both characters speak in turn.

392
00:22:24,449 --> 00:22:26,710
And finally, we'll also use a shot like this

393
00:22:26,710 --> 00:22:28,890
if one of the characters speak for the first time in a while,

394
00:22:28,890 --> 00:22:34,932
so that the viewer understands its place in the scene.

395
00:22:34,932 --> 00:22:37,813
So we have a functional edit, but there's still a few things

396
00:22:37,813 --> 00:22:39,113
we need to do to improve it.

397
00:22:39,113 --> 00:22:41,954
There are things that we never want that never work.

398
00:22:41,954 --> 00:22:45,295
So for instance, we never want shots that are just too short.

399
00:22:45,295 --> 00:22:47,716
So we will remove them.

400
00:22:47,716 --> 00:22:50,057
And on the other hand, a shot that is too long

401
00:22:50,057 --> 00:22:51,897
can become a bit boring.

402
00:22:51,897 --> 00:22:54,118
So we can add an insert or a reverse shot there.

403
00:22:57,912 --> 00:23:01,615
And the final step is to decide the precise timing

404
00:23:01,615 --> 00:23:03,756
of every cut.

405
00:23:03,756 --> 00:23:06,238
And we could choose to be really conservative here.

406
00:23:06,238 --> 00:23:09,780
We could cut at the end of the VO or in the middle of silences.

407
00:23:09,780 --> 00:23:11,521
This is classic, but a bit boring.

408
00:23:11,521 --> 00:23:13,583
So we tried to do a bit better.

409
00:23:13,583 --> 00:23:16,625
So we can cut before the end of the VO.

410
00:23:16,625 --> 00:23:19,627
And that's like a reaction cut.

411
00:23:19,627 --> 00:23:21,868
So it allows us to see the listener a bit before he

412
00:23:21,868 --> 00:23:22,249
answers.

413
00:23:23,140 --> 00:23:26,803
And at the opposite, we can cut after the next video starts,

414
00:23:26,803 --> 00:23:29,504
and that gives the impression that the cut is triggered

415
00:23:29,504 --> 00:23:32,306
or called for by the sound of the new speaker.

416
00:23:32,306 --> 00:23:38,129
So these two give the most organic feeling.

417
00:23:38,129 --> 00:23:41,832
Okay, now let's see how we generate the animation.

418
00:23:41,832 --> 00:23:43,653
We divide animation in two layers.

419
00:23:43,653 --> 00:23:46,895
We have the idle layer and the gesture layer.

420
00:23:46,895 --> 00:23:48,916
The idle layer gives us the base pose

421
00:23:48,916 --> 00:23:50,016
or stance for our character.

422
00:23:51,079 --> 00:23:52,640
The animations on this layer usually

423
00:23:52,640 --> 00:23:55,661
have some very limited looping movement.

424
00:23:55,661 --> 00:23:56,922
And then we have the gesture layer,

425
00:23:56,922 --> 00:24:00,683
which will be made up of a lot of small modular gesture

426
00:24:00,683 --> 00:24:02,984
animations that are blended together.

427
00:24:02,984 --> 00:24:06,546
These animations are usually additive,

428
00:24:06,546 --> 00:24:09,267
although they can completely override the idle layer

429
00:24:09,267 --> 00:24:11,988
if needed, for instance, for entrance and exit animations.

430
00:24:13,604 --> 00:24:17,165
So for every idle state, we build a collection

431
00:24:17,165 --> 00:24:19,206
of about 50 to 100 gesture animations

432
00:24:19,206 --> 00:24:20,147
that work with that stance.

433
00:24:20,147 --> 00:24:23,088
And the generator will use that library

434
00:24:23,088 --> 00:24:25,549
to create an animation track for the character

435
00:24:25,549 --> 00:24:28,030
by choosing a few idle states throughout the scene

436
00:24:28,030 --> 00:24:29,470
and many gestures to overlay on top.

437
00:24:29,470 --> 00:24:35,652
Choosing the idle state starts from the emotions

438
00:24:35,652 --> 00:24:38,233
that we have from the script.

439
00:24:38,233 --> 00:24:39,734
We try to find a dominant emotion

440
00:24:39,734 --> 00:24:41,194
for a character in a scene.

441
00:24:42,054 --> 00:24:45,297
Every emotion is associated to a list of idle states

442
00:24:45,297 --> 00:24:47,619
that we can choose from.

443
00:24:47,619 --> 00:24:49,061
So if we're looking for a proud character,

444
00:24:49,061 --> 00:24:52,123
we could get to choose from these.

445
00:24:52,123 --> 00:24:55,366
And that list is different for male and female characters.

446
00:24:55,366 --> 00:24:58,569
And you can also override that list per character

447
00:24:58,569 --> 00:25:00,391
so we can give a more controlled personality

448
00:25:00,391 --> 00:25:04,174
to some important recurrent characters.

449
00:25:04,174 --> 00:25:06,276
We have a little more than 100 idle states

450
00:25:06,276 --> 00:25:07,257
in total in the game.

451
00:25:08,525 --> 00:25:10,606
So the generator will choose one of those at random,

452
00:25:10,606 --> 00:25:11,506
let's say this one,

453
00:25:11,506 --> 00:25:15,689
and then we need to generate some gestures.

454
00:25:15,689 --> 00:25:16,830
And in order to do that,

455
00:25:16,830 --> 00:25:19,491
we are gonna look at the words in the view.

456
00:25:19,491 --> 00:25:21,792
Remember that we have the timing of every word.

457
00:25:21,792 --> 00:25:24,654
So the goal is to examine those words

458
00:25:24,654 --> 00:25:27,236
and find potential animations for them.

459
00:25:27,236 --> 00:25:29,737
We'll use the words me and quickly as an example.

460
00:25:31,607 --> 00:25:34,507
And to help us, we define dictionaries of words

461
00:25:34,507 --> 00:25:36,448
related to a specific concept.

462
00:25:36,448 --> 00:25:37,988
For example, we have the me concept

463
00:25:37,988 --> 00:25:40,189
that conveniently has the me word in it,

464
00:25:40,189 --> 00:25:43,290
but also I, myself, personally.

465
00:25:43,290 --> 00:25:47,211
And we have a now concept that contains the words quickly,

466
00:25:47,211 --> 00:25:47,931
but also fast, today.

467
00:25:47,931 --> 00:25:52,973
And when a gesture animation is integrated,

468
00:25:52,973 --> 00:25:56,174
the animator will associate it to one or more

469
00:25:56,174 --> 00:25:56,934
of these concepts.

470
00:25:58,414 --> 00:26:02,398
So if we're looking for an animation for a word in the

471
00:26:02,398 --> 00:26:08,946
me concept, we are going to get to choose from these.

472
00:26:08,946 --> 00:26:09,767
We're almost there.

473
00:26:09,767 --> 00:26:12,871
Now we have a big list of all the words in the VO and some

474
00:26:12,871 --> 00:26:15,634
candidate animations for each one of them.

475
00:26:15,634 --> 00:26:17,616
So now we're going to assign a score to each one.

476
00:26:18,930 --> 00:26:23,213
And there's multiple factors involved in the scoring.

477
00:26:23,213 --> 00:26:25,894
For example, we don't want to stretch animations if we can.

478
00:26:25,894 --> 00:26:29,576
So if an animation that fits a hole that we are trying to put

479
00:26:29,576 --> 00:26:33,618
an animation in will score higher.

480
00:26:33,618 --> 00:26:36,260
And then another example is the pitch of the word will

481
00:26:36,260 --> 00:26:37,760
affect the score.

482
00:26:37,760 --> 00:26:41,002
So a higher pitch will score higher.

483
00:26:41,002 --> 00:26:43,323
And from that big weighted list, we pick a winner at

484
00:26:43,323 --> 00:26:47,706
random, and now we can insert the animation in the track.

485
00:26:48,753 --> 00:26:52,653
And we will repeat this process until the track is full

486
00:26:52,653 --> 00:26:57,394
or until we reach some density that we are aiming for.

487
00:26:57,394 --> 00:26:59,755
Notice how here we are avoiding having

488
00:26:59,755 --> 00:27:03,635
any overlapping animation, which is a safe thing in general.

489
00:27:03,635 --> 00:27:06,176
Because if you're not careful with additive animations,

490
00:27:06,176 --> 00:27:08,196
you can get very broken results.

491
00:27:08,196 --> 00:27:11,477
But if you simply disallow any overlap at all,

492
00:27:11,477 --> 00:27:13,257
you also don't get a very good flow.

493
00:27:13,257 --> 00:27:16,058
And you can feel every gesture always ending completely

494
00:27:16,058 --> 00:27:17,178
before the next one starts.

495
00:27:18,924 --> 00:27:21,045
So our solution to that is to analyze the animations

496
00:27:21,045 --> 00:27:23,746
and extract what we call a motion curve.

497
00:27:23,746 --> 00:27:27,808
It's a simple scalar curve that represents the general motion

498
00:27:27,808 --> 00:27:30,789
of some of the important bones in the animation.

499
00:27:30,789 --> 00:27:33,971
And it is computed by looking at the relative displacement

500
00:27:33,971 --> 00:27:38,913
of the bones relative to their initial position.

501
00:27:40,619 --> 00:27:43,120
So now we have that curve, and if we define some motion

502
00:27:43,120 --> 00:27:45,822
threshold above which it is not allowed to overlap,

503
00:27:45,822 --> 00:27:48,923
we get an effective range for the animation,

504
00:27:48,923 --> 00:27:52,085
which is shorter than its full duration,

505
00:27:52,085 --> 00:27:54,306
and it is in that range that we will not allow the overlap,

506
00:27:54,306 --> 00:27:56,527
but outside of that range, we can overlap and blend.

507
00:27:56,527 --> 00:28:02,450
Another thing that this motion curve gives us

508
00:28:02,450 --> 00:28:04,771
is the extremum of the animation

509
00:28:04,771 --> 00:28:06,251
or the point of maximum motion.

510
00:28:07,211 --> 00:28:09,972
And this is useful because this is the point in the animation

511
00:28:09,972 --> 00:28:14,134
that we want to align to the word for which it was chosen.

512
00:28:14,134 --> 00:28:17,915
It's not always exactly what the animator wants,

513
00:28:17,915 --> 00:28:19,516
so we also allow them to override

514
00:28:19,516 --> 00:28:21,137
that moment per animation if they need.

515
00:28:21,137 --> 00:28:25,919
So, the final result looks more like this,

516
00:28:25,919 --> 00:28:30,061
a series of slightly overlapping but never breaking animations.

517
00:28:30,061 --> 00:28:33,962
And that's how we generate body animations in our scenes.

518
00:28:39,054 --> 00:28:41,135
Facial animation is a lot more dynamic,

519
00:28:41,135 --> 00:28:44,015
and it's built on the fly at runtime.

520
00:28:44,015 --> 00:28:45,476
So here's an example.

521
00:28:45,476 --> 00:28:46,076
All right.

522
00:28:46,076 --> 00:28:49,317
Then do you have the money you owe me?

523
00:28:49,317 --> 00:28:50,637
Do I have the money I owe you?

524
00:28:50,637 --> 00:28:52,897
Of course, of course.

525
00:28:52,897 --> 00:28:55,938
Well, no, not at the moment.

526
00:28:55,938 --> 00:28:56,798
Then get it.

527
00:28:56,798 --> 00:28:58,999
Instantly, my friend, instantly.

528
00:28:58,999 --> 00:29:02,080
But maybe you should do that.

529
00:29:02,080 --> 00:29:03,500
There is a merchant in Sammy.

530
00:29:03,500 --> 00:29:06,681
I'm not very good at these things, as you know.

531
00:29:07,042 --> 00:29:09,103
You want me to collect my own debt.

532
00:29:09,103 --> 00:29:14,404
So there was a lot of work involved

533
00:29:14,404 --> 00:29:17,145
in making sure our characters can show some emotions.

534
00:29:17,145 --> 00:29:18,765
We have around 60 different facial states

535
00:29:18,765 --> 00:29:21,226
associated with the various emotions

536
00:29:21,226 --> 00:29:23,046
coming out of the script.

537
00:29:23,046 --> 00:29:26,647
And each of these states have their own little

538
00:29:26,647 --> 00:29:29,407
internal state machine with their own logic.

539
00:29:29,407 --> 00:29:31,968
And we can use the same word concepts like me and now

540
00:29:31,968 --> 00:29:33,848
that we use to generate the body gestures

541
00:29:33,848 --> 00:29:36,309
and we can use them to trigger some facial responses.

542
00:29:37,897 --> 00:29:40,319
On top of that, we have a few additional layers.

543
00:29:40,319 --> 00:29:42,321
One example is what we call head bobbing,

544
00:29:42,321 --> 00:29:44,203
where we tilt the character's head around

545
00:29:44,203 --> 00:29:45,944
while he's talking.

546
00:29:45,944 --> 00:29:48,126
Another example is talk anticipation,

547
00:29:48,126 --> 00:29:51,289
where we change the face of the character slightly

548
00:29:51,289 --> 00:29:55,313
before he speaks to mimic how a person prepares to speak.

549
00:29:55,313 --> 00:30:00,037
The lip sync animation is built using a blend tree

550
00:30:00,037 --> 00:30:02,479
and the funnel information that we extract from the view.

551
00:30:03,170 --> 00:30:06,932
The challenge here is that the FUNM information that we get is not 100% reliable.

552
00:30:06,932 --> 00:30:13,016
And so there's a good amount of lines where we needed to fix the lip sync more or less

553
00:30:13,016 --> 00:30:13,917
manually.

554
00:30:13,917 --> 00:30:17,980
Also, the FUNM information we had was only available in English.

555
00:30:17,980 --> 00:30:21,242
So for localized languages, we needed to try something a bit different.

556
00:30:21,242 --> 00:30:27,526
And we worked with a group at Ubisoft called LaForge, which is like our internal R&D department,

557
00:30:27,526 --> 00:30:29,227
and we used sound matching.

558
00:30:30,398 --> 00:30:33,121
And this is a technology that uses machine learning to

559
00:30:33,121 --> 00:30:36,363
generate facial animation strictly from the sound.

560
00:30:36,363 --> 00:30:39,045
And there's a lot of promise in getting reliable results

561
00:30:39,045 --> 00:30:40,446
more often.

562
00:30:40,446 --> 00:30:41,987
So here are some results from the game.

563
00:30:53,597 --> 00:30:55,579
My political projects concern you in no way.

564
00:30:55,579 --> 00:31:01,104
Just know that I only seek the recognition of the well-founded of my strategy.

565
00:31:01,104 --> 00:31:05,868
Let yourself not be intimidated by the society here.

566
00:31:05,868 --> 00:31:09,631
Ah, Rikaon. You are a mercenary.

567
00:31:09,631 --> 00:31:11,273
Did you come for treatment?

568
00:31:11,273 --> 00:31:12,934
I told you to stay away from the bad guys.

569
00:31:12,934 --> 00:31:14,836
Ha! Fuck, never!

570
00:31:14,836 --> 00:31:20,941
She asks the faithful about the movement in the ports and then tells me.

571
00:31:20,941 --> 00:31:21,461
That's it.

572
00:31:23,096 --> 00:31:24,797
If you want more information on this,

573
00:31:24,797 --> 00:31:27,499
Daniel Holden is having a presentation tomorrow

574
00:31:27,499 --> 00:31:29,260
called A New Era of Performance Capture

575
00:31:29,260 --> 00:31:30,380
with Machine Learning,

576
00:31:30,380 --> 00:31:32,722
in which he talks about sound matching.

577
00:31:32,722 --> 00:31:38,405
Because the body animation is made up

578
00:31:38,405 --> 00:31:41,687
of a lot of reusable, small pieces of animation,

579
00:31:41,687 --> 00:31:43,649
we have to rely on a look-at system

580
00:31:43,649 --> 00:31:45,630
to really bring the characters to life

581
00:31:45,630 --> 00:31:47,351
and establish a real connection between them.

582
00:31:48,918 --> 00:31:53,321
And in terms of generation, the look at intentions are

583
00:31:53,321 --> 00:31:56,903
drawn only from the text, given two simple rules.

584
00:31:56,903 --> 00:31:58,764
When you're not speaking, you're going to tend to look

585
00:31:58,764 --> 00:32:00,125
at who's speaking.

586
00:32:00,125 --> 00:32:04,167
And if you're speaking, you're going to look at the person

587
00:32:04,167 --> 00:32:06,268
you're speaking to or the last person who spoke.

588
00:32:06,268 --> 00:32:10,091
And those simple rules will work most of the time.

589
00:32:10,091 --> 00:32:12,232
But there are also some exceptions.

590
00:32:12,232 --> 00:32:15,094
And that's why we also allow the writer or cinematic

591
00:32:15,094 --> 00:32:17,775
designer to override who the line is directed at.

592
00:32:21,726 --> 00:32:23,287
To add even more life to characters,

593
00:32:23,287 --> 00:32:25,808
we also generate a secondary layer of look at motions

594
00:32:25,808 --> 00:32:28,129
that we call glances.

595
00:32:28,129 --> 00:32:29,790
So depending on the mood of the character,

596
00:32:29,790 --> 00:32:31,291
we will generate small motions,

597
00:32:31,291 --> 00:32:34,072
shifting the gaze of the character for an instant.

598
00:32:34,072 --> 00:32:38,234
And we have a few rules to choose when to trigger those.

599
00:32:38,234 --> 00:32:41,896
A good occasion is using the micro silences in the view,

600
00:32:41,896 --> 00:32:46,238
mimicking some hesitation or thought by the speaker.

601
00:32:46,238 --> 00:32:48,439
And another one is using the gesture motion

602
00:32:48,439 --> 00:32:49,700
to attract the eyes for a second.

603
00:32:54,198 --> 00:32:57,001
The final element that we'll discuss is the photography,

604
00:32:57,001 --> 00:32:58,843
which is essential to get our final look.

605
00:32:58,843 --> 00:33:01,025
And as is the case with most games,

606
00:33:01,025 --> 00:33:03,848
the lighting from the in-game world is not enough

607
00:33:03,848 --> 00:33:06,231
when the camera gets closer to the characters

608
00:33:06,231 --> 00:33:07,733
in a cinematic context.

609
00:33:08,487 --> 00:33:10,188
Without additional lighting, the characters

610
00:33:10,188 --> 00:33:11,029
would look very flat.

611
00:33:11,029 --> 00:33:15,453
So what we do is we add a procedural light rig with

612
00:33:15,453 --> 00:33:18,316
multiple lights that target all the actors automatically.

613
00:33:18,316 --> 00:33:21,859
And the position and orientation of the lights are

614
00:33:21,859 --> 00:33:24,761
re-computed dynamically for every shot, as

615
00:33:24,761 --> 00:33:25,542
you can see here.

616
00:33:30,556 --> 00:33:33,657
And this rig will use different rules, intensities,

617
00:33:33,657 --> 00:33:35,978
and color temperatures depending on the time of day

618
00:33:35,978 --> 00:33:39,639
and whether the scene is played inside or outside.

619
00:33:39,639 --> 00:33:41,800
The exposure values for the camera

620
00:33:41,800 --> 00:33:44,881
is also constantly adjusted to make sure

621
00:33:44,881 --> 00:33:47,022
that the character faces are always lit properly.

622
00:33:48,312 --> 00:33:50,333
So this system allowed the majority of scenes

623
00:33:50,333 --> 00:33:53,776
to be lit appropriately without needing any intervention

624
00:33:53,776 --> 00:33:55,578
by a lighting artist.

625
00:33:55,578 --> 00:33:57,760
There were a few more problematic scenes

626
00:33:57,760 --> 00:34:00,182
where a lighting artist had to come in and create a custom

627
00:34:00,182 --> 00:34:04,946
light rig for that scene.

628
00:34:04,946 --> 00:34:08,009
OK, so we've seen how we change the way we work.

629
00:34:08,009 --> 00:34:11,512
We've seen how each element of a scene can be generated.

630
00:34:11,512 --> 00:34:14,194
And those two were the biggest challenges that we had.

631
00:34:15,379 --> 00:34:19,640
We introduced new roles, asked writers to be more technical.

632
00:34:19,640 --> 00:34:21,761
We iterated constantly on generation,

633
00:34:21,761 --> 00:34:23,962
trying to see how much we could generate

634
00:34:23,962 --> 00:34:26,122
and how far we could push it.

635
00:34:26,122 --> 00:34:28,323
Now let's look at some additional interesting topics

636
00:34:28,323 --> 00:34:28,983
that we worked on.

637
00:34:28,983 --> 00:34:33,944
So Assassin's Creed has a living open world

638
00:34:33,944 --> 00:34:36,205
with NPCs that move around,

639
00:34:36,205 --> 00:34:39,486
and we always kept in mind to try to allow the scenes

640
00:34:39,486 --> 00:34:41,707
to take place anywhere at any time of day.

641
00:34:43,169 --> 00:34:45,130
Now, of course, there's also plenty of scenes

642
00:34:45,130 --> 00:34:48,012
where we do know where the characters will be waiting

643
00:34:48,012 --> 00:34:50,973
and where the scene will take place exactly.

644
00:34:50,973 --> 00:34:54,335
But for simple scenes, we can afford to give that freedom.

645
00:34:54,335 --> 00:34:56,096
And this is only made possible

646
00:34:56,096 --> 00:34:57,396
because of the procedural systems

647
00:34:57,396 --> 00:34:59,457
like the screen space camera framing

648
00:34:59,457 --> 00:35:04,320
and the lighting rig, for instance.

649
00:35:04,320 --> 00:35:06,661
Another challenge is the crowd around the scene.

650
00:35:06,661 --> 00:35:08,942
You can easily photobomb your scene if you're not careful.

651
00:35:10,506 --> 00:35:13,408
So we have a simple avoidance system that will make them

652
00:35:13,408 --> 00:35:18,712
take the long way around.

653
00:35:18,712 --> 00:35:20,614
OK, the next challenge is localization.

654
00:35:20,614 --> 00:35:23,996
So in a traditional cinematic pipeline, the localization

655
00:35:23,996 --> 00:35:27,599
costs for recording videos is higher because of the strict

656
00:35:27,599 --> 00:35:29,280
timing constraint that must be respected.

657
00:35:30,338 --> 00:35:32,099
across all languages.

658
00:35:32,099 --> 00:35:36,241
So we are using a technique called timeline scaling

659
00:35:36,241 --> 00:35:38,241
to be more flexible in that regards.

660
00:35:38,241 --> 00:35:39,802
This is inspired by a technique I first

661
00:35:39,802 --> 00:35:42,744
saw in Richard Tree's presentation at GDC 16.

662
00:35:42,744 --> 00:35:45,485
And as a reminder, timeline scaling

663
00:35:45,485 --> 00:35:49,567
is about adapting the timeline to slightly different view

664
00:35:49,567 --> 00:35:52,708
lengths for every language by stretching and squashing

665
00:35:52,708 --> 00:35:53,408
its content.

666
00:35:54,389 --> 00:35:56,850
And it was especially useful for our game

667
00:35:56,850 --> 00:35:58,910
because we have two playable characters

668
00:35:58,910 --> 00:36:01,971
that you can choose, Alexios or Cassandra.

669
00:36:01,971 --> 00:36:04,612
And as far as recorded audio is concerned,

670
00:36:04,612 --> 00:36:08,313
those can be considered as different audio languages.

671
00:36:08,313 --> 00:36:10,814
And so we also benefited greatly

672
00:36:10,814 --> 00:36:12,874
from not requiring a precise timing match

673
00:36:12,874 --> 00:36:15,815
when recording both actors, even in English.

674
00:36:17,835 --> 00:36:22,696
Stretching content sounds scary, but it works quite well, actually.

675
00:36:22,696 --> 00:36:29,677
Most VOs do have a similar timing, but some VOs could have up to 10, 20, even 30% difference

676
00:36:29,677 --> 00:36:31,898
in length across variations.

677
00:36:31,898 --> 00:36:47,001
Here's a scene from both player perspectives where the difference is extremely visible.

678
00:36:52,375 --> 00:36:54,936
The eastern coast, can you be more specific?

679
00:36:54,936 --> 00:36:57,218
I think they've settled in an abandoned house

680
00:36:57,218 --> 00:36:59,079
by a small forest south of Sami.

681
00:36:59,079 --> 00:37:01,581
One thing that we always underestimate

682
00:37:01,581 --> 00:37:03,242
is the effort needed to track, test,

683
00:37:03,242 --> 00:37:04,043
and polish all that content.

684
00:37:14,757 --> 00:37:18,159
And procedural generation is both a blessing and a curse

685
00:37:18,159 --> 00:37:19,339
here.

686
00:37:19,339 --> 00:37:21,660
It does give us the ability to create a large amount of

687
00:37:21,660 --> 00:37:23,521
content faster than ever before.

688
00:37:23,521 --> 00:37:25,662
But how do we green light this content?

689
00:37:25,662 --> 00:37:26,923
How do we test it?

690
00:37:26,923 --> 00:37:30,525
And also, how do we ensure that all scenes are up to date

691
00:37:30,525 --> 00:37:31,645
with regards to generation?

692
00:37:32,973 --> 00:37:36,076
And our initial idea was that the cinematic designer

693
00:37:36,076 --> 00:37:37,718
was responsible for delivering a scene.

694
00:37:37,718 --> 00:37:39,860
So he should be the one opening the scene,

695
00:37:39,860 --> 00:37:41,501
pressing the magic generate button,

696
00:37:41,501 --> 00:37:43,423
and reviewing the result.

697
00:37:43,423 --> 00:37:46,086
And that would give us kind of a QA for our scenes.

698
00:37:47,782 --> 00:37:50,443
But that was a disaster because we never knew

699
00:37:50,443 --> 00:37:52,164
if scenes were up to date,

700
00:37:52,164 --> 00:37:55,366
when scenes had been last generated.

701
00:37:55,366 --> 00:37:57,987
Was this scene using the latest iteration

702
00:37:57,987 --> 00:37:58,747
of look at generation?

703
00:37:58,747 --> 00:37:59,368
We didn't know.

704
00:37:59,368 --> 00:38:02,229
We added an animation to the bank.

705
00:38:02,229 --> 00:38:03,990
Why don't we see it anywhere in the game?

706
00:38:03,990 --> 00:38:07,192
Well, the scenes were not regenerated.

707
00:38:07,192 --> 00:38:08,613
So eventually we took the leap of faith

708
00:38:08,613 --> 00:38:13,675
and decided that all scenes would be regenerated every night

709
00:38:13,675 --> 00:38:15,476
which in hindsight was the right thing to do.

710
00:38:16,523 --> 00:38:19,325
Yes, it meant that a problem in generation

711
00:38:19,325 --> 00:38:22,188
could break the game overnight, but also it

712
00:38:22,188 --> 00:38:27,272
meant that an improvement would be made visible in the game

713
00:38:27,272 --> 00:38:27,812
very quickly.

714
00:38:27,812 --> 00:38:30,294
So that was a big win overall.

715
00:38:30,294 --> 00:38:33,617
Still having so much content was a challenge and a big strain

716
00:38:33,617 --> 00:38:34,958
on QA.

717
00:38:34,958 --> 00:38:37,821
Even if we tried to have dashboards and processes,

718
00:38:37,821 --> 00:38:39,902
but there's still a lot of scenes

719
00:38:39,902 --> 00:38:40,903
that need to be validated.

720
00:38:44,937 --> 00:38:50,340
I want to come back to this notion of mixing procedural systems with handcrafted content

721
00:38:50,340 --> 00:38:54,422
because I think it's the source of a very interesting tension or conflict among the

722
00:38:54,422 --> 00:38:54,622
team.

723
00:38:54,622 --> 00:39:01,206
You can imagine that if you tell an artist that a robot will regenerate and possibly

724
00:39:01,206 --> 00:39:06,669
change elements of their scene every night, they might not be super happy about that.

725
00:39:06,669 --> 00:39:09,390
Even if you tell them that this robot is super careful.

726
00:39:10,773 --> 00:39:13,695
And there's a similar tension with the runtime systems

727
00:39:13,695 --> 00:39:14,556
that work in the game.

728
00:39:14,556 --> 00:39:19,300
Those systems are going to get improved across the project.

729
00:39:19,300 --> 00:39:20,941
Look at dynamics are improved.

730
00:39:20,941 --> 00:39:24,544
We add features for facial animation.

731
00:39:24,544 --> 00:39:26,045
And this is for the better, but it

732
00:39:26,045 --> 00:39:28,547
can be a source of frustration for the cinematic designers.

733
00:39:28,547 --> 00:39:31,610
Because when they worked on a scene, they made it work.

734
00:39:31,610 --> 00:39:33,851
It was looking good for them.

735
00:39:33,851 --> 00:39:35,793
And then they come back to it a month later.

736
00:39:35,793 --> 00:39:37,214
And it's not quite as they left it.

737
00:39:39,367 --> 00:39:43,168
Speaking of procedural systems, however smart and magic

738
00:39:43,168 --> 00:39:46,310
we try to make them, cinematic designers do need

739
00:39:46,310 --> 00:39:47,931
some kind of control over them.

740
00:39:47,931 --> 00:39:50,992
But it's a constant challenge to find the right level

741
00:39:50,992 --> 00:39:52,453
of control to offer.

742
00:39:52,453 --> 00:39:55,094
So yes, we need to give control for specific moments

743
00:39:55,094 --> 00:39:57,515
in the game where we need to turn off some systems.

744
00:39:57,515 --> 00:40:02,177
But if the procedural system is constantly being taken over

745
00:40:02,177 --> 00:40:05,299
or controlled, then we lose once more the ability

746
00:40:05,299 --> 00:40:08,480
to improve the content as a whole very quickly.

747
00:40:09,427 --> 00:40:12,369
So in the end, this issue is very important

748
00:40:12,369 --> 00:40:14,571
about discussing with the cinematic designers

749
00:40:14,571 --> 00:40:18,314
about their needs and making sure they understand

750
00:40:18,314 --> 00:40:20,675
all the procedural systems at play.

751
00:40:20,675 --> 00:40:23,157
And sometimes we do need to give them the ability

752
00:40:23,157 --> 00:40:25,819
to override the system, but also sometimes

753
00:40:25,819 --> 00:40:28,121
we can try to show them that their problem

754
00:40:28,121 --> 00:40:31,063
might need to be addressed in the procedural system

755
00:40:31,063 --> 00:40:32,504
rather than in their specific scene.

756
00:40:36,978 --> 00:40:41,080
The last thing I want to mention is the artistic direction

757
00:40:41,080 --> 00:40:45,302
process is obviously very different when using generation.

758
00:40:45,302 --> 00:40:47,663
Pre-production becomes a very important period

759
00:40:47,663 --> 00:40:51,345
to try to get the result that you want out of the machine.

760
00:40:51,345 --> 00:40:54,086
You need to work out the rules at the very broad level.

761
00:40:54,086 --> 00:40:56,428
So it's very different from working on a scene per scene

762
00:40:56,428 --> 00:40:58,068
basis with the script, the actors.

763
00:40:59,802 --> 00:41:02,943
And all the content creators, and especially writers,

764
00:41:02,943 --> 00:41:05,004
need to build a shared understanding of what

765
00:41:05,004 --> 00:41:07,264
the system can and cannot deliver,

766
00:41:07,264 --> 00:41:10,565
because there are limitations.

767
00:41:10,565 --> 00:41:15,667
So what should you take away from this presentation?

768
00:41:15,667 --> 00:41:18,608
We saw that this kind of system requires a different approach

769
00:41:18,608 --> 00:41:19,988
to content creation.

770
00:41:19,988 --> 00:41:22,529
Then hopefully you have some insight

771
00:41:22,529 --> 00:41:25,630
into how we generate the animations, the cameras,

772
00:41:25,630 --> 00:41:25,930
and such.

773
00:41:26,896 --> 00:41:32,378
and the benefits and issues of procedural generation.

774
00:41:32,378 --> 00:41:34,398
But I guess the most important thing to remember

775
00:41:34,398 --> 00:41:35,738
would be to keep asking ourselves

776
00:41:35,738 --> 00:41:39,319
whether we can create our content in smarter ways.

777
00:41:39,319 --> 00:41:41,280
And the most offending thing I still see

778
00:41:41,280 --> 00:41:44,281
is people creating data in a very manual or convoluted way

779
00:41:44,281 --> 00:41:47,342
because systems were created by a team

780
00:41:47,342 --> 00:41:49,402
that basically decided that tools were not worth it,

781
00:41:49,402 --> 00:41:53,143
or even worse, that the tools team would eventually do it.

782
00:41:54,511 --> 00:41:57,492
So first of all, if you create a new system, you are

783
00:41:57,492 --> 00:42:00,552
responsible of how the users will use it and create

784
00:42:00,552 --> 00:42:01,313
content for it.

785
00:42:01,313 --> 00:42:04,453
You know the system, you know the users, so you should be

786
00:42:04,453 --> 00:42:06,934
building the tools as well.

787
00:42:06,934 --> 00:42:07,954
But we can do better.

788
00:42:07,954 --> 00:42:12,035
We can build systems on top of systems to generate data or

789
00:42:12,035 --> 00:42:14,076
avoid having to create content at all.

790
00:42:14,076 --> 00:42:17,937
And we saw this in the past with level design, procedural

791
00:42:17,937 --> 00:42:18,737
level generation.

792
00:42:19,797 --> 00:42:23,399
We saw this with level art and procedural world building.

793
00:42:23,399 --> 00:42:26,581
We generate huge worlds with forests and cities and

794
00:42:26,581 --> 00:42:28,782
mountains, and we couldn't do that with a

795
00:42:28,782 --> 00:42:30,923
bunch of level artists.

796
00:42:30,923 --> 00:42:33,624
It doesn't mean that we don't need those level artists.

797
00:42:33,624 --> 00:42:37,527
They need to figure out the rules and guide the system.

798
00:42:38,630 --> 00:42:41,354
But I believe this can be applied to cinematic content

799
00:42:41,354 --> 00:42:42,736
as well.

800
00:42:42,736 --> 00:42:46,321
We will never replace cinematic artists,

801
00:42:46,321 --> 00:42:49,205
but they can be used more efficiently

802
00:42:49,205 --> 00:42:51,168
by having them work or concentrate

803
00:42:51,168 --> 00:42:52,890
on the important or the hard parts.

804
00:42:56,145 --> 00:42:58,106
Procedural systems will get better.

805
00:42:58,106 --> 00:43:00,948
I think a big next step will be to incorporate machine learning

806
00:43:00,948 --> 00:43:04,071
in some of the aspects of generation.

807
00:43:04,071 --> 00:43:07,073
We started using it for lip sync animation,

808
00:43:07,073 --> 00:43:10,315
but why not for gesture generation?

809
00:43:10,315 --> 00:43:12,517
I think a cool thing to do would be

810
00:43:12,517 --> 00:43:16,440
to be able to choose the best sequence of animations

811
00:43:16,440 --> 00:43:19,322
to get a character from point A to point B in a scene.

812
00:43:19,322 --> 00:43:21,604
That would be tremendously helpful for the content

813
00:43:21,604 --> 00:43:22,104
creators.

814
00:43:24,091 --> 00:43:27,613
Hopefully some of you are already secretly working

815
00:43:27,613 --> 00:43:30,474
on interesting things that have to do

816
00:43:30,474 --> 00:43:31,335
with procedural generation.

817
00:43:31,335 --> 00:43:32,595
That would be awesome.

818
00:43:32,595 --> 00:43:37,558
So anyway, even if the scenes that we generate

819
00:43:37,558 --> 00:43:39,239
were not all masterpieces,

820
00:43:39,239 --> 00:43:42,901
they were still tremendously helpful for the production.

821
00:43:42,901 --> 00:43:45,822
Even in the cases where the cinematic designer

822
00:43:45,822 --> 00:43:47,984
ended up redoing everything manually,

823
00:43:47,984 --> 00:43:49,825
you still had a working scene to start with.

824
00:43:50,901 --> 00:43:54,706
It was useful to quest designers who could get the quest running earlier.

825
00:43:54,706 --> 00:44:00,613
It was useful to writers who could playtest their scenes in the game and get a feel for

826
00:44:00,613 --> 00:44:00,693
it.

827
00:44:00,693 --> 00:44:06,461
It was useful to directors and playtesters who could understand the narrative of a quest

828
00:44:06,461 --> 00:44:07,542
more easily and earlier.

829
00:44:09,818 --> 00:44:11,399
So for us, it was immensely useful,

830
00:44:11,399 --> 00:44:14,081
and it's definitely something that we're going to continue

831
00:44:14,081 --> 00:44:15,783
to push for and improve.

832
00:44:15,783 --> 00:44:17,304
And I hope this will also inspire

833
00:44:17,304 --> 00:44:20,887
you to push for automation and generation

834
00:44:20,887 --> 00:44:21,728
on your own projects.

835
00:44:21,728 --> 00:44:24,050
And thank you.

836
00:44:24,050 --> 00:44:34,719
I'll take questions.

837
00:44:34,719 --> 00:44:37,221
Hello.

838
00:44:37,760 --> 00:44:42,942
You were saying you were using the word recognition to place

839
00:44:42,942 --> 00:44:45,343
the beats of the gestures.

840
00:44:45,343 --> 00:44:46,564
Are you doing that for different

841
00:44:46,564 --> 00:44:48,365
languages as well?

842
00:44:48,365 --> 00:44:53,187
No, we do that only for English because it's used to

843
00:44:53,187 --> 00:44:55,288
we kind of bait the clips in.

844
00:44:55,288 --> 00:44:56,508
So we generate actual clips.

845
00:44:56,508 --> 00:45:00,930
So we don't have a track for every language.

846
00:45:00,930 --> 00:45:03,211
OK, thank you.

847
00:45:03,211 --> 00:45:04,672
Hello.

848
00:45:04,672 --> 00:45:05,052
Hey.

849
00:45:05,640 --> 00:45:08,582
It looked like there was an amount of randomness in there.

850
00:45:08,582 --> 00:45:10,883
Like you had a lot of rules, and then from the best options

851
00:45:10,883 --> 00:45:12,964
you would do a weighted selection.

852
00:45:12,964 --> 00:45:15,225
How did that work with regenerating

853
00:45:15,225 --> 00:45:17,006
the scenes every night?

854
00:45:17,006 --> 00:45:21,848
Would they change even if there were no generation changes or

855
00:45:21,848 --> 00:45:23,349
no content changes?

856
00:45:23,349 --> 00:45:26,050
So the question is about the randomness in the generation

857
00:45:26,050 --> 00:45:29,432
and whether the scenes would change a lot every night.

858
00:45:29,432 --> 00:45:32,253
There is a randomness in the system.

859
00:45:33,275 --> 00:45:36,536
Actually, if you have the same scene and the same inputs,

860
00:45:36,536 --> 00:45:38,157
you get quite consistent results.

861
00:45:38,157 --> 00:45:42,038
Like you're going to get small shifts, but not too much,

862
00:45:42,038 --> 00:45:45,459
because we put in so much rules to take into account

863
00:45:45,459 --> 00:45:50,020
the mood and the words that the end result is not

864
00:45:50,020 --> 00:45:51,400
completely deterministic.

865
00:45:51,400 --> 00:45:53,821
But there's not a lot of changes.

866
00:45:53,821 --> 00:45:56,822
But yes, the scenes would be regenerated every night,

867
00:45:56,822 --> 00:45:58,803
even if there was no content change.

868
00:45:58,803 --> 00:45:59,703
Thank you.

869
00:46:00,944 --> 00:46:03,125
Hello, thank you for a great talk.

870
00:46:03,125 --> 00:46:05,085
I have a question.

871
00:46:05,085 --> 00:46:09,886
You know, sometimes in games, dialogues, they sound a bit

872
00:46:09,886 --> 00:46:13,887
superficial because people, they speak one after another

873
00:46:13,887 --> 00:46:16,307
one, while in real life, sometimes you kind of

874
00:46:16,307 --> 00:46:17,288
interrupt the person.

875
00:46:17,288 --> 00:46:21,009
Do you have some kind of system to generate this kind

876
00:46:21,009 --> 00:46:22,129
of behavior?

877
00:46:22,129 --> 00:46:27,170
No, the generation is pretty safe in that regard.

878
00:46:27,170 --> 00:46:28,750
It will space out the VOs.

879
00:46:29,202 --> 00:46:31,163
according to some rules.

880
00:46:31,163 --> 00:46:33,144
And we wanted to experiment more with that.

881
00:46:33,144 --> 00:46:37,006
We could change the pacing of the scene according to the

882
00:46:37,006 --> 00:46:38,486
mood of the characters.

883
00:46:38,486 --> 00:46:42,268
We ended up not doing that for scope reasons.

884
00:46:42,268 --> 00:46:45,690
But no, we never overlap the views in generation, but the

885
00:46:45,690 --> 00:46:48,071
users can do that manually if they need to.

886
00:46:48,071 --> 00:46:48,671
OK, thank you.

887
00:46:50,890 --> 00:46:54,534
So it's awesome.

888
00:46:54,534 --> 00:46:58,099
So my question is, I guess there is any chance

889
00:46:58,099 --> 00:47:00,582
to add more animation assets?

890
00:47:00,582 --> 00:47:04,967
So once added, so it would be possible to change the.

891
00:47:06,215 --> 00:47:11,918
scene, everything, so because it's procedure generated,

892
00:47:11,918 --> 00:47:15,959
so it's very difficult to guess when are the more animation

893
00:47:15,959 --> 00:47:20,722
in the asset, so is there any way to check the difference,

894
00:47:20,722 --> 00:47:24,303
because it's impossible to check by the tester, everything.

895
00:47:24,303 --> 00:47:26,124
I'm not sure I understood the question.

896
00:47:26,124 --> 00:47:27,765
So, yeah, when...

897
00:47:29,296 --> 00:47:36,478
I guess it's possible to add more animation because it's impossible to prepare all of

898
00:47:36,478 --> 00:47:39,739
the animation for all of the dialogue.

899
00:47:39,739 --> 00:47:46,562
So if you add it, everything is generated by procedure.

900
00:47:46,562 --> 00:47:53,044
So it would be possible to change the animation if there is much more good animation for the

901
00:47:53,044 --> 00:47:54,145
dialogue.

902
00:47:54,145 --> 00:47:56,526
So is there any way to check the update?

903
00:47:58,673 --> 00:48:07,196
So the question is how do we make sure that we have enough animations basically in the system?

904
00:48:07,196 --> 00:48:12,777
So we started by our animators, we knew the list of word concepts that we were going to have

905
00:48:12,777 --> 00:48:17,599
and we made sure when going shooting that we had gestures covering everyone.

906
00:48:19,281 --> 00:48:23,864
And then after the fact, we had reports that would tell us

907
00:48:23,864 --> 00:48:25,766
the usage of animations across the game.

908
00:48:25,766 --> 00:48:28,888
So we knew, like, OK, this concept

909
00:48:28,888 --> 00:48:30,269
happens more frequently.

910
00:48:30,269 --> 00:48:35,252
So maybe we need more variations of animations for

911
00:48:35,252 --> 00:48:35,793
that concept.

912
00:48:35,793 --> 00:48:38,134
But it was on that level that we worked.

913
00:48:38,134 --> 00:48:38,495
Thank you.

914
00:48:39,893 --> 00:48:42,876
Hi, thank you for the great presentation.

915
00:48:42,876 --> 00:48:45,218
I have a question, just a clarification maybe.

916
00:48:45,218 --> 00:48:49,702
I didn't understand how the system work with the body

917
00:48:49,702 --> 00:48:52,244
animation.

918
00:48:52,244 --> 00:48:56,008
So the system analyze the voice over here, and after

919
00:48:56,008 --> 00:48:58,170
apply the animation over it?

920
00:48:58,170 --> 00:48:58,310
Yes.

921
00:49:00,476 --> 00:49:02,917
And...

922
00:49:02,917 --> 00:49:09,960
But you have exact moment, you know, with the motion and the words.

923
00:49:09,960 --> 00:49:13,882
It looks like it's very natural. How did you do this?

924
00:49:13,882 --> 00:49:18,584
With the voiceover and body animation, it looks like, you know, like motion,

925
00:49:18,584 --> 00:49:22,326
full motion capture in terms of body animation and face animation.

926
00:49:22,326 --> 00:49:24,147
I didn't understand this moment.

927
00:49:25,287 --> 00:49:27,933
The question is how we choose animations?

928
00:49:27,933 --> 00:49:31,360
How we apply animation over the voiceover.

929
00:49:32,422 --> 00:49:36,964
Well, we choose many animations and we place them on a track.

930
00:49:36,964 --> 00:49:40,646
We lay them out and we blend them together.

931
00:49:40,646 --> 00:49:44,228
So the system is analyze the voice over, yeah?

932
00:49:44,228 --> 00:49:46,250
And after that, apply the animation.

933
00:49:46,250 --> 00:49:48,831
Yeah, we know the words from the text.

934
00:49:48,831 --> 00:49:52,493
And we know their timings in the view, in the audio.

935
00:49:52,493 --> 00:49:55,955
And that allows us to choose the right animations and

936
00:49:55,955 --> 00:49:57,616
generate those clips.

937
00:49:57,616 --> 00:49:57,996
OK, I see.

938
00:49:57,996 --> 00:49:58,417
Thank you.

939
00:50:00,181 --> 00:50:02,303
My question is about the nightly re-export.

940
00:50:02,303 --> 00:50:05,325
Given that you just said that the exports were not

941
00:50:05,325 --> 00:50:08,287
deterministic, but close to it, were your users ever able

942
00:50:08,287 --> 00:50:10,449
to opt out of the nightly re-export if

943
00:50:10,449 --> 00:50:12,731
to mark a scene as final?

944
00:50:12,731 --> 00:50:16,894
Yes, users could at any point lock part of the content,

945
00:50:16,894 --> 00:50:19,857
lock by track, or lock the whole scene if they need to.

946
00:50:19,857 --> 00:50:20,357
Thank you.

947
00:50:20,357 --> 00:50:22,819
Hey, I was just curious how long it took to get first

948
00:50:22,819 --> 00:50:28,043
iteration of this system working, and how many people

949
00:50:28,043 --> 00:50:29,284
you had working on it.

950
00:50:30,875 --> 00:50:35,896
My team was four programmers, two animators, one camera specialist.

951
00:50:35,896 --> 00:50:44,278
It's hard to say because we didn't have any system at start, so we developed the system

952
00:50:44,278 --> 00:50:50,240
with the tracks and the cameras and also generation simultaneously.

953
00:50:51,105 --> 00:51:02,553
I would say after a year we had good results and then the last 20% took the next two years.

954
00:51:02,553 --> 00:51:02,813
Thanks.

955
00:51:05,470 --> 00:51:12,215
Hi, so my question touches on the gestures when you're selecting animations for the speaker.

956
00:51:12,215 --> 00:51:17,599
How much of that goes into, or if you have put any emphasis on the listener for the much

957
00:51:17,599 --> 00:51:21,582
larger scenes when there's more people as far as words for them to react to?

958
00:51:21,582 --> 00:51:26,005
The question is how do we handle listeners and that's actually a problematic area because

959
00:51:26,005 --> 00:51:28,026
we don't have a lot of information about them.

960
00:51:28,487 --> 00:51:30,650
in terms of generation, like if you only have a script,

961
00:51:30,650 --> 00:51:33,854
you don't really know what the listeners are doing.

962
00:51:33,854 --> 00:51:36,497
You can infer a mood for them from the previous fields.

963
00:51:38,447 --> 00:51:42,431
So actually, we don't generate any gestures for listeners.

964
00:51:42,431 --> 00:51:45,994
And we do have some procedural facial animation, though.

965
00:51:45,994 --> 00:51:51,079
So when we have a reverse shot or an insert where we see the

966
00:51:51,079 --> 00:51:55,123
listener, we tend to focus on the face.

967
00:51:55,123 --> 00:51:56,765
And that's where we can get some results.

968
00:51:56,765 --> 00:51:58,527
But we don't generate any body animation right

969
00:51:58,527 --> 00:51:59,948
now for listeners.

970
00:51:59,948 --> 00:52:01,910
So when we do have them, it's because a cinematic

971
00:52:01,910 --> 00:52:02,951
designer added them.

972
00:52:04,239 --> 00:52:08,784
Have you guys maybe thought about using the speaker's words themselves so the listener

973
00:52:08,784 --> 00:52:09,605
could react to their words?

974
00:52:09,605 --> 00:52:09,985
Yeah.

975
00:52:09,985 --> 00:52:11,647
That's probably how we would do it, yeah.

976
00:52:11,647 --> 00:52:13,189
Thanks.

977
00:52:13,189 --> 00:52:13,369
Thank you.

978
00:52:18,430 --> 00:52:21,233
My question cycles back a bit to the locking question.

979
00:52:21,233 --> 00:52:25,736
How do you make sure that with the regeneration every night,

980
00:52:25,736 --> 00:52:28,799
if let's say an artist has modified a single track

981
00:52:28,799 --> 00:52:32,281
and that whole system can be locked or unlocked,

982
00:52:32,281 --> 00:52:35,724
how do you make sure that the rest is not modified?

983
00:52:35,724 --> 00:52:39,467
And if so, how do you make it modifiable

984
00:52:39,467 --> 00:52:40,868
if he wants it to be modified,

985
00:52:40,868 --> 00:52:43,530
if you modify the single little element?

986
00:52:43,530 --> 00:52:45,752
I don't know if your question is good.

987
00:52:46,440 --> 00:52:52,103
So nightly generation tended to be super safe, so more on the safe side.

988
00:52:52,103 --> 00:52:56,966
So if we were, like the rules were very strict.

989
00:52:58,090 --> 00:53:01,032
I think that for a sequence, for a block in the graph,

990
00:53:01,032 --> 00:53:03,354
if there was any uncrafted change,

991
00:53:03,354 --> 00:53:06,896
we would be on the safe side and not regenerate it.

992
00:53:06,896 --> 00:53:09,879
Personally, I would like to be able to go

993
00:53:09,879 --> 00:53:13,261
in more finer details, because our generation is still

994
00:53:13,261 --> 00:53:14,022
pretty safe.

995
00:53:14,022 --> 00:53:15,863
Like, you could change some animations

996
00:53:15,863 --> 00:53:17,164
in a portion of the track, and then you

997
00:53:17,164 --> 00:53:18,925
could generate the rest, and it would work.

998
00:53:19,226 --> 00:53:22,949
And we take into account the fact that you changed some stuff at the beginning.

999
00:53:22,949 --> 00:53:26,112
Okay, so basically once changed and locked, it's over for the generation.

1000
00:53:26,112 --> 00:53:28,234
Pretty much, right now, yeah.

1001
00:53:28,234 --> 00:53:29,115
Thank you very much.

1002
00:53:29,115 --> 00:53:30,736
Thanks for the talk.

1003
00:53:30,736 --> 00:53:34,119
I was wondering, when you're talking about the,

1004
00:53:34,119 --> 00:53:35,741
you have different stages of like 1v1, 1v2,

1005
00:53:35,741 --> 00:53:40,525
and some of them had between 16 and 65 cameras that were possible.

1006
00:53:40,525 --> 00:53:44,809
Were those possibilities hand-authored camera positions for each stage setup, or...?

1007
00:53:48,112 --> 00:53:53,975
Well, the cameras are procedural, so yes, they are end authored, but it's not as easy

1008
00:53:53,975 --> 00:53:57,617
as positioning the camera and saying it's okay.

1009
00:53:57,617 --> 00:54:01,879
So it's actually a lot of parameters to tweak per camera, set up the angle, the distance,

1010
00:54:01,879 --> 00:54:03,200
and then the camera frames automatically.

1011
00:54:04,662 --> 00:54:07,344
So what you set up is more like an intention for the

1012
00:54:07,344 --> 00:54:10,966
camera, I want this shot type and shot size, basically.

1013
00:54:10,966 --> 00:54:15,890
And then the cinematic designers, they ended up also

1014
00:54:15,890 --> 00:54:18,552
adding a lot of custom cameras to every scene.

1015
00:54:18,552 --> 00:54:21,434
Because the stage cameras are there as a base, but you can

1016
00:54:21,434 --> 00:54:22,494
add more afterwards.

1017
00:54:22,494 --> 00:54:23,055
OK, thank you.

1018
00:54:23,055 --> 00:54:28,599
With things like voice cloning, how do you see this

1019
00:54:28,599 --> 00:54:32,381
sort of system expanding and evolving in the future?

1020
00:54:32,381 --> 00:54:33,502
I missed the first part.

1021
00:54:33,855 --> 00:54:37,678
With things like voice cloning coming down the pipeline,

1022
00:54:37,678 --> 00:54:39,959
basically from text to realistic sounding voice from

1023
00:54:39,959 --> 00:54:42,020
just text, how do you see this sort of system expanding in

1024
00:54:42,020 --> 00:54:42,421
the future?

1025
00:54:42,421 --> 00:54:49,765
I think we're going to need to do more stuff at

1026
00:54:49,765 --> 00:54:51,226
runtime, possibly.

1027
00:54:51,226 --> 00:54:53,628
Like right now, we do a lot of stuff offline.

1028
00:54:53,628 --> 00:54:56,750
And the reason we do that is because we want someone to

1029
00:54:56,750 --> 00:54:57,570
validate the result.

1030
00:54:57,570 --> 00:54:59,772
And at some point, we want to be able to lock it and say,

1031
00:54:59,772 --> 00:55:00,752
OK, this is what we ship.

1032
00:55:02,075 --> 00:55:05,598
But if we construct our scenes more dynamically, or we

1033
00:55:05,598 --> 00:55:08,841
assemble lines dynamically, or we create audio dynamically,

1034
00:55:08,841 --> 00:55:12,605
then we'll need to embrace that and go with the stuff

1035
00:55:12,605 --> 00:55:14,587
that we generate at runtime.

1036
00:55:14,587 --> 00:55:16,288
So that might be a direction to go.

1037
00:55:16,288 --> 00:55:18,430
I would also like to see.

1038
00:55:20,717 --> 00:55:23,600
More tools, like I said, to help the cinematic designer

1039
00:55:23,600 --> 00:55:26,623
achieve specific tasks, like having a character go

1040
00:55:26,623 --> 00:55:28,005
from point A to point B in a scene.

1041
00:55:28,005 --> 00:55:29,786
That's very common, but he has to,

1042
00:55:29,786 --> 00:55:32,209
like this is, since he doesn't necessarily have

1043
00:55:32,209 --> 00:55:34,531
mocap, an exact mocap animation for this,

1044
00:55:34,531 --> 00:55:36,453
he needs to stitch up many animations,

1045
00:55:36,453 --> 00:55:39,296
like starting to turn, walking a bit.

1046
00:55:40,017 --> 00:55:43,058
getting rested in its final position.

1047
00:55:43,058 --> 00:55:45,318
So I think we could just let the promise

1048
00:55:45,318 --> 00:55:48,740
in having a system where you just give your intention

1049
00:55:48,740 --> 00:55:52,001
and then we find the animations for that.

1050
00:55:52,001 --> 00:55:54,461
Thank you.

1051
00:55:54,461 --> 00:55:55,142
Hey.

1052
00:55:55,142 --> 00:55:58,063
Hey, so just one question about your,

1053
00:55:58,063 --> 00:56:01,444
so you had animators or designers going

1054
00:56:01,444 --> 00:56:04,325
and tagging up animations to say,

1055
00:56:04,325 --> 00:56:06,165
oh, it's like happy or sad or whatnot.

1056
00:56:06,165 --> 00:56:06,986
Is that...

1057
00:56:07,853 --> 00:56:12,357
determination of what the intention of the animation is, is that something you foresee

1058
00:56:12,357 --> 00:56:17,802
that could be determined procedurally?

1059
00:56:17,802 --> 00:56:19,263
I don't think we...

1060
00:56:19,263 --> 00:56:26,148
The question is whether the tags on the animations could be decided procedurally.

1061
00:56:26,148 --> 00:56:27,770
I don't really see how...

1062
00:56:27,770 --> 00:56:29,391
Maybe with machine learning and classification.

1063
00:56:29,391 --> 00:56:31,813
I'm not sure it's worth it.

1064
00:56:31,813 --> 00:56:32,033
I'm not sure.

1065
00:56:32,033 --> 00:56:32,474
I'm not sure.

1066
00:56:32,474 --> 00:56:32,934
I don't think so.

1067
00:56:34,455 --> 00:56:41,060
We didn't tag animations with moods, we associate them with idle states.

1068
00:56:41,060 --> 00:56:48,185
Although that would be an interesting idea.

1069
00:56:48,185 --> 00:56:48,705
Yeah, that's it.

1070
00:56:48,705 --> 00:56:54,629
There's no other question.

1071
00:56:54,629 --> 00:56:55,850
So thank you, thanks a lot.

