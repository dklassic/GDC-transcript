1
00:00:03,678 --> 00:00:06,524
Alrighty, looks like it's time so

2
00:00:07,043 --> 00:00:09,045
We're going to jump right in because we have a lot of ground to cover.

3
00:00:09,045 --> 00:00:11,067
But I know there's still some people coming in.

4
00:00:11,067 --> 00:00:13,409
So looks like this session is pretty full.

5
00:00:13,409 --> 00:00:18,413
So if some of you guys could scoot a little bit closer to the center so there's more room for other people, that'd be great.

6
00:00:18,413 --> 00:00:21,376
And without further ado, let's jump right in.

7
00:00:21,376 --> 00:00:23,738
Our subject today is the future of art production.

8
00:00:23,738 --> 00:00:28,022
And I actually want to kick it off with a story that I really like.

9
00:00:28,022 --> 00:00:30,804
Probably my most favorite story that I saw.

10
00:00:31,145 --> 00:00:34,568
shamelessly stole from a speech by David Foster Wallace and it

11
00:00:34,568 --> 00:00:39,173
goes like this. Two younger fish are swimming at the bottom of

12
00:00:39,173 --> 00:00:41,495
the ocean minding their own business as an older fish swims

13
00:00:41,495 --> 00:00:44,698
by and the older fish goes, hey boys, how's the water and then

14
00:00:44,698 --> 00:00:47,761
just keeps on going. And a couple of moments later, one of

15
00:00:47,761 --> 00:00:51,685
the younger fish asks his buddy, hey man, what's water?

16
00:00:52,691 --> 00:00:55,815
And while not that amusing, I think this anecdote

17
00:00:55,815 --> 00:00:58,678
very well describes the condition that all of us

18
00:00:58,678 --> 00:01:01,682
are very prone to, where we get so used

19
00:01:01,682 --> 00:01:04,105
to the circumstance around us that we stop

20
00:01:04,105 --> 00:01:06,207
critically analyzing it day to day.

21
00:01:06,207 --> 00:01:08,069
We stop applying critical thinking,

22
00:01:08,069 --> 00:01:10,032
and especially being a person involved in

23
00:01:10,712 --> 00:01:15,815
Pipeline development and tool production. I find it to be crucial to constantly be asking. What is water?

24
00:01:15,815 --> 00:01:23,639
What are the things that we're not consciously thinking right now that impact us dramatically that need improving that could make things a lot better

25
00:01:23,639 --> 00:01:28,842
And so this is something that we're kind of trying gonna try and do today with our production

26
00:01:28,842 --> 00:01:31,643
We're gonna try and see what are the things we're missing?

27
00:01:31,643 --> 00:01:35,905
What things are we not thinking about and we're gonna do it through the prism of technology

28
00:01:36,785 --> 00:01:38,948
And this talk is obviously about technology, right?

29
00:01:38,948 --> 00:01:42,012
We're going to be talking about the latest trends in all

30
00:01:42,012 --> 00:01:45,176
of the pipeline in our tech and sort of even tech outside

31
00:01:45,176 --> 00:01:46,377
of the games industry.

32
00:01:46,377 --> 00:01:48,300
This is going to be shuffling its way into

33
00:01:48,300 --> 00:01:50,923
art production pipelines.

34
00:01:50,923 --> 00:01:53,987
But at the end of the day, I think the most important part

35
00:01:53,987 --> 00:01:56,070
here is that

36
00:01:56,290 --> 00:02:01,072
Technology will force us to consider art more.

37
00:02:01,072 --> 00:02:03,173
Because if you look at all these pipelines,

38
00:02:03,173 --> 00:02:05,934
they're inherently reductive to the amount of work.

39
00:02:05,934 --> 00:02:07,134
We're gonna be giving things up.

40
00:02:07,134 --> 00:02:11,336
There are gonna be things that we're gonna have to find

41
00:02:11,336 --> 00:02:13,957
minimally contributing, least contributing something

42
00:02:13,957 --> 00:02:15,338
that we'll have to let go off.

43
00:02:15,338 --> 00:02:18,499
And on its own, it's fascinating because technology

44
00:02:18,499 --> 00:02:21,381
is gonna force upon us that conversation about what is art.

45
00:02:22,101 --> 00:02:24,223
Because when you look at it the other way around,

46
00:02:24,223 --> 00:02:26,384
the things that we're not going to be able to let go of,

47
00:02:26,384 --> 00:02:29,226
the things that are going to be so inherently human

48
00:02:29,226 --> 00:02:31,548
and artistic that they're always going to be parts

49
00:02:31,548 --> 00:02:34,490
of pipelines, are going to essentially be art.

50
00:02:34,490 --> 00:02:36,932
And to tell you the truth, this is probably

51
00:02:36,932 --> 00:02:40,654
the scariest talk that I'll ever have to do, because ...

52
00:02:41,435 --> 00:02:43,878
This is no joke, right? It affects all of our livelihoods.

53
00:02:43,878 --> 00:02:48,824
It's, you know, years and decades of skills that we acquired,

54
00:02:48,824 --> 00:02:51,928
and 10 years, 20 years down the line, some of them might be gone.

55
00:02:51,928 --> 00:02:52,589
And, uh...

56
00:02:53,247 --> 00:02:57,529
The biggest reason for doing this talk for me is I feel that everyone has the right to be

57
00:02:57,529 --> 00:03:01,371
informed on that question. Everyone has the right to be part of that conversation

58
00:03:01,371 --> 00:03:06,173
because this is going to be a debate that we're going to be having for the next 10 or 20 years and

59
00:03:06,173 --> 00:03:10,675
that debate is not going to happen here or any other conference. It's going to be each and every one of you

60
00:03:10,675 --> 00:03:15,918
going back to your studio and having conversations about how do you want to work? How do you want to create art?

61
00:03:17,019 --> 00:03:21,984
and basically hopefully giving you some language and some context as to how to do that

62
00:03:21,984 --> 00:03:26,009
will help all of us end up in a situation where we're only improving.

63
00:03:26,009 --> 00:03:30,815
And so, without further ado, let's jump right in, into the actual features.

64
00:03:30,815 --> 00:03:33,598
And these are kind of the four major things we're going to talk about.

65
00:03:34,658 --> 00:03:40,003
They are automating optimization, capturing reality,

66
00:03:40,003 --> 00:03:42,805
parametrization simulation and generation are all lumped

67
00:03:42,805 --> 00:03:45,687
together in one point and we'll talk about why. And then

68
00:03:45,687 --> 00:03:48,630
finally we're going to have deep learning and artificial

69
00:03:48,630 --> 00:03:50,631
intelligence and how that is going to affect.

70
00:03:51,292 --> 00:03:55,393
art production. So let's start with a simple one. Optimization

71
00:03:55,393 --> 00:03:58,334
automation, that is probably a no brainer that we're doing that

72
00:03:58,334 --> 00:04:01,415
already and we're going to keep doing that. But something very

73
00:04:01,415 --> 00:04:04,676
interesting to the subject of what's water. I don't know how

74
00:04:04,676 --> 00:04:08,217
many of you folks got a chance to work during the NES days, but

75
00:04:08,217 --> 00:04:11,118
this is the original color palette from NES. And back in

76
00:04:11,118 --> 00:04:14,038
those times, color was a technical resource.

77
00:04:14,098 --> 00:04:18,521
It was something that you managed because you couldn't afford to display all the colors at the same time.

78
00:04:18,521 --> 00:04:21,582
So artists carefully picked their palettes and made compromises,

79
00:04:21,582 --> 00:04:23,823
and that was a very big optimization point.

80
00:04:23,823 --> 00:04:26,104
But how many of you think about this today?

81
00:04:26,104 --> 00:04:28,726
Probably none of us because it's no longer an issue.

82
00:04:28,726 --> 00:04:32,307
Technology has evolved, it has caught up, so we don't have to worry about that.

83
00:04:32,307 --> 00:04:33,988
But that inherently begs a question.

84
00:04:34,617 --> 00:04:37,138
what other things in our pipelines today

85
00:04:37,138 --> 00:04:38,878
that we don't even think about,

86
00:04:38,878 --> 00:04:40,359
that we spend so much time on,

87
00:04:40,359 --> 00:04:42,179
that are gonna go away.

88
00:04:42,179 --> 00:04:44,439
And there's obviously a lot of examples, right?

89
00:04:44,439 --> 00:04:48,700
Anything from low-poly or high-poly to low-poly workflows

90
00:04:48,700 --> 00:04:50,301
to level of detail meshes,

91
00:04:50,301 --> 00:04:52,581
to separate collision meshes, shadow casters,

92
00:04:52,581 --> 00:04:55,362
IK meshes, gameplay features,

93
00:04:55,362 --> 00:04:57,282
even unwrapping UVs manually,

94
00:04:57,282 --> 00:04:59,023
all of that is basically a compromise

95
00:04:59,023 --> 00:05:00,703
that we have to make for the sake of technology

96
00:05:00,703 --> 00:05:02,164
that is still imperfect,

97
00:05:02,164 --> 00:05:04,204
that is still developing, that is catching up,

98
00:05:04,204 --> 00:05:04,364
but...

99
00:05:04,584 --> 00:05:07,865
But inevitably we're going to reach a point where that doesn't matter anymore.

100
00:05:07,865 --> 00:05:11,405
Where we're going to be able to afford to display anything we want to display.

101
00:05:11,405 --> 00:05:14,726
And then from the other hand, we're tackling that problem on the software side.

102
00:05:14,726 --> 00:05:17,887
Where we're getting better and better at automating those things.

103
00:05:17,887 --> 00:05:21,628
We're automating level of detail meshes and improving UV unwraps.

104
00:05:21,628 --> 00:05:26,149
And so the more that's going to happen, the more chunks of our pipeline are going to sort

105
00:05:26,149 --> 00:05:28,289
of fall off and become obsolete.

106
00:05:28,289 --> 00:05:29,049
Which is great.

107
00:05:29,049 --> 00:05:31,590
And this point is easy, right?

108
00:05:31,910 --> 00:05:35,154
we can actually very easily and safely say

109
00:05:35,154 --> 00:05:38,179
that these processes do not have any artistic value.

110
00:05:38,179 --> 00:05:43,005
So they're gonna go because we want to allow ourselves

111
00:05:43,005 --> 00:05:44,948
more time to focus on the things that are important,

112
00:05:44,948 --> 00:05:46,830
but that once again inherently begs the question,

113
00:05:46,830 --> 00:05:47,632
what is important?

114
00:05:48,192 --> 00:05:55,295
And so now we're going to jump into something that is a little bit more controversial, or probably more controversial.

115
00:05:55,295 --> 00:05:57,096
And this is Capture in Reality.

116
00:05:57,096 --> 00:06:03,478
And I actually wanted to start with this slide, which seems very far removed from the subject.

117
00:06:03,478 --> 00:06:10,881
But actually, I mean, obviously Prince of Persia, a lot of us, probably as kids or maybe not, played the crap out of it, got inspired, wanted to make some games.

118
00:06:10,881 --> 00:06:15,003
And, you know, the fluidity of the animation there made the prince so lifelike that you couldn't...

119
00:06:15,983 --> 00:06:17,584
couldn't help but be blown away.

120
00:06:17,584 --> 00:06:18,785
But every time I look at this now,

121
00:06:18,785 --> 00:06:21,446
I can't help to think back to Jordan Mechner's talk

122
00:06:21,446 --> 00:06:24,348
in 2011 at GDC, where he was talking about

123
00:06:24,348 --> 00:06:25,848
how he produced Prince of Persia.

124
00:06:25,848 --> 00:06:30,131
And the way this worked back then in 1986

125
00:06:30,131 --> 00:06:31,351
is he and his brother went outside

126
00:06:31,351 --> 00:06:33,312
and he shot his brother running around in a parking lot

127
00:06:33,312 --> 00:06:35,053
and then he actually rotoscoped it

128
00:06:35,053 --> 00:06:38,935
and basically pixel by pixel painted it in into the game.

129
00:06:38,935 --> 00:06:41,317
So when we're talking about all of these new and coming

130
00:06:41,317 --> 00:06:44,398
scanning techniques and sort of capture reality

131
00:06:44,398 --> 00:06:45,119
and animation.

132
00:06:45,759 --> 00:06:46,760
it's not a new concept.

133
00:06:46,760 --> 00:06:48,781
We can't treat them like they just appeared

134
00:06:48,781 --> 00:06:50,162
and they're gonna sort of circumvent

135
00:06:50,162 --> 00:06:51,323
what the art process was

136
00:06:51,323 --> 00:06:53,744
because they were there all along.

137
00:06:53,744 --> 00:06:55,486
And we were doing them 30 years ago

138
00:06:55,486 --> 00:06:56,786
and we're gonna keep doing them

139
00:06:56,786 --> 00:06:58,147
because at the end of the day,

140
00:06:58,147 --> 00:06:59,969
Jordan's goal was to make a game

141
00:06:59,969 --> 00:07:01,990
and that got him where he needed to go

142
00:07:01,990 --> 00:07:03,751
with the resources he had

143
00:07:03,751 --> 00:07:05,272
and allowing him the opportunity

144
00:07:05,272 --> 00:07:07,694
to retain that artistic vision.

145
00:07:08,594 --> 00:07:09,795
we're only going to keep going with that.

146
00:07:09,795 --> 00:07:12,878
And same thing for facial scanning.

147
00:07:12,878 --> 00:07:15,220
First time playing Max Payne, I remember being so blown away

148
00:07:15,220 --> 00:07:16,401
by the quality of his face.

149
00:07:16,401 --> 00:07:18,503
I was like, this cannot absolutely get better.

150
00:07:18,503 --> 00:07:19,684
This is photoreal.

151
00:07:19,684 --> 00:07:22,287
Because it was a photo on a box, basically.

152
00:07:22,287 --> 00:07:25,390
But this only keeps on going.

153
00:07:25,390 --> 00:07:27,372
And there's no sign of stopping.

154
00:07:27,372 --> 00:07:29,153
And there's more and more of that coming around.

155
00:07:29,153 --> 00:07:30,755
Obviously, we're doing that for environments.

156
00:07:30,755 --> 00:07:33,878
And we, I mean, predominantly dice at this point.

157
00:07:34,278 --> 00:07:37,361
Hopefully you guys caught their talk last year I think it was.

158
00:07:37,361 --> 00:07:41,364
And it definitely proves that it's already doable.

159
00:07:41,364 --> 00:07:45,488
And technically, there's hardly anything in the world

160
00:07:45,488 --> 00:07:47,289
that we can't scan today.

161
00:07:47,289 --> 00:07:49,211
We're solving these problems one by one

162
00:07:49,211 --> 00:07:51,833
where we can do characters, we can do organic environments.

163
00:07:51,833 --> 00:07:54,796
There's obviously concern about, oh, hard surface,

164
00:07:54,796 --> 00:07:57,978
very noodly kind of man-made objects.

165
00:07:58,299 --> 00:08:02,265
we still can do those. This exists today. And with enough

166
00:08:02,265 --> 00:08:05,650
pictures that you take of an object you can get the levels of

167
00:08:05,650 --> 00:08:08,273
reality and sort of sophistication and detail and

168
00:08:08,273 --> 00:08:11,679
history and wear and tear that would take you a stupidly long

169
00:08:11,679 --> 00:08:13,301
time to do by hand. And so

170
00:08:14,383 --> 00:08:17,984
We are solving most of the problems that exist, and a lot of them are solved.

171
00:08:17,984 --> 00:08:21,285
The other one being reflective surfaces, which is obviously a big concern.

172
00:08:21,285 --> 00:08:24,166
It's something that we have a hard time scanning, but you can already do that.

173
00:08:24,166 --> 00:08:27,247
Either you're using a cross-polarized darkroom setup,

174
00:08:27,247 --> 00:08:31,168
or you're using a matte spray that's already starting to appear on the market,

175
00:08:31,168 --> 00:08:34,929
actual sprays for photogrammetry that you can just use as coating for an object,

176
00:08:34,929 --> 00:08:37,210
and then apply that.

177
00:08:37,210 --> 00:08:39,471
So most of these problems are already solved,

178
00:08:39,471 --> 00:08:40,671
and they're only going to keep...

179
00:08:40,991 --> 00:08:42,652
being incorporated more and more, right?

180
00:08:42,652 --> 00:08:45,014
You can scan entire environments that are going to be

181
00:08:45,014 --> 00:08:48,117
100% photoreal and your only limitation is memory.

182
00:08:48,117 --> 00:08:50,219
And as we all know, that is only going to grow.

183
00:08:50,219 --> 00:08:54,882
So at some point, once again, we'll be able to leverage that

184
00:08:54,882 --> 00:08:56,243
much more extensively than we do today.

185
00:08:56,243 --> 00:08:58,165
But obviously there's still a lot of questions, right?

186
00:08:58,165 --> 00:09:00,527
Photogrammetry is clunky to implement into a regular

187
00:09:00,527 --> 00:09:03,729
development pipeline when you're augmenting man-made art

188
00:09:03,729 --> 00:09:04,390
with photogrammetry.

189
00:09:04,830 --> 00:09:08,052
And then also just flying places and getting your entire team

190
00:09:08,052 --> 00:09:10,953
and having them go somewhere is an expensive process

191
00:09:10,953 --> 00:09:12,633
and not everyone can afford it.

192
00:09:12,633 --> 00:09:14,854
And we've made games just using Google,

193
00:09:14,854 --> 00:09:18,015
so I'm sure a lot of people are used and accustomed to that.

194
00:09:18,015 --> 00:09:20,296
And I think by the time photogrammetry reaches

195
00:09:20,296 --> 00:09:22,437
mass penetration, we're going to over-compensate.

196
00:09:22,857 --> 00:09:24,818
overcome most of these issues, but I think fundamentally

197
00:09:24,818 --> 00:09:28,599
what's happening is we got used to producing everything

198
00:09:28,599 --> 00:09:31,639
from scratch because there wasn't anything in the world

199
00:09:31,639 --> 00:09:33,780
at that level of abstraction where we could scan it

200
00:09:33,780 --> 00:09:34,500
and put it into a game.

201
00:09:34,500 --> 00:09:37,761
Because the word did not afford us low poly models

202
00:09:37,761 --> 00:09:40,681
that could be transported into the game, but eventually,

203
00:09:40,681 --> 00:09:42,322
and this might not even be games, right?

204
00:09:42,322 --> 00:09:44,322
That might be Google Earth coming in

205
00:09:44,322 --> 00:09:46,763
and just scanning the crap out of everything,

206
00:09:46,763 --> 00:09:49,483
and then we're gonna have accessible environments

207
00:09:49,483 --> 00:09:52,084
from across the world at a resolution that is.

208
00:09:53,084 --> 00:09:56,065
at a highest level of fidelity that we can just borrow

209
00:09:56,065 --> 00:09:57,826
and then eventually we'll basically transition

210
00:09:57,826 --> 00:09:59,407
into the same thing that film is doing

211
00:09:59,407 --> 00:10:01,527
where you treat your environments as sets

212
00:10:01,527 --> 00:10:04,248
and you light them and you dress them and you modify them

213
00:10:04,248 --> 00:10:05,889
but you can still communicate art, right?

214
00:10:05,889 --> 00:10:07,249
The art is not going anywhere.

215
00:10:07,249 --> 00:10:08,330
If you look at Blade Runner,

216
00:10:08,330 --> 00:10:12,171
one of the most iconic and stylized films ever,

217
00:10:12,171 --> 00:10:14,912
it heavily leaned on the real life Los Angeles

218
00:10:14,912 --> 00:10:16,293
and the Bradbury building is still around

219
00:10:16,293 --> 00:10:18,614
and it's there, downtown LA, you can go there.

220
00:10:19,895 --> 00:10:22,558
going to be a major part of our pipelines and most importantly

221
00:10:22,558 --> 00:10:25,322
it's going to be very cheap and that's why it's going to find

222
00:10:25,322 --> 00:10:27,765
traction because it's going to be a lot cheaper to just take an

223
00:10:27,765 --> 00:10:31,591
existing scan of an entire environment and use it rather

224
00:10:31,591 --> 00:10:32,892
than produce everything from scratch.

225
00:10:34,737 --> 00:10:38,379
I'm actually going to skip this one.

226
00:10:38,379 --> 00:10:39,880
But you can download it online later.

227
00:10:39,880 --> 00:10:41,681
It's just more scam stuff.

228
00:10:41,681 --> 00:10:45,143
But now I want to talk about parametrization, simulation,

229
00:10:45,143 --> 00:10:45,783
and generation.

230
00:10:45,783 --> 00:10:48,705
And I wanted to start with this.

231
00:10:48,705 --> 00:10:52,507
And this is an example of a visualized L-system, which was

232
00:10:52,507 --> 00:10:55,349
developed by a biologist and a botanist by the name of

233
00:10:55,349 --> 00:10:59,571
Lindenmeier, where he basically described a plant cell growth

234
00:10:59,571 --> 00:11:02,993
using something very close to an algorithm that basically

235
00:11:02,993 --> 00:11:03,193
used.

236
00:11:04,174 --> 00:11:08,079
types of an element of a plant as a letter

237
00:11:08,079 --> 00:11:09,641
that he would organize into words

238
00:11:09,641 --> 00:11:11,824
that would describe the growth of a plant.

239
00:11:11,824 --> 00:11:15,489
And so this particular system is inherently organic.

240
00:11:15,489 --> 00:11:17,051
It comes from botany,

241
00:11:17,051 --> 00:11:19,695
but it lends itself very well to programming.

242
00:11:20,015 --> 00:11:21,936
to basically being computer simulated.

243
00:11:21,936 --> 00:11:24,297
And there are a lot of things like that in the world

244
00:11:24,297 --> 00:11:27,899
that we can definitely use and sort of apply

245
00:11:27,899 --> 00:11:29,460
in our current day technology.

246
00:11:29,460 --> 00:11:31,901
And similarly, right, Epic for their kite demo

247
00:11:31,901 --> 00:11:33,862
had like a simulation of growing a forest,

248
00:11:33,862 --> 00:11:35,663
and that was two years ago on Unreal Engine.

249
00:11:35,663 --> 00:11:37,804
This is basically old news,

250
00:11:37,804 --> 00:11:40,866
but you can simulate natural processes to get.

251
00:11:41,426 --> 00:11:44,067
art or to get the content that you need.

252
00:11:44,067 --> 00:11:46,687
And later today we're obviously going to have the privilege

253
00:11:46,687 --> 00:11:50,108
of checking out a talk about Horizon that leaned heavily

254
00:11:50,108 --> 00:11:53,009
on a lot of these procedural population technique.

255
00:11:53,009 --> 00:11:55,210
And Guerrilla being the great example of a studio

256
00:11:55,210 --> 00:11:58,530
that embraced that approach and sort of how that approach

257
00:11:58,530 --> 00:12:00,331
is going to shape our future moving forward.

258
00:12:00,811 --> 00:12:02,532
Same thing with our tools, right?

259
00:12:02,532 --> 00:12:08,334
If you look at Speedtree, we're moving away from working with individual vertices or polygons.

260
00:12:08,334 --> 00:12:10,075
We're actually working with trees now.

261
00:12:10,075 --> 00:12:13,756
We want to treat virtual objects as if they were real objects.

262
00:12:13,756 --> 00:12:18,718
We want to control the height and the density rather than the polygons and the faces.

263
00:12:18,718 --> 00:12:22,220
And the same thing with Substance Painter, because you no longer work with...

264
00:12:22,420 --> 00:12:30,111
pixels per se and textures you're applying materials your brushstrokes are abstracted to a particle simulation that will actually populate an entire sort of

265
00:12:30,111 --> 00:12:35,759
System of patterns that you want on an object and this is only going to continue

266
00:12:37,822 --> 00:12:40,704
Same thing with the sort of physicality and simulation

267
00:12:40,704 --> 00:12:42,825
because once again, we're treating objects

268
00:12:42,825 --> 00:12:44,125
as if they are virtual.

269
00:12:44,125 --> 00:12:45,726
But further down the line,

270
00:12:45,726 --> 00:12:47,787
anything in our production pipeline,

271
00:12:47,787 --> 00:12:49,508
we're gonna wanna treat as if it's something

272
00:12:49,508 --> 00:12:50,128
in the real world.

273
00:12:50,128 --> 00:12:51,889
If you're populating objects, they have physics.

274
00:12:51,889 --> 00:12:55,010
They interact with each other, they lean on each other,

275
00:12:55,010 --> 00:12:57,411
and that will allow us, first of all,

276
00:12:57,411 --> 00:12:58,612
to create more believable worlds,

277
00:12:58,612 --> 00:13:00,693
but also save some time doing it, right?

278
00:13:00,693 --> 00:13:03,054
Because you don't wanna sculpt every single fold

279
00:13:03,054 --> 00:13:04,315
on a curtain when you can actually

280
00:13:04,315 --> 00:13:06,256
just have a physics simulation of it.

281
00:13:06,256 --> 00:13:06,376
So.

282
00:13:08,317 --> 00:13:11,038
Another example of that is obviously characters.

283
00:13:11,038 --> 00:13:14,680
And there's nothing today that is inconceivable

284
00:13:14,680 --> 00:13:16,982
about a system where we go in and we scan

285
00:13:16,982 --> 00:13:19,924
a whole lot of people and we use their facial features

286
00:13:19,924 --> 00:13:23,426
as sort of the extremes for different representation

287
00:13:23,426 --> 00:13:26,067
of facial features and then we automate that

288
00:13:26,067 --> 00:13:27,728
and blend between that.

289
00:13:27,848 --> 00:13:33,131
wouldn't be surprised if ten years from now most of say indie studios that cannot afford the

290
00:13:33,131 --> 00:13:36,613
talent is going to be that much more expensive at that point to generate characters are going to

291
00:13:36,613 --> 00:13:42,357
be using an automated system like that that might be augmented with some deep learning or AI

292
00:13:42,357 --> 00:13:48,020
technology. But at the end of the day we're very close to it today. This is from black desert I

293
00:13:48,020 --> 00:13:53,203
think and it's a couple of years old probably video. And we can do nice believable characters

294
00:13:53,203 --> 00:13:56,385
in a modularized procedural way.

295
00:13:57,565 --> 00:14:01,528
I think the bigger take away, and this is why they're all lumped together, is we're seeing this

296
00:14:01,528 --> 00:14:06,431
abstraction of interfaces. And abstraction is a programming term that basically means

297
00:14:06,431 --> 00:14:10,773
creating a higher level input into a lower level system. So say you have ones and zeros that your

298
00:14:10,773 --> 00:14:15,056
processor operates on, but you have programming language commands that you actually issue to

299
00:14:15,056 --> 00:14:19,078
execute something. And so this is an abstraction layer. And we're going to keep building those up

300
00:14:19,078 --> 00:14:22,580
to a point where the knowledge of computers is not necessarily...

301
00:14:23,521 --> 00:14:25,682
necessary because you can interact with virtual objects

302
00:14:25,682 --> 00:14:28,402
as you would interact with the real world objects.

303
00:14:28,402 --> 00:14:29,863
And so that attraction is gonna keep going.

304
00:14:29,863 --> 00:14:32,164
It's not only inherent to art.

305
00:14:32,164 --> 00:14:33,484
If you look at programming, right,

306
00:14:33,484 --> 00:14:35,865
Unreal Blueprint allowed people to make entire games

307
00:14:35,865 --> 00:14:37,905
without having a programmer on the team,

308
00:14:37,905 --> 00:14:40,286
meaning we're building up that functionality

309
00:14:40,286 --> 00:14:42,367
to go higher and higher level,

310
00:14:42,367 --> 00:14:45,407
trying to get people to express their intent

311
00:14:45,407 --> 00:14:47,768
to do what they wanna do faster

312
00:14:47,768 --> 00:14:50,669
without less sort of layers of execution.

313
00:14:51,699 --> 00:14:57,522
And the final point for this particular section is obviously

314
00:14:57,522 --> 00:15:00,984
AI stuff. And we're actually going to start a little bit

315
00:15:00,984 --> 00:15:03,225
outside in consumer tech. This is a promotional picture from

316
00:15:03,225 --> 00:15:06,706
Google's new communicator, Allo. And the way it works is it

317
00:15:06,706 --> 00:15:09,788
actually has a neural net on board that is going to track

318
00:15:09,788 --> 00:15:12,529
your answers and it's going to remember how you reply to

319
00:15:12,529 --> 00:15:15,351
questions and it's going to analyze the questions posed to

320
00:15:15,351 --> 00:15:18,172
you and it's going to intelligently propose answers.

321
00:15:18,552 --> 00:15:19,613
And this is not unheard of, right?

322
00:15:19,613 --> 00:15:21,674
Chatbots, for most of the companies that you interact

323
00:15:21,674 --> 00:15:24,995
online, they rely on these deep neural networks that are

324
00:15:24,995 --> 00:15:26,776
taught to communicate with humans.

325
00:15:26,776 --> 00:15:29,798
And we're only going to see more of that, where neural net

326
00:15:29,798 --> 00:15:33,299
is going to analyze, say, your entire game that you made

327
00:15:33,299 --> 00:15:34,780
previously and all the art choices you make.

328
00:15:34,780 --> 00:15:37,221
And it's going to offer you solutions that you can then

329
00:15:37,221 --> 00:15:40,142
pick or modify or interact with.

330
00:15:40,142 --> 00:15:42,083
But once again, this is a

331
00:15:43,039 --> 00:15:48,265
not as far off. So Google did a thing with their deep learning

332
00:15:48,265 --> 00:15:51,348
neural nets that they used for image recognition and they

333
00:15:51,348 --> 00:15:54,031
basically flipped it around. When you search for an image in

334
00:15:54,031 --> 00:15:57,755
Google, it would actually scan an image and spit out words that

335
00:15:57,755 --> 00:15:59,477
you would then match with your search pattern.

336
00:16:00,198 --> 00:16:07,285
But when they flipped that system around and they put words into it, it was actually able to output images that look like this.

337
00:16:07,285 --> 00:16:13,612
Which inherently proves that a system that is capable of that kind of analysis is also capable of some form of creativity.

338
00:16:13,612 --> 00:16:17,776
Albeit driven by the information that is fed to it by humans.

339
00:16:18,817 --> 00:16:21,800
But all of this is not as far off as it seems.

340
00:16:21,800 --> 00:16:25,663
So there was a deep learning panel at SIGGRAPH this year

341
00:16:25,663 --> 00:16:28,806
and folks from NVIDIA were talking about how Remedy used

342
00:16:28,806 --> 00:16:32,049
a neural net based animation solver where they just

343
00:16:32,049 --> 00:16:35,612
basically taught a neural net to convert a raw video of

344
00:16:35,612 --> 00:16:37,934
actors talking into almost game ready animation.

345
00:16:38,354 --> 00:16:44,083
And in general, deep learning becomes a bigger and bigger part of animation solvers today.

346
00:16:44,083 --> 00:16:49,612
So it might sound like an episode of Black Mirror, but it's actually closer than we all think.

347
00:16:49,612 --> 00:16:52,917
And I wouldn't be surprised if 20 years from now everyone has...

348
00:16:53,377 --> 00:16:56,558
a deep learning net sort of as a partner

349
00:16:56,558 --> 00:16:58,279
that actually learns how we do things

350
00:16:58,279 --> 00:17:00,080
and then allows us to, once again,

351
00:17:00,080 --> 00:17:03,221
deliver on what we want to do by offering us suggestions

352
00:17:03,221 --> 00:17:05,201
as of what it thinks we're going to do,

353
00:17:05,201 --> 00:17:07,562
rather than for us having to do the whole thing by hand.

354
00:17:07,562 --> 00:17:08,983
And once again, this very well feeds

355
00:17:08,983 --> 00:17:11,124
into this abstraction layer theory, right?

356
00:17:11,124 --> 00:17:12,684
Because essentially when, say,

357
00:17:12,684 --> 00:17:14,825
Google LO sends a message for you,

358
00:17:14,825 --> 00:17:16,686
you're still communicating what you want to say.

359
00:17:16,686 --> 00:17:18,106
It's just that you don't have to type

360
00:17:18,106 --> 00:17:19,527
every individual letter.

361
00:17:19,527 --> 00:17:21,247
So we're going to that higher level

362
00:17:21,247 --> 00:17:22,748
of communicating intent without the.

363
00:17:23,168 --> 00:17:25,910
manual labor of typing in letters.

364
00:17:25,910 --> 00:17:29,112
And same panel as Seagraph, Frostbite Labs,

365
00:17:29,112 --> 00:17:31,553
we're talking about how they're looking into neural nets

366
00:17:31,553 --> 00:17:33,274
for the stuff that they're doing.

367
00:17:33,274 --> 00:17:37,397
And also at Steam Dev Days last year during the keynote,

368
00:17:37,397 --> 00:17:39,238
Team Sweeney was talking about games industry

369
00:17:39,238 --> 00:17:41,179
being way behind on deep learning

370
00:17:41,179 --> 00:17:42,560
compared to a lot of other industries.

371
00:17:42,560 --> 00:17:44,501
So that kind of leads you to believe

372
00:17:44,501 --> 00:17:45,982
that there must be someone at Epic

373
00:17:45,982 --> 00:17:48,443
looking into this right now.

374
00:17:48,443 --> 00:17:50,225
Now here's the million dollar question.

375
00:17:50,945 --> 00:17:55,429
So what is left when we scan the crap out of the entire world,

376
00:17:55,429 --> 00:17:57,731
when we have neural nets helping us populate it

377
00:17:57,731 --> 00:17:59,853
and everything's generated and scanned?

378
00:17:59,853 --> 00:18:01,475
Where do people come in?

379
00:18:01,475 --> 00:18:03,456
What's left of the artistic process?

380
00:18:03,456 --> 00:18:05,818
And that is the most scary question.

381
00:18:05,818 --> 00:18:07,200
And we're going to try and unpack that.

382
00:18:07,540 --> 00:18:12,023
this as best as we can. But basically what's happening right now is we have a creative problem,

383
00:18:12,023 --> 00:18:16,305
we come up with a solution, say this environment looks boring, I want to add a puddle. That was

384
00:18:16,305 --> 00:18:20,848
the creative problem and a solution. But then the execution of it is I'm going to go to a shader,

385
00:18:20,848 --> 00:18:24,871
add a feature, make sure it has a vertex blend on it, go cut in some verts into the environment,

386
00:18:24,871 --> 00:18:29,234
paint in the verts, build the level, look at it in game, tweak the shader, bake the lighting,

387
00:18:29,234 --> 00:18:31,275
and then hopefully it's done. So that chunk...

388
00:18:31,695 --> 00:18:35,297
is execution and it's by far the biggest part of any production.

389
00:18:35,297 --> 00:18:38,318
And so what all of these things are doing,

390
00:18:38,318 --> 00:18:42,240
all of the technology that we're talking about, they're cutting down on execution time.

391
00:18:42,240 --> 00:18:46,882
They're going to get you from your idea, from your solution, from your intent,

392
00:18:46,882 --> 00:18:49,283
to the final result as fast as possible.

393
00:18:49,283 --> 00:18:51,804
Hopefully instantaneously at some point.

394
00:18:52,625 --> 00:19:00,909
This basically means that the core skills that we rely on as artists are still as valuable and as needed as they're ever going to be.

395
00:19:00,909 --> 00:19:09,333
But a lot of other skills that surround feeding a still imperfect hardware or software might go redundant.

396
00:19:09,333 --> 00:19:20,079
And so the interesting thing that comes out of all of this is that intent is basically going to be our basic building block of any art production, but also of any interface.

397
00:19:20,079 --> 00:19:21,160
If you're working on tools.

398
00:19:22,647 --> 00:19:24,388
they'll have to be refactored into a manner

399
00:19:24,388 --> 00:19:26,629
where we don't treat content as something

400
00:19:26,629 --> 00:19:27,970
that pertains to a computer.

401
00:19:27,970 --> 00:19:29,451
We have to treat content as something

402
00:19:29,451 --> 00:19:30,871
that's from the real world,

403
00:19:30,871 --> 00:19:33,332
and we'll want to interact with it based on intent,

404
00:19:33,332 --> 00:19:34,913
just like we would in the real world.

405
00:19:34,913 --> 00:19:38,335
And once again, that very well feeds

406
00:19:38,335 --> 00:19:40,476
into the artistic process that we have today,

407
00:19:40,476 --> 00:19:41,937
because we're all masters of intent, right?

408
00:19:41,937 --> 00:19:44,878
We don't just go in and do something for no reason.

409
00:19:44,878 --> 00:19:47,820
If this plan has to have more angles and be sharp,

410
00:19:47,820 --> 00:19:50,301
it's because this environment has to be scary or foreboding.

411
00:19:50,301 --> 00:19:51,821
We're trying to communicate something about it.

412
00:19:52,262 --> 00:19:55,243
And then all of the choices we make during production

413
00:19:55,243 --> 00:19:58,265
hopefully all rely on some kind of artistic intent

414
00:19:58,265 --> 00:20:00,486
or meaning to back it up.

415
00:20:00,486 --> 00:20:02,567
And so if we were to look at a process

416
00:20:02,567 --> 00:20:05,768
as to how it might look years down the line

417
00:20:05,768 --> 00:20:07,969
is you would have your high level intent

418
00:20:07,969 --> 00:20:09,590
or global intent where you would generate

419
00:20:09,590 --> 00:20:11,871
an entire environment space.

420
00:20:11,871 --> 00:20:12,912
And then you have a regional intent

421
00:20:12,912 --> 00:20:14,352
where you go, oh, I want plants in this corner.

422
00:20:14,352 --> 00:20:16,814
So you place your region, you specify a biome,

423
00:20:16,814 --> 00:20:17,514
and they just grow.

424
00:20:17,514 --> 00:20:18,835
And then you can go in and be,

425
00:20:18,835 --> 00:20:21,436
okay, I want to actually add an individual prototypes.

426
00:20:21,776 --> 00:20:24,478
and I actually want to modify them and add a particular color or something,

427
00:20:24,478 --> 00:20:27,699
but that will have to be the workflow.

428
00:20:27,699 --> 00:20:31,922
And what's interesting is, this is kind of the way movies do it.

429
00:20:31,922 --> 00:20:35,664
When you think about it, I don't think anyone's going to say that movies are not artistic.

430
00:20:35,664 --> 00:20:38,185
And this is a great example from Rebel Without a Cause,

431
00:20:38,185 --> 00:20:41,066
and this shot is without a doubt art, right?

432
00:20:41,066 --> 00:20:44,628
But it's art because the director and the director of photography infused it.

433
00:20:44,928 --> 00:20:47,949
with meaning, because the character of James Dean is,

434
00:20:47,949 --> 00:20:50,470
you know, smack dab in the middle of the sharp corner

435
00:20:50,470 --> 00:20:52,610
that's dividing the screen in two halves,

436
00:20:52,610 --> 00:20:53,990
and the right side is the policeman,

437
00:20:53,990 --> 00:20:58,351
and sort of men in kind of the stern world of men

438
00:20:58,351 --> 00:21:00,411
that James Dean's character is getting into,

439
00:21:00,411 --> 00:21:02,232
and then the other side, it's women,

440
00:21:02,232 --> 00:21:04,792
it's his love interest, it's sort of more kindness,

441
00:21:04,792 --> 00:21:07,613
and the choice, for example, of the red coat

442
00:21:07,613 --> 00:21:09,833
is not accidental, it attracts our attention.

443
00:21:09,833 --> 00:21:12,054
So the art part of this is not the fact

444
00:21:12,054 --> 00:21:14,274
that someone put a mug in the corner of that room.

445
00:21:14,834 --> 00:21:16,257
or build that desk.

446
00:21:16,257 --> 00:21:19,401
It's the fact that it was heavily infused with meaning

447
00:21:19,401 --> 00:21:22,566
that communicated something, and that part was art.

448
00:21:22,566 --> 00:21:24,469
So in essence, deriving from this,

449
00:21:24,469 --> 00:21:26,171
you can say that creating art is essentially

450
00:21:26,171 --> 00:21:27,393
a process of assigning meaning.

451
00:21:28,394 --> 00:21:31,917
And in that case, no matter how much you optimize

452
00:21:31,917 --> 00:21:34,260
the process, the art is not gonna go away

453
00:21:34,260 --> 00:21:35,662
because you're still gonna have to think about

454
00:21:35,662 --> 00:21:37,744
what are you communicating to your audience.

455
00:21:37,744 --> 00:21:39,846
If your art does not have a meaning to back it up,

456
00:21:39,846 --> 00:21:42,309
then it will not be as successful

457
00:21:42,309 --> 00:21:45,112
because there's nothing for people to resonate with.

458
00:21:45,112 --> 00:21:48,836
And so this part is, once again, not going anywhere.

459
00:21:50,487 --> 00:21:52,088
There's obviously the bigger question, right?

460
00:21:52,088 --> 00:21:54,049
How is it going to impact us as an industry?

461
00:21:54,049 --> 00:21:56,270
And cinema is once again a great example of that

462
00:21:56,270 --> 00:21:57,851
because they went through it, through this.

463
00:21:57,851 --> 00:22:00,092
They went through the process of

464
00:22:00,092 --> 00:22:01,873
democratizing their productions.

465
00:22:01,873 --> 00:22:03,914
They used to be way more time consuming,

466
00:22:03,914 --> 00:22:06,115
laborious, required a lot more money,

467
00:22:06,115 --> 00:22:08,656
but then with this great abstraction came great democratization

468
00:22:08,656 --> 00:22:11,518
because everyone had a pocket camera that they could shoot a movie with.

469
00:22:11,898 --> 00:22:20,042
And that brought a lot of different things and we're going to try and see how that applies to the games industry, or at least speculate and do our best.

470
00:22:20,042 --> 00:22:24,204
So obviously productions are going to get cheaper, right? This is understandable.

471
00:22:24,204 --> 00:22:28,467
When you don't have to model all of the art but you can just import real locations and dress them up.

472
00:22:28,996 --> 00:22:31,177
the bulk of the cost of any production goes away.

473
00:22:31,177 --> 00:22:33,558
And the same for animation.

474
00:22:33,558 --> 00:22:36,059
20 years from now, you're going to have a 4D phone that

475
00:22:36,059 --> 00:22:38,920
captures holographic people that you can just drop into

476
00:22:38,920 --> 00:22:39,701
the game immediately.

477
00:22:39,701 --> 00:22:42,262
And same thing for smaller teams.

478
00:22:42,262 --> 00:22:43,242
Don't get scared just yet.

479
00:22:43,242 --> 00:22:44,523
We'll circle around to that point.

480
00:22:44,523 --> 00:22:47,244
But yes, you will need smaller teams, because you can do more

481
00:22:47,244 --> 00:22:47,765
with less people.

482
00:22:48,365 --> 00:22:51,149
And that means that there's going to be a sort of

483
00:22:51,149 --> 00:22:53,852
a re-generalization where we used to specialize a lot,

484
00:22:53,852 --> 00:22:55,835
but then at some point it's not going to make sense anymore.

485
00:22:55,835 --> 00:22:57,657
At some point all this is going to be automated

486
00:22:57,657 --> 00:22:59,320
and we're going to be more generalized again,

487
00:22:59,320 --> 00:23:01,382
and we're going to execute more artistry

488
00:23:01,382 --> 00:23:02,984
rather than technical communication.

489
00:23:04,437 --> 00:23:06,057
Production times.

490
00:23:06,057 --> 00:23:08,838
So I don't believe that the production times change much in the movie industry

491
00:23:08,838 --> 00:23:11,920
because a good story or a good gameplay takes time to mature.

492
00:23:11,920 --> 00:23:15,041
It's not something that if you can produce an entire world in three days

493
00:23:15,041 --> 00:23:17,282
it doesn't mean that you're going to have a good game.

494
00:23:17,282 --> 00:23:20,043
Because a good story takes iteration.

495
00:23:20,043 --> 00:23:22,304
You're going to have to work with your audience, you're going to have to playtest,

496
00:23:22,304 --> 00:23:24,344
you're going to have to figure out what makes it great,

497
00:23:24,344 --> 00:23:25,845
and that part just takes time.

498
00:23:25,845 --> 00:23:28,566
There's nothing technology can do to speed it up.

499
00:23:28,946 --> 00:23:32,789
excuse me, speed it up. Another fun outcome is that

500
00:23:32,789 --> 00:23:36,492
Photoreal is going to become the new indie because it's going to be that much cheaper. Right now it's

501
00:23:36,492 --> 00:23:40,596
diametrically opposed. Independent studios do more stylized games because they

502
00:23:40,596 --> 00:23:44,719
cannot afford to compete with super expensive productions. The more

503
00:23:44,719 --> 00:23:48,742
AAA studios do that are very realistic and detailed and that way they also get to stand out

504
00:23:48,742 --> 00:23:52,885
on the market. But eventually when the cost of everything scanned is going to become

505
00:23:52,885 --> 00:23:53,466
dirt cheap.

506
00:23:54,923 --> 00:23:56,525
everything's going to be very realistic

507
00:23:56,525 --> 00:23:57,987
and everything's going to look good,

508
00:23:57,987 --> 00:24:01,130
provided you can light it and give it enough context.

509
00:24:01,130 --> 00:24:04,054
But that being said, if I were a big AAA publisher

510
00:24:04,054 --> 00:24:05,375
or a studio thinking of a franchise

511
00:24:05,375 --> 00:24:06,697
that's going to last for 20 years,

512
00:24:06,697 --> 00:24:10,321
I would probably consider something slightly less real.

513
00:24:10,541 --> 00:24:16,469
And final one, I do not necessarily believe that a lot of jobs are going to get lost.

514
00:24:16,469 --> 00:24:22,136
Same way in the movie industry when democratization happened, it didn't shrink.

515
00:24:22,136 --> 00:24:26,781
There was actually more value being generated, there were more movies made because...

516
00:24:27,999 --> 00:24:29,359
It's that much simpler now.

517
00:24:29,359 --> 00:24:31,200
Many more people are coming in to do it,

518
00:24:31,200 --> 00:24:32,140
and all of them need talent,

519
00:24:32,140 --> 00:24:33,700
all of them need people to support it,

520
00:24:33,700 --> 00:24:35,161
all of them need artists,

521
00:24:35,161 --> 00:24:37,861
all of them need lighters and directors of photography,

522
00:24:37,861 --> 00:24:39,022
and what be it.

523
00:24:39,022 --> 00:24:42,082
And I'm convinced that that is what's gonna happen in games

524
00:24:42,082 --> 00:24:44,803
because right now it's a very technical process.

525
00:24:44,803 --> 00:24:46,103
It's a high barrier to entry,

526
00:24:46,103 --> 00:24:47,324
but eventually it's not gonna be,

527
00:24:47,324 --> 00:24:49,524
and then everyone will get a chance to express themselves.

528
00:24:50,044 --> 00:24:53,645
And that's just going to mean that we're creating that much more value in that many more games,

529
00:24:53,645 --> 00:24:57,526
but it's just that on every individual project you're going to have less people.

530
00:24:57,526 --> 00:25:03,588
So if you take one thing from this talk, it's hopefully that this is how I think it's going to be.

531
00:25:03,588 --> 00:25:05,169
So take some comfort in that.

532
00:25:05,169 --> 00:25:08,630
But then for the final point, is...

533
00:25:09,507 --> 00:25:12,969
Every time you go from this big, huge, gigantic production

534
00:25:12,969 --> 00:25:15,211
that has a lot of people to just a handful of people

535
00:25:15,211 --> 00:25:16,932
being able to produce something of the same quality,

536
00:25:16,932 --> 00:25:18,953
you know, for every Captain America,

537
00:25:18,953 --> 00:25:21,495
you get a good wool hunting.

538
00:25:21,495 --> 00:25:24,857
And this, to me, is fascinating because...

539
00:25:26,210 --> 00:25:28,692
Every time I go to GDC, I get to meet all of you,

540
00:25:28,692 --> 00:25:33,736
I get to talk to you and see this sort of contagious passion

541
00:25:33,736 --> 00:25:36,159
for art and desire to do things.

542
00:25:36,159 --> 00:25:39,201
And the people that are going to be making

543
00:25:39,201 --> 00:25:40,542
the next Good Will Hunting games are going to be you.

544
00:25:41,363 --> 00:25:45,586
And if, you know, I used to model and I still do

545
00:25:45,586 --> 00:25:48,628
for 15 years now, and I come home after a long day at work

546
00:25:48,628 --> 00:25:51,250
and I do some modeling and texturing until 3 a.m.,

547
00:25:51,250 --> 00:25:53,031
and more and more these days I'm realizing

548
00:25:53,031 --> 00:25:56,033
that I might not get to do this for much longer,

549
00:25:56,033 --> 00:26:00,316
but if this means that that many people get to have a voice.

550
00:26:01,103 --> 00:26:03,743
if that means that that many people get to tell their stories,

551
00:26:03,743 --> 00:26:07,784
if that many people get to go back to what inspired them to make games in the first place.

552
00:26:07,784 --> 00:26:10,765
Because I don't think any one of you saw someone do a UV unwrap and went,

553
00:26:10,765 --> 00:26:13,766
holy shit, that's what I want to do for the rest of my life.

554
00:26:13,766 --> 00:26:16,766
You know, we're all inspired by stories that profoundly changed us.

555
00:26:16,766 --> 00:26:18,107
We just want to be better.

556
00:26:18,107 --> 00:26:21,888
We're all inspired by virtual worlds that made us want to go there,

557
00:26:21,888 --> 00:26:23,348
live there, and share them.

558
00:26:23,348 --> 00:26:26,489
And this is what I think technology will allow us to go back to.

559
00:26:26,489 --> 00:26:28,509
And yes, we're going to lose some things.

560
00:26:28,509 --> 00:26:30,950
But if that kind of future means that...

561
00:26:31,610 --> 00:26:33,252
I don't get to model or texture anymore,

562
00:26:33,252 --> 00:26:35,554
then I guess I'm fine with that.

563
00:26:35,554 --> 00:26:37,657
And to be honest, I think we as a species

564
00:26:37,657 --> 00:26:38,958
are gonna be better off that way.

565
00:26:38,958 --> 00:26:42,501
So with all that said, to tell you the truth,

566
00:26:42,501 --> 00:26:44,003
I can't fucking wait.

567
00:26:44,003 --> 00:26:44,423
Thank you so much.

568
00:26:58,188 --> 00:27:03,976
If you have any questions, I think we have a minute.

569
00:27:03,976 --> 00:27:08,423
You can always just find me after the presentation.

570
00:27:08,423 --> 00:27:10,225
Hey, man, one question.

571
00:27:10,225 --> 00:27:11,968
One question over here.

572
00:27:11,968 --> 00:27:12,388
Yes, yes, yes.

573
00:27:12,725 --> 00:27:15,447
So I'm with you, I can't wait.

574
00:27:15,447 --> 00:27:17,108
I think ultimately what we,

575
00:27:17,108 --> 00:27:19,189
I wanted to say for your first story,

576
00:27:19,189 --> 00:27:21,170
it's what is water, it's why is water?

577
00:27:21,170 --> 00:27:23,051
I think that will be the question we have to ask.

578
00:27:23,051 --> 00:27:24,232
That's a good question.

579
00:27:24,232 --> 00:27:28,694
When we don't have all the worlds ready at our fingertips,

580
00:27:28,694 --> 00:27:30,275
it's like what do we want to tell in that world?

581
00:27:30,275 --> 00:27:30,515
Exactly.

582
00:27:30,515 --> 00:27:32,256
So that's what I hope, you know.

583
00:27:32,886 --> 00:27:33,868
That's what I get out of your talk,

584
00:27:33,868 --> 00:27:35,591
and I'm inspired by it because I think ultimately

585
00:27:35,591 --> 00:27:38,176
we're going to be able to be more empowered to tell stories.

586
00:27:38,176 --> 00:27:40,260
We won't have that barrier to tell those great stories.

587
00:27:40,260 --> 00:27:42,524
So thank you for the presentation.

588
00:27:42,524 --> 00:27:42,905
Thank you.

589
00:27:42,905 --> 00:27:43,285
See you, bud.

590
00:27:43,285 --> 00:27:43,706
Totally agree.

591
00:27:43,706 --> 00:27:43,826
Cheers.

