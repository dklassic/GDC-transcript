1
00:00:06,286 --> 00:00:11,550
Welcome to Marvel's Spider-Man Procedural Lighting Tools, GDC.

2
00:00:11,550 --> 00:00:14,332
The conference associates have asked me

3
00:00:14,332 --> 00:00:16,353
to make a couple of reminders.

4
00:00:16,353 --> 00:00:20,876
Please silence your cell phones or put them in pleasure mode.

5
00:00:20,876 --> 00:00:24,439
And remember to fill out the survey

6
00:00:24,439 --> 00:00:27,741
that they'll send out after the presentation.

7
00:00:27,741 --> 00:00:32,284
My name's X-Ray Halperin.

8
00:00:33,272 --> 00:00:36,113
I am a senior technical artist at Insomniac Games.

9
00:00:36,113 --> 00:00:38,993
It's my pleasure to be here with you today.

10
00:00:38,993 --> 00:00:42,914
This is my second GDC, my first time speaking here.

11
00:00:42,914 --> 00:00:45,974
I think it was last year in this very room

12
00:00:45,974 --> 00:00:48,475
I had the pleasure of watching Yoko Taro

13
00:00:48,475 --> 00:00:52,576
present an amazing talk on Nier Automata.

14
00:00:52,576 --> 00:00:55,896
And I'm really happy to be in the same room

15
00:00:55,896 --> 00:00:57,817
that that happened.

16
00:00:57,817 --> 00:01:00,537
Insomniac's a great place to work.

17
00:01:03,037 --> 00:01:05,258
We've got a lot of current job openings,

18
00:01:05,258 --> 00:01:09,420
so go to our webpage, check these out.

19
00:01:09,420 --> 00:01:11,421
We're looking for talented folks.

20
00:01:11,421 --> 00:01:18,165
I wanna give a big thank you and a shout out

21
00:01:18,165 --> 00:01:21,327
to Sony Interactive Media, SideFX Software,

22
00:01:21,327 --> 00:01:26,510
Jeff Hanna and GDC, as well as everyone at Insomniac Games.

23
00:01:26,510 --> 00:01:29,631
There's a number of talks by Insomniacs

24
00:01:29,631 --> 00:01:31,812
about Spider-Man at GDC this year.

25
00:01:35,543 --> 00:01:40,408
Some of the related talks include Marvel's Spider-Man,

26
00:01:40,408 --> 00:01:42,229
a technical post-mortem by Elon Ruskin.

27
00:01:42,229 --> 00:01:45,412
That's this evening at 5.30 p.m.

28
00:01:45,412 --> 00:01:49,456
And tomorrow, there's a lot of talks about Spider-Man.

29
00:01:49,456 --> 00:01:52,239
Doug Sheehan is gonna be presenting

30
00:01:52,239 --> 00:01:56,062
the traversal through the city.

31
00:01:56,062 --> 00:01:57,804
Ron Peekt is gonna be talking about

32
00:01:57,804 --> 00:01:59,366
editing with immutable data.

33
00:02:01,329 --> 00:02:07,974
Alex Previty is going to be talking about designing sound for Spider-Man.

34
00:02:07,974 --> 00:02:14,279
And Jason Hickey is going to be talking about leading a large environmental team.

35
00:02:14,279 --> 00:02:22,445
As a technical artist on Marvel's Spider-Man, part of my job was to identify points in the

36
00:02:22,445 --> 00:02:29,270
production pipeline that can be proceduralized with the goal of...

37
00:02:29,813 --> 00:02:33,275
removing rote tasks from the artist's plate.

38
00:02:33,275 --> 00:02:36,217
Basically, I try to keep the artist sane

39
00:02:36,217 --> 00:02:38,779
so they don't rage quit by throwing their keyboards

40
00:02:38,779 --> 00:02:40,120
across the room.

41
00:02:40,120 --> 00:02:44,263
So what is procedural in this context?

42
00:02:44,263 --> 00:02:48,326
Procedural refers to algorithmic methods

43
00:02:48,326 --> 00:02:51,048
of creating data as opposed to manual methods.

44
00:02:51,048 --> 00:02:53,990
At Insomniac Games, we've developed a number

45
00:02:53,990 --> 00:02:56,171
of procedural workflows for generating

46
00:02:56,171 --> 00:02:57,993
open world content for our games.

47
00:02:58,758 --> 00:03:03,939
If you attended my colleague, David Santiago's presentation earlier today, you'll have a

48
00:03:03,939 --> 00:03:06,900
good idea about many of these procedural systems.

49
00:03:06,900 --> 00:03:12,521
This talk will cover some of the procedural workflows which apply to lighting the open

50
00:03:12,521 --> 00:03:14,142
world of Marvel's Spider-Man.

51
00:03:14,142 --> 00:03:22,224
Lighting artists illuminate the open world by hand placing lights throughout the environment.

52
00:03:22,224 --> 00:03:26,125
But how can procedural techniques augment the hard work of the lighting artists?

53
00:03:27,428 --> 00:03:31,310
By identifying the rote technical tasks and automating them,

54
00:03:31,310 --> 00:03:33,731
we can remove the boring, repetitive stuff

55
00:03:33,731 --> 00:03:36,873
from the artist's workflow and allow them to focus

56
00:03:36,873 --> 00:03:39,374
on creating great art.

57
00:03:39,374 --> 00:03:42,735
Procedural techniques assisted and augmented

58
00:03:42,735 --> 00:03:46,757
the lighting artists with bulk tasks across the open world.

59
00:03:46,757 --> 00:03:53,220
Procedural techniques contributed to three main aspects

60
00:03:53,220 --> 00:03:54,480
of lighting in Spider-Man.

61
00:03:56,112 --> 00:04:00,653
Light fixtures could be placed in the open world based on rules defining things like

62
00:04:00,653 --> 00:04:08,256
the minimum distance between lights or how far back on the sidewalk to place street lamps.

63
00:04:08,256 --> 00:04:14,698
Light probes used for generating real-time reflections were placed in optimized positions

64
00:04:14,698 --> 00:04:19,520
using the context of the open world geometry in the immediate vicinity of each probe.

65
00:04:21,797 --> 00:04:25,579
and light grid capture volumes used to generate

66
00:04:25,579 --> 00:04:29,302
cached light grid data for diffuse global illumination

67
00:04:29,302 --> 00:04:32,143
were created and optimized using procedural techniques.

68
00:04:32,143 --> 00:04:35,746
We'll review each of these, but first,

69
00:04:35,746 --> 00:04:38,428
let's take a look at some of the open world environments

70
00:04:38,428 --> 00:04:38,828
from the game.

71
00:04:39,890 --> 00:04:41,771
Don't you think you're a little hard on Spider-Man?

72
00:04:41,771 --> 00:04:43,232
Let me tell you something, Patterson.

73
00:04:43,232 --> 00:04:47,636
Spider-Man treats New York City as his own personal playground.

74
00:04:47,636 --> 00:04:50,878
Just yesterday, I saw him doing back flips and 360s.

75
00:04:50,878 --> 00:04:52,359
Disgraceful.

76
00:04:52,359 --> 00:04:55,181
Running and crawling on buildings.

77
00:04:55,181 --> 00:04:57,383
In fact, I have it on good authority

78
00:04:57,383 --> 00:05:00,445
that he's been doing swan dives off of skyscrapers.

79
00:05:00,445 --> 00:05:03,347
It seems the more confident he gets,

80
00:05:03,347 --> 00:05:05,389
the more creative he gets.

81
00:05:05,489 --> 00:05:06,409
Walk like a normal person.

82
00:05:06,409 --> 00:05:08,790
Come on, what's wrong with a little sightseeing?

83
00:05:08,790 --> 00:05:12,432
New York is super diverse and constantly changing.

84
00:05:12,432 --> 00:05:16,814
Maybe he's just looking for vans.

85
00:05:16,814 --> 00:05:21,295
So we can see that we've got a wide and varied open world

86
00:05:21,295 --> 00:05:25,377
environment that's just really dense with visual information

87
00:05:25,377 --> 00:05:25,817
and content.

88
00:05:25,817 --> 00:05:33,040
The open world of Spider-Man is divided into 726 tile regions.

89
00:05:33,876 --> 00:05:40,702
Each tile region is defined by several zone files, which are JSON that contain references

90
00:05:40,702 --> 00:05:44,204
to the assets within a given tile region.

91
00:05:44,204 --> 00:05:50,670
Procedural systems allow iterating over the content in each tile region to add massive

92
00:05:50,670 --> 00:05:52,251
amounts of information to the game.

93
00:05:53,185 --> 00:05:55,988
This image shows how the island of Manhattan

94
00:05:55,988 --> 00:05:58,130
is divided up into tiles.

95
00:05:58,130 --> 00:06:00,872
We iterate over each tile as a work unit

96
00:06:00,872 --> 00:06:04,375
to add or adjust the content using procedural tools.

97
00:06:04,375 --> 00:06:09,500
Our Manhattan is about six kilometers by three kilometers

98
00:06:09,500 --> 00:06:11,521
divided up into these 726 tiles

99
00:06:11,521 --> 00:06:14,024
measuring 128 meters per side.

100
00:06:14,024 --> 00:06:15,785
Spider-Man is a streaming game.

101
00:06:20,498 --> 00:06:22,920
As Spider-Man moves through the open world,

102
00:06:22,920 --> 00:06:26,481
the current tile and its neighbors stream into memory

103
00:06:26,481 --> 00:06:28,402
and the previous tiles stream out.

104
00:06:28,402 --> 00:06:32,784
This poses some issues for distant reflections,

105
00:06:32,784 --> 00:06:34,945
but more on that in a moment.

106
00:06:34,945 --> 00:06:37,646
The first step in most of the Insomniac game's

107
00:06:37,646 --> 00:06:40,327
procedural workflows is to construct a point cloud

108
00:06:40,327 --> 00:06:42,248
from the zone data.

109
00:06:42,248 --> 00:06:46,210
We use Python to parse JSON from the zone files

110
00:06:46,210 --> 00:06:48,571
and recurse through all of the references.

111
00:06:49,584 --> 00:06:53,727
Let's look at a tile called M35 in Greenwich Village.

112
00:06:53,727 --> 00:07:01,695
This JSON snippet represents the region for a single file.

113
00:07:01,695 --> 00:07:04,657
Each one of those zones contains data

114
00:07:04,657 --> 00:07:07,060
that streams in along with the tile.

115
00:07:07,060 --> 00:07:12,044
The building geometry used for the context

116
00:07:12,044 --> 00:07:15,888
in procedural lighting tools is located in the ground zone.

117
00:07:19,004 --> 00:07:23,607
I load the ground zone data into a point cloud.

118
00:07:23,607 --> 00:07:30,211
Each point represents the pivot of an individual model instance within a prefabricated building

119
00:07:30,211 --> 00:07:30,651
asset.

120
00:07:30,651 --> 00:07:38,296
The point cloud contains all of the attributes we ever need to reconstruct the ground zone

121
00:07:38,296 --> 00:07:42,478
and the game data in third-party digital content creation applications such as Houdini.

122
00:07:42,478 --> 00:07:48,562
We flatten all of the transformation hierarchies into world space.

123
00:07:51,438 --> 00:07:54,039
We encant the attributes n, up, and tangent u.

124
00:07:54,039 --> 00:07:58,522
There's a lot of aligning and instancing,

125
00:07:58,522 --> 00:08:02,224
and packed geometry is very memory efficient

126
00:08:02,224 --> 00:08:07,448
because the assets are built from repeated model instances.

127
00:08:07,448 --> 00:08:10,730
We've got id and asset path point attributes,

128
00:08:10,730 --> 00:08:13,551
which let us define a clear way to identify

129
00:08:13,551 --> 00:08:18,034
and address each unique asset, such as this sanctum.

130
00:08:22,281 --> 00:08:24,302
Sometimes bounding boxes are handy.

131
00:08:24,302 --> 00:08:34,148
A moment ago, I mentioned prefabricated assets.

132
00:08:34,148 --> 00:08:38,630
Each prefabricated asset is a collection of models

133
00:08:38,630 --> 00:08:41,972
and other information, such as lights and shaders,

134
00:08:41,972 --> 00:08:44,393
grouped together in a JSON file on disk,

135
00:08:44,393 --> 00:08:47,635
creating a single addressable asset entity.

136
00:08:48,584 --> 00:08:52,646
These assets may be browsed by using the Insomniac Vault.

137
00:08:52,646 --> 00:08:56,367
Here's an example of a street light prefabricated asset.

138
00:08:56,367 --> 00:09:01,669
Rather than tasking artists with placing every street lamp

139
00:09:01,669 --> 00:09:06,611
along the streets that make up the city,

140
00:09:06,611 --> 00:09:10,113
we were able to offload this repetitive rules-based task

141
00:09:10,113 --> 00:09:13,734
and procedurally place the street lamps

142
00:09:13,734 --> 00:09:16,355
into the open world of Marvel's Spider-Man.

143
00:09:22,377 --> 00:09:26,560
Each prefabricated asset can be instanced multiple times.

144
00:09:26,560 --> 00:09:30,843
For Marvel's Spider-Man, streetlights were placed

145
00:09:30,843 --> 00:09:33,985
on a metric along sidewalks at a fixed distance

146
00:09:33,985 --> 00:09:37,688
back from the curb and aligned according to the normals

147
00:09:37,688 --> 00:09:39,889
of the sidewalk upon which they are placed.

148
00:09:39,889 --> 00:09:47,574
We can visualize the location of all the light sources

149
00:09:47,574 --> 00:09:51,937
in a tile to help find underlit areas of the open world.

150
00:09:53,812 --> 00:09:57,696
Marvel's Spider-Man supports night as a time of day,

151
00:09:57,696 --> 00:09:59,397
so it's important to make sure

152
00:09:59,397 --> 00:10:03,181
there are no unintentionally underlit areas.

153
00:10:03,181 --> 00:10:09,326
Doing some nearest neighbor and ray casting computations,

154
00:10:09,326 --> 00:10:12,429
we can detect underserved areas

155
00:10:12,429 --> 00:10:14,071
which are not receiving enough light.

156
00:10:18,335 --> 00:10:20,715
We can then attempt to procedurally place

157
00:10:20,715 --> 00:10:23,516
additional light fixtures into those areas

158
00:10:23,516 --> 00:10:26,557
and log them for further inspection by the lighting team.

159
00:10:26,557 --> 00:10:39,600
Light probes are used for reflection maps.

160
00:10:39,600 --> 00:10:41,680
Light probes occur in the open world

161
00:10:41,680 --> 00:10:44,281
at a low spatial frequency,

162
00:10:44,281 --> 00:10:46,021
but capture the reflected objects

163
00:10:46,021 --> 00:10:47,961
at high fidelity in real time.

164
00:10:48,953 --> 00:10:52,376
They are procedurally placed in optimized positions

165
00:10:52,376 --> 00:10:54,958
based on heuristics verbally described

166
00:10:54,958 --> 00:10:57,460
by the lighting team for optimal placement.

167
00:10:57,460 --> 00:11:05,766
Marvel's Spider-Man had four procedurally placed

168
00:11:05,766 --> 00:11:06,987
light probes per tile.

169
00:11:06,987 --> 00:11:09,529
Additional light probes are placed

170
00:11:09,529 --> 00:11:11,010
by the lighting artists where needed.

171
00:11:11,010 --> 00:11:15,853
The first step is dividing the tile into four cells,

172
00:11:15,853 --> 00:11:17,595
one for each light probe.

173
00:11:19,480 --> 00:11:22,221
We create a point at the center of each cell,

174
00:11:22,221 --> 00:11:23,642
and based on the rules of thumb

175
00:11:23,642 --> 00:11:26,763
described by the lighting artists,

176
00:11:26,763 --> 00:11:29,604
I analyze the ground zone geometry

177
00:11:29,604 --> 00:11:31,345
to identify optimal positions

178
00:11:31,345 --> 00:11:35,086
and move the location of the light probes.

179
00:11:35,086 --> 00:11:39,088
We find where the roads and intersections exist

180
00:11:39,088 --> 00:11:39,888
in each cell.

181
00:11:39,888 --> 00:11:44,330
And we move the light probe points

182
00:11:44,330 --> 00:11:47,551
to the nearest major road intersection in its cell.

183
00:11:48,464 --> 00:11:50,526
If there's no major intersection,

184
00:11:50,526 --> 00:11:52,027
we use a minor intersection.

185
00:11:52,027 --> 00:11:53,208
If there's no minor intersection,

186
00:11:53,208 --> 00:11:56,171
we use the centroid of the road segment

187
00:11:56,171 --> 00:11:57,092
that intersects the cell.

188
00:11:57,092 --> 00:12:00,154
If there's no road, we leave it alone

189
00:12:00,154 --> 00:12:04,238
at the center of the cell.

190
00:12:04,238 --> 00:12:05,999
We can then check if any probes

191
00:12:05,999 --> 00:12:07,981
are inside of building volumes.

192
00:12:07,981 --> 00:12:09,602
We don't want them inside of buildings,

193
00:12:09,602 --> 00:12:12,064
we just want them outside of buildings in the open world.

194
00:12:13,135 --> 00:12:17,197
If so, we use the sign distance function of the volume

195
00:12:17,197 --> 00:12:20,418
to push the light probe outside of the building.

196
00:12:20,418 --> 00:12:23,239
Finally, we export the JSON containing light probe

197
00:12:23,239 --> 00:12:26,641
information for ingestion into the game engine.

198
00:12:26,641 --> 00:12:28,701
Wash, rinse, and repeat 726 times.

199
00:12:28,701 --> 00:12:34,404
As a procedural system, should the needing capability

200
00:12:34,404 --> 00:12:36,785
arise to support more light probes,

201
00:12:36,785 --> 00:12:39,566
we can increase the number of subdivisions per tile,

202
00:12:39,566 --> 00:12:41,927
thus increasing the number of light probes.

203
00:12:44,969 --> 00:12:48,131
This JSON snippet represents a single light probe.

204
00:12:48,131 --> 00:12:50,912
The probe is defined by a volume

205
00:12:50,912 --> 00:12:52,693
at a certain position within the tile,

206
00:12:52,693 --> 00:12:55,534
then the exact position of the light probe

207
00:12:55,534 --> 00:12:58,596
is defined as an offset from the centroid of that volume.

208
00:12:58,596 --> 00:13:05,079
So the volume represents the extents of the cell,

209
00:13:05,079 --> 00:13:08,060
and the offset represents the position

210
00:13:08,060 --> 00:13:10,021
of the light probe within the cell.

211
00:13:10,021 --> 00:13:11,762
Here's another example of a light probe

212
00:13:11,762 --> 00:13:13,543
in the open world of Marvel's Spider-Man.

213
00:13:15,445 --> 00:13:18,166
The image in the upper left corner shows each side

214
00:13:18,166 --> 00:13:23,969
of the generated environment map for this light probe.

215
00:13:23,969 --> 00:13:29,051
You'll notice that the quality of the assets captured

216
00:13:29,051 --> 00:13:32,453
in the light probe are not the full resolution assets,

217
00:13:32,453 --> 00:13:35,754
but rather the optimized 3D meshes

218
00:13:35,754 --> 00:13:39,596
used in the Insomniac Games imposter system.

219
00:13:39,596 --> 00:13:43,057
I'm going to explain more about the imposter system

220
00:13:43,057 --> 00:13:43,818
in a few moments.

221
00:13:44,658 --> 00:13:48,419
But this is what allowed us to generate distant reflections

222
00:13:48,419 --> 00:13:50,099
for the whole city in real time,

223
00:13:50,099 --> 00:13:54,241
even though the high-res assets are only streamed in

224
00:13:54,241 --> 00:13:57,281
for the local tile that Spider-Man is currently occupying,

225
00:13:57,281 --> 00:14:02,823
plus its neighbors.

226
00:14:02,823 --> 00:14:04,984
Storing all the light probe reflection maps

227
00:14:04,984 --> 00:14:08,024
proved bulky on disks, so Tony Archulio

228
00:14:08,024 --> 00:14:10,585
on the core engineering team developed technology

229
00:14:10,585 --> 00:14:12,986
for generating the light probe captures in real time.

230
00:14:13,919 --> 00:14:19,025
Since only the current streaming tile and its neighbors are available at full resolution,

231
00:14:19,025 --> 00:14:23,430
we leveraged the imposter system to create the content for the distant reflections.

232
00:14:23,430 --> 00:14:28,956
The IG imposters informed a number of game systems, including the real-time light probes.

233
00:14:28,956 --> 00:14:32,981
The IG imposters are 3D mesh models with projected textures.

234
00:14:34,258 --> 00:14:38,299
As for the light probes, each face of the light cubemap

235
00:14:38,299 --> 00:14:40,020
is rendered at a 512 by 512 resolution.

236
00:14:40,020 --> 00:14:42,341
We take advantage of mip mapping

237
00:14:42,341 --> 00:14:45,142
to convolve the cubemap down five levels,

238
00:14:45,142 --> 00:14:47,162
and each mip level ends up representing

239
00:14:47,162 --> 00:14:48,963
an amount of glossiness.

240
00:14:48,963 --> 00:14:51,764
Regardless of how an artist sets the glossiness

241
00:14:51,764 --> 00:14:55,465
on the slider for the shader of the surface material,

242
00:14:55,465 --> 00:14:57,926
we always quantize that glossiness response

243
00:14:57,926 --> 00:14:59,627
down to one of the five mip levels.

244
00:15:03,407 --> 00:15:06,390
All of the buildings in the island of Manhattan

245
00:15:06,390 --> 00:15:08,352
in this screen capture are the IG imposters.

246
00:15:08,352 --> 00:15:11,274
We can load the entire island into memory.

247
00:15:11,274 --> 00:15:15,638
The IG imposter geometry and lowest MIP texture

248
00:15:15,638 --> 00:15:18,981
remain in global persistent memory

249
00:15:18,981 --> 00:15:21,123
and represent the lowest LOD in the game.

250
00:15:21,123 --> 00:15:24,185
This allows for reflecting distant buildings

251
00:15:24,185 --> 00:15:26,828
when their tile region is not streamed into memory.

252
00:15:26,828 --> 00:15:30,291
The total geometry footprint for all of Manhattan

253
00:15:30,648 --> 00:15:32,249
was about 101 megabytes.

254
00:15:32,249 --> 00:15:37,432
And the lowest MIP for texture maps is about 90 megabytes.

255
00:15:37,432 --> 00:15:40,634
High quality polygons for reflective

256
00:15:40,634 --> 00:15:45,137
and emissive properties take up about another 30 megabytes.

257
00:15:45,137 --> 00:15:48,800
So we're looking at about 220 megs of RAM

258
00:15:48,800 --> 00:15:51,121
in global persistent memory that hold

259
00:15:51,121 --> 00:15:55,124
the entire representation of the lowest LOD of the city

260
00:15:55,124 --> 00:15:58,186
that's accessible by any game system at any time.

261
00:16:01,511 --> 00:16:07,992
The IG imposter geometry and lowest MIP texture stay in that global resident memory.

262
00:16:07,992 --> 00:16:10,873
They always maintain fidelity under all circumstances.

263
00:16:10,873 --> 00:16:14,714
It eliminates a far clipping plane for draw in.

264
00:16:14,714 --> 00:16:20,135
It maintains geometric relief details of the source assets, supports fully emissive and

265
00:16:20,135 --> 00:16:25,876
reflective surfaces, and transitions seamlessly between the high-res instance geometry and

266
00:16:25,876 --> 00:16:27,997
the corresponding IG imposter.

267
00:16:30,344 --> 00:16:32,546
Additionally, as I said, it informs many

268
00:16:32,546 --> 00:16:35,668
of the other game systems.

269
00:16:35,668 --> 00:16:37,570
So how do we take a high-res model

270
00:16:37,570 --> 00:16:39,411
and turn it into one of these impostors?

271
00:16:39,411 --> 00:16:41,313
This is a building from Tile H21.

272
00:16:41,313 --> 00:16:47,338
This exploded view shows all of the model instances

273
00:16:47,338 --> 00:16:48,459
that make up the building.

274
00:16:48,459 --> 00:16:51,441
Buildings are constructed from model kits

275
00:16:51,441 --> 00:16:53,323
containing predefined assets,

276
00:16:53,323 --> 00:16:55,845
such as windows, walls, and doors.

277
00:16:57,732 --> 00:16:59,913
Since the prefabricated building assets

278
00:16:59,913 --> 00:17:02,455
are used over and over again within a building,

279
00:17:02,455 --> 00:17:04,236
there are actually a small number

280
00:17:04,236 --> 00:17:05,677
of unique models per building.

281
00:17:05,677 --> 00:17:10,480
Again, here's the full resolution.

282
00:17:10,480 --> 00:17:13,942
This is the lowest LOD.

283
00:17:13,942 --> 00:17:16,603
To build the imposter,

284
00:17:16,603 --> 00:17:18,864
we identify groups of connected geometry

285
00:17:18,864 --> 00:17:21,806
which share primitive normals.

286
00:17:21,806 --> 00:17:24,167
We iterate over each set of connected geometry

287
00:17:24,167 --> 00:17:25,948
which shares a common primitive normal.

288
00:17:27,398 --> 00:17:29,659
and we remove shared edges from the polygons,

289
00:17:29,659 --> 00:17:30,840
leaving an outline of the shape.

290
00:17:30,840 --> 00:17:39,662
We triangulate the result

291
00:17:39,662 --> 00:17:44,464
and remove occluded geometry

292
00:17:44,464 --> 00:17:49,786
that's on the interior of the building.

293
00:17:49,786 --> 00:17:51,066
After occlusion removal.

294
00:17:52,364 --> 00:17:54,105
we do a final optimization pass.

295
00:17:54,105 --> 00:17:57,266
And we've brought a high-res building

296
00:17:57,266 --> 00:17:58,947
that had tens of thousands of polys

297
00:17:58,947 --> 00:18:01,908
down to about 5,000 polygons.

298
00:18:01,908 --> 00:18:04,449
This is a single mesh that represents

299
00:18:04,449 --> 00:18:06,669
the entire prefabricated asset.

300
00:18:06,669 --> 00:18:10,591
We capture the imposter geometry

301
00:18:10,591 --> 00:18:13,652
and generate orthogonal texture atlases.

302
00:18:14,588 --> 00:18:16,711
The building in the middle is the high res asset.

303
00:18:16,711 --> 00:18:19,133
The building on the left is the imposter

304
00:18:19,133 --> 00:18:20,314
with textures applied.

305
00:18:20,314 --> 00:18:25,820
The building on the right is the imposter without textures.

306
00:18:25,820 --> 00:18:29,564
We generate two texture atlases per building.

307
00:18:29,564 --> 00:18:32,006
Atlas A contains the RGB albedo.

308
00:18:32,006 --> 00:18:36,791
Atlas B contains spec, gloss, and emission.

309
00:18:37,994 --> 00:18:41,595
We've replaced all of the model instances and texturing

310
00:18:41,595 --> 00:18:44,656
from a building prefab with a single model instance

311
00:18:44,656 --> 00:18:47,577
and a pair of texture maps.

312
00:18:47,577 --> 00:18:50,878
Each building atlas is collected with the atlases

313
00:18:50,878 --> 00:18:54,579
from neighboring tiles in an imposter zone atlas.

314
00:18:54,579 --> 00:18:57,860
The RGB albedo is stored at full size

315
00:18:57,860 --> 00:19:01,321
while spec gloss and emission are stored at half size.

316
00:19:01,321 --> 00:19:05,543
Those half size maps are represented as green in this image.

317
00:19:05,935 --> 00:19:08,896
you can see Avengers Tower on the bottom.

318
00:19:08,896 --> 00:19:13,279
This is one of the nine tile imposter zones.

319
00:19:13,279 --> 00:19:17,201
This is another nine tile imposter zones.

320
00:19:17,201 --> 00:19:23,465
We also use the imposters to generate the light grids

321
00:19:23,465 --> 00:19:25,947
for caching global illumination data.

322
00:19:29,270 --> 00:19:32,111
Light grids are high spatial frequency,

323
00:19:32,111 --> 00:19:35,293
low detail samples for diffuse light in the open world.

324
00:19:35,293 --> 00:19:39,136
Using the same geometry measures as the IG Impostors,

325
00:19:39,136 --> 00:19:41,357
I quickly load the contents of a tile

326
00:19:41,357 --> 00:19:43,858
and all of its neighbors in order to determine

327
00:19:43,858 --> 00:19:47,240
what content would affect the diffuse samples

328
00:19:47,240 --> 00:19:53,324
used for diffuse global illumination calculations.

329
00:19:53,324 --> 00:19:56,366
The 128 meter square tile is divided

330
00:19:56,366 --> 00:19:58,307
into 16 meter capture volumes.

331
00:19:59,078 --> 00:20:04,561
The cached data for each volume represents the 16 meter volume divided into 4,096 samples

332
00:20:04,561 --> 00:20:06,442
at a one meter resolution.

333
00:20:06,442 --> 00:20:11,645
The data is similar to that captured by the real-time light probes, but the resolution

334
00:20:11,645 --> 00:20:16,227
is much lower and compressed for the diffuse lighting computations.

335
00:20:16,227 --> 00:20:22,070
The capture volumes for sampling and caching diffuse illumination were procedurally placed

336
00:20:22,070 --> 00:20:28,213
and optimized into each tile based on the tile contents and the contents of neighboring

337
00:20:28,213 --> 00:20:28,673
tiles.

338
00:20:29,673 --> 00:20:32,095
The number of vertical light grids generated

339
00:20:32,095 --> 00:20:35,077
depends on the height of the tallest building in the tile.

340
00:20:35,077 --> 00:20:38,480
Testing the individual capture volumes

341
00:20:38,480 --> 00:20:42,264
against the assets in the tile's zone file

342
00:20:42,264 --> 00:20:45,206
allows us to remove capture volumes with no contribution.

343
00:20:45,206 --> 00:20:49,229
Light grid capture volumes are also removed

344
00:20:49,229 --> 00:20:52,712
from the inside volumes of buildings.

345
00:20:52,712 --> 00:20:55,615
The final light grid capture volumes are written out

346
00:20:55,615 --> 00:20:58,197
as JSON and ingested into the Insomniac engine

347
00:20:58,445 --> 00:21:01,806
where the samples are rendered into a cached file format

348
00:21:01,806 --> 00:21:03,706
for runtime usage.

349
00:21:03,706 --> 00:21:05,807
Light probes are real time,

350
00:21:05,807 --> 00:21:07,788
while light grids are pre-cached

351
00:21:07,788 --> 00:21:08,888
and never generated at runtime.

352
00:21:08,888 --> 00:21:12,710
Light grid capture volumes

353
00:21:12,710 --> 00:21:15,550
removed from the insides of buildings,

354
00:21:15,550 --> 00:21:19,452
as you can see in this slide.

355
00:21:19,452 --> 00:21:23,213
The final light grid capture volumes

356
00:21:23,213 --> 00:21:24,474
are written out as JSON.

357
00:21:24,474 --> 00:21:27,835
This JSON snippet represents a single light grid.

358
00:21:30,500 --> 00:21:33,284
And here we can see the game engine iterating

359
00:21:33,284 --> 00:21:35,186
through each of the light grids

360
00:21:35,186 --> 00:21:37,369
as it generates that point cache data.

361
00:21:52,462 --> 00:21:56,125
There are 4,096 samples per capture volume.

362
00:21:56,125 --> 00:21:58,887
Each sample generates a cube map

363
00:21:58,887 --> 00:22:00,568
at 256 by 256 pixels per face.

364
00:22:00,568 --> 00:22:05,632
Each face of the cube map is then convolved down

365
00:22:05,632 --> 00:22:08,575
to a single HDR color value

366
00:22:08,575 --> 00:22:12,858
representing the diffuse term and a directional vector.

367
00:22:13,622 --> 00:22:16,605
So each sample inside of that capture volume

368
00:22:16,605 --> 00:22:19,589
is six pixels, each with a directional vector.

369
00:22:19,589 --> 00:22:23,994
The color value and direction data is highly compressible.

370
00:22:23,994 --> 00:22:28,119
Thank you very much.

371
00:22:28,119 --> 00:22:29,942
This concludes my talk.

372
00:22:29,942 --> 00:22:32,365
And if there are any questions, I'll be happy to take them.

373
00:22:45,267 --> 00:22:51,353
Hey, I saw you used JSON a lot to spit out the procedurally generated data and read it

374
00:22:51,353 --> 00:22:57,199
back into the game engine. Did you ever, like, load Houdini into the game engine or it was

375
00:22:57,199 --> 00:22:58,200
all built with JSON?

376
00:22:59,181 --> 00:23:03,545
So the question is, did we load Houdini into the game engine,

377
00:23:03,545 --> 00:23:06,868
or did we use JSON as an intermediary format

378
00:23:06,868 --> 00:23:08,229
to go between the two?

379
00:23:08,229 --> 00:23:12,112
The answer to that question is it's a bit of a hybrid.

380
00:23:12,112 --> 00:23:15,555
JSON was certainly the way that we communicated

381
00:23:15,555 --> 00:23:18,097
back and forth in many cases.

382
00:23:18,097 --> 00:23:20,319
We did not implement the Houdini engine

383
00:23:20,319 --> 00:23:21,560
in our Insomniac engine.

384
00:23:22,200 --> 00:23:25,984
But what we did do is expose several tools from pull-down

385
00:23:25,984 --> 00:23:35,412
menus in the engine, which would spawn a non-GUI shell of

386
00:23:35,412 --> 00:23:40,276
Houdini that we could send requests to process data

387
00:23:40,276 --> 00:23:44,640
offline, which could then generate JSON on disk that

388
00:23:44,640 --> 00:23:47,402
could be read back into the Insomniac engine.

389
00:23:47,402 --> 00:23:47,782
Thank you.

390
00:23:52,300 --> 00:23:53,141
Hi, thank you for the talk.

391
00:23:53,141 --> 00:23:56,785
Quick question on the imposter system.

392
00:23:56,785 --> 00:24:01,449
So I noticed that I'm guessing you were marking specific

393
00:24:01,449 --> 00:24:04,171
prefabs for generating an imposter, and specific prefabs

394
00:24:04,171 --> 00:24:07,034
were not generating an imposter intentionally.

395
00:24:07,034 --> 00:24:09,236
I noticed that on some of the buildings, there were benches

396
00:24:09,236 --> 00:24:11,879
and other things that were just completely excluded from

397
00:24:11,879 --> 00:24:13,380
the imposter generation.

398
00:24:13,380 --> 00:24:16,143
So how did you decide what was going and what wasn't going

399
00:24:16,143 --> 00:24:17,003
into the imposter?

400
00:24:17,214 --> 00:24:24,236
So there were a number of ways that we could include or exclude things from imposter generation.

401
00:24:24,236 --> 00:24:29,537
In additional, we had another subsystem called the hibernation subsystem.

402
00:24:29,537 --> 00:24:38,380
So for example, things that would contribute to the silhouette of a building that were

403
00:24:38,380 --> 00:24:42,121
accoutrements on top of the building, like water towers or air conditioning units.

404
00:24:42,121 --> 00:24:45,501
Those were handled by a separate system.

405
00:24:46,851 --> 00:24:53,034
called the Hibernate system, that basically had the full resolution asset, but with a

406
00:24:53,034 --> 00:24:54,515
much longer draw distance.

407
00:24:55,295 --> 00:24:58,737
So we would exclude those kind of things from the imposters

408
00:24:58,737 --> 00:25:02,760
because that geometry tended to be a little bit more organic,

409
00:25:02,760 --> 00:25:05,642
like things like water towers with lots of details

410
00:25:05,642 --> 00:25:07,804
and struts and things like that,

411
00:25:07,804 --> 00:25:10,186
just wouldn't really imposter very well

412
00:25:10,186 --> 00:25:13,648
and would have created a lot of extra geometry

413
00:25:13,648 --> 00:25:15,329
for the imposter system to deal with.

414
00:25:15,329 --> 00:25:18,371
So selectively, we would use meta tags

415
00:25:18,371 --> 00:25:20,293
to say this thing's hibernated,

416
00:25:20,293 --> 00:25:22,635
this thing should be skipped.

417
00:25:22,855 --> 00:25:25,455
or this thing should be,

418
00:25:25,455 --> 00:25:27,476
well the default was to include things.

419
00:25:27,476 --> 00:25:27,556
Okay.

420
00:25:27,556 --> 00:25:29,976
Thank you.

421
00:25:29,976 --> 00:25:30,036
Hi.

422
00:25:30,036 --> 00:25:35,197
So you guys were actually in engine at game time

423
00:25:35,197 --> 00:25:36,658
rendering your reflection maps.

424
00:25:36,658 --> 00:25:37,238
Is that to save space?

425
00:25:37,238 --> 00:25:40,158
To save disk space essentially, right?

426
00:25:40,158 --> 00:25:41,439
Yes, to save disk space.

427
00:25:41,439 --> 00:25:43,139
So did you only have to do that

428
00:25:43,139 --> 00:25:45,839
when the user would kind of cross over into that region?

429
00:25:45,839 --> 00:25:49,480
How often were you like refreshing those or?

430
00:25:50,790 --> 00:25:54,695
they were refreshed whenever there was time to do so.

431
00:25:54,695 --> 00:25:57,818
So it was a, I think it was classified

432
00:25:57,818 --> 00:26:00,301
as sort of a medium priority task

433
00:26:00,301 --> 00:26:02,203
along all of the other rendering tasks

434
00:26:02,203 --> 00:26:03,324
that are happening per frame.

435
00:26:03,324 --> 00:26:05,066
So it's not happening 30 times per second.

436
00:26:05,066 --> 00:26:07,248
It's not happening 30 times per second.

437
00:26:07,248 --> 00:26:11,413
I think it's probably happening about twice a second.

438
00:26:12,337 --> 00:26:15,819
the reflection maps would get updated

439
00:26:15,819 --> 00:26:18,761
about twice a second on average.

440
00:26:18,761 --> 00:26:20,423
That seemed to be fine.

441
00:26:20,423 --> 00:26:21,323
All right, thank you.

442
00:26:21,323 --> 00:26:27,108
Hi, I might have misheard you earlier,

443
00:26:27,108 --> 00:26:29,069
but I heard you mention lightmaps,

444
00:26:29,069 --> 00:26:33,793
and were you speaking specifically about the GI lightmaps

445
00:26:33,793 --> 00:26:35,734
you were using or geometry lightmaps?

446
00:26:35,734 --> 00:26:38,276
You mean light grids?

447
00:26:38,276 --> 00:26:40,618
I thought you said lightmaps specifically, but...

448
00:26:42,988 --> 00:26:47,552
I guess the question is, did you use lightmaps for geometry?

449
00:26:47,552 --> 00:26:50,914
Or was it just the grids that were generated?

450
00:26:50,914 --> 00:26:54,938
Light grids were used for generating the samples

451
00:26:54,938 --> 00:26:57,019
used for the global illumination.

452
00:26:57,019 --> 00:26:58,220
Right.

453
00:26:58,220 --> 00:27:01,183
And light probes were used for the specular and reflection.

454
00:27:01,183 --> 00:27:04,946
In addition, there are real-time sources of illumination

455
00:27:04,946 --> 00:27:05,847
all over the game.

456
00:27:05,847 --> 00:27:06,067
Right.

457
00:27:06,067 --> 00:27:07,508
For direct illumination.

458
00:27:07,508 --> 00:27:08,068
Gotcha, thanks.

459
00:27:14,196 --> 00:27:19,098
With the light grids, how many points along the time of day did you capture those?

460
00:27:20,467 --> 00:27:23,489
So there are four times, the question is for the light grids,

461
00:27:23,489 --> 00:27:26,091
how many times a day did we sample?

462
00:27:26,091 --> 00:27:30,775
And there are four times a day in the game.

463
00:27:30,775 --> 00:27:33,577
We have sort of daytime noon lighting,

464
00:27:33,577 --> 00:27:35,559
we have sunset lighting,

465
00:27:35,559 --> 00:27:39,542
we have a foggy rainy day lighting,

466
00:27:39,542 --> 00:27:43,625
and we have nighttime lighting.

467
00:27:43,625 --> 00:27:45,447
So each of the light grids was generated

468
00:27:45,447 --> 00:27:47,148
at each of those times a day.

469
00:27:47,148 --> 00:27:47,348
Thank you.

470
00:27:47,348 --> 00:27:49,070
Hey.

471
00:27:49,745 --> 00:27:55,813
You talked about reflection probes and indirect lighting data using the probes, but what about

472
00:27:55,813 --> 00:27:56,274
the shadows?

473
00:27:56,274 --> 00:28:01,300
And I'm assuming everything is dynamic, but these buildings are so huge and they cast

474
00:28:01,300 --> 00:28:02,822
like dynamic shadows.

475
00:28:02,822 --> 00:28:04,384
So what's the resolution?

476
00:28:04,384 --> 00:28:06,446
How is the optimization for that implemented?

477
00:28:07,137 --> 00:28:09,840
The question is, how did we optimize for shadows

478
00:28:09,840 --> 00:28:11,001
and handle the shadows?

479
00:28:11,001 --> 00:28:16,365
So, that's an interesting topic I didn't really touch on

480
00:28:16,365 --> 00:28:19,268
in my talk, maybe I could have.

481
00:28:19,268 --> 00:28:24,412
But using the light probes and the imposters,

482
00:28:24,412 --> 00:28:28,015
we were able to generate occlusion maps.

483
00:28:28,776 --> 00:28:31,398
for the different times of day.

484
00:28:31,398 --> 00:28:32,959
In addition to the light probe,

485
00:28:32,959 --> 00:28:34,960
each light probe has a draw list

486
00:28:34,960 --> 00:28:40,124
of what buildings are visible to that light probe.

487
00:28:40,124 --> 00:28:43,706
So if a building is not visible to the light probe,

488
00:28:43,706 --> 00:28:48,290
it can be placed into the list of the occlusion map.

489
00:28:48,290 --> 00:28:54,134
I'm not completely familiar with all of the technology

490
00:28:54,134 --> 00:28:56,315
that was used for that technique.

491
00:28:56,891 --> 00:29:01,232
But again, that was Tony Archulio in our core rendering team

492
00:29:01,232 --> 00:29:03,433
who devised that system.

493
00:29:03,433 --> 00:29:05,214
And the imposters sort of helped,

494
00:29:05,214 --> 00:29:07,314
the imposters and the light probes

495
00:29:07,314 --> 00:29:11,235
helped inform that system to make optimized choices.

496
00:29:11,235 --> 00:29:12,656
Just another follow up,

497
00:29:12,656 --> 00:29:14,837
did you use like a mix shadowing

498
00:29:14,837 --> 00:29:18,598
where you used to bake the shadows too far off

499
00:29:18,598 --> 00:29:20,558
and then have dynamic in which were closer?

500
00:29:20,558 --> 00:29:24,640
There aren't really any baked shadows that I'm aware of.

501
00:29:25,301 --> 00:29:31,788
Obviously, the global illumination is baked, the samples are baked, so if something is

502
00:29:31,788 --> 00:29:36,173
in shadow in those samples, that is cached data.

503
00:29:36,173 --> 00:29:43,140
But that's not being, that's not considering any of the direct illumination from the game.

504
00:29:45,967 --> 00:29:49,749
So I think we've got time for one more question.

505
00:29:49,749 --> 00:29:50,349
Yes.

506
00:29:50,349 --> 00:29:53,871
So the 128 by 128 meter tiles, how many of those, on average,

507
00:29:53,871 --> 00:29:56,072
were you able to fit into memory?

508
00:29:56,072 --> 00:29:57,893
Because the whole city was imposters,

509
00:29:57,893 --> 00:30:01,234
but then you had, I'm sure you had more than one of them

510
00:30:01,234 --> 00:30:01,815
loaded at a time.

511
00:30:01,815 --> 00:30:03,295
So how many, for average, did you have?

512
00:30:03,295 --> 00:30:04,816
So there would be.

513
00:30:06,568 --> 00:30:11,410
I don't know about an average, but the goal was to be able to have a tile and its neighbors

514
00:30:11,410 --> 00:30:13,672
streamed into memory, so nine tiles.

515
00:30:13,672 --> 00:30:19,735
The tile that Spider-Man would currently be in would be streamed in, or the model instance

516
00:30:19,735 --> 00:30:23,917
would be drawn at full resolution, and then there's, in addition to the imposter system,

517
00:30:23,917 --> 00:30:29,140
there's a more standard LOD system to handle neighboring tiles, for example.

518
00:30:29,660 --> 00:30:33,202
I believe there were also some optimizations put in place

519
00:30:33,202 --> 00:30:36,384
so that when Spider-Man is moving quickly,

520
00:30:36,384 --> 00:30:39,787
we sort of predict where he's gonna go

521
00:30:39,787 --> 00:30:42,408
and we don't load the tiles behind him necessarily.

522
00:30:42,408 --> 00:30:46,371
We sort of figure out what his likely frustum of travel

523
00:30:46,371 --> 00:30:49,693
is gonna be at any time and just load those tiles in

524
00:30:49,693 --> 00:30:51,094
if he's moving at a really fast clip.

525
00:30:51,094 --> 00:30:55,277
And we do that to avoid load time frame dropouts

526
00:30:55,277 --> 00:30:56,478
and stuff like that.

527
00:30:56,478 --> 00:30:57,418
Thanks a lot.

528
00:30:57,418 --> 00:30:58,639
Thank you very much.

