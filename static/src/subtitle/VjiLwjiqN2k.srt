1
00:00:11,526 --> 00:00:15,467
Hi, everyone. Welcome to GDC.

2
00:00:15,467 --> 00:00:19,909
Today our topic is finding harmony in anime style and physically based rendering.

3
00:00:19,909 --> 00:00:25,271
So first, a brief introduction about me and my team.

4
00:00:25,271 --> 00:00:31,033
My name is Chen Zhou. I joined NetEase Games back in 2014 and work for Tensha division.

5
00:00:31,689 --> 00:00:35,590
which is one known that is game studios with teams in Hong Kong

6
00:00:35,590 --> 00:00:38,351
and also in Guangzhou and Shanghai.

7
00:00:38,351 --> 00:00:40,872
As a technical lead, my work is mainly

8
00:00:40,872 --> 00:00:44,273
focused on game engine and graphics development,

9
00:00:44,273 --> 00:00:47,994
collaborating with artists and technical artists

10
00:00:47,994 --> 00:00:50,274
to build games with nice looking visuals

11
00:00:50,274 --> 00:00:52,815
and acceptable performance budgets.

12
00:00:52,815 --> 00:00:55,496
Over the years, I have worked on and shipped

13
00:00:55,496 --> 00:00:57,416
several online mobile games.

14
00:00:57,416 --> 00:01:01,097
As you can see, most of them are manga or anime styled.

15
00:01:03,141 --> 00:01:06,743
Currently, we are working on Exordino 1's Mirage,

16
00:01:06,743 --> 00:01:10,125
which is a multi-character RPG based on the same IP

17
00:01:10,125 --> 00:01:14,068
as our online game, Exordino 1's MOBA.

18
00:01:14,068 --> 00:01:16,269
Here is a real-time rendering from the game.

19
00:01:16,269 --> 00:01:22,513
For this game, we are trying to create a world

20
00:01:22,513 --> 00:01:25,415
that combines the art style of anime

21
00:01:25,415 --> 00:01:27,936
and elements of photorealism

22
00:01:27,936 --> 00:01:31,338
with nearly 100 playable characters and over 100 levels.

23
00:01:32,082 --> 00:01:35,403
including indoor settings with complex lighting,

24
00:01:35,403 --> 00:01:38,344
modern day city, and outdoor environments

25
00:01:38,344 --> 00:01:40,785
in both day and night conditions,

26
00:01:40,785 --> 00:01:42,726
which brings us to today's topic.

27
00:01:42,726 --> 00:01:45,987
The game's targeting all platforms

28
00:01:45,987 --> 00:01:48,608
on mobile devices and PCs,

29
00:01:48,608 --> 00:01:52,550
and it's built with our in-house game engine, Messiah.

30
00:01:52,550 --> 00:01:56,331
I should point out, since the game's still in development,

31
00:01:56,331 --> 00:01:59,933
so any images shown here don't represent the final quality.

32
00:02:03,452 --> 00:02:06,715
This presentation is split into two parts.

33
00:02:06,715 --> 00:02:08,697
Part one is some background knowledge

34
00:02:08,697 --> 00:02:12,500
on the anime art style, its typical characteristics,

35
00:02:12,500 --> 00:02:14,842
traditional cell shading techniques,

36
00:02:14,842 --> 00:02:18,084
its real-world limitations, and some possible solutions

37
00:02:18,084 --> 00:02:21,848
for combining cell shading and physically-based rendering.

38
00:02:21,848 --> 00:02:25,210
While in part two, I'll introduce our goals and methods

39
00:02:25,210 --> 00:02:27,332
for building a physics-based game world

40
00:02:27,332 --> 00:02:30,615
while preserving notable anime features in our characters.

41
00:02:31,215 --> 00:02:34,237
using a single pass deferred rendering pipeline,

42
00:02:34,237 --> 00:02:35,918
special lighting and shadow techniques

43
00:02:35,918 --> 00:02:39,900
with customized shading models, as well as an in-game look

44
00:02:39,900 --> 00:02:43,062
dev pipeline we built for integrating characters

45
00:02:43,062 --> 00:02:45,383
with all the environments.

46
00:02:45,383 --> 00:02:48,185
And finally, conclusions.

47
00:02:48,185 --> 00:02:50,427
So first, what is an anime art style?

48
00:02:50,427 --> 00:02:53,749
Or in other words, what makes characters

49
00:02:53,749 --> 00:02:55,890
feel like they are anime?

50
00:02:55,890 --> 00:02:59,172
Here is a classic theme from the traditional 2D animation.

51
00:03:00,037 --> 00:03:02,458
we can see a lot of traits of anime in this scene.

52
00:03:02,458 --> 00:03:06,560
Looking at the character, the most obvious clue

53
00:03:06,560 --> 00:03:09,421
is a flat face with manualized colors and shadows.

54
00:03:09,421 --> 00:03:13,242
Another clue is the silhouette lines,

55
00:03:13,242 --> 00:03:16,783
which are important for creating a sense of form and structure.

56
00:03:16,783 --> 00:03:19,104
For example, a piece of curved line

57
00:03:19,104 --> 00:03:21,645
can become the character's nose.

58
00:03:21,645 --> 00:03:24,186
And if we look closer, we see the face

59
00:03:24,186 --> 00:03:26,187
is in a non-perspective projection.

60
00:03:26,848 --> 00:03:32,511
which is just saying, the size and position of mouth and nose are off-center.

61
00:03:32,511 --> 00:03:35,612
The mouth is a bit off to the right.

62
00:03:35,612 --> 00:03:40,414
Moving on to the hair, the character's hair has a ring-like and stroking specular shine.

63
00:03:40,414 --> 00:03:43,475
We like to call this a shiny headband.

64
00:03:43,475 --> 00:03:46,197
And then the eyes and eyebrows.

65
00:03:46,197 --> 00:03:51,019
They can be partially blocked by locks of hair, but redrawn on top of it.

66
00:03:51,019 --> 00:03:53,400
We call this the see-through hair.

67
00:03:54,425 --> 00:03:59,049
And to keep the clean look of anime images, especially around the face,

68
00:03:59,049 --> 00:04:02,372
in most cases, they use only one main light source,

69
00:04:02,372 --> 00:04:07,957
and the shadows have hard edges formed by hair blocking the light.

70
00:04:07,957 --> 00:04:11,420
These traits are the stylistic conventions of anime creators

71
00:04:11,420 --> 00:04:14,402
formed over many decades, and they come together

72
00:04:14,402 --> 00:04:18,105
to form the anime art style that audiences have come to expect.

73
00:04:19,212 --> 00:04:21,693
To render this art style in real time,

74
00:04:21,693 --> 00:04:24,014
a lot of solutions have already been explored,

75
00:04:24,014 --> 00:04:27,617
thanks to the emergence and popularity of anime games

76
00:04:27,617 --> 00:04:30,418
on the market.

77
00:04:30,418 --> 00:04:33,940
So we started to work on our first Toon style game in 2014.

78
00:04:33,940 --> 00:04:37,142
And to get our feet wet, we first

79
00:04:37,142 --> 00:04:39,944
experimented with 2D sprites.

80
00:04:39,944 --> 00:04:42,705
Because it was simple and 100% controllable by concept

81
00:04:42,705 --> 00:04:46,207
artists, we used the morph animation

82
00:04:46,207 --> 00:04:47,508
for each piece of sprite.

83
00:04:48,132 --> 00:04:52,796
and the shading is simple, just samples the texture and blends with the unified globe

84
00:04:52,796 --> 00:04:58,520
lighting from Scene Ambient Map. This had the added benefit of being performance friendly

85
00:04:58,520 --> 00:05:05,726
for mobile devices at that time. I might add, in recent years, other games have started

86
00:05:05,726 --> 00:05:11,651
using additional techniques for 2D, like adding localized lighting and rigging, which brings

87
00:05:11,651 --> 00:05:13,492
more variety to the sprites tag.

88
00:05:15,152 --> 00:05:22,574
Then in 2015, inspired by the GDC talk Guilty Gear XR Artstyle, we started to explore cell

89
00:05:22,574 --> 00:05:24,735
shading in our game.

90
00:05:24,735 --> 00:05:29,916
Cell shading, also known as toon shading, is a type of non-photorealistic rendering

91
00:05:29,916 --> 00:05:33,837
technique designed to make computer graphics appear like they are hand-drawn.

92
00:05:34,187 --> 00:05:39,409
The basic principle is pretty intuitive. To reduce the color gradient to a base color

93
00:05:39,409 --> 00:05:44,652
and a shadow color, a step function is used by passing the dot product of normal vector

94
00:05:44,652 --> 00:05:50,474
from geometry and the light direction. And after that, we can add outline slats to

95
00:05:50,474 --> 00:05:56,337
the geometry during post-processing, using edge detection or natural backface paths with

96
00:05:56,337 --> 00:05:57,097
vertex biasing.

97
00:05:59,112 --> 00:06:05,173
We explore a lot of techniques or tricks in real-time cel shading in our previous games.

98
00:06:05,173 --> 00:06:09,915
As shown on the right, most of them focus on character rendering.

99
00:06:09,915 --> 00:06:16,196
For example, fixed or per-character lighting to get the best look for each individual character.

100
00:06:16,196 --> 00:06:20,617
We can use smooth step functions to create tiny gradients between light and dark for

101
00:06:20,617 --> 00:06:25,139
the skin, which mimics the feel of subsurface scattering.

102
00:06:25,139 --> 00:06:28,400
We also use multi-channel rep textures for easier artist control.

103
00:06:29,479 --> 00:06:32,541
modified normal vector in vertices for lighting,

104
00:06:32,541 --> 00:06:35,243
and pre-integrated facial shadow masks

105
00:06:35,243 --> 00:06:36,764
to suit most light directions,

106
00:06:36,764 --> 00:06:39,666
and customized tone mappings

107
00:06:39,666 --> 00:06:42,909
to enhance color precision in HDR pipeline,

108
00:06:42,909 --> 00:06:44,089
and many others so on.

109
00:06:44,089 --> 00:06:48,012
All of them are designed to keep the final shading result

110
00:06:48,012 --> 00:06:50,354
as close as possible to the anime art style,

111
00:06:50,354 --> 00:06:52,275
a hand-drawn concept art.

112
00:06:54,947 --> 00:07:00,429
So shading is great for making games look like anime, especially for the characters,

113
00:07:00,429 --> 00:07:06,572
because most 2D animations focus on the characters and less on the environment.

114
00:07:06,572 --> 00:07:09,473
But for games, that's not always true.

115
00:07:09,473 --> 00:07:14,536
In our previous game, MMORPG set in modern day city,

116
00:07:14,536 --> 00:07:18,478
cell shading had limited our environment design and in turn,

117
00:07:18,478 --> 00:07:20,959
diminished the player exploration experience.

118
00:07:21,755 --> 00:07:25,938
and it was hard to create complex scenes with lots of details,

119
00:07:25,938 --> 00:07:28,059
since hand-drawing the base color

120
00:07:28,059 --> 00:07:31,301
is a critical part of the cell shading process.

121
00:07:31,301 --> 00:07:34,043
This step didn't have clear standards,

122
00:07:34,043 --> 00:07:37,325
so results varied from artist to artist.

123
00:07:37,325 --> 00:07:40,868
Last but not least, as mobile devices grew rapidly

124
00:07:40,868 --> 00:07:44,170
in terms of performance, many modern rendering techniques

125
00:07:44,170 --> 00:07:46,792
become feasible on all platforms.

126
00:07:46,792 --> 00:07:48,973
But we found it very hard to introduce them

127
00:07:48,973 --> 00:07:50,815
into a game based on cell shading.

128
00:07:52,312 --> 00:07:57,557
Compared to traditional cell shading, physically-based rendering imposes fewer restrictions.

129
00:07:57,557 --> 00:08:04,422
It describes both the mathematical theory as well as its practical implementations.

130
00:08:04,422 --> 00:08:10,067
PBR decouples material and lighting, so it is easy to create assets which are well-suited

131
00:08:10,067 --> 00:08:12,589
to all kinds of lighting environments.

132
00:08:12,589 --> 00:08:18,153
A wide range of materials can be defined quantitatively using close-to-real-world physical parameters.

133
00:08:18,958 --> 00:08:24,701
And most important of all, the standardized PBR production process has been widely adopted

134
00:08:24,701 --> 00:08:26,583
by the game industry.

135
00:08:26,583 --> 00:08:32,246
And that level of universal acceptance means game asset creation can be outsourced to many

136
00:08:32,246 --> 00:08:39,211
external suppliers, which is very helpful for building a large game world.

137
00:08:39,211 --> 00:08:44,294
So we started to explore the possibility of creating a physics-based world while keeping

138
00:08:44,294 --> 00:08:45,155
anime charms.

139
00:08:45,853 --> 00:08:51,836
Here is a side-by-side comparison of the concept art from our current Extraordinary Ones MOBA

140
00:08:51,836 --> 00:08:55,537
and our upcoming new game based on the same IP.

141
00:08:55,537 --> 00:09:01,279
We found that skin, especially around the face, eyes and hair are the major factor of

142
00:09:01,279 --> 00:09:03,400
what gives us the look and feel of anime.

143
00:09:03,400 --> 00:09:10,163
Imagine a photorealistic head on a cartoony body that would feel really bizarre and out

144
00:09:10,163 --> 00:09:14,725
of place, but the reverse actually feels quite harmonious.

145
00:09:15,945 --> 00:09:22,031
Realistic materials on cloth, such as silks, velvet, or translucent materials are acceptable,

146
00:09:22,031 --> 00:09:29,538
and complex lighting and shadow will be a plus as long as they contribute a harmonious overall look to the character.

147
00:09:29,538 --> 00:09:40,288
To prove this opinion, we conducted a survey with these two concept arts above, among a group of core players from our Extraordinary Ones MOBA game.

148
00:09:41,325 --> 00:09:48,330
Everyone interviewed agreed that both pictures are the same anime character that they are currently playing in-game,

149
00:09:48,330 --> 00:09:54,314
and over 70% of people prefer the new version on the right, and most of them are anime fans.

150
00:09:54,314 --> 00:09:59,739
So here comes the goals for our game's graphics.

151
00:09:59,739 --> 00:10:02,441
Combine the look and feel of anime and PBR,

152
00:10:02,441 --> 00:10:08,865
build a wide variety of materials suited for all kinds of lighting environments,

153
00:10:08,865 --> 00:10:11,147
and take advantage of modern rendering techniques.

154
00:10:11,578 --> 00:10:18,962
while keeping the graphics flexible to handle everything from low-end mobile devices to high-end PCs,

155
00:10:18,962 --> 00:10:23,644
and try to keep a low overhead and be compatible with as many devices as possible.

156
00:10:23,644 --> 00:10:28,746
This is what we get in our game.

157
00:10:28,746 --> 00:10:33,028
As you can see, the entire environment is under photorealism,

158
00:10:33,028 --> 00:10:37,810
while most of the traits of the anime mentioned above can be found on the character.

159
00:10:39,547 --> 00:10:47,169
So in general, our approach is to create a graphics pipeline using a photorealistic deferred shading framework,

160
00:10:47,169 --> 00:10:55,091
supporting various factors such as sunlight, local lights, global illumination, shadows, and ambient occlusion,

161
00:10:55,091 --> 00:11:02,274
but adding special shading models for parts of the character, like rendering skin, hair, and eyes,

162
00:11:02,274 --> 00:11:07,655
and preserving the constraints of energy conservation when integrating different BXDF functions.

163
00:11:08,751 --> 00:11:11,032
We implemented custom rendering techniques

164
00:11:11,032 --> 00:11:14,635
to imitate noble features into the anime, which leads

165
00:11:14,635 --> 00:11:16,176
to a very similar look and feel.

166
00:11:16,176 --> 00:11:19,558
And we built an in-game look dev pipeline

167
00:11:19,558 --> 00:11:22,440
for character and the environment artists

168
00:11:22,440 --> 00:11:25,402
to perform sanity checks on material captures

169
00:11:25,402 --> 00:11:28,104
and ensure the overall shading result looks

170
00:11:28,104 --> 00:11:30,725
harmonious from all feasible positions

171
00:11:30,725 --> 00:11:33,207
and angles in the game world.

172
00:11:33,207 --> 00:11:38,030
Here is our Minimoji buffer layout for mobile devices.

173
00:11:38,603 --> 00:11:42,824
which is designed to be compatible and performant for as many devices as possible.

174
00:11:42,824 --> 00:11:44,184
At the low end,

175
00:11:44,184 --> 00:11:48,185
our devices with max color attachments equals to 4 on the GLES,

176
00:11:48,185 --> 00:11:51,906
which keeps the color buffer as thin as 128 bits

177
00:11:51,906 --> 00:11:56,047
to meet the performance guidance of Mali GPUs.

178
00:11:56,047 --> 00:12:00,948
Thanks to the TBDR architecture of modern mobile GPUs,

179
00:12:00,948 --> 00:12:04,509
fragment shaders can read the render target's data from tile memory.

180
00:12:05,126 --> 00:12:09,007
perform calculations, and write composition results back.

181
00:12:09,007 --> 00:12:12,289
The tree buffer generating, deferred lighting,

182
00:12:12,289 --> 00:12:16,610
and composition are implemented in a single render pass.

183
00:12:16,610 --> 00:12:19,812
This is very important, not only for deferred shading

184
00:12:19,812 --> 00:12:22,172
with limited memory and bandwidth,

185
00:12:22,172 --> 00:12:25,214
but also some custom animated stylization passes

186
00:12:25,214 --> 00:12:26,414
we will introduce later.

187
00:12:28,779 --> 00:12:36,567
First, the main light source, mostly the sun and moon when outdoors, or some major local light when indoors.

188
00:12:36,567 --> 00:12:44,636
To support variety shading models for characters such as skin, hair, and eyes, we use a hybrid forward and deferred lighting method.

189
00:12:45,580 --> 00:12:51,526
For the forward part, when generating the G-buffers, we calculate the indirect light,

190
00:12:51,526 --> 00:12:57,953
using baked light maps for static models to restore light info, while dynamic models interpolating

191
00:12:57,953 --> 00:13:03,438
the SH coefficients from light probes to get the incident lighting function.

192
00:13:03,438 --> 00:13:06,121
Materials emission is also added to G-buffer A.

193
00:13:07,287 --> 00:13:10,029
As for those anime-style shading models,

194
00:13:10,029 --> 00:13:13,591
they are shaded with indirect and direct main light

195
00:13:13,591 --> 00:13:15,432
while the GBuffer is being generated.

196
00:13:15,432 --> 00:13:19,434
And the results are also stored into GBufferA,

197
00:13:19,434 --> 00:13:22,696
just like what we normally do in a forward rendering pipeline.

198
00:13:22,696 --> 00:13:27,278
One beetle stencil is marked as forward-shaded,

199
00:13:27,278 --> 00:13:30,540
so those pixels get masked out when the GPU comes

200
00:13:30,540 --> 00:13:32,061
to this particular main light.

201
00:13:33,552 --> 00:13:41,976
The reason for pre-calculating the main light is that not all parameters for anime-style shading models can be held in the limited GBuffer channels.

202
00:13:41,976 --> 00:13:53,122
This step also gives a speed boost for the lighting path, since fewer branch instructions are needed for integrating different BXDFs in Fragment Shader.

203
00:13:53,122 --> 00:14:01,947
We also sample the Cascadia shadow map, EMV map for image-based specular lighting, and a real-time reflection map in the base and lighting paths.

204
00:14:02,614 --> 00:14:04,696
which is done by a lot of other games as well.

205
00:14:04,696 --> 00:14:10,282
A significant advantage of deferred shading is that

206
00:14:10,282 --> 00:14:12,845
we have an easier time rendering large numbers

207
00:14:12,845 --> 00:14:14,726
of dynamic lights.

208
00:14:14,726 --> 00:14:17,469
These local lights helps a lot to make the environment

209
00:14:17,469 --> 00:14:22,014
and the character looks well-integrated.

210
00:14:22,014 --> 00:14:24,697
We put all the point, spot, and red lights

211
00:14:24,697 --> 00:14:25,958
in a single sub-path.

212
00:14:26,678 --> 00:14:32,261
The number of shadow-producing lights is limited according to the device performance level.

213
00:14:32,261 --> 00:14:37,424
Shadow maps are cached for those shadow lights and updated when needed.

214
00:14:37,424 --> 00:14:45,129
Other non-shadow lights often act as ambient lights and are drawn instance with simple calculations.

215
00:14:45,129 --> 00:14:54,175
For devices with Apple A11 and later, rest-order groups helps to increase the parallelization of the GPU's fragment shader for shading all these lights.

216
00:14:56,392 --> 00:15:01,955
The most notable trait of anime characters are their flat faces.

217
00:15:01,955 --> 00:15:07,258
We implement this using the intuitive method of shifting normals to the face's forward

218
00:15:07,258 --> 00:15:08,539
vector.

219
00:15:08,539 --> 00:15:14,182
The curve intensity is provided by a texture, so artists get precise control of lighting

220
00:15:14,182 --> 00:15:15,463
in the face.

221
00:15:15,463 --> 00:15:20,266
For example, the soft edges of the cheeks and the shadows around the nose tip.

222
00:15:20,266 --> 00:15:25,649
Flat faces and slanted normals are not enough because they can be modified by scanning the

223
00:15:25,649 --> 00:15:26,190
animation.

224
00:15:26,759 --> 00:15:31,162
and aren't very accurate after interpolation.

225
00:15:31,162 --> 00:15:32,803
The lighting equations are kept the same,

226
00:15:32,803 --> 00:15:35,565
except we specify a normal vector for calculation,

227
00:15:35,565 --> 00:15:38,247
so the face can still interface

228
00:15:38,247 --> 00:15:41,209
with multiple local lights naturally.

229
00:15:41,209 --> 00:15:43,571
And to avoid flickering lights on the character

230
00:15:43,571 --> 00:15:48,854
during slight movements, such as breathing.

231
00:15:48,854 --> 00:15:52,096
The face samples lower degree of spherical harmonics

232
00:15:52,096 --> 00:15:53,157
for the GI part.

233
00:15:56,365 --> 00:16:01,629
The flat face gets along quite well with physically based materials in the front view,

234
00:16:01,629 --> 00:16:05,591
but sometimes gets an overexposed color when looked at from the side,

235
00:16:05,591 --> 00:16:07,813
under certain lighting angles.

236
00:16:07,813 --> 00:16:13,456
The lighting with a specified normal vector pointing forward from the face is mathematically correct,

237
00:16:13,456 --> 00:16:18,219
but the resulting image looks off when viewed from the right.

238
00:16:18,219 --> 00:16:21,402
Here is a set of diagrams to illustrate this problem.

239
00:16:22,463 --> 00:16:26,585
For normal human faces, light reflection is a range of values,

240
00:16:26,585 --> 00:16:30,766
while the flat anime face acts as one single plane.

241
00:16:30,766 --> 00:16:33,467
So now our solution is for local lights,

242
00:16:33,467 --> 00:16:37,208
no casting shadows, to reweight the light from VXDF

243
00:16:37,208 --> 00:16:39,508
using a wrap function affected by V dot L.

244
00:16:39,508 --> 00:16:43,530
And for the main light, we use a precomputed path

245
00:16:43,530 --> 00:16:46,590
for statistical coverage calculation

246
00:16:46,590 --> 00:16:50,071
using a shadow map, which will be mentioned later.

247
00:16:51,587 --> 00:16:57,531
By doing this, we get a more natural-looking result.

248
00:16:57,531 --> 00:17:00,473
And for rendering skin other than the face,

249
00:17:00,473 --> 00:17:02,334
we use a different shading model.

250
00:17:02,334 --> 00:17:06,197
To make skin on the body feel like part of the environment,

251
00:17:06,197 --> 00:17:08,038
we use the same lighting equations

252
00:17:08,038 --> 00:17:09,419
as physically-based materials,

253
00:17:09,419 --> 00:17:12,361
but intentionally manipulate the colors.

254
00:17:13,625 --> 00:17:18,830
Instead of an artist giving us a shadow color or a ramp texture, like in traditional cell

255
00:17:18,830 --> 00:17:24,035
shading, the color manipulation is hard-coded and then turned into a formula for the pixel

256
00:17:24,035 --> 00:17:24,896
shader.

257
00:17:24,896 --> 00:17:30,922
This is important especially for multi-character games, since hand-drawn colors differ from

258
00:17:30,922 --> 00:17:36,087
artist to artist, which will lead to a lot of color variance when placing multiple characters

259
00:17:36,087 --> 00:17:36,988
into a single shot.

260
00:17:36,988 --> 00:17:39,010
For this shading model,

261
00:17:39,424 --> 00:17:43,767
We preserve the anime characteristic of hard transitions from light to dark.

262
00:17:43,767 --> 00:17:49,210
Then we shift the hue by the luminance of direct light and increase saturation,

263
00:17:49,210 --> 00:17:56,915
especially for dark areas and edges, according to the saturation of direct and indirect lights.

264
00:17:56,915 --> 00:18:04,079
By manipulating the color, we get enhanced structural details and better contrast.

265
00:18:04,079 --> 00:18:06,240
Next, we'll talk about shadow rendering.

266
00:18:06,993 --> 00:18:12,235
Most cell shading games don't bother with incrementing casted shadow for their characters,

267
00:18:12,235 --> 00:18:18,216
since they usually calculate a generalized shadow color using a well-designed algorithm.

268
00:18:18,216 --> 00:18:24,318
While for PBR, detailed shadows and ambient occlusions are important components.

269
00:18:24,318 --> 00:18:29,559
We need to make the two co-exist harmoniously, since many parts of the character's body use

270
00:18:29,559 --> 00:18:36,300
realistic materials. Like a lot of games, we use a cascaded shadow map for the main light.

271
00:18:37,109 --> 00:18:42,110
And since anime-style cutscenes often feature extreme close-up shots,

272
00:18:42,110 --> 00:18:45,771
where the character's face might occupy the entire screen,

273
00:18:45,771 --> 00:18:48,071
the shadows also need to be high quality,

274
00:18:48,071 --> 00:18:52,412
especially self-shadows produced by fringe soloxel hair,

275
00:18:52,412 --> 00:18:55,373
which are the only form structures on top of a flat face.

276
00:18:55,373 --> 00:19:00,554
And we have to create hard outline shadows for our anime-style faces.

277
00:19:02,092 --> 00:19:09,278
This is showing the same cutscene, but with different ranges for the lightbox, from 0.2 to 0.8.

278
00:19:09,278 --> 00:19:19,107
As we can see in the image, traditional per-object shadow map like the 0.8 result still leads to soft shadows around the face,

279
00:19:19,107 --> 00:19:21,530
which is not what we want for our anime style.

280
00:19:23,394 --> 00:19:29,118
To achieve more accurate close-up shadows, we implemented a view-adaptive shadow system

281
00:19:29,118 --> 00:19:34,601
for cutscenes that support distances from close-ups to multi-person wide shots.

282
00:19:34,601 --> 00:19:40,244
This is done by calculating several pivot point capsules in screen space, then adjusting

283
00:19:40,244 --> 00:19:45,808
the center position and size of frustum when generating shadow map of the first cascade

284
00:19:45,808 --> 00:19:49,390
to frame the characters tightly within the camera.

285
00:19:49,390 --> 00:19:52,992
The adaptive algorithm can be fitted for nearly all the shots in the game.

286
00:19:53,533 --> 00:19:56,555
and it's how we achieve that point two shot above.

287
00:19:56,555 --> 00:20:00,938
But there are still edge cases that require manual adjustment.

288
00:20:00,938 --> 00:20:03,279
We provide a one-click method for artists

289
00:20:03,279 --> 00:20:05,721
to adjust the shadow as they see fit

290
00:20:05,721 --> 00:20:07,842
and align it for timeline frames.

291
00:20:07,842 --> 00:20:11,625
Lighting and shadow can be customized

292
00:20:11,625 --> 00:20:13,466
for individual shots during cut scenes,

293
00:20:13,466 --> 00:20:16,728
while it doesn't work with outdoor environments

294
00:20:16,728 --> 00:20:18,229
due to the time of day system.

295
00:20:19,115 --> 00:20:26,419
We added a hair shadow proxy pass to create a nice self-shadow on face under any lighting circumstances.

296
00:20:26,419 --> 00:20:33,002
A simplified skeletal mesh with the same skinny data as the hair is drawn between GBuffer and lighting,

297
00:20:33,002 --> 00:20:38,064
with a slight vertex position offset according to the face vector and main light direction.

298
00:20:38,064 --> 00:20:46,468
We fetch the basic data from GBuffer and overwrite the result by recalculating only the indirect light from light props.

299
00:20:47,172 --> 00:20:48,813
we weaken the indirect light result

300
00:20:48,813 --> 00:20:53,015
so that the hair shadow look is always there,

301
00:20:53,015 --> 00:20:56,417
even viewed from the backlight.

302
00:20:56,417 --> 00:21:00,219
From this perspective, the hair shadow proxy

303
00:21:00,219 --> 00:21:04,301
logically works as a shadow and ambient occlusion path.

304
00:21:04,301 --> 00:21:06,782
And it's only applied to the face,

305
00:21:06,782 --> 00:21:12,165
since we can determine that by the underlying shading model

306
00:21:12,165 --> 00:21:12,345
ID.

307
00:21:12,345 --> 00:21:14,406
Besides self-shadows, we also wanted

308
00:21:14,406 --> 00:21:16,287
to have environment shadows in our game.

309
00:21:17,247 --> 00:21:19,027
which brings the partial shadow program.

310
00:21:19,027 --> 00:21:24,409
This is where light is masked out irregularly for the face.

311
00:21:24,409 --> 00:21:28,110
For instance, if a character was standing under a tree,

312
00:21:28,110 --> 00:21:31,371
there should be double shadows on his face.

313
00:21:31,371 --> 00:21:33,692
These shadows are totally out of control

314
00:21:33,692 --> 00:21:35,753
and makes the enemy face like a mess.

315
00:21:35,753 --> 00:21:40,334
So now our solution is to use a pre-compute path

316
00:21:40,334 --> 00:21:44,676
for all characters' face in a line-shaped render target.

317
00:21:46,190 --> 00:21:49,852
and we built a polygon for each face in FragmentShader,

318
00:21:49,852 --> 00:21:53,193
find the average in shadow value from the shadow maps,

319
00:21:53,193 --> 00:21:54,873
and store it into one pixel.

320
00:21:54,873 --> 00:21:58,394
Self-shadow is filtered out by adjusting the depth

321
00:21:58,394 --> 00:22:01,516
in light space when comparing to the shadow map

322
00:22:01,516 --> 00:22:03,856
on dynamic objects.

323
00:22:03,856 --> 00:22:06,957
Now, when we load the corresponding pixel,

324
00:22:06,957 --> 00:22:10,819
we get a flattened shadow on the face.

325
00:22:10,819 --> 00:22:13,240
Eight floats of uniform data for each character

326
00:22:13,240 --> 00:22:15,520
are passed to GPU for pre-computing.

327
00:22:16,298 --> 00:22:21,701
Notice that there is one standing for weather in the same character as last frame.

328
00:22:21,701 --> 00:22:27,565
As an added bonus, this gives us smooth shadow transitions temporarily for free, which is

329
00:22:27,565 --> 00:22:31,907
very helpful when navigating within the game.

330
00:22:31,907 --> 00:22:37,470
The anisotropic specular hair shine is a typical anime trait, also known as a shiny headband.

331
00:22:37,470 --> 00:22:43,934
We shade the hair with classic Kajiaki model, which shifts tangents along to the direction

332
00:22:43,934 --> 00:22:44,734
of the normal.

333
00:22:45,506 --> 00:22:50,030
But we don't use the traditional half-angle vector for strand specular lighting,

334
00:22:50,030 --> 00:22:52,512
because when there are multiple local lights nearby,

335
00:22:52,512 --> 00:22:57,277
the shine will become spread out across the hair strand in each direction,

336
00:22:57,277 --> 00:23:02,261
which while realistic, doesn't convey the sense of anime art.

337
00:23:02,261 --> 00:23:07,866
Instead, we use a fixed vector interpolated from view direction and main light direction.

338
00:23:08,523 --> 00:23:16,508
store the main light speculum mask into G-Buffer and reuse it instead of GGX for other local lights.

339
00:23:16,508 --> 00:23:21,391
By doing this, we get a concentrated anime shine spot as shown in figure 3.

340
00:23:21,391 --> 00:23:26,174
The see-through hair is another important trait in anime.

341
00:23:26,174 --> 00:23:31,437
Since the eyes and eyebrows are important for conveying the character's personality,

342
00:23:31,437 --> 00:23:34,639
some comic artists choose to draw them on top of the hair.

343
00:23:35,686 --> 00:23:42,389
The standard way to achieve a translucent look is using alpha blend, which doesn't work well here,

344
00:23:42,389 --> 00:23:47,091
because the shadows would also be blended and make the hair look dirty.

345
00:23:47,091 --> 00:23:53,254
We accomplish this effect by using programmable blending in the G-Buffer generating path.

346
00:23:53,254 --> 00:23:58,977
The hair is drawn with lowest priority, so the GPU can fetch the underlying shading model ID

347
00:23:58,977 --> 00:24:04,280
and distinguish the maxed out eyes to perform a differential blending.

348
00:24:05,429 --> 00:24:12,591
On devices that do not support separate blend mode, an extra draw path is needed for filling the other G-buffers.

349
00:24:12,591 --> 00:24:29,356
Since we are using a deferred rendering pipeline, traditional translucent materials are blended after the lighting path, which leads to inconsistent lighting results from opaque elements, because only constant lights are being calculated.

350
00:24:30,266 --> 00:24:35,488
To implement these materials correctly, we store the triangle face info inside the shading

351
00:24:35,488 --> 00:24:39,870
model ID with different diesel patterns stored in GBuffer.

352
00:24:39,870 --> 00:24:45,433
And we run a dedicated convolution blur path to do pattern recognization and correct multi-layer

353
00:24:45,433 --> 00:24:46,113
color blending.

354
00:24:46,113 --> 00:24:51,175
And finally, the colors are merged back into the scene using a stencil mask.

355
00:24:51,175 --> 00:24:59,059
Using silhouette lines and other notable features for anime will not exist in photorealistic

356
00:24:59,059 --> 00:24:59,599
rendering.

357
00:25:00,303 --> 00:25:05,749
We try to keep the outline as thin as 1 or 2 pixels by extruding normals in clip space,

358
00:25:05,749 --> 00:25:08,751
with consideration for the render target size.

359
00:25:08,751 --> 00:25:15,418
A second set of smoothed vertex normal data are stored in vertex color for use by Silhouette

360
00:25:15,418 --> 00:25:17,159
vertex shader.

361
00:25:17,159 --> 00:25:22,604
We draw the lines in GBuffer as ordinary render elements, with a specified shading model ID.

362
00:25:23,442 --> 00:25:31,431
By doing this this way, we preserve the ability to render these lines later to correspond with different environments,

363
00:25:31,431 --> 00:25:37,999
and also keep the right linear depth buffer for use in lighting and post-processes, for example depth of field.

364
00:25:37,999 --> 00:25:44,346
But because these lines are so thin, they may simply disappear after anti-aliasing.

365
00:25:45,360 --> 00:25:47,861
to deal with temporal anti-aliasing.

366
00:25:47,861 --> 00:25:50,982
We did some special treatment on those pixels

367
00:25:50,982 --> 00:25:54,483
in velocity buffer with less worldview projection

368
00:25:54,483 --> 00:25:56,904
to recalculate their precise position.

369
00:25:56,904 --> 00:26:01,486
Besides shading techniques,

370
00:26:01,486 --> 00:26:04,467
facial expression animations

371
00:26:04,467 --> 00:26:06,828
also contribute to the anime feel.

372
00:26:06,828 --> 00:26:08,789
Using non-perspective projection

373
00:26:08,789 --> 00:26:12,891
for the eyes, nose, and mouth is a notable feature in 2D.

374
00:26:13,530 --> 00:26:18,052
Anime characters often have large eyes, but tiny noses and mouths.

375
00:26:18,052 --> 00:26:24,394
This makes their 3D model look natural from the front, but off when viewed from the side.

376
00:26:24,394 --> 00:26:31,497
To prep for this, we built an adaptive facial modifier system based on 4 to 6 poses,

377
00:26:31,497 --> 00:26:34,418
manipulated from fixed angles by animation artists.

378
00:26:35,178 --> 00:26:38,159
and adjust the bone matrices at runtime,

379
00:26:38,159 --> 00:26:40,240
corresponding to the original animation data

380
00:26:40,240 --> 00:26:44,842
and the pitch and yaw of the camera in the facial space.

381
00:26:44,842 --> 00:26:49,503
We simplify the calculation at runtime.

382
00:26:49,503 --> 00:26:52,284
The modified bones are all set up

383
00:26:52,284 --> 00:26:54,925
using the same coordinate space.

384
00:26:54,925 --> 00:26:59,267
Since we are building a game with nearly 100 playable

385
00:26:59,267 --> 00:27:01,168
characters and over 100 levels.

386
00:27:01,787 --> 00:27:07,111
we need to check if the characters can integrate harmoniously with all the environments.

387
00:27:07,111 --> 00:27:12,055
We used a lot of custom shading models besides the standard TBR ones in our characters.

388
00:27:12,055 --> 00:27:18,259
So as the amount of scenes that needed to be checked grew, we built an in-game pipeline

389
00:27:18,259 --> 00:27:22,363
for validation and signed off new characters and environment assets.

390
00:27:23,133 --> 00:27:27,017
For characters, we provided artists with an engine look dev

391
00:27:27,017 --> 00:27:29,358
tool with fast environment switching

392
00:27:29,358 --> 00:27:31,500
and neatly arranged reference spheres

393
00:27:31,500 --> 00:27:35,103
in standard PBR roughness and metallic gradient

394
00:27:35,103 --> 00:27:38,085
to help them quickly correct for issues in customer shading

395
00:27:38,085 --> 00:27:41,588
models under complex lighting conditions.

396
00:27:41,588 --> 00:27:43,990
And we have a fast character parade mode

397
00:27:43,990 --> 00:27:46,852
to check for the consistency of animated shading

398
00:27:46,852 --> 00:27:49,294
models in a given environment.

399
00:27:49,630 --> 00:27:54,812
since those non-standard parameters can vary from artist to artist.

400
00:27:54,812 --> 00:28:00,813
And as for environment design, the tool has an option to quickly place characters randomly

401
00:28:00,813 --> 00:28:04,214
in a level at a specified density.

402
00:28:04,214 --> 00:28:09,816
We can pile a bunch of characters on top of the generated nail mesh, and auto-rotate them

403
00:28:09,816 --> 00:28:12,157
or play random animations at our command.

404
00:28:13,151 --> 00:28:18,034
On larger levels, the characters are placed in a fixed area of interest and get updated

405
00:28:18,034 --> 00:28:22,016
when the in-game camera flies over the entire map.

406
00:28:22,016 --> 00:28:27,719
This is how we do look-depth with a large number of characters and environment combinations,

407
00:28:27,719 --> 00:28:35,123
using real-time tools to help the character and the environment team get immediate feedback

408
00:28:35,123 --> 00:28:39,445
and iterate and polish the game.

409
00:28:39,445 --> 00:28:41,146
Finally, let's look at the summary.

410
00:28:42,179 --> 00:28:47,623
In this presentation, we talked about stylistic conventions of anime art style,

411
00:28:47,623 --> 00:28:52,187
different approaches of achieving anime-style visual creation in game,

412
00:28:52,187 --> 00:28:55,589
and our choice for Extraordinary Ones Mirage.

413
00:28:55,589 --> 00:29:01,233
I shared some key techniques we used for recreating anime features in 3D,

414
00:29:01,233 --> 00:29:04,736
and how to coexist in harmony with physically-based rendering.

415
00:29:05,562 --> 00:29:14,370
The thought process for bringing modern graphics techniques to stylized rendering can also be applied to other art styles.

416
00:29:14,370 --> 00:29:23,759
That's all. Hope this presentation has given you some food for thought. If you have any questions, please feel free to contact me by email. Thank you for listening.

