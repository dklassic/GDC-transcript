1
00:00:05,806 --> 00:00:06,667
Okay, last talk.

2
00:00:06,667 --> 00:00:09,429
I'm hopefully not gonna make it too hard for you guys,

3
00:00:09,429 --> 00:00:12,032
but I have a little bit of mathematical content

4
00:00:12,032 --> 00:00:14,574
to wake you all up on a Friday afternoon.

5
00:00:14,574 --> 00:00:16,396
First off, I'll just introduce myself.

6
00:00:16,396 --> 00:00:19,979
So, I've been in the game industry for quite a while.

7
00:00:19,979 --> 00:00:23,002
Started a long time ago doing Commodore 64 game development,

8
00:00:23,002 --> 00:00:25,444
then was the co-founder and CTO of Havok,

9
00:00:25,444 --> 00:00:27,987
the physics special effects company.

10
00:00:28,762 --> 00:00:32,865
And then Core, which is a Lua virtual machine company,

11
00:00:32,865 --> 00:00:36,067
which got sold to Havoc, and then now Swerve.

12
00:00:36,067 --> 00:00:38,589
And Swerve is a company that focuses really

13
00:00:38,589 --> 00:00:41,871
on app and game developers developing mobile titles.

14
00:00:41,871 --> 00:00:45,113
And we provide a series of platform tools and technologies

15
00:00:45,113 --> 00:00:47,914
for those guys, from analytics to A-B testing

16
00:00:47,914 --> 00:00:51,217
to messaging and targeting and all that sort of cool stuff.

17
00:00:51,217 --> 00:00:52,918
If you're interested, come and talk to me afterwards.

18
00:00:52,918 --> 00:00:55,099
That's all I'm gonna say about Swerve.

19
00:00:56,451 --> 00:00:59,593
So part of what we do in Swerve is A-B testing.

20
00:00:59,593 --> 00:01:03,135
And we've been involved in that for the last three years

21
00:01:03,135 --> 00:01:05,016
and sort of have evolved our architecture

22
00:01:05,016 --> 00:01:07,698
quite considerably over those three years.

23
00:01:07,698 --> 00:01:10,339
And I thought I'd give you some information

24
00:01:10,339 --> 00:01:12,320
on how we've evolved that, some of the background

25
00:01:12,320 --> 00:01:14,162
to the design of the current system that we have.

26
00:01:14,402 --> 00:01:16,764
and sort of the learnings as a result of running tests

27
00:01:16,764 --> 00:01:19,387
in the wild with millions of users

28
00:01:19,387 --> 00:01:21,970
and just how that's worked out for us.

29
00:01:21,970 --> 00:01:24,472
I also wanted to sort of do a little bit of soapboxing,

30
00:01:24,472 --> 00:01:27,816
comparing perhaps the sort of more classical

31
00:01:27,816 --> 00:01:29,978
experimental design approach, a frequentist approach,

32
00:01:29,978 --> 00:01:32,641
to say the more current Bayesian approach,

33
00:01:32,641 --> 00:01:35,324
although Bayes is arguably an older technology.

34
00:01:36,728 --> 00:01:40,432
So I'm not trying to say either is perfect,

35
00:01:40,432 --> 00:01:43,354
but I think certainly the evolving opinion

36
00:01:43,354 --> 00:01:45,436
is that Bayesian approach is a much more suitable approach

37
00:01:45,436 --> 00:01:47,978
for the sorts of things that we do in this industry.

38
00:01:47,978 --> 00:01:49,620
And I'll try and make that case

39
00:01:49,620 --> 00:01:51,421
and do some degree of comparing

40
00:01:51,421 --> 00:01:53,143
and contrasting the two different approaches.

41
00:01:54,059 --> 00:01:56,780
So first off, just in case, and I'm sure I don't need

42
00:01:56,780 --> 00:01:59,961
to do this terribly much, but I'll just introduce

43
00:01:59,961 --> 00:02:02,721
the concept of A-B testing and the why of A-B testing.

44
00:02:02,721 --> 00:02:06,623
We all know now it's all about rapid iteration.

45
00:02:06,623 --> 00:02:08,683
It's about getting to soft launch in our titles

46
00:02:08,683 --> 00:02:12,204
as early as we can, getting them in front of an audience,

47
00:02:12,204 --> 00:02:14,105
sort of using that information that we get

48
00:02:14,105 --> 00:02:15,865
from how they interact with the game

49
00:02:15,865 --> 00:02:17,726
to essentially get to a final launch,

50
00:02:17,726 --> 00:02:20,566
and then you're constantly iterating that game service.

51
00:02:21,067 --> 00:02:22,767
And the idea is you're looking at how users interact

52
00:02:22,767 --> 00:02:24,568
with the service, the things that are working,

53
00:02:24,568 --> 00:02:25,609
the things that are not working,

54
00:02:25,609 --> 00:02:27,450
the things that are monetizing well,

55
00:02:27,450 --> 00:02:28,890
things that aren't monetizing well.

56
00:02:28,890 --> 00:02:31,251
And you use that data to hopefully upgrade

57
00:02:31,251 --> 00:02:33,392
and adapt the service to user behavior.

58
00:02:33,392 --> 00:02:35,033
And that's the idea.

59
00:02:35,033 --> 00:02:36,834
In order to do that, you need a framework

60
00:02:36,834 --> 00:02:39,095
that allows you to make changes very rapidly

61
00:02:39,095 --> 00:02:39,795
inside the game.

62
00:02:39,795 --> 00:02:42,476
And you need a sort of an underpinning data science

63
00:02:42,476 --> 00:02:45,018
that gives you the confidence to be able to make decisions

64
00:02:45,018 --> 00:02:47,699
in an appropriate way, decisions that are informed by data.

65
00:02:47,999 --> 00:02:52,461
and informed by real actionable results.

66
00:02:52,461 --> 00:02:54,342
Ultimately, what we're trying to do

67
00:02:54,342 --> 00:02:55,962
is balance an equation, right?

68
00:02:55,962 --> 00:02:57,843
Now I'm sort of glossing over,

69
00:02:57,843 --> 00:02:59,584
obviously there are lots of different types of developers

70
00:02:59,584 --> 00:03:01,625
and lots of different types of business models,

71
00:03:01,625 --> 00:03:03,246
and this probably is a talk that focuses

72
00:03:03,246 --> 00:03:05,226
a little bit more on the assumption

73
00:03:05,226 --> 00:03:07,327
of a free to play style model,

74
00:03:07,327 --> 00:03:09,648
but I think a lot of these ideas

75
00:03:09,648 --> 00:03:11,069
translate to any sort of model.

76
00:03:11,609 --> 00:03:13,351
But fundamentally, there's a cost to you

77
00:03:13,351 --> 00:03:14,452
in developing your game.

78
00:03:14,452 --> 00:03:17,716
There's a cost to you in serving the game to your users.

79
00:03:17,716 --> 00:03:20,379
And that cost needs to be balanced by the things

80
00:03:20,379 --> 00:03:22,642
that the users gain value out of inside of your game

81
00:03:22,642 --> 00:03:24,003
and the things they pay for.

82
00:03:24,003 --> 00:03:25,805
So either they pay up front as a premium title

83
00:03:25,805 --> 00:03:30,050
or they pay after the fact with in-game items or upgrades

84
00:03:30,050 --> 00:03:30,410
or whatever.

85
00:03:30,991 --> 00:03:33,552
But fundamentally, there's a lot of different activities

86
00:03:33,552 --> 00:03:36,354
that you're going to get involved in that hopefully

87
00:03:36,354 --> 00:03:39,356
accrue to a lifetime value for your users that

88
00:03:39,356 --> 00:03:41,917
balances the equation of the spend

89
00:03:41,917 --> 00:03:43,678
that you have to get the user into the game

90
00:03:43,678 --> 00:03:45,299
in the first place.

91
00:03:45,299 --> 00:03:47,660
So I'm going to look at some of the A-B testing techniques

92
00:03:47,660 --> 00:03:49,261
that we can use on the right-hand side

93
00:03:49,261 --> 00:03:50,922
of this sort of equation.

94
00:03:50,922 --> 00:03:53,523
We're not going to be interested at all at this stage

95
00:03:53,523 --> 00:03:55,264
in how we get users into the app, but it's more.

96
00:03:55,604 --> 00:03:57,867
what do we do after they arrive in their first session,

97
00:03:57,867 --> 00:03:59,608
how can we interact with them,

98
00:03:59,608 --> 00:04:01,911
and how can we learn from their behavior.

99
00:04:01,911 --> 00:04:04,733
And obviously this is the equation we're trying to balance.

100
00:04:04,733 --> 00:04:08,557
We want an ROI, we want to make money, we want a profit.

101
00:04:08,557 --> 00:04:10,079
And fundamentally we want to make sure

102
00:04:10,079 --> 00:04:12,701
that we're making more money than we're spending.

103
00:04:12,701 --> 00:04:14,863
So ROI is an interesting thing.

104
00:04:14,863 --> 00:04:18,247
And lifetime value is perhaps an even more intangible thing

105
00:04:18,247 --> 00:04:19,428
to get your head around.

106
00:04:20,318 --> 00:04:24,383
Arguably, lifetime value is an infinite series.

107
00:04:24,383 --> 00:04:25,965
You wait for long enough,

108
00:04:25,965 --> 00:04:27,667
and people will spend more and more on your game,

109
00:04:27,667 --> 00:04:29,489
and eventually they'll stop playing.

110
00:04:29,489 --> 00:04:31,472
So over what period of time do you want to measure this?

111
00:04:31,472 --> 00:04:33,935
And what sort of time frame do you have

112
00:04:33,935 --> 00:04:36,057
in order to make changes inside of the game?

113
00:04:36,842 --> 00:04:41,526
So just looking very quickly at some data from games on our service,

114
00:04:41,526 --> 00:04:45,689
this is a classic profile of popular games with high volumes of users.

115
00:04:45,689 --> 00:04:47,591
And this is showing the spend curve.

116
00:04:47,591 --> 00:04:51,074
This is where spending happens inside the game

117
00:04:51,074 --> 00:04:53,456
based on from day one install.

118
00:04:53,456 --> 00:04:54,938
How early in the game are people spending

119
00:04:54,938 --> 00:04:57,380
and how much revenue comes in in those early stages?

120
00:04:57,380 --> 00:04:59,442
And it turns out the vast majority of the revenue,

121
00:04:59,442 --> 00:05:02,164
the vast majority of people's engagement with your title

122
00:05:02,624 --> 00:05:05,185
tends to be in the very early stages of their play.

123
00:05:05,185 --> 00:05:08,707
So usually, 50% of revenue comes in the first 30 days.

124
00:05:08,707 --> 00:05:11,628
The other 50 is spread over maybe a year or longer.

125
00:05:11,628 --> 00:05:14,930
So it's all about having a very quick reaction time,

126
00:05:14,930 --> 00:05:17,031
being able to fire out tests and test things

127
00:05:17,031 --> 00:05:19,492
and look at what users are doing

128
00:05:19,492 --> 00:05:21,773
and react very quickly in order to sort of

129
00:05:21,773 --> 00:05:22,833
maximize your ROI.

130
00:05:22,833 --> 00:05:26,395
So, nearly finished my A-B testing soapbox.

131
00:05:26,395 --> 00:05:27,795
You need to understand what users are doing,

132
00:05:27,795 --> 00:05:29,696
which is about analytics and getting data in.

133
00:05:30,555 --> 00:05:33,876
You need an ability to test hypotheses against your users.

134
00:05:33,876 --> 00:05:35,377
You want to be able to try things out

135
00:05:35,377 --> 00:05:36,838
and see what works and see what doesn't work.

136
00:05:36,838 --> 00:05:38,799
And essentially use a data-driven approach

137
00:05:38,799 --> 00:05:39,899
to making those decisions.

138
00:05:39,899 --> 00:05:43,001
And finally, you need a way to sort of act

139
00:05:43,001 --> 00:05:44,722
on the data that you're seeing.

140
00:05:44,722 --> 00:05:47,383
You need to push out content or lock in changes

141
00:05:47,383 --> 00:05:49,864
or adapt to the game service very, very rapidly.

142
00:05:49,864 --> 00:05:51,685
And that sort of promotes the idea

143
00:05:51,685 --> 00:05:54,187
of having a data-driven layer on your game,

144
00:05:54,187 --> 00:05:56,568
which is something in the game industry we know a lot about.

145
00:05:56,948 --> 00:06:00,271
in sort of separating tools from run times.

146
00:06:00,271 --> 00:06:03,433
It's exactly the same concept can be used for A-B testing

147
00:06:03,433 --> 00:06:05,575
and for live updated game service.

148
00:06:05,575 --> 00:06:10,919
So, the mechanics of an A-B test are very simple.

149
00:06:10,919 --> 00:06:11,800
At any given point in time,

150
00:06:11,800 --> 00:06:13,381
you have an hypothesis you want to test.

151
00:06:13,381 --> 00:06:16,444
You split your users into separate user groups.

152
00:06:16,444 --> 00:06:18,806
You show them different variations of the game,

153
00:06:18,806 --> 00:06:20,547
different content, different price points,

154
00:06:20,547 --> 00:06:21,188
different whatever.

155
00:06:22,142 --> 00:06:25,503
You look at the data coming back in and you assess the validity of that data.

156
00:06:25,503 --> 00:06:27,484
You try to determine is this actionable or not.

157
00:06:27,484 --> 00:06:28,744
You use statistics to do that.

158
00:06:28,744 --> 00:06:31,746
And that's actually where we're going to focus the talk today on.

159
00:06:31,746 --> 00:06:35,367
And then ultimately you want to choose some winning variation or treatment

160
00:06:35,367 --> 00:06:37,048
and push that out then to all your users.

161
00:06:37,048 --> 00:06:38,989
And this cycle continues ad nauseum.

162
00:06:39,549 --> 00:06:44,337
And the successful game developers who are really adopting A-B testing are running multiple

163
00:06:44,337 --> 00:06:49,104
tests in parallel against different segments of users and having to deal with some of the

164
00:06:49,104 --> 00:06:50,146
complexities of that.

165
00:06:50,146 --> 00:06:53,291
But essentially it's all the time testing and all the time updating.

166
00:06:54,272 --> 00:06:59,418
So from a platform perspective, the mechanics are quite simple at a high level.

167
00:06:59,418 --> 00:07:03,002
We have a game which is being served, typically with a backend server,

168
00:07:03,002 --> 00:07:07,007
storing game state and user save play and all that sort of stuff.

169
00:07:07,007 --> 00:07:10,631
And so on the left-hand side, you have your BI stack, your analytics stack,

170
00:07:10,631 --> 00:07:12,533
your testing platform.

171
00:07:13,133 --> 00:07:17,254
And as the game is uploading, or as the game is being started,

172
00:07:17,254 --> 00:07:19,435
users are being bucketed into A or B groups,

173
00:07:19,435 --> 00:07:21,055
and they're getting custom content.

174
00:07:21,055 --> 00:07:23,196
So the A group gets one version of the game,

175
00:07:23,196 --> 00:07:25,056
and the B group gets the second version of the game.

176
00:07:25,056 --> 00:07:27,556
Now, I'm not going to get into the details of serving that,

177
00:07:27,556 --> 00:07:30,077
but think of that as a content management system, where

178
00:07:30,077 --> 00:07:32,457
the content that you get streamed down to the game

179
00:07:32,457 --> 00:07:34,318
depends on what user group you're in,

180
00:07:34,318 --> 00:07:36,458
or what behavioral target group you're in.

181
00:07:36,458 --> 00:07:37,578
And that content might be just.

182
00:07:37,997 --> 00:07:44,744
different imagery, it might be data controlling the flow of a UI or it could be price point information or whatever.

183
00:07:46,176 --> 00:07:48,357
Users then play the game, interact with it,

184
00:07:48,357 --> 00:07:49,597
hopefully enjoy that game.

185
00:07:49,597 --> 00:07:51,958
And as they're doing that, you're streaming event data

186
00:07:51,958 --> 00:07:53,978
back to your backend service.

187
00:07:53,978 --> 00:07:56,399
And that event data is essentially tagged by,

188
00:07:56,399 --> 00:07:58,980
is the user in population A or population B?

189
00:07:58,980 --> 00:08:01,301
And you use that to generate pretty graphs

190
00:08:01,301 --> 00:08:03,381
and boot up Tableau and do lots of analysis.

191
00:08:03,381 --> 00:08:06,202
And ultimately, based on that data, you make a choice.

192
00:08:06,202 --> 00:08:08,363
You lock in perhaps variation A or variation B.

193
00:08:08,363 --> 00:08:10,683
So you have this sort of feedback loop

194
00:08:10,683 --> 00:08:12,584
where content is all the time being

195
00:08:13,024 --> 00:08:15,266
deployed with logic to the game.

196
00:08:15,266 --> 00:08:17,407
The game players are playing away,

197
00:08:17,407 --> 00:08:18,888
and that data is coming back,

198
00:08:18,888 --> 00:08:21,930
promoting us to make different choices about content.

199
00:08:21,930 --> 00:08:25,192
This is sort of a constantly adapting and shifting system.

200
00:08:25,192 --> 00:08:27,433
And that sort of operates nearly in parallel

201
00:08:27,433 --> 00:08:29,234
to your regular game development cycle,

202
00:08:29,234 --> 00:08:31,015
where you're pushing out new app updates

203
00:08:31,015 --> 00:08:33,857
every two weeks or every four weeks or whatever it is.

204
00:08:33,857 --> 00:08:35,958
These sorts of iterations can happen

205
00:08:35,958 --> 00:08:37,439
in hours or even minutes.

206
00:08:37,439 --> 00:08:38,740
And if you automate some of this,

207
00:08:38,740 --> 00:08:39,921
it can happen in seconds.

208
00:08:41,472 --> 00:08:43,515
So what would you want to test in your game?

209
00:08:43,515 --> 00:08:45,076
Well, anything, of course.

210
00:08:45,076 --> 00:08:47,679
Anything that's available to be tested, can be tested.

211
00:08:47,679 --> 00:08:50,422
And the types of things that we see people testing,

212
00:08:50,422 --> 00:08:52,865
typically, the low-hanging fruit are things like messages.

213
00:08:52,865 --> 00:08:55,608
You know, different layouts of UI,

214
00:08:55,608 --> 00:08:58,091
different message content, different calls to action,

215
00:08:58,091 --> 00:08:59,192
all that sort of thing.

216
00:09:00,355 --> 00:09:02,376
Tutorial flow is another classic one.

217
00:09:02,376 --> 00:09:05,478
So looking at building into your game,

218
00:09:05,478 --> 00:09:07,219
sort of a data-driven view of the tutorial,

219
00:09:07,219 --> 00:09:09,360
being able to dynamically reconfigure

220
00:09:09,360 --> 00:09:10,281
the tutorial on the fly,

221
00:09:10,281 --> 00:09:11,701
and essentially thinking of the tutorial

222
00:09:11,701 --> 00:09:14,283
like a state machine that you can sort of play with

223
00:09:14,283 --> 00:09:15,483
as users are interacting with it.

224
00:09:15,483 --> 00:09:17,124
So this is an example of an actual tutorial,

225
00:09:17,124 --> 00:09:20,166
and there's a choke point where users are falling off

226
00:09:20,166 --> 00:09:23,067
at, say, the seventh or eighth stage in the tutorial.

227
00:09:23,428 --> 00:09:30,621
And that's a good motivator to go in there and try and A-B test different versions of whatever it is you're presenting to the user there, because it's clearly not working so well.

228
00:09:32,307 --> 00:09:34,468
Then you can get into the economy of the game.

229
00:09:34,468 --> 00:09:35,929
And there's a whole ton of this sort of stuff

230
00:09:35,929 --> 00:09:37,350
that goes on in the background.

231
00:09:37,350 --> 00:09:40,691
And the simple things to think about are changing price.

232
00:09:40,691 --> 00:09:42,632
But typically, you don't just change price.

233
00:09:42,632 --> 00:09:46,174
That's a bit too disruptive to your users.

234
00:09:46,174 --> 00:09:48,455
You'll typically go in and look at marketing activities.

235
00:09:48,455 --> 00:09:49,636
And if you've got an in-game store,

236
00:09:49,636 --> 00:09:51,357
you can look at promotions and discounts

237
00:09:51,357 --> 00:09:52,857
and trying out different discounts

238
00:09:52,857 --> 00:09:53,918
at different points in time.

239
00:09:54,794 --> 00:09:56,895
You could try it different exchange rates.

240
00:09:56,895 --> 00:09:59,717
A classic technique in economy management in games

241
00:09:59,717 --> 00:10:02,218
is as users progress through the game,

242
00:10:02,218 --> 00:10:04,359
you sort of induce an inflationary effect

243
00:10:04,359 --> 00:10:05,340
into the game's economy.

244
00:10:05,340 --> 00:10:07,281
Things get more expensive.

245
00:10:07,281 --> 00:10:09,121
And so we sort of know this intuitively,

246
00:10:09,121 --> 00:10:11,643
but how more expensive and how quickly you do that

247
00:10:11,643 --> 00:10:12,983
is sort of like a game balancing

248
00:10:12,983 --> 00:10:14,884
and economy balancing thing.

249
00:10:14,884 --> 00:10:17,346
And you can use A-B testing to test that out

250
00:10:17,346 --> 00:10:18,887
and to test different exchange rates.

251
00:10:20,114 --> 00:10:27,557
Something that's used quite a lot is your sort of price sets and the pricing that's available to users.

252
00:10:27,557 --> 00:10:31,719
Now you're not changing the value of anything here. You're not saying something that was $2 is now $4.

253
00:10:31,719 --> 00:10:35,341
You're just essentially changing the inventory that's available in the store.

254
00:10:35,341 --> 00:10:38,222
And in this case it's, you know, coin bundles or whatever.

255
00:10:38,563 --> 00:10:40,946
And if you look at these price sets just a little bit closely,

256
00:10:40,946 --> 00:10:42,688
you'll see that as you go from top to bottom,

257
00:10:42,688 --> 00:10:46,093
we're sort of increasing the value of some of these things

258
00:10:46,093 --> 00:10:47,175
in fairly subtle ways.

259
00:10:47,175 --> 00:10:50,639
In fact, the users are arguably getting better value

260
00:10:50,639 --> 00:10:53,223
because we've increased the price point from $1 to $2.

261
00:10:53,664 --> 00:10:56,266
But we've more than doubled the number of gems they're getting.

262
00:10:56,266 --> 00:10:57,648
So it's not an unfair thing.

263
00:10:57,648 --> 00:11:00,090
But all we're doing is we're changing the choices

264
00:11:00,090 --> 00:11:02,293
that users have inside of the store, which

265
00:11:02,293 --> 00:11:04,615
is exactly the same as a retail manager laying

266
00:11:04,615 --> 00:11:07,798
at their shelves, deciding what things to place

267
00:11:07,798 --> 00:11:09,080
on key places on the shelf.

268
00:11:09,080 --> 00:11:11,963
And we have exactly the same problem of scarcity in games,

269
00:11:11,963 --> 00:11:13,905
if scarcity of screen space.

270
00:11:14,605 --> 00:11:17,367
So what typically happens here is testing has motivated

271
00:11:17,367 --> 00:11:18,808
the different price points,

272
00:11:18,808 --> 00:11:20,509
and as users go through the game

273
00:11:20,509 --> 00:11:21,890
and perhaps become a paying user,

274
00:11:21,890 --> 00:11:23,651
you start shifting around the inventory

275
00:11:23,651 --> 00:11:25,292
that's available for them to purchase,

276
00:11:25,292 --> 00:11:28,774
again to try and increase the monetization inside the game.

277
00:11:28,774 --> 00:11:32,257
By basically getting out of the way of the user,

278
00:11:32,257 --> 00:11:34,178
typically people who pay a lot in games,

279
00:11:34,178 --> 00:11:35,979
and like paying a lot in games,

280
00:11:35,979 --> 00:11:37,540
don't pay at the lower price points,

281
00:11:37,540 --> 00:11:39,901
they prefer to pay at the higher price points.

282
00:11:39,901 --> 00:11:42,963
So this is a way to allow them to do that.

283
00:11:43,989 --> 00:11:45,689
Here's some examples of that in action.

284
00:11:45,689 --> 00:11:48,030
So this is a sort of a complex graph.

285
00:11:48,030 --> 00:11:49,430
I'll try and step through it.

286
00:11:49,430 --> 00:11:51,131
On the bottom we have the value

287
00:11:51,131 --> 00:11:53,671
of the very first purchase a user makes

288
00:11:53,671 --> 00:11:54,951
out of one of those sort of price sets,

289
00:11:54,951 --> 00:11:57,272
one of those gem bundles.

290
00:11:57,272 --> 00:11:59,752
And there's multiple different price points

291
00:11:59,752 --> 00:12:00,812
they can purchase at.

292
00:12:00,812 --> 00:12:02,893
So let's say the $2, the $5, $15, $30, and $70.

293
00:12:02,893 --> 00:12:06,234
So, you know, a classic stratification of pricing

294
00:12:06,234 --> 00:12:07,974
inside of a game or a free-to-play game.

295
00:12:08,834 --> 00:12:12,635
And you can see that there are users who purchase first

296
00:12:12,635 --> 00:12:14,456
right over there on the $70 line.

297
00:12:14,456 --> 00:12:16,877
And some of these guys then continue to purchase

298
00:12:16,877 --> 00:12:17,277
at the $70 level.

299
00:12:17,277 --> 00:12:20,298
So that's what this sort of second faded line means.

300
00:12:20,298 --> 00:12:23,279
Each user there first purchased at $70,

301
00:12:23,279 --> 00:12:26,079
and then their total purchase so far is $140.

302
00:12:26,079 --> 00:12:29,580
And you can see the steps further up

303
00:12:29,580 --> 00:12:30,861
as users continue to purchase.

304
00:12:30,861 --> 00:12:33,081
So these guys up here are our VIPs.

305
00:12:33,081 --> 00:12:35,162
These are the guys who are spending lots of money

306
00:12:35,162 --> 00:12:37,403
in the game, clearly a high disposable income.

307
00:12:38,411 --> 00:12:41,575
But some of the things to notice here are AB testing smears.

308
00:12:41,575 --> 00:12:43,657
So what we've done here is we've looked at different price

309
00:12:43,657 --> 00:12:45,759
points and we've looked to see can we shift, say, a price

310
00:12:45,759 --> 00:12:49,063
point that was $28 to $29 to $30 and look at the price

311
00:12:49,063 --> 00:12:53,108
elasticity, the sensitivity of the users to those changes.

312
00:12:53,108 --> 00:12:54,049
Now again, you're shifting.

313
00:12:54,049 --> 00:12:55,330
You're also giving them better value.

314
00:12:55,330 --> 00:12:57,853
You're adding to the coin bundles that they get.

315
00:12:58,214 --> 00:13:00,796
but you're just looking at their sensitivity to the specific price point.

316
00:13:00,796 --> 00:13:06,281
And that's, you know, classic A-B testing used to try and mix very small changes in the economy,

317
00:13:06,281 --> 00:13:11,045
very small changes in the inventory, which can have big impacts on the actual underlying revenue itself.

318
00:13:12,982 --> 00:13:15,062
Here's something else that you want to test.

319
00:13:15,062 --> 00:13:16,803
The sort of marketing activities

320
00:13:16,803 --> 00:13:17,863
inside of your applications.

321
00:13:17,863 --> 00:13:21,284
Something that people do a lot in games, obviously,

322
00:13:21,284 --> 00:13:24,465
is ask the users, can I send you a push notification?

323
00:13:24,465 --> 00:13:26,426
Or would you like to register on Facebook?

324
00:13:26,426 --> 00:13:29,607
Or would you like to tweet the thing you just experienced?

325
00:13:29,607 --> 00:13:30,287
Or whatever it is.

326
00:13:30,287 --> 00:13:30,787
So these are.

327
00:13:31,307 --> 00:13:34,170
sort of ways to increase the virality of your game.

328
00:13:34,170 --> 00:13:36,311
Now to do that, the last thing you want to do

329
00:13:36,311 --> 00:13:38,013
is just ask them right when they install

330
00:13:38,013 --> 00:13:39,093
because everyone says no.

331
00:13:39,093 --> 00:13:41,335
Because there's no benefit to a user at that point.

332
00:13:41,335 --> 00:13:43,437
They haven't learned anything about the game.

333
00:13:43,437 --> 00:13:46,179
So a classic thing to test for is let's wait.

334
00:13:46,179 --> 00:13:48,441
Let's create a sort of a marketing strategy

335
00:13:48,441 --> 00:13:50,302
that says we'll wait for a little while.

336
00:13:50,302 --> 00:13:52,504
Wait until the user has played the game a couple of times.

337
00:13:52,504 --> 00:13:53,225
Let's say three sessions.

338
00:13:53,725 --> 00:13:55,887
And then we look at a key point inside the game

339
00:13:55,887 --> 00:13:58,529
that we know people have shown high engagement after.

340
00:13:58,529 --> 00:14:01,852
Let's say there's a video reward sequence

341
00:14:01,852 --> 00:14:03,174
at the end of completing a level.

342
00:14:03,174 --> 00:14:05,055
So right at the end of the level,

343
00:14:05,055 --> 00:14:07,037
you play a pre-roll video, and then you ask the user,

344
00:14:07,037 --> 00:14:09,259
would you like to share your experience on Facebook?

345
00:14:09,259 --> 00:14:10,000
And at that point,

346
00:14:10,000 --> 00:14:11,862
you bring up the Facebook registration page.

347
00:14:11,862 --> 00:14:14,904
So there's lots of choices that have been made there.

348
00:14:14,904 --> 00:14:17,807
And the danger is to assume that you have an intuitive

349
00:14:18,107 --> 00:14:21,170
a good opinion as to the best place

350
00:14:21,170 --> 00:14:23,031
to make that call to action happen inside the app.

351
00:14:23,031 --> 00:14:25,433
The best thing to do is to have lots of opinions

352
00:14:25,433 --> 00:14:26,994
and to try them all out against your users

353
00:14:26,994 --> 00:14:28,775
and see which one works best.

354
00:14:28,775 --> 00:14:30,957
So for example, how many sessions do I wait?

355
00:14:30,957 --> 00:14:33,519
One, two, three, four, five, try them all out.

356
00:14:33,519 --> 00:14:35,180
Test different groups of users

357
00:14:35,180 --> 00:14:37,462
and see what your sort of conversion rate is

358
00:14:37,462 --> 00:14:39,563
for their Facebook call to action in this example.

359
00:14:39,563 --> 00:14:41,845
So this is an example of testing

360
00:14:41,845 --> 00:14:44,367
the marketing logic inside of your game.

361
00:14:44,367 --> 00:14:45,948
So the when and the where.

362
00:14:47,460 --> 00:14:48,581
So what you end up with is data.

363
00:14:48,581 --> 00:14:51,202
And this is sort of the classic result you'll get

364
00:14:51,202 --> 00:14:54,183
from running a multi-treatment A-AB test.

365
00:14:54,183 --> 00:14:57,004
That's a sort of a bit of a contradiction in terms,

366
00:14:57,004 --> 00:15:00,185
I agree, but A-B, no one is actually doing A-B testing

367
00:15:00,185 --> 00:15:02,366
in games, they're all doing sort of multivariate testing

368
00:15:02,366 --> 00:15:06,068
or multi-treatment testing or constant optimization.

369
00:15:06,068 --> 00:15:07,668
But we just call it an A-B test

370
00:15:07,668 --> 00:15:09,989
just for simplicity of communication.

371
00:15:09,989 --> 00:15:12,850
So here you can see an A-B test running

372
00:15:12,850 --> 00:15:14,251
with I think it's four variants.

373
00:15:15,436 --> 00:15:18,157
And you see over time, the pattern of behavior is changing.

374
00:15:18,157 --> 00:15:19,958
Our confidence in the winning variant

375
00:15:19,958 --> 00:15:21,399
has changed dramatically.

376
00:15:21,399 --> 00:15:22,499
Certainly from the start, you can see

377
00:15:22,499 --> 00:15:23,740
there's a huge amount of oscillation.

378
00:15:23,740 --> 00:15:25,701
And then things slowly settle down,

379
00:15:25,701 --> 00:15:27,982
but there's still an inherent amount of noise.

380
00:15:27,982 --> 00:15:29,983
And this is the challenge you face.

381
00:15:29,983 --> 00:15:31,784
So if you're running these sorts of tests,

382
00:15:31,784 --> 00:15:35,206
you have to have an underpinning mathematical model

383
00:15:35,206 --> 00:15:37,547
to validate the choices you're making.

384
00:15:37,547 --> 00:15:38,787
You can't just look on Tuesday and say,

385
00:15:38,787 --> 00:15:42,529
conversion rate A is higher, I'll go with conversion rate A.

386
00:15:42,529 --> 00:15:44,390
You need to know what's happening underneath that.

387
00:15:45,030 --> 00:15:46,312
So in this case here, for example,

388
00:15:46,312 --> 00:15:47,453
at the start of the test,

389
00:15:47,453 --> 00:15:48,874
it looked like one of these variants,

390
00:15:48,874 --> 00:15:50,115
the yellow one, was winning.

391
00:15:50,115 --> 00:15:51,876
But very quickly, the blue one started to take over.

392
00:15:51,876 --> 00:15:53,818
And at some point, you're gonna make a decision

393
00:15:53,818 --> 00:15:54,779
to lock in a result.

394
00:15:54,779 --> 00:15:57,341
Otherwise, you're gonna run the test for too long

395
00:15:57,341 --> 00:16:00,063
and lose out on possible extra revenue

396
00:16:00,063 --> 00:16:01,204
or extra audience engagement.

397
00:16:01,204 --> 00:16:02,866
I suppose the question is,

398
00:16:02,866 --> 00:16:05,088
A, how do you produce this data?

399
00:16:05,088 --> 00:16:06,949
How do you produce these probabilities

400
00:16:06,949 --> 00:16:08,951
or these confidence levels?

401
00:16:08,951 --> 00:16:11,293
And B, when do you decide to lock in a result?

402
00:16:12,194 --> 00:16:14,635
So I'm making an assumption here that we're not looking

403
00:16:14,635 --> 00:16:16,116
at a multi-armed bandit style scenario,

404
00:16:16,116 --> 00:16:17,937
we're just looking at something that is managed

405
00:16:17,937 --> 00:16:19,317
by our product manager to look at data

406
00:16:19,317 --> 00:16:20,458
and then lock in a result,

407
00:16:20,458 --> 00:16:22,079
which is sort of a classic A-B test.

408
00:16:22,079 --> 00:16:24,780
So I'm gonna run through how we do that.

409
00:16:24,780 --> 00:16:27,702
And ultimately, we wanna look at conversion rates over time.

410
00:16:27,702 --> 00:16:30,343
And we wanna see clear separations between them

411
00:16:30,343 --> 00:16:31,864
before we make our judgment.

412
00:16:31,864 --> 00:16:35,826
So, I'm gonna use a very simple and rather silly example,

413
00:16:35,826 --> 00:16:37,847
and apologies to all the copyright owners

414
00:16:37,847 --> 00:16:40,809
that I'm clearly walking over at the moment.

415
00:16:41,727 --> 00:16:45,571
So, Can a Candy Crush Bolt is obviously a fictional title.

416
00:16:45,571 --> 00:16:47,833
And what we're gonna do is we're gonna launch this title

417
00:16:47,833 --> 00:16:50,576
and we're gonna try out some different variations of it

418
00:16:50,576 --> 00:16:53,779
and see impacts on a conversion rate.

419
00:16:53,779 --> 00:16:58,464
And the conversion rate we'll look at is day one retention.

420
00:16:58,464 --> 00:17:01,167
The least understood and most overused KPI

421
00:17:01,167 --> 00:17:02,108
in the game industry.

422
00:17:02,108 --> 00:17:03,569
But that's a topic for another talk.

423
00:17:04,340 --> 00:17:07,743
So let's imagine our fundamental conversion rate

424
00:17:07,743 --> 00:17:08,823
for day one is 30%, which means 30% of users

425
00:17:08,823 --> 00:17:12,226
come back on the second day into our game.

426
00:17:12,226 --> 00:17:13,307
And I'm pretty happy with that,

427
00:17:13,307 --> 00:17:15,469
but I'd like to push that up a little bit.

428
00:17:15,469 --> 00:17:18,471
So what I do is I start playing around with the gameplay.

429
00:17:18,471 --> 00:17:20,733
I have no idea how you actually play this game.

430
00:17:20,733 --> 00:17:22,074
I'm actually quite intrigued.

431
00:17:22,074 --> 00:17:24,676
I might try and code this up someday.

432
00:17:24,676 --> 00:17:26,658
I suspect it'll slow down the speed

433
00:17:26,658 --> 00:17:30,141
of a cannonball style infinite runner, but anyway.

434
00:17:30,141 --> 00:17:31,582
Imagine we've made some gameplay change,

435
00:17:31,582 --> 00:17:33,083
and this is obviously the.

436
00:17:33,700 --> 00:17:36,963
the change I've made here has absolutely no bearing on the math.

437
00:17:36,963 --> 00:17:38,764
And there's an impact, obviously, on the game.

438
00:17:38,764 --> 00:17:41,766
There's an impact on the number of users who come back the second day.

439
00:17:41,766 --> 00:17:45,528
And in this case, we were expecting a 30-day,

440
00:17:45,528 --> 00:17:48,590
a 30% day-win retention, and in fact, we saw no users come back the next day.

441
00:17:48,590 --> 00:17:51,352
So whatever we did with the game, we've completely destroyed it.

442
00:17:52,153 --> 00:17:54,613
Now the question we ask ourselves at this point is,

443
00:17:54,613 --> 00:17:57,354
after 50 users, we've seen none of them return on day two.

444
00:17:57,354 --> 00:17:59,574
So that's a really bad result,

445
00:17:59,574 --> 00:18:02,995
and I guess the panic attack starts to settle in.

446
00:18:02,995 --> 00:18:06,476
The question we want to ask ourself is, how bad is this?

447
00:18:06,476 --> 00:18:09,096
And is it enough information now for me to say,

448
00:18:09,096 --> 00:18:10,957
well, I should stop that, I should move

449
00:18:10,957 --> 00:18:12,297
and make a change to the game,

450
00:18:12,297 --> 00:18:14,237
and revert at the change I've just done?

451
00:18:14,237 --> 00:18:15,878
That's sort of an interesting question,

452
00:18:15,878 --> 00:18:17,518
and I'm gonna sort of ask that question

453
00:18:17,518 --> 00:18:18,998
both from a frequentist perspective

454
00:18:18,998 --> 00:18:19,918
and a Bayesian perspective.

455
00:18:20,358 --> 00:18:22,319
So first off, the null hypothesis view of the world.

456
00:18:22,319 --> 00:18:24,480
This is the way we think about it.

457
00:18:24,480 --> 00:18:25,921
So the null hypothesis states,

458
00:18:25,921 --> 00:18:27,921
well, in the absence of anything else,

459
00:18:27,921 --> 00:18:31,023
we assume that the change you've made had no impact.

460
00:18:31,023 --> 00:18:33,824
And underlying my assumption is that I have a model

461
00:18:33,824 --> 00:18:35,424
for how users are coming back to my game,

462
00:18:35,424 --> 00:18:37,805
30% of them return, and I have some idea

463
00:18:37,805 --> 00:18:39,506
of what variability I have in that 30%

464
00:18:39,506 --> 00:18:40,426
sort of from day to day.

465
00:18:40,426 --> 00:18:43,307
So that gives us a spread, and this is usually modeled

466
00:18:43,307 --> 00:18:45,308
in some sort of normal distribution

467
00:18:45,308 --> 00:18:46,388
or a binomial or whatever.

468
00:18:47,619 --> 00:18:50,360
So my null hypothesis is that there's no difference.

469
00:18:50,360 --> 00:18:53,360
So having observed the users, I assume from day one

470
00:18:53,360 --> 00:18:55,601
that there's no difference between that

471
00:18:55,601 --> 00:18:56,141
and my 30% use case.

472
00:18:56,141 --> 00:18:58,281
What I'm trying to do is I'm trying to disprove that.

473
00:18:58,281 --> 00:19:00,662
I'm trying to say, well actually, based on the data,

474
00:19:00,662 --> 00:19:03,002
the null hypothesis clearly doesn't hold anymore.

475
00:19:03,002 --> 00:19:06,083
Now if I saw a retention rate, say, maybe of 35%,

476
00:19:06,083 --> 00:19:08,443
I don't have enough information at the moment

477
00:19:08,443 --> 00:19:11,084
to dispute the null hypothesis, and I'd probably accept it.

478
00:19:11,862 --> 00:19:14,266
But if I saw a conversion rate that was off the charts,

479
00:19:14,266 --> 00:19:16,790
I'd probably start thinking about

480
00:19:16,790 --> 00:19:18,854
that null hypothesis is no longer true,

481
00:19:18,854 --> 00:19:19,635
and so I reject it.

482
00:19:21,318 --> 00:19:24,079
So in our case, we've got a 0% conversion rate,

483
00:19:24,079 --> 00:19:26,981
which is obviously very bad, and it's off the charts.

484
00:19:26,981 --> 00:19:28,801
So we would reject the non-hypothesis.

485
00:19:28,801 --> 00:19:30,222
And this is our frequentest result.

486
00:19:30,222 --> 00:19:33,603
And that's actually the result of a classic A-B test.

487
00:19:33,603 --> 00:19:35,724
But what does that result tell us?

488
00:19:35,724 --> 00:19:38,925
So essentially, it means that the 30% conversion rate

489
00:19:38,925 --> 00:19:41,186
that we had previously is unlikely to be

490
00:19:41,186 --> 00:19:42,846
the new conversion rate that we're seeing now.

491
00:19:42,846 --> 00:19:44,327
That's actually all it really tells us.

492
00:19:44,327 --> 00:19:47,248
It doesn't say anything else about how unlikely that is.

493
00:19:47,248 --> 00:19:48,488
It just says it's unlikely to be.

494
00:19:49,581 --> 00:19:52,704
Now we capture that information in what's called a p-value,

495
00:19:52,704 --> 00:19:53,445
or confidence value.

496
00:19:53,445 --> 00:19:56,869
And a confidence value is just based on normal distributions

497
00:19:56,869 --> 00:19:59,112
and standard deviations and all that good stuff.

498
00:19:59,112 --> 00:20:02,595
And what we say is, if the value we see

499
00:20:02,595 --> 00:20:05,999
is sort of within 95% of the main center of the bell curve,

500
00:20:05,999 --> 00:20:06,480
we accept it.

501
00:20:06,480 --> 00:20:07,701
If it's outside of that, we reject it.

502
00:20:07,701 --> 00:20:09,683
And in our case, it's certainly outside of that.

503
00:20:10,299 --> 00:20:12,260
Now what the p value actually captures

504
00:20:12,260 --> 00:20:14,880
is the probability of observing a result

505
00:20:14,880 --> 00:20:17,161
which is as extreme a result,

506
00:20:17,161 --> 00:20:19,281
assuming the null hypothesis is true.

507
00:20:19,281 --> 00:20:21,602
So that's a bit of a tongue twister

508
00:20:21,602 --> 00:20:23,522
and it's quite hard to get your head around,

509
00:20:23,522 --> 00:20:26,743
but it's essentially saying the probability

510
00:20:26,743 --> 00:20:28,863
of the observations you see in the data,

511
00:20:28,863 --> 00:20:29,604
given the model.

512
00:20:29,604 --> 00:20:31,604
So we sort of assume the model is true

513
00:20:31,604 --> 00:20:34,065
and we look at the data and we try to disprove the model.

514
00:20:34,065 --> 00:20:36,925
That's how the sort of null hypothesis testing works.

515
00:20:36,925 --> 00:20:39,726
And what you end up with is sort of a truth table like this

516
00:20:39,726 --> 00:20:40,106
where.

517
00:20:40,806 --> 00:20:43,509
okay, maybe the hypothesis is true and we accept it,

518
00:20:43,509 --> 00:20:44,470
which is a good result.

519
00:20:44,470 --> 00:20:47,092
But maybe the hypothesis is true, there's no difference,

520
00:20:47,092 --> 00:20:48,413
but we reject it.

521
00:20:48,413 --> 00:20:49,875
We see an outlier and we say,

522
00:20:49,875 --> 00:20:53,098
actually I think I made a good positive change

523
00:20:53,098 --> 00:20:55,360
to my game here and I accept that as being something

524
00:20:55,360 --> 00:20:56,281
I'll make a change on.

525
00:20:56,281 --> 00:20:57,802
But in fact, that's a false positive.

526
00:20:57,802 --> 00:20:59,904
And that's the root of evil, you know,

527
00:20:59,904 --> 00:21:03,527
for null hypothesis testing in the AB world.

528
00:21:03,527 --> 00:21:06,290
So I'm gonna sort of talk about these false positives.

529
00:21:07,800 --> 00:21:11,003
A p-value is a number between zero and one,

530
00:21:11,003 --> 00:21:13,605
and usually what we say is if it's less than .05,

531
00:21:13,605 --> 00:21:16,287
we accept that there obviously has been a big change.

532
00:21:16,287 --> 00:21:18,249
It's not just due to random noise,

533
00:21:18,249 --> 00:21:20,331
and we make the change and we lock it into our game

534
00:21:20,331 --> 00:21:22,292
if it's a positive change.

535
00:21:22,292 --> 00:21:24,334
And a p-value of less than .05 simply says

536
00:21:24,334 --> 00:21:26,977
the retention rates are different.

537
00:21:26,977 --> 00:21:29,799
If you sample this thing 95 times out of 100,

538
00:21:29,799 --> 00:21:32,341
that retention rate will actually be

539
00:21:32,341 --> 00:21:33,262
a different retention rate.

540
00:21:34,591 --> 00:21:37,434
And if you dig into it and try and express exactly what that means,

541
00:21:37,434 --> 00:21:42,278
it says that the data that you've seen supports a rejection of the null hypothesis.

542
00:21:42,278 --> 00:21:48,264
And that's essentially saying the probability of seeing a result as extreme as this is less than 5%.

543
00:21:48,264 --> 00:21:54,430
And that's again really tricky to even communicate to your CFO or to your head of design or anything like that.

544
00:21:55,545 --> 00:21:57,166
So that's sort of leading to an argument that

545
00:21:57,166 --> 00:22:00,307
p-values are difficult for us to intuit about.

546
00:22:00,307 --> 00:22:02,668
They're sort of unwieldy to work with,

547
00:22:02,668 --> 00:22:03,929
and it'd be nice to have something else

548
00:22:03,929 --> 00:22:05,009
which was just a probability.

549
00:22:05,009 --> 00:22:06,330
Is one better than the other?

550
00:22:06,330 --> 00:22:07,430
Give me that probability.

551
00:22:07,430 --> 00:22:08,971
And that turns out is exactly

552
00:22:08,971 --> 00:22:10,072
what a Bayesian approach gives you.

553
00:22:10,072 --> 00:22:13,413
And so you don't have to sort of wrangle your head around

554
00:22:13,413 --> 00:22:15,634
normal distributions and null hypothesis

555
00:22:15,634 --> 00:22:17,215
and rejections and non-rejections.

556
00:22:17,555 --> 00:22:19,457
The other problem with this approach is peaking.

557
00:22:19,457 --> 00:22:21,879
So a classic thing people do is set up these A-B tests,

558
00:22:21,879 --> 00:22:24,081
and they just constantly observe the result.

559
00:22:24,081 --> 00:22:26,884
And once the result gets below 0.05, they say, I'm done.

560
00:22:26,884 --> 00:22:29,386
And that's a really bad thing to do, it turns out.

561
00:22:29,386 --> 00:22:30,767
What you should be doing is sort of looking

562
00:22:30,767 --> 00:22:33,530
at the power of your test, deciding in advance,

563
00:22:33,530 --> 00:22:35,412
how big a change do I want to be able to detect?

564
00:22:35,412 --> 00:22:37,494
So let's say I want to be able to detect a 5% change

565
00:22:37,494 --> 00:22:38,275
in retention.

566
00:22:39,075 --> 00:22:43,400
I need to have, you know, observed that retention change over time.

567
00:22:43,400 --> 00:22:45,262
I need to know how that distribution looks like.

568
00:22:45,262 --> 00:22:49,046
So I need to have some idea of the variance of the standard deviation of the retention stat.

569
00:22:49,046 --> 00:22:51,428
And that gives us a number of participants.

570
00:22:51,428 --> 00:22:54,531
And typically that number of participants will be, say, 10,000 or 100,000 or...

571
00:22:55,052 --> 00:22:57,213
It's hugely dependent on the size of change

572
00:22:57,213 --> 00:22:58,134
you want to detect.

573
00:22:58,134 --> 00:23:00,495
If you want to detect a really small change,

574
00:23:00,495 --> 00:23:02,596
you know, a shift of retention from 30 to 31,

575
00:23:02,596 --> 00:23:05,858
you probably need to observe a very large number of users

576
00:23:05,858 --> 00:23:07,619
to essentially compensate for the noise

577
00:23:07,619 --> 00:23:08,320
that's in your system.

578
00:23:08,320 --> 00:23:09,801
So, what does this mean?

579
00:23:09,801 --> 00:23:12,162
This means people typically ignore this,

580
00:23:12,162 --> 00:23:14,203
and say, well, I've computed all this,

581
00:23:14,203 --> 00:23:15,344
and I see I need 100,000 users.

582
00:23:15,344 --> 00:23:17,485
I start my test, and I immediately start looking

583
00:23:17,485 --> 00:23:19,226
at the graphs and the p-values.

584
00:23:19,226 --> 00:23:21,128
And as soon as I see something hitting a .05,

585
00:23:21,128 --> 00:23:22,248
I say, stop, I'm good to go.

586
00:23:22,248 --> 00:23:23,929
I've got the result I want to see.

587
00:23:24,650 --> 00:23:33,275
And what that means is, it's saying I'm taking the very first time that the noise has pushed my P-score below 0.05, which is a really bad thing to do.

588
00:23:33,275 --> 00:23:38,998
What that does is, it increases the chances of you getting a false positive, and it's actually quite bad.

589
00:23:38,998 --> 00:23:44,401
Let's imagine during the course of your test, you were prepared to accept a 5% false positive rate.

590
00:23:44,401 --> 00:23:49,784
So, you're running a test and you expect that 1 in 20 times I'll accept the result and it'll be wrong.

591
00:23:50,883 --> 00:23:53,465
If you look at that test 10 times in succession

592
00:23:53,465 --> 00:23:55,586
before it's actually reached a conclusion,

593
00:23:55,586 --> 00:23:57,668
you're actually increasing the likelihood

594
00:23:57,668 --> 00:24:00,270
of you seeing a false positive by a factor of five,

595
00:24:00,270 --> 00:24:03,172
which means you need essentially a factor of five

596
00:24:03,172 --> 00:24:05,814
more observations to compensate for that.

597
00:24:05,814 --> 00:24:08,716
So people generally speaking don't realize that.

598
00:24:08,716 --> 00:24:10,758
It was a good blog post by Evan Miller

599
00:24:10,758 --> 00:24:12,419
that I guess anybody who knows about A-B testing

600
00:24:12,419 --> 00:24:13,460
has come across before.

601
00:24:13,460 --> 00:24:15,421
But it sort of, I've just parroted his data here

602
00:24:15,421 --> 00:24:17,262
and it's a really good exposition

603
00:24:17,262 --> 00:24:18,603
of some of the problems that exist.

604
00:24:19,730 --> 00:24:21,651
So the second problem, or the third problem, should I say,

605
00:24:21,651 --> 00:24:22,833
is the family-wise error.

606
00:24:22,833 --> 00:24:27,177
And this is, you know, if you have multiple treatments,

607
00:24:27,177 --> 00:24:30,840
again, the chances of you seeing a false positive

608
00:24:30,840 --> 00:24:33,382
if you have more than one treatment increases

609
00:24:33,382 --> 00:24:35,665
every time you add a new treatment.

610
00:24:35,665 --> 00:24:37,927
So for example, if you have two treatments,

611
00:24:37,927 --> 00:24:40,709
your false positive rate for exactly the same test

612
00:24:40,709 --> 00:24:42,251
is now up to sort of 9.75%.

613
00:24:42,251 --> 00:24:43,292
So again, it's nearly doubled.

614
00:24:43,292 --> 00:24:45,214
And people tend not to correct for that in their AB tests.

615
00:24:45,214 --> 00:24:45,694
Okay.

616
00:24:45,852 --> 00:24:47,173
That's the bad news, sort of.

617
00:24:47,173 --> 00:24:48,874
And now the good news, the Bayesian view.

618
00:24:48,874 --> 00:24:51,255
The Bayesian view takes a completely different approach.

619
00:24:51,255 --> 00:24:54,857
And it basically says, we have an expected retention rate.

620
00:24:54,857 --> 00:24:54,977
It's 30%.

621
00:24:54,977 --> 00:24:56,318
That's what we saw before.

622
00:24:56,318 --> 00:24:59,400
So we've acknowledged that our system, without any changes,

623
00:24:59,400 --> 00:25:00,240
has a 30% retention rate.

624
00:25:00,240 --> 00:25:02,041
I'm going to look at the data.

625
00:25:02,622 --> 00:25:04,702
And based on the data, I'm going to update my view

626
00:25:04,702 --> 00:25:08,444
on what their likely retention rate actually is.

627
00:25:08,444 --> 00:25:10,485
So I have a model of what it was before.

628
00:25:10,485 --> 00:25:12,246
I have data coming in.

629
00:25:12,246 --> 00:25:14,927
And I use that to create a model of what it might be now.

630
00:25:14,927 --> 00:25:17,368
And in this example, with 50 users,

631
00:25:17,368 --> 00:25:20,089
all not having been retained, what actually happens

632
00:25:20,089 --> 00:25:22,790
is we get now a new expected retention rate, which is 15%.

633
00:25:24,607 --> 00:25:26,667
And if you look at the shapes of these curves,

634
00:25:26,667 --> 00:25:28,708
these curves give us a sort of a,

635
00:25:28,708 --> 00:25:29,989
our belief in that retention rate.

636
00:25:29,989 --> 00:25:32,930
And the first one had a 30% with a fairly large spread.

637
00:25:32,930 --> 00:25:35,151
The second one is centered at 15%,

638
00:25:35,151 --> 00:25:36,732
but a tighter sort of spread,

639
00:25:36,732 --> 00:25:38,993
which means that we're actually a bit more confident

640
00:25:38,993 --> 00:25:39,573
about the 15% number.

641
00:25:39,913 --> 00:25:41,575
than we were about the 30% number now,

642
00:25:41,575 --> 00:25:42,916
because we've observed some results.

643
00:25:42,916 --> 00:25:45,218
But the nice thing about this is it still admits

644
00:25:45,218 --> 00:25:46,860
the fact that we might be wrong,

645
00:25:46,860 --> 00:25:50,564
and it's something that's immediately usable.

646
00:25:50,564 --> 00:25:53,066
It looks like now the conversion rate is 15%,

647
00:25:53,066 --> 00:25:54,387
but I'm prepared to accept more data.

648
00:25:54,387 --> 00:25:57,410
And when you're dealing with these sorts of systems,

649
00:25:57,410 --> 00:26:01,094
runs of failed conversions happen all the time,

650
00:26:01,094 --> 00:26:02,355
and you have to be very careful about that.

651
00:26:02,736 --> 00:26:05,099
So I'm going to go through and talk about this

652
00:26:05,099 --> 00:26:06,882
and real examples from games.

653
00:26:06,882 --> 00:26:09,245
And I'm going to show you how you build up this Bayesian

654
00:26:09,245 --> 00:26:11,028
approach to A-B testing.

655
00:26:11,028 --> 00:26:13,371
But the difference between the frequentist view

656
00:26:13,371 --> 00:26:15,634
and the Bayesian view is essentially the Bayesian view

657
00:26:15,634 --> 00:26:17,377
gives you the probability of the model.

658
00:26:17,757 --> 00:26:18,358
given the data.

659
00:26:18,358 --> 00:26:20,198
If you remember, the frequentist one was

660
00:26:20,198 --> 00:26:22,059
the probability of the data given the model.

661
00:26:22,059 --> 00:26:24,980
So the model in the frequentist view is sort of locked in.

662
00:26:24,980 --> 00:26:27,021
Here we're sort of saying, as we see new data,

663
00:26:27,021 --> 00:26:28,062
we'll update this model.

664
00:26:28,062 --> 00:26:30,102
We'll sort of learn what the new shape

665
00:26:30,102 --> 00:26:31,923
of our probability distributions are

666
00:26:31,923 --> 00:26:33,804
and use that to make an assessment.

667
00:26:33,804 --> 00:26:34,364
So, trying to put some,

668
00:26:34,364 --> 00:26:40,747
trying to get a little bit less abstract about that.

669
00:26:40,747 --> 00:26:43,068
The canonical example is the coin flipping,

670
00:26:43,068 --> 00:26:44,368
so I'm going to stick with that.

671
00:26:44,368 --> 00:26:44,828
You know a coin?

672
00:26:45,124 --> 00:26:47,445
It has a head and it has a tail,

673
00:26:47,445 --> 00:26:48,766
just in case you didn't know.

674
00:26:48,766 --> 00:26:51,448
And when you flip it, one of those comes up

675
00:26:51,448 --> 00:26:53,309
and with a 50% probability it's heads or tails.

676
00:26:53,309 --> 00:26:54,050
All right, we got that bit.

677
00:26:54,050 --> 00:26:57,532
So let's say we run an experiment for a period of time

678
00:26:57,532 --> 00:26:59,053
and look at the number of flips.

679
00:26:59,053 --> 00:27:00,794
And just look at this, you can see immediately

680
00:27:00,794 --> 00:27:01,935
there are runs.

681
00:27:01,935 --> 00:27:04,717
So we see series where you get seven heads in a row

682
00:27:04,717 --> 00:27:07,079
or five tails in a row, and that's completely expected.

683
00:27:07,079 --> 00:27:10,541
People get very confused about random systems sometimes

684
00:27:10,541 --> 00:27:12,603
and think that mustn't be random anymore.

685
00:27:13,616 --> 00:27:15,137
But ultimately we get a series of heads and tails.

686
00:27:15,137 --> 00:27:17,819
And you look at the sort of the trend

687
00:27:17,819 --> 00:27:19,641
of those heads or tails over time,

688
00:27:19,641 --> 00:27:21,082
you look at the distribution of the,

689
00:27:21,082 --> 00:27:23,463
or let's say the percentage of heads

690
00:27:23,463 --> 00:27:24,304
and see how that works.

691
00:27:24,304 --> 00:27:27,186
And what we see is early on it's all over the shop,

692
00:27:27,186 --> 00:27:29,568
but eventually after enough observations it settles down.

693
00:27:29,568 --> 00:27:32,050
So it's settling down to an expected value,

694
00:27:32,050 --> 00:27:33,951
which anybody who has a stats background

695
00:27:33,951 --> 00:27:35,553
knows this stuff pretty well.

696
00:27:35,953 --> 00:27:38,395
But the point here is early stages,

697
00:27:38,395 --> 00:27:39,896
even something as simple as a coin

698
00:27:39,896 --> 00:27:41,657
exhibits a whole lot of noise.

699
00:27:41,657 --> 00:27:43,038
And if you're sort of modeling that

700
00:27:43,038 --> 00:27:45,540
and trying to produce data out of that,

701
00:27:45,540 --> 00:27:48,663
you have to be very aware that you need to run a lot of data

702
00:27:48,663 --> 00:27:50,284
before you see anything that's actionable

703
00:27:50,284 --> 00:27:51,885
that gives you any real value

704
00:27:51,885 --> 00:27:54,367
for the long-run average of the coin.

705
00:27:55,469 --> 00:27:57,350
So just a bit of terminology, just to get things straight.

706
00:27:57,350 --> 00:28:00,592
So I'm gonna talk about the probability of an event X.

707
00:28:00,592 --> 00:28:01,772
We can talk about the probability,

708
00:28:01,772 --> 00:28:03,934
the joint probability of event X and Y, so X and Y.

709
00:28:03,934 --> 00:28:05,895
And then we're also gonna look at

710
00:28:05,895 --> 00:28:07,475
the probabilities of X given Y.

711
00:28:07,475 --> 00:28:09,657
So X, assuming Y has happened,

712
00:28:09,657 --> 00:28:11,958
what's the probability then of X happening?

713
00:28:11,958 --> 00:28:13,999
So these three things together are gonna be used

714
00:28:13,999 --> 00:28:16,020
in the Bayesian way for us to essentially

715
00:28:16,020 --> 00:28:18,081
try and figure out what's the probability

716
00:28:18,081 --> 00:28:20,422
of the model being true given the data that we've seen.

717
00:28:21,639 --> 00:28:22,960
So let's look at our heads and tails model.

718
00:28:22,960 --> 00:28:26,383
There's a nice sort of function that captures

719
00:28:26,383 --> 00:28:28,885
the probability of tails or heads in this case.

720
00:28:28,885 --> 00:28:31,187
So we'll assume heads represents one and tails is zero.

721
00:28:31,187 --> 00:28:34,629
And the probability of heads given some parameter

722
00:28:34,629 --> 00:28:37,231
of our coin is given by this Bernoulli distribution,

723
00:28:37,231 --> 00:28:39,733
which many of you might have seen before.

724
00:28:39,733 --> 00:28:41,474
This theta thing is the fairness parameter.

725
00:28:41,474 --> 00:28:43,616
So if it's 0.5, it says it's equally likely

726
00:28:43,616 --> 00:28:44,397
to be heads and tails.

727
00:28:45,186 --> 00:28:47,487
If it's .2, it's more likely to be tails,

728
00:28:47,487 --> 00:28:49,109
and if it's .8, it's more likely to be heads.

729
00:28:49,109 --> 00:28:52,811
So it's a nice parameter that gives us a control.

730
00:28:52,811 --> 00:28:54,252
Think of that now as your conversion rate,

731
00:28:54,252 --> 00:28:55,793
your day one retention.

732
00:28:55,793 --> 00:28:58,775
You know, theta is your day one retention probability.

733
00:28:58,775 --> 00:28:59,936
And in this case, we're assuming

734
00:28:59,936 --> 00:29:01,277
our day one retention is 50%.

735
00:29:01,277 --> 00:29:04,018
So every time we flip a coin, every time we play a game,

736
00:29:04,018 --> 00:29:05,779
the user comes back the next day or not

737
00:29:05,779 --> 00:29:06,980
with a 50% probability.

738
00:29:07,400 --> 00:29:08,501
So for a fair coin, that's 50% or 0.5.

739
00:29:08,501 --> 00:29:11,423
And if you sort of push 0.5 through that Bernoulli

740
00:29:11,423 --> 00:29:15,687
distribution, you'll see that the probability of heads

741
00:29:15,687 --> 00:29:17,168
is 0.5 and the probability of tails is 0.5.

742
00:29:17,168 --> 00:29:19,390
So there's nothing particularly exciting about that.

743
00:29:20,600 --> 00:29:22,702
So that's just the probability for a single throw,

744
00:29:22,702 --> 00:29:24,783
but we're more interested in lots of users

745
00:29:24,783 --> 00:29:28,265
and the distribution of those guys.

746
00:29:28,265 --> 00:29:30,546
So you build up a binomial distribution

747
00:29:30,546 --> 00:29:33,188
by essentially running the Bernoulli process multiple times.

748
00:29:33,188 --> 00:29:34,769
So flipping multiple coins,

749
00:29:34,769 --> 00:29:36,870
and then looking at the proportion of those flips

750
00:29:36,870 --> 00:29:38,030
that are heads or tails.

751
00:29:38,030 --> 00:29:40,512
And in this case, you just have to account

752
00:29:40,512 --> 00:29:43,474
for the combinatorial with the NCX.

753
00:29:43,474 --> 00:29:47,116
So just graphing that, here is 20 tosses.

754
00:29:47,725 --> 00:29:50,507
And here's the distribution of the expected number of heads.

755
00:29:50,507 --> 00:29:53,229
And as you'd expect, we'd expect the number of heads

756
00:29:53,229 --> 00:29:55,491
to be around 10 if it's a fair coin.

757
00:29:55,491 --> 00:29:58,333
But we also allow for the fact that there are possibilities

758
00:29:58,333 --> 00:30:00,635
it might be 15 or possibilities it might be five,

759
00:30:00,635 --> 00:30:02,236
but with significantly lower probability.

760
00:30:02,236 --> 00:30:04,638
So this captures our sort of view of, you know,

761
00:30:04,638 --> 00:30:07,420
how likely it is for a different number of heads to arise.

762
00:30:07,420 --> 00:30:09,222
Now for an unfair coin, it shifts.

763
00:30:09,682 --> 00:30:12,364
So this is an unfair coin where it's more likely

764
00:30:12,364 --> 00:30:14,106
to come up tails as opposed to heads.

765
00:30:14,106 --> 00:30:15,627
If it was heads, it would be shifting

766
00:30:15,627 --> 00:30:16,627
to the right-hand side.

767
00:30:16,627 --> 00:30:18,149
And here the theta parameter is 0.2.

768
00:30:18,149 --> 00:30:19,510
Okay, what we have here is a model

769
00:30:19,510 --> 00:30:24,133
of the probability of number of heads.

770
00:30:24,133 --> 00:30:26,655
We can actually turn that on its head,

771
00:30:26,655 --> 00:30:29,037
no pun intended, and think of it as a likelihood.

772
00:30:29,037 --> 00:30:31,499
Imagine we observed a series of flips,

773
00:30:31,499 --> 00:30:33,100
heads and tails, so 20 of those,

774
00:30:33,100 --> 00:30:34,441
and we had this data set.

775
00:30:34,441 --> 00:30:37,363
And the question we wanted to ask instead is,

776
00:30:37,363 --> 00:30:38,524
what's the likelihood of theta?

777
00:30:38,744 --> 00:30:41,647
What's the likelihood of the coin being fair?

778
00:30:41,647 --> 00:30:42,688
I see 50% heads, 50% tails,

779
00:30:42,688 --> 00:30:45,250
that means it's very likely theta is 0.5.

780
00:30:45,250 --> 00:30:47,793
But if I saw 10 heads and two tails,

781
00:30:47,793 --> 00:30:50,175
the likelihood of theta being 0.5 is quite low.

782
00:30:50,175 --> 00:30:53,819
So we can use exactly the same sort of function

783
00:30:53,819 --> 00:30:56,581
to capture likelihood of a particular value of theta.

784
00:30:56,581 --> 00:30:58,103
And here's some graphs of that.

785
00:30:58,103 --> 00:31:02,287
So let's say you did two throws and you saw one head.

786
00:31:03,095 --> 00:31:05,077
One head means there's also one tail.

787
00:31:05,077 --> 00:31:07,519
So we get this sort of fairly smooth distribution

788
00:31:07,519 --> 00:31:09,961
to say, well, there's nothing really to be gained,

789
00:31:09,961 --> 00:31:11,523
or we haven't learned very much.

790
00:31:11,523 --> 00:31:13,365
All we've learned is that there is at least one head

791
00:31:13,365 --> 00:31:14,446
and one tail in this coin.

792
00:31:14,446 --> 00:31:18,489
So the probability of tails being zero is zero.

793
00:31:19,772 --> 00:31:21,432
As we flip more and more times,

794
00:31:21,432 --> 00:31:23,493
we start gaining confidence about what the actual,

795
00:31:23,493 --> 00:31:27,395
this model parameter is, this theta, this fairness value.

796
00:31:27,395 --> 00:31:29,395
And again, think of this fairness value

797
00:31:29,395 --> 00:31:30,516
as your day one retention,

798
00:31:30,516 --> 00:31:32,457
or your conversion rate for an ad,

799
00:31:32,457 --> 00:31:36,238
or the likelihood of someone to purchase an item in a store.

800
00:31:36,238 --> 00:31:38,579
It's all the same sort of process, give or take.

801
00:31:38,579 --> 00:31:43,381
So this captures our view of how likely

802
00:31:43,381 --> 00:31:46,762
a value of theta is given data that we've observed,

803
00:31:46,762 --> 00:31:48,623
which is gonna be useful in a second.

804
00:31:50,288 --> 00:31:53,709
So, X is gonna be our observations, the number of heads.

805
00:31:53,709 --> 00:31:56,150
Theta, that we've just talked about, is a model parameter.

806
00:31:56,150 --> 00:31:58,571
Our model is essentially the binomial,

807
00:31:58,571 --> 00:32:01,693
and the parameter is essentially this fairness value

808
00:32:01,693 --> 00:32:03,593
that we've talked about, so it's a value from zero to one.

809
00:32:03,593 --> 00:32:07,695
What we've looked at so far in this likelihood

810
00:32:07,695 --> 00:32:11,416
is the probability of a given set of data given theta.

811
00:32:11,416 --> 00:32:13,617
So the probability of X given theta,

812
00:32:13,617 --> 00:32:15,898
and that's what that previous distribution gave us.

813
00:32:16,853 --> 00:32:18,956
That's actually, if you recall, very similar to what

814
00:32:18,956 --> 00:32:21,178
the frequentist view is, the probability of the data

815
00:32:21,178 --> 00:32:22,419
given the model, right?

816
00:32:23,384 --> 00:32:28,086
What we actually want to do is to determine the probability of the model itself.

817
00:32:28,086 --> 00:32:31,287
We want to say, is it true that the conversion rate is 30%?

818
00:32:31,287 --> 00:32:38,290
We don't actually want to know, is it likely that we saw a conversion rate of 28% if the conversion rate was actually 30%?

819
00:32:38,290 --> 00:32:40,131
That's the wrong question to be asking.

820
00:32:40,131 --> 00:32:47,054
We really want to say, what's the conversion rate and what's the probability that our model is correct, that the conversion rate is 30%?

821
00:32:48,132 --> 00:32:49,273
So that's what we like to get.

822
00:32:49,273 --> 00:32:51,394
Now looking at those two, you know,

823
00:32:51,394 --> 00:32:53,556
PX given theta and theta given X,

824
00:32:53,556 --> 00:32:55,417
it looks like they're fairly similar.

825
00:32:55,417 --> 00:32:57,619
But be very careful, these are not the same thing.

826
00:32:57,619 --> 00:32:59,840
They don't interact.

827
00:32:59,840 --> 00:33:02,222
P of X given theta is not P of theta given X.

828
00:33:02,222 --> 00:33:04,143
And a nice way to intuit about that

829
00:33:04,143 --> 00:33:05,844
is just to put something real in there.

830
00:33:07,069 --> 00:33:10,091
So this is obviously a different version of LaTeX

831
00:33:10,091 --> 00:33:11,252
being used to produce these diagrams.

832
00:33:11,252 --> 00:33:13,933
So the probability of it being cloudy,

833
00:33:13,933 --> 00:33:16,575
given that it's raining, think about that.

834
00:33:16,575 --> 00:33:18,316
If it's raining, it's very likely to be cloudy,

835
00:33:18,316 --> 00:33:21,098
so we'd imagine that probability is high, right?

836
00:33:21,098 --> 00:33:22,418
It's not equal to the probability

837
00:33:22,418 --> 00:33:24,300
that it's raining, given it's cloudy.

838
00:33:24,300 --> 00:33:25,300
Again, think about that.

839
00:33:25,300 --> 00:33:28,222
If it's cloudy, the likelihood of it raining

840
00:33:28,222 --> 00:33:30,723
is actually a good deal less, maybe 20% of the time

841
00:33:30,723 --> 00:33:31,944
that it's cloudy, it actually rains,

842
00:33:31,944 --> 00:33:34,446
or maybe less, or maybe more in San Francisco.

843
00:33:36,283 --> 00:33:38,447
So these two things are clearly not the same.

844
00:33:38,447 --> 00:33:40,492
And what we want to do is try and find out

845
00:33:40,492 --> 00:33:42,596
the right-hand side given the left-hand side.

846
00:33:42,596 --> 00:33:45,081
So we'll just do a little bit of math.

847
00:33:47,489 --> 00:33:49,010
And we end up with this rule here.

848
00:33:49,010 --> 00:33:50,851
I'm not gonna go through the math,

849
00:33:50,851 --> 00:33:51,812
but folks who are interested,

850
00:33:51,812 --> 00:33:53,633
it's just the conjoined probability expressed

851
00:33:53,633 --> 00:33:56,334
in terms of the conditional probabilities.

852
00:33:56,334 --> 00:33:58,576
So this thing here is basically saying

853
00:33:58,576 --> 00:33:59,776
the probability of Y given X

854
00:33:59,776 --> 00:34:01,597
is the same as the probability of X given Y

855
00:34:01,597 --> 00:34:03,559
times the probability of Y

856
00:34:03,559 --> 00:34:04,779
divided by the probability of X.

857
00:34:04,779 --> 00:34:07,101
And if we expand the probability of X

858
00:34:07,101 --> 00:34:08,501
into something a little bit larger,

859
00:34:08,501 --> 00:34:10,643
we've actually done something very interesting.

860
00:34:10,643 --> 00:34:12,684
We've managed to figure out a way to relate

861
00:34:12,684 --> 00:34:14,245
the sort of frequentist view of the world

862
00:34:14,245 --> 00:34:15,786
with the Bayesian view of the world.

863
00:34:16,246 --> 00:34:18,547
we now can relate the probability of the model

864
00:34:18,547 --> 00:34:20,548
given the data to something which is about

865
00:34:20,548 --> 00:34:22,509
the probability of the data given the model.

866
00:34:22,509 --> 00:34:24,350
And that's exactly what we want to be able to do.

867
00:34:24,350 --> 00:34:26,592
And Bayes' rule is this.

868
00:34:26,592 --> 00:34:29,533
This is what Bayesian statistics and Bayesian inference

869
00:34:29,533 --> 00:34:30,514
is essentially all about.

870
00:34:30,514 --> 00:34:34,756
So there's two different forms, discrete and continuous.

871
00:34:34,756 --> 00:34:39,099
We're working pretty much with the discrete form here.

872
00:34:39,099 --> 00:34:42,360
And if you start taking this and applying it back

873
00:34:42,360 --> 00:34:44,622
to our model of the coin, what does that look like?

874
00:34:45,623 --> 00:34:47,304
Well first off, the probability of Y given X

875
00:34:47,304 --> 00:34:48,784
is what we're looking for.

876
00:34:48,784 --> 00:34:52,446
It's the probability that our retention rate is 30%,

877
00:34:52,446 --> 00:34:54,906
or the probability that the coin is fair,

878
00:34:54,906 --> 00:34:57,167
given the data that we've observed so far.

879
00:34:57,167 --> 00:35:00,908
Given the fact we've seen no users out of 50 users

880
00:35:00,908 --> 00:35:03,869
returning, what's the probability that the retention rate

881
00:35:03,869 --> 00:35:05,250
is still 30%, that's the question we're asking.

882
00:35:05,250 --> 00:35:08,331
And we relate it to what we know,

883
00:35:08,331 --> 00:35:11,452
which is a model of how coin flipping happens.

884
00:35:11,452 --> 00:35:13,552
So in this case, it's gonna be our binomial,

885
00:35:13,552 --> 00:35:14,693
and that's our likelihood.

886
00:35:15,593 --> 00:35:18,054
We also have a probability of the model itself.

887
00:35:18,054 --> 00:35:20,175
And this is one of the really interesting parts

888
00:35:20,175 --> 00:35:21,035
about Bayesian.

889
00:35:21,035 --> 00:35:22,616
We say, what's the probability of theta?

890
00:35:22,616 --> 00:35:24,437
Now theta, if you think about it, is the fairness.

891
00:35:24,437 --> 00:35:27,658
So this is a way of you expressing to the system

892
00:35:27,658 --> 00:35:29,138
how much you believe that the coin is fair.

893
00:35:29,138 --> 00:35:30,859
And you might not believe it's fair at all.

894
00:35:30,859 --> 00:35:32,800
You might have no information, in which case you say,

895
00:35:32,800 --> 00:35:34,200
I don't know anything about P of theta.

896
00:35:34,200 --> 00:35:35,921
Or you might say, well actually,

897
00:35:35,921 --> 00:35:38,042
I'm very sure it's a fair coin.

898
00:35:38,042 --> 00:35:40,543
I'll say P of theta is 0.5 and plug that in.

899
00:35:41,540 --> 00:35:43,362
And this down here, for want of a better term,

900
00:35:43,362 --> 00:35:44,623
is just a normalizing term.

901
00:35:44,623 --> 00:35:46,725
We're dealing with probability distributions,

902
00:35:46,725 --> 00:35:47,946
so they need to sum to one.

903
00:35:47,946 --> 00:35:50,349
So this underneath it is just the integral

904
00:35:50,349 --> 00:35:51,450
of the thing that's on the top.

905
00:35:51,450 --> 00:35:53,212
So we don't need to get too concerned about that.

906
00:35:53,212 --> 00:35:55,474
So if you just break that out,

907
00:35:55,474 --> 00:35:58,377
and these are the classic terms people use in Bayesian.

908
00:35:58,377 --> 00:36:01,500
So the probability of the model given the data,

909
00:36:01,500 --> 00:36:03,262
the thing we're looking for is the posterior.

910
00:36:04,092 --> 00:36:05,693
The probability of the data given the model

911
00:36:05,693 --> 00:36:08,175
is the binomial thing, and this is the likelihood.

912
00:36:08,175 --> 00:36:10,016
This is something we sort of choose.

913
00:36:10,016 --> 00:36:12,197
We choose a model that maps to the process

914
00:36:12,197 --> 00:36:13,017
we're trying to test for.

915
00:36:13,017 --> 00:36:14,638
A probability of the model itself,

916
00:36:14,638 --> 00:36:16,980
the model parameter, is our prior.

917
00:36:16,980 --> 00:36:18,781
And that's the thing that we use.

918
00:36:18,781 --> 00:36:20,622
That's our industry knowledge comes into play here.

919
00:36:20,622 --> 00:36:22,883
And we can say, P of theta should be something

920
00:36:22,883 --> 00:36:25,845
because I understand that my retention rate should be 30%.

921
00:36:25,845 --> 00:36:26,786
And I plug that in.

922
00:36:26,786 --> 00:36:28,366
So it's a really good way of bringing

923
00:36:28,366 --> 00:36:29,987
your industry experience to bear.

924
00:36:29,987 --> 00:36:32,369
And the last thing is just a normalizing factor.

925
00:36:33,720 --> 00:36:37,182
So this captures, this sort of prior captures our belief.

926
00:36:37,182 --> 00:36:38,483
Captures our belief in the model.

927
00:36:38,483 --> 00:36:42,326
How strongly do we think that our prior experience is right?

928
00:36:42,326 --> 00:36:45,507
And there's a number of ways of doing that.

929
00:36:45,507 --> 00:36:46,988
And we might say for our coin,

930
00:36:46,988 --> 00:36:48,409
well, we think it's pretty fair.

931
00:36:48,409 --> 00:36:49,550
It's likely that theta is 0.5.

932
00:36:49,550 --> 00:36:51,911
But we're gonna allow for the fact that,

933
00:36:51,911 --> 00:36:54,193
well, we hadn't seen it being manufactured.

934
00:36:54,193 --> 00:36:55,814
So we're not completely sure.

935
00:36:55,814 --> 00:36:57,795
We haven't measured it, we haven't weighed it,

936
00:36:57,795 --> 00:37:00,176
we haven't looked to see if it's a dual-sided coin,

937
00:37:00,176 --> 00:37:01,117
or I mean, a dual-headed coin.

938
00:37:01,897 --> 00:37:06,301
Or we might decide, actually I've seen someone play with this, a magician has been using it on stage

939
00:37:06,301 --> 00:37:11,705
and it's clearly been doctored. So I'll model that by a distribution which is different, which is skewed

940
00:37:11,705 --> 00:37:16,409
maybe to the right hand side. It's more likely, I believe, that this coin is going to come up heads.

941
00:37:16,409 --> 00:37:20,212
And you can encode that straightforwardly into the prior. It's just a normal distribution,

942
00:37:20,212 --> 00:37:24,295
it just needs to sum to one and that allows you to capture your understanding.

943
00:37:25,375 --> 00:37:27,815
So what we do in Bayesian is we plug all that together

944
00:37:27,815 --> 00:37:29,956
and we try to iterate based on data

945
00:37:29,956 --> 00:37:33,417
towards an understanding of how good that model is.

946
00:37:33,417 --> 00:37:37,438
So we start off with essentially an initial guess.

947
00:37:37,438 --> 00:37:38,118
We have a prior.

948
00:37:38,118 --> 00:37:40,099
We say we believe the coin is fair

949
00:37:40,099 --> 00:37:42,539
and we create a distribution based on that.

950
00:37:42,539 --> 00:37:43,319
We plug it in.

951
00:37:43,319 --> 00:37:44,480
We know what our likelihood is

952
00:37:44,480 --> 00:37:46,960
because it's the binomial in this case.

953
00:37:46,960 --> 00:37:48,961
We observe data, coin tosses,

954
00:37:48,961 --> 00:37:50,061
so we look at 10 tosses

955
00:37:50,061 --> 00:37:51,922
and see how many heads or tails there are.

956
00:37:51,922 --> 00:37:53,922
We plug that into our likelihood function.

957
00:37:54,082 --> 00:37:55,843
Multiply all that together, and we get a new result

958
00:37:55,843 --> 00:37:57,864
at the left-hand side, which is the posterior.

959
00:37:57,864 --> 00:38:00,326
And this new result is essentially a new distribution.

960
00:38:00,326 --> 00:38:02,887
It says, based on everything we've seen,

961
00:38:02,887 --> 00:38:05,889
our belief in the thetas and our likelihoods,

962
00:38:05,889 --> 00:38:08,630
this is our best guess now as to how fair the coin is.

963
00:38:08,630 --> 00:38:10,671
And it's still a distribution of probabilities.

964
00:38:11,332 --> 00:38:13,093
And what we can do now is plug that back in.

965
00:38:13,093 --> 00:38:14,735
We say, all right, we'll use that as a starting point

966
00:38:14,735 --> 00:38:15,495
for the next iteration.

967
00:38:15,495 --> 00:38:18,098
And then we get a lovely sort of iterative loop

968
00:38:18,098 --> 00:38:19,499
where we can continually refine

969
00:38:19,499 --> 00:38:21,521
and plug in the data that we see,

970
00:38:21,521 --> 00:38:23,002
plug in the new data that we get,

971
00:38:23,002 --> 00:38:25,665
and evolve over time this probability

972
00:38:25,665 --> 00:38:28,948
that the coin is fair or the conversion rate is actually 30%.

973
00:38:31,049 --> 00:38:32,470
So selecting priors is tricky.

974
00:38:32,470 --> 00:38:34,952
Now the great thing today is with computers

975
00:38:34,952 --> 00:38:37,874
and numerical methods and pi MC

976
00:38:37,874 --> 00:38:40,416
and lots of great mathematical libraries out there,

977
00:38:40,416 --> 00:38:42,578
we sort of don't have to worry about some of this stuff.

978
00:38:42,578 --> 00:38:44,139
But typically in the past people used

979
00:38:44,139 --> 00:38:46,981
what's known as a conjugate prior to make all this simple.

980
00:38:46,981 --> 00:38:49,323
So just very quickly I'll describe that.

981
00:38:49,323 --> 00:38:51,805
This is our likelihood function.

982
00:38:53,112 --> 00:38:54,634
When you plug it into the previous base,

983
00:38:54,634 --> 00:38:56,235
you get something horrible like this.

984
00:38:56,235 --> 00:38:57,616
So obviously this is a scary function.

985
00:38:57,616 --> 00:38:58,917
Lots of things can go wrong here.

986
00:38:58,917 --> 00:39:00,579
But the most important thing is,

987
00:39:00,579 --> 00:39:02,481
we've got a prior here and here.

988
00:39:02,481 --> 00:39:05,463
So we're gonna multiply our binomial by a prior.

989
00:39:05,463 --> 00:39:07,005
We hope that that will come out to something

990
00:39:07,005 --> 00:39:08,346
that's easy to work with.

991
00:39:08,346 --> 00:39:10,067
And then underneath it, we've got this integral

992
00:39:10,067 --> 00:39:12,169
with a prior, again, a bit messy to deal with.

993
00:39:12,169 --> 00:39:14,551
So is there some way we can sort of stack the odds

994
00:39:14,551 --> 00:39:15,913
in our favor and make life easy?

995
00:39:15,913 --> 00:39:18,375
Well, you can by using what's known as a conjugate prior.

996
00:39:19,175 --> 00:39:25,942
So we would like that multiplying the prior by this binomial thing gives us something that looks basically like a binomial again.

997
00:39:25,942 --> 00:39:31,488
So that when we multiply again it looks again like a binomial and we can just deal with this algebraically rather than numerically.

998
00:39:31,488 --> 00:39:38,776
Similarly we'd like that integral just to be tractable. Ideally it's analytical so I can actually just run a formula and get a number at the end.

999
00:39:38,776 --> 00:39:42,760
And that turns out to be fairly straightforward for lots of different distributions.

1000
00:39:43,898 --> 00:39:45,179
So that's what a conjugate prior is.

1001
00:39:45,179 --> 00:39:47,441
It's something that just works nicely

1002
00:39:47,441 --> 00:39:48,802
in this sort of formula.

1003
00:39:48,802 --> 00:39:51,243
And the conjugate prior we use for a binomial

1004
00:39:51,243 --> 00:39:52,944
is something called a beta, a beta function,

1005
00:39:52,944 --> 00:39:54,365
a beta distribution, should I say.

1006
00:39:54,365 --> 00:39:56,147
And that's, if you look at the shape of it,

1007
00:39:56,147 --> 00:39:57,207
just look at how it's written,

1008
00:39:57,207 --> 00:39:59,029
it's sort of similar to that binomial.

1009
00:39:59,029 --> 00:40:02,531
A binomial is in fact a specialization of a beta function.

1010
00:40:03,602 --> 00:40:05,704
So I'm not gonna get into this,

1011
00:40:05,704 --> 00:40:07,566
this is the normalizing term,

1012
00:40:07,566 --> 00:40:10,409
but just to say it's a factorial at the end of the day,

1013
00:40:10,409 --> 00:40:12,852
it's an integer value, it's really easy to work with.

1014
00:40:12,852 --> 00:40:15,574
So a big scary integral turns out to be

1015
00:40:15,574 --> 00:40:17,476
just a couple of multiplies on a computer,

1016
00:40:17,476 --> 00:40:19,298
so it's very straightforward to code out.

1017
00:40:19,298 --> 00:40:22,762
And it turns out this beta function,

1018
00:40:22,762 --> 00:40:23,562
previously we had...

1019
00:40:24,001 --> 00:40:26,522
the probability of a head or a tail,

1020
00:40:26,522 --> 00:40:29,243
we can actually create a prior that maps

1021
00:40:29,243 --> 00:40:31,224
to the number of heads and tails we've seen before,

1022
00:40:31,224 --> 00:40:33,725
literally by plugging in for this first parameter A,

1023
00:40:33,725 --> 00:40:35,025
the number of heads plus one,

1024
00:40:35,025 --> 00:40:37,586
and the second parameter B, the number of tails plus one.

1025
00:40:37,586 --> 00:40:41,028
So if you flip a coin and see 10 heads and five tails,

1026
00:40:41,028 --> 00:40:43,249
stick in 11 and six for the A and B parameters,

1027
00:40:43,249 --> 00:40:45,149
and that is a beta prior that represents

1028
00:40:45,149 --> 00:40:47,951
exactly your knowledge about that coin to date,

1029
00:40:47,951 --> 00:40:49,431
and you use that to kickstart the system.

1030
00:40:49,431 --> 00:40:50,432
It's really simple.

1031
00:40:51,682 --> 00:40:54,564
So here's just examples of that beta distribution.

1032
00:40:54,564 --> 00:40:57,065
And this is sort of an interesting one.

1033
00:40:57,065 --> 00:40:58,506
This is a, I have no information yet,

1034
00:40:58,506 --> 00:40:59,527
I've never flipped a coin.

1035
00:40:59,527 --> 00:41:02,368
In fact, I don't even know if there's a head or a tail,

1036
00:41:02,368 --> 00:41:03,889
so I can't say anything about it.

1037
00:41:03,889 --> 00:41:06,491
So essentially, it's an uninformed prior,

1038
00:41:06,491 --> 00:41:07,831
it's just uniform, we know nothing.

1039
00:41:07,831 --> 00:41:10,073
After, say, flipping a coin,

1040
00:41:10,073 --> 00:41:12,434
you might find it came up two tails.

1041
00:41:13,387 --> 00:41:16,088
So what this means is I now have evidence that tails exist

1042
00:41:16,088 --> 00:41:18,909
but I have no evidence that heads actually exist.

1043
00:41:18,909 --> 00:41:21,971
So I can't say the probability of heads being zero

1044
00:41:21,971 --> 00:41:23,872
is non-zero.

1045
00:41:23,872 --> 00:41:27,013
So we get this sort of strange slope distribution.

1046
00:41:27,013 --> 00:41:29,394
And as soon as I see a head, I start getting

1047
00:41:29,394 --> 00:41:32,015
the classic sort of bell curve shaped thing.

1048
00:41:32,015 --> 00:41:34,617
And different shapes of A's and B's give you things

1049
00:41:34,617 --> 00:41:37,138
that look like exactly like the binomials we saw earlier.

1050
00:41:37,138 --> 00:41:38,919
And that's true because there's always a beta

1051
00:41:38,919 --> 00:41:39,679
to match a binomial.

1052
00:41:41,082 --> 00:41:42,024
So plug it in.

1053
00:41:42,024 --> 00:41:43,948
Again, it looks a bit scary, but we have our...

1054
00:41:44,606 --> 00:41:46,347
binomial and we have our beta.

1055
00:41:46,347 --> 00:41:48,288
We multiply those things together

1056
00:41:48,288 --> 00:41:50,950
and we get something that looks like this.

1057
00:41:50,950 --> 00:41:52,571
That also sort of seems like it's relatively scary

1058
00:41:52,571 --> 00:41:54,012
but it's actually really simple.

1059
00:41:54,012 --> 00:41:57,274
All that's happened is we've changed the values of A and B

1060
00:41:57,274 --> 00:41:58,435
in our beta function essentially.

1061
00:41:58,435 --> 00:42:02,277
And that turns out that Bayesian update step

1062
00:42:02,277 --> 00:42:05,379
in a full Bayesian inference engine using binomials

1063
00:42:05,379 --> 00:42:08,041
which powers certainly the Swerve A-B testing system

1064
00:42:08,041 --> 00:42:10,262
involves just adding one number to another.

1065
00:42:10,262 --> 00:42:11,823
That's fundamentally what you're doing.

1066
00:42:12,303 --> 00:42:15,104
and then some stuff afterwards to interpret the results.

1067
00:42:15,104 --> 00:42:16,545
So I'll skip over that.

1068
00:42:16,545 --> 00:42:20,126
So putting it together, we first off decide on a prior

1069
00:42:20,126 --> 00:42:23,167
which captures our belief about how strong the coin is biased

1070
00:42:23,167 --> 00:42:25,468
and that just is a function with a certain shape.

1071
00:42:25,468 --> 00:42:27,668
We run our experiment and observe some data

1072
00:42:27,668 --> 00:42:28,829
for heads and tails.

1073
00:42:28,829 --> 00:42:31,310
Based on that, we update our view

1074
00:42:31,310 --> 00:42:34,811
of what the posterior distribution is or our model is.

1075
00:42:35,671 --> 00:42:37,172
And using that, we can sort of feed it back

1076
00:42:37,172 --> 00:42:38,413
into the system and keep going.

1077
00:42:38,413 --> 00:42:39,915
And essentially, at any point in time,

1078
00:42:39,915 --> 00:42:43,298
we have a new belief about how well

1079
00:42:43,298 --> 00:42:44,719
our model represents the coin,

1080
00:42:44,719 --> 00:42:46,821
or represents that conversion rate.

1081
00:42:46,821 --> 00:42:48,322
And at some point, you stop and say,

1082
00:42:48,322 --> 00:42:49,663
I've done enough.

1083
00:42:49,663 --> 00:42:52,185
Some conversion has been achieved,

1084
00:42:52,185 --> 00:42:54,407
or I see a result that I'm happy with.

1085
00:42:54,407 --> 00:42:55,708
It's gone above a certain threshold.

1086
00:42:55,708 --> 00:42:58,230
And we'll talk a little bit about that now.

1087
00:42:59,251 --> 00:43:00,693
So this is what it looks like when you run that.

1088
00:43:00,693 --> 00:43:02,095
It's an iteration process.

1089
00:43:02,095 --> 00:43:03,036
And all that's really happening

1090
00:43:03,036 --> 00:43:05,239
is the shape of the beta is changing,

1091
00:43:05,239 --> 00:43:08,523
representing how confident we now are in this model.

1092
00:43:08,523 --> 00:43:10,626
And at any point in time, we can stop and say,

1093
00:43:10,626 --> 00:43:12,809
this is what we think our conversion rate is.

1094
00:43:12,809 --> 00:43:14,351
It's, looking at this, it's about 30%

1095
00:43:14,351 --> 00:43:17,114
with a spread of, you know, 0.1.

1096
00:43:19,105 --> 00:43:21,006
Now if we plug that in to an actual experiment

1097
00:43:21,006 --> 00:43:23,006
and start running it, so we start off

1098
00:43:23,006 --> 00:43:25,807
with a uniform prior, that is we don't have

1099
00:43:25,807 --> 00:43:27,987
any prior knowledge at all of this coin.

1100
00:43:27,987 --> 00:43:30,388
And let's say the coin is actually fair,

1101
00:43:30,388 --> 00:43:31,308
it's theta parameter is 0.5,

1102
00:43:31,308 --> 00:43:34,049
and we start flipping it and seeing what happens.

1103
00:43:34,049 --> 00:43:37,710
So we get two heads, two tails, 10 heads, 11 tails,

1104
00:43:37,710 --> 00:43:40,270
31 heads, 29 tails, and as we go we can see

1105
00:43:40,270 --> 00:43:43,191
what's happening is we're increasing our certainty

1106
00:43:43,191 --> 00:43:45,471
that this coin looks like it's fair,

1107
00:43:45,471 --> 00:43:48,432
the dotted line there represents the 0.5 line.

1108
00:43:49,152 --> 00:43:51,433
We can see that even though it's still,

1109
00:43:51,433 --> 00:43:52,793
even though it's centered at .5,

1110
00:43:52,793 --> 00:43:54,794
we're still allowing for the fact that

1111
00:43:54,794 --> 00:43:56,974
we might not have seen all the examples

1112
00:43:56,974 --> 00:43:58,035
of the coin's behavior.

1113
00:43:58,035 --> 00:44:00,015
And so we're allowing for the fact

1114
00:44:00,015 --> 00:44:01,776
that it could be .6, .7 or something lower.

1115
00:44:01,776 --> 00:44:04,837
But as you see more data, that tightness starts to happen.

1116
00:44:04,837 --> 00:44:06,757
And essentially we get more and more confident

1117
00:44:06,757 --> 00:44:09,058
about the spread of the actual true distribution.

1118
00:44:09,058 --> 00:44:11,438
So we're pretty sure this coin is fair

1119
00:44:11,438 --> 00:44:13,599
because it looks like this one is very close to .5

1120
00:44:13,599 --> 00:44:14,019
at its peak.

1121
00:44:15,374 --> 00:44:18,415
Let's say we have prior knowledge that the coin is fair.

1122
00:44:18,415 --> 00:44:20,576
So we're actually starting off with something like this.

1123
00:44:20,576 --> 00:44:23,337
This is our prior, and we've drawn this curve ourselves.

1124
00:44:23,337 --> 00:44:25,258
Say previously we saw 50 heads and 50 tails,

1125
00:44:25,258 --> 00:44:27,098
and now we start the experiment.

1126
00:44:27,098 --> 00:44:28,919
With essentially the same sort of data,

1127
00:44:28,919 --> 00:44:30,400
run it a few times, and you can see.

1128
00:44:30,840 --> 00:44:33,123
Even though we're sort of getting the same data coming in,

1129
00:44:33,123 --> 00:44:35,045
it's not exactly the same, but it's pretty close.

1130
00:44:35,045 --> 00:44:37,268
Generally, the shape of the curve hasn't changed at all.

1131
00:44:37,268 --> 00:44:39,831
What's really happened is nothing has come in

1132
00:44:39,831 --> 00:44:43,035
to upset our belief that this coin is actually fair.

1133
00:44:43,035 --> 00:44:46,880
And in fact, all we've done is we've improved our certainty.

1134
00:44:46,880 --> 00:44:47,521
It's become sort of tighter.

1135
00:44:47,521 --> 00:44:49,463
Let's look at the opposite case.

1136
00:44:50,356 --> 00:44:52,416
where we start off with a biased coin

1137
00:44:52,416 --> 00:44:55,357
and we start observing what the true case is.

1138
00:44:55,357 --> 00:44:57,038
So we start off with no prior,

1139
00:44:57,038 --> 00:44:59,018
we've no previous knowledge at all,

1140
00:44:59,018 --> 00:45:00,499
we haven't seen the coin being made,

1141
00:45:00,499 --> 00:45:02,139
and we start observing the result.

1142
00:45:02,139 --> 00:45:04,580
And in this case you can see that over time

1143
00:45:04,580 --> 00:45:06,040
we build up a profile that,

1144
00:45:06,040 --> 00:45:08,081
ah yeah, this coin is definitely unfair,

1145
00:45:08,081 --> 00:45:10,141
it's sort of off to the right-hand side.

1146
00:45:10,141 --> 00:45:12,922
Certainly that the mass of our probability distribution

1147
00:45:12,922 --> 00:45:14,563
is not centered around point five.

1148
00:45:14,563 --> 00:45:16,543
So we'd say that's probably an unfair coin,

1149
00:45:16,543 --> 00:45:17,683
given what we've seen.

1150
00:45:19,381 --> 00:45:22,963
Now what happens if we start out with a preconceived bias,

1151
00:45:22,963 --> 00:45:24,623
that we think this coin is fair?

1152
00:45:24,623 --> 00:45:25,364
What does that mean?

1153
00:45:25,364 --> 00:45:26,704
Actually, it changes things,

1154
00:45:26,704 --> 00:45:29,526
and this is maybe the negative side of priors.

1155
00:45:29,526 --> 00:45:30,967
So if we're pretty certain the coin is fair,

1156
00:45:30,967 --> 00:45:32,067
and then we start observing it,

1157
00:45:32,067 --> 00:45:34,608
and then it comes up like a very unfair coin,

1158
00:45:34,608 --> 00:45:36,609
we see maybe 20 heads and four tails.

1159
00:45:37,470 --> 00:45:39,131
all that does is really shift it slightly

1160
00:45:39,131 --> 00:45:40,953
because there's a weight of evidence already

1161
00:45:40,953 --> 00:45:41,914
expressed in the prior.

1162
00:45:41,914 --> 00:45:44,757
And that's where working with the prior is really important.

1163
00:45:44,757 --> 00:45:48,580
You need to be very clear about how much confidence

1164
00:45:48,580 --> 00:45:50,542
or how much certainty you put into that prior

1165
00:45:50,542 --> 00:45:54,005
because it'll impede progress in your experiment

1166
00:45:54,005 --> 00:45:55,406
if you're really sure.

1167
00:45:55,406 --> 00:45:57,929
But that's a good thing because it means that you're saying,

1168
00:45:57,929 --> 00:45:59,410
I'm really sure the conversion rate is 30%.

1169
00:45:59,410 --> 00:46:01,112
I want to see a heck of a lot of evidence

1170
00:46:01,112 --> 00:46:02,933
before I'm prepared to accept that it's not.

1171
00:46:04,083 --> 00:46:05,463
So in this case, we're not sure of anything.

1172
00:46:05,463 --> 00:46:07,104
So when do you reject?

1173
00:46:07,104 --> 00:46:11,485
Well, quite simply, we reject based on how far

1174
00:46:11,485 --> 00:46:13,006
into the center of the bell curve

1175
00:46:13,006 --> 00:46:14,787
or into the center of the mass

1176
00:46:14,787 --> 00:46:17,168
is the observation that we have.

1177
00:46:17,168 --> 00:46:20,029
And in this case, we can look at the credible interval.

1178
00:46:20,029 --> 00:46:23,510
And this is just looking at the probability distribution,

1179
00:46:23,510 --> 00:46:24,870
figuring out where 95% of the mass is.

1180
00:46:24,870 --> 00:46:26,631
This is where it's sort of similar

1181
00:46:26,631 --> 00:46:27,591
to null hypothesis testing.

1182
00:46:27,591 --> 00:46:30,712
And then checking to see if the 0.5 value is inside of that.

1183
00:46:30,712 --> 00:46:31,713
And in this case, it is.

1184
00:46:31,993 --> 00:46:33,593
So we would express this as saying,

1185
00:46:33,593 --> 00:46:36,254
we're 95% confident that this coin is fair.

1186
00:46:36,254 --> 00:46:38,815
Similarly with the previous one,

1187
00:46:38,815 --> 00:46:41,216
with the uniform prior and the biased coin,

1188
00:46:41,216 --> 00:46:45,057
we're pretty confident, we're greater than 95% confident

1189
00:46:45,057 --> 00:46:46,478
that this coin is unfair in this case.

1190
00:46:46,478 --> 00:46:48,778
So it's outside that credible interval.

1191
00:46:49,762 --> 00:46:54,003
So the prior captures our belief, captures our experience,

1192
00:46:54,003 --> 00:46:58,224
and it's a really creative way, mathematically,

1193
00:46:58,224 --> 00:46:59,424
to get business knowledge and intuition

1194
00:46:59,424 --> 00:47:00,364
into a system like this,

1195
00:47:00,364 --> 00:47:01,885
which the null hypothesis approach

1196
00:47:01,885 --> 00:47:04,285
has no real easy way to do.

1197
00:47:04,285 --> 00:47:07,526
Strong beliefs means that we need lots of evidence

1198
00:47:07,526 --> 00:47:08,966
to conflict our belief, which is good.

1199
00:47:08,966 --> 00:47:11,987
It means I really need to be convinced before

1200
00:47:11,987 --> 00:47:14,007
I'm prepared to accept that this coin isn't fair.

1201
00:47:15,156 --> 00:47:17,918
It also provides inertia and it allows convergence

1202
00:47:17,918 --> 00:47:20,880
a lot more quickly if indeed your belief is true.

1203
00:47:20,880 --> 00:47:24,322
And with enough samples though,

1204
00:47:24,322 --> 00:47:26,043
the importance of the prior diminishes.

1205
00:47:26,043 --> 00:47:27,064
So that's a good thing as well.

1206
00:47:27,064 --> 00:47:28,725
And it acts like a really nice filter

1207
00:47:28,725 --> 00:47:29,665
at the start of your test.

1208
00:47:29,665 --> 00:47:31,607
So the noise at the start of your test

1209
00:47:31,607 --> 00:47:33,488
essentially is reduced significantly

1210
00:47:33,488 --> 00:47:34,589
by a decent choice of prior.

1211
00:47:34,589 --> 00:47:36,730
And that makes the experience for a product manager

1212
00:47:36,730 --> 00:47:38,871
or an analyst looking at the A-B tests,

1213
00:47:38,871 --> 00:47:39,952
it makes it a lot easier for them.

1214
00:47:41,008 --> 00:47:42,229
So let's look at running a test.

1215
00:47:42,229 --> 00:47:46,472
So we've got our kind of canny crush bolt thing again.

1216
00:47:46,472 --> 00:47:47,993
We've got our variation A and B.

1217
00:47:47,993 --> 00:47:50,975
We start observing results for both A and B

1218
00:47:50,975 --> 00:47:52,996
and looking at the conversion rates.

1219
00:47:52,996 --> 00:47:56,078
What we have now is sort of two of those coin flipping tests

1220
00:47:56,078 --> 00:47:57,819
and we accept the fact that there's probably

1221
00:47:57,819 --> 00:47:58,900
two conversion rates here.

1222
00:47:58,900 --> 00:48:01,501
We just want to know which of those is better.

1223
00:48:02,757 --> 00:48:05,039
So with multiple variants, things get a little trickier.

1224
00:48:05,039 --> 00:48:06,680
We're no longer dealing with one distribution.

1225
00:48:06,680 --> 00:48:09,762
We're actually dealing with a two-dimensional distribution.

1226
00:48:09,762 --> 00:48:11,664
And in order to actually evaluate the results,

1227
00:48:11,664 --> 00:48:13,865
we start getting into a little bit more hairy stuff.

1228
00:48:13,865 --> 00:48:16,227
And that's where the computers start shining.

1229
00:48:16,227 --> 00:48:17,848
So we can start using sort of quadrature rules

1230
00:48:17,848 --> 00:48:20,010
and other things like Markov chain, Monte Carlo.

1231
00:48:20,010 --> 00:48:21,571
But here's what you're actually doing.

1232
00:48:21,571 --> 00:48:24,073
You're getting surfaces for a two-variant test

1233
00:48:24,073 --> 00:48:25,154
or a two-treatment test.

1234
00:48:25,494 --> 00:48:27,896
A three treatment test is now a volume,

1235
00:48:27,896 --> 00:48:29,517
and four treatment, you're into four dimensions,

1236
00:48:29,517 --> 00:48:33,079
and it gets harder to think about or to visualize.

1237
00:48:33,079 --> 00:48:34,500
But the sort of 2D or 2.5D version

1238
00:48:34,500 --> 00:48:35,280
is fairly straightforward.

1239
00:48:35,280 --> 00:48:39,463
So this is our conversion expectation for A

1240
00:48:39,463 --> 00:48:40,884
and a conversion expectation for B,

1241
00:48:40,884 --> 00:48:43,966
the two different versions of the game.

1242
00:48:43,966 --> 00:48:45,907
And in both cases, it's sort of centered

1243
00:48:45,907 --> 00:48:46,528
or close to that 30%,

1244
00:48:46,528 --> 00:48:48,549
which I should have skewed when I.

1245
00:48:49,720 --> 00:48:51,804
And this is what we're actually trying to evaluate.

1246
00:48:51,804 --> 00:48:53,607
We're trying to say, is A better than B?

1247
00:48:53,607 --> 00:48:55,811
And A is better than B if essentially the area

1248
00:48:55,811 --> 00:48:59,257
under the curve where theta A is greater than theta B

1249
00:48:59,257 --> 00:48:59,777
is larger.

1250
00:48:59,777 --> 00:49:01,280
That's essentially what we're trying to evaluate,

1251
00:49:01,280 --> 00:49:02,101
which is this thing here.

1252
00:49:02,607 --> 00:49:05,328
So we just look at the area where theta A is greater

1253
00:49:05,328 --> 00:49:07,550
than theta B, we integrate under the curve,

1254
00:49:07,550 --> 00:49:09,211
we compute the volume of that shape,

1255
00:49:09,211 --> 00:49:12,013
and we say, is it greater on the right-hand side

1256
00:49:12,013 --> 00:49:13,393
or on the left-hand side?

1257
00:49:13,393 --> 00:49:15,695
If it's greater on the right-hand side, then A is better.

1258
00:49:15,695 --> 00:49:18,016
If it's greater on the left-hand side, B is better.

1259
00:49:18,016 --> 00:49:20,218
And the volume gives us our degree of certainty.

1260
00:49:20,218 --> 00:49:21,899
And it's a really cool way of saying,

1261
00:49:21,899 --> 00:49:23,580
I am 75% certain that A is better than B.

1262
00:49:23,580 --> 00:49:25,661
It gives us a real number to work with,

1263
00:49:25,661 --> 00:49:28,163
a probability to work with, which is why it's so useful.

1264
00:49:29,300 --> 00:49:30,960
What prior might we use for our game?

1265
00:49:30,960 --> 00:49:34,101
So in this case, we have a prior which is, say, 30%,

1266
00:49:34,101 --> 00:49:36,762
but we need to figure out a spread.

1267
00:49:36,762 --> 00:49:39,763
How certain am I about the 30% conversion rate

1268
00:49:39,763 --> 00:49:41,223
for day one retention?

1269
00:49:41,223 --> 00:49:42,563
Well, maybe I'm not very certain at all,

1270
00:49:42,563 --> 00:49:44,844
but what I can do is I can look at the history of the game.

1271
00:49:44,844 --> 00:49:46,244
So maybe I've run the game for a month,

1272
00:49:46,244 --> 00:49:47,785
and I actually have data to say,

1273
00:49:47,785 --> 00:49:49,265
what sort of conversion rates,

1274
00:49:49,265 --> 00:49:51,126
what sort of retention rates was I seeing?

1275
00:49:51,126 --> 00:49:54,046
And here's an actual game that's available now.

1276
00:49:54,607 --> 00:49:58,131
with a conversion rate around about 30% for day one,

1277
00:49:58,131 --> 00:49:59,372
and that's the spread.

1278
00:49:59,372 --> 00:50:01,655
So what we can do is we can just very simply

1279
00:50:01,655 --> 00:50:02,816
fit a beta to that.

1280
00:50:02,816 --> 00:50:04,658
In this case, it was a beta with an A of 42 and a B of 94.

1281
00:50:04,658 --> 00:50:06,260
Really simple to do with Python and OR.

1282
00:50:06,260 --> 00:50:09,203
And then you feed that into your system.

1283
00:50:09,904 --> 00:50:12,226
And you start running your Bayesian analysis.

1284
00:50:12,226 --> 00:50:14,448
You iterate with all the data you see.

1285
00:50:14,448 --> 00:50:15,689
You iterate with the coin tosses,

1286
00:50:15,689 --> 00:50:16,289
people do or do not convert.

1287
00:50:16,289 --> 00:50:17,710
And you observe the results.

1288
00:50:17,710 --> 00:50:19,912
And you can observe the results all the time

1289
00:50:19,912 --> 00:50:21,794
and make a choice at any point in time.

1290
00:50:21,794 --> 00:50:24,376
You look at this and nothing's really settled down.

1291
00:50:24,376 --> 00:50:26,658
So we can see that one variant looks like

1292
00:50:26,658 --> 00:50:27,738
it's doing better than the other.

1293
00:50:27,738 --> 00:50:29,280
It was oscillating a bit at the start.

1294
00:50:29,280 --> 00:50:30,601
This used the uniform prior,

1295
00:50:30,601 --> 00:50:32,722
so early oscillation is classic there.

1296
00:50:32,722 --> 00:50:35,064
But we're probably saying at this point

1297
00:50:35,064 --> 00:50:38,867
that we're 80% sure that the top variant is better.

1298
00:50:39,468 --> 00:50:40,509
it's probably not a good point to stop.

1299
00:50:40,509 --> 00:50:43,251
You really want to let this run for a little bit longer.

1300
00:50:43,251 --> 00:50:44,652
It's only been running for a few days.

1301
00:50:44,652 --> 00:50:47,054
So here's some examples of real tests that have run.

1302
00:50:47,054 --> 00:50:50,938
This is sort of how we read out the result of a test.

1303
00:50:50,938 --> 00:50:54,040
This is a control in four variants,

1304
00:50:54,040 --> 00:50:56,122
or a four treatment test.

1305
00:50:56,122 --> 00:50:59,245
And in this case, the mathematicians among you

1306
00:50:59,245 --> 00:51:01,967
should be revolting, because there's no such thing

1307
00:51:01,967 --> 00:51:03,789
as 100% certainty in any of these things.

1308
00:51:03,789 --> 00:51:05,690
But we round up from 99.99 to 100,

1309
00:51:05,690 --> 00:51:07,952
so forgive us that at least.

1310
00:51:08,795 --> 00:51:10,096
It just looks nicer on the dashboard.

1311
00:51:10,096 --> 00:51:12,677
So what we're reading out here is the probability

1312
00:51:12,677 --> 00:51:15,239
of any one of those treatments being the outright winner

1313
00:51:15,239 --> 00:51:16,940
or the probability that they beat the control.

1314
00:51:16,940 --> 00:51:19,922
And in this case, here's how that test ran for a while.

1315
00:51:19,922 --> 00:51:22,504
So again, it was uniform prior in this case,

1316
00:51:22,504 --> 00:51:24,305
or an uninformed prior, should I say.

1317
00:51:24,305 --> 00:51:25,526
So lots of noise at the start.

1318
00:51:25,526 --> 00:51:28,088
But it eventually settled down into a very stable result.

1319
00:51:28,088 --> 00:51:30,530
All the other treatments were practically 0%

1320
00:51:30,530 --> 00:51:33,652
and we were very certain that one of these treatments

1321
00:51:33,652 --> 00:51:34,692
was by far and away the winner.

1322
00:51:34,692 --> 00:51:36,173
So that became actionable very quickly.

1323
00:51:37,252 --> 00:51:39,613
And here's how the conversion rate looked over time.

1324
00:51:39,613 --> 00:51:41,754
So again, at the start, this is the actual,

1325
00:51:41,754 --> 00:51:43,875
you know, is it 30% or is it 31% for day one conversion?

1326
00:51:43,875 --> 00:51:45,776
In this case, it was measuring something else.

1327
00:51:45,776 --> 00:51:48,497
But that credible interval that I talked about,

1328
00:51:48,497 --> 00:51:50,357
we're actually tracking that over time as well.

1329
00:51:50,357 --> 00:51:51,298
And that's a good thing to do

1330
00:51:51,298 --> 00:51:54,099
because it gives you an idea of the separation

1331
00:51:54,099 --> 00:51:56,800
of the different treatments and how confident you are.

1332
00:51:56,800 --> 00:51:58,781
What you really want to see is a full separation

1333
00:51:58,781 --> 00:51:59,781
of your 95% credible intervals

1334
00:51:59,781 --> 00:52:02,662
to be really sure that these are different conversion rates.

1335
00:52:02,662 --> 00:52:04,523
But again, it depends on how you're setting up

1336
00:52:04,523 --> 00:52:05,063
the experiment.

1337
00:52:06,108 --> 00:52:08,690
Here's what it looks like when it's not so successful.

1338
00:52:08,690 --> 00:52:09,570
Not so is a bad term.

1339
00:52:09,570 --> 00:52:11,691
This is a successful test,

1340
00:52:11,691 --> 00:52:13,352
but the result wasn't a success.

1341
00:52:13,352 --> 00:52:16,574
So the change we made didn't actually have

1342
00:52:16,574 --> 00:52:18,055
the right impact that we wanted to see.

1343
00:52:18,055 --> 00:52:19,636
So this is what it looked like.

1344
00:52:19,636 --> 00:52:22,837
The control very, very quickly drowned out the treatment.

1345
00:52:22,837 --> 00:52:24,578
And after a couple of observations,

1346
00:52:24,578 --> 00:52:27,560
and you can see there literally the spikiness of this graph

1347
00:52:27,560 --> 00:52:30,261
sort of represents the number of observations.

1348
00:52:30,261 --> 00:52:34,223
And it very quickly drowned out the treatment.

1349
00:52:34,223 --> 00:52:35,624
So we killed that test fairly quickly.

1350
00:52:37,074 --> 00:52:40,276
and this was the observed conversion rate of the posterior.

1351
00:52:40,276 --> 00:52:41,897
So again, you can see that initially,

1352
00:52:41,897 --> 00:52:45,440
we've so little data that the probability distributions

1353
00:52:45,440 --> 00:52:48,342
of both the control and the variant are overlapping.

1354
00:52:48,342 --> 00:52:50,563
Our beta distributions are essentially all over,

1355
00:52:50,563 --> 00:52:51,684
are overlapping each other.

1356
00:52:51,684 --> 00:52:53,605
And you can think of this as just a visualization

1357
00:52:53,605 --> 00:52:54,986
of the shape of the beta distribution

1358
00:52:54,986 --> 00:52:56,227
sort of tightening over time

1359
00:52:56,227 --> 00:52:58,068
as we become more and more certain

1360
00:52:58,068 --> 00:52:59,569
about the true conversion rate

1361
00:52:59,569 --> 00:53:01,490
of each of our population groups.

1362
00:53:01,490 --> 00:53:03,072
Now we're making some big assumptions here.

1363
00:53:03,072 --> 00:53:04,613
First off, that users are independent.

1364
00:53:05,992 --> 00:53:07,753
This isn't such a great assumption to be making,

1365
00:53:07,753 --> 00:53:09,574
for example, in multiplayer games.

1366
00:53:09,574 --> 00:53:12,335
If you're running a test where there can be an interaction

1367
00:53:12,335 --> 00:53:14,917
between users, then you have to be very careful

1368
00:53:14,917 --> 00:53:15,737
about the design of your test.

1369
00:53:15,737 --> 00:53:18,399
It also seems that users convert very quickly.

1370
00:53:18,399 --> 00:53:21,901
In fact, the model assumes users convert instantaneously.

1371
00:53:21,901 --> 00:53:23,122
So that's not great when, say,

1372
00:53:23,122 --> 00:53:25,683
you're looking at a day 30 retention test.

1373
00:53:25,683 --> 00:53:28,465
So you have to sort of frame that slightly differently,

1374
00:53:28,465 --> 00:53:30,166
but I don't have time to get into that here.

1375
00:53:31,107 --> 00:53:32,928
And the other thing we assume is that probability,

1376
00:53:32,928 --> 00:53:35,510
the probability of conversion is independent of time.

1377
00:53:35,510 --> 00:53:36,571
That's also untrue.

1378
00:53:36,571 --> 00:53:39,413
You know, sometimes people might purchase things

1379
00:53:39,413 --> 00:53:41,555
more frequently during lunchtime

1380
00:53:41,555 --> 00:53:43,617
and less likely to purchase, you know,

1381
00:53:43,617 --> 00:53:44,998
at four o'clock in the afternoon.

1382
00:53:44,998 --> 00:53:46,759
So there is a sort of a relationship

1383
00:53:46,759 --> 00:53:47,900
between time and conversion rate.

1384
00:53:47,900 --> 00:53:50,242
So you have to make sure you counter for that

1385
00:53:50,242 --> 00:53:51,403
in some of the modeling.

1386
00:53:51,403 --> 00:53:53,965
Really, a lot of the complexity of Bayesian A-B testing

1387
00:53:53,965 --> 00:53:55,987
really comes in the later stage stuff.

1388
00:53:55,987 --> 00:53:57,868
The implementation of a Bayesian A-B test

1389
00:53:57,868 --> 00:53:59,530
is really straightforward.

1390
00:54:00,312 --> 00:54:02,974
This is what it looks like if you try to run an A-B test

1391
00:54:02,974 --> 00:54:05,355
without any corrections on a conversion

1392
00:54:05,355 --> 00:54:07,196
that happens a long time into the game.

1393
00:54:07,196 --> 00:54:09,437
Let's say, you know, after seven or eight days of play.

1394
00:54:09,437 --> 00:54:11,238
In this case, actually it's not.

1395
00:54:11,238 --> 00:54:13,879
This is probably about three or four hours into play,

1396
00:54:13,879 --> 00:54:15,160
not looking at the data.

1397
00:54:15,160 --> 00:54:16,781
But you can see that the conversion rate

1398
00:54:16,781 --> 00:54:17,821
hasn't settled down.

1399
00:54:18,202 --> 00:54:21,024
it's sort of starting to become asymptotic to something.

1400
00:54:21,024 --> 00:54:22,186
So when you're running tests,

1401
00:54:22,186 --> 00:54:24,167
and if you see something like this in your own graphs,

1402
00:54:24,167 --> 00:54:26,530
wait until it flattens out so that you can see,

1403
00:54:26,530 --> 00:54:29,793
my population has actually reached a stable conversion rate

1404
00:54:29,793 --> 00:54:30,934
and I have a decent estimator.

1405
00:54:32,205 --> 00:54:34,586
So some benefits and features of Bayesian.

1406
00:54:34,586 --> 00:54:36,588
It's continuously observable, and this is genius.

1407
00:54:36,588 --> 00:54:38,489
Unlike the null hypothesis stuff

1408
00:54:38,489 --> 00:54:40,050
where you have to set up the test in advance

1409
00:54:40,050 --> 00:54:41,631
and being fairly rigorous about that,

1410
00:54:41,631 --> 00:54:42,431
Bayesian, you just look at it,

1411
00:54:42,431 --> 00:54:43,912
and you get a new probability every day,

1412
00:54:43,912 --> 00:54:45,773
hour, minute, even second,

1413
00:54:45,773 --> 00:54:48,175
depending on how you implement the infrastructure.

1414
00:54:48,175 --> 00:54:50,816
So there's no need to think about population sizes

1415
00:54:50,816 --> 00:54:53,658
in advance, you just let your users flow over your test,

1416
00:54:53,658 --> 00:54:54,539
and you look at the results,

1417
00:54:54,539 --> 00:54:57,140
and you build up with every new piece of data that you have,

1418
00:54:57,140 --> 00:55:00,763
a new model that represents what we believe about the game.

1419
00:55:01,578 --> 00:55:03,800
We can incorporate prior knowledge using the prior,

1420
00:55:03,800 --> 00:55:05,261
which is really cool.

1421
00:55:05,261 --> 00:55:07,082
The ability to bring in your own business knowledge

1422
00:55:07,082 --> 00:55:09,344
or your own experience from previous tests

1423
00:55:09,344 --> 00:55:11,826
or experience about what you know about games

1424
00:55:11,826 --> 00:55:14,348
and bring that to bear and sort of factor that

1425
00:55:14,348 --> 00:55:17,770
into the mathematical implementation is really cool.

1426
00:55:17,770 --> 00:55:21,193
And the result at any point in time is a true probability.

1427
00:55:21,193 --> 00:55:22,294
It's a value from zero to one

1428
00:55:22,294 --> 00:55:23,815
that you can sort of intuit about

1429
00:55:23,815 --> 00:55:26,257
and doesn't have any strange special casing

1430
00:55:26,257 --> 00:55:28,619
about null hypotheses and false positives or.

1431
00:55:29,159 --> 00:55:31,120
Clearly it can have false positives,

1432
00:55:31,120 --> 00:55:33,441
but it doesn't have any of the strangeness of a p-value.

1433
00:55:33,441 --> 00:55:36,323
And as well as that, it gives you a magnitude

1434
00:55:36,323 --> 00:55:38,324
of the difference between population groups,

1435
00:55:38,324 --> 00:55:40,725
a magnitude of the effect you're seeing.

1436
00:55:40,725 --> 00:55:43,206
Again, with null hypothesis, all you get to know is,

1437
00:55:43,206 --> 00:55:46,468
is it or is it not likely to be due to that distribution?

1438
00:55:46,468 --> 00:55:48,469
So it's a binary choice, whereas in Bayesian,

1439
00:55:48,469 --> 00:55:50,190
you get a magnitude in the probability,

1440
00:55:50,190 --> 00:55:52,451
and that all makes for a much better assessment

1441
00:55:52,451 --> 00:55:53,531
of the results of the test.

1442
00:55:54,072 --> 00:55:55,753
And frankly, it's a really great framework

1443
00:55:55,753 --> 00:55:58,275
for building lots of different analyses inside your game.

1444
00:55:58,275 --> 00:56:01,857
So get onto your analysts, get onto your data scientists

1445
00:56:01,857 --> 00:56:04,339
and your companies, and get them to build a Bayesian framework.

1446
00:56:04,339 --> 00:56:06,701
Because you can start to look at lots of other different things

1447
00:56:06,701 --> 00:56:08,322
and not just simple A-B tests.

1448
00:56:09,860 --> 00:56:11,961
So some useful links, that's just for those of you

1449
00:56:11,961 --> 00:56:14,503
who want to download the paper or the talk later.

1450
00:56:14,503 --> 00:56:16,504
I'd particularly recommend that first link.

1451
00:56:16,504 --> 00:56:19,385
If you haven't heard about

1452
00:56:19,385 --> 00:56:23,187
Cam Davidson's The Probabilistic Programming thing in Python,

1453
00:56:23,187 --> 00:56:26,289
it's a book written in IPython, so it's fully interactive.

1454
00:56:26,289 --> 00:56:28,310
It's the most genius thing I've come across

1455
00:56:28,310 --> 00:56:29,130
in the last year.

1456
00:56:29,130 --> 00:56:32,972
So if you just Google for Bayesian hacking, I think it is,

1457
00:56:32,972 --> 00:56:34,233
or Bayesian hackers.

1458
00:56:34,954 --> 00:56:36,134
you'll come across it.

1459
00:56:36,134 --> 00:56:37,035
Absolutely brilliant book.

1460
00:56:37,035 --> 00:56:38,396
Can't recommend it enough.

1461
00:56:38,396 --> 00:56:41,898
It's not finished, so there's a lot of errata to come,

1462
00:56:41,898 --> 00:56:42,699
but it's great.

1463
00:56:42,699 --> 00:56:48,382
Other than that, I'd just like to thank you for your time

1464
00:56:48,382 --> 00:56:49,763
and ask if there's any questions.

1465
00:56:49,763 --> 00:56:49,943
Thank you.

1466
00:56:49,943 --> 00:56:58,929
So we have one question there.

1467
00:56:58,929 --> 00:57:00,791
We might use the.

1468
00:57:02,504 --> 00:57:04,669
Actually, there's one over there, the microphone,

1469
00:57:04,669 --> 00:57:07,174
so I'm gonna go with him first, right?

1470
00:57:07,174 --> 00:57:08,677
Oh, sorry, he went the previous way.

1471
00:57:08,677 --> 00:57:08,837
Yes.

1472
00:57:11,637 --> 00:57:19,904
Hi, thanks. So, one thing that I think most people who have worked with MCMC know is that it is quite computationally expensive.

1473
00:57:19,904 --> 00:57:28,172
And I'm wondering whether you have successfully scaled some of these approaches to tens of thousands, hundreds of thousands, millions of users,

1474
00:57:28,172 --> 00:57:35,399
or whether you do some kind of sampling or use closed form kind of solutions, or how it is that you run this at scale?

1475
00:57:35,399 --> 00:57:37,080
Yeah, good question. In fact, the...

1476
00:57:38,802 --> 00:57:41,583
If you're rerunning this or you're computing the results,

1477
00:57:41,583 --> 00:57:43,364
every new user and every new observation,

1478
00:57:43,364 --> 00:57:44,204
clearly that's an issue.

1479
00:57:44,204 --> 00:57:45,685
So we batch that up for a start.

1480
00:57:45,685 --> 00:57:47,086
So we look at series of observations

1481
00:57:47,086 --> 00:57:49,227
and then we sort of recompute at regular intervals.

1482
00:57:49,227 --> 00:57:51,368
To be honest, most of the tests we run

1483
00:57:51,368 --> 00:57:52,889
are actually straightforward.

1484
00:57:52,889 --> 00:57:54,910
We don't even have to resort to the MCMC stuff.

1485
00:57:54,910 --> 00:57:57,171
And we can use this analytic closed form solutions

1486
00:57:57,171 --> 00:57:59,832
that exist out there for computing the area

1487
00:57:59,832 --> 00:58:02,474
under multi-dimensional sort of beta functions.

1488
00:58:02,474 --> 00:58:04,595
So there's a very good Java library

1489
00:58:04,595 --> 00:58:06,556
whose name I sort of forget at the moment.

1490
00:58:06,976 --> 00:58:08,556
but if you ping me afterwards by email,

1491
00:58:08,556 --> 00:58:09,437
I'll send it to you.

1492
00:58:09,437 --> 00:58:11,797
And that's a great library that we use internally

1493
00:58:11,797 --> 00:58:13,238
for computing these integrals.

1494
00:58:13,238 --> 00:58:13,938
Thank you.

1495
00:58:13,938 --> 00:58:14,338
I think it's you.

1496
00:58:14,338 --> 00:58:15,838
So I'm not trying to defend frequentist statistics,

1497
00:58:15,838 --> 00:58:20,680
but one nice thing about the Naaman-Pearson approach

1498
00:58:20,680 --> 00:58:28,222
is that it at least gives you a way to think about

1499
00:58:28,222 --> 00:58:31,163
inferential risk for type one, type two error.

1500
00:58:31,697 --> 00:58:35,420
with respect to sample size, and I'm wondering in your setting,

1501
00:58:35,420 --> 00:58:40,645
are the sample sizes typically so big that you don't really have to worry about it too much,

1502
00:58:40,645 --> 00:58:47,132
so that the data just flows in and at some point your credible intervals are obvious and then you're done?

1503
00:58:47,132 --> 00:58:48,853
Yeah, I think you're absolutely right.

1504
00:58:50,414 --> 00:58:55,357
I'm not sure, this is probably an untrue statement, but we haven't needed to really think about

1505
00:58:55,357 --> 00:58:58,559
that too much because sample sizes are definitely in the hundreds of thousands of users and

1506
00:58:58,559 --> 00:59:02,021
beyond in which case, you know, you don't really have to think too much about this,

1507
00:59:02,021 --> 00:59:02,702
which is the good news.

1508
00:59:02,702 --> 00:59:07,304
Certainly, if you were doing a test which had only 50 users, then, you know, obviously

1509
00:59:07,304 --> 00:59:10,426
you have to be very careful, you know, you have to be careful of degrees of freedom and

1510
00:59:10,426 --> 00:59:11,967
all that sort of stuff.

1511
00:59:12,207 --> 00:59:14,269
generally by switching to a Bayesian approach

1512
00:59:14,269 --> 00:59:15,610
and by just relying on the fact

1513
00:59:15,610 --> 00:59:17,332
that there's lots of observations,

1514
00:59:17,332 --> 00:59:19,033
we haven't had to get too deep into that stuff.

1515
00:59:19,033 --> 00:59:20,234
But I think you're absolutely right.

1516
00:59:20,234 --> 00:59:24,197
I think there's a deeper set of knowledge

1517
00:59:24,197 --> 00:59:26,179
on the sort of frequentist approach out there.

1518
00:59:26,179 --> 00:59:28,541
The experimental design research

1519
00:59:28,541 --> 00:59:33,125
in sort of frequentist is rich and vast.

1520
00:59:33,125 --> 00:59:35,727
What I sort of like about Bayesian is just simple,

1521
00:59:35,727 --> 00:59:37,008
to be honest, from my perspective.

1522
00:59:37,008 --> 00:59:39,550
So I was able to understand it a little bit better.

1523
00:59:39,550 --> 00:59:39,810
Cheers.

1524
00:59:41,358 --> 00:59:42,279
Thank you.

1525
00:59:42,279 --> 00:59:44,600
It was a very concise talk on Bayesianism.

1526
00:59:44,600 --> 00:59:48,323
And as I'm sure you know, there's always a really big divide against frequentism and

1527
00:59:48,323 --> 00:59:50,885
Bayesianism, especially in a situation I have.

1528
00:59:50,885 --> 00:59:55,248
I'm dealing with lots of basically stats 101 or someone who has an undergrad with math

1529
00:59:55,248 --> 00:59:59,632
that really yell out sample size or bring up these things about Bayesianism.

1530
00:59:59,632 --> 01:00:04,375
And what kind of experiences have you had working with companies or clients of saying,

1531
01:00:04,375 --> 01:00:06,237
hey, this stuff really does work?

1532
01:00:06,905 --> 01:00:11,698
What advice do you have for basically converting people to the benefits of Bayesianism?

1533
01:00:12,922 --> 01:00:15,023
I can only go really from our own experience,

1534
01:00:15,023 --> 01:00:17,844
because largely, when we talk with companies,

1535
01:00:17,844 --> 01:00:19,886
we divorce them from the complexities

1536
01:00:19,886 --> 01:00:21,226
of how we implement this.

1537
01:00:21,226 --> 01:00:23,608
In some cases, we'll talk directly to their data scientists

1538
01:00:23,608 --> 01:00:24,148
and get into it.

1539
01:00:24,148 --> 01:00:29,111
But in my experience, getting to grips with

1540
01:00:29,111 --> 01:00:31,853
and creating a very robust sort of

1541
01:00:31,853 --> 01:00:34,254
frequencist approach to this, we found quite tricky.

1542
01:00:34,254 --> 01:00:37,856
And we went a good deal down the road of doing that,

1543
01:00:37,856 --> 01:00:39,177
looking at correction factors,

1544
01:00:39,177 --> 01:00:41,058
and done it and all those other things.

1545
01:00:42,099 --> 01:00:46,540
But eventually decided to make the switch based on some advice that we got a couple of years ago.

1546
01:00:46,540 --> 01:00:49,121
And since then things have just gone so much easier.

1547
01:00:49,121 --> 01:00:51,182
I think horses for courses.

1548
01:00:51,182 --> 01:00:55,724
I think in the high tech, in the computer world, which I come from, the computer science world,

1549
01:00:55,724 --> 01:00:59,425
I think there's a natural affinity to Bayesian because it...

1550
01:00:59,745 --> 01:01:02,347
It unlocks itself once you have the capability

1551
01:01:02,347 --> 01:01:04,448
of running these calculations at scale,

1552
01:01:04,448 --> 01:01:07,149
where you can divorce yourself from having to figure out

1553
01:01:07,149 --> 01:01:11,271
really complex conjugate priors and can just rely on

1554
01:01:11,271 --> 01:01:13,352
what are also tricky things, the MCMC methods

1555
01:01:13,352 --> 01:01:14,273
and things like that.

1556
01:01:14,273 --> 01:01:16,674
It just sort of fits our model view of the world

1557
01:01:16,674 --> 01:01:17,895
I think a lot better.

1558
01:01:17,895 --> 01:01:21,817
So I wouldn't personally get into the A versus B

1559
01:01:21,817 --> 01:01:24,498
comparison of those two schools.

1560
01:01:24,498 --> 01:01:27,179
We have just found Bayesian, it suits our team better.

1561
01:01:27,179 --> 01:01:27,720
So that's all.

1562
01:01:27,720 --> 01:01:28,840
Thank you.

1563
01:01:29,879 --> 01:01:54,640
If you start taking advantage of some of the more complex methods you touched on, like doing real values instead of discrete, so let's say you're optimizing for revenue, you're looking at ARPU or ARPDAU, and you also want to do multivariate testing, so you're kind of pushing it to the most of what you talked about, do any new challenges emerge there?

1564
01:01:54,640 --> 01:01:58,223
Or tractability of the computation or needing to switch to different methods?

1565
01:02:00,977 --> 01:02:05,119
I guess so far, maybe we haven't gone far enough into this

1566
01:02:05,119 --> 01:02:07,100
to hit up against some of those intractability issues.

1567
01:02:07,100 --> 01:02:09,282
We found the majority of the use cases

1568
01:02:09,282 --> 01:02:11,303
that we've come across can be actually

1569
01:02:11,303 --> 01:02:13,224
nearly trivially solved with Bayesian.

1570
01:02:13,224 --> 01:02:15,365
Now, you do have to implement hierarchical methods,

1571
01:02:15,365 --> 01:02:16,185
you have to get into

1572
01:02:16,506 --> 01:02:19,008
things that are beyond binomial and negative binomial

1573
01:02:19,008 --> 01:02:20,389
and Brownian and all that sort of stuff.

1574
01:02:20,389 --> 01:02:23,793
But fundamentally, once you choose the right model

1575
01:02:23,793 --> 01:02:25,495
and once you choose the right Bayesian approach,

1576
01:02:25,495 --> 01:02:27,156
it all sort of falls out.

1577
01:02:27,156 --> 01:02:29,098
We haven't come across an issue for us

1578
01:02:29,098 --> 01:02:31,781
in terms of computational tractability yet.

1579
01:02:32,798 --> 01:02:35,499
Now I think the direction that we find ourselves going in

1580
01:02:35,499 --> 01:02:38,540
is away from the sort of more curated A-B test approach

1581
01:02:38,540 --> 01:02:41,600
to the more automated optimization and multi-armed bandits

1582
01:02:41,600 --> 01:02:44,061
and starting to think more on sort of that direction.

1583
01:02:44,061 --> 01:02:45,241
And I think that's very interesting

1584
01:02:45,241 --> 01:02:47,801
where you can just sort of automate across

1585
01:02:47,801 --> 01:02:49,682
a parameter space of different options.

1586
01:02:49,682 --> 01:02:51,522
But, and that's probably where we're gonna spend

1587
01:02:51,522 --> 01:02:52,482
most of our time.

1588
01:02:52,482 --> 01:02:52,822
Thank you.

1589
01:02:52,822 --> 01:02:53,162
Cheers.

1590
01:02:53,162 --> 01:02:59,203
In terms of a company looking to buy a system like this,

1591
01:02:59,203 --> 01:03:02,044
can you talk about like the return on an investment?

1592
01:03:02,044 --> 01:03:02,524
Like.

1593
01:03:03,295 --> 01:03:09,084
say a company wasn't doing this sort of approach and then a year later was adopting it,

1594
01:03:09,084 --> 01:03:13,931
what sort of effect would you expect to see in their revenue and business model?

1595
01:03:14,892 --> 01:03:21,494
That's entirely a function of to what degree testing becomes incorporated into the culture of the company.

1596
01:03:21,494 --> 01:03:22,895
So I think you know there's no again

1597
01:03:22,895 --> 01:03:29,397
there's no silver bullet. A piece of technology or a cool platform doesn't actually deliver the ROI in and of itself.

1598
01:03:29,397 --> 01:03:34,178
It sort of has to nearly infiltrate itself into the the way you develop the game and the way you develop the economy and

1599
01:03:34,178 --> 01:03:35,999
the way you manage the store or whatever.

1600
01:03:36,939 --> 01:03:39,000
And I think that's still an ongoing story.

1601
01:03:39,000 --> 01:03:42,241
I can't tell you any specific examples

1602
01:03:42,241 --> 01:03:44,002
of customers working with us,

1603
01:03:44,002 --> 01:03:45,702
because we sort of measure ROI

1604
01:03:45,702 --> 01:03:47,763
nearly on an A-B test by A-B test basis.

1605
01:03:47,763 --> 01:03:49,284
But each of those has value.

1606
01:03:49,284 --> 01:03:53,105
An individual test could be worth 100 bucks,

1607
01:03:53,105 --> 01:03:54,206
could be worth 10,000 bucks,

1608
01:03:54,206 --> 01:03:56,086
depending on what needle you shift.

1609
01:03:57,020 --> 01:04:02,102
You know, I think some companies have defined their success on the basis of always being testing.

1610
01:04:02,102 --> 01:04:06,403
And so I think it does huge value to embedding that in your culture.

1611
01:04:06,403 --> 01:04:13,025
There's obviously a spectrum. You don't want it all just to be data-driven and testing.

1612
01:04:13,025 --> 01:04:15,105
It's also about design and intuition.

1613
01:04:15,105 --> 01:04:16,926
Okay, so a different question.

1614
01:04:16,926 --> 01:04:21,687
You talked a little bit about how do you tell if a change is good or not good?

1615
01:04:22,888 --> 01:04:26,711
A game has a huge surface area of things you could change.

1616
01:04:26,711 --> 01:04:32,016
If you change everything every day, it's a mess.

1617
01:04:32,016 --> 01:04:34,117
So really, an interesting question is,

1618
01:04:34,117 --> 01:04:37,961
I have a whole bunch of ideas that my game designers want to do.

1619
01:04:37,961 --> 01:04:39,822
Which one is the one that I should try first?

1620
01:04:40,235 --> 01:04:41,797
Sort of a very interesting one,

1621
01:04:41,797 --> 01:04:42,978
not quite a philosophical question,

1622
01:04:42,978 --> 01:04:45,060
but really a kind of optimization problem.

1623
01:04:45,060 --> 01:04:47,483
You know, if in the limit you could express

1624
01:04:47,483 --> 01:04:49,465
every parameter of the game to an A-B,

1625
01:04:49,465 --> 01:04:51,206
or an optimization system,

1626
01:04:51,206 --> 01:04:53,549
a whole point he'd hit a sort of a diminishing

1627
01:04:53,549 --> 01:04:55,671
law of return that you now just get too complex

1628
01:04:55,671 --> 01:04:56,712
and are changing too many things.

1629
01:04:56,712 --> 01:04:59,635
I have no idea the answer to that question.

1630
01:04:59,635 --> 01:05:02,337
Our advice to any company working with A-B testing,

1631
01:05:02,337 --> 01:05:04,259
certainly to begin with, is keep it simple.

1632
01:05:04,700 --> 01:05:08,704
talk to your CFO, talk to the guy who owns the P&L

1633
01:05:08,704 --> 01:05:10,686
and ask him, what do you want?

1634
01:05:10,686 --> 01:05:12,708
What's the business goal?

1635
01:05:12,708 --> 01:05:15,510
And then work back from that into what things inside

1636
01:05:15,510 --> 01:05:18,813
the game can impact on that business goal most quickly.

1637
01:05:18,813 --> 01:05:21,076
And generally speaking, that's something to do with

1638
01:05:21,076 --> 01:05:24,339
the economy or the monetization mechanisms inside the game

1639
01:05:24,339 --> 01:05:27,402
and things that directly impact on early stage

1640
01:05:27,402 --> 01:05:28,623
sort of engagement and retention.

1641
01:05:29,183 --> 01:05:30,824
And that's usually where we start out.

1642
01:05:30,824 --> 01:05:33,226
And then over time, you start building more and more tests.

1643
01:05:33,226 --> 01:05:35,707
And I think we're still early, actually,

1644
01:05:35,707 --> 01:05:37,489
certainly for mobile A-B testing

1645
01:05:37,489 --> 01:05:40,470
and this sort of technique in general.

1646
01:05:40,470 --> 01:05:44,533
In the limit, you think about an auto-adapting game

1647
01:05:44,533 --> 01:05:45,914
based on what users are doing,

1648
01:05:45,914 --> 01:05:47,835
some sort of crazy machine learning system

1649
01:05:47,835 --> 01:05:50,997
that adapts itself, but I think that's a limit

1650
01:05:50,997 --> 01:05:52,678
we'll never want to reach, I suspect.

1651
01:05:52,678 --> 01:05:57,321
Okay, listen, thanks very much for your time,

1652
01:05:57,321 --> 01:05:57,901
and enjoy your beers.

1653
01:05:57,901 --> 01:05:58,422
Thank you.

