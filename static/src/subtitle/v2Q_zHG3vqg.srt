1
00:00:01,550 --> 00:00:08,014
Thank you for coming. My name is Barry Genova. I'm the platform technical lead at Bungie.

2
00:00:08,014 --> 00:00:15,038
I'm going to talk about multithreading the Destiny engine. To start off, this talk is not about

3
00:00:15,038 --> 00:00:18,621
multithreaded primitives. We're not going to be talking about atomics. We're not going to be

4
00:00:18,621 --> 00:00:24,304
talking about semaphores. It's more about the engine structure and strategies to increase

5
00:00:24,304 --> 00:00:26,305
parallelization in the engine.

6
00:00:27,122 --> 00:00:33,544
and we're also going to describe our system to help program in multi-threaded ways to prove that it's safe.

7
00:00:33,544 --> 00:00:39,266
So sections, a brief overview, and then I'm going to talk a little bit about multi-threading.

8
00:00:39,266 --> 00:00:44,267
I'm going to follow that up with how we did multi-threading in Destiny, what our philosophies are,

9
00:00:44,267 --> 00:00:48,729
and then how we ended up mapping that to the hardware for the different platforms that we shipped.

10
00:00:48,729 --> 00:00:53,530
I'm going to talk a little bit about how we proved that our code base was thread-safe,

11
00:00:53,530 --> 00:00:56,651
and then how we deployed that into our engine.

12
00:00:57,417 --> 00:01:00,060
and the lessons learned from that. Finally, I'll just wrap

13
00:01:00,060 --> 00:01:06,946
that up. So Destiny is a shared world shooter. We want to

14
00:01:06,946 --> 00:01:11,229
provide low latency action. It's a fast-paced game. It's basically

15
00:01:11,229 --> 00:01:14,312
the start of a new generation for us. We're sun setting Halo.

16
00:01:14,312 --> 00:01:18,756
We're starting with two new consoles, the PS4 and Xbox One.

17
00:01:19,658 --> 00:01:21,641
And then of course we're still shipping on 360 and PS3.

18
00:01:21,641 --> 00:01:30,151
A little bit of gameplay footage in case you're one of the people who aren't the 16 million

19
00:01:30,151 --> 00:01:31,492
people who've played our game yet.

20
00:02:07,430 --> 00:02:10,251
So I'm going to talk a bit about multi-threading, why we needed

21
00:02:10,251 --> 00:02:12,712
to do it, how we knew it was going to be hard.

22
00:02:12,712 --> 00:02:15,373
Basically, we determined that we couldn't ship without

23
00:02:15,373 --> 00:02:16,073
multi-threading.

24
00:02:16,073 --> 00:02:18,954
The gameplay needs to be the same across

25
00:02:18,954 --> 00:02:20,115
all of our platforms.

26
00:02:20,115 --> 00:02:22,496
We want everybody to have the same experience, regardless

27
00:02:22,496 --> 00:02:25,297
where they're playing it, if they're playing it on last gen

28
00:02:25,297 --> 00:02:26,457
or current gen.

29
00:02:27,337 --> 00:02:30,019
But we've already shipped on last gen.

30
00:02:30,019 --> 00:02:34,022
This workload is now much more than we've done in the past

31
00:02:34,022 --> 00:02:37,284
because we're doing both AI and networking in the same game

32
00:02:37,284 --> 00:02:41,867
modes instead of just networking for PVP and PVE

33
00:02:41,867 --> 00:02:43,248
being single player.

34
00:02:43,248 --> 00:02:44,589
Our PVE is now shared.

35
00:02:44,589 --> 00:02:49,053
And so we have to basically be able to extract as much CPU as

36
00:02:49,053 --> 00:02:51,675
we can out of the whole system, especially on those

37
00:02:51,675 --> 00:02:55,938
last gen platforms like PS3 with the two PPUs that aren't

38
00:02:55,938 --> 00:02:56,818
very powerful.

39
00:02:59,261 --> 00:03:01,703
But we knew multi-threading was going to be hard.

40
00:03:01,703 --> 00:03:04,946
So we had to figure out a good way to do it.

41
00:03:04,946 --> 00:03:07,268
There's basically three big hard things in it.

42
00:03:07,268 --> 00:03:08,629
Splitting the workloads.

43
00:03:08,629 --> 00:03:13,053
You never really know what the right way is to split things.

44
00:03:13,053 --> 00:03:15,815
Preventing the data dependency misses.

45
00:03:15,815 --> 00:03:18,638
Knowing how your data is going to interact with each other.

46
00:03:18,638 --> 00:03:20,820
And then tracking down those issues

47
00:03:20,820 --> 00:03:23,542
when you've missed all of that and figuring it out.

48
00:03:26,487 --> 00:03:28,288
So as an example for splitting the workload,

49
00:03:28,288 --> 00:03:30,390
I'll take a look at our object move.

50
00:03:30,390 --> 00:03:33,692
Basically, object move calculating the positions

51
00:03:33,692 --> 00:03:38,596
and the skeleton positions by combining physics update,

52
00:03:38,596 --> 00:03:40,597
animation, IK, et cetera.

53
00:03:40,597 --> 00:03:44,620
And so this is usually difficult to parallelize code.

54
00:03:44,620 --> 00:03:46,401
It tends to be very branchy.

55
00:03:47,057 --> 00:03:50,719
You want it to be branchy because you want to be able to improve the responsiveness.

56
00:03:50,719 --> 00:03:53,001
But you have that trade-off. Maybe you don't want to do that.

57
00:03:53,001 --> 00:03:58,304
Maybe you want to make it so it's easier to thread by making everything the same

58
00:03:58,304 --> 00:04:00,365
and getting rid of those branches.

59
00:04:00,365 --> 00:04:04,848
But, you know, at the end of the day, each object is going to want to do something different.

60
00:04:04,848 --> 00:04:08,350
The objects are interacting with the other objects in the system.

61
00:04:08,350 --> 00:04:11,832
How do you deal with that across the threads?

62
00:04:12,535 --> 00:04:15,156
And then, as they're moving through the system,

63
00:04:15,156 --> 00:04:16,676
the things that they're interacting with

64
00:04:16,676 --> 00:04:18,577
are changing all the time.

65
00:04:18,577 --> 00:04:21,317
It's just a difficult problem to actually figure out

66
00:04:21,317 --> 00:04:22,718
the right way to split.

67
00:04:22,718 --> 00:04:26,879
And then you're missing data dependencies.

68
00:04:26,879 --> 00:04:30,679
So let's say you have some workloads that you've got here,

69
00:04:30,679 --> 00:04:33,180
like your AI update, which triggers raycasts and triggers

70
00:04:33,180 --> 00:04:34,000
the physics update.

71
00:04:34,902 --> 00:04:43,606
Physics updates can then trigger the audio update because maybe you've got obstruction or occluders that needs to be aware of what's going on in the physics world.

72
00:04:43,606 --> 00:04:48,527
And so you can see this part here with the physics box that's moving back and forth.

73
00:04:48,527 --> 00:04:51,629
I mean, that job can start late, it can run long.

74
00:04:51,629 --> 00:04:56,831
You don't really know what it's going to actually overlap with, especially if you're just dependency-bound here.

75
00:04:56,831 --> 00:05:04,353
And so there's this missing data dependency on the raycasts reading your physics world versus the physics world actually being updated.

76
00:05:07,910 --> 00:05:11,895
And then the rare bugs. You get a bug from QA. They send you a

77
00:05:11,895 --> 00:05:14,458
video. That's all you got. It's not a crash. You don't have a

78
00:05:14,458 --> 00:05:17,321
core dump. You can't inspect anything. You just get this

79
00:05:17,321 --> 00:05:21,206
video that says, hey, the rocket effect on this player is the

80
00:05:21,206 --> 00:05:24,490
wrong one. It's the same as this other player. What's going on

81
00:05:24,490 --> 00:05:24,610
here?

82
00:05:25,624 --> 00:05:29,187
And that's another bug that's just, how are you ever going to

83
00:05:29,187 --> 00:05:29,467
debug that?

84
00:05:29,467 --> 00:05:32,149
You don't know if it's ever being reproduced in-house.

85
00:05:32,149 --> 00:05:35,112
You don't know how many times it's actually gone on.

86
00:05:35,112 --> 00:05:37,053
And then QA can't really tell you anything.

87
00:05:37,053 --> 00:05:40,416
Maybe they told you, hey, their join in progress happened.

88
00:05:40,416 --> 00:05:45,820
So I'm going to talk a little bit about the multi-threading

89
00:05:45,820 --> 00:05:48,983
that we built for Destiny principles.

90
00:05:48,983 --> 00:05:52,425
First and foremost, we wanted to keep it simple.

91
00:05:52,425 --> 00:05:54,527
We wanted our complexity to be necessary.

92
00:05:55,229 --> 00:05:57,851
And there's definitely complexity that we have,

93
00:05:57,851 --> 00:05:59,433
but anything that we could keep simple

94
00:05:59,433 --> 00:06:00,814
definitely helped us out.

95
00:06:00,814 --> 00:06:02,715
And we wanted to keep everything as cross-platform

96
00:06:02,715 --> 00:06:03,296
as possible.

97
00:06:03,296 --> 00:06:05,178
With the four platforms that we're shipping on,

98
00:06:05,178 --> 00:06:09,321
it's just a nightmare to have to keep separate implementations

99
00:06:09,321 --> 00:06:10,702
and keep maintenance on those.

100
00:06:10,702 --> 00:06:12,304
It just doesn't make sense.

101
00:06:12,304 --> 00:06:15,686
And then the biggest important thing

102
00:06:15,686 --> 00:06:17,908
was having to understand our data access patterns.

103
00:06:17,908 --> 00:06:19,389
If you don't know what your data is doing,

104
00:06:19,389 --> 00:06:22,552
it's just going to be really difficult to multi-thread.

105
00:06:24,987 --> 00:06:28,610
We also didn't want to wait for synchronization.

106
00:06:28,610 --> 00:06:29,771
Synchronization just takes time.

107
00:06:29,771 --> 00:06:32,553
We don't necessarily have the CPU time to actually do that.

108
00:06:32,553 --> 00:06:36,076
Basically, we shied away from using synchronization

109
00:06:36,076 --> 00:06:37,617
primitives wherever we could.

110
00:06:37,617 --> 00:06:40,319
We just wanted to express everything via dependencies.

111
00:06:40,319 --> 00:06:42,701
So work that could start would start.

112
00:06:42,701 --> 00:06:44,362
And if it wasn't ready to start yet,

113
00:06:44,362 --> 00:06:45,783
we would just start some other piece of work.

114
00:06:45,783 --> 00:06:46,624
Like many other engines, it's basically

115
00:06:46,624 --> 00:06:47,044
the flow of the.

116
00:06:54,373 --> 00:06:57,895
of the system is running from simulation to rendering.

117
00:06:57,895 --> 00:06:59,436
You want your game world to be simulated.

118
00:06:59,436 --> 00:07:01,077
You want to put it on screen.

119
00:07:01,077 --> 00:07:03,198
We've pipelined that so our rendering

120
00:07:03,198 --> 00:07:05,200
is overlapping our simulation.

121
00:07:05,200 --> 00:07:08,602
But you'll have the previous frame's rendering finishing off

122
00:07:08,602 --> 00:07:10,163
while your next frame simulation is going, vice versa.

123
00:07:10,163 --> 00:07:15,046
We used a job system.

124
00:07:15,046 --> 00:07:17,667
They're pretty well described by now.

125
00:07:17,667 --> 00:07:19,188
Definitely seen lots of talks on them.

126
00:07:19,188 --> 00:07:22,530
Ron's talk from GDC 2010, definitely a good one.

127
00:07:24,091 --> 00:07:26,994
The job, if you're unfamiliar, it's just a self-contained task.

128
00:07:26,994 --> 00:07:28,995
It's got some parameters, tells you what to do.

129
00:07:28,995 --> 00:07:32,979
For our system, we have them at half a millisecond to two milliseconds.

130
00:07:32,979 --> 00:07:36,222
And that reflects that our jobs do not get preempted

131
00:07:36,222 --> 00:07:40,626
and that we have a significantly high overhead on the jobs.

132
00:07:40,626 --> 00:07:43,949
It's not like making a bunch of SPU jobs where you have that sea of jobs

133
00:07:43,949 --> 00:07:47,653
because you can run two microsecond jobs and not really worry about it.

134
00:07:52,561 --> 00:07:55,824
It's priority-based, first in, first out,

135
00:07:55,824 --> 00:07:57,726
nothing really fancy there.

136
00:07:57,726 --> 00:08:00,549
Our job graph, again, it takes into account

137
00:08:00,549 --> 00:08:02,610
all the different types of cores that we have.

138
00:08:02,610 --> 00:08:06,454
So on PS3, that's going to be both the CPU and the SPU jobs.

139
00:08:06,454 --> 00:08:08,956
And we use dependencies between our jobs.

140
00:08:08,956 --> 00:08:10,017
We don't do fences.

141
00:08:10,017 --> 00:08:13,581
So in this example, we have our AI kickoff and AI finish

142
00:08:13,581 --> 00:08:15,843
bookends that have the dependencies for those actor

143
00:08:15,843 --> 00:08:18,425
update jobs that would be running in parallel there.

144
00:08:22,495 --> 00:08:24,696
What we did find, though, is most systems

145
00:08:24,696 --> 00:08:27,137
tend to do the same work every frame.

146
00:08:27,137 --> 00:08:30,798
You're just going to run that code over and over again.

147
00:08:30,798 --> 00:08:33,619
And it's basically pretty linear,

148
00:08:33,619 --> 00:08:35,499
kind of reflective from olden days

149
00:08:35,499 --> 00:08:38,120
where you're using a single thread to do that work.

150
00:08:38,120 --> 00:08:41,921
And then most of that work is using the same data.

151
00:08:41,921 --> 00:08:43,222
And that data access pattern is going

152
00:08:43,222 --> 00:08:45,202
to be the same across frames.

153
00:08:45,202 --> 00:08:47,283
So we formalized this into a first class citizen.

154
00:08:49,664 --> 00:08:53,306
which we call the fiber system. So we took this industry

155
00:08:53,306 --> 00:08:59,010
standard word fiber and totally corrupted it. I'm sorry. For us

156
00:08:59,010 --> 00:09:02,652
a fiber means a set of jobs that are going to run in sequence.

157
00:09:02,652 --> 00:09:05,955
They will not run in parallel with each other. They can run

158
00:09:05,955 --> 00:09:09,877
with other fibers, but these ones will always run. And we'll

159
00:09:09,877 --> 00:09:13,039
call that sequence of jobs. So in this case network update,

160
00:09:13,039 --> 00:09:16,982
network send, network receive. Those would be three jobs that

161
00:09:16,982 --> 00:09:18,663
form an iteration for our fibers.

162
00:09:19,528 --> 00:09:24,730
And then the other piece that goes with our fiber system is

163
00:09:24,730 --> 00:09:27,650
there's a set of data that's associated with it.

164
00:09:27,650 --> 00:09:30,391
So in this case, the network state that's accessible by all

165
00:09:30,391 --> 00:09:31,431
of the network jobs inside that fiber.

166
00:09:31,431 --> 00:09:35,792
For Destiny, we have three to four fibers, basically.

167
00:09:35,792 --> 00:09:39,453
Our simulation contains all the game logic,

168
00:09:39,453 --> 00:09:41,394
as you would expect.

169
00:09:41,394 --> 00:09:44,514
Similarly, the networking is all of the networking code.

170
00:09:44,514 --> 00:09:47,435
And then we have a couple of fibers for rendering that

171
00:09:47,435 --> 00:09:48,175
covers all of our.

172
00:09:49,293 --> 00:09:52,296
All of the work of extracting that game state from simulation

173
00:09:52,296 --> 00:09:56,640
and pushing it all the way into the GPU, getting it on screen.

174
00:09:56,640 --> 00:10:03,728
Fibers really are acting as a convenience for us here.

175
00:10:03,728 --> 00:10:06,170
It's not like they're really buying us anything apart

176
00:10:06,170 --> 00:10:08,853
from having jobs, because the underlying representation is

177
00:10:08,853 --> 00:10:09,954
just a sequence of jobs.

178
00:10:09,954 --> 00:10:12,997
But what it does allow us to do is communicate with people.

179
00:10:13,681 --> 00:10:17,444
When you look at a big job graph and you want to know and you want to talk to other people about it,

180
00:10:17,444 --> 00:10:20,907
if you're not on the same page, then it's really difficult to talk about,

181
00:10:20,907 --> 00:10:25,011
oh, this specific job over here, we need to work about this.

182
00:10:25,011 --> 00:10:28,774
Getting somebody ramped up to understand that is a lot easier if you basically say,

183
00:10:28,774 --> 00:10:33,318
hey, in the render fiber, when we're kicking off the work to extract things out of the frame,

184
00:10:33,318 --> 00:10:35,680
people can catch that very quickly.

185
00:10:35,680 --> 00:10:37,761
It gives us common ground, basically, to talk about.

186
00:10:38,503 --> 00:10:41,625
It also gives you an expectation of how the data is going to be used,

187
00:10:41,625 --> 00:10:43,526
because you know what data is associated with it.

188
00:10:43,526 --> 00:10:46,808
So there's that general feel of,

189
00:10:46,808 --> 00:10:48,449
this data is owned by this fiber,

190
00:10:48,449 --> 00:10:51,811
versus I'm never going to touch the network data inside the rendering fiber.

191
00:10:51,811 --> 00:10:55,694
And then the other big key thing that it gave us is,

192
00:10:55,694 --> 00:10:58,355
because all of our big systems are fibers,

193
00:10:58,355 --> 00:11:02,178
the cross-system dependencies can be documented in one location in our code.

194
00:11:03,081 --> 00:11:10,307
I don't know if you've ever had to work in a codebase where the dependencies between the systems are spread through the hundreds of CPP files that you've got.

195
00:11:10,307 --> 00:11:14,951
But it's a big pain to try to figure out what's going on, especially after the fact.

196
00:11:14,951 --> 00:11:22,377
So being able to have that in a single function as, you know, 20 to 30 lines is a great way to be able to look and see where that's all going.

197
00:11:25,464 --> 00:11:29,025
Time control is the only real thread that we have in our system.

198
00:11:29,025 --> 00:11:32,146
It's responsible for kicking off all the iterations of the fibers.

199
00:11:32,146 --> 00:11:34,886
It's queued off of Vsync for the different platforms.

200
00:11:34,886 --> 00:11:40,888
We had tried to do this as a job to keep the entire system as a job,

201
00:11:40,888 --> 00:11:44,709
but it basically added a bunch of overhead into our job manager.

202
00:11:44,709 --> 00:11:49,050
It was the only job that was trying to execute with accurate timing.

203
00:11:49,050 --> 00:11:52,050
And so cutting that out just cut out a lot of overhead in our job system.

204
00:11:53,898 --> 00:11:56,520
It's also responsible for serializing all the fibers,

205
00:11:56,520 --> 00:11:58,562
which basically just means draining the current

206
00:11:58,562 --> 00:11:59,222
iterations.

207
00:11:59,222 --> 00:12:00,423
You wait for them all to complete.

208
00:12:00,423 --> 00:12:03,145
You're going to do this if you need to run something in a

209
00:12:03,145 --> 00:12:05,307
single-threaded type context.

210
00:12:05,307 --> 00:12:08,109
So for us, that basically means, hey, we're changing

211
00:12:08,109 --> 00:12:08,830
destinations.

212
00:12:08,830 --> 00:12:09,790
You're going to Mars.

213
00:12:09,790 --> 00:12:11,452
You're going to Venus.

214
00:12:11,452 --> 00:12:14,074
We basically need to do a few things where the rest of the

215
00:12:14,074 --> 00:12:15,435
game can't run at that time.

216
00:12:16,501 --> 00:12:21,024
We'll also use it for system events like suspend, resume,

217
00:12:21,024 --> 00:12:24,087
or some of our debugging events where we're doing patching

218
00:12:24,087 --> 00:12:25,748
and developer mode patching.

219
00:12:25,748 --> 00:12:28,090
We don't really care if it works multi-threaded.

220
00:12:28,090 --> 00:12:29,711
We just want to have it work.

221
00:12:29,711 --> 00:12:35,355
So how do we map this to the hardware?

222
00:12:35,355 --> 00:12:39,198
Well, first off, this is a picture

223
00:12:39,198 --> 00:12:40,179
of one of our job graphs.

224
00:12:40,179 --> 00:12:43,502
This is from Cosmodrome on Xbox One.

225
00:12:44,612 --> 00:12:46,754
It's pretty much an average frame.

226
00:12:46,754 --> 00:12:48,515
It gets a lot more complicated.

227
00:12:48,515 --> 00:12:51,296
I grabbed this frame from Natasha's talk.

228
00:12:51,296 --> 00:12:54,358
And it's basically a lot of rendering and a little bit of

229
00:12:54,358 --> 00:12:55,999
simulation here.

230
00:12:55,999 --> 00:12:59,241
We've got over 100 types of jobs.

231
00:12:59,241 --> 00:13:01,823
Basically, hard to really see what's going on unless you can

232
00:13:01,823 --> 00:13:06,365
zoom in and move around, which again comes back to the fibers

233
00:13:06,365 --> 00:13:08,366
being easier to describe what's going on.

234
00:13:12,147 --> 00:13:16,071
So for us, we wanted to keep all the platforms as similar

235
00:13:16,071 --> 00:13:16,851
as we could.

236
00:13:16,851 --> 00:13:19,173
And that goes in with our hardware utilization as well.

237
00:13:19,173 --> 00:13:21,756
Basically, most of the principles

238
00:13:21,756 --> 00:13:24,178
apply to all of the platforms.

239
00:13:24,178 --> 00:13:26,219
We usually have one job thread per core.

240
00:13:26,219 --> 00:13:29,362
And the simulation fiber, we want

241
00:13:29,362 --> 00:13:31,264
to keep that latency really low.

242
00:13:31,264 --> 00:13:33,746
We're particular about our input latency.

243
00:13:33,746 --> 00:13:36,288
So we need to make sure that we get our simulation work done

244
00:13:36,288 --> 00:13:38,750
as fast as possible with as little interrupts as we

245
00:13:38,750 --> 00:13:39,331
possibly can.

246
00:13:40,109 --> 00:13:43,011
So we're going to try to put this on a high priority job

247
00:13:43,011 --> 00:13:44,552
thread across the platforms.

248
00:13:44,552 --> 00:13:50,157
So we also have async job threads.

249
00:13:50,157 --> 00:13:51,778
A lot of the platforms have tasks

250
00:13:51,778 --> 00:13:53,099
that we don't really have control over.

251
00:13:53,099 --> 00:13:56,742
If they go to sleep, you want to query for your network friends

252
00:13:56,742 --> 00:13:57,042
list.

253
00:13:57,042 --> 00:13:59,484
Hey, that might take 20 seconds.

254
00:13:59,484 --> 00:14:02,806
You're sending an HTTP request to log into a server,

255
00:14:02,806 --> 00:14:04,608
or you're loading data off of disk.

256
00:14:05,354 --> 00:14:08,276
And so these ones run in our async job threads, which

257
00:14:08,276 --> 00:14:11,578
are allowed to run across the serialization events.

258
00:14:11,578 --> 00:14:12,839
They can go to sleep.

259
00:14:12,839 --> 00:14:14,040
They can take blocks.

260
00:14:14,040 --> 00:14:16,141
Basically just calling OS level stuff.

261
00:14:16,141 --> 00:14:19,244
And then, of course, we try to keep that data self-contained

262
00:14:19,244 --> 00:14:22,686
so that if it does need to get serialized,

263
00:14:22,686 --> 00:14:24,507
we don't want to wait for those 20 second jobs.

264
00:14:24,507 --> 00:14:26,228
So I'll start with PS3.

265
00:14:32,050 --> 00:14:36,294
Basically, this is a layout of what we've done for the hardware threads.

266
00:14:36,294 --> 00:14:39,717
There's no affinity on PS3, so it's not like we could say,

267
00:14:39,717 --> 00:14:42,159
hey, this job thread only runs on PPU0.

268
00:14:42,159 --> 00:14:47,564
So we kind of cheated a little bit, and we just cranked up the priority as high as we possibly could.

269
00:14:47,564 --> 00:14:50,747
And that helps minimize a lot of the preemption that we're seeing on it.

270
00:14:50,747 --> 00:14:54,891
And then that job thread is only allowed to run the simulation jobs most of the time.

271
00:14:55,956 --> 00:15:00,297
The other PPU thread is another job thread.

272
00:15:00,297 --> 00:15:02,538
But that job thread has the lowest priority

273
00:15:02,538 --> 00:15:03,919
that we could put in the system.

274
00:15:03,919 --> 00:15:06,380
We basically crammed all the other threads, the middleware

275
00:15:06,380 --> 00:15:08,000
and the async jobs in between there,

276
00:15:08,000 --> 00:15:11,781
so that they can take up time when they need to.

277
00:15:11,781 --> 00:15:14,622
And then across all of the SPUs, we use the six SPUs.

278
00:15:14,622 --> 00:15:16,183
They're just running job threads to consume those jobs.

279
00:15:16,183 --> 00:15:16,963
So here's a capture from Tunr.

280
00:15:16,963 --> 00:15:17,603
This is job thread zero.

281
00:15:28,190 --> 00:15:29,951
You can see here that the preemption,

282
00:15:29,951 --> 00:15:31,633
there's not a lot of preemption events.

283
00:15:31,633 --> 00:15:34,995
There's still some, but it gets a pretty good utilization.

284
00:15:34,995 --> 00:15:40,138
And that allows us to keep that high priority

285
00:15:40,138 --> 00:15:42,900
set of simulation jobs going, which essentially

286
00:15:42,900 --> 00:15:46,562
are these jobs here.

287
00:15:46,562 --> 00:15:51,545
So it's the red jobs that have been marked off here,

288
00:15:51,545 --> 00:15:56,228
all the simulation work that's either simulation fiber work

289
00:15:56,228 --> 00:15:56,388
or.

290
00:15:58,979 --> 00:16:00,300
jobs kicked off from simulation.

291
00:16:00,300 --> 00:16:03,102
And so they're all running during this time frame

292
00:16:03,102 --> 00:16:04,423
up to here.

293
00:16:04,423 --> 00:16:06,224
And then this red line that goes down

294
00:16:06,224 --> 00:16:08,446
marks the end where the simulation is completed

295
00:16:08,446 --> 00:16:09,326
for that frame.

296
00:16:09,326 --> 00:16:12,148
And so we've now opened it up so that other jobs or other work

297
00:16:12,148 --> 00:16:14,370
can run on this hardware thread.

298
00:16:14,370 --> 00:16:17,252
And so you can see a rendering job sneaked in here

299
00:16:17,252 --> 00:16:18,893
on this red job here.

300
00:16:18,893 --> 00:16:20,374
On the other job thread, you can see up top here.

301
00:16:29,669 --> 00:16:31,532
This job thread is preempted a lot.

302
00:16:31,532 --> 00:16:35,257
Totally reflecting what I said earlier, where we put

303
00:16:35,257 --> 00:16:38,462
everything else in between.

304
00:16:38,462 --> 00:16:43,088
The SPUs are fairly well utilized.

305
00:16:43,088 --> 00:16:45,211
We get about 50% to 70% utilization.

306
00:16:45,859 --> 00:16:49,381
which I think is actually pretty good for our first shipped PS3 title.

307
00:16:49,381 --> 00:16:50,822
I know we're a little bit behind,

308
00:16:50,822 --> 00:16:55,965
given that other people are on their, like, 7th or 8th PS3 title.

309
00:16:55,965 --> 00:17:02,950
But this one's our first one, and I think we've done a pretty solid job on moving work to the SPUs.

310
00:17:02,950 --> 00:17:08,513
We've got about 20 different job types that cover most of the code base.

311
00:17:08,513 --> 00:17:12,516
I mean, we've got audio, AI, animation, physics, networking, all running on the...

312
00:17:13,012 --> 00:17:19,320
the SPUs, and of course we have graphics going there too, SPA lighting, other aspects of

313
00:17:19,320 --> 00:17:23,525
the graphics. I think the entire graphics pipeline is running on the SPU for the most

314
00:17:23,525 --> 00:17:24,065
part.

315
00:17:24,065 --> 00:17:31,014
Moving on to 360. So you've got your three cores.

316
00:17:31,895 --> 00:17:33,816
with the two hardware threads each.

317
00:17:33,816 --> 00:17:38,899
The interesting one is the first core, so this one's not being preempted by XAMM.

318
00:17:38,899 --> 00:17:43,683
You don't have that one millisecond time that's getting in, so we're putting all of our simulation jobs there.

319
00:17:43,683 --> 00:17:50,547
And then we've gone one step further and hardware thread one is idle for most of the time and that allows the

320
00:17:50,547 --> 00:17:56,091
contended hardware elements not to be used by hardware thread one enabling a little bit of a speed up on some of the code

321
00:17:56,091 --> 00:17:57,132
for hardware thread zero.

322
00:17:57,132 --> 00:18:00,634
It allows our simulation to finish just a little bit earlier.

323
00:18:02,009 --> 00:18:04,850
Hardware threads 2 and 3 are just regular job threads.

324
00:18:04,850 --> 00:18:08,071
All our middleware is crammed onto hardware thread 4

325
00:18:08,071 --> 00:18:09,772
with the Xam update.

326
00:18:09,772 --> 00:18:11,652
And then hardware thread 5 is also a job thread

327
00:18:11,652 --> 00:18:12,793
and some asynchronous jobs.

328
00:18:12,793 --> 00:18:16,994
These threads don't move around because 360

329
00:18:16,994 --> 00:18:19,695
has affinity that we can lock the threads to the hardware

330
00:18:19,695 --> 00:18:20,596
threads.

331
00:18:20,596 --> 00:18:25,217
So this is a capture from Rad Game Tools Telemetry,

332
00:18:25,217 --> 00:18:27,058
one of their older versions.

333
00:18:27,058 --> 00:18:28,538
This is a frame from the 360.

334
00:18:29,762 --> 00:18:32,023
It's a little bit harder to see what's going on here,

335
00:18:32,023 --> 00:18:35,004
because we're not zooming in and whatnot.

336
00:18:35,004 --> 00:18:37,704
But this red circled section here,

337
00:18:37,704 --> 00:18:39,525
this is all the simulation work.

338
00:18:39,525 --> 00:18:44,446
Everything past that is moving on to different jobs

339
00:18:44,446 --> 00:18:46,406
where we finish the sim frame for 360.

340
00:18:46,406 --> 00:18:50,647
You can see in these circled spots here,

341
00:18:50,647 --> 00:18:53,968
this is the spots where we've left the second CPU idle

342
00:18:53,968 --> 00:18:56,209
so that we can actually get the better performance

343
00:18:56,209 --> 00:18:56,989
on the first CPU.

344
00:18:57,953 --> 00:19:03,463
And then this red line over here, again marking where simulation is complete for that frame

345
00:19:03,463 --> 00:19:07,671
and we've opened it up for the rest of the jobs to be able to execute on that thread.

346
00:19:13,323 --> 00:19:16,225
So on PS4 and Xbox One, there's the two clusters.

347
00:19:16,225 --> 00:19:20,468
Basically use cluster one, so core zero through three,

348
00:19:20,468 --> 00:19:22,329
to run all of our jobs.

349
00:19:22,329 --> 00:19:24,851
Again, core zero, it's our simulation jobs.

350
00:19:24,851 --> 00:19:26,592
That's the only jobs it's going to be running.

351
00:19:26,592 --> 00:19:29,194
Want to keep those as high priority as possible,

352
00:19:29,194 --> 00:19:31,416
just like on all the other platforms.

353
00:19:31,416 --> 00:19:33,017
We're able to set the affinity, so we

354
00:19:33,017 --> 00:19:35,999
don't have to worry about the threads moving around.

355
00:19:35,999 --> 00:19:38,081
And on the second cluster, we basically

356
00:19:38,081 --> 00:19:40,703
run all of our middleware and any of our async jobs.

357
00:19:44,549 --> 00:19:54,972
Here's again a telemetry capture. This is from Xbox One. The PS4 is fairly similar, although it's a little bit more idle than the Xbox One is.

358
00:19:54,972 --> 00:20:06,275
You can see again at the top here, these jobs are a simulation workload. On next gen we are able to complete the frame relatively quickly.

359
00:20:07,853 --> 00:20:09,815
We've got a rendering that starts in after that.

360
00:20:09,815 --> 00:20:12,697
And we actually finish the rendering almost within 33

361
00:20:12,697 --> 00:20:13,758
milliseconds.

362
00:20:13,758 --> 00:20:16,380
We almost don't need to pipeline for next gen.

363
00:20:16,380 --> 00:20:17,681
So we're going to move on a little bit,

364
00:20:17,681 --> 00:20:23,585
and see how we prove that our code base is thread safe.

365
00:20:23,585 --> 00:20:27,488
Because all that job graph is fairly complicated.

366
00:20:27,488 --> 00:20:31,110
We basically want to be able to say, hey,

367
00:20:31,110 --> 00:20:34,393
this is totally safe, right?

368
00:20:36,705 --> 00:20:39,808
So the big requirements here to be able to say that is we need

369
00:20:39,808 --> 00:20:42,690
to be able to get actionable bugs when we're getting it.

370
00:20:42,690 --> 00:20:44,832
We can't have those bugs like I talked about earlier, where

371
00:20:44,832 --> 00:20:46,393
it's like, here's a video that says that the

372
00:20:46,393 --> 00:20:47,934
rocket looks the same.

373
00:20:47,934 --> 00:20:49,956
We need to be able to know when that's actually

374
00:20:49,956 --> 00:20:52,978
happening, how often it's happening, and then why it's

375
00:20:52,978 --> 00:20:53,799
actually happening.

376
00:20:53,799 --> 00:20:56,461
And then we need the tools to actually be able to debug it.

377
00:21:00,725 --> 00:21:03,306
Really, we need to enforce our data patterns.

378
00:21:03,306 --> 00:21:06,248
So I bring up this picture that we had at the beginning.

379
00:21:06,248 --> 00:21:09,609
And you see the physics going where it's conflicting with

380
00:21:09,609 --> 00:21:11,070
the raycasts again.

381
00:21:11,070 --> 00:21:13,991
We want to be able to robustly detect this bug.

382
00:21:13,991 --> 00:21:16,513
How do we do that?

383
00:21:16,513 --> 00:21:19,074
We need to do that because we have 50 client engineers all

384
00:21:19,074 --> 00:21:23,956
banging on the code.

385
00:21:23,956 --> 00:21:26,758
So we came up with our execution environment.

386
00:21:26,758 --> 00:21:28,419
This is our solution to this.

387
00:21:29,157 --> 00:21:31,581
the thing that let us ship across all of our platforms.

388
00:21:31,581 --> 00:21:34,926
And it's really a system to validate resources

389
00:21:34,926 --> 00:21:37,209
and to make sure that the patterns used with those

390
00:21:37,209 --> 00:21:40,334
resources are actually going to be thread safe.

391
00:21:40,334 --> 00:21:42,618
Our goal is really to satisfy those multi-threaded

392
00:21:42,618 --> 00:21:43,739
requirements that I just said.

393
00:21:47,600 --> 00:21:50,282
So it's going to be identifying unsafe patterns,

394
00:21:50,282 --> 00:21:52,163
but it's going to be doing it during development.

395
00:21:52,163 --> 00:21:54,405
You're not going to be waiting to find out later

396
00:21:54,405 --> 00:21:55,466
after you've checked in.

397
00:21:55,466 --> 00:21:57,327
It's not going to be three months later.

398
00:21:57,327 --> 00:21:59,048
It's going to be before you've actually submitted

399
00:21:59,048 --> 00:22:01,069
and unleashed it upon the rest of the people who

400
00:22:01,069 --> 00:22:02,650
are developing in that code.

401
00:22:02,650 --> 00:22:06,973
It's also going to find the potential issues

402
00:22:06,973 --> 00:22:09,195
without you actually having to hit them.

403
00:22:09,195 --> 00:22:11,496
So we want to make sure that if it's

404
00:22:11,496 --> 00:22:13,237
possible to have this race condition,

405
00:22:13,237 --> 00:22:15,919
we found it, not only when the race condition occurs.

406
00:22:17,595 --> 00:22:19,496
And it's going to detect any of the patterns that

407
00:22:19,496 --> 00:22:21,498
lead to the weirdness that you're going to see that's

408
00:22:21,498 --> 00:22:24,080
hard to debug, like those things where, hey,

409
00:22:24,080 --> 00:22:26,322
if this job runs in a different order from this job,

410
00:22:26,322 --> 00:22:28,984
you get a different result. But you can't tell,

411
00:22:28,984 --> 00:22:31,386
and you can't really debug that, because how do you control which

412
00:22:31,386 --> 00:22:34,629
jobs run in the different order without having put dependencies

413
00:22:34,629 --> 00:22:35,149
between them?

414
00:22:35,149 --> 00:22:37,491
And then if you did put dependencies between them,

415
00:22:37,491 --> 00:22:38,732
then you've already fixed the problem.

416
00:22:38,732 --> 00:22:43,056
It'll also catch any of the data race conditions or any

417
00:22:43,056 --> 00:22:43,536
of the other.

418
00:22:44,162 --> 00:22:46,664
crazy bugs that you're trying to find that are all based off

419
00:22:46,664 --> 00:22:49,026
of code running at the same time, banging on the same

420
00:22:49,026 --> 00:22:53,149
data. But I do want to stress that this is verification

421
00:22:53,149 --> 00:22:56,672
only. We don't ship with this. It's totally compiled

422
00:22:56,672 --> 00:23:00,155
out inside of our release builds. We're not doing

423
00:23:00,155 --> 00:23:02,737
any synchronization as a result of what we find.

424
00:23:02,737 --> 00:23:06,179
It's strictly, we're going to assert when we've detected

425
00:23:06,179 --> 00:23:09,542
that you're able to do some sort of access that's

426
00:23:09,542 --> 00:23:09,882
not good.

427
00:23:12,888 --> 00:23:16,950
We'll talk a little bit of terminology. We have a resource.

428
00:23:16,950 --> 00:23:20,232
It's just really a theoretical concept. It's nothing specific.

429
00:23:20,232 --> 00:23:24,275
It's not a data structure. But it's anything that you would

430
00:23:24,275 --> 00:23:27,717
want to have protected. So, you know, anything from our Havoc

431
00:23:27,717 --> 00:23:34,781
world to actor data, maybe your input controller. Anything that

432
00:23:34,781 --> 00:23:37,263
would be used in a multi-threaded fashion.

433
00:23:39,486 --> 00:23:42,408
We have policies, and these policies describe what you can

434
00:23:42,408 --> 00:23:44,050
do with a resource.

435
00:23:44,050 --> 00:23:47,812
We want to be able to say, hey, this job is allowed to

436
00:23:47,812 --> 00:23:49,033
pull the controller.

437
00:23:49,033 --> 00:23:52,356
This job is allowed to read physics.

438
00:23:52,356 --> 00:23:55,459
Those policies are associated with a job, and it's really

439
00:23:55,459 --> 00:23:57,440
just explicit markup that you have to add into the code.

440
00:23:57,440 --> 00:23:58,261
And then we have to provide resource access

441
00:23:58,261 --> 00:23:58,741
checks for everything.

442
00:24:06,040 --> 00:24:08,041
Any resource that you want to have protected

443
00:24:08,041 --> 00:24:10,062
needs to be able to look up into that policy

444
00:24:10,062 --> 00:24:12,884
to see if it has permission to do that work.

445
00:24:12,884 --> 00:24:15,546
And so you need to be able to put in all of the hooks.

446
00:24:15,546 --> 00:24:19,168
And then, of course, you have to actually have a lot of code

447
00:24:19,168 --> 00:24:20,970
coverage to be able to go through all

448
00:24:20,970 --> 00:24:23,131
of those if statements and all the different pathways

449
00:24:23,131 --> 00:24:25,613
through your code to make sure that your policies are actually

450
00:24:25,613 --> 00:24:27,854
properly protecting that data.

451
00:24:29,290 --> 00:24:31,391
And then for our access checks, we're going to assert,

452
00:24:31,391 --> 00:24:33,653
as I mentioned before, when you don't have access.

453
00:24:33,653 --> 00:24:36,414
And that's going to be a clear assert that basically says,

454
00:24:36,414 --> 00:24:38,855
hey, no, you can't read game time from here.

455
00:24:38,855 --> 00:24:40,576
You're the renderer thread.

456
00:24:40,576 --> 00:24:42,137
You have to get it some other way.

457
00:24:42,137 --> 00:24:43,037
The policies can overlap.

458
00:24:43,037 --> 00:24:47,600
This is when you have resource usage that conflicts.

459
00:24:47,600 --> 00:24:55,323
So maybe you're like the example before, ray casting,

460
00:24:55,323 --> 00:24:58,025
but you're also updating the Havoc world at the same time.

461
00:24:58,025 --> 00:24:58,785
That's not a good thing.

462
00:24:59,555 --> 00:25:03,138
These also trigger an assert and it's going to be a clear

463
00:25:03,138 --> 00:25:07,181
assert that says, hey, your Raycast job is trying to read

464
00:25:07,181 --> 00:25:09,863
the physics world, but you're also writing to the physics

465
00:25:09,863 --> 00:25:11,705
world from your Havoc update job.

466
00:25:11,705 --> 00:25:19,611
These are really to detect potential race conditions.

467
00:25:20,159 --> 00:25:22,340
you didn't necessarily hit the race condition.

468
00:25:22,340 --> 00:25:24,462
Maybe it was totally safe to read the Havok world

469
00:25:24,462 --> 00:25:27,664
and do those raycasts when you were updating it

470
00:25:27,664 --> 00:25:31,046
because the parts in the physics world that you were updating

471
00:25:31,046 --> 00:25:34,448
weren't the parts that the raycast was actually looking at.

472
00:25:34,448 --> 00:25:36,650
But it could happen in the future.

473
00:25:36,650 --> 00:25:40,972
And then we're going to check this against all

474
00:25:40,972 --> 00:25:42,273
of the jobs in the job graph.

475
00:25:43,025 --> 00:25:46,027
We basically integrated the execution environment

476
00:25:46,027 --> 00:25:48,569
to be able to know the dependencies between those jobs

477
00:25:48,569 --> 00:25:50,270
so that we can actually tell which jobs are

478
00:25:50,270 --> 00:25:52,011
capable of running at the same time.

479
00:25:52,011 --> 00:25:58,275
And this basically makes us provably safe.

480
00:25:58,275 --> 00:26:01,858
So as long as you have instrumented all of your data

481
00:26:01,858 --> 00:26:06,901
access, exercised all the pathways through your code,

482
00:26:06,901 --> 00:26:10,744
and you're only using jobs, then it's perfectly proven.

483
00:26:11,833 --> 00:26:16,674
I realize that that's a hard, tall order to ask for.

484
00:26:16,674 --> 00:26:17,915
But it's not as bad as you think.

485
00:26:17,915 --> 00:26:21,715
So I'm going to talk a little bit about how we actually

486
00:26:21,715 --> 00:26:25,036
implemented that, got it into our engine.

487
00:26:25,036 --> 00:26:29,037
To start off, writing code.

488
00:26:29,037 --> 00:26:31,917
This is how we basically write all of our code.

489
00:26:31,917 --> 00:26:34,898
And you're going to start off doing your planning.

490
00:26:34,898 --> 00:26:37,118
You're going to plan what data access you're going to have.

491
00:26:37,118 --> 00:26:39,579
You're going to add access checks for all the resources

492
00:26:39,579 --> 00:26:40,599
that you're going to need.

493
00:26:41,227 --> 00:26:43,127
And then you can add policies to all the new code

494
00:26:43,127 --> 00:26:45,108
that you're writing that basically expresses

495
00:26:45,108 --> 00:26:46,888
what you're going to do and how you're

496
00:26:46,888 --> 00:26:47,769
going to access that data.

497
00:26:47,769 --> 00:26:51,029
You're going to run through all the code pathways.

498
00:26:51,029 --> 00:26:53,350
And then you're going to resolve any of the overlaps

499
00:26:53,350 --> 00:26:53,810
that it's found.

500
00:26:53,810 --> 00:26:58,052
So I'm going to talk about these pieces in a little more detail.

501
00:26:58,052 --> 00:27:02,653
The first part, catching every resource.

502
00:27:02,653 --> 00:27:05,814
You know, you can't really just say, hey, everybody

503
00:27:05,814 --> 00:27:08,255
mark up every single pointer dereference

504
00:27:08,255 --> 00:27:09,255
that you're going to do.

505
00:27:09,255 --> 00:27:10,295
So it's kind of crazy talk.

506
00:27:11,088 --> 00:27:14,589
Nobody's going to do it unless you're forced to actually do it.

507
00:27:14,589 --> 00:27:17,171
And if you don't have compiler support to force those people,

508
00:27:17,171 --> 00:27:21,052
you pretty much have to put a wrapper around every piece of data inside your engine.

509
00:27:21,052 --> 00:27:25,014
But thankfully for us, from previous titles,

510
00:27:25,014 --> 00:27:28,155
we actually use handles for all of our data access.

511
00:27:28,155 --> 00:27:33,038
So we had a single point that we were able to put those access checks in

512
00:27:33,038 --> 00:27:36,079
and be able to verify that we had the safe spot.

513
00:27:37,235 --> 00:27:42,989
Handles have been great for us. It's used for every piece of data in our engine.

514
00:27:42,989 --> 00:27:46,798
We just found cache pointers are very often causing bugs.

515
00:27:47,625 --> 00:27:50,947
You can't tell that this thing has been deleted frames ago.

516
00:27:50,947 --> 00:27:53,329
But with handles, we're able to actually see that.

517
00:27:53,329 --> 00:27:55,650
We have salt in the handle that basically says,

518
00:27:55,650 --> 00:27:57,331
this has been deleted.

519
00:27:57,331 --> 00:27:59,833
It's not the same one as when you took the handle

520
00:27:59,833 --> 00:28:00,873
from before it.

521
00:28:00,873 --> 00:28:04,395
So we can have a nice, easy assert that says, hey,

522
00:28:04,395 --> 00:28:06,797
this simulation object that you dereferenced

523
00:28:06,797 --> 00:28:10,039
is no longer up to date.

524
00:28:10,039 --> 00:28:16,362
So the data types that we have, global data.

525
00:28:17,077 --> 00:28:19,919
This is your standard structure that you would normally use.

526
00:28:19,919 --> 00:28:21,340
We've wrapped it with a handle.

527
00:28:21,340 --> 00:28:24,642
The only piece that's actually really global in this case

528
00:28:24,642 --> 00:28:27,925
is the pointer into the data structure

529
00:28:27,925 --> 00:28:29,966
that we've backed in the fiber memory area.

530
00:28:29,966 --> 00:28:31,608
And so that's that area that I said,

531
00:28:31,608 --> 00:28:32,909
the network state at the beginning,

532
00:28:32,909 --> 00:28:35,591
where we had that associated with the fibers.

533
00:28:35,591 --> 00:28:37,192
And that helps group the memory that's

534
00:28:37,192 --> 00:28:39,293
used a little bit more cache coherent as well.

535
00:28:39,293 --> 00:28:42,176
And this accounts for about 10% of all

536
00:28:42,176 --> 00:28:43,497
of the data in our game state.

537
00:28:45,855 --> 00:28:47,896
We also have arrays.

538
00:28:47,896 --> 00:28:49,597
These are typical C-style array.

539
00:28:49,597 --> 00:28:51,598
We call them datum arrays.

540
00:28:51,598 --> 00:28:54,240
The only difference between this is it's got

541
00:28:54,240 --> 00:28:56,001
an element of sparsity to it.

542
00:28:56,001 --> 00:28:59,444
You can have different elements that are not allocated.

543
00:28:59,444 --> 00:29:02,846
So in this example, datums three and four, the gray ones,

544
00:29:02,846 --> 00:29:03,746
are not allocated.

545
00:29:03,746 --> 00:29:04,987
But datum five is.

546
00:29:04,987 --> 00:29:06,568
So there are holes in there.

547
00:29:06,568 --> 00:29:09,870
These are also accessed with handles.

548
00:29:09,870 --> 00:29:13,233
And this accounts for the bulk of our game state, about 80%.

549
00:29:18,666 --> 00:29:23,027
Datum array with heap is our solution for variable size data.

550
00:29:23,027 --> 00:29:26,328
The big usage case of this is all of our content memory.

551
00:29:26,328 --> 00:29:28,749
All of the resources that you're going to see, of course,

552
00:29:28,749 --> 00:29:30,830
are different sizes throughout the game.

553
00:29:30,830 --> 00:29:34,171
And it's really just a datum array

554
00:29:34,171 --> 00:29:35,551
that indirects into a heap.

555
00:29:35,551 --> 00:29:39,632
So with those data resources, these

556
00:29:39,632 --> 00:29:43,513
are the access checks that we've actually chosen to provide.

557
00:29:44,152 --> 00:29:46,892
There's your basic protection, which is just read and write,

558
00:29:46,892 --> 00:29:49,853
which is exactly what you would expect.

559
00:29:49,853 --> 00:29:52,153
We provide array protection for the datum arrays

560
00:29:52,153 --> 00:29:53,374
and the datum array with heap.

561
00:29:53,374 --> 00:29:55,834
It's array modify, array iterate,

562
00:29:55,834 --> 00:29:56,994
which I'll talk about shortly.

563
00:29:56,994 --> 00:29:59,255
And then there's some advanced protection,

564
00:29:59,255 --> 00:30:01,375
producer, consumer, and white listing

565
00:30:01,375 --> 00:30:02,936
that I'll talk about after that.

566
00:30:02,936 --> 00:30:06,436
So array modify is really protecting

567
00:30:06,436 --> 00:30:07,337
the life cycle of data.

568
00:30:07,337 --> 00:30:11,197
It's about whether or not that allocated status

569
00:30:11,197 --> 00:30:12,558
can be changed or written to.

570
00:30:13,328 --> 00:30:18,333
And so in this example, it's hey, datum zero going from unallocated to allocated.

571
00:30:18,333 --> 00:30:23,178
And it covers the destruction side as well, going the other way.

572
00:30:25,850 --> 00:30:29,393
Array iterate is the read side of this allocated status.

573
00:30:29,393 --> 00:30:31,374
It's anything that you can do to discover data.

574
00:30:31,374 --> 00:30:34,937
So it's meant for the typical loop that you're going to have,

575
00:30:34,937 --> 00:30:36,438
where you're walking over all of your data,

576
00:30:36,438 --> 00:30:38,700
doing something for every single element.

577
00:30:38,700 --> 00:30:41,042
But it also covers being able to count or query

578
00:30:41,042 --> 00:30:45,846
whether or not a piece of data inside that datum array

579
00:30:45,846 --> 00:30:47,687
is available for usage.

580
00:30:50,875 --> 00:31:00,619
The producer-consumer is our solution to allow things to create and remove elements while other jobs are capable of reading or writing from that data.

581
00:31:00,619 --> 00:31:06,081
And so this is the case where you typically, you're loading all of your assets into the game.

582
00:31:06,081 --> 00:31:10,662
You need to still be able to read every other asset when you're loading new ones or creating new ones.

583
00:31:10,662 --> 00:31:18,885
In this example, the object update is running, the actor update, rendering objects, they're all going to read into the content.

584
00:31:19,704 --> 00:31:21,825
And so they still need to be able to read that content

585
00:31:21,825 --> 00:31:24,467
when your assets are loading.

586
00:31:24,467 --> 00:31:26,288
Or another example, you've got AI.

587
00:31:26,288 --> 00:31:28,869
Maybe you have a job that's spawning new AI,

588
00:31:28,869 --> 00:31:31,751
while you've got other jobs in parallel that are updating

589
00:31:31,751 --> 00:31:32,452
the existing AI.

590
00:31:32,452 --> 00:31:33,692
You're going to want to be able to do that

591
00:31:33,692 --> 00:31:35,153
without having to serialize those operations.

592
00:31:35,153 --> 00:31:36,394
And the producer-consumer allows us

593
00:31:36,394 --> 00:31:39,015
to represent that in the execution environment.

594
00:31:39,015 --> 00:31:41,217
White listing is our solution for data parallel jobs.

595
00:31:49,427 --> 00:31:51,669
It's about breaking up one datum array

596
00:31:51,669 --> 00:31:55,231
and allowing different access for each element within it.

597
00:31:55,231 --> 00:31:57,712
So you can see here, we have three actor update jobs

598
00:31:57,712 --> 00:32:02,235
that are taking two actors from the datum array above it.

599
00:32:02,235 --> 00:32:04,436
It doesn't need to have the exact same thing.

600
00:32:04,436 --> 00:32:07,058
It's not saying, hey, these ones all have write access.

601
00:32:07,058 --> 00:32:10,079
It could be that the actor two and actor three are only

602
00:32:10,079 --> 00:32:13,061
read access in this case, whereas the actor zero, actor

603
00:32:13,061 --> 00:32:14,702
one is write access.

604
00:32:17,811 --> 00:32:19,693
So you take all of these permissions.

605
00:32:19,693 --> 00:32:22,395
Here's an example of what a policy looks like in our

606
00:32:22,395 --> 00:32:23,236
engine.

607
00:32:23,236 --> 00:32:28,700
I apologize for showing code, but it gets the point across.

608
00:32:28,700 --> 00:32:30,762
Basically, we have a policy builder.

609
00:32:30,762 --> 00:32:35,886
You add access to it with writes or reads for the

610
00:32:35,886 --> 00:32:38,448
different pieces of data, and then you associate it at the

611
00:32:38,448 --> 00:32:40,090
end with one of your jobs.

612
00:32:40,090 --> 00:32:44,013
So you've taken all of that, and we get to the point where

613
00:32:44,013 --> 00:32:45,754
we have to exercise all of our code.

614
00:32:46,418 --> 00:32:48,659
This is a picture of our stress lab.

615
00:32:48,659 --> 00:32:51,521
We're one of the parts inside of our stress lab.

616
00:32:51,521 --> 00:32:55,862
We do a lot of automation in our building.

617
00:32:55,862 --> 00:32:59,864
We have 150 machines that are dedicated just to doing stress

618
00:32:59,864 --> 00:33:02,565
for PC side of things.

619
00:33:02,565 --> 00:33:06,046
We've got 200 machines that are dedicated to doing builds

620
00:33:06,046 --> 00:33:06,987
across the studio.

621
00:33:06,987 --> 00:33:09,908
And then another 200 machines that are doing

622
00:33:09,908 --> 00:33:10,808
content builds for us.

623
00:33:12,929 --> 00:33:17,010
In addition to that, we've got 600 different consoles inside

624
00:33:17,010 --> 00:33:19,791
there that's running test cases on it as well.

625
00:33:19,791 --> 00:33:21,531
And so every time you check in code,

626
00:33:21,531 --> 00:33:25,152
we actually run a stress run for your builds.

627
00:33:25,152 --> 00:33:26,972
And then we have overnight stress runs,

628
00:33:26,972 --> 00:33:31,673
or sometimes longer, that run a more exhaustive test suite

629
00:33:31,673 --> 00:33:31,773
on it.

630
00:33:31,773 --> 00:33:34,734
And this is to cover all of those cases.

631
00:33:35,166 --> 00:33:37,707
And those stress things aren't just, hey, run this same test

632
00:33:37,707 --> 00:33:38,827
over and over again.

633
00:33:38,827 --> 00:33:41,788
Some of them are monkey scripts, where we basically

634
00:33:41,788 --> 00:33:44,869
just provide random input to controllers that you are

635
00:33:44,869 --> 00:33:46,690
capable of exercising code paths that you

636
00:33:46,690 --> 00:33:47,710
wouldn't normally use.

637
00:33:47,710 --> 00:33:53,472
In our last month, I think we've done about 12,000 hours

638
00:33:53,472 --> 00:33:59,074
of stress run, and then 2,000 runs of just check-ins, where

639
00:33:59,074 --> 00:34:01,035
we've done stress against those.

640
00:34:03,415 --> 00:34:07,196
So you found the overlaps. You need to resolve them in some way.

641
00:34:07,196 --> 00:34:10,417
There's really only four ways to resolve these issues.

642
00:34:10,417 --> 00:34:13,198
And they're the standard ones that you're used to.

643
00:34:13,198 --> 00:34:15,678
You can add a dependency between the jobs.

644
00:34:15,678 --> 00:34:17,539
If the two jobs are dependent on each other,

645
00:34:17,539 --> 00:34:20,280
then they're not going to run at the same time.

646
00:34:20,280 --> 00:34:22,480
The data's not going to be overlapping.

647
00:34:22,480 --> 00:34:25,721
You can double buffer or cache your data.

648
00:34:25,721 --> 00:34:26,782
So maybe you want to read.

649
00:34:27,348 --> 00:34:33,974
At the same time, maybe you duplicate that data in a pre-job and pass it into the jobs that read it while you've got the other jobs updating it.

650
00:34:33,974 --> 00:34:40,220
You can do the opposite. You can queue write messages so you know you want to update the actors.

651
00:34:40,220 --> 00:34:45,945
So you build up a big list of operations to proceed and you do that at a point where the actors aren't being used elsewise.

652
00:34:45,945 --> 00:34:50,450
You're basically making it a single threaded part in the future of that framework.

653
00:34:51,677 --> 00:34:57,258
or the worst case scenario, you have to restructure your algorithm. You just fundamentally can't

654
00:34:57,258 --> 00:35:01,059
do it. And that's the hard part. And those are the parts that you want to find early

655
00:35:01,059 --> 00:35:06,761
on where it's just not going to work. I'm going to talk a little bit about the overlap

656
00:35:06,761 --> 00:35:13,822
algorithm. It's a fairly simple algorithm, but it's not really obvious until you've really

657
00:35:13,822 --> 00:35:15,763
thought about it. And so in our case...

658
00:35:16,545 --> 00:35:19,206
We're going to take this example frame where

659
00:35:19,206 --> 00:35:22,327
we've got our AI kickoff and finish with our actor update

660
00:35:22,327 --> 00:35:23,867
jobs in between.

661
00:35:23,867 --> 00:35:26,388
We've got another job that's not part of this dependency chain,

662
00:35:26,388 --> 00:35:27,169
the network send.

663
00:35:27,169 --> 00:35:29,610
And then after the AI is finished updating,

664
00:35:29,610 --> 00:35:31,530
we're going to update the rest of the objects in the frame.

665
00:35:31,530 --> 00:35:35,352
So the question here is, which jobs

666
00:35:35,352 --> 00:35:38,453
can overlap with this actor update job here at the top?

667
00:35:45,623 --> 00:35:48,785
And so step one, we're going to traverse down the dependency

668
00:35:48,785 --> 00:35:49,506
tree.

669
00:35:49,506 --> 00:35:51,887
We're going to mark all of the children of this job.

670
00:35:51,887 --> 00:35:54,969
So all the jobs that can't run until this job is completed,

671
00:35:54,969 --> 00:35:56,410
those ones clearly can't overlap.

672
00:35:56,410 --> 00:36:01,973
So in this case, AI finish is dependent on the actor update

673
00:36:01,973 --> 00:36:02,253
job.

674
00:36:02,253 --> 00:36:05,155
And then afterwards, the object update

675
00:36:05,155 --> 00:36:07,056
is dependent on the AI finish.

676
00:36:07,056 --> 00:36:11,719
Step two, we're going to go the opposite way

677
00:36:11,719 --> 00:36:13,180
in the dependency graph.

678
00:36:14,285 --> 00:36:15,906
can make sure that all of our parents,

679
00:36:15,906 --> 00:36:18,508
so the jobs that need to complete before we can run,

680
00:36:18,508 --> 00:36:21,690
have been marked off as non-overlapping as well.

681
00:36:21,690 --> 00:36:27,154
That case, this is just the AI kickoff.

682
00:36:27,154 --> 00:36:32,938
For the third step, we're going to union all of the jobs

683
00:36:32,938 --> 00:36:34,859
that we haven't marked, and we're

684
00:36:34,859 --> 00:36:37,841
going to take the policy from each of those jobs

685
00:36:37,841 --> 00:36:40,723
and build one big, giant, global policy that

686
00:36:40,723 --> 00:36:43,725
encompasses all of the access that those jobs can have.

687
00:36:45,122 --> 00:36:48,203
In that case, this is the two actor update jobs and the

688
00:36:48,203 --> 00:36:51,024
network send job that we've got here.

689
00:36:51,024 --> 00:36:57,628
For step four, we check that policy to see if that policy

690
00:36:57,628 --> 00:36:59,929
has any conflicts with our current actor update.

691
00:36:59,929 --> 00:37:03,750
And so for this example, we're going to say, hey, maybe the

692
00:37:03,750 --> 00:37:06,772
actor update job just gave full write access to all of

693
00:37:06,772 --> 00:37:08,253
the actors instead of doing a white list.

694
00:37:08,253 --> 00:37:11,374
So in that case, there will be a conflict.

695
00:37:13,333 --> 00:37:14,754
And we take the conflict, and we're

696
00:37:14,754 --> 00:37:17,595
going to walk all of the jobs that we just finished unioning,

697
00:37:17,595 --> 00:37:20,756
the policies for that, to check those individually so that we

698
00:37:20,756 --> 00:37:23,717
can get finer detail information about what's actually

699
00:37:23,717 --> 00:37:27,418
overlapping.

700
00:37:27,418 --> 00:37:28,559
So we walk it.

701
00:37:28,559 --> 00:37:31,580
We see that the actor update, as I mentioned before,

702
00:37:31,580 --> 00:37:33,761
it's conflicting with the first actor update.

703
00:37:33,761 --> 00:37:36,962
So we take note of that.

704
00:37:36,962 --> 00:37:39,603
Likewise, with the other actor update, it's also conflicting.

705
00:37:40,890 --> 00:37:42,511
But the network send job isn't.

706
00:37:42,511 --> 00:37:45,153
It's not using any data that the actor update job is.

707
00:37:45,153 --> 00:37:47,535
So we can mark that as not conflicting.

708
00:37:47,535 --> 00:37:52,178
And so for the final step here, we basically just report

709
00:37:52,178 --> 00:37:53,138
the errors and assert out.

710
00:37:53,138 --> 00:37:55,860
So you're going to get those nice, clear errors that I was

711
00:37:55,860 --> 00:37:58,622
mentioning before that says, hey, the actor update is busy

712
00:37:58,622 --> 00:38:01,884
writing to the actors, while the other actor update is also

713
00:38:01,884 --> 00:38:03,365
busy writing to the actors.

714
00:38:03,365 --> 00:38:05,526
So you know what to go and look for from the get-go.

715
00:38:05,526 --> 00:38:08,448
And you didn't spend time trying to figure out later

716
00:38:08,448 --> 00:38:09,589
what's going on.

717
00:38:10,121 --> 00:38:13,182
why your actors were being clobbered by other jobs.

718
00:38:13,182 --> 00:38:20,406
I'm going to talk about the lessons that we learned from actually implementing this.

719
00:38:20,406 --> 00:38:29,350
Retrofitting the system into an existing codebase takes a long time.

720
00:38:29,350 --> 00:38:32,951
We should not account for how much time it's going to take to mark up our codebase.

721
00:38:35,157 --> 00:38:38,959
It was actually longer to write markup for jobs that already

722
00:38:38,959 --> 00:38:41,460
existed and the multi-threading that was already there than new

723
00:38:41,460 --> 00:38:42,440
jobs.

724
00:38:42,440 --> 00:38:45,022
You just don't know all of the nuances of what's going on in

725
00:38:45,022 --> 00:38:45,602
the code.

726
00:38:45,602 --> 00:38:48,623
You haven't looked at it for who knows when.

727
00:38:48,623 --> 00:38:50,724
You may not have even been the person who wrote the code in the

728
00:38:50,724 --> 00:38:51,905
first place.

729
00:38:51,905 --> 00:38:55,366
So you end up with this tale of bugs that you get where you're

730
00:38:55,366 --> 00:38:57,607
getting those asserts that say you don't have permission to

731
00:38:57,607 --> 00:39:01,529
read this piece of data because you didn't realize that it reads

732
00:39:01,529 --> 00:39:03,770
this piece of data on the off chance that your player is

733
00:39:03,770 --> 00:39:05,050
looking up while jumping.

734
00:39:07,772 --> 00:39:14,477
And then, you know, it was just this unending feel where we kept going at it and kept going at it.

735
00:39:14,477 --> 00:39:20,421
I'm pretty sure it took us multiple months with multiple people to do it.

736
00:39:20,421 --> 00:39:22,622
So we learned we really needed a relief valve.

737
00:39:22,622 --> 00:39:27,625
As soon as we put the stuff in, we were getting asserts all over the place.

738
00:39:27,625 --> 00:39:30,727
We had issues in our code base that we've been skating by for a while now.

739
00:39:30,727 --> 00:39:31,948
And then...

740
00:39:32,785 --> 00:39:35,827
That workload just explodes on all the other people's teams

741
00:39:35,827 --> 00:39:38,069
because you're saying, hey, maybe there's

742
00:39:38,069 --> 00:39:39,150
an issue in rendering.

743
00:39:39,150 --> 00:39:42,232
Maybe there's an issue in the AI update or animation.

744
00:39:42,232 --> 00:39:45,474
And you're basically saying, hey, you now need to stop what

745
00:39:45,474 --> 00:39:48,916
you're doing and fix this multi-threaded bug.

746
00:39:48,916 --> 00:39:50,577
But you can't really do that.

747
00:39:50,577 --> 00:39:52,298
And you can't really do that all at once across your

748
00:39:52,298 --> 00:39:53,459
entire studio.

749
00:39:53,459 --> 00:39:56,441
So you need to have a way to ignore the issues or filter

750
00:39:56,441 --> 00:39:59,283
out the issues so that you can basically add a bug.

751
00:40:00,074 --> 00:40:02,536
forget about it, let the game run, and then at least know

752
00:40:02,536 --> 00:40:05,619
that it's going to get fixed when you triage your bugs

753
00:40:05,619 --> 00:40:09,362
later.

754
00:40:09,362 --> 00:40:11,684
We also had this great experience where we thought we

755
00:40:11,684 --> 00:40:12,205
were smart.

756
00:40:12,205 --> 00:40:14,587
We're going to roll this out in phases.

757
00:40:14,587 --> 00:40:17,169
We're going to start off by adding all of our resource

758
00:40:17,169 --> 00:40:20,152
protection to every piece of data that we've got.

759
00:40:20,152 --> 00:40:22,234
Then we're going to enable resource checks first.

760
00:40:22,234 --> 00:40:24,035
We want to enable overlaps.

761
00:40:24,035 --> 00:40:24,836
We can deal with that later.

762
00:40:24,836 --> 00:40:27,458
It'll be our second phase of rolling it out.

763
00:40:28,381 --> 00:40:30,423
But if you don't educate your team on what's going to happen,

764
00:40:30,423 --> 00:40:32,585
then your team goes ahead and just gives full permission

765
00:40:32,585 --> 00:40:33,405
to every single job.

766
00:40:33,405 --> 00:40:36,548
And then you turn on overlaps later,

767
00:40:36,548 --> 00:40:38,570
thinking it's going to be an easy time,

768
00:40:38,570 --> 00:40:40,792
and every single job in your system

769
00:40:40,792 --> 00:40:44,175
overlaps with every other job, even though the data is not

770
00:40:44,175 --> 00:40:44,916
being used.

771
00:40:44,916 --> 00:40:49,460
And so that comes back to trying to keep your policies tight

772
00:40:49,460 --> 00:40:51,061
with what you're actually doing.

773
00:40:51,753 --> 00:40:56,637
because the issue may not be a real issue it may just be that you've over

774
00:40:56,637 --> 00:40:59,239
subscribed that job to different data that it can use

775
00:40:59,239 --> 00:41:00,140
even if it's not using that data

776
00:41:00,140 --> 00:41:04,704
and there's a balance there

777
00:41:04,704 --> 00:41:08,907
you can't protect all of your resources

778
00:41:08,907 --> 00:41:11,809
I suppose you could if you really wanted to spend all the time

779
00:41:11,809 --> 00:41:15,913
but it's hard to represent all of the safe operations that you can do

780
00:41:16,651 --> 00:41:19,152
There's a lot of things that's really easy.

781
00:41:19,152 --> 00:41:21,073
You can be clever and try to pack data

782
00:41:21,073 --> 00:41:22,954
into different fields.

783
00:41:22,954 --> 00:41:26,255
You can try to do substructure allocations and think that

784
00:41:26,255 --> 00:41:28,877
it's safe for two jobs to be able to write to a different

785
00:41:28,877 --> 00:41:31,418
field inside of a structure, when really it's not because

786
00:41:31,418 --> 00:41:34,399
it's going to clobber it from some weird read from the

787
00:41:34,399 --> 00:41:36,760
compiler because you didn't do it on a atomic

788
00:41:36,760 --> 00:41:38,481
level for the chip.

789
00:41:39,843 --> 00:41:43,885
And so this really helped discourage that cleverness.

790
00:41:43,885 --> 00:41:46,266
But you really do need to figure out what level you're

791
00:41:46,266 --> 00:41:48,426
willing to go to actually protect.

792
00:41:48,426 --> 00:41:52,308
And we did that by restricting what programmers could

793
00:41:52,308 --> 00:41:54,708
actually do in some cases, just to make it simpler.

794
00:41:54,708 --> 00:41:55,729
Validation is not fast.

795
00:41:55,729 --> 00:42:02,131
It gets slower and slower every time you add another job.

796
00:42:02,131 --> 00:42:05,832
Those overlap checks are essentially n squared.

797
00:42:07,417 --> 00:42:10,600
And so we really just do the full validation steps inside

798
00:42:10,600 --> 00:42:10,900
automation.

799
00:42:10,900 --> 00:42:15,164
When you're checking in, you're doing a validation, but

800
00:42:15,164 --> 00:42:17,886
it's not the full exhaustive validation that you're getting

801
00:42:17,886 --> 00:42:19,207
from our automated farms.

802
00:42:19,207 --> 00:42:25,193
But we also found that it improved communication within

803
00:42:25,193 --> 00:42:25,733
our studio.

804
00:42:25,733 --> 00:42:30,157
You think that you've planned out your data well, and

805
00:42:30,157 --> 00:42:31,298
everything seems fine.

806
00:42:32,150 --> 00:42:35,293
But then you go and you implement it, and it just doesn't work.

807
00:42:35,293 --> 00:42:37,415
Somebody's using that data in a way that you didn't know.

808
00:42:37,415 --> 00:42:42,019
The person who originally designed it didn't know that people were using the data that way.

809
00:42:42,019 --> 00:42:46,324
And then of course, the engineer who originally wrote the code

810
00:42:46,324 --> 00:42:49,727
and thought that the data was only going to be used in one way

811
00:42:49,727 --> 00:42:53,050
now finally has a way to assert that that's going to happen.

812
00:42:53,050 --> 00:42:53,751
You don't have to...

813
00:42:54,812 --> 00:42:59,013
wait for some bug that you get six months down the road that

814
00:42:59,013 --> 00:43:02,054
says, hey, Joe Blow decided to use this data,

815
00:43:02,054 --> 00:43:04,795
and I don't want him to use it right now because I'm busy.

816
00:43:04,795 --> 00:43:06,895
I'm busy writing to it.

817
00:43:06,895 --> 00:43:09,896
So really, engineers ended up talking to other engineers.

818
00:43:09,896 --> 00:43:11,917
You ran into an assert from this.

819
00:43:11,917 --> 00:43:13,337
You got an overlap.

820
00:43:13,337 --> 00:43:15,418
And you wanted to find the right solution.

821
00:43:15,418 --> 00:43:17,519
So you ended up working with the people who architected

822
00:43:17,519 --> 00:43:18,559
the original system.

823
00:43:18,559 --> 00:43:20,460
And that was fantastic.

824
00:43:20,839 --> 00:43:23,020
especially for new hires or contractors.

825
00:43:23,020 --> 00:43:26,381
Because those people have just come into your code base

826
00:43:26,381 --> 00:43:28,422
and they don't really know anything.

827
00:43:28,422 --> 00:43:31,883
They're trying to get in and they're trying to do the best that they can.

828
00:43:31,883 --> 00:43:33,463
And sometimes that just turns into,

829
00:43:33,463 --> 00:43:35,304
I'm just going to make it work.

830
00:43:35,304 --> 00:43:37,965
And this system was a good way of saying,

831
00:43:37,965 --> 00:43:39,845
you think it's working, but it's not,

832
00:43:39,845 --> 00:43:42,006
and we're not going to let you keep that code checked in.

833
00:43:45,835 --> 00:43:48,378
It's actually faster than fixing it later.

834
00:43:48,378 --> 00:43:52,221
It seems like the upfront time is huge.

835
00:43:52,221 --> 00:43:55,203
It feels like you're spending more time overall.

836
00:43:55,203 --> 00:43:55,864
But you're really not.

837
00:43:55,864 --> 00:44:00,948
You're actually doing the fixes for this right away,

838
00:44:00,948 --> 00:44:03,610
right when you're doing the code in the first place.

839
00:44:03,610 --> 00:44:04,651
You actually know what's going on.

840
00:44:04,651 --> 00:44:07,314
It's not the three months later, I've come back,

841
00:44:07,314 --> 00:44:09,415
what the hell was I thinking?

842
00:44:09,415 --> 00:44:11,857
I don't know what I did in this function,

843
00:44:11,857 --> 00:44:13,058
and I'm never going to remember it

844
00:44:13,058 --> 00:44:14,460
without reading through the whole thing.

845
00:44:15,282 --> 00:44:17,303
But you haven't even checked the code in at this point,

846
00:44:17,303 --> 00:44:20,424
and it's telling you that it doesn't run because it has data

847
00:44:20,424 --> 00:44:23,005
conflicts over here or data conflicts over there.

848
00:44:23,005 --> 00:44:27,787
But it also has the advantage that when you walk away

849
00:44:27,787 --> 00:44:29,768
from the system, you can actually

850
00:44:29,768 --> 00:44:30,928
walk away from the system.

851
00:44:30,928 --> 00:44:32,469
The bug tail ends.

852
00:44:32,469 --> 00:44:33,949
You get all of the issues up front.

853
00:44:33,949 --> 00:44:37,931
It's not going to last for the next two years of your life

854
00:44:37,931 --> 00:44:40,432
when you try to figure out why the renderer can't work with

855
00:44:40,432 --> 00:44:41,352
the particle system.

856
00:44:46,323 --> 00:44:50,706
The other interesting piece that we had is reorganizing our frame was actually really easy.

857
00:44:50,706 --> 00:44:53,188
We had multiple occasions where people just decided,

858
00:44:53,188 --> 00:44:56,451
hey, I want to be able to get more use of the CPU during this area,

859
00:44:56,451 --> 00:44:59,293
so let's just figure out what runs over here.

860
00:44:59,293 --> 00:45:02,856
And the easiest way to do that now is by trial and error.

861
00:45:02,856 --> 00:45:05,538
You can try 20 different places where this piece of code can run,

862
00:45:05,538 --> 00:45:10,602
and the system will just tell you, no, you can't run there, you can't run here.

863
00:45:11,533 --> 00:45:13,874
or it will let you through for the one place that's there and

864
00:45:13,874 --> 00:45:15,895
you know you can just leave it there without having to think

865
00:45:15,895 --> 00:45:18,817
about it. So you're not in those meetings trying to discuss maybe

866
00:45:18,817 --> 00:45:21,598
it will work here. Let's try this out. And then you've got

867
00:45:21,598 --> 00:45:24,840
those three or four days when you have tests banging on it to

868
00:45:24,840 --> 00:45:27,862
hope that you find some crash. But you can actually do

869
00:45:27,862 --> 00:45:30,463
something crazy like change it just before beta. So to wrap

870
00:45:30,463 --> 00:45:30,723
things up.

871
00:45:38,051 --> 00:45:41,913
In conclusion, we shipped four platforms. We didn't have any

872
00:45:41,913 --> 00:45:45,696
threading issues that we were aware of. We had fewer threading

873
00:45:45,696 --> 00:45:48,577
bugs overall coming out of tests than we had on our previous

874
00:45:48,577 --> 00:45:52,460
titles. And those previous titles were only on one platform.

875
00:45:52,460 --> 00:45:56,983
So four platforms with fewer bugs than one platform was

876
00:45:56,983 --> 00:46:00,465
pretty awesome. We're pretty confident that we wouldn't have

877
00:46:00,465 --> 00:46:04,127
been able to ship without the execution environment. But the

878
00:46:04,127 --> 00:46:06,569
execution environment can't actually protect everything in

879
00:46:06,569 --> 00:46:07,229
the system.

880
00:46:10,620 --> 00:46:15,301
Was it worth it? Absolutely. We had to do it. No questions.

881
00:46:15,301 --> 00:46:21,043
We have some other bungee talks. Natasha's talk on the

882
00:46:21,043 --> 00:46:26,725
rendering architecture is next at 530, room 3005. Butcher has a

883
00:46:26,725 --> 00:46:30,987
talk tomorrow on the core architecture of destiny and the

884
00:46:30,987 --> 00:46:34,268
learnings that we had from it, which was fairly interesting.

885
00:46:34,268 --> 00:46:37,309
And Justin Truman has a talk on how we did our mission

886
00:46:37,309 --> 00:46:38,569
architecture for multiplayer.

887
00:46:40,735 --> 00:46:43,978
we're hiring, come work on the platform team, work in this

888
00:46:43,978 --> 00:46:48,742
environment, it's awesome. Any questions?

889
00:46:48,742 --> 00:47:04,176
Hey, that was really cool. What language features do you use to

890
00:47:04,176 --> 00:47:08,920
declare the dependencies of jobs when you write jobs?

891
00:47:09,725 --> 00:47:11,207
So it was just in C++.

892
00:47:11,207 --> 00:47:13,330
So a dependency from one job.

893
00:47:13,330 --> 00:47:15,613
We had a command, a depends on b.

894
00:47:15,613 --> 00:47:18,216
And you pass in the handle for the a job and the b job.

895
00:47:18,216 --> 00:47:21,620
And do you, I'm assuming you do this

896
00:47:21,620 --> 00:47:25,725
like via some sort of dynamic analysis that tries to just.

897
00:47:27,502 --> 00:47:31,683
Yes, at run time we check the job graph. That was the overlap

898
00:47:31,683 --> 00:47:34,844
algorithm. And then every time they handle the references is

899
00:47:34,844 --> 00:47:37,345
checking whether or not you have the policy permission.

900
00:47:37,345 --> 00:47:40,586
Have you explored doing like static analysis or something

901
00:47:40,586 --> 00:47:43,967
instead? There's a certain element that you can do in

902
00:47:43,967 --> 00:47:47,208
static analysis, but you can't cover everything. So you end up

903
00:47:47,208 --> 00:47:52,389
needing the dynamic analysis as well. So at the end of the day

904
00:47:52,389 --> 00:47:56,331
it's you can cover 80% one way, but you really do need that

905
00:47:56,331 --> 00:47:56,811
final 20%. So...

906
00:47:57,874 --> 00:48:00,916
there's an area that you can explore so you can catch it at

907
00:48:00,916 --> 00:48:04,859
compile time. But you catch it pretty fast at run time.

908
00:48:04,859 --> 00:48:10,483
Did threading your client in this way present any challenges

909
00:48:10,483 --> 00:48:13,565
trying to share game play code between the client and the

910
00:48:13,565 --> 00:48:21,570
server? That's a good question. We certainly had issues for

911
00:48:22,734 --> 00:48:26,718
pretty much everything that we did, right? Any threading had

912
00:48:26,718 --> 00:48:31,902
consequences from one place or another. As for the server side,

913
00:48:31,902 --> 00:48:34,865
I mean, most of that stuff is already serialized via the

914
00:48:34,865 --> 00:48:37,868
networking code. You're sending packets to it. It's a big

915
00:48:37,868 --> 00:48:41,471
buffer. So I don't know of anything that comes to my mind

916
00:48:41,471 --> 00:48:46,035
as this was a real big issue for the server client architecture

917
00:48:46,035 --> 00:48:46,696
doing it this way.

918
00:48:49,481 --> 00:48:52,246
Hello, this side, this side.

919
00:48:52,246 --> 00:48:54,209
And I have two questions.

920
00:48:54,209 --> 00:48:58,295
First, how to define a complete code path?

921
00:48:58,295 --> 00:49:00,078
Sorry, how do you define the?

922
00:49:00,078 --> 00:49:02,462
A complete code path to test.

923
00:49:07,493 --> 00:49:10,134
That's the same problem that you have with any case where you're

924
00:49:10,134 --> 00:49:12,994
trying to get full coverage over your code base.

925
00:49:12,994 --> 00:49:16,335
For us, most of that was done via explicit testing,

926
00:49:16,335 --> 00:49:20,396
where we knew, hey, if you do this, this covers all of this.

927
00:49:20,396 --> 00:49:23,017
Getting rid of branches that seem unnecessary

928
00:49:23,017 --> 00:49:24,637
if you don't need them.

929
00:49:24,637 --> 00:49:26,638
Our stress farm, again, with the monkeys

930
00:49:26,638 --> 00:49:28,619
that I mentioned earlier, where it's just

931
00:49:28,619 --> 00:49:31,979
a big stream of random input that helps get that coverage.

932
00:49:31,979 --> 00:49:34,600
I can't guarantee that we hit 100%, but.

933
00:49:35,516 --> 00:49:39,058
How long machine hours will you test?

934
00:49:39,058 --> 00:49:41,941
How long in hours was the unit test?

935
00:49:41,941 --> 00:49:45,543
It depends on the level of testing that you're doing.

936
00:49:45,543 --> 00:49:49,206
But a check-in job is probably about one to two hours.

937
00:49:49,206 --> 00:49:56,491
The full BVT test suite is easily 20 hours, if not more.

938
00:49:57,426 --> 00:49:59,627
Okay, and another question.

939
00:49:59,627 --> 00:50:03,769
We are putting our engine to the multi-thread architecture

940
00:50:03,769 --> 00:50:05,570
and we face the same problem,

941
00:50:05,570 --> 00:50:07,911
that there are a lot of older systems

942
00:50:07,911 --> 00:50:10,732
that are doing multi-threading in older ways.

943
00:50:10,732 --> 00:50:14,994
And we found that it's better to port the entire system

944
00:50:14,994 --> 00:50:17,595
to the new architecture in one time.

945
00:50:18,216 --> 00:50:25,801
So we open up a branch and when we finish doing this and putting back we find a lot of new bugs

946
00:50:25,801 --> 00:50:29,644
fly out. So I want to know how do you change your old

947
00:50:29,644 --> 00:50:34,608
systems to this new architecture step-by-step or

948
00:50:34,608 --> 00:50:37,249
any other suggestions?

949
00:50:37,249 --> 00:50:43,314
So if I get the question right as you're adding this to an existing architecture

950
00:50:43,314 --> 00:50:45,335
how do you catch all the bugs without

951
00:50:45,950 --> 00:50:49,651
systems. You just mentioned that. So for us it was mark up

952
00:50:49,651 --> 00:50:55,813
all the data and make sure that the access checks are going. As

953
00:50:55,813 --> 00:50:59,375
you find that you're going to see overlaps. We had a system to

954
00:50:59,375 --> 00:51:02,396
filter out those overlaps so we would know about it. We would

955
00:51:02,396 --> 00:51:05,897
create a bug in our database and basically just say don't report

956
00:51:05,897 --> 00:51:09,819
this overlap to any user who is doing it until the person who is

957
00:51:09,819 --> 00:51:12,220
gone responsible for that bug actually fixes it.

958
00:51:12,660 --> 00:51:18,502
So that's allowed us to basically turn it on for the old systems without exploding it everywhere.

959
00:51:18,502 --> 00:51:23,965
Okay, so you have two systems running simultaneously at certain points?

960
00:51:23,965 --> 00:51:27,266
The older system and the new system?

961
00:51:27,266 --> 00:51:32,629
So I mean, you have a toggle in some way to switch between those systems, right?

962
00:51:32,629 --> 00:51:37,211
Like, you're just going to hit that as you toggle between the systems.

963
00:51:37,211 --> 00:51:38,991
Okay, thank you.

964
00:51:38,991 --> 00:51:39,572
Thank you.

965
00:51:40,883 --> 00:51:40,923
Hi.

966
00:51:40,923 --> 00:51:44,845
So if you had all these really nice systems

967
00:51:44,845 --> 00:51:48,607
for determining when data contention happened,

968
00:51:48,607 --> 00:51:52,889
why did you build this gigantic validation test system?

969
00:51:52,889 --> 00:51:58,832
Well, the validation test system is the thing that's telling us

970
00:51:58,832 --> 00:52:00,773
about data contention.

971
00:52:00,773 --> 00:52:03,414
Well, doesn't it just tell you up front whether or not

972
00:52:03,414 --> 00:52:05,195
you have contention?

973
00:52:05,195 --> 00:52:07,596
It does, but it's the only piece of our system

974
00:52:07,596 --> 00:52:09,877
that is telling us about that contention.

975
00:52:10,904 --> 00:52:14,625
It's not, so the handles would tell you whether or not they've been deleted.

976
00:52:14,625 --> 00:52:17,527
The handles don't tell you whether or not somebody else is accessing it.

977
00:52:17,527 --> 00:52:20,868
This is the piece that takes that information from the handles

978
00:52:20,868 --> 00:52:24,069
and then cross-references what every other piece of data is doing.

979
00:52:24,069 --> 00:52:28,371
So it's doing that, like, after the fact?

980
00:52:28,371 --> 00:52:30,091
It's doing...

981
00:52:30,091 --> 00:52:31,692
Part of it is up front.

982
00:52:31,692 --> 00:52:35,513
So every time that you access the data, it's checking dynamically right there and then

983
00:52:35,513 --> 00:52:37,474
for whether or not you have permission.

984
00:52:37,995 --> 00:52:41,436
And then the overlap checking is after the fact.

985
00:52:41,436 --> 00:52:45,097
We keep about three frames queued up so that you can see

986
00:52:45,097 --> 00:52:47,438
which jobs within there could be running long.

987
00:52:47,438 --> 00:52:50,459
And that piece is just done whenever the jobs are being

988
00:52:50,459 --> 00:52:51,459
added to the graph.

989
00:52:51,459 --> 00:52:54,040
It'll go across all of the other jobs that are

990
00:52:54,040 --> 00:52:54,561
previously there.

991
00:52:58,170 --> 00:53:05,593
Hi. So also related to this question that was just asked. So once you have handles, once you have

992
00:53:05,593 --> 00:53:10,955
policies that specify what data you can access and how, and handles that let you track the data

993
00:53:10,955 --> 00:53:17,137
as you access it, how do you deal with, like normally every engine is going to have a certain

994
00:53:17,137 --> 00:53:21,418
amount of third party software that is not going to have handles in the code. So...

995
00:53:23,152 --> 00:53:26,354
like once you have some components that just use raw

996
00:53:26,354 --> 00:53:27,535
pointers.

997
00:53:27,535 --> 00:53:27,695
Yes.

998
00:53:27,695 --> 00:53:31,098
There's lots of middleware that just use raw pointers.

999
00:53:31,098 --> 00:53:34,660
We've done things where we've embedded,

1000
00:53:34,660 --> 00:53:36,721
like our raw pointers for the user data

1001
00:53:36,721 --> 00:53:38,803
is just pointing into a handle.

1002
00:53:38,803 --> 00:53:41,985
We've had other parts where inside that actual callback

1003
00:53:41,985 --> 00:53:44,727
that you might get, you actually are explicitly

1004
00:53:44,727 --> 00:53:46,848
calling into the execution environment saying,

1005
00:53:46,848 --> 00:53:48,009
hey, check this access.

1006
00:53:48,618 --> 00:53:50,099
There's a few spots where, you know,

1007
00:53:50,099 --> 00:53:52,741
I've simplified some of the details

1008
00:53:52,741 --> 00:53:55,103
where it's not just in the handle access.

1009
00:53:55,103 --> 00:53:57,525
There's, there are those places where

1010
00:53:57,525 --> 00:53:59,366
that thread that's running in Havoc

1011
00:53:59,366 --> 00:54:01,348
that's calling your code is not actually a job.

1012
00:54:01,348 --> 00:54:05,311
And so the system does handle that via other mechanisms.

1013
00:54:05,311 --> 00:54:08,213
Okay, so it's like on a case by case basis.

1014
00:54:08,213 --> 00:54:09,174
Pretty much.

1015
00:54:09,174 --> 00:54:10,174
Okay, cool, thanks.

1016
00:54:10,174 --> 00:54:10,855
I had a question.

1017
00:54:10,855 --> 00:54:16,639
What types of data did you end up double buffering?

1018
00:54:19,178 --> 00:54:22,079
What types of data do we end up double buffering?

1019
00:54:22,079 --> 00:54:26,001
You know, there's a lot of stuff that we ended up doing.

1020
00:54:26,001 --> 00:54:28,962
There is the weirder esoteric ones,

1021
00:54:28,962 --> 00:54:33,824
like a bunch of simulation state for timing information

1022
00:54:33,824 --> 00:54:34,924
for networking.

1023
00:54:34,924 --> 00:54:37,585
Because of the time frame when networking ran,

1024
00:54:37,585 --> 00:54:39,706
it ran where simulation was going,

1025
00:54:39,706 --> 00:54:41,566
but it could have lagged over the frame.

1026
00:54:41,566 --> 00:54:44,127
So it couldn't actually directly access that.

1027
00:54:44,127 --> 00:54:46,948
It was most of the time that we were doing the caching.

1028
00:54:47,528 --> 00:54:55,495
If you go and you see Natasha's talk, you'll find a big section that we double-buffered from the game state for rendering.

1029
00:54:55,495 --> 00:55:01,399
Not the entire game state, but portions that went out and that probably encompasses the bulk of what's there.

1030
00:55:01,399 --> 00:55:09,585
Yeah, it seems like if you're updating game entities all in parallel, don't you need to double buffer their states so that...

1031
00:55:10,510 --> 00:55:13,072
So in that case, we actually, the way

1032
00:55:13,072 --> 00:55:16,275
that we update those entities, we have families,

1033
00:55:16,275 --> 00:55:17,196
object families.

1034
00:55:17,196 --> 00:55:19,658
So if an object is likely to touch another object,

1035
00:55:19,658 --> 00:55:21,499
it's going to be updated in the same job.

1036
00:55:21,499 --> 00:55:25,903
And then furthermore, if it has to touch an object that's

1037
00:55:25,903 --> 00:55:28,065
outside of that job, it'll just queue a message.

1038
00:55:28,065 --> 00:55:29,787
And we have a final message drain

1039
00:55:29,787 --> 00:55:32,469
at the end that can process interactions like that

1040
00:55:32,469 --> 00:55:33,690
so that we don't have those problems.

1041
00:55:36,365 --> 00:55:41,928
Hey, so do you only detect bad accesses on like dynamic tests?

1042
00:55:41,928 --> 00:55:45,370
Or do you do it on like commit as well?

1043
00:55:46,384 --> 00:55:47,904
So we don't need to do it on commit,

1044
00:55:47,904 --> 00:55:52,045
because the scope of a policy is within the entire job.

1045
00:55:52,045 --> 00:55:54,546
So in order to actually commit, you

1046
00:55:54,546 --> 00:55:56,226
need to dereference the handle.

1047
00:55:56,226 --> 00:55:58,727
And in order to read, you have to dereference the handle.

1048
00:55:58,727 --> 00:56:01,327
We do differentiate those with different functions

1049
00:56:01,327 --> 00:56:04,028
that we can choose whether or not it's a reader or write.

1050
00:56:04,028 --> 00:56:06,969
But that's just done at the time that you're dereferencing it.

1051
00:56:06,969 --> 00:56:09,649
And it's safe, because later in the scope,

1052
00:56:09,649 --> 00:56:11,570
you still have the same EE policy.

1053
00:56:11,570 --> 00:56:13,750
So by commit, I meant like a git commit.

1054
00:56:15,159 --> 00:56:20,641
Oh, I see. So yes, for our submission process runs through

1055
00:56:20,641 --> 00:56:24,522
the automation. That's our gauntlet process. And that's

1056
00:56:24,522 --> 00:56:28,063
done where you'll get kicked back. You won't be able to

1057
00:56:28,063 --> 00:56:30,804
submit if your code doesn't run.

1058
00:56:30,804 --> 00:56:37,706
So this is a pretty inherently complex system. And you

1059
00:56:37,706 --> 00:56:38,426
acknowledge that.

1060
00:56:39,477 --> 00:56:41,978
has this at A, what do you guys do for code?

1061
00:56:41,978 --> 00:56:45,118
How do you code review code about Fabricator, GitHub,

1062
00:56:45,118 --> 00:56:46,259
or so on?

1063
00:56:46,259 --> 00:56:50,119
And has it added a lot of overhead or time

1064
00:56:50,119 --> 00:56:52,100
on your people on your team having

1065
00:56:52,100 --> 00:56:53,700
to review a lot of code for people

1066
00:56:53,700 --> 00:56:56,641
that aren't as familiar with the system as you guys are?

1067
00:56:56,641 --> 00:56:58,641
So I mean, depending on the time frame

1068
00:56:58,641 --> 00:57:01,082
where we're in within the production cycle,

1069
00:57:01,082 --> 00:57:03,662
the amount of code review that we do is different.

1070
00:57:03,662 --> 00:57:06,043
The closer we are to our release point,

1071
00:57:06,043 --> 00:57:07,903
we have more code reviews going on.

1072
00:57:07,903 --> 00:57:08,743
But.

1073
00:57:10,222 --> 00:57:14,965
for the added amount of code review for the extra policy, it's not usually too much. There was

1074
00:57:14,965 --> 00:57:19,047
definitely a lot right up front when we were rolling out the system, and it did add a lot of

1075
00:57:19,047 --> 00:57:25,931
work for a lot of teams. But in the current state, it's basically, hey, did you run this in the test

1076
00:57:25,931 --> 00:57:31,214
build? Did you actually check that it's working? They say yes. You generally look through their

1077
00:57:31,214 --> 00:57:36,517
policy to make sure that it looks like it's doing the right thing. It's not a huge amount of time.

1078
00:57:37,030 --> 00:57:40,592
And this might be a naive question, but if you, if all of

1079
00:57:40,592 --> 00:57:45,413
your jobs declaratively declare what their data dependencies

1080
00:57:45,413 --> 00:57:49,175
are, why do you need to dynamically run them?

1081
00:57:49,175 --> 00:57:52,896
So you don't need to dynamically run them in order

1082
00:57:52,896 --> 00:57:56,397
for that portion, because you've got that piece already

1083
00:57:56,397 --> 00:58:00,839
running. That piece is actually statically checked. It just

1084
00:58:00,839 --> 00:58:04,020
happens to be that some of the jobs are run in different

1085
00:58:04,020 --> 00:58:05,800
orders on different frames. So we do.

1086
00:58:06,235 --> 00:58:08,257
check that at the frame level.

1087
00:58:08,257 --> 00:58:11,239
But for the pieces, like the question earlier,

1088
00:58:11,239 --> 00:58:13,561
where it's like, hey, what do you do when middleware is

1089
00:58:13,561 --> 00:58:14,441
calling into this code?

1090
00:58:14,441 --> 00:58:17,303
That actually needs a dynamic check going on it,

1091
00:58:17,303 --> 00:58:20,005
because you don't know the dependencies

1092
00:58:20,005 --> 00:58:22,507
between that piece with the rest of your game frame.

1093
00:58:22,507 --> 00:58:23,407
Cool.

1094
00:58:23,407 --> 00:58:27,350
Cool.

1095
00:58:27,350 --> 00:58:27,490
Hi.

1096
00:58:27,490 --> 00:58:30,673
I was wondering if, in addition to your built-in system

1097
00:58:30,673 --> 00:58:34,495
that you tried using third-party thread-checking software,

1098
00:58:35,195 --> 00:58:37,656
thread sanitizer with Clang or Intel Inspector?

1099
00:58:37,656 --> 00:58:41,458
Sorry, can you repeat the question a little bit louder?

1100
00:58:41,458 --> 00:58:45,700
I was wondering if you tried using third party thread

1101
00:58:45,700 --> 00:58:48,261
checking software in addition to what you've been doing.

1102
00:58:48,261 --> 00:58:51,542
So Clang's thread sanitizer or Intel's Inspector,

1103
00:58:51,542 --> 00:58:54,744
which will do runtime checks for.

1104
00:58:54,744 --> 00:58:59,406
So we do have some static analysis that we run offline.

1105
00:58:59,406 --> 00:59:02,807
We didn't investigate a huge amount of the other pieces.

1106
00:59:04,248 --> 00:59:09,935
A lot of those times you get a big bucket of work items that filtering the signal through

1107
00:59:09,935 --> 00:59:12,058
the noise is really hard in those systems.

1108
00:59:12,058 --> 00:59:12,519
Yep, thank you.

1109
00:59:12,519 --> 00:59:13,660
Thanks everybody for coming.

1110
00:59:13,660 --> 00:59:18,667
Please fill out your form, survey form.

1111
00:59:18,667 --> 00:59:19,148
Thank you.

1112
00:59:19,148 --> 00:59:19,568
Thank you.

1113
00:59:19,568 --> 00:59:20,549
Thank you.

1114
00:59:20,549 --> 00:59:20,830
Thank you.

1115
00:59:20,830 --> 00:59:20,990
Thank you.

1116
00:59:20,990 --> 00:59:21,170
Thank you.

1117
00:59:21,170 --> 00:59:21,370
Thank you.

1118
00:59:21,370 --> 00:59:21,551
Thank you.

1119
00:59:21,551 --> 00:59:21,751
Thank you.

1120
00:59:21,751 --> 00:59:21,911
Thank you.

1121
00:59:21,911 --> 00:59:22,091
Thank you.

1122
00:59:22,091 --> 00:59:22,312
Thank you.

1123
00:59:22,312 --> 00:59:22,492
Thank you.

1124
00:59:22,492 --> 00:59:22,652
Thank you.

