1
00:00:06,268 --> 00:00:10,571
All right, hello, welcome to Bringing Hell to Life,

2
00:00:10,571 --> 00:00:11,932
AI and Full Body Animation in Doom.

3
00:00:11,932 --> 00:00:14,915
I wanna thank you all for coming today,

4
00:00:14,915 --> 00:00:16,096
I really appreciate it.

5
00:00:16,096 --> 00:00:17,677
My name is Jake Campbell,

6
00:00:17,677 --> 00:00:19,138
I'm an AI developer at id Software.

7
00:00:19,138 --> 00:00:21,240
And for those of you that don't know,

8
00:00:21,240 --> 00:00:23,682
Doom was released last year,

9
00:00:23,682 --> 00:00:26,844
and it's our reimagining and modernization of the series.

10
00:00:26,844 --> 00:00:29,346
And since release, it has gone on to receive

11
00:00:29,346 --> 00:00:31,708
a number of awards and nominations.

12
00:00:33,877 --> 00:00:38,880
The underlying theme of this talk is how we have given our AI more direct control over

13
00:00:38,880 --> 00:00:39,540
their animations.

14
00:00:39,540 --> 00:00:44,784
The AI does not drive the character with stick input and button presses.

15
00:00:44,784 --> 00:00:49,267
In our system, there's not really a clear distinction between AI code and character

16
00:00:49,267 --> 00:00:49,487
code.

17
00:00:49,487 --> 00:00:56,491
And along with that, we rely heavily on full body animation rather than a partial body

18
00:00:56,491 --> 00:00:57,372
or layered approach.

19
00:00:59,392 --> 00:01:01,854
This presentation is split into three segments.

20
00:01:01,854 --> 00:01:04,276
First, I'm going to explain some of the reasons

21
00:01:04,276 --> 00:01:06,078
that we went with a direct control approach.

22
00:01:06,078 --> 00:01:08,881
Then I'm going to provide four examples

23
00:01:08,881 --> 00:01:11,924
of how our AI makes use of this extra control.

24
00:01:11,924 --> 00:01:14,727
And finally, I'm going to conclude with an example

25
00:01:14,727 --> 00:01:17,109
of how it all works together to influence

26
00:01:17,109 --> 00:01:18,951
the ways we implement certain behaviors.

27
00:01:21,524 --> 00:01:25,045
Now, our most defining feature, which is a diverse cast of enemies,

28
00:01:25,045 --> 00:01:31,746
was the source of two primary factors that influenced how much control we gave our AI.

29
00:01:31,746 --> 00:01:38,308
Our game contains 19 AI types, each with many custom behaviors that imply custom animation solutions.

30
00:01:38,308 --> 00:01:44,889
Along with that, the game fiction and genre dictate that animation style is of utmost importance.

31
00:01:47,170 --> 00:01:52,915
So the goal of minimizing constraints that inhibit animator creativity was one of the

32
00:01:52,915 --> 00:01:55,557
significant factors over the duration of the project.

33
00:01:55,557 --> 00:02:01,683
If the AI requires things like shorter animations, multiple layers, pose matching, etc., those

34
00:02:01,683 --> 00:02:05,005
can quickly add up to have a net impact on a final result.

35
00:02:05,005 --> 00:02:10,370
Animators can typically deliver the most stylish and impressive results when they can focus

36
00:02:10,370 --> 00:02:13,153
on the animation itself rather than technicalities.

37
00:02:13,593 --> 00:02:18,397
And nothing looks as good as a well-made full body animation full of style and personality.

38
00:02:18,397 --> 00:02:24,923
A great example of how successful an unconstrained straightforward approach can be

39
00:02:24,923 --> 00:02:26,645
is the response of RAI to damage.

40
00:02:26,645 --> 00:02:30,348
Now there are four general categories of damage response,

41
00:02:30,348 --> 00:02:32,290
each being more severe than the previous.

42
00:02:32,290 --> 00:02:35,753
And there are also different severities within each category.

43
00:02:35,753 --> 00:02:38,415
This ends up being a lot of animations.

44
00:02:40,068 --> 00:02:43,831
Twitches are additive animations that are played in layers

45
00:02:43,831 --> 00:02:45,453
over whatever the AI is currently doing.

46
00:02:45,453 --> 00:02:47,074
Now, they are not full body,

47
00:02:47,074 --> 00:02:49,176
but I'm including them here for completeness

48
00:02:49,176 --> 00:02:50,797
and to illustrate that we do use

49
00:02:50,797 --> 00:02:52,839
partial body solutions at times.

50
00:02:52,839 --> 00:02:55,822
But anything more severe than twitches,

51
00:02:55,822 --> 00:02:56,943
like a standard pain,

52
00:02:56,943 --> 00:02:59,445
is just a straightforward, full-bloody animation.

53
00:02:59,445 --> 00:03:02,848
Now, our pain animations often move the characters,

54
00:03:02,848 --> 00:03:04,169
and animators find great enjoyment

55
00:03:04,169 --> 00:03:05,911
in authoring this kind of content.

56
00:03:07,203 --> 00:03:08,983
A special category of full body,

57
00:03:08,983 --> 00:03:12,425
a special category of pain animation

58
00:03:12,425 --> 00:03:14,305
is what we call a stagger,

59
00:03:14,305 --> 00:03:17,267
and the player can execute synchronized glory kills

60
00:03:17,267 --> 00:03:18,547
against staggered enemies.

61
00:03:18,547 --> 00:03:22,288
Standard deaths start out as full body animations,

62
00:03:22,288 --> 00:03:25,269
but they blend into ragdoll physics as the model is falling.

63
00:03:26,146 --> 00:03:31,289
And classic deaths include multiple separate skeletal meshes, all animating in sequence.

64
00:03:31,289 --> 00:03:36,393
For example, a Hell Knight's limb being severed and animating along with the rest of his body.

65
00:03:36,393 --> 00:03:39,995
Now, many classic deaths involve animated jibs

66
00:03:39,995 --> 00:03:44,238
because we wanted to give the animators control over every facet of the presentation.

67
00:03:44,238 --> 00:03:49,902
All of this content was manageable and successful across more than 10 unique character skeletons

68
00:03:49,902 --> 00:03:52,303
because we just let the animators have at it.

69
00:03:54,065 --> 00:03:56,466
The other significant factor in forming our approach

70
00:03:56,466 --> 00:03:59,527
was the goal of adding sophisticated polish to characters

71
00:03:59,527 --> 00:04:01,308
in order to make them feel as alive as possible.

72
00:04:01,308 --> 00:04:03,029
This is kind of obvious, right?

73
00:04:03,029 --> 00:04:06,250
But we wanted the ability to easily add or modify behaviors

74
00:04:06,250 --> 00:04:08,171
in ways that increase responsiveness

75
00:04:08,171 --> 00:04:11,453
while maintaining the style and cadence

76
00:04:11,453 --> 00:04:12,373
of full-body animation.

77
00:04:12,373 --> 00:04:14,374
An example is our imp performing

78
00:04:14,374 --> 00:04:16,955
the conceptually simple behavior of throwing a fireball,

79
00:04:16,955 --> 00:04:18,676
which ends up being quite sophisticated.

80
00:04:19,580 --> 00:04:22,260
The projectile throws follow parabolic arcs,

81
00:04:22,260 --> 00:04:23,841
and the imps lead their targets.

82
00:04:23,841 --> 00:04:26,481
So validating these potential trajectory paths

83
00:04:26,481 --> 00:04:28,442
entails a non-trivial set of tests

84
00:04:28,442 --> 00:04:30,683
that requires timing and pose information

85
00:04:30,683 --> 00:04:31,963
from the animations themselves.

86
00:04:31,963 --> 00:04:34,884
Furthermore, to improve presentation,

87
00:04:34,884 --> 00:04:38,185
our imps try to release their fireball not on a fixed frame,

88
00:04:39,052 --> 00:04:41,874
but when the tangent of the arc that their hand joint follows

89
00:04:41,874 --> 00:04:43,475
matches the desired launch angle,

90
00:04:43,475 --> 00:04:44,756
just like throwing a baseball.

91
00:04:44,756 --> 00:04:50,019
And since a target is typically moving throughout a windup,

92
00:04:50,019 --> 00:04:51,881
this essentially couples the animation

93
00:04:51,881 --> 00:04:52,541
with the AI targeting systems.

94
00:04:52,541 --> 00:04:55,503
Then we wanted to give the imp the ability to throw

95
00:04:55,503 --> 00:04:58,205
during stop transitions and evasion hops,

96
00:04:58,205 --> 00:04:59,906
which is coupling attack behavior

97
00:04:59,906 --> 00:05:02,307
and locomotion animation selection.

98
00:05:02,307 --> 00:05:05,609
On top of all this, we added stronger fastball throws

99
00:05:05,609 --> 00:05:08,011
that require a looping charge animation shown there.

100
00:05:08,355 --> 00:05:11,277
that can be aborted when the angle to the target exceeds a threshold.

101
00:05:11,277 --> 00:05:12,397
So why give the AI more animation control though?

102
00:05:12,397 --> 00:05:20,462
To sum up, the two goals were keep the animators from being unnecessarily constrained.

103
00:05:20,462 --> 00:05:26,486
The thing that they do best is animate straightforward full-body animations that play out the way

104
00:05:26,486 --> 00:05:27,727
they see them in their tools.

105
00:05:28,345 --> 00:05:30,327
And second, make it easier for the AI

106
00:05:30,327 --> 00:05:33,249
to do more sophisticated things without needing

107
00:05:33,249 --> 00:05:36,531
to constantly refactor non-AI code in ways

108
00:05:36,531 --> 00:05:39,073
that only the AI ultimately benefits from.

109
00:05:39,073 --> 00:05:42,075
Now, both goals are reached by shifting

110
00:05:42,075 --> 00:05:43,176
animation control to the AI.

111
00:05:43,176 --> 00:05:46,198
Because then, using full-body animations

112
00:05:46,198 --> 00:05:49,680
to construct and improve behaviors is a straightforward

113
00:05:49,680 --> 00:05:51,061
and that's a known quantity.

114
00:05:51,061 --> 00:05:53,283
They become the ideal building block

115
00:05:53,283 --> 00:05:54,323
for whatever we want to do.

116
00:05:56,401 --> 00:05:59,023
Now the AI code can do extra work on its end

117
00:05:59,023 --> 00:06:00,644
to make better use of full body animations.

118
00:06:00,644 --> 00:06:02,766
Today I'm going to talk about four examples.

119
00:06:02,766 --> 00:06:06,648
Our AI modify animation translation and rotation

120
00:06:06,648 --> 00:06:08,470
using a technique we call delta correction.

121
00:06:08,470 --> 00:06:11,472
Their focus tracking involves modifying animation pose.

122
00:06:11,472 --> 00:06:15,495
Our foot phase synchronization requires being able

123
00:06:15,495 --> 00:06:18,517
to modify playback rate and position.

124
00:06:18,517 --> 00:06:21,459
And the way our AI perform bad zone avoidance

125
00:06:21,459 --> 00:06:24,381
is somewhat counterintuitive way of modifying blend weights.

126
00:06:26,817 --> 00:06:29,979
So the first way I try to make the animations more useful

127
00:06:29,979 --> 00:06:32,581
is by influencing the origin bone or root bone,

128
00:06:32,581 --> 00:06:34,082
depending on the engine you use,

129
00:06:34,082 --> 00:06:35,502
translation and or rotation.

130
00:06:35,502 --> 00:06:38,324
The primary use of this in our code

131
00:06:38,324 --> 00:06:39,505
is what we call delta correction.

132
00:06:39,505 --> 00:06:42,247
And the basic idea is scaling or lerping

133
00:06:42,247 --> 00:06:44,228
the translation and or rotation

134
00:06:44,228 --> 00:06:46,689
of a non-blended full body animation.

135
00:06:46,689 --> 00:06:48,790
We take a single animation here,

136
00:06:48,790 --> 00:06:50,051
an imp jumping forward,

137
00:06:50,051 --> 00:06:53,073
and we make it usable in an infinite number of scenarios

138
00:06:53,073 --> 00:06:53,713
within reason.

139
00:06:53,713 --> 00:06:55,495
And effectively,

140
00:06:55,987 --> 00:06:59,307
This allows the AI to use far fewer animations,

141
00:06:59,307 --> 00:07:01,248
yet retain the ability to move where it wants

142
00:07:01,248 --> 00:07:02,348
when playing those animations.

143
00:07:02,348 --> 00:07:04,129
Now, in the following slides,

144
00:07:04,129 --> 00:07:05,949
I focus mostly on translation,

145
00:07:05,949 --> 00:07:07,529
but the system is equally powerful

146
00:07:07,529 --> 00:07:09,530
and is used just as much with rotation.

147
00:07:09,530 --> 00:07:12,931
So here we have an imp playing a gap jump animation,

148
00:07:12,931 --> 00:07:15,752
but the animation doesn't automatically place

149
00:07:15,752 --> 00:07:17,092
in where we want in the world,

150
00:07:17,092 --> 00:07:18,492
which is at the red star.

151
00:07:18,492 --> 00:07:19,372
So how do we fix that?

152
00:07:19,372 --> 00:07:22,753
Well, if the model is at point X at time T sub C,

153
00:07:23,838 --> 00:07:25,981
You first want to define a reference point in the animation.

154
00:07:25,981 --> 00:07:28,485
This is what you want to align with the target position

155
00:07:28,485 --> 00:07:30,949
by the time that time in the animation is reached.

156
00:07:30,949 --> 00:07:33,653
And here, the time at the reference point is T sub N.

157
00:07:33,653 --> 00:07:36,718
We already know what the target point is, just label it Z.

158
00:07:38,056 --> 00:07:40,317
The delta between those defines the remaining error

159
00:07:40,317 --> 00:07:41,437
that's gonna need to be applied

160
00:07:41,437 --> 00:07:42,998
before the animation finishes.

161
00:07:42,998 --> 00:07:45,099
But how much of this error should be applied

162
00:07:45,099 --> 00:07:47,380
on the next time slice of the animation?

163
00:07:47,380 --> 00:07:50,541
Well, find the next time, t sub c plus one,

164
00:07:50,541 --> 00:07:53,362
and then the ratio of the next time slice

165
00:07:53,362 --> 00:07:55,403
to the remaining time in the animation

166
00:07:55,403 --> 00:07:58,024
to the reference point defines the fraction

167
00:07:58,024 --> 00:07:59,725
to apply on the next game frame.

168
00:07:59,725 --> 00:08:00,966
So we do that.

169
00:08:01,975 --> 00:08:04,558
and it moves the model a little bit towards the target point.

170
00:08:04,558 --> 00:08:07,962
Now, applying the same equation each game frame

171
00:08:07,962 --> 00:08:09,724
will ensure that animation point Y

172
00:08:09,724 --> 00:08:12,367
coincides with world point Z

173
00:08:12,367 --> 00:08:14,369
under a wide variety of conditions.

174
00:08:15,637 --> 00:08:17,738
In particular, if the conditions change

175
00:08:17,738 --> 00:08:20,039
such that the reference point is prior

176
00:08:20,039 --> 00:08:21,099
to the window of correction,

177
00:08:21,099 --> 00:08:24,341
the target point is before the animation

178
00:08:24,341 --> 00:08:25,781
or behind the model,

179
00:08:25,781 --> 00:08:28,042
and even if the window of correction

180
00:08:28,042 --> 00:08:29,743
ends before the animation,

181
00:08:29,743 --> 00:08:31,904
the math stays exactly the same.

182
00:08:31,904 --> 00:08:33,985
Applying the same equation gets a different result.

183
00:08:33,985 --> 00:08:36,086
In this case, correction is backwards.

184
00:08:36,086 --> 00:08:38,908
And the math aligns the model

185
00:08:38,908 --> 00:08:41,649
as if the animation has hit the target point,

186
00:08:41,649 --> 00:08:43,890
essentially correcting to a point in the past

187
00:08:43,890 --> 00:08:44,730
rather than the future.

188
00:08:46,616 --> 00:08:51,497
Given an animation like this traversal, where the imp is leaping up to grab hold of an overhang,

189
00:08:51,497 --> 00:08:56,598
climbing over it, and jumping off, we can more effectively use delta correction if we

190
00:08:56,598 --> 00:09:02,079
restrict the application to discrete windows of the animation.

191
00:09:02,079 --> 00:09:07,101
For example, to prevent sliding and or clipping, we can apply the error correction only when

192
00:09:07,101 --> 00:09:10,361
the model is completely free of world contacts, in this case, in the air.

193
00:09:11,257 --> 00:09:13,599
Now defining windows like this,

194
00:09:13,599 --> 00:09:16,782
where the correction will not cause foot sliding,

195
00:09:16,782 --> 00:09:17,983
is absolutely essential in most cases.

196
00:09:17,983 --> 00:09:21,746
You can even use multiple windows if you want.

197
00:09:21,746 --> 00:09:24,008
For example, maybe you want to separate

198
00:09:24,008 --> 00:09:25,910
translation correction from rotation correction.

199
00:09:25,910 --> 00:09:28,612
Now the power of using windows,

200
00:09:28,612 --> 00:09:31,595
is that the AI is able to treat a single animation

201
00:09:31,595 --> 00:09:33,277
as a sequence of multiple parts,

202
00:09:33,277 --> 00:09:35,799
without the animators needing to do the work

203
00:09:35,799 --> 00:09:36,440
of cutting it up.

204
00:09:38,527 --> 00:09:40,108
Some more subtleties in our approach.

205
00:09:40,108 --> 00:09:42,530
If you really want to minimize the perception

206
00:09:42,530 --> 00:09:45,573
of error correction, you can scale the fractional amount

207
00:09:45,573 --> 00:09:48,836
of correction each frame by the relative velocity

208
00:09:48,836 --> 00:09:49,957
of the model in that frame.

209
00:09:49,957 --> 00:09:52,400
In other words, you hide the correction

210
00:09:52,400 --> 00:09:53,881
behind a faster moving model.

211
00:09:54,592 --> 00:09:57,633
And most importantly, because the math is repeated

212
00:09:57,633 --> 00:09:59,454
each game frame rather than just once

213
00:09:59,454 --> 00:10:01,095
at the beginning of the animation,

214
00:10:01,095 --> 00:10:03,156
a target point moving through the world

215
00:10:03,156 --> 00:10:04,637
is automatically accounted for.

216
00:10:04,637 --> 00:10:06,338
In this case, assume that our target point

217
00:10:06,338 --> 00:10:08,379
is moving upwards like that during the animation.

218
00:10:08,379 --> 00:10:10,620
Well, the system simply plays catch up

219
00:10:10,620 --> 00:10:13,602
and increasingly applies more error correction each frame.

220
00:10:16,012 --> 00:10:18,975
Some examples of where we use Delta Correction extensively

221
00:10:18,975 --> 00:10:20,556
are traversals and attacks.

222
00:10:20,556 --> 00:10:22,818
Now in all these videos, the blue lines

223
00:10:22,818 --> 00:10:25,360
correspond to windows of Delta Correction.

224
00:10:25,360 --> 00:10:27,441
We have a library of traversal animations

225
00:10:27,441 --> 00:10:29,823
that is orders of magnitude smaller

226
00:10:29,823 --> 00:10:31,084
than the use cases and levels.

227
00:10:31,084 --> 00:10:34,187
Scaling the traversals lets the animators

228
00:10:34,187 --> 00:10:36,949
deliver highly stylized and unique animations for them,

229
00:10:36,949 --> 00:10:40,132
while also allowing designers nearly unlimited use

230
00:10:40,132 --> 00:10:41,573
of those animations in their levels.

231
00:10:42,845 --> 00:10:44,726
And we also delta correct melee attacks,

232
00:10:44,726 --> 00:10:46,747
such as the rotational yaw of swipes,

233
00:10:46,747 --> 00:10:50,310
the forward translation of lunges, the arc of leaps.

234
00:10:50,310 --> 00:10:52,351
All of this helps the AI feel more engaged.

235
00:10:52,351 --> 00:10:54,933
They can relentlessly pursue the target

236
00:10:54,933 --> 00:10:56,894
with less requirements to reposition

237
00:10:56,894 --> 00:11:00,236
and orient themselves properly prior to the next attack.

238
00:11:00,236 --> 00:11:02,718
And scaling leaps in particular allows the AI

239
00:11:02,718 --> 00:11:06,040
to attack across a wider variety of level conditions.

240
00:11:06,040 --> 00:11:08,461
In this case, the Hell Knight is able to leap up

241
00:11:08,461 --> 00:11:10,262
and down the stairs by delta correcting

242
00:11:10,262 --> 00:11:12,644
the same animations that he uses on flat ground.

243
00:11:15,335 --> 00:11:18,598
A second example of the control I have over animation

244
00:11:18,598 --> 00:11:20,460
is changing their pose to track a target

245
00:11:20,460 --> 00:11:21,601
with their torso, head, or weapons.

246
00:11:21,601 --> 00:11:26,385
Now the canonical name we use for this is focus tracking.

247
00:11:26,385 --> 00:11:28,166
We use a hybrid inverse kinematic

248
00:11:28,166 --> 00:11:29,647
and forward kinematic solution,

249
00:11:29,647 --> 00:11:31,769
but hereafter I'm gonna refer to it as IK.

250
00:11:31,769 --> 00:11:32,050
Take a drink.

251
00:11:32,050 --> 00:11:33,691
The basics of focus tracking is straightforward.

252
00:11:42,248 --> 00:11:45,730
First, you find an effector transform in a reference pose.

253
00:11:45,730 --> 00:11:48,692
Now when I say effector, I'm speaking of the end effector

254
00:11:48,692 --> 00:11:49,873
in an IK joint chain.

255
00:11:49,873 --> 00:11:52,354
And I'm gonna explain this in a few slides,

256
00:11:52,354 --> 00:11:54,355
but how the reference pose is composed

257
00:11:54,355 --> 00:11:55,736
is extremely important.

258
00:11:55,736 --> 00:12:00,279
Next step is finding the desired transform for the effector.

259
00:12:00,279 --> 00:12:01,980
In this case, it looks like the Helmite

260
00:12:01,980 --> 00:12:02,941
wants to look to the right.

261
00:12:04,529 --> 00:12:07,612
Using IK, calculate the rotation that bring the effector

262
00:12:07,612 --> 00:12:09,113
into the desired transform.

263
00:12:09,113 --> 00:12:12,917
Then, spread those rotations across the desired joints

264
00:12:12,917 --> 00:12:15,059
in the IK chain underneath the effector.

265
00:12:15,059 --> 00:12:17,741
Now, since the spreading like this

266
00:12:17,741 --> 00:12:18,982
will introduce inaccuracy,

267
00:12:18,982 --> 00:12:20,504
if you desire perfect alignment,

268
00:12:20,504 --> 00:12:23,266
you can recalculate error at each joint

269
00:12:23,266 --> 00:12:23,987
as you go up the chain,

270
00:12:23,987 --> 00:12:25,668
or just the final joint in the chain.

271
00:12:27,959 --> 00:12:29,239
Then we add the joint rotations

272
00:12:29,239 --> 00:12:31,400
to the current animation pose.

273
00:12:31,400 --> 00:12:35,021
Now notice that this is identical to an additive animation.

274
00:12:35,021 --> 00:12:36,842
Conceptually, we're just making

275
00:12:36,842 --> 00:12:38,082
an additive animation on the fly.

276
00:12:38,082 --> 00:12:41,223
I mentioned that calculating error once

277
00:12:41,223 --> 00:12:43,484
and naively spreading it across multiple joints

278
00:12:43,484 --> 00:12:45,164
introduces inaccuracy.

279
00:12:45,164 --> 00:12:47,865
But that's exactly what our AI do,

280
00:12:47,865 --> 00:12:50,226
and yet they are accurate even at range.

281
00:12:50,226 --> 00:12:52,207
So in practice, the error isn't much,

282
00:12:52,207 --> 00:12:53,607
on smaller characters especially.

283
00:12:55,263 --> 00:12:57,664
The way we calculate angular error in our IK

284
00:12:57,664 --> 00:12:59,025
is what we call the circle trick.

285
00:12:59,025 --> 00:13:03,428
Given an IK chain or a joint chain rooted at P

286
00:13:03,428 --> 00:13:07,471
and a target T that you wanna align with,

287
00:13:07,471 --> 00:13:10,353
first create a sphere around P that intersects T.

288
00:13:10,353 --> 00:13:14,656
Then, simply extend a ray from the effector

289
00:13:14,656 --> 00:13:16,097
and find where it intersects the sphere.

290
00:13:16,097 --> 00:13:19,079
In this case, I've labeled it E.

291
00:13:19,079 --> 00:13:23,082
Those two intersections on the sphere define an angle,

292
00:13:23,082 --> 00:13:24,002
here labeled A.

293
00:13:25,155 --> 00:13:29,642
and rotating the root by A is going to align the effector,

294
00:13:29,642 --> 00:13:32,185
like that.

295
00:13:32,185 --> 00:13:35,190
Now often, we want to preserve animation content

296
00:13:35,190 --> 00:13:36,973
on a skeleton while tracking a target.

297
00:13:37,730 --> 00:13:40,852
To do this, we limit the rotations visible to the IK,

298
00:13:40,852 --> 00:13:43,795
and it calculates error from a single pose

299
00:13:43,795 --> 00:13:45,636
of the animation that stays constant.

300
00:13:45,636 --> 00:13:47,798
Here I have included a very embellished taunt

301
00:13:47,798 --> 00:13:50,821
from the Hell Knight, and an even more flavorful reaction

302
00:13:50,821 --> 00:13:52,142
from the Revenant.

303
00:13:52,142 --> 00:13:54,584
In both cases, notice how animation rotations

304
00:13:54,584 --> 00:13:56,986
in the head and torso are fully preserved

305
00:13:56,986 --> 00:13:59,348
as the characters track the target circling around them.

306
00:14:01,058 --> 00:14:05,106
Preserving animation content is just as useful for subtle embellishment.

307
00:14:05,106 --> 00:14:09,915
In this case, notice how the Mancubus appears to be glancing back and forth a little as he is looking at us.

308
00:14:09,915 --> 00:14:12,780
That's actually part of the animation, that is not focus tracking.

309
00:14:15,611 --> 00:14:17,753
And being able to preserve animation like this

310
00:14:17,753 --> 00:14:20,675
also makes it simple to implement behaviors like sweeps.

311
00:14:20,675 --> 00:14:23,857
In this case, the Hellraiser's focus tracking

312
00:14:23,857 --> 00:14:26,059
is merely adding some pitch to his lower back.

313
00:14:26,059 --> 00:14:28,460
It is the animation itself

314
00:14:28,460 --> 00:14:31,883
that sweeps the beam back and forth.

315
00:14:31,883 --> 00:14:33,724
IK is not even aware that this guy's arm is moving.

316
00:14:33,724 --> 00:14:38,367
So when we talk about what rotations are visible

317
00:14:38,367 --> 00:14:40,469
to an effector when it generates a reference pose,

318
00:14:41,467 --> 00:14:46,031
We're speaking of what information the joints in an IK chain inherit from their parents.

319
00:14:46,684 --> 00:14:49,665
For example, the head effectors chain in this Hell Knight

320
00:14:49,665 --> 00:14:52,026
inherits only the IK rotations

321
00:14:52,026 --> 00:14:53,966
from the torso joints underneath it.

322
00:14:53,966 --> 00:14:56,467
The debug arrows shown in the video

323
00:14:56,467 --> 00:14:59,288
display the joint transforms visible to the IK system

324
00:14:59,288 --> 00:15:02,949
as it builds a reference pose for the head to calculate air.

325
00:15:02,949 --> 00:15:04,569
Now observe how those transforms

326
00:15:04,569 --> 00:15:07,370
maintain a constant position and orientation

327
00:15:07,370 --> 00:15:10,251
despite the wildly changing animation on the upper body.

328
00:15:10,251 --> 00:15:12,352
In other words, the reference pose

329
00:15:12,352 --> 00:15:14,032
is constant throughout the animation.

330
00:15:14,683 --> 00:15:18,345
Now this implies that the rotations IK generates

331
00:15:18,345 --> 00:15:21,388
to aim the head are going to be constant as well.

332
00:15:21,388 --> 00:15:24,129
The animation rotations are not counteracted.

333
00:15:24,129 --> 00:15:26,891
In contrast, if an effector's chain inherits

334
00:15:26,891 --> 00:15:29,853
the animation rotations that change from frame to frame,

335
00:15:29,853 --> 00:15:31,375
it will calculate counter rotations

336
00:15:31,375 --> 00:15:34,036
and the animation will be counteracted.

337
00:15:34,036 --> 00:15:36,178
For example, look at the reference poses calculated

338
00:15:36,178 --> 00:15:38,339
for the shoulder cannon effectors of the Revenant.

339
00:15:38,339 --> 00:15:40,581
They're moving like crazy with the animation.

340
00:15:41,687 --> 00:15:44,510
They inherit the actual animation rotations,

341
00:15:44,510 --> 00:15:47,052
the IK counteracts those rotations,

342
00:15:47,052 --> 00:15:49,754
and the guns are conceptually locked on target

343
00:15:49,754 --> 00:15:52,056
with almost all animation rotation being removed.

344
00:15:54,262 --> 00:15:56,645
Because proper usage of a system like this

345
00:15:56,645 --> 00:15:59,168
requires reference poses that are fairly representative

346
00:15:59,168 --> 00:16:01,170
of the current animation behavior,

347
00:16:01,170 --> 00:16:03,192
swapping effector data sets is common.

348
00:16:03,192 --> 00:16:05,655
For example, in a forward aiming animation,

349
00:16:05,655 --> 00:16:07,397
the Mancubus uses an effector

350
00:16:07,397 --> 00:16:09,279
that is conceptually forward,

351
00:16:09,279 --> 00:16:11,281
while in another animation it might use an aim right.

352
00:16:11,281 --> 00:16:14,284
Now since the system generates a set of rotations

353
00:16:14,284 --> 00:16:16,407
that are essentially an additive pose,

354
00:16:16,948 --> 00:16:18,389
Swapping is easy.

355
00:16:18,389 --> 00:16:19,990
Simply generate the rotations

356
00:16:19,990 --> 00:16:21,651
for each effector independently

357
00:16:21,651 --> 00:16:24,253
and then blend from one set to another

358
00:16:24,253 --> 00:16:27,035
just like you would blend any other set

359
00:16:27,035 --> 00:16:27,735
of additive animations.

360
00:16:27,735 --> 00:16:31,538
This system also easily handles multiple effectors

361
00:16:31,538 --> 00:16:32,878
in a tree topology,

362
00:16:32,878 --> 00:16:35,680
as long as they are evaluated in order of inheritance,

363
00:16:35,680 --> 00:16:38,562
such that each child inherits the rotations of its parent,

364
00:16:38,562 --> 00:16:39,743
the math just works.

365
00:16:41,084 --> 00:16:43,886
In this case, the torso focus inherits nothing.

366
00:16:43,886 --> 00:16:45,268
It's parented to the origin.

367
00:16:45,268 --> 00:16:47,850
This is similar to the hybrid joint

368
00:16:47,850 --> 00:16:49,912
that the previous talk mentioned.

369
00:16:49,912 --> 00:16:54,696
The head focus is a child of the torso focus in terms of IK,

370
00:16:54,696 --> 00:16:56,617
so it inherits the IK rotations,

371
00:16:56,617 --> 00:16:59,280
but for animation purposes, it is a child of the origin,

372
00:16:59,280 --> 00:17:00,941
so it inherits no animation.

373
00:17:00,941 --> 00:17:04,604
But we want the shoulder guns to aim directly at you,

374
00:17:04,604 --> 00:17:08,007
so they inherit both the IK rotations from the torso focus

375
00:17:08,007 --> 00:17:09,728
and the current pose from the animation.

376
00:17:11,847 --> 00:17:14,388
The third control mechanism available to the AI

377
00:17:14,388 --> 00:17:16,588
is access to the playback rate and time

378
00:17:16,588 --> 00:17:18,289
in the animations themselves.

379
00:17:18,289 --> 00:17:20,309
An example is the way that our AI

380
00:17:20,309 --> 00:17:22,850
use foot phase tracking to synchronize animations.

381
00:17:22,850 --> 00:17:26,751
Now this is important to us because we remove the need

382
00:17:26,751 --> 00:17:29,611
to match both footstep counts and poses

383
00:17:29,611 --> 00:17:32,252
amongst locomotion cycles and animations

384
00:17:32,252 --> 00:17:34,233
that blend into such cycles.

385
00:17:34,233 --> 00:17:37,553
For example, this zombies walk animation blend space

386
00:17:37,874 --> 00:17:39,135
shown in the video on the left,

387
00:17:39,135 --> 00:17:42,298
is composed of animations with different footstep counts,

388
00:17:42,298 --> 00:17:45,481
yet we are able to seamlessly synchronize their playback.

389
00:17:45,481 --> 00:17:47,103
Forward is at least four cycles,

390
00:17:47,103 --> 00:17:49,445
while left, right, and backward are two cycles each,

391
00:17:49,445 --> 00:17:50,586
shown in the videos on the right.

392
00:17:52,303 --> 00:17:55,424
Now, we use four markers to keep track of foot phase.

393
00:17:55,424 --> 00:17:56,365
Why four and not two?

394
00:17:56,365 --> 00:18:00,987
Because directionality is encoded in a sequence of four,

395
00:18:00,987 --> 00:18:01,607
but not in two.

396
00:18:01,607 --> 00:18:05,229
In other words, the sequence one, two, three, four, one

397
00:18:05,229 --> 00:18:07,110
clearly defines a forward direction

398
00:18:07,110 --> 00:18:10,751
while the sequence one, two, one, two, one does not.

399
00:18:10,751 --> 00:18:14,333
The four markers we use are left foot plant,

400
00:18:14,333 --> 00:18:18,395
right knee cross left leg, right foot plant,

401
00:18:18,395 --> 00:18:20,436
and left knee cross right leg.

402
00:18:21,733 --> 00:18:28,399
Now suppose we have two animations that we want to play in sync, animation A and animation B.

403
00:18:28,399 --> 00:18:32,622
Further suppose that animation A has twice as many footsteps as animation B,

404
00:18:32,622 --> 00:18:36,146
yet the time between footsteps in animation B is longer.

405
00:18:36,146 --> 00:18:38,968
First, get the current frame of each animation.

406
00:18:38,968 --> 00:18:42,691
Then advance each animation as if they are not synchronized.

407
00:18:42,691 --> 00:18:45,113
Just assuming they have the same playback rate,

408
00:18:45,113 --> 00:18:49,217
we'll come up with the contrived number 1.3 animation frames.

409
00:18:50,397 --> 00:18:55,082
then you want to convert those frame deltas to phase deltas.

410
00:18:55,082 --> 00:18:58,605
Now note, since animation B is a longer span

411
00:18:58,605 --> 00:19:00,868
between footsteps, it's going to have a smaller fraction

412
00:19:00,868 --> 00:19:01,428
of the phase.

413
00:19:03,053 --> 00:19:04,915
Then we want to find the weighted average,

414
00:19:04,915 --> 00:19:06,797
weighted by blend contribution.

415
00:19:06,797 --> 00:19:09,220
I apologize that the number in the math

416
00:19:09,220 --> 00:19:11,582
does not match the number in the picture.

417
00:19:11,582 --> 00:19:14,245
The essential thing is that we're finding

418
00:19:14,245 --> 00:19:16,908
a single average phase amongst all the animations

419
00:19:16,908 --> 00:19:19,410
weighted by their blend values.

420
00:19:19,410 --> 00:19:22,073
In this case, because animation B is 66% of the blend,

421
00:19:22,073 --> 00:19:23,955
the end result, 0.19, is closer

422
00:19:23,955 --> 00:19:24,976
to its original value of 0.17.

423
00:19:25,837 --> 00:19:29,039
and then we take that single average phase

424
00:19:29,039 --> 00:19:31,820
and convert it back to animation frame deltas,

425
00:19:31,820 --> 00:19:34,142
which are gonna be different for each animation,

426
00:19:34,142 --> 00:19:36,864
and then advance each animation with the new numbers.

427
00:19:36,864 --> 00:19:38,485
Now they are synchronized.

428
00:19:38,485 --> 00:19:40,426
Now observe how in this example,

429
00:19:40,426 --> 00:19:42,567
animation B will be cycling from start to finish

430
00:19:42,567 --> 00:19:44,008
much faster than animation A.

431
00:19:44,008 --> 00:19:46,430
That's okay, that's what it's supposed to be doing.

432
00:19:48,355 --> 00:19:53,547
A fourth control the AI makes use of is manipulating blend values through a number of means.

433
00:19:53,547 --> 00:19:55,712
One example is bad zone avoidance.

434
00:19:56,587 --> 00:19:59,008
Here we have some hypothetical edges

435
00:19:59,008 --> 00:20:02,150
in a walking Revenant's 360 degree blend space.

436
00:20:02,150 --> 00:20:04,891
Now a bad zone is an area of this blend space

437
00:20:04,891 --> 00:20:07,112
where the animations don't work well together

438
00:20:07,112 --> 00:20:09,113
when played simultaneously.

439
00:20:09,113 --> 00:20:11,294
Perhaps the blend here colored in red.

440
00:20:11,294 --> 00:20:13,516
Now what do these bad blends look like?

441
00:20:13,516 --> 00:20:17,057
Well, Doom AI does not suffer from bunny hopping

442
00:20:17,057 --> 00:20:19,939
in bad zones because our foot phase synchronization

443
00:20:19,939 --> 00:20:20,719
prevents this.

444
00:20:20,719 --> 00:20:22,760
Instead, we get foot mangling.

445
00:20:23,328 --> 00:20:27,349
which is where the legs interpenetrate during crossover events in the animation

446
00:20:27,349 --> 00:20:29,169
and the hips just look awkward.

447
00:20:29,169 --> 00:20:33,210
So in trying to find a decent solution to this, we asked, well, what do humans do?

448
00:20:33,210 --> 00:20:36,991
Well, we, our legs physically cannot mangle.

449
00:20:36,991 --> 00:20:41,793
Instead, our bodies over or under rotate our hips

450
00:20:41,793 --> 00:20:46,694
relative to our desired facing and relative to our desired movement heading.

451
00:20:46,694 --> 00:20:49,755
And then we simply walk a little differently to maintain those.

452
00:20:50,357 --> 00:20:52,139
Now the AI used the same approach.

453
00:20:52,139 --> 00:20:54,541
This is based on the fact that the blend space

454
00:20:54,541 --> 00:20:56,363
is conceptually parented to the model's hips.

455
00:20:56,363 --> 00:20:58,044
Meaning if you rotate the hips,

456
00:20:58,044 --> 00:21:00,306
you will rotate the blend space underneath them.

457
00:21:00,306 --> 00:21:04,210
Given blend inputs in model space,

458
00:21:04,210 --> 00:21:06,452
which is the desired facing of the hips

459
00:21:06,452 --> 00:21:07,773
and the desired movement direction,

460
00:21:08,599 --> 00:21:12,820
We simply rotate the hips and thus the blend space like that

461
00:21:12,820 --> 00:21:15,821
until the move direction is out of the bad zone.

462
00:21:15,821 --> 00:21:17,802
Now unfortunately, this implies that the hips

463
00:21:17,802 --> 00:21:19,642
are no longer gonna align with the target.

464
00:21:19,642 --> 00:21:23,003
The usual reason we want hips to align with the target

465
00:21:23,003 --> 00:21:24,644
is just because the character wants to aim

466
00:21:24,644 --> 00:21:25,704
in that direction.

467
00:21:25,704 --> 00:21:28,945
So we just let the aim focus system fix the difference.

468
00:21:30,156 --> 00:21:34,460
Now one additional item to note is that you should always over-rotate or under-rotate

469
00:21:34,460 --> 00:21:36,302
the hips by the minimum amount.

470
00:21:36,302 --> 00:21:41,167
In other words, find the nearest edge of the bad zone and always rotate with that edge

471
00:21:41,167 --> 00:21:41,548
in mind.

472
00:21:41,548 --> 00:21:45,892
In this first case, since the desired movement direction was closer to the top of the bad

473
00:21:45,892 --> 00:21:47,554
zone, we rotate clockwise.

474
00:21:47,554 --> 00:21:51,798
But if the desired movement direction is closer to the bottom edge, we do the opposite.

475
00:21:54,749 --> 00:21:57,711
Some subtleties about our particular implementation.

476
00:21:57,711 --> 00:22:00,312
If the system dithers back and forth

477
00:22:00,312 --> 00:22:02,113
across a bad zone rapidly,

478
00:22:02,113 --> 00:22:04,134
it defeats the purpose of avoiding them.

479
00:22:04,134 --> 00:22:06,075
To solve this, we treat the system

480
00:22:06,075 --> 00:22:07,556
as a simple state machine,

481
00:22:07,556 --> 00:22:11,398
and simply prevent it from re-entering states too quickly.

482
00:22:11,398 --> 00:22:12,958
And then to refine the system even more.

483
00:22:13,916 --> 00:22:18,018
we use foot phase data to delay the switch across the zone

484
00:22:18,018 --> 00:22:20,120
until the ideal foot phase has been reached

485
00:22:20,120 --> 00:22:21,080
in the animation.

486
00:22:21,080 --> 00:22:23,342
Now if used correctly, this kind of approach

487
00:22:23,342 --> 00:22:25,723
can help prevent the brief foot mangling

488
00:22:25,723 --> 00:22:28,605
that would be inevitable if the bad zone was crossed

489
00:22:28,605 --> 00:22:30,306
at any arbitrary time in the animation.

490
00:22:33,528 --> 00:22:39,372
So I've covered four examples of the ways the AI can improve the viability of a full-body solution.

491
00:22:39,372 --> 00:22:47,237
And I want to conclude by going a bit higher level and providing an example of how this can influence the behavior implementation and presentation.

492
00:22:47,237 --> 00:22:52,641
As AI developers, we have two goals that we try to satisfy simultaneously.

493
00:22:52,641 --> 00:22:55,543
We want the AI to feel as alive and responsive as possible.

494
00:22:55,543 --> 00:22:58,946
But at the same time, we also want the player to enjoy their experience.

495
00:22:59,506 --> 00:23:04,548
The combat in Doom is critically acclaimed in large part because of how powerful it makes

496
00:23:04,548 --> 00:23:05,248
players feel.

497
00:23:05,248 --> 00:23:07,929
They really enjoy beating up on the enemies.

498
00:23:07,929 --> 00:23:13,412
We found that the cadence of the AI behavior is essential to this power fantasy.

499
00:23:13,412 --> 00:23:20,315
If the player understands enemy cadence, they're able to avoid attacks and exploit openings.

500
00:23:21,022 --> 00:23:23,904
Having so many of our behaviors be structured

501
00:23:23,904 --> 00:23:26,626
as sequences of discrete full body animations

502
00:23:26,626 --> 00:23:30,068
means that the player is able to more easily read

503
00:23:30,068 --> 00:23:31,789
and understand this cadence.

504
00:23:31,789 --> 00:23:33,771
Now you can really approach our enemies

505
00:23:33,771 --> 00:23:37,213
and sort of dance with them, even the strongest demons,

506
00:23:37,213 --> 00:23:40,716
because of how clearly the animations define their attacks.

507
00:23:40,716 --> 00:23:42,937
Now, behaviors like this always work best

508
00:23:42,937 --> 00:23:44,718
in wide open areas where the player stays

509
00:23:44,718 --> 00:23:45,459
in front of the enemies.

510
00:23:45,459 --> 00:23:47,180
These are ideal conditions.

511
00:23:47,180 --> 00:23:49,142
But Doom has a very dynamic player

512
00:23:49,142 --> 00:23:50,763
and all sorts of combat spaces.

513
00:23:51,997 --> 00:23:54,779
One approach we used to preserve as much of the rhythm

514
00:23:54,779 --> 00:23:57,782
of combat as we could in less than ideal conditions

515
00:23:57,782 --> 00:24:00,405
is that of driving behavior with animation sampling.

516
00:24:00,405 --> 00:24:02,847
Now conceptually, this is the practice

517
00:24:02,847 --> 00:24:05,850
of sampling animations against a target and or world

518
00:24:05,850 --> 00:24:07,352
to see which will work best.

519
00:24:07,352 --> 00:24:11,616
The desired benefit is the ability to quickly transition

520
00:24:11,616 --> 00:24:13,979
to another attack without upsetting the cadence

521
00:24:13,979 --> 00:24:15,080
for longer than necessary.

522
00:24:16,449 --> 00:24:18,912
Now as the debug output in these videos shows,

523
00:24:18,912 --> 00:24:21,175
at times we like to go one step further

524
00:24:21,175 --> 00:24:23,098
and also sample multiple instances

525
00:24:23,098 --> 00:24:25,622
of the same animation against the world,

526
00:24:25,622 --> 00:24:27,464
differing from each other,

527
00:24:27,464 --> 00:24:30,208
only in slight rotation and translation offsets.

528
00:24:31,552 --> 00:24:33,113
the AI then uses delta correction

529
00:24:33,113 --> 00:24:36,716
to ensure that the animation playback mirrors those offsets.

530
00:24:36,716 --> 00:24:40,419
In this way, even if there's only a single attack animation

531
00:24:40,419 --> 00:24:41,520
that might reach the target,

532
00:24:41,520 --> 00:24:44,123
our daemons have a number of options to choose amongst.

533
00:24:44,123 --> 00:24:47,085
And there's almost always at least one instance

534
00:24:47,085 --> 00:24:49,687
that will fit on the navigation graph

535
00:24:49,687 --> 00:24:50,748
and within world geometry.

536
00:24:50,748 --> 00:24:54,051
Driving AI decisions with sampling like this

537
00:24:54,051 --> 00:24:55,993
can really bring a behavior to life.

538
00:24:55,993 --> 00:24:57,775
It feels extremely responsive.

539
00:24:58,326 --> 00:25:04,173
But in all honesty, being alive as an enemy in a game like Doom has a lot to do with death.

540
00:25:04,173 --> 00:25:07,818
And so coming full circle, we return to damage response.

541
00:25:07,818 --> 00:25:14,466
We perceive enemies as the most alive when they react directly to our actions in the game world.

542
00:25:15,241 --> 00:25:18,864
and no player action is more deserving of a reaction

543
00:25:18,864 --> 00:25:20,625
than causing damage.

544
00:25:20,625 --> 00:25:23,107
So in an ironic twist, I think it can be argued

545
00:25:23,107 --> 00:25:25,790
that the best example of how we bring health to life

546
00:25:25,790 --> 00:25:28,652
is the way our heavy use of pain and death animations

547
00:25:28,652 --> 00:25:30,954
makes hurting and killing the enemies so satisfying.

548
00:25:34,367 --> 00:25:36,647
So giving all this control to our AI

549
00:25:36,647 --> 00:25:38,868
and building our behaviors with full body animations

550
00:25:38,868 --> 00:25:39,948
worked out very well.

551
00:25:39,948 --> 00:25:42,408
The animators really got to focus on their craft

552
00:25:42,408 --> 00:25:45,009
and the animations in the game are just fantastic.

553
00:25:45,009 --> 00:25:47,490
And the way those animations are used

554
00:25:47,490 --> 00:25:49,750
helps the enemies feel like they are really living

555
00:25:49,750 --> 00:25:50,830
in this game world.

556
00:25:50,830 --> 00:25:52,971
An added bonus is that it was really fun

557
00:25:52,971 --> 00:25:54,451
to develop these units.

558
00:25:54,451 --> 00:25:57,772
You know, being able to easily and reliably get the AI

559
00:25:57,772 --> 00:25:59,652
to deal with animation content,

560
00:25:59,652 --> 00:26:01,373
having that amount of control on our end

561
00:26:01,373 --> 00:26:03,653
made it super satisfying to author the AI.

562
00:26:05,114 --> 00:26:06,395
That concludes the presentation.

563
00:26:06,395 --> 00:26:09,637
I'd like to thank everyone again for coming here today.

564
00:26:09,637 --> 00:26:11,237
GDC wants me to remind you, do not

565
00:26:11,237 --> 00:26:13,539
forget to fill out the electronic evaluation

566
00:26:13,539 --> 00:26:14,139
for this talk.

567
00:26:14,139 --> 00:26:16,881
If you have any questions, I can answer a few right now.

568
00:26:16,881 --> 00:26:20,243
Otherwise, I will be in the wrap up rooms afterwards

569
00:26:20,243 --> 00:26:22,044
to talk about whatever you guys want to chat about.

570
00:26:22,044 --> 00:26:22,324
Thank you.

571
00:26:22,324 --> 00:26:30,548
Yes, go ahead.

572
00:26:31,432 --> 00:26:33,212
Great presentation, by the way.

573
00:26:33,212 --> 00:26:37,574
One of the questions I had is when you have a lot of AIs

574
00:26:37,574 --> 00:26:43,216
who do a lunge melee at you, and during those times,

575
00:26:43,216 --> 00:26:47,038
do you commit to the animations, or especially for reactions,

576
00:26:47,038 --> 00:26:49,799
do you have you considered, or did you

577
00:26:49,799 --> 00:26:53,441
consider having additive paints during the melee lunges

578
00:26:53,441 --> 00:26:56,482
to be able to continue to have reactions

579
00:26:56,482 --> 00:26:58,623
if the player shoots the AI?

580
00:26:58,958 --> 00:27:01,881
Yes, so, sorry, so the question is,

581
00:27:01,881 --> 00:27:03,362
do we consider having like a more

582
00:27:03,362 --> 00:27:04,724
additive pain approach so that the AI

583
00:27:04,724 --> 00:27:08,408
could continue their attacks while taking pain?

584
00:27:08,408 --> 00:27:10,510
Yes and no.

585
00:27:10,510 --> 00:27:13,853
That's kind of what the Twitch pains ended up being.

586
00:27:13,853 --> 00:27:16,516
And we did experiment with sort of

587
00:27:18,115 --> 00:27:20,857
the idea of pains being only a visual thing

588
00:27:20,857 --> 00:27:22,959
and not interrupting the AI,

589
00:27:22,959 --> 00:27:27,422
but it ended up being that the feedback that we got

590
00:27:27,422 --> 00:27:30,585
during play testing and iteration really suggested

591
00:27:30,585 --> 00:27:33,347
that people like being able to stop the AI in their tracks.

592
00:27:33,347 --> 00:27:36,049
And in fact, when we embrace that decision

593
00:27:36,049 --> 00:27:38,511
to sort of make the pain this...

594
00:27:38,731 --> 00:27:44,896
discrete thing that you can put them in it and then do whatever you want to them that changed our gameplay from being you

595
00:27:44,896 --> 00:27:50,780
know from kind of not knowing which direction we wanted to go to this is absolutely what players are going to enjoy and

596
00:27:50,780 --> 00:27:56,044
The game was made you know much much better because of it now that's not going to work in everybody's situation

597
00:27:56,044 --> 00:27:59,187
but again because the power fantasy of

598
00:27:59,187 --> 00:28:05,231
Controlling the demons with your gun is kind of what makes the game so satisfying it really worked for us in our instance

599
00:28:05,602 --> 00:28:08,526
Just a quick question on the other part where you do the IK

600
00:28:08,526 --> 00:28:12,773
correction for the upper body to be able to track the player.

601
00:28:12,773 --> 00:28:16,600
Do you give control to the animators to control how much

602
00:28:16,600 --> 00:28:18,904
rotation based on the variations

603
00:28:18,904 --> 00:28:19,805
within the animations?

604
00:28:20,434 --> 00:28:23,917
especially because in some cases the hip looks good

605
00:28:23,917 --> 00:28:26,319
and hands look good, but in some other cases

606
00:28:26,319 --> 00:28:27,720
like the hands do not look as good.

607
00:28:27,720 --> 00:28:32,144
So do you give control, very similar to the footsteps,

608
00:28:32,144 --> 00:28:35,727
do you give controls for the windows or amount of angles

609
00:28:35,727 --> 00:28:38,029
for how much you are allowed to rotate procedurally?

610
00:28:38,757 --> 00:28:44,101
Yes, so the question is, do we, what level of control do we expose for like the parameters

611
00:28:44,101 --> 00:28:49,365
that go into the IK so that the animators could say in this animation maybe constrain

612
00:28:49,365 --> 00:28:52,868
the angles a little more or switch or whatever.

613
00:28:52,868 --> 00:28:54,689
And yes, we have full level of control.

614
00:28:54,689 --> 00:28:57,071
That's what I was talking about in the slide about swapping effectors.

615
00:28:57,712 --> 00:29:02,195
Our effector comes with a data set that defines all those attributes.

616
00:29:02,195 --> 00:29:06,879
The clamp values, the rotation speeds, which bones it's parented to.

617
00:29:06,879 --> 00:29:10,962
Although we actually use like a hybrid bone solution like I said where we have an

618
00:29:10,962 --> 00:29:14,085
even an extra layer of abstraction that we can specify in the tool.

619
00:29:14,485 --> 00:29:15,767
and we can put an offset from a bone

620
00:29:15,767 --> 00:29:17,148
for where the effector is.

621
00:29:17,148 --> 00:29:19,390
And so all that kind of stuff is encapsulated

622
00:29:19,390 --> 00:29:21,413
in the data set for a single effector,

623
00:29:21,413 --> 00:29:23,094
and we just swap back and forth

624
00:29:23,094 --> 00:29:24,796
depending on which animation we're playing,

625
00:29:24,796 --> 00:29:27,158
or even multiple times in the same animation

626
00:29:27,158 --> 00:29:28,360
depending on what the needs are.

627
00:29:28,360 --> 00:29:30,021
All right, well thank you very much.

628
00:29:30,021 --> 00:29:30,662
You're welcome.

629
00:29:32,693 --> 00:29:37,376
Hi, so first of all I would like to thank you very much for providing this incredibly

630
00:29:37,376 --> 00:29:38,056
insightful talk.

631
00:29:38,056 --> 00:29:39,057
You're welcome.

632
00:29:39,057 --> 00:29:45,480
Now, given all the details that you provided about the nuances and subtleties with regards

633
00:29:45,480 --> 00:29:46,641
to effectors.

634
00:29:47,021 --> 00:29:52,903
and also the use of planes in order to dictate, you know, enemy movement.

635
00:29:52,903 --> 00:29:59,565
And taking into account the diverse cast of enemies that's kind of a hallmark of the Doom franchise,

636
00:29:59,565 --> 00:30:07,248
I'm curious as to what exactly entailed in terms of giving each monster their unique traits and personalities

637
00:30:07,248 --> 00:30:10,729
when it comes to, you know, animating all those different body parts

638
00:30:10,729 --> 00:30:14,730
and making them feel unique from a presentational standpoint.

639
00:30:14,950 --> 00:30:22,157
in addition to serving the gameplay through their manifold combat functions.

640
00:30:22,157 --> 00:30:27,122
I'm sorry, what was the actual, what question?

641
00:30:27,122 --> 00:30:33,988
Like, basically in terms of, because each enemy has their own combat routine,

642
00:30:33,988 --> 00:30:39,413
such as him throwing the fireballs, and you mentioned nuances and subtleties,

643
00:30:39,413 --> 00:30:40,153
like in terms of...

644
00:30:40,577 --> 00:30:47,202
Like, how did you essentially try to make them, you know, that much more distinguishable,

645
00:30:47,202 --> 00:30:51,865
like, from both a presentational and gameplay standpoint, given their diversity

646
00:30:51,865 --> 00:30:54,967
and also the fact that they add variety to the combat?

647
00:30:55,263 --> 00:30:57,405
All right, so the question is, basically,

648
00:30:57,405 --> 00:31:00,788
what did we do to really embrace the diversity of the enemies?

649
00:31:00,788 --> 00:31:04,691
And the simple answer is we gave a lot of that control

650
00:31:04,691 --> 00:31:05,692
to our animators.

651
00:31:05,692 --> 00:31:08,674
You know, we have previs videos where they sort of come up

652
00:31:08,674 --> 00:31:11,337
with ideas of what attacks might look like.

653
00:31:11,997 --> 00:31:15,640
they are allowed to basically make a character look

654
00:31:15,640 --> 00:31:19,183
animation-wise, however they think it should look.

655
00:31:19,183 --> 00:31:22,446
And I mean, there's feedback and iteration and meetings

656
00:31:22,446 --> 00:31:25,328
where things are rejected and things are embraced,

657
00:31:25,328 --> 00:31:27,971
but at the end of the day, it was mostly driven

658
00:31:27,971 --> 00:31:30,453
by giving a lot of control to our animators.

659
00:31:30,453 --> 00:31:32,555
And the awesome thing about giving control

660
00:31:32,555 --> 00:31:35,657
to the animators is that as an AI developer

661
00:31:35,657 --> 00:31:38,479
or as anyone else on the team,

662
00:31:38,479 --> 00:31:39,861
you can come back the next day

663
00:31:40,441 --> 00:31:43,403
and maybe you'll not even look at what an animation looks like

664
00:31:43,403 --> 00:31:46,146
before the animator plugs it in to replace a previous one,

665
00:31:46,146 --> 00:31:50,449
and you'll play the game and all of a sudden this thing will look amazing

666
00:31:50,449 --> 00:31:55,193
and have so much style and personality and it will surprise you.

667
00:31:55,193 --> 00:31:58,015
And that's the moment when it's really cool to be a game developer,

668
00:31:58,015 --> 00:32:03,219
when you're surprised by playing your own game just a day after you played it

669
00:32:03,219 --> 00:32:06,962
because some content creator has put something in that's just totally awesome.

670
00:32:07,362 --> 00:32:10,670
And so I guess the short answer is we let the animators drive

671
00:32:10,670 --> 00:32:11,191
a lot of that.

672
00:32:11,191 --> 00:32:12,033
All right.

673
00:32:12,033 --> 00:32:13,998
Well, thank you very much.

674
00:32:13,998 --> 00:32:15,621
Again, congrats on the talk.

675
00:32:15,621 --> 00:32:15,882
Thank you.

