1
00:00:04,902 --> 00:00:06,303
Thanks everyone for being here virtually.

2
00:00:06,783 --> 00:00:08,664
This is definitely a very interesting time.

3
00:00:09,565 --> 00:00:11,246
And a little bit about myself.

4
00:00:12,366 --> 00:00:16,589
My name is Norman and I'm the CEO of Glassbox.

5
00:00:17,329 --> 00:00:20,992
We're a company that specializes in making real-time production tools.

6
00:00:21,092 --> 00:00:27,256
And we have a global team with offices in Germany, Los Angeles, Australia, and in Asia.

7
00:00:28,216 --> 00:00:33,620
Today I'm going to be talking about the democratization of virtual production for indie game makers.

8
00:00:34,487 --> 00:00:38,988
which is brought about through a convergence of cinema and gaming technologies.

9
00:00:40,909 --> 00:00:47,010
And you may have seen some of this in the works of large projects such as The Lion King,

10
00:00:47,390 --> 00:00:50,711
where they made use of game engine technologies and filmmaking equipment

11
00:00:51,171 --> 00:00:55,532
to make an animated film, almost as if they were making a real film.

12
00:00:57,052 --> 00:01:00,373
And more recently, we have projects such as The Mandalorian

13
00:01:00,413 --> 00:01:03,973
that broke new ground on how to combine real-time.

14
00:01:05,002 --> 00:01:11,865
engines that are traditionally made for video games to transform how film and visual effects are made.

15
00:01:13,545 --> 00:01:18,627
But before we go into that, I kind of want to take a step back and think about the history

16
00:01:19,208 --> 00:01:27,131
of cinematic gaming. We've been with this term for a long time now and we as an industry doesn't

17
00:01:27,211 --> 00:01:32,313
really have an agreement on what cinematic gaming really is meant to be.

18
00:01:33,382 --> 00:01:38,603
And here are some examples of attempts to making games cinematic.

19
00:01:39,343 --> 00:01:43,324
And this includes certain things like using live action,

20
00:01:44,264 --> 00:01:47,885
live action cinematics, like in the case of Resident Evil and Red Alert.

21
00:01:48,305 --> 00:01:51,806
But then there's also the idea of cinematic gaming being more about

22
00:01:51,846 --> 00:01:54,867
the content and the presentation and the subject matter,

23
00:01:55,367 --> 00:01:59,148
like is the case with Detroit Become Human, as well as other games

24
00:01:59,228 --> 00:02:02,648
like The Last of Us, Red Dead Redemption, The Witcher,

25
00:02:04,210 --> 00:02:04,871
and got a war.

26
00:02:06,352 --> 00:02:07,294
But strictly speaking,

27
00:02:07,314 --> 00:02:08,515
I kind of want to think about

28
00:02:08,535 --> 00:02:11,459
what makes games cinematic

29
00:02:11,599 --> 00:02:13,241
and also the evolution of

30
00:02:13,281 --> 00:02:14,823
the technology that

31
00:02:15,423 --> 00:02:17,386
are enabling cinematic gaming.

32
00:02:18,973 --> 00:02:23,076
So, adopting a very specific look at cinematics,

33
00:02:23,276 --> 00:02:26,298
we're just talking about game cinematics here.

34
00:02:26,858 --> 00:02:31,602
So, here we have an example of Starcraft Brew War,

35
00:02:31,982 --> 00:02:35,064
which is pre-rendered, produced using the same tools

36
00:02:35,384 --> 00:02:37,866
that are available for animation studios

37
00:02:37,906 --> 00:02:38,907
and visual effects studios.

38
00:02:39,747 --> 00:02:40,288
And this was in 1998.

39
00:02:43,006 --> 00:02:47,550
And now, in 2015, for StarCraft The Legacy of the Void,

40
00:02:48,091 --> 00:02:52,295
we have Blizzard also using tools and technologies

41
00:02:52,355 --> 00:02:54,657
available to animators and visual effects studios,

42
00:02:55,057 --> 00:02:58,280
but they're able to create a much, much higher

43
00:02:58,320 --> 00:03:01,183
visual quality because of the evolution of the technology

44
00:03:01,243 --> 00:03:02,784
and the evolution of the tools,

45
00:03:03,125 --> 00:03:05,427
and also the evolution of the artists themselves.

46
00:03:06,922 --> 00:03:13,464
But here's a really interesting intersection of real-time cinematics or in-engine cinematics,

47
00:03:14,205 --> 00:03:21,307
where we're actually making use of game engine technologies to render basically game footage,

48
00:03:21,947 --> 00:03:29,750
but to a quality that approximates the pre-render cinematics of yesteryear.

49
00:03:33,662 --> 00:03:35,142
I want to talk about cinema.

50
00:03:35,782 --> 00:03:41,863
When we talk about cinematic, we have to talk about how cinematic references the idea of cinema.

51
00:03:42,544 --> 00:03:48,145
And in the area of cinema, there is the technology called virtual production.

52
00:03:49,065 --> 00:03:55,126
And it really is about making use of technology to emulate certain aspects of filmmaking.

53
00:03:55,923 --> 00:03:59,184
instead of using a physical camera to shoot a subject,

54
00:03:59,544 --> 00:04:01,525
a physical subject on a physical set,

55
00:04:01,905 --> 00:04:05,247
we're now using virtual camera to shoot virtual actors

56
00:04:05,587 --> 00:04:06,387
on a virtual set.

57
00:04:07,248 --> 00:04:10,229
And the beginning of that comes from things like

58
00:04:10,289 --> 00:04:13,070
photo real, digital humans,

59
00:04:13,550 --> 00:04:15,791
virtual cinematography and performance capture,

60
00:04:16,412 --> 00:04:18,452
such as is the case with Final Fantasy in 2001,

61
00:04:18,492 --> 00:04:19,073
Polar Express, Beowulf,

62
00:04:19,193 --> 00:04:19,453
then also.

63
00:04:26,496 --> 00:04:30,098
The film that made all of this prolific is Avatar.

64
00:04:31,939 --> 00:04:34,220
And when we're looking at Avatar,

65
00:04:34,240 --> 00:04:37,122
we're looking at an entirely new way of making films.

66
00:04:37,202 --> 00:04:39,503
And here is an example of a virtual camera.

67
00:04:40,703 --> 00:04:43,585
And this virtual camera is basically virtual reality

68
00:04:43,625 --> 00:04:44,445
without a headset.

69
00:04:44,685 --> 00:04:47,247
It'll allow the director to look into the screen

70
00:04:47,387 --> 00:04:51,689
as if they're looking onto a world that doesn't exist.

71
00:04:53,403 --> 00:04:57,185
Then there's performance capture, where through the use of technology,

72
00:04:57,245 --> 00:05:00,307
we're digitizing the performance of an actor,

73
00:05:00,427 --> 00:05:03,488
not just how they move, but also their emotion.

74
00:05:05,589 --> 00:05:08,771
And the third piece of this puzzle is real-time visualization,

75
00:05:09,211 --> 00:05:13,993
where in order for the director to see what is being shot,

76
00:05:14,373 --> 00:05:17,395
they needed a way to interactively render the images

77
00:05:17,495 --> 00:05:21,016
so that the director could see it as they're being generated.

78
00:05:22,947 --> 00:05:27,792
And the combination of these technologies is one main avatar possible.

79
00:05:32,216 --> 00:05:37,621
And this technology very much still persists today where we're using the

80
00:05:37,661 --> 00:05:39,323
combination of cinematography,

81
00:05:39,383 --> 00:05:44,148
performance capture and real time visualization to drive a new generation of

82
00:05:44,168 --> 00:05:44,908
virtual production.

83
00:05:46,313 --> 00:05:52,437
Take for example, Battle Angel Alita, where this is very much kind of the latest in how

84
00:05:52,517 --> 00:05:58,421
this technology was used, where we're using performance capture technology to digitize

85
00:05:58,461 --> 00:06:03,444
the performance of the actor, and then we're shooting it with a virtual camera and combining

86
00:06:03,484 --> 00:06:04,324
with virtual sets.

87
00:06:04,985 --> 00:06:07,246
And this is especially sophisticated because

88
00:06:08,727 --> 00:06:12,148
we're also merging real life elements into it.

89
00:06:12,508 --> 00:06:15,489
So it's not just virtual actors on virtual sets,

90
00:06:15,689 --> 00:06:18,891
it's the virtual and the real combining together

91
00:06:18,911 --> 00:06:20,571
to make a seamless whole.

92
00:06:21,572 --> 00:06:22,832
Now that we looked at cinema,

93
00:06:22,992 --> 00:06:25,993
I wanna take a step back to looking at games.

94
00:06:26,894 --> 00:06:31,535
And for a while, I think people have been toying

95
00:06:31,655 --> 00:06:34,416
with making use of gaming technology to make film.

96
00:06:35,297 --> 00:06:37,658
And this really began with machinima,

97
00:06:38,258 --> 00:06:42,480
where players are making use of gameplay footage

98
00:06:42,560 --> 00:06:47,323
or gameplay technology to record content that is not games.

99
00:06:48,203 --> 00:06:50,404
So we have some really well-known examples

100
00:06:50,484 --> 00:06:55,106
like Red vs. Blue and the series of highly popular shorts

101
00:06:55,206 --> 00:06:57,868
that made by Valve for the promotion of Team Fortress 2.

102
00:06:58,648 --> 00:06:59,849
As I touched on before,

103
00:06:59,869 --> 00:07:02,670
this technology has definitely evolved.

104
00:07:03,509 --> 00:07:05,531
in the last decade.

105
00:07:06,052 --> 00:07:08,615
In such that here we have two comparisons

106
00:07:08,675 --> 00:07:11,038
of the same scene.

107
00:07:11,459 --> 00:07:12,540
Both of these games,

108
00:07:12,961 --> 00:07:14,363
a Meadowvano Allied Assault

109
00:07:14,923 --> 00:07:16,425
and Call of Duty World War II

110
00:07:16,525 --> 00:07:19,229
are both depicting the Normandy landing.

111
00:07:20,167 --> 00:07:23,390
But on the left, we have one generation of technology,

112
00:07:23,470 --> 00:07:26,933
whereas on the right, we have an entirely different generation of technology

113
00:07:27,513 --> 00:07:29,935
capable of producing visual qualities,

114
00:07:30,516 --> 00:07:33,939
the likes of which that was just simply not attainable previously.

115
00:07:35,560 --> 00:07:36,821
So where does that leave us?

116
00:07:37,802 --> 00:07:42,766
Well, now that the technology behind real time rendering

117
00:07:42,826 --> 00:07:47,710
has led to an exponential increase in the computing power available to us.

118
00:07:49,094 --> 00:07:58,798
And we have real-time rendering that are approaching the level of pre-rendered animations from last decade.

119
00:08:00,538 --> 00:08:11,343
We're sort of looking into an area where the filmmaking tools that were somewhat originally meant for very niche productions

120
00:08:11,963 --> 00:08:16,765
beginning to be applicable for a broad range of users.

121
00:08:18,879 --> 00:08:22,702
And here are two examples of some of the tools

122
00:08:22,742 --> 00:08:24,484
that were made in Game Engine,

123
00:08:24,644 --> 00:08:27,987
dedicated to using Game Engine as a filmmaking tool,

124
00:08:28,307 --> 00:08:30,670
that maybe a lot of us haven't really come across

125
00:08:31,230 --> 00:08:32,191
or used ourselves.

126
00:08:35,714 --> 00:08:38,057
This is where it leads to kind of the next

127
00:08:38,737 --> 00:08:40,519
and the final topic I wanna talk about,

128
00:08:40,599 --> 00:08:43,221
which is the convergence of technology.

129
00:08:44,182 --> 00:08:44,403
Where

130
00:08:45,978 --> 00:08:51,322
Technology meant for virtual reality and broadcast is coming together

131
00:08:52,022 --> 00:08:55,124
to create what we now call real-time visual effects.

132
00:08:56,865 --> 00:09:01,869
And going further than that, we're now making use of game engine technologies

133
00:09:01,929 --> 00:09:06,972
to render virtual images that we directly apply to cinematic production,

134
00:09:07,033 --> 00:09:12,156
to animation production, to commercials, and more.

135
00:09:13,205 --> 00:09:21,371
and the latest advances of using virtually rendered images on LED walls to facilitate

136
00:09:21,431 --> 00:09:28,455
what is now called in-camera visual effects. And some of the most recent advances in real-time

137
00:09:28,475 --> 00:09:34,779
visual effects is in the production of animated features directly using game engine technology

138
00:09:35,460 --> 00:09:37,401
and also in advertisement.

139
00:09:38,462 --> 00:09:46,409
But perhaps the most influential is the use of real-time technology to render what's now called in-camera visual effects,

140
00:09:47,030 --> 00:09:55,357
where in combination of display technology, we are displaying the virtual world together with all the live-action components

141
00:09:55,937 --> 00:10:01,722
so that the virtual visual effects is a part of the camera plate.

142
00:10:02,663 --> 00:10:09,007
So the crew can walk away from set with near final footage, with minimal work in post-production,

143
00:10:09,768 --> 00:10:14,751
in a bid to dramatically shorten the time it takes from conception to final frame.

144
00:10:15,572 --> 00:10:18,794
And the best example of this is perhaps the Mandalorian.

145
00:10:19,627 --> 00:10:22,871
where they use a very large LED volume

146
00:10:24,373 --> 00:10:28,439
to kind of create the effect of surrounding the film crew

147
00:10:28,899 --> 00:10:31,423
inside of this virtual world that doesn't exist.

148
00:10:31,983 --> 00:10:33,666
And then when you're looking through the camera,

149
00:10:33,766 --> 00:10:36,850
it is almost as if everything is together in one place.

150
00:10:39,122 --> 00:10:42,102
But not everyone has access to Mandalorian tech.

151
00:10:42,903 --> 00:10:46,784
And ultimately, the real changes comes from the advances

152
00:10:46,844 --> 00:10:49,945
in latest technology, making the great ideas

153
00:10:50,085 --> 00:10:54,006
from a decade ago cheaper, faster, and more available.

154
00:10:54,666 --> 00:10:57,307
And that leads to the topic of democratization.

155
00:10:58,167 --> 00:11:01,388
And democratization, we're talking about affordability,

156
00:11:02,108 --> 00:11:05,329
availability, and the usability of the technology.

157
00:11:06,158 --> 00:11:12,802
Like for example, we see this general trend of highly specialized hardware becoming increasingly

158
00:11:13,182 --> 00:11:18,304
more available and highly specialized tools becoming increasingly more available.

159
00:11:19,285 --> 00:11:24,347
And generally we're kind of moving from something that would cost millions to something that

160
00:11:24,367 --> 00:11:25,408
would cost thousands.

161
00:11:26,128 --> 00:11:33,151
Take for example over here, we have a specialist real-time renderer that was bespoke to the project

162
00:11:33,592 --> 00:11:37,233
all the way through to something that was running on a consumer device.

163
00:11:39,132 --> 00:11:41,154
And likewise here, on the one hand,

164
00:11:41,254 --> 00:11:43,735
we have highly specialized camera tracking

165
00:11:43,835 --> 00:11:48,178
and camera robotics through to motion capture technology.

166
00:11:48,859 --> 00:11:53,442
And on the low end, we have consumer-centric

167
00:11:54,042 --> 00:11:57,205
augmented reality and virtual reality technology

168
00:11:57,525 --> 00:12:01,487
that approximates the capabilities of the tools

169
00:12:01,948 --> 00:12:04,409
that used to cost tens of thousands of dollars.

170
00:12:05,844 --> 00:12:08,625
And this is also true for performance capture,

171
00:12:09,125 --> 00:12:13,546
where we're talking about highly studio-specific pipelines

172
00:12:13,606 --> 00:12:16,546
on the one hand, professional tools in the middle,

173
00:12:16,967 --> 00:12:20,347
and also performance capture

174
00:12:20,707 --> 00:12:23,628
using consumer-centric devices like the ARKit

175
00:12:24,188 --> 00:12:25,008
on the lower end.

176
00:12:25,909 --> 00:12:29,289
And for example, of how this new democratized

177
00:12:29,329 --> 00:12:31,410
virtual production technology is being used

178
00:12:31,470 --> 00:12:33,610
by independent studio to create content.

179
00:12:34,465 --> 00:12:39,213
Here is Infinite Reality, who is working on the latest project, Morad.

180
00:13:09,143 --> 00:13:12,684
MoRAV is essentially a giant robot military drama

181
00:13:13,625 --> 00:13:16,865
where a global arms race for building robots

182
00:13:17,005 --> 00:13:18,266
sparks World War III.

183
00:13:18,606 --> 00:13:20,906
Even though there's a lot of these amazing giant robots,

184
00:13:21,026 --> 00:13:24,207
it's very important that the story remain about the people

185
00:13:24,327 --> 00:13:25,747
and the crews of the giant robots.

186
00:13:26,328 --> 00:13:29,628
So the seamless integration between visual effects

187
00:13:30,388 --> 00:13:35,290
and the story including the robots is very, very important.

188
00:13:36,076 --> 00:13:39,177
Since partnering up with Fonko Studios and Fawn Davis,

189
00:13:39,717 --> 00:13:42,198
we've been able to take some of his miniature creations

190
00:13:42,918 --> 00:13:45,039
and digitize those for the game engine.

191
00:13:45,679 --> 00:13:48,841
The real-time visual effects pipeline in the Unreal Engine

192
00:13:49,681 --> 00:13:51,482
has been a game changer for us.

193
00:13:51,982 --> 00:13:54,523
You know, we can build these effects and particle sims

194
00:13:55,043 --> 00:13:57,804
right out of the box, and we can see these things in real time.

195
00:13:58,964 --> 00:14:00,985
So once we have the boards all worked out,

196
00:14:01,385 --> 00:14:03,246
we're going to plan our performance capture.

197
00:14:05,185 --> 00:14:08,949
With a combination of Glassbox DragonFly camera system,

198
00:14:09,670 --> 00:14:12,853
we'll take FaceWear for our facial performance capture,

199
00:14:13,353 --> 00:14:17,477
Perception Neuron StudioSuit to do our motion capture.

200
00:14:18,469 --> 00:14:26,797
We can put out hundreds of shots in a day to experiment with what direction we want to take our storyboards and our final edits.

201
00:14:27,577 --> 00:14:33,923
This would have taken weeks before animating cameras by hand and trying to set up our shots.

202
00:14:34,584 --> 00:14:36,505
But because of these virtual production tools.

203
00:14:37,446 --> 00:14:40,190
That changes everything and we can do this in a day.

204
00:14:40,791 --> 00:14:48,561
Big benefit of using real time for me is how fast that we can put scenes together, shots together,

205
00:14:49,502 --> 00:14:52,406
you know, with our basic VFX pipeline.

206
00:14:53,247 --> 00:14:56,751
works the same, we get the animation out, the models out,

207
00:14:57,151 --> 00:15:02,797
but now we're not going into this post-processing part of the pipeline.

208
00:15:03,177 --> 00:15:07,021
It's as we're creating it, we're actually putting it into the scene,

209
00:15:07,581 --> 00:15:10,964
and we're seeing it come to life immediately.

210
00:15:12,850 --> 00:15:18,353
Special thanks to Dean and his team for allowing us to use the materials from the MORAD project.

211
00:15:19,073 --> 00:15:24,477
And if you have any further questions, sorry I can't take audience questions given the

212
00:15:24,517 --> 00:15:29,099
circumstances, but you can visit our website and send us an email if you have any further

213
00:15:29,139 --> 00:15:29,560
questions.

214
00:15:30,040 --> 00:15:31,881
Thank you and best of luck.

