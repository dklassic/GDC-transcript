1
00:00:08,137 --> 00:00:08,937
So welcome, everyone.

2
00:00:10,517 --> 00:00:15,899
This is a movie game called Avatar Frontiers of Pandora.

3
00:00:15,959 --> 00:00:24,280
So naturally, this talk is a sequel to the talk that I did in 2020, which was Finding Space for Sound Environmental Acoustics of Tom Clancy's Division 2.

4
00:00:26,101 --> 00:00:28,181
I have a couple of caveats to point out.

5
00:00:28,281 --> 00:00:30,802
One of them is I will use the term emitter a lot.

6
00:00:31,482 --> 00:00:32,062
And what that is,

7
00:00:33,003 --> 00:00:42,809
in Snowdrop Engine World is a virtual render context that has a position and an orientation that may or may not be used by the sound designers.

8
00:00:44,751 --> 00:00:51,295
And all of the videos I've made are in stereo fold down, so unfortunately you won't get the full benefit of object mixing.

9
00:00:51,415 --> 00:00:56,418
So just imagine in your minds when you're hearing the stereo how great it would be if it was in Atmos, but it isn't.

10
00:00:57,359 --> 00:00:59,340
Other spatial audio systems are available.

11
00:01:02,717 --> 00:01:03,697
My name is Robert Banton.

12
00:01:03,897 --> 00:01:05,078
My pronouns are they, them.

13
00:01:05,858 --> 00:01:09,058
And my job title is Snowdrop Audio Architect.

14
00:01:09,939 --> 00:01:10,599
What does that mean?

15
00:01:11,759 --> 00:01:12,999
I'm an audio programmer by trade.

16
00:01:14,420 --> 00:01:16,960
I steer the roadmap for the audio tech within the Snowdrop pipeline.

17
00:01:17,440 --> 00:01:21,241
And Snowdrop, of course, is an engine within Ubisoft that we use for making lots of different games.

18
00:01:22,481 --> 00:01:26,042
My background is in MPEG codecs originally, music tech, and cinema audio.

19
00:01:27,602 --> 00:01:30,143
And this year is my 10th year in the games industry.

20
00:01:32,873 --> 00:01:36,696
So to summarize, what we're going to be talking about today are two things, BubbleSpace 2.0.

21
00:01:37,257 --> 00:01:38,738
In the last talk, we talked about BubbleSpace.

22
00:01:38,878 --> 00:01:40,920
I just want to show you some things that have happened in the last five years.

23
00:01:41,501 --> 00:01:42,181
It might be interesting.

24
00:01:43,382 --> 00:01:44,643
And Slapback 4.0.

25
00:01:45,304 --> 00:01:49,868
So to be clear, what we shipped with Division 2 was Slapback 3.0.

26
00:01:50,849 --> 00:01:54,692
Two other versions before that never got shipped or saw the light of day.

27
00:01:55,193 --> 00:01:56,434
So I'm keeping track.

28
00:01:56,834 --> 00:01:58,416
In case you're wondering, I don't remember there being a 3 or a 2.

29
00:01:59,376 --> 00:01:59,677
You heard 3.

30
00:02:01,973 --> 00:02:02,895
Okay, let's get started.

31
00:02:02,955 --> 00:02:04,237
So, Bubble Space 2.0.

32
00:02:07,362 --> 00:02:07,742
What is it?

33
00:02:08,744 --> 00:02:10,387
So what we're doing is, is that we are

34
00:02:12,928 --> 00:02:16,049
devising a system for finding the free air around the player.

35
00:02:16,289 --> 00:02:21,831
So in an analogy like this with a Division player, it's finding the best fit cylinder in a 3D space.

36
00:02:22,031 --> 00:02:25,192
And that's the version we shipped in 1.0, we shipped in Division 2.

37
00:02:25,512 --> 00:02:32,995
The tightest fit cylinder is about the azimuth plane, and the height of it is from above the player's head.

38
00:02:34,456 --> 00:02:38,517
And it uses raycasts, it uses them radially and above the player's position.

39
00:02:40,148 --> 00:02:40,208
at

40
00:02:53,747 --> 00:03:00,112
That way you can do effectively 12, but you're doing it over four frames, which aids in mitigating the CPU cost.

41
00:03:01,053 --> 00:03:07,759
And then, whilst it does these measurements, by the way, these dots, the green dots are a raycast that hit nothing, and the red dot is a raycast that hit something.

42
00:03:08,359 --> 00:03:11,922
So that gives you an idea, and the outer circle is the maximum range of the raycast.

43
00:03:12,583 --> 00:03:18,387
And this is a plan view of typical American city, like Washington, D.C., for instance.

44
00:03:19,548 --> 00:03:21,670
And, of course, that means that when the player moves around the world,

45
00:03:23,698 --> 00:03:28,441
The green circle is shrinking and expanding constantly, and from that we can do some intelligent mixing.

46
00:03:30,462 --> 00:03:32,063
So here's a video.

47
00:03:32,083 --> 00:03:37,106
This is like pre-shipping, I guess it was a year before we shipped Division 2, of it working.

48
00:04:09,192 --> 00:04:09,713
death death

49
00:04:43,200 --> 00:04:44,140
So there's some examples there.

50
00:04:44,180 --> 00:04:46,221
What you were seeing there was controlling weapon tails.

51
00:04:46,261 --> 00:04:49,262
So each bullet has the initial hit and then spliced onto it.

52
00:04:49,302 --> 00:05:02,307
The tail has some reverb baked into it and it was switching sizes of tails depending on the size of the environment and also mixing in some kind of like local ping pong delays, maybe when you're in alleyway, mixing out large ambiences that were in the street, that kind of thing.

53
00:05:03,507 --> 00:05:04,668
So what did we do with Bubble Space 2.0?

54
00:05:06,980 --> 00:05:14,374
So, the thing that we did before, we still do, it's an option, is called the minima azimuth estimation, and I call that the blue ring.

55
00:05:14,434 --> 00:05:18,742
So if you look here, the red dots are a raycast hit.

56
00:05:20,230 --> 00:05:21,852
And the green one is where it's hit nothing.

57
00:05:22,192 --> 00:05:25,835
And the yellow ones is where they both hit, but it's gonna ignore one of them.

58
00:05:26,175 --> 00:05:31,620
And the reason why is, is that whenever you have three hits, it's sorting and showing the two shortest distances.

59
00:05:32,020 --> 00:05:35,163
So the furthest one at the end of that sort gets ignored.

60
00:05:35,183 --> 00:05:37,345
So it's only averaging the two shortest ones.

61
00:05:39,106 --> 00:05:41,808
And then the overall effect is this blue circle.

62
00:05:41,888 --> 00:05:44,731
So that would have been our azimuth estimate for bubble space back then.

63
00:05:46,249 --> 00:05:50,892
And it works great, except that sometimes when you're getting into cover or going up against the wall, it shrinks very, very small.

64
00:05:51,773 --> 00:05:53,334
And sometimes it shrinks very, very, very large.

65
00:05:54,054 --> 00:05:55,115
In some cases, you want that.

66
00:05:56,215 --> 00:05:57,696
In some cases, you don't.

67
00:05:58,417 --> 00:06:05,061
So I had a look into it, like, can we have a less aggressive Azimuth estimates?

68
00:06:05,181 --> 00:06:06,702
So we came up with this thing called the Maxima one.

69
00:06:08,403 --> 00:06:09,083
So what's the difference?

70
00:06:09,223 --> 00:06:11,505
The difference is the sorting order is reversed.

71
00:06:12,401 --> 00:06:16,764
So it's exactly the same calculations, but now we're looking at the two largest points and averaging them.

72
00:06:17,165 --> 00:06:20,507
So in that case, the two red ones are being used, and the green one is being ignored.

73
00:06:21,528 --> 00:06:25,891
In the yellow case, the yellow dots, one of those is being used, and the red one's being used.

74
00:06:26,432 --> 00:06:40,583
If you look there, the actual circle is larger, but it's actually more like the average between, in a situation where you're in a large rectangular space, if you look at the total distances you average between these two, it's more close to that rectangle than the other one was.

75
00:06:40,603 --> 00:06:41,564
The other one's more like,

76
00:06:42,675 --> 00:06:44,336
closer to the minimum width.

77
00:06:44,396 --> 00:06:45,637
This is more like the average width.

78
00:06:46,418 --> 00:06:56,705
So it turns out this is preferable for outdoor environments where you're coming out of a cave, you're out in the forest and it's less extreme and it means obviously that problem where you got into cover doesn't occur.

79
00:06:59,146 --> 00:06:59,867
So here's an example.

80
00:07:17,997 --> 00:07:24,319
I forgot to mention also, a lot of these videos look kind of, ugh, because I often put the graphic settings right down so I don't get GPU bound.

81
00:07:25,100 --> 00:07:26,800
So if you're wondering, why does the game look so ugly?

82
00:07:26,880 --> 00:07:27,240
That's why.

83
00:07:27,780 --> 00:07:29,801
But you should be losing your ears anyway, so who cares?

84
00:07:31,442 --> 00:07:34,323
So that's the azimuth estimation done.

85
00:07:34,363 --> 00:07:35,163
So we have two modes.

86
00:07:35,303 --> 00:07:36,704
And it's basically the same calculation.

87
00:07:36,744 --> 00:07:38,464
So depending on how you sort, oh, hi, Alyssa.

88
00:07:40,225 --> 00:07:45,487
Depending on how you sort them, you can get the two largest or the two smallest.

89
00:07:45,667 --> 00:07:46,047
And that's it.

90
00:07:48,028 --> 00:07:54,773
For the Zenith estimation, what we were doing originally was we were taking three raycasts going straight up, and we were taking the ones that agree the most.

91
00:07:54,873 --> 00:08:01,638
The reason why you need to do that is you might be standing under a satellite dish, lampposts or something.

92
00:08:01,818 --> 00:08:08,102
If you had one raycast, you might get a really weird edge case where suddenly it feels like the whole world has come down, but it's just because you're standing under a lamppost.

93
00:08:08,703 --> 00:08:11,485
So the idea of doing three is to make it a bit more democratic.

94
00:08:13,142 --> 00:08:18,125
One of the things about it is, is that minimally the two heights have to marginally agree for it to affect change.

95
00:08:18,165 --> 00:08:23,089
So once it takes a measurement, two raycasts have to agree again for it to change.

96
00:08:23,149 --> 00:08:24,370
So you don't get sudden changes.

97
00:08:24,530 --> 00:08:27,552
Basically, everything has to agree before something happens.

98
00:08:28,112 --> 00:08:29,793
So intelligent mix makes it a bit more stable.

99
00:08:30,794 --> 00:08:33,956
And the tolerance is based on the sample area above the player.

100
00:08:34,016 --> 00:08:36,878
So that actual radius distance is what gives you the tolerance.

101
00:08:36,938 --> 00:08:38,980
The wider the tolerance, sorry, the wider the radius,

102
00:08:39,868 --> 00:08:42,170
the less tolerant it is to things that it measures above it.

103
00:08:42,251 --> 00:08:51,440
So imagine in this room here, everything would agree because it's a flat ceiling, but maybe if we're in a cave or in a forest canopy, they'd be constantly changing.

104
00:08:51,540 --> 00:08:54,283
So if you make a smaller radius, they're more likely to agree.

105
00:08:54,343 --> 00:08:56,045
In a larger radius, they're less likely to agree.

106
00:08:56,165 --> 00:08:58,728
So that was how we controlled the tolerance.

107
00:09:01,525 --> 00:09:06,567
And of course, edge cases are easily dealt with, as you can see here, with this hypothetical block hovering in the air.

108
00:09:07,667 --> 00:09:08,727
So, what do we change?

109
00:09:09,107 --> 00:09:13,549
So, it kind of got interesting because the Zenith estimation now has a variable tolerance.

110
00:09:13,609 --> 00:09:15,229
This is something that Dave Ostenacker asked me about.

111
00:09:15,629 --> 00:09:23,692
He said, look, I want to be able to fly one of those flying lizards called Ikran under like a stone archway, these huge bridges.

112
00:09:24,752 --> 00:09:28,273
But I want it to kick in and out the sparkly sweeteners of the rain

113
00:09:29,358 --> 00:09:34,800
immediately if you fly under the bridge, but if you're 50 meters below, don't kick in immediately.

114
00:09:35,140 --> 00:09:40,981
And in fact, at some point, maybe, for the perspective of the rain, the bridge is kind of out of focus, so maybe don't change anything at all.

115
00:09:42,582 --> 00:09:45,683
So the sample area can get smaller or larger with height.

116
00:09:45,823 --> 00:09:46,683
That's how we deal with that.

117
00:09:47,283 --> 00:09:51,124
Therefore, the intolerance can taper off with increased height.

118
00:09:51,284 --> 00:09:52,225
So I have a diagram here.

119
00:09:52,365 --> 00:09:56,606
So imagine you start ray casting with a radius like that, and then you taper them in.

120
00:09:58,368 --> 00:10:00,248
The further you go up, the more they tend to agree.

121
00:10:00,709 --> 00:10:02,889
So eventually, you get to a situation where they will always agree.

122
00:10:03,909 --> 00:10:04,850
And that's how you deal with that.

123
00:10:04,970 --> 00:10:10,671
If you want to have a tolerance, be very, very tolerant of high distances.

124
00:10:10,871 --> 00:10:12,032
But that's not actually what he wanted.

125
00:10:12,072 --> 00:10:15,272
He wanted the opposite of that, which is fine because we can taper the other direction.

126
00:10:16,373 --> 00:10:20,014
We can go from out, wider and wider.

127
00:10:20,094 --> 00:10:25,255
In this situation, they're more likely to agree closer to the player's head and less likely to agree further away.

128
00:10:27,347 --> 00:10:40,260
And of course, therefore, you can then have the idea of the rain, not the main rain, but like the sparkly high-frequency stuff, mid-frequency stuff maybe, cut in and out just as you clip under that bridge, like when you're driving a car on the motorway when it's raining.

129
00:10:40,761 --> 00:10:43,144
But if it's really, really high up, don't really notice.

130
00:10:44,245 --> 00:10:45,186
So here's a video showing that.

131
00:11:45,831 --> 00:11:52,881
So hopefully you noticed the fact that when you were just clipping under the bridge, it kicks in quicker, and then lower down, hardly makes any difference.

132
00:11:54,223 --> 00:12:00,191
So the summary conclusion for this is, with the bubble space, is that having both minimum and maximum estimates makes it more useful.

133
00:12:01,180 --> 00:12:05,884
And the variable zenith tolerance is very cheap to do, because all you're doing is really tapering those raycasts, right?

134
00:12:06,424 --> 00:12:08,606
You're not actually adding any extra calculations.

135
00:12:09,226 --> 00:12:20,314
And it's very easy to do with a coned radius, which is much more applicable for a planetary scale type stuff, large organic landscapes and so on, and the weird things you find on Pandora.

136
00:12:21,375 --> 00:12:21,775
There we go.

137
00:12:22,016 --> 00:12:22,956
So let's get into Slapback 4.0.

138
00:12:25,828 --> 00:12:26,549
What is slapback?

139
00:12:27,189 --> 00:12:29,412
So picture of Elvis Presley.

140
00:12:30,213 --> 00:12:35,498
Slapback was originally this delay for a single short repeat echo effect.

141
00:12:36,279 --> 00:12:40,043
And it was simulating essentially the immediate echo from a hard wall near a loudspeaker.

142
00:12:40,103 --> 00:12:42,786
So when you had, we were playing in a speakeasy, you might have had this effect.

143
00:12:42,806 --> 00:12:44,528
And then when you went to the recording studio, it's gone.

144
00:12:44,588 --> 00:12:45,609
And you were used to hearing that.

145
00:12:45,669 --> 00:12:46,450
So they simulated it.

146
00:12:47,557 --> 00:12:51,040
and it was popularized in the 1950s with singers such as Elvis and so on.

147
00:12:52,281 --> 00:12:58,127
So the slapback system in Snowdrop started out doing something vaguely similar, so that's the name stuck, basically, and we're still calling it that.

148
00:13:00,089 --> 00:13:07,556
And in fact, there's other variations like mountain slapback and stuff like that, which is sometimes used in movie sound design, so we'll have some of that in a moment.

149
00:13:09,028 --> 00:13:13,851
So in the inception, the version 3.0, as I said, was the one that was development, came out with Division 2.

150
00:13:14,892 --> 00:13:21,337
It was enabled a few months into the initial launch of the game because we had some problems with memory fragmentation, with delay line cannibalization, actually.

151
00:13:22,498 --> 00:13:23,338
And this is what AIMS to do.

152
00:13:23,698 --> 00:13:25,079
I stole this from a textbook.

153
00:13:25,960 --> 00:13:26,680
I didn't make this up.

154
00:13:27,261 --> 00:13:29,222
So what you're doing is you're imagining the source position.

155
00:13:30,083 --> 00:13:34,366
And then you're essentially creating a phantom image of where the mirror image would be.

156
00:13:35,015 --> 00:13:43,999
and then you can re-render the sound at that distance and direction, add the propagation delay, flip the phase, and then effectively you have a very simple idea of an effect.

157
00:13:44,920 --> 00:13:55,885
Additionally, of course, if you know the material of that wall, you can add some filtering to the delayed version, if it's rock or concrete or wood or earth, and then it starts to sound like the material that it's bouncing from.

158
00:13:59,997 --> 00:14:04,082
In Division 2, what we were doing was we were raycasting in six directions.

159
00:14:04,702 --> 00:14:06,685
It's data-driven, but you can choose six.

160
00:14:07,486 --> 00:14:11,030
And then what it was doing is the raycast hits, which are the red ones, the green ones is where it hits nothing.

161
00:14:11,611 --> 00:14:16,517
They have a surface normal, and then from that surface normal you can calculate where the phantom image would be.

162
00:14:17,425 --> 00:14:27,990
So it wasn't, the raycast themselves are kind of like feelers, working out where the, because you don't really know where the materials or surfaces are, so you have to kind of guess and then you can extrapolate from there.

163
00:14:30,251 --> 00:14:33,693
And then what it did was it placed emitters around the player, remember the word emitter I used earlier?

164
00:14:34,615 --> 00:14:37,376
And the placement, the raycasting was using this phantom image technique.

165
00:14:38,097 --> 00:14:43,200
And what we did was, in order to avoid having to do piercing raycasts that are very expensive, we had our own physics world.

166
00:14:43,300 --> 00:14:48,222
So this image here, which was taken from the last talk, is very small, but it's because it's not that important.

167
00:14:49,043 --> 00:14:56,687
The left side is basically the render view, what the player sees, and the right-hand side is what the audio raycast would see, which is, as you can see, a much more simpler geometry.

168
00:14:58,165 --> 00:15:01,249
and cheaper because you're just doing a single hit raycast, not having to pierce.

169
00:15:01,289 --> 00:15:03,051
You only see the materials you care about.

170
00:15:03,171 --> 00:15:06,996
So what you would do is you'd mark up these materials as acoustically opaque.

171
00:15:07,797 --> 00:15:12,544
And then when they're streamed into the world, they'll get added into this physical world.

172
00:15:15,050 --> 00:15:20,813
And it would also shut down when the player was indoors because we had another system for indoors with our procedural reverb system.

173
00:15:21,734 --> 00:15:25,536
And also because the echoes are very, very, very close.

174
00:15:25,576 --> 00:15:27,577
You get sort of a flamming effect when they're very close.

175
00:15:27,597 --> 00:15:29,799
It's accurate, but it's not cinematic.

176
00:15:32,308 --> 00:15:36,812
So what we did was select audio from the player and route them to a fake device driver.

177
00:15:37,792 --> 00:15:41,756
And then what we do is we feed back from the device driver back into the mix matrix.

178
00:15:42,136 --> 00:15:46,099
So it's like a loopback system essentially.

179
00:15:46,360 --> 00:15:49,622
At that point you can add on the delay and you can spatialize, you can move the direction.

180
00:15:50,804 --> 00:15:54,429
And you can also compute the attenuations of distance and all that good stuff.

181
00:15:55,070 --> 00:16:01,238
And the transit delay was added with a bespoke DSP effect because we wanted to have a delay that you could change as it's playing.

182
00:16:03,461 --> 00:16:04,423
So here's a little demo of that.

183
00:16:41,116 --> 00:16:44,621
Imagine how great that would sound in Atmos.

184
00:16:55,230 --> 00:16:59,813
So the overview of SatBack 4.0 was we wanted to extend the system.

185
00:17:00,034 --> 00:17:06,498
So a more versatile system, we wanted to be able to tackle landscapes and natural phenomena and weird stuff that you get in the world of Pandora.

186
00:17:07,659 --> 00:17:12,703
It works in two functional layers with distinct behavioral differences, which I'll explain what they are in a moment.

187
00:17:13,614 --> 00:17:16,055
And it allows for both early and late reflection effects.

188
00:17:16,676 --> 00:17:19,958
What we were doing before was just doing early reflections first order.

189
00:17:19,978 --> 00:17:24,040
Now we're having kind of that plus some pseudo late reflection effects.

190
00:17:25,021 --> 00:17:27,482
And we also implemented material IDs for filtering.

191
00:17:29,824 --> 00:17:34,146
The delay effect always had filters in it, but they weren't doing anything.

192
00:17:34,547 --> 00:17:34,927
Now they are.

193
00:17:36,775 --> 00:17:37,616
So here's a demo.

194
00:17:37,776 --> 00:17:51,187
I'm going to show the system off, firing the gun randomly in the forest, system on, and then a more realistic thing where you're running in and out of a building, firing at stuff at random, and you'll hear the echoes between the early and late reflection balance change over time.

195
00:17:52,969 --> 00:17:53,750
That's off.

196
00:18:10,607 --> 00:18:10,971
Okay.

197
00:18:53,275 --> 00:18:55,783
Fun fact, what you saw there was an exploding barrel.

198
00:18:56,044 --> 00:18:58,231
Why was that part of the slapback system?

199
00:18:58,612 --> 00:19:00,217
The reason was it's being mixed into it.

200
00:19:01,105 --> 00:19:02,046
Does that make any sense?

201
00:19:02,326 --> 00:19:03,287
Well, think about it like this.

202
00:19:03,747 --> 00:19:07,149
The further away it is, the quieter it is, so it will pick up less in the system.

203
00:19:07,169 --> 00:19:10,752
The closer it is, the closer it is to the player position, and therefore more accurate the echoes.

204
00:19:10,812 --> 00:19:13,774
So it's kind of a cheat, but I think it works great.

205
00:19:13,794 --> 00:19:15,035
That's why I put that in there.

206
00:19:16,676 --> 00:19:18,858
So, in order to achieve this, you need several things.

207
00:19:19,238 --> 00:19:25,742
First of all, you need to have a raycast emitter manager that places reflection points on designer set rules.

208
00:19:26,643 --> 00:19:31,484
You want an audio signal router for capturing source sounds and playing them back through multiple emitter positions.

209
00:19:32,285 --> 00:19:42,107
You need some DSP, digital signal processing, in case you forgot what that means, at each emitter destination that handles flexible delay times and filter EQ.

210
00:19:43,508 --> 00:19:50,069
And for the late reflection effects, the emitter destination needs to be routed through an environmentally defined reverb generator with no pre-delay.

211
00:19:51,050 --> 00:19:52,390
I'll explain how that works in a moment.

212
00:19:54,264 --> 00:19:55,165
So let's look at reverb.

213
00:19:55,425 --> 00:19:58,246
As you might have noticed, I stole that from the Audio Kinetic website.

214
00:19:58,326 --> 00:20:00,447
But it is a good diagram of what reverb can look like.

215
00:20:00,627 --> 00:20:04,029
So the red spike is initial source excitation.

216
00:20:04,790 --> 00:20:09,892
The green ones are the early reflections, the ones you get from the immediate surfaces first, second, third order.

217
00:20:10,353 --> 00:20:17,537
And then the blue stuff is after it starts bouncing repeatedly and starts becoming this late reflection diffuse reverb effect.

218
00:20:17,657 --> 00:20:18,797
So what is early reflections?

219
00:20:18,817 --> 00:20:19,478
Let's just define it.

220
00:20:20,528 --> 00:20:20,568
in

221
00:20:40,849 --> 00:20:50,397
a room space, designing a room space like this, they talk about things like the direct field and the reverberant field and figuring out that critical distance to make sure that people are sitting in the reverberant field because then it's easier to predict what they're going to hear.

222
00:20:51,018 --> 00:20:56,162
But when you do those calculations with the formula you got from college, you might get the wrong distance.

223
00:20:56,182 --> 00:21:02,147
And the reason is, is because you're not taking into account the early reflections being like their own sources.

224
00:21:02,347 --> 00:21:04,910
So not just these speakers, but imagine if these walls were hard.

225
00:21:05,622 --> 00:21:08,925
There would also be additional sources, and that pushes back the critical distance.

226
00:21:09,666 --> 00:21:19,895
So therefore, I will say that since we're not ever in games in an ideal acoustic space, that the early reflections, especially first order ones, are really part of the direct field.

227
00:21:21,557 --> 00:21:26,461
The late reflections, nth order echoes, echo, echo, echo, echo stuff.

228
00:21:27,522 --> 00:21:29,925
They're diffuse, largely phase invariant, kind of like noise, really.

229
00:21:31,000 --> 00:21:34,464
And they have very predictable loudness attenuation over distance, so quite different behavior.

230
00:21:35,265 --> 00:21:37,307
And therefore they're part of what we call the reverberant field.

231
00:21:37,508 --> 00:21:40,471
So everything beyond the critical distance, reverberant field.

232
00:21:40,992 --> 00:21:43,775
So for instance, right now, probably Guy there is in the direct field.

233
00:21:45,095 --> 00:21:48,456
and the GDC staff are in the reverberant field for sure.

234
00:21:48,616 --> 00:21:48,776
Hey.

235
00:21:52,058 --> 00:21:53,018
So let's look at it like this.

236
00:21:53,338 --> 00:21:58,140
If you were to capture that, if you made that impulse response yourself with an omni mic, what are you getting?

237
00:21:59,501 --> 00:22:05,323
You're actually getting a bunch of different reflections coming at different angles and they're being recorded equally and then they're all summing together.

238
00:22:06,443 --> 00:22:07,664
So if you were to place that

239
00:22:08,643 --> 00:22:08,683
in

240
00:22:22,818 --> 00:22:24,798
So you're componentizing parts of that reverb.

241
00:22:24,818 --> 00:22:31,240
So rather than going with the final impulse, you're breaking it up into smaller chunks, and then when they re-sum, as you move around the world, they do change.

242
00:22:31,680 --> 00:22:44,883
And in fact, even if you make a lower quality reverb than a very expensive impulse response that you've licensed from Penguin Audio or somebody, the fact that it's moving around, it actually makes it much more satisfying, and in many ways probably is superior because it's reactive.

243
00:22:46,446 --> 00:22:50,288
So, I'm gonna define reverberation time, T60, okay?

244
00:22:50,848 --> 00:22:56,030
Defined as the time it takes the reverberant sound pressure level from the impulse to fall by 60 decibels.

245
00:22:58,071 --> 00:23:02,473
Interestingly enough, a tile bathroom can have the same T60 as a Gothic church.

246
00:23:03,734 --> 00:23:06,675
They're quite different in size, so what's happening there?

247
00:23:07,556 --> 00:23:10,877
Clearly the church is a much larger space, so why is the T60 the same?

248
00:23:10,957 --> 00:23:14,579
Well, distance reflections, how much energy is being dissipated.

249
00:23:16,317 --> 00:23:21,979
So, how your brain estimates the scale of reverberant space is from processing the times of the early reflections.

250
00:23:22,360 --> 00:23:23,940
You learn this as a baby growing up.

251
00:23:24,360 --> 00:23:26,821
You start to recognize the early reflections are super important.

252
00:23:26,861 --> 00:23:34,104
That's how you know you're in a bathroom, if you're blindfolded, compared to being in a gothic church or in a train station concourse, for example.

253
00:23:36,385 --> 00:23:39,326
Therefore, the delayed times in the direct field are critical to immersion.

254
00:23:39,706 --> 00:23:40,306
That's my point.

255
00:23:40,507 --> 00:23:41,427
That's why it's worth mentioning.

256
00:23:42,299 --> 00:23:50,283
So the light reflections are essential for colored noise that indicate what the surfaces are made from and that kind of thing, so they know the difference between marble and wood and that kind of thing.

257
00:23:51,544 --> 00:23:56,266
So stone or concrete versus wood or carpet, as I said here, they're clearly very different materials.

258
00:23:58,467 --> 00:23:59,788
So the raycast and emitter management.

259
00:23:59,928 --> 00:24:02,149
We have two raycast functionalized working independently.

260
00:24:02,909 --> 00:24:04,670
The raycasts have a minimum distance radius.

261
00:24:05,571 --> 00:24:07,812
So rather than going straight from the, oops, sorry.

262
00:24:08,368 --> 00:24:13,192
rather than going straight from the center of the player position, they can be a little bit further out.

263
00:24:13,232 --> 00:24:15,734
This is needed for a thing that I call the ring of local origins.

264
00:24:16,695 --> 00:24:18,256
I will have a diagram for this in a moment.

265
00:24:19,757 --> 00:24:25,342
Reflection points are rendered via emitters, of course, and the layers have different emitter cannibalization behavior.

266
00:24:25,502 --> 00:24:37,092
So what you're doing is you're budgeting your emitters for these two layers and how they cannibalize and decide to go to a new reflection point changes because for what you want for early reflections and what you want for late reflections can be quite different.

267
00:24:38,554 --> 00:24:42,457
So the early reflections layer was optimized around some response enough to oncoming geometry.

268
00:24:42,477 --> 00:24:45,720
So what's happening is, because you're moving around, they're moving quickly, quickly, quickly.

269
00:24:46,081 --> 00:24:48,823
And whatever they were playing a moment ago, they keep playing in the new position.

270
00:24:50,350 --> 00:24:52,872
The late reflection stuff is optimized around long tail fidelity.

271
00:24:52,912 --> 00:24:59,638
So what will happen instead is, a new point will start forming, the other one will start fading out, because it still has reverb in it, so you don't want it to cut out immediately.

272
00:25:00,198 --> 00:25:02,620
And if you moved it to the new position, it might sound weird.

273
00:25:03,080 --> 00:25:04,121
So that's how we get around that.

274
00:25:04,161 --> 00:25:07,084
You can actually change the fade out times.

275
00:25:08,144 --> 00:25:11,387
And this is how you tackle the direct field versus the reverberant field stuff, okay?

276
00:25:12,788 --> 00:25:18,513
So, I'm gonna use a division character again, because there was no clip art available for Avatar.

277
00:25:19,668 --> 00:25:24,310
It's player-centric, so it only happens to the actual player and not to any of the other characters yet.

278
00:25:25,491 --> 00:25:28,152
Mathematically, it still only performs first-order reflections.

279
00:25:28,472 --> 00:25:31,434
So that thing I showed you before, hitting off the walls, it still does that.

280
00:25:32,174 --> 00:25:42,579
So for the azimuth raycast, if you imagine you raycast out radially, what it's doing is it's hitting like an imaginary surface, and then you can work out where the phantom image is, and if it duplicates, then you know, well, they're duplicates.

281
00:25:42,599 --> 00:25:47,221
So in this case, from three hits, we go, okay, well, two of them are the same as the other, so don't just kill them off.

282
00:25:48,001 --> 00:25:48,802
And then if you end up with one,

283
00:25:50,699 --> 00:26:03,063
And also we can do things like we can have an azimuth height offset which we can then correct for When we resolve the position there might be handy for not accidentally hitting things that are Just outside of your minimum distance, but they're still too close.

284
00:26:03,263 --> 00:26:07,525
Maybe a wall cover you know Video games, right?

285
00:26:09,418 --> 00:26:11,179
And then upwards or downwards.

286
00:26:11,219 --> 00:26:16,283
So depending on the layer, for the early reflections, we raycast upwards because we want to hear ceiling stuff.

287
00:26:16,623 --> 00:26:20,065
And when we're in the air flying, we want to hear the late reflections from the ground.

288
00:26:20,125 --> 00:26:24,648
So we raycast down for the late reflection layer.

289
00:26:26,529 --> 00:26:29,951
So here's some maths, but visualize graphically.

290
00:26:30,051 --> 00:26:30,532
Don't panic.

291
00:26:31,312 --> 00:26:34,735
Reflection points are derived from the raycast hit positions and the surface normals.

292
00:26:35,670 --> 00:26:39,391
So reflected images can be positioned either by the full 3D phantom image.

293
00:26:40,552 --> 00:26:47,834
So you start off with the white circle, you ray cast down, you get your ray cast hit, it's red, and from there you have a position and a normal.

294
00:26:48,154 --> 00:26:54,776
And what you do is the reflected distance scale is two times the dot product of the direction vector from P to Q, that ray cast, okay?

295
00:26:55,476 --> 00:27:01,078
Then the reflection vector, I've got to move my mouse somewhere, where's my mouse pointer gone?

296
00:27:03,635 --> 00:27:10,577
reflection vector is then the surface normal multiplied by the reflected distance scale, and then you can then shift across.

297
00:27:10,637 --> 00:27:14,978
So from the extruded position, if you subtract that from the original source position, you get the blue dot.

298
00:27:14,998 --> 00:27:17,018
That's your phantom image position.

299
00:27:17,959 --> 00:27:18,919
You can do it fully 3D.

300
00:27:19,279 --> 00:27:22,120
You can lock it in the horizontal plane if you want to do that.

301
00:27:24,400 --> 00:27:27,341
is the same in terms of like looking overhead.

302
00:27:28,441 --> 00:27:33,643
And interestingly enough, there was another mode that Alex asked for, which is like, what if we don't bother with that at all and we just double the distance?

303
00:27:34,483 --> 00:27:36,483
So we call this distance only, that's another mode you can do.

304
00:27:37,143 --> 00:27:51,547
Interestingly enough, it's less correct, but it's more stable usually, actually, because you think about it, if you're running on the side of a mountain wall, those reflections are gonna be constantly shifting around, where if you want something stable that's always at the right kind of distance, maybe that's better to just do distance only.

305
00:27:51,787 --> 00:27:52,427
Super cheap, right?

306
00:27:54,528 --> 00:27:55,389
So here we go.

307
00:27:55,509 --> 00:27:57,210
This is what the ring of local origins is about.

308
00:27:57,250 --> 00:27:58,491
This is how we got our minimum distance.

309
00:27:58,531 --> 00:27:59,552
So we have the player position.

310
00:28:00,272 --> 00:28:02,214
We have a radius around it, which is the minimum distance.

311
00:28:02,694 --> 00:28:06,397
We ray cast from a local origin around that radius.

312
00:28:07,397 --> 00:28:11,841
When we get our hit, we then calculate the rest of the stuff you just saw as if it came from the center.

313
00:28:14,122 --> 00:28:18,025
Record the hits, and then we compute the reflection points accordingly.

314
00:28:19,482 --> 00:28:28,144
And so you get the same calculation, but in this example, you would have completely missed that little wall on the right there, which is what you want for something that is further out.

315
00:28:28,884 --> 00:28:35,226
So without having to do any kind of additional calculations, by literally just moving the origin away, you're getting later reflection points.

316
00:28:36,726 --> 00:28:39,327
And of course, if you do the distance only, you get that effect.

317
00:28:41,127 --> 00:28:43,488
So let's focus on the early reflection layer.

318
00:28:44,068 --> 00:28:47,509
As old reflection points invalidate, emitters move immediately to the new position.

319
00:28:49,518 --> 00:28:52,680
Reflection DSP affects play uninterrupted.

320
00:28:52,760 --> 00:28:57,863
So if you happen to be firing a gun at that time, whatever gunshot's still playing out, just move to the new position.

321
00:28:58,863 --> 00:29:02,906
Delay time and filter settings are updated to the reflection point on the fly.

322
00:29:03,046 --> 00:29:10,349
This is why it's important to have a delay time that can move as you're rendering, and filters that can move stably whilst you're rendering, so you don't hear any weird pops or glitches.

323
00:29:12,070 --> 00:29:13,731
Okay, let's take it through step by step.

324
00:29:13,851 --> 00:29:16,273
So imagine we are in some kind of gully.

325
00:29:16,293 --> 00:29:16,993
This is a plan view.

326
00:29:17,193 --> 00:29:18,554
The player position is the black dot.

327
00:29:20,201 --> 00:29:28,485
It'll raycast out to, say, the right there, find those two hits, realize it's the same position, so it'll cannibalize one of them, and then you end up with that blue dot.

328
00:29:28,705 --> 00:29:30,485
That is our ER position, okay?

329
00:29:30,966 --> 00:29:34,047
If the player moves forward, oh, sorry, I did the wrong thing.

330
00:29:35,508 --> 00:29:42,310
Player moves forward, what it'll do is, is it'll make a new position, but it realizes it's close enough to the old one to just shift the point.

331
00:29:42,711 --> 00:29:45,172
So it just keeps playing, moves immediately, like that.

332
00:29:46,867 --> 00:29:52,728
Keep moving again, it's going to find a new position, which is not strictly correct, because as you can see the wall isn't there anymore.

333
00:29:53,188 --> 00:29:54,549
You could actually sanity check that.

334
00:29:54,589 --> 00:29:58,249
If you re-raycast that position and realize you're not getting the same information, you could kill it completely.

335
00:29:58,450 --> 00:30:00,790
But, video games.

336
00:30:03,391 --> 00:30:10,172
And then, when you go up to here, you get another position over there, but it's so far away from the last one that it decides it's going to kill off

337
00:30:11,447 --> 00:30:16,009
The older one now, rather than moving it, it's going to fade that out and start a new one over there.

338
00:30:16,549 --> 00:30:18,009
And that's how we deal with early reflections.

339
00:30:19,670 --> 00:30:20,510
Late reverberation.

340
00:30:21,751 --> 00:30:23,391
So here we're going to do something a bit different.

341
00:30:25,732 --> 00:30:31,554
As old reflection points invalidate, they fade out, and new reflection points can begin in new positions.

342
00:30:31,714 --> 00:30:33,335
There's always a kind of a fade happening.

343
00:30:34,958 --> 00:30:36,981
It allows for long reverb tails to play out.

344
00:30:37,041 --> 00:30:41,426
So if you've already committed to a rather than cutting that off, that would sound disturbing, right?

345
00:30:41,746 --> 00:30:43,228
Let it play out and then fade.

346
00:30:44,822 --> 00:30:51,745
So it uses the ring of local origins quite extensively, because you really want to have that minimum raycast radius quite a far bit out.

347
00:30:52,565 --> 00:30:55,826
To prevent hitting valid materials too soon, that's really what it's for.

348
00:30:56,827 --> 00:30:58,848
It's much more efficient than using a piercing raycast.

349
00:30:58,948 --> 00:31:09,412
So what you could have done is decide to do a piercing raycast, and then the number of hits you got back, just keep shimmying down that array until you found one that was a favorable distance.

350
00:31:09,932 --> 00:31:10,733
But super expensive.

351
00:31:10,793 --> 00:31:12,413
This, it's just one raycast and you're done.

352
00:31:14,814 --> 00:31:17,436
And then you add reverb to the delay line.

353
00:31:17,656 --> 00:31:22,719
So the reverb engine is working normally, but it's getting a super delayed copy.

354
00:31:24,400 --> 00:31:29,843
And therefore, when you hear it back, you're getting it spatialized at that distance with the reverb that's defined by the environment.

355
00:31:30,884 --> 00:31:36,187
And therefore, the shift, you see here, the yellow line is varying with the delay time.

356
00:31:36,347 --> 00:31:37,128
That's what you're shifting.

357
00:31:37,188 --> 00:31:39,449
So it's the pre-delay on that reverb is what's affecting.

358
00:31:39,589 --> 00:31:41,891
And it's happening in all these different positions around your player's head.

359
00:31:43,614 --> 00:31:47,595
Let us look at the same gully situation, but with this wider ring of local origins.

360
00:31:47,675 --> 00:31:48,235
Let us start here.

361
00:31:48,935 --> 00:31:56,616
The player stood there, and you have bottom left, top right, bottom right, three raycasts, and therefore we have these phantom image positions.

362
00:31:57,557 --> 00:32:02,617
We move forwards, they invalidate, and they start to fade out because they are invalid, and new ones are found.

363
00:32:02,657 --> 00:32:08,959
Momentarily, you actually have more emitters playing than you have actually budgeted for.

364
00:32:09,179 --> 00:32:11,139
That is what you have to double your budget for this.

365
00:32:12,286 --> 00:32:18,793
and then you move again, and then the other ones that were just started fade out again, and the new ones start further on.

366
00:32:20,354 --> 00:32:20,775
And that's it.

367
00:32:21,696 --> 00:32:30,345
So in terms of like filtering, I did some research and got some real acoustic data back about what happens in different environments.

368
00:32:30,425 --> 00:32:31,526
I have a chart here from

369
00:32:33,207 --> 00:32:39,288
somewhere in the Pacific Northwest, and it's different plants that someone's found the acoustic absorption spectrum for.

370
00:32:39,808 --> 00:32:42,349
And I use this information for the cloud forest.

371
00:32:43,409 --> 00:32:46,469
Don't panic, baby tears is a plant, not actual baby tears.

372
00:32:47,109 --> 00:32:49,970
Let me clarify that, because when I showed this to somebody, they panicked.

373
00:32:49,990 --> 00:32:56,051
They went, no, it's... So what you do then is, is that this is the absorption spectrum.

374
00:32:56,111 --> 00:32:58,171
So to make the EQ, you just basically flip that.

375
00:32:58,271 --> 00:32:59,011
It is power-based.

376
00:32:59,571 --> 00:33:02,752
And then once you add the logarithms, you get a kind of decibel shape.

377
00:33:04,152 --> 00:33:07,393
So that's all the EQ settings I based upon, based on that.

378
00:33:08,253 --> 00:33:09,353
And I don't think they ever change.

379
00:33:09,373 --> 00:33:11,914
I think Alex was happy with them, so cool.

380
00:33:14,274 --> 00:33:23,677
So every value reflection point has a material ID, and we take the material ID, whatever that material is, and then we have a list of known EQ settings, and we apply it.

381
00:33:25,537 --> 00:33:29,038
Materials are mapped to filter parameters, so we use the raw filter parameters.

382
00:33:30,781 --> 00:33:37,824
And then we send those in to Wwise through real-time parameter controls, and that's what the reflection effect is getting for every single emitter.

383
00:33:39,044 --> 00:33:40,805
And of course it can be different for every emitter, right?

384
00:33:43,486 --> 00:33:47,067
So this is a little bit of a window screenshot from Snowdrop.

385
00:33:47,747 --> 00:33:55,552
So it's kind of small, but basically there's a couple of materials there, and basically you can decide to have, there's two types of filter in the delay.

386
00:33:56,192 --> 00:33:59,414
You can have one of them on, both of them on, whatever.

387
00:34:00,575 --> 00:34:05,658
If one of them's off, it just disables and it's not part of that, it doesn't take part in the processing.

388
00:34:06,279 --> 00:34:15,945
So you have this idea of center frequency and gain and some kind of balance, and this is because the filters have different profiles.

389
00:34:16,025 --> 00:34:17,066
One of them is a peaking filter,

390
00:34:17,746 --> 00:34:21,088
So therefore, we can change the cutoff frequency and the gain.

391
00:34:22,669 --> 00:34:26,411
I set the Q factor to four, just so I don't have the Q factor changing constantly.

392
00:34:28,091 --> 00:34:31,073
The other one is a high-low shelf kind of filter.

393
00:34:31,093 --> 00:34:33,034
We can move the center frequency like that.

394
00:34:35,335 --> 00:34:37,196
So you create a list of materials that you want to target.

395
00:34:37,336 --> 00:34:39,977
And if the material is not on that list, it just ignores it, filter turns off.

396
00:34:40,017 --> 00:34:41,999
So therefore, it's just completely flat frequency response.

397
00:34:42,499 --> 00:34:45,120
For each material, it links material ID used in the game.

398
00:34:45,580 --> 00:34:46,841
So it's for game-specific now, right?

399
00:34:47,987 --> 00:34:56,815
enable each parametric band crossover filter as required and these values are posted to the slapback emitter as it moves or is reactivated.

400
00:34:58,976 --> 00:35:02,459
Any unlisted materials disable the filters when they are encountered.

401
00:35:04,441 --> 00:35:06,703
So and one other thing I want to bring up.

402
00:35:07,463 --> 00:35:08,424
We're sending the

403
00:35:09,544 --> 00:35:12,406
propagation distance, but the sound designers choose the delay.

404
00:35:12,686 --> 00:35:15,508
So here is an example of one of the curves they used.

405
00:35:15,968 --> 00:35:19,670
If you think about it, 450 meters should be about two seconds, and it's not.

406
00:35:19,690 --> 00:35:20,611
It's about one second.

407
00:35:21,351 --> 00:35:23,032
That's because it sounds cool that way.

408
00:35:24,153 --> 00:35:24,693
Entertainment.

409
00:35:27,875 --> 00:35:35,840
The signal rerouting stuff, the guts of that is essentially that we have this broadcaster system, very similar to the one in the Red Engine, funnily enough.

410
00:35:37,486 --> 00:35:43,091
where you're taking each time that the Wwise engine is doing its render pass, you get a callback.

411
00:35:43,531 --> 00:35:45,413
There's two buffers and they're switching constantly.

412
00:35:45,633 --> 00:35:50,117
So you imagine after the second callback, the next one will look like the top image.

413
00:35:50,157 --> 00:35:55,201
You either have one buffer recording and the other one playing, but they never meet.

414
00:35:58,223 --> 00:35:59,845
We can actually have up to eight of these.

415
00:36:00,245 --> 00:36:03,468
So there are broadcast channels and inside of those, they have up to eight audio channels.

416
00:36:05,362 --> 00:36:06,743
So think of it like a digital tape loop.

417
00:36:07,383 --> 00:36:09,905
If you ever use one of those, you have a record head and a playback head.

418
00:36:10,585 --> 00:36:16,108
And the loop gets moved on from a callback, we register within a rendering chain, so we know when it's happened.

419
00:36:17,229 --> 00:36:18,150
It does add latency though.

420
00:36:18,370 --> 00:36:20,951
So by doing this, you're adding an extra buffer of latency.

421
00:36:21,031 --> 00:36:30,917
So if you're rendering 1,024 samples, by rerouting it this way, you're adding 1,024 samples, which is 21.33 milliseconds at 48 kilohertz sample rate.

422
00:36:31,177 --> 00:36:33,058
However, we're gonna delay even more, so it's fine.

423
00:36:35,217 --> 00:36:40,981
So the recording side, we have basically the sender sync plugin in Wwise, which is a fake audio device.

424
00:36:41,561 --> 00:36:43,302
Wwise doesn't know that it's not an audio device.

425
00:36:43,322 --> 00:36:45,904
It's actually writing to a common memory.

426
00:36:47,145 --> 00:36:49,387
And it sends the audio always to the record head.

427
00:36:49,667 --> 00:36:50,447
It doesn't know which one.

428
00:36:50,548 --> 00:36:54,550
Every time it writes, it gets whichever one the broadcaster tells it to, remember, because they're switching.

429
00:36:56,292 --> 00:36:58,093
And it controls what the broadcast channel it's using.

430
00:36:59,292 --> 00:37:00,813
and how many audio channels is allocated.

431
00:37:00,913 --> 00:37:06,075
So you might, if you're deciding to make a game like X-Defiant where it's only stereo, then maybe reduce the allocation to two channels.

432
00:37:08,136 --> 00:37:11,158
Called once at the end of each render pass, as I said.

433
00:37:11,218 --> 00:37:13,319
So every time it renders, call back, switch.

434
00:37:15,060 --> 00:37:23,284
From the playback side, we have a receiver source plugin, and that just takes whatever's recorded in the last pass, right?

435
00:37:23,324 --> 00:37:25,045
Because that will be now in the playback buffer.

436
00:37:25,827 --> 00:37:27,628
And that's triggered by a play event.

437
00:37:27,648 --> 00:37:30,089
So the emitter needs to know there's a play action.

438
00:37:30,229 --> 00:37:31,670
And then it will start reading from that buffer.

439
00:37:33,711 --> 00:37:34,912
It's faded out by the stop event.

440
00:37:35,092 --> 00:37:38,434
So we always have a stop event, say, to fade it out, as I said before.

441
00:37:38,774 --> 00:37:42,756
But depending on whether it's early or late reflection, that fade out might be very short or quite long.

442
00:37:44,417 --> 00:37:46,438
And it controls what the broadcast channel it reads from.

443
00:37:47,298 --> 00:37:49,019
So you can actually have a one-to-many relationship.

444
00:37:49,220 --> 00:37:53,442
So if you record once to one channel, you can read many, many times from that same broadcast channel.

445
00:37:57,325 --> 00:38:05,291
It gets its actual audio channel layout, specifically whether it's 7.1 or 5.1 or whatever it is, it gets that from the sender sync plugin.

446
00:38:05,471 --> 00:38:11,516
So that's defined by the actual fake audio device, which it actually gets from the properties set up by the playback engine.

447
00:38:13,077 --> 00:38:15,219
And it is called once at the beginning of each render pass.

448
00:38:17,320 --> 00:38:18,141
The filtering part

449
00:38:19,338 --> 00:38:22,119
Each reflection point receives a receiver instance, okay?

450
00:38:22,619 --> 00:38:23,499
Then we add the delay.

451
00:38:23,859 --> 00:38:33,722
So Wwise is playing a source plugin with a single parameter, the broadcast channel, and then the audio signal from the source plugin needs delaying and filtering, right?

452
00:38:33,762 --> 00:38:35,182
We need to get that propagation delay in there.

453
00:38:35,222 --> 00:38:36,723
We need to filter according to materials.

454
00:38:37,943 --> 00:38:39,764
So how it works is it's kind of like this.

455
00:38:39,804 --> 00:38:44,465
You have a circular buffer, and the record pointer is spinning around constantly.

456
00:38:44,705 --> 00:38:47,526
Imagine it's going to the right, and when it gets to the end, it goes back to the start again.

457
00:38:48,957 --> 00:38:54,818
The output side is going to be behind it, and the difference between those two positions is the actual delay that you hear.

458
00:38:56,079 --> 00:39:00,980
Now if you shift that audio position suddenly, it'll hear a click or a pop or it'll not sound good.

459
00:39:01,360 --> 00:39:07,441
So what we do is we actually create a nice power complemented crossfade between the old delay and the new delay.

460
00:39:08,001 --> 00:39:12,282
This is not actually the high fidelity delay with Doppler you would expect.

461
00:39:12,322 --> 00:39:14,463
What's actually happening is it's just editing.

462
00:39:15,580 --> 00:39:18,142
And that way, you can get around unnecessary Doppler.

463
00:39:18,162 --> 00:39:19,483
It depends how fast you're running, I guess.

464
00:39:20,283 --> 00:39:23,606
But if you're in a car, you would definitely hear that in a racing game, right?

465
00:39:24,226 --> 00:39:24,686
But this is it.

466
00:39:24,747 --> 00:39:30,691
We're now jumping to the new part of the delay buffer and doing it whilst removing any kind of weird artifacts.

467
00:39:31,091 --> 00:39:33,753
And then we do phase control, which is just basically flipping the phase.

468
00:39:33,953 --> 00:39:35,114
And then we do the filter EQ.

469
00:39:35,854 --> 00:39:36,775
And that's the output sample.

470
00:39:38,369 --> 00:39:42,756
So, do I need to, yeah, basically I've just said all this stuff, haven't I?

471
00:39:43,557 --> 00:39:43,938
There we go.

472
00:39:44,539 --> 00:39:45,661
So, let's have...

473
00:39:47,350 --> 00:39:49,671
Some kind of like technical points in case it comes up.

474
00:39:50,072 --> 00:39:55,635
You need specialized memory management to do this because you're constantly needing these delay lines and they're half a meg in size, right?

475
00:39:55,755 --> 00:39:56,435
Why half a meg?

476
00:39:56,475 --> 00:40:03,399
Well, four bytes per sample is 131, 72 samples or 2.73 seconds at 48 kilohertz sample rate.

477
00:40:04,000 --> 00:40:05,560
Why does it need to be up to two seconds?

478
00:40:05,700 --> 00:40:07,742
Because that's the size of the world you're dealing with.

479
00:40:07,762 --> 00:40:09,483
Those are the kind of delays you might have to deal with.

480
00:40:11,124 --> 00:40:12,484
Speed of sound and air is typically 340 meters per second.

481
00:40:13,820 --> 00:40:15,400
In Pandora, they never told us.

482
00:40:15,480 --> 00:40:18,081
We never have found out what the speed of sound in that atmosphere is.

483
00:40:18,161 --> 00:40:20,282
But let's say it's like air.

484
00:40:21,702 --> 00:40:25,403
Therefore, the maximum transit distance could be 928 meters.

485
00:40:28,104 --> 00:40:31,785
You need to have multi-threaded access because this is being rendered in multiple threads.

486
00:40:33,346 --> 00:40:35,266
And you want to be able to prevent memory fragmentation.

487
00:40:35,886 --> 00:40:37,767
So therefore, we need specialized memory management, right?

488
00:40:39,223 --> 00:40:41,707
So the first filter looks like this.

489
00:40:41,887 --> 00:40:43,850
If you're a DSP programmer, you should recognize this.

490
00:40:43,930 --> 00:40:46,473
This is called the biquadratic filter direct form two.

491
00:40:47,815 --> 00:40:51,981
And what happens is you change five multiplies, and you can get lots of different filter effects.

492
00:40:52,822 --> 00:40:55,286
In this case, we're just using a purple formula for those coefficients.

493
00:40:57,044 --> 00:41:01,368
We're not doing any kind of musical modulation type stuff, so this is actually not a very stable filter.

494
00:41:01,989 --> 00:41:05,312
Don't use this if you're trying to do something, you know, DJing.

495
00:41:05,852 --> 00:41:06,032
Don't.

496
00:41:06,933 --> 00:41:09,715
But, as I said, the Q factor is fixed to four.

497
00:41:10,116 --> 00:41:12,918
That makes it simpler to do the calculations, the coefficients, actually.

498
00:41:13,399 --> 00:41:20,825
And then you can then do things like you can attenuate, or you can boost, or you can move the frequency left to right, and this is the kind of the overall range that that filter works at, okay?

499
00:41:21,526 --> 00:41:22,367
That's our Bode plot.

500
00:41:23,930 --> 00:41:26,831
For the other filter, this is a little bit more unexpected for some of you, I guess.

501
00:41:27,571 --> 00:41:29,472
The crossover filter part looks like this.

502
00:41:29,912 --> 00:41:37,475
So if you look at the inner core of that, that is a low-pass filter modeled on a capacitor-resistor time constant that discharges exponentially.

503
00:41:38,996 --> 00:41:46,859
And the K value, that multiplier, is one minus e to the minus omega t. That big T is actually the sample rate inverted.

504
00:41:46,899 --> 00:41:47,979
It's a time of one sample.

505
00:41:50,193 --> 00:41:59,299
The e to the minus omega t, if you calculate it exactly like that, it's kind of expensive, so you don't do that, you do a polynomial fit, because that's obviously a very good candidate for a SIMD optimization then.

506
00:42:00,280 --> 00:42:09,526
Anyway, the outer line is the same input that's subtracted from this output, and then you get like a high pass characteristic, kind of.

507
00:42:09,886 --> 00:42:16,791
And then at the end here, we have a voltage divider, and if it's exactly in the middle, they will perfectly cancel each other out and be completely phase linear.

508
00:42:17,211 --> 00:42:17,872
If you don't believe me,

509
00:42:19,671 --> 00:42:20,091
There you go.

510
00:42:20,812 --> 00:42:26,217
So the inner core part, as I said, that time constant low-pass filter is the blue line.

511
00:42:26,818 --> 00:42:31,742
And then when you subtract that from the input, you get the orange line with a bit of a bump, but don't worry about that.

512
00:42:32,243 --> 00:42:34,905
And then when you sum them together, completely phase linear.

513
00:42:35,406 --> 00:42:36,647
So you can have this on and not hear it.

514
00:42:37,548 --> 00:42:41,091
But of course, you can then change the offset between the two.

515
00:42:41,211 --> 00:42:42,512
And so you can get things like this.

516
00:42:42,873 --> 00:42:43,653
So you can boost it.

517
00:42:45,555 --> 00:42:46,316
You can boost the other way.

518
00:42:46,996 --> 00:42:51,299
So therefore, you get your high-low shelving in a nice, efficient way that sounds very natural.

519
00:42:52,599 --> 00:42:53,900
Are you all ready for a white noise test?

520
00:42:55,901 --> 00:42:56,461
All right, here we go.

521
00:42:56,481 --> 00:42:58,322
Here are the filters in action, just with some white noise.

522
00:42:58,342 --> 00:42:59,263
You can hear them working.

523
00:43:34,168 --> 00:43:34,528
Here we go.

524
00:43:34,888 --> 00:43:35,408
How are your ears?

525
00:43:36,889 --> 00:43:39,349
Hopefully that tells you how the filters are working, right?

526
00:43:39,369 --> 00:43:43,210
So this is when we're taking the echoed sound and we're filtering it, that's how it's being applied.

527
00:43:44,111 --> 00:43:47,052
So the combined results, I put this all into one picture.

528
00:43:47,152 --> 00:43:48,152
Let's go back to that gully.

529
00:43:49,570 --> 00:43:53,571
So what we're actually getting, if we're in that position, we're getting two early reflections.

530
00:43:53,771 --> 00:43:55,572
One of them is quieter than the other, because it's further away.

531
00:43:55,852 --> 00:43:58,192
And we're getting four late reflections with the reverb applied.

532
00:43:58,412 --> 00:44:00,413
It's defined by the environment with different filtering.

533
00:44:00,873 --> 00:44:04,134
And because of their angles, they're spatialized at different angles around the head.

534
00:44:04,714 --> 00:44:06,815
And different distances mean they have different pre-delays.

535
00:44:07,095 --> 00:44:07,535
There we go.

536
00:44:07,695 --> 00:44:08,675
Does that picture make sense?

537
00:44:09,615 --> 00:44:14,537
This is the decomponentized version of that nice impulse response you saw at the start.

538
00:44:18,038 --> 00:44:18,338
And then,

539
00:44:20,381 --> 00:44:22,883
I want to show an example where it's realistically in the game.

540
00:44:23,883 --> 00:44:34,489
The one other thing that's missing from this is obstruction occlusion tests, because sometimes you'll have phantom emitters that are behind a wall, and you want them to be filtered that way, right?

541
00:44:35,950 --> 00:44:47,057
So here's an example in-game, very chaotic, but because of the propagation system, you can therefore control what you hear, depending on the geometry around you.

542
00:45:09,306 --> 00:45:10,067
All soldiers be ready

543
00:45:35,083 --> 00:45:35,503
There we go.

544
00:45:36,824 --> 00:45:38,325
So, let's summarize then.

545
00:45:38,486 --> 00:45:40,367
The reflection point cannibalization needs to be different.

546
00:45:40,647 --> 00:45:44,690
You need to have different modes for that to optimize around the requirements of early or late reflections, right?

547
00:45:44,730 --> 00:45:46,392
That direct field, reverberant field.

548
00:45:47,392 --> 00:45:49,674
Ray casting with a ring of local origins, really useful.

549
00:45:50,054 --> 00:45:55,038
It just incentivizes doing something where you're maximizing the amount of information and minimizing the CPU cost.

550
00:45:55,999 --> 00:46:00,722
And filtering materials is a big win, obviously, because it sounds, you get lots of variations, much more natural sounding.

551
00:46:01,523 --> 00:46:01,783
Okay?

552
00:46:02,704 --> 00:46:04,265
And you need robust memory management.

553
00:46:05,603 --> 00:46:10,367
I did a more elaborate description of that in the 2020 talk, so if you're curious, you can go back to that.

554
00:46:10,427 --> 00:46:11,008
It's on YouTube.

555
00:46:12,589 --> 00:46:13,369
And one last thing.

556
00:46:14,450 --> 00:46:17,833
Some people will think, we should hire an audio program to do this.

557
00:46:18,073 --> 00:46:21,496
So I want to explain to you how big the team is that's working at Snowdrop Reference Branch right now.

558
00:46:22,436 --> 00:46:25,238
In Sweden, we have me, Martin Wallin, who's the lead.

559
00:46:25,719 --> 00:46:28,521
We have Martin Lfgren, who did the emitter manager.

560
00:46:29,141 --> 00:46:33,465
Kasper Zedekunas, who did the amazing propagation system that works on the GPU.

561
00:46:34,085 --> 00:46:34,866
We have Hang Zhang.

562
00:46:35,246 --> 00:46:36,787
We also have Dave Driggers in Stockholm.

563
00:46:37,448 --> 00:46:40,931
In Germany, we have Hannah Kriegler, who's working on rapid prototyping stuff.

564
00:46:41,251 --> 00:46:46,575
And we also have in Canada, we have Oliver Snade and Andrew Smith, neither of whom are Canadian, but for some reason they live in Toronto.

565
00:46:47,616 --> 00:46:54,081
So, what I'm trying to say with this picture is, as well as credit where credit's due, you don't need an audio programmer, you need a platoon.

566
00:46:55,982 --> 00:46:56,563
Thanks for listening.

567
00:47:07,423 --> 00:47:08,664
So I guess some of you have some questions.

568
00:47:09,064 --> 00:47:10,505
Yeah, thanks for that.

569
00:47:10,525 --> 00:47:13,487
That was a buffet of delicious ideas for an audio program.

570
00:47:14,368 --> 00:47:18,030
I had a question about the ring of local emitters.

571
00:47:18,371 --> 00:47:21,453
Is that based on bubble space at all, or is that just a completely separate thing?

572
00:47:21,913 --> 00:47:25,896
So the ring of local origins is just like another circle that I just visualized in my head.

573
00:47:26,156 --> 00:47:32,961
To be specifically, the bubble space thing, the reason why I call it that is because when I originally drew it out on paper, it looked like lots of bubbles on the page.

574
00:47:34,182 --> 00:47:34,722
It's not really.

575
00:47:35,237 --> 00:47:37,338
bubbles, it's cylinders, but anyway.

576
00:47:38,559 --> 00:47:46,104
The ring of local origins is just a imaginary radius you've created in your system where you then create these origins you may cast out from.

577
00:47:46,525 --> 00:47:49,747
And then you use the original position for doing the phantom image technique, that's all.

578
00:47:50,047 --> 00:47:53,269
So it's just a mathematical concept to avoid hitting things too soon.

579
00:47:54,170 --> 00:47:54,510
Okay, cool.

580
00:47:54,590 --> 00:47:56,652
Can I ask a quick follow-up question on that?

581
00:47:56,672 --> 00:48:01,095
Do you do any slewing over time for the bubble space calculations as well?

582
00:48:01,835 --> 00:48:03,556
There's lots of smoothing going on.

583
00:48:05,349 --> 00:48:09,052
Again, there's a better description of that in the last talk, 2020, so I won't repeat it here.

584
00:48:09,132 --> 00:48:12,175
That's why I didn't put it in this talk, because it would seem like money for old rope.

585
00:48:12,916 --> 00:48:28,911
But yeah, so there's lots of smoothing going on, and that's why you can avoid weird glitches, like walking past a bunch of pillars in a train station, because it will pick them up, but there won't be enough coherency for them to take effect to the overall calculation, which happens actually over 16 frames.

586
00:48:33,371 --> 00:48:35,112
Hey, thanks for the great presentation.

587
00:48:36,093 --> 00:48:41,257
You mentioned that it was always player- or listener-based, all these systems?

588
00:48:41,817 --> 00:48:44,179
So, you could do it listener-based.

589
00:48:45,359 --> 00:48:46,020
You could do that.

590
00:48:47,861 --> 00:48:54,186
What I found was, is that because of the way we make games, listener is usually the camera position, or something close to it.

591
00:48:54,666 --> 00:48:58,169
Maybe you interpolate between player and camera position.

592
00:48:59,159 --> 00:48:59,379
going to

593
00:49:15,227 --> 00:49:19,308
But what you can do is that you have a threshold for when you start making the calculations happen again.

594
00:49:19,328 --> 00:49:20,368
Because you're not doing it every frame.

595
00:49:20,548 --> 00:49:23,249
If you're standing still, you do the calculations once and you've stopped.

596
00:49:23,649 --> 00:49:24,569
And then you have a threshold.

597
00:49:24,909 --> 00:49:26,029
And you can set that in data.

598
00:49:26,049 --> 00:49:27,150
But let's say it's half a meter.

599
00:49:27,410 --> 00:49:29,890
You move half a meter, and then it does the calculations again.

600
00:49:30,450 --> 00:49:35,872
If you were to do that with the listener position, you'd probably be doing lots and lots of extra calculations and just be heavier on the CPU.

601
00:49:36,272 --> 00:49:36,992
So that's the trade-off.

602
00:49:37,312 --> 00:49:39,514
So it wasn't actually my question, sorry.

603
00:49:40,574 --> 00:49:53,183
It was, did you ever find a situation where you would have liked to have an emitter, so another emitter than the player position, to also have its calculations?

604
00:49:53,243 --> 00:49:54,905
And are you considering that for the future?

605
00:49:55,685 --> 00:49:57,426
We have lots of, OK, 10 minutes to go.

606
00:49:57,787 --> 00:50:00,909
We have tried a lot of different things.

607
00:50:01,169 --> 00:50:03,711
And some of it sounds really cool, but it's just very expensive.

608
00:50:03,731 --> 00:50:05,952
And if you remember, we were originally targeting Xbox One and PS4.

609
00:50:07,168 --> 00:50:10,011
So this is why it ended up the way that it is now.

610
00:50:10,392 --> 00:50:14,116
However, now we're in a next generation and we're using the GPU and stuff like that.

611
00:50:15,397 --> 00:50:16,238
Lots of possibilities.

612
00:50:16,739 --> 00:50:17,380
So we'll see.

613
00:50:17,640 --> 00:50:21,464
Maybe in a couple of years I'll do another talk and I'll remind you of this question and go, hey look, guess what we did?

614
00:50:22,345 --> 00:50:22,906
So we'll see.

615
00:50:22,966 --> 00:50:23,767
I look forward to it.

616
00:50:27,501 --> 00:50:39,797
I have a question about geometries and I was wondering who is simplifying the geometry for audio and how hard?

617
00:50:39,837 --> 00:50:41,459
How is the geometry simplified?

618
00:50:42,321 --> 00:50:43,923
That's actually done by technical artists.

619
00:50:45,843 --> 00:50:49,184
So what they do is they start off with a random mesh.

620
00:50:49,844 --> 00:50:52,305
And if it turns out to be too complicated, they simplify it.

621
00:50:52,365 --> 00:50:55,006
So if you get like a fallen down tree trunk, they might turn that into a box.

622
00:50:55,826 --> 00:50:57,027
That's what ends up in that physics world.

623
00:50:57,327 --> 00:50:58,767
And that's what we see with the raycasts.

624
00:50:59,007 --> 00:50:59,848
Does that make sense?

625
00:50:59,888 --> 00:51:01,388
Is it hard for them to do?

626
00:51:01,988 --> 00:51:03,829
It's just in the data.

627
00:51:04,209 --> 00:51:11,991
I had the same question, so great talk.

628
00:51:12,031 --> 00:51:12,732
I have another question.

629
00:51:15,680 --> 00:51:15,780
and

630
00:51:37,697 --> 00:51:41,598
You could use FDN reverb or something else, some algorithm.

631
00:51:41,918 --> 00:51:43,098
That's the part that doesn't matter.

632
00:51:43,258 --> 00:51:45,339
That's the modular part of it, so that's up to you to decide.

633
00:51:45,879 --> 00:51:55,801
And maybe it's, you could have more reflections, more and more LRO type late reflections with a cheaper algorithm perhaps, if you wanted to do that.

634
00:51:56,061 --> 00:52:05,683
But that's, I purposely avoided talking about that because that's not part of the system that is decided further down the, it's actually the environment element manager in Snowdrop that actually defines that.

635
00:52:10,405 --> 00:52:25,575
With having the reflections be driven by this kind of like ring buffer kind of thing, was that sync plug-in where you were collecting the delay line, was that, did you have just like one of those or did you put them on multiple different buses?

636
00:52:25,715 --> 00:52:29,958
I'm wondering about like... So the sync plug-in part is one per exit destination.

637
00:52:30,919 --> 00:52:35,522
If you come to the Audio Kinetic booth at 115, I will show you that slide.

638
00:52:36,956 --> 00:52:37,036
to

639
00:52:53,694 --> 00:52:54,434
didn't end up in the game.

640
00:52:54,494 --> 00:52:55,335
But it was a nice idea.

641
00:52:55,935 --> 00:52:57,315
I think it just didn't quite work.

642
00:52:57,855 --> 00:52:59,456
But yes, that would have been a separate channel.

643
00:52:59,696 --> 00:53:02,497
So therefore, you have a different device and then a different auxiliary send.

644
00:53:03,097 --> 00:53:07,879
And therefore, you read it off a different channel on the way back again and then do something else with it.

645
00:53:12,113 --> 00:53:13,014
Thank you for your talk.

646
00:53:13,414 --> 00:53:24,723
I think in your system, all the reflection and the light reverberation is fully 3D positioning, but isn't the light reverberation should be more omnidirectional?

647
00:53:25,855 --> 00:53:27,136
Sorry, what was the last part of the question?

648
00:53:27,356 --> 00:53:30,938
Late reverberation should be omnidirectional.

649
00:53:31,138 --> 00:53:32,238
It's non-directional.

650
00:53:32,298 --> 00:53:33,479
Yeah, so it's a good point.

651
00:53:33,519 --> 00:53:41,043
So the question is, if you're positioning these emitters and they are being spatialized, when you're adding reverb to them, how does that affect it?

652
00:53:41,503 --> 00:53:46,726
Well, in actual fact, the reverb in and of itself is working already to render out the channels.

653
00:53:47,106 --> 00:53:50,848
And so what you're sending to that has already been spatialized in some way.

654
00:53:50,888 --> 00:53:53,230
So you've already worked out the distribution based on the emitter position.

655
00:53:53,830 --> 00:53:54,270
the delay.

656
00:53:54,711 --> 00:53:59,075
And then however that reverb chooses to do its work, that's what ends up going to the channels.

657
00:53:59,555 --> 00:54:00,917
So they're actually completely decoupled.

658
00:54:01,337 --> 00:54:05,521
Okay, thank you.

659
00:54:05,721 --> 00:54:07,483
Did I exhaust all the curiosity in the room?

660
00:54:09,885 --> 00:54:10,666
Should we go get a coffee?

661
00:54:10,686 --> 00:54:13,669
Alright, thanks very much.

