1
00:00:05,648 --> 00:00:09,709
Please welcome to the stage, the studio head and directors

2
00:00:09,749 --> 00:00:12,249
of Kojima Production, Hideo Kojima.

3
00:00:29,913 --> 00:00:30,453
Hello, guys.

4
00:00:33,659 --> 00:00:35,240
Thank you for joining us today.

5
00:00:36,060 --> 00:00:40,243
As promised, I have our new trailer.

6
00:00:42,364 --> 00:00:42,824
Take a look.

7
00:00:57,132 --> 00:00:58,353
Don't you die on me, dammit!

8
00:00:58,413 --> 00:00:59,194
He's dropping!

9
00:00:59,894 --> 00:01:00,695
Interbate, now!

10
00:01:02,110 --> 00:01:03,311
Cardiac arrest, he's in B-fib!

11
00:01:03,331 --> 00:01:03,591
Clear!

12
00:01:03,891 --> 00:01:12,333
No response, hit him again!

13
00:01:36,226 --> 00:01:39,090
How's he doing?

14
00:01:39,471 --> 00:01:42,334
Well, he's stabilized, but it took too long.

15
00:01:42,495 --> 00:01:43,416
He's in a coma.

16
00:01:43,516 --> 00:01:44,678
What about him?

17
00:03:00,301 --> 00:03:00,941
Thanks for listening!

18
00:04:54,886 --> 00:04:58,214
We won't preach as you whisper

19
00:05:33,120 --> 00:05:35,844
You've been in a coma for quite some time.

20
00:05:36,505 --> 00:05:40,171
Yes, yes, I know you would like to know how long.

21
00:05:42,474 --> 00:05:43,877
I'm afraid it's been...

22
00:05:45,459 --> 00:05:46,180
nine years.

23
00:06:11,794 --> 00:06:12,595
Diamond Docks.

24
00:06:15,657 --> 00:06:16,338
Our new home.

25
00:06:42,419 --> 00:06:43,020
Did you like it?

26
00:06:43,040 --> 00:06:46,542
Yeah!

27
00:06:50,085 --> 00:06:50,465
Ah...

28
00:06:51,606 --> 00:06:52,486
It's hot.

29
00:06:52,566 --> 00:06:56,830
From here on, I'll be presenting as Hideo Kojima.

30
00:06:57,555 --> 00:07:01,215
As you've seen in the trailer and probably understand now,

31
00:07:01,676 --> 00:07:06,857
the Phantom Pain and Metal Gear Solid Ground Zeroes put together is Metal Gear Solid V.

32
00:07:06,877 --> 00:07:08,637
The trailer itself is all run real-time.

33
00:07:31,137 --> 00:07:36,259
Since today our session is about the Fox engine, I'd like to show you a little something that's actually moving in the engine.

34
00:07:36,279 --> 00:07:46,363
Metal Gear Solid V is an open world game, but the beginning of Phantom Pain is a tutorial, so it's more of a rail game.

35
00:07:50,290 --> 00:07:55,352
The Phantom Pain is an open world game, but in the beginning as an introduction and a tutorial,

36
00:07:55,412 --> 00:07:58,953
it's more of a real game to understand the controls and the system overall.

37
00:07:59,293 --> 00:08:14,619
The tutorial itself is a sequence where a snake wakes up from a coma from nine years,

38
00:08:15,299 --> 00:08:18,960
and is all of a sudden attacked by an unknown enemy, and he has to escape the hospital.

39
00:08:32,675 --> 00:08:37,719
Since he's been in a coma for nine years, Snake has lost a lot of his movement capabilities.

40
00:08:38,039 --> 00:08:42,983
So you start off from crawling and then standing up, falling onto things to gather your composure,

41
00:08:43,424 --> 00:08:45,305
and that's the rail game that we'll be showing today.

42
00:08:45,949 --> 00:08:49,011
And everything is running on PC right now.

43
00:09:15,151 --> 00:09:15,451
Where am I?

44
00:09:15,531 --> 00:09:17,832
I've been...

45
00:09:17,912 --> 00:09:22,293
I've been watching over you for nine years.

46
00:09:22,313 --> 00:09:24,234
You can call me Ishmael.

47
00:09:25,634 --> 00:09:27,274
What the hell is going on?

48
00:09:27,995 --> 00:09:28,835
Well, the good news is,

49
00:09:28,875 --> 00:09:30,015
you're in the land of the living.

50
00:09:30,575 --> 00:09:32,756
Bad news? The world wants you dead.

51
00:09:32,776 --> 00:09:35,217
On your feet, soldier.

52
00:09:35,357 --> 00:09:39,958
It's our only place to come down.

53
00:09:42,819 --> 00:09:43,559
Need a little pick me up?

54
00:10:19,760 --> 00:10:20,480
The drug's not working.

55
00:10:32,312 --> 00:10:33,573
We're getting out of here. Move it!

56
00:13:08,322 --> 00:13:08,523
song

57
00:13:08,603 --> 00:13:11,024
riiiiiiiiiiiiiiiimp

58
00:13:11,044 --> 00:13:12,645
pppppppppppppppppppppppp

59
00:13:12,685 --> 00:13:13,686
Pew pew pew pew pew pew...

60
00:13:13,726 --> 00:13:16,127
ResidentSleep has become infuriatingly obese

61
00:13:16,127 --> 00:13:16,367
有人angry

62
00:14:00,433 --> 00:14:16,803
The emergency stairs, come on!

63
00:14:17,243 --> 00:14:19,585
This way, hurry!

64
00:14:43,134 --> 00:14:45,736
Thank you.

65
00:15:15,321 --> 00:15:22,486
From here on out, Snake will be able to walk freely, open world, and whoever he wants to.

66
00:15:22,546 --> 00:15:26,389
And from here, we'll talk about the engine. Let me introduce you to the members.

67
00:15:42,934 --> 00:15:46,035
First, the CG art director, Hideki Sasaki.

68
00:15:53,836 --> 00:15:58,117
And our lighting artist, Masayuki Suzuki.

69
00:16:01,557 --> 00:16:04,258
And our technical director, Junji Tago.

70
00:16:04,898 --> 00:16:07,178
And our technical director, Junji Tago.

71
00:16:09,569 --> 00:16:11,910
Alright, let's get it started.

72
00:16:21,878 --> 00:16:25,081
Welcome to the session, Photorealism Through the Eyes of a Fox,

73
00:16:25,481 --> 00:16:27,342
the core of Metal Gear Solid Ground Zeroes.

74
00:16:29,969 --> 00:16:32,230
Now that Metal Gear Solid V has officially been announced,

75
00:16:32,390 --> 00:16:35,833
our presentation title will be reflected to show that.

76
00:16:35,953 --> 00:16:38,355
The fox in the title refers to our development environment.

77
00:16:42,398 --> 00:16:44,520
Let me give a brief overview of what the fox engine is.

78
00:16:45,941 --> 00:16:47,942
The fox engine is the engine created in-house

79
00:16:47,982 --> 00:16:49,123
here at Kojima Productions.

80
00:16:52,285 --> 00:16:53,346
It contains the level editor,

81
00:16:53,366 --> 00:16:54,127
cutscene editor,

82
00:16:54,187 --> 00:16:54,627
effects,

83
00:16:58,824 --> 00:17:04,951
UI, sound, motion, and others.

84
00:17:05,011 --> 00:17:06,613
This is what we use to create our game.

85
00:17:09,396 --> 00:17:11,758
Because the Fox Engine covers such a wide range,

86
00:17:11,778 --> 00:17:17,685
I unfortunately do not have time to touch on each aspect.

87
00:17:17,745 --> 00:17:19,507
I would like, however, to focus on the visuals.

88
00:17:22,732 --> 00:17:27,115
I will show you an overview of how we go about creating MGS5 using the Fox Engine rather

89
00:17:27,135 --> 00:17:36,142
than each individual detail.

90
00:17:36,403 --> 00:17:37,463
Here is the agenda for today.

91
00:17:39,405 --> 00:17:42,647
I will start off showing you how assets are created for MGS5.

92
00:17:46,310 --> 00:17:49,733
Next, the lighting artist, Mr. Suzuki, will talk about the lighting, shaders, and camera.

93
00:17:52,070 --> 00:17:55,132
And finally, the technical director, Mr. Tago, will go over the graphics engine.

94
00:17:55,152 --> 00:18:05,918
Well, let's jump right in. I will be covering how we go about creating assets.

95
00:18:13,443 --> 00:18:16,005
Does this picture look familiar?

96
00:18:17,226 --> 00:18:18,586
Some of you have probably seen it before.

97
00:18:20,367 --> 00:18:23,349
This is an actual photograph of our conference room here at Kojima Productions.

98
00:18:26,131 --> 00:18:30,374
On our Kojima Productions website, we've asked visitors which image was an actual photograph

99
00:18:30,454 --> 00:18:36,297
and which image was rendered in the Fox engine.

100
00:18:36,357 --> 00:18:38,298
Here, the image on the left is the photograph.

101
00:18:38,539 --> 00:18:40,040
The one on the right is rendered in Fox.

102
00:18:46,416 --> 00:18:49,056
Here again, the left image is a photograph, the right rendered in Fox.

103
00:18:51,517 --> 00:18:55,898
You can tell which is which quite easily by looking at the differences in the assets,

104
00:18:56,058 --> 00:19:05,120
but if you focus on the lighting, they become very hard to distinguish.

105
00:19:05,160 --> 00:19:08,981
Promotion was not the goal of making the conference room, but rather to have a good reference

106
00:19:09,021 --> 00:19:11,961
for artists to use when dealing with linear space lighting.

107
00:19:12,001 --> 00:19:13,041
https://TheBusinessProfessor.com

108
00:19:21,574 --> 00:19:25,377
Linear workflow will be talked about more in the next talk by Mr. Suzuki,

109
00:19:25,417 --> 00:19:31,262
but it basically means rendering, taking into account your monitor's gamma.

110
00:19:31,623 --> 00:19:36,627
It is the foundation of physically-based rendering.

111
00:19:39,189 --> 00:19:43,132
When working in linear space, the most important and difficult problem we faced

112
00:19:43,492 --> 00:19:45,254
was the way to create diffuse maps.

113
00:19:50,973 --> 00:19:55,476
Using conventional color maps, the artist's job was only to make a texture look good.

114
00:19:57,197 --> 00:20:01,280
In physically-based rendering, on the other hand, the artist has to be aware of diffuse reflection.

115
00:20:01,300 --> 00:20:08,405
To make our texture references, we use a real-world camera and use the captured raw image without correction.

116
00:20:17,176 --> 00:20:19,197
Artists are used to creating assets that look good

117
00:20:19,297 --> 00:20:20,977
without worrying about detailed parameters,

118
00:20:21,198 --> 00:20:23,198
but this would create problems in linear space.

119
00:20:23,278 --> 00:20:25,499
So in order to test if the results look natural

120
00:20:25,539 --> 00:20:26,099
in linear space lighting,

121
00:20:26,119 --> 00:20:27,380
we needed to create a reference model.

122
00:20:27,400 --> 00:20:28,480
This model is the conference room.

123
00:20:46,395 --> 00:20:48,877
Now I would like to show you the actual Fox engine in action.

124
00:20:50,459 --> 00:20:51,740
Please wait just a couple seconds.

125
00:21:00,347 --> 00:21:01,488
Gotta get these computers running.

126
00:21:13,217 --> 00:21:13,658
There it is.

127
00:21:22,930 --> 00:21:25,011
So this is the actual Fox engine running in real time.

128
00:21:37,960 --> 00:21:39,381
Here we're changing some of the view styles.

129
00:21:40,602 --> 00:21:41,903
That's the normal map.

130
00:21:42,043 --> 00:21:43,023
Here is the specular mask.

131
00:21:44,784 --> 00:21:46,967
And here's the roughness map.

132
00:21:49,289 --> 00:21:54,415
For the roughness, blacker is glossier, while whiter is more of a matte finish.

133
00:21:58,139 --> 00:22:00,101
And here is the diffuse albedo map.

134
00:22:16,848 --> 00:22:21,629
This image is being created from values taken from a real photograph.

135
00:22:21,789 --> 00:22:27,430
Unlike conventional workflows, textures do not have as much shading or detail applied to them.

136
00:22:27,450 --> 00:22:38,292
This image is not something that an artist has created, but simulated based on the reflection values of each surface.

137
00:22:38,672 --> 00:22:39,852
Well, let's move the camera around.

138
00:22:52,657 --> 00:22:55,158
It sure does look real.

139
00:22:58,600 --> 00:23:00,721
While I was playing with the simulation back at the office,

140
00:23:00,741 --> 00:23:02,442
one of the programmers was looking over my shoulder

141
00:23:02,482 --> 00:23:04,783
watching me do this, and he thought we had security cameras

142
00:23:04,803 --> 00:23:05,703
set up in the conference room.

143
00:23:07,364 --> 00:23:09,485
I guess that's a testament to how real this really does look.

144
00:23:09,805 --> 00:23:14,848
We frequently use this conference room to check shaders,

145
00:23:14,948 --> 00:23:15,628
assets, and the like.

146
00:23:25,435 --> 00:23:25,936
for example.

147
00:23:37,642 --> 00:23:40,164
This is a soldier that has appeared in the Phantom Pain trailer.

148
00:23:45,587 --> 00:23:46,567
Some kid hanging out in the back.

149
00:23:48,248 --> 00:23:51,170
I'll explain about the kid in just a little bit.

150
00:23:58,690 --> 00:24:00,733
This is the soldier that appeared in the Ground Zeroes trailer.

151
00:24:04,220 --> 00:24:05,943
You can see that he looks a bit wet from the rain.

152
00:24:22,548 --> 00:24:27,270
In order to check for the weapons, the artists have created a gun rack here, and here's what it looks like.

153
00:24:32,732 --> 00:24:35,112
The tank and helicopter were also shown in the trailer as well.

154
00:24:35,132 --> 00:24:44,876
Here are the details of what the weapons do look like.

155
00:24:45,676 --> 00:24:47,357
We think it looks pretty real.

156
00:25:10,235 --> 00:25:13,878
Because we have a real-looking environment, it is easy to spot things that do not look

157
00:25:14,058 --> 00:25:19,601
natural in our created assets.

158
00:25:20,082 --> 00:25:23,344
If we need to test what something looks like, we just take pictures of it and can quickly

159
00:25:23,384 --> 00:25:27,046
and easily contrast what that thing looks like in real life and what it looks like rendered

160
00:25:27,066 --> 00:25:27,366
in Fox.

161
00:25:29,587 --> 00:25:33,410
These images of cloth and leaves are from Look Development.

162
00:25:34,691 --> 00:25:37,372
The left image is rendered in Fox, the right is a real photograph.

163
00:25:39,314 --> 00:25:43,637
We sure do think it looks quite similar, the rendered image looks quite similar to the

164
00:25:43,657 --> 00:25:44,117
photograph.

165
00:25:46,879 --> 00:25:50,101
And the asset creators can check very easily for any inconsistencies when creating their

166
00:25:50,141 --> 00:25:50,421
assets.

167
00:25:51,957 --> 00:25:56,080
We are able to keep our textures looking like real life, even when using linear space sliding.

168
00:25:56,320 --> 00:25:58,822
Texture creation will be touched on by Mr. Suzuki in the next talk.

169
00:26:09,323 --> 00:26:12,665
I have talked about how we go about making our textures look real life, but what about

170
00:26:12,705 --> 00:26:13,165
our models?

171
00:26:13,765 --> 00:26:18,047
I now want to talk a bit about photorealistic modeling.

172
00:26:19,048 --> 00:26:22,069
The conference room you have seen rendered in Fox was created using photographs.

173
00:26:22,710 --> 00:26:27,092
This character on the other hand was created by 3D scanning.

174
00:26:27,632 --> 00:26:31,634
3D scanning is not a new technology by any means, but it is the first time the Metal

175
00:26:31,654 --> 00:26:32,915
Gear Solid series has used it.

176
00:26:37,709 --> 00:26:41,950
The model shown on the previous slide was created from refining a laser scan, but we

177
00:26:41,990 --> 00:26:45,251
are also using a different approach, that of photo-based scanning.

178
00:26:49,472 --> 00:26:53,914
To generate a model from a photograph, we used PhotoScan by Agisoft.

179
00:26:53,954 --> 00:26:57,535
PhotoScan automatically generates a 3D model using multiple photographs as a reference

180
00:26:57,575 --> 00:26:57,735
point.

181
00:26:58,613 --> 00:27:01,855
The photo scan is not just limited to models.

182
00:27:01,895 --> 00:27:04,097
It can also generate textures and camera data as well.

183
00:27:06,559 --> 00:27:07,900
There have been tools used in the past

184
00:27:07,920 --> 00:27:09,481
to generate a model from a photograph,

185
00:27:09,602 --> 00:27:11,843
but the quality and accuracy with which this is accomplished

186
00:27:11,863 --> 00:27:13,445
has increased dramatically in recent times.

187
00:27:17,588 --> 00:27:19,910
In order to make one important character for the game,

188
00:27:20,150 --> 00:27:22,532
we made a photo real sculpture and scanned it.

189
00:27:30,989 --> 00:27:33,911
The character in-game is over 100 years old,

190
00:27:33,931 --> 00:27:37,672
so the wrinkles and sags and skin needed to be accurate.

191
00:27:37,712 --> 00:27:40,894
Here is what we did.

192
00:27:40,914 --> 00:27:42,815
We constructed a clay mold from the actor,

193
00:27:43,115 --> 00:27:45,236
and then added special effects makeup to the mold

194
00:27:45,416 --> 00:27:47,918
to create the final character.

195
00:27:47,998 --> 00:27:49,478
Finally, we scanned in the finished mold

196
00:27:49,659 --> 00:27:51,019
and stuck the character back into the game.

197
00:27:53,160 --> 00:27:54,301
Here is this process in action.

198
00:27:58,656 --> 00:27:59,897
Here is the life cast of the model.

199
00:28:04,100 --> 00:28:06,242
The model on the right is the original life cast,

200
00:28:06,422 --> 00:28:08,504
and the one on the left is the clay press-out.

201
00:28:09,865 --> 00:28:14,269
As I said previously, we added special effects makeup to the character and scanned it in,

202
00:28:14,589 --> 00:28:16,771
but we also did a scan before adding the makeup as well.

203
00:28:19,616 --> 00:28:22,298
The person we requested to do the sculpting

204
00:28:22,398 --> 00:28:24,820
was Mr. Kazuhiro Tsuji.

205
00:28:24,960 --> 00:28:27,141
He is famous in the field of photo-real sculpting

206
00:28:27,421 --> 00:28:28,642
and has worked on many projects,

207
00:28:28,682 --> 00:28:31,124
including The Curious Case of Benjamin Button and Looper.

208
00:28:33,445 --> 00:28:37,108
Unfortunately, we are unable to show you

209
00:28:37,148 --> 00:28:38,508
what the finished character does look like.

210
00:28:39,149 --> 00:28:41,750
We can, however, show you the skin of the clay model

211
00:28:41,891 --> 00:28:43,532
before the addition of the special effects makeup.

212
00:28:49,422 --> 00:28:51,804
And here are some photographs of the model that we used to scan.

213
00:28:56,648 --> 00:28:58,790
I want to show you a short clip of this as well.

214
00:29:19,499 --> 00:29:25,963
Sometimes movies don't play, there it goes.

215
00:29:26,123 --> 00:29:29,145
We use PhotoScan to create the 3D model and camera data,

216
00:29:29,205 --> 00:29:30,765
and then use SoftImage to display it.

217
00:29:32,606 --> 00:29:36,869
The blue objects shown around the model are the cameras.

218
00:29:37,229 --> 00:29:39,510
The cameras took pictures of the model at these coordinates.

219
00:29:41,031 --> 00:29:44,193
The 3D model and textures are then generated from these photographs.

220
00:29:48,034 --> 00:29:51,816
Many cameras were used in this example, but it is completely possible to scan with less.

221
00:29:53,997 --> 00:29:58,558
Here is what the model looks like with textures.

222
00:29:58,738 --> 00:30:02,660
Since these textures were generated from the photographs taken, they match the model perfectly.

223
00:30:02,680 --> 00:30:03,680
And here is the wireframe.

224
00:30:20,322 --> 00:30:24,105
You can even see that detailed features like wrinkles in the face are kept faithful to

225
00:30:24,145 --> 00:30:24,766
the original model.

226
00:30:38,288 --> 00:30:42,071
On the left is a photograph of the sculpture, on the right is the image of the 3D scan model.

227
00:30:42,911 --> 00:30:44,752
You can see how accurate the scan model is.

228
00:30:45,053 --> 00:30:47,394
There is virtually no difference when compared to the photograph.

229
00:30:47,414 --> 00:30:56,701
All right, I'd like to show you one more quick clip.

230
00:31:11,011 --> 00:31:16,836
This is an example of how an environmental asset is scanned in PhotoScan.

231
00:31:16,876 --> 00:31:22,602
For this specific asset, we placed the rock on the turntable, rotated it, and photographed it.

232
00:31:22,622 --> 00:31:25,484
We then flipped it over and did the same to get a scan of the rock from all angles.

233
00:31:28,808 --> 00:31:31,951
One advantage of doing photo-based scanning is that it creates camera data.

234
00:31:34,506 --> 00:31:41,268
You can put the camera data, as an FBX file, into a 3D tool and can easily modify the textures from the given camera projection.

235
00:31:44,128 --> 00:31:50,430
For example, when using the camera data in Mudbox and setting the stencil, we can paint the texture onto the model, matching it exactly.

236
00:31:55,271 --> 00:31:59,291
Photoscan can automatically generate textures, and in recent versions, it actually looks pretty good.

237
00:32:01,546 --> 00:32:05,068
So if you want to modify a small part of a certain texture, it is possible and quite

238
00:32:05,108 --> 00:32:05,528
easy to do.

239
00:32:05,588 --> 00:32:06,668
And here is the finished product.

240
00:32:06,688 --> 00:32:14,051
For another example, here is a scan of a tree trunk.

241
00:32:29,938 --> 00:32:34,127
Of course, we can use the scan as is, but we can also extract the height map and use

242
00:32:34,147 --> 00:32:35,891
it as a brush in ZBrush or Mudbox.

243
00:32:42,503 --> 00:32:46,187
This example is especially cool.

244
00:32:46,228 --> 00:32:48,891
This is a scan of a seashell.

245
00:32:49,051 --> 00:32:53,236
Even with such a complicated surface, the scanned data is an almost perfect replication.

246
00:32:55,218 --> 00:32:58,823
What surprised me the most was that even the very thin parts of the shell were reproduced

247
00:32:58,903 --> 00:32:59,283
perfectly.

248
00:33:08,681 --> 00:33:11,062
Next, cloth modeling.

249
00:33:14,464 --> 00:33:19,727
For character clothing and environmental cloth assets, we used Marvellous Designer.

250
00:33:22,408 --> 00:33:25,109
Constructing real-looking wrinkles in cloth is very difficult,

251
00:33:25,129 --> 00:33:28,051
and when doing it by hand, can have a fabricated look.

252
00:33:31,125 --> 00:33:34,727
During Metal Gear Solid 4, we tested some simulation-based modeling tools,

253
00:33:35,188 --> 00:33:42,193
but it was difficult to use these tools for any high-res models that required baking normal maps.

254
00:33:42,353 --> 00:33:44,374
However, when using Marvelous Designer on this project,

255
00:33:44,514 --> 00:33:46,736
it was very quick and easy to get high-quality cloth models.

256
00:33:54,284 --> 00:33:58,488
In the final scene in the trailer, snake stitching on his shoulders was done completely in Marvelous

257
00:33:58,508 --> 00:33:59,028
Designer.

258
00:33:59,549 --> 00:34:03,512
No one had to touch it up by hand, and it sure did turn out pretty well, we think.

259
00:34:09,157 --> 00:34:11,499
And here's another demonstration of Marvelous Designer.

260
00:34:15,822 --> 00:34:20,106
It is incredibly simple in Marvelous Designer to set up a specific pattern to get a high-quality

261
00:34:20,146 --> 00:34:20,406
result.

262
00:34:20,426 --> 00:34:21,507
And that's what Marvelous Designer is all about.

263
00:34:25,244 --> 00:34:27,225
Just by setting a pattern and generating the model,

264
00:34:27,486 --> 00:34:29,488
the time saved for a modeler is enormous.

265
00:34:29,648 --> 00:34:31,069
Here are some of the sleeves being adjusted.

266
00:34:31,129 --> 00:34:35,693
And here are some wrinkles on his jacket being adjusted.

267
00:34:54,328 --> 00:35:05,612
One big advantage is being able to adjust by hand the simulated result.

268
00:35:05,692 --> 00:35:09,493
Finally, the polygon density is raised and recalculated.

269
00:35:10,673 --> 00:35:14,815
The stitching near his shoulders turned out quite well, I think you can see from this example.

270
00:35:34,446 --> 00:35:38,931
Snake's goggles and gloves were both generated in the same way.

271
00:35:39,112 --> 00:35:40,133
And here is the final result.

272
00:35:54,485 --> 00:35:58,732
Next on the agenda is Mr. Suzuki to talk about Fox Engine's shaders, lighting, and camera.

273
00:36:17,615 --> 00:36:23,259
Thank you. I would now like to talk about linear workflow, shaders, lighting, and the camera.

274
00:36:25,861 --> 00:36:34,167
Metal Gear Solid V uses a linear workflow. Without a linear workflow, physically based rendering would simply not be possible.

275
00:36:35,048 --> 00:36:38,690
Many of you may already know about linear workflow, but I'll give a brief summary here.

276
00:36:43,128 --> 00:36:47,032
And what we see here is the basic outline of how linear workflow works.

277
00:36:48,673 --> 00:36:52,517
In conventional nonlinear workflows, values are rendered as is and then output to the

278
00:36:52,557 --> 00:36:54,119
monitor as is.

279
00:36:54,179 --> 00:36:57,682
In a linear workflow, however, all values are rendered in linear space.

280
00:36:57,702 --> 00:37:01,146
This is called gamma decoding, or D-gamma.

281
00:37:01,286 --> 00:37:05,270
After the values are rendered, they are then changed back into monitor space, and this

282
00:37:05,310 --> 00:37:06,331
is called gamma correction.

283
00:37:06,912 --> 00:37:09,057
And this is the basic tenet of linear workflow.

284
00:37:17,910 --> 00:37:22,954
And the image on the left here was created in nonlinear workflow, while the right was done in linear workflow.

285
00:37:22,994 --> 00:37:27,498
You can see the light in the right image is brighter when compared to the left image.

286
00:37:28,499 --> 00:37:33,143
In reality, the far back wall would be receiving more light, as seen in the right-hand image.

287
00:37:33,383 --> 00:37:36,306
In real life, the inverse square law determines the attenuation.

288
00:37:36,946 --> 00:37:40,129
By not using linear workflow, you get a darker image when compared to real life.

289
00:37:45,886 --> 00:37:52,270
And this example shows both non-linear workflow and linear workflow, showing an addition of

290
00:37:52,330 --> 00:37:53,571
brightness by a factor of 0.1.

291
00:37:54,731 --> 00:37:55,272
Which is correct?

292
00:37:55,292 --> 00:37:57,693
The example on the right, which uses linear workflow.

293
00:37:57,953 --> 00:38:04,777
The value used is 0.1 in linear workflow, and linear workflow actually uses this value

294
00:38:04,797 --> 00:38:06,038
in the calculations to be successful.

295
00:38:06,358 --> 00:38:06,558
However...

296
00:38:08,699 --> 00:38:11,881
If you ever had a problem where adding multiple effects would wash things out,

297
00:38:12,422 --> 00:38:14,123
or, you know, would make things too white,

298
00:38:14,163 --> 00:38:15,864
I think many of us have had this problem.

299
00:38:16,704 --> 00:38:18,426
Or maybe by making the light a little bit stronger,

300
00:38:18,686 --> 00:38:20,767
everything suddenly gets really bright.

301
00:38:21,107 --> 00:38:24,389
The reason why this happens is because your monitor is not showing the correct value.

302
00:38:29,173 --> 00:38:31,694
As seen here, TV monitors tend to exaggerate darkness.

303
00:38:33,482 --> 00:38:35,463
For example, using the gamma value of 2.2,

304
00:38:36,764 --> 00:38:38,744
all values will be raised to the power of 2.2

305
00:38:39,445 --> 00:38:40,725
and shown this way on the monitor.

306
00:38:41,165 --> 00:38:44,746
In Windows, the sRGB rule is not exactly gamma 2.2,

307
00:38:45,407 --> 00:38:49,008
but it is very close.

308
00:38:49,048 --> 00:38:51,829
For example, on a monitor using a gamma of 2.2,

309
00:38:52,489 --> 00:38:55,790
the value 0.1 will become a brightness of 0.006 when displayed.

310
00:38:58,707 --> 00:39:01,189
So in order to get a brightness value of 0.1 on the monitor,

311
00:39:01,389 --> 00:39:04,011
you actually need to input a value of about 0.35.

312
00:39:05,432 --> 00:39:09,776
Using Linear Workflow allows rendering using the correct values,

313
00:39:09,876 --> 00:39:14,761
and this is necessary for creating lights and textures using physically based values.

314
00:39:17,963 --> 00:39:22,107
Okay then, next I'd like to give a simple introduction

315
00:39:22,227 --> 00:39:25,130
to the way diffuse albedo textures are created at Kojima Productions.

316
00:39:28,662 --> 00:39:37,830
We use a photography room as pictured here in order to photograph our textures.

317
00:39:38,330 --> 00:39:42,553
Modern cameras have image sensors that can capture images linearly.

318
00:39:42,613 --> 00:39:45,156
In addition, we use a camera that supports a raw image format

319
00:39:45,656 --> 00:39:50,240
and use care to preserve linearity when developing the image by eliminating any unnecessary tone curves.

320
00:39:51,816 --> 00:39:58,161
That way we can preserve linearity when upon delting the image.

321
00:39:59,382 --> 00:40:04,826
So first we photograph a gray card that has a reflectance of 18% using a proper exposure.

322
00:40:08,069 --> 00:40:12,552
Next, in the same environment, at the same camera settings, we photograph our desired texture.

323
00:40:12,632 --> 00:40:15,835
We then develop it using the same linear processing settings as the gray card.

324
00:40:22,613 --> 00:40:24,453
After developing, we further tweak the values

325
00:40:24,513 --> 00:40:25,993
that the RGB value of the gray card

326
00:40:26,053 --> 00:40:28,454
represents a brightness of 18%.

327
00:40:28,714 --> 00:40:30,674
In this case, with a gamma of 2.2,

328
00:40:31,115 --> 00:40:33,935
the RGB values fall within the 117 or 255 range.

329
00:40:34,015 --> 00:40:35,416
The same adjustments are applied to the desired texture.

330
00:40:35,436 --> 00:40:39,777
Using this technique, you're able to get a photograph

331
00:40:39,797 --> 00:40:40,697
with the correct tone values.

332
00:40:51,234 --> 00:40:54,437
As you can see here, there are various other details that you should be aware of and be cautious of,

333
00:40:54,577 --> 00:40:56,679
but for today, I won't go into too much detail.

334
00:41:01,523 --> 00:41:06,147
After getting the corrected photograph, we then manually eliminate highlights and shadows to complete the texture.

335
00:41:07,608 --> 00:41:09,930
And this is the basic flow we use for creating our textures.

336
00:41:13,553 --> 00:41:17,516
And the materials we use are also physically based to a certain extent.

337
00:41:19,046 --> 00:41:22,248
So, as you can see here, we can create various types of materials.

338
00:41:26,210 --> 00:41:30,653
By creating presets, we can simplify the setting of numerous material parameters.

339
00:41:31,413 --> 00:41:33,154
And this is the screen used to adjust those settings.

340
00:41:37,450 --> 00:41:44,253
We observe the texture of various surfaces to evaluate our shaders and determine what parameters to use.

341
00:41:45,254 --> 00:41:49,896
As seen here, we use a light attached to an arm to observe light hitting objects from various angles.

342
00:41:50,596 --> 00:41:53,237
We use this method to create our various material presets.

343
00:41:57,859 --> 00:42:00,860
Now, a new feature we've added is view-dependent roughness,

344
00:42:00,880 --> 00:42:04,542
which smooths out subtle roughness when looking at surfaces from the side.

345
00:42:06,090 --> 00:42:09,553
This illusion occurs on certain rough, flat surfaces at particular angles.

346
00:42:10,293 --> 00:42:14,055
As you can see in this photograph, the smaller the angle you view the surface from,

347
00:42:14,376 --> 00:42:15,656
the smoother the surface looks.

348
00:42:15,676 --> 00:42:22,220
And this is an example of the effect simulated in Fox.

349
00:42:30,983 --> 00:42:34,005
In this image, the black arrows indicate the viewing angle.

350
00:42:34,085 --> 00:42:36,967
The white arrows indicate the direction of the visible reflected light.

351
00:42:37,627 --> 00:42:41,990
If you view a surface head-on as seen in the top image, the reflected light becomes disrupted.

352
00:42:42,910 --> 00:42:46,251
However, as the viewing angle and the direction of reflected light align,

353
00:42:46,271 --> 00:42:48,951
the occluded vectors are not seen by the viewer.

354
00:42:49,091 --> 00:42:51,772
Therefore, as the viewing angle becomes closer to horizontal,

355
00:42:51,912 --> 00:42:54,753
disruptions in the reflected light become less apparent.

356
00:42:54,873 --> 00:42:56,613
Also, due to the Fresnel effect,

357
00:42:56,993 --> 00:43:08,135
horizontal refractions are emphasized, enhancing the smoothing effect.

358
00:43:08,275 --> 00:43:10,035
And next I would like to talk a bit about lighting.

359
00:43:11,974 --> 00:43:16,377
The parameters we use for lighting are based on real-world parameters.

360
00:43:16,897 --> 00:43:21,300
By doing this, it's easy to compare and contrast in-game lighting with real-world lighting,

361
00:43:21,320 --> 00:43:23,461
so that we can create lights easily.

362
00:43:27,383 --> 00:43:31,626
The main units of measurement that our artists use to create light

363
00:43:31,686 --> 00:43:35,248
are luminous flux, illuminance, and luminance.

364
00:43:36,248 --> 00:43:38,750
Also, the color of light is adjusted by using color temperature.

365
00:43:44,354 --> 00:43:49,837
Illuminance is used for the sky and sun, luminous flux is used for artificial lights and flame,

366
00:43:50,537 --> 00:43:58,361
and luminance is used for monitors and other self-imaging models.

367
00:43:58,881 --> 00:44:02,903
Light attenuation is simulated by using physically based techniques.

368
00:44:02,963 --> 00:44:09,446
Therefore, when using a point light source, physically based attenuation is calculated using inverse square attenuation.

369
00:44:09,506 --> 00:44:11,467
This is made possible only because we're using LWF.

370
00:44:12,986 --> 00:44:19,611
Also, spotlights, etc., are placed like their real-world counterparts.

371
00:44:20,732 --> 00:44:23,494
The more narrow the light, the brighter it gets.

372
00:44:23,734 --> 00:44:27,076
And this sort of light can be simulated easily by adjusting the light distribution.

373
00:44:30,078 --> 00:44:33,801
Ambient lighting is used to replicate bounced light.

374
00:44:34,421 --> 00:44:37,143
The value of bounced light varies depending on the direction,

375
00:44:38,564 --> 00:44:40,306
and we set many of them within space.

376
00:44:43,294 --> 00:44:50,537
Here's an example of ambient light placement.

377
00:44:50,577 --> 00:44:53,239
Skylight is based primarily on a sky simulation.

378
00:44:53,699 --> 00:44:56,580
This contributes to the ambient light.

379
00:44:57,961 --> 00:45:00,723
Here's an example of what the passage of time looks like.

380
00:45:02,323 --> 00:45:05,205
This is what it would look like during morning.

381
00:45:06,786 --> 00:45:07,966
This is evening.

382
00:45:10,368 --> 00:45:11,348
And this would be night.

383
00:45:16,090 --> 00:45:20,931
The scattering effect of the atmosphere is also very important, and this has been replicated in the engine.

384
00:45:29,875 --> 00:45:33,496
And now we'd like to give a brief demonstration of the 24-hour day-night cycle.

385
00:45:37,956 --> 00:45:43,280
Camera parameters and color correction for each phase of the day is set to specific key values.

386
00:45:43,601 --> 00:45:51,087
For example, afternoon would use a high exposure,

387
00:45:51,207 --> 00:45:53,109
while night would use a lower exposure.

388
00:45:53,669 --> 00:45:57,412
Furthermore, when it becomes night, the color balance is made cooler and bluer.

389
00:46:17,755 --> 00:46:26,440
And the auto-exposure used in Fox has been adjusted to only focus on lighting.

390
00:46:26,460 --> 00:46:31,363
This kind of exposure is not real by any means, but it does have its uses when creating a game.

391
00:46:33,204 --> 00:46:36,866
Normally, whatever image is seen by the camera determines the exposure.

392
00:46:37,967 --> 00:46:40,929
However, this exposure is influenced too much by the material's brightness,

393
00:46:41,169 --> 00:46:43,270
and the resulting image looks like an amateur photograph.

394
00:46:47,992 --> 00:46:50,277
So, let's take a look at a real-life demonstration.

395
00:46:52,160 --> 00:46:56,027
This movie was taken by a camera with auto-exposure.

396
00:46:56,609 --> 00:46:58,091
When zoomed in close, the black.

397
00:47:02,612 --> 00:47:06,654
Cameras are able to distinguish between very black and very white things, but a camera cannot.

398
00:47:07,495 --> 00:47:16,620
A camera is not able to distinguish whether an object is bright because it's white, or just because it's being lit up.

399
00:47:16,920 --> 00:47:18,801
Objects that are very black are also the same.

400
00:47:19,081 --> 00:47:27,146
By having the exposure focus only on the lighting element, hardly any influence comes from the material's color, and the result is a correct exposure.

401
00:47:27,667 --> 00:47:30,228
By doing this, we are able to create a stable exposure.

402
00:47:37,142 --> 00:47:42,105
The gain camera is set with parameters that a real-world camera uses,

403
00:47:42,605 --> 00:47:46,968
such as exposure, focal length, shutter speed, aperture, and so on.

404
00:47:47,788 --> 00:47:52,051
Shutter speed influences motion blur, and aperture influences depth of field.

405
00:47:53,272 --> 00:47:55,533
Exposure is set by the exposure value.

406
00:47:56,754 --> 00:47:59,755
In order to simplify exposure settings,

407
00:47:59,795 --> 00:48:02,517
shutter speed and aperture do not influence the exposure.

408
00:48:09,686 --> 00:48:11,206
Other basic features exist as well.

409
00:48:11,967 --> 00:48:14,747
For example, motion blur, bloom, depth of field,

410
00:48:14,967 --> 00:48:16,528
effective focal length, and others.

411
00:48:16,988 --> 00:48:21,409
We started using effective focal length for the first time on this project.

412
00:48:24,650 --> 00:48:26,891
These images show, from the top left,

413
00:48:27,011 --> 00:48:32,713
depth of field, motion blur, flare, and color correction.

414
00:48:32,733 --> 00:48:35,233
When using color correction, we use a 3D lookup table.

415
00:48:40,176 --> 00:48:43,919
And now as you can see here, depending on where

416
00:48:43,959 --> 00:48:46,240
the camera's focus is, the focal length changes.

417
00:48:46,260 --> 00:48:50,142
So you can see it changing focus here.

418
00:48:53,344 --> 00:48:55,585
In other words, the field of view changes.

419
00:48:55,685 --> 00:48:57,066
And here we have an example of a movie

420
00:48:57,106 --> 00:48:59,988
with the focal length changing in real life.

421
00:49:09,274 --> 00:49:23,911
So this is an actual movie of real-life footage.

422
00:49:24,251 --> 00:49:27,535
And here's the same example replicated in the Fox Engine.

423
00:49:36,451 --> 00:49:40,719
All right, and that concludes this section of the presentation.

424
00:49:40,860 --> 00:49:45,068
Now I'd like to hand the mic over to Junji Tago, who will talk about our graphics engine.

425
00:49:58,684 --> 00:50:02,706
The artists have talked about lighting, shaders, asset creation, and the like.

426
00:50:02,806 --> 00:50:05,387
How exactly does the Fox engine actually do all these things?

427
00:50:07,448 --> 00:50:13,271
The rendering method Fox uses is deferred rendering.

428
00:50:14,111 --> 00:50:18,473
One reason for using deferred rendering is that we wanted to be able to support a large number of lights.

429
00:50:21,965 --> 00:50:25,326
Another is to keep a consistent look for both the characters and the environment,

430
00:50:25,406 --> 00:50:34,270
making the characters seem immersed in the environment.

431
00:50:34,311 --> 00:50:36,872
Here are the steps taken in deferred rendering by the Fox engine.

432
00:50:39,693 --> 00:50:42,674
First of all, the G-Buffer is generated with geometry to render.

433
00:50:44,635 --> 00:50:48,317
The G-Buffer stores diffuse albedo, normal, velocity, depth.

434
00:50:49,047 --> 00:50:54,352
specular albedo, roughness, translucency, and material ID.

435
00:50:59,536 --> 00:51:06,222
The lighting is based on the normal, specular albedo, roughness, translucency, and material ID.

436
00:51:06,242 --> 00:51:14,909
The kinds of lights that are supported in FOX are sunlight, ambient lights, point lights, and spot lights.

437
00:51:18,306 --> 00:51:22,050
The ambient light is used as light and stored to the light accumulation buffer.

438
00:51:24,612 --> 00:51:27,915
Diffuse and specular are stored separately in the light accumulation buffer.

439
00:51:34,000 --> 00:51:37,864
The lighting result is generated by combining the light accumulation buffer and diffuse

440
00:51:37,944 --> 00:51:38,284
albedo.

441
00:51:40,686 --> 00:51:42,428
Fog is then combined with the lighting result.

442
00:51:44,929 --> 00:51:49,631
Finally, in post-processing, motion blur, depth of field, tone mapping, and so on are

443
00:51:49,671 --> 00:51:51,491
calculated and used in the final output.

444
00:51:54,552 --> 00:51:58,893
During tone mapping, auto-exposure is applied by referring to the diffuse element stored

445
00:51:58,933 --> 00:52:00,114
in the light accumulation buffer.

446
00:52:02,595 --> 00:52:06,736
By only referring to the diffuse element, we are able to achieve a stable auto-exposure.

447
00:52:11,580 --> 00:52:14,702
The lighting model is based on the familiar Blinn-Fong model.

448
00:52:18,164 --> 00:52:21,366
The material parameters are determined from references, such as photographs.

449
00:52:24,308 --> 00:52:27,970
The parameters that are able to be extracted from references are the parameters we chose.

450
00:52:30,272 --> 00:52:33,373
Therefore, we use a model that has diffuse and specular separated.

451
00:52:34,075 --> 00:52:41,662
For diffuse, we use diffuse albedo, and for specular, we use specular albedo and roughness as material parameters.

452
00:52:44,925 --> 00:52:48,228
Diffuse albedo is created from photographs captured in linear space.

453
00:52:51,551 --> 00:52:57,957
Specular is created from the refraction index of materials or from photographs captured from various light angles, like the picture on the right.

454
00:53:01,141 --> 00:53:03,842
Specular is generated from the roughness and then normalized.

455
00:53:04,302 --> 00:53:06,023
This keeps the highlights looking natural.

456
00:53:09,124 --> 00:53:12,085
We also support translucent material in the deferred rendering model.

457
00:53:12,105 --> 00:53:17,207
All lighting shaders have support for translucency.

458
00:53:24,541 --> 00:53:29,643
The reason why we support translucency in our lighting model is because characters play an important role in our games.

459
00:53:32,944 --> 00:53:36,905
Also, subsurface scattering is aggressively approximated, evading a potential bottleneck.

460
00:53:39,806 --> 00:53:42,246
This approximation is inspired by half-Lambert shading.

461
00:53:44,347 --> 00:53:48,528
Some examples that translucency is used for are skin, hair, cloth, and vegetation.

462
00:53:52,468 --> 00:53:55,510
And here is an example of skin using translucency.

463
00:53:55,690 --> 00:54:01,293
This is with translucency off, and with it on.

464
00:54:01,313 --> 00:54:03,354
You can see the softness of the shadows near his nose.

465
00:54:05,395 --> 00:54:11,638
So off, and on.

466
00:54:11,879 --> 00:54:12,999
Here's an example using hair.

467
00:54:13,419 --> 00:54:15,040
This image is with translucency off.

468
00:54:16,364 --> 00:54:19,887
and with it on.

469
00:54:19,907 --> 00:54:22,309
You can see how the light is shown through the hair.

470
00:54:24,331 --> 00:54:26,272
So off, and on.

471
00:54:32,197 --> 00:54:34,819
In deferred rendering, the number of material parameters

472
00:54:34,899 --> 00:54:36,120
stored in the G-Buffer is limited.

473
00:54:38,102 --> 00:54:39,523
In order to overcome this limitation,

474
00:54:39,723 --> 00:54:41,705
we write the material ID to the G-Buffer,

475
00:54:42,085 --> 00:54:43,987
and during lighting, the parameter texture

476
00:54:44,027 --> 00:54:45,728
is then referenced from the material ID.

477
00:54:48,127 --> 00:54:50,948
For each unique material, the parameters hold different values.

478
00:54:53,289 --> 00:54:59,613
The stored parameters are ones related to Fresnel and translucency and specular color.

479
00:55:00,033 --> 00:55:05,876
In the figure shown, all models are the same, but each has a different material ID.

480
00:55:06,676 --> 00:55:10,858
Only by changing the material ID, we are able to change the type of metal the object is.

481
00:55:14,387 --> 00:55:16,929
Since specular color is also stored to the material texture,

482
00:55:17,189 --> 00:55:19,531
the colored specular particular to the metal is shown.

483
00:55:26,956 --> 00:55:29,038
We are able to achieve a natural specular look

484
00:55:29,198 --> 00:55:30,459
just by adjusting the roughness.

485
00:55:33,061 --> 00:55:35,662
The images on the top and bottom have the same material ID,

486
00:55:35,923 --> 00:55:36,703
but different roughness.

487
00:55:38,324 --> 00:55:39,525
The guns on the top are glossy,

488
00:55:39,845 --> 00:55:41,426
and the guns on the bottom have a matte surface.

489
00:55:47,968 --> 00:55:52,211
Roughness is stored to the G-Buffer, so by changing the roughness after the G-Buffer renders,

490
00:55:52,591 --> 00:55:54,792
it is possible and easy to produce some effects.

491
00:55:57,214 --> 00:56:02,017
By lowering the value of the roughness, the entire screen takes on a wet look.

492
00:56:09,282 --> 00:56:11,703
Using deferred rendering does pose one big problem.

493
00:56:12,083 --> 00:56:14,005
It only supports a single lighting model.

494
00:56:17,106 --> 00:56:22,788
In order to produce various shaders, we have to tweak the value of the G-buffer.

495
00:56:23,828 --> 00:56:29,110
Some shaders that have tweaked values are eyes, anisotropic specular surfaces, and view-dependent

496
00:56:29,150 --> 00:56:33,032
roughness.

497
00:56:33,112 --> 00:56:36,133
These calculations are not accurate, but cause no practical problems.

498
00:56:38,013 --> 00:56:39,414
This image shows eyes drawn with the eye shader off.

499
00:56:43,456 --> 00:56:44,077
and with it on.

500
00:56:44,177 --> 00:56:49,801
If you look at the image of the eye on the bottom left,

501
00:56:50,321 --> 00:56:53,544
you can see the refraction in the eye.

502
00:56:56,026 --> 00:57:02,911
So off and on.

503
00:57:04,352 --> 00:57:07,094
The left image here has anisotropic specular disabled,

504
00:57:07,515 --> 00:57:08,916
while the center and right images

505
00:57:08,976 --> 00:57:10,737
have anisotropic specular enabled.

506
00:57:14,335 --> 00:57:18,817
When the G-buffer is generated, specular albedo is tweaked to take the shape of anisotropic

507
00:57:18,837 --> 00:57:20,318
specular, causing it to look real.

508
00:57:22,939 --> 00:57:24,940
This method is a practical way of achieving this look.

509
00:57:29,762 --> 00:57:31,783
This image shows the results of view-dependent lab work.

510
00:57:37,756 --> 00:57:40,459
Depending on the angle between the view and normal vectors,

511
00:57:40,900 --> 00:57:47,748
the specular value is sharper the more parallel the view vector is to the surface.

512
00:57:48,008 --> 00:57:50,271
Here is an image of the roughness value stored in the G-Buffer.

513
00:57:52,654 --> 00:57:53,695
Looking at the wall on the right,

514
00:57:54,035 --> 00:57:56,718
you can see how the roughness gets darker the further back you look.

515
00:58:03,747 --> 00:58:07,049
We use light probes for ambient lighting, and they are placed by the artist.

516
00:58:08,530 --> 00:58:10,451
The effective range is set by a bounding box.

517
00:58:13,313 --> 00:58:17,075
Cube maps are captured in the level editor, and irradiance is generated from the cube

518
00:58:17,115 --> 00:58:17,375
maps.

519
00:58:18,116 --> 00:58:22,078
Irradiance is stored as second-order spherical harmonics.

520
00:58:24,499 --> 00:58:27,921
Light probes are rendered as light when the light accumulation buffer is generated.

521
00:58:30,184 --> 00:58:33,306
Since there are many light probes, they are rendered in quarter resolution.

522
00:58:36,328 --> 00:58:44,812
The ambient light can also be blended between probes, so the boundary between them is quite smooth.

523
00:58:44,872 --> 00:58:49,415
As the sky plays a very important role for the ambient lighting, we simulate atmospheric scattering.

524
00:58:51,716 --> 00:58:54,958
The results of the scattering simulation become the actual sky in fog.

525
00:58:56,846 --> 00:59:00,587
The sky is included when the cube maps get captured for light probes,

526
00:59:02,008 --> 00:59:03,869
and these results are then stored in the light probe.

527
00:59:08,991 --> 00:59:10,951
Ambient light supports the day-night cycle.

528
00:59:12,812 --> 00:59:16,073
Light probes exist for major transition points in a 24-hour date.

529
00:59:16,474 --> 00:59:19,355
The values between these points are interpolated.

530
00:59:21,896 --> 00:59:23,737
Ambient light also supports the weather cycle.

531
00:59:25,925 --> 00:59:27,967
Light probes exist for each major weather condition.

532
00:59:29,670 --> 00:59:31,913
The weather is represented as a one-dimensional parameter,

533
00:59:31,953 --> 00:59:34,736
from sunny to cloudy to rainy to stormy.

534
00:59:37,080 --> 00:59:39,343
The values between weather conditions are also interpolated.

535
00:59:52,797 --> 00:59:55,138
Here is a short demonstration of how cube maps are captured.

536
00:59:59,081 --> 01:00:02,103
You can see how bright the environment became when the cube map was generated.

537
01:00:12,709 --> 01:00:17,072
The trailer we released last year of Ground Zeroes took place at night, in the rain.

538
01:00:18,450 --> 01:00:23,317
Here is a demonstration of the same trailer, but taking place during the day and sunny.

539
01:01:00,068 --> 01:01:03,369
All the materials used have not been changed, only the light.

540
01:01:06,731 --> 01:01:11,173
Since the material parameters are correct, the visuals do not break down even when the light is changed.

541
01:02:17,867 --> 01:02:18,888
Kept you waiting, huh?

542
01:02:20,848 --> 01:02:22,289
Sorry, my snake voice was not very good.

543
01:02:35,254 --> 01:02:36,014
All right.

544
01:02:37,434 --> 01:02:41,536
Up to this point, our presentation has focused on the digital or technical aspects of game creation.

545
01:02:42,055 --> 01:02:46,358
But I'd like to shift gears a bit and turn our focus back to the analog, or real world.

546
01:02:47,139 --> 01:02:52,222
To get physically accurate assets, artists need to observe and have knowledge of our actual physical world.

547
01:02:52,742 --> 01:02:58,286
We need to know things about lighting, cameras, surface textures, and how they are represented.

548
01:02:58,346 --> 01:03:03,269
Even in simply capturing textures or models,

549
01:03:03,369 --> 01:03:06,251
artists need a thorough understanding of the input devices used.

550
01:03:17,674 --> 01:03:22,278
But more importantly, it is good to remember that we have many real-world examples within reach.

551
01:03:23,519 --> 01:03:28,663
For example, on the left is a shirt that one of our staff cut up in order to understand the construction of clothing.

552
01:03:29,244 --> 01:03:32,246
This was very beneficial in understanding clothing patterns.

553
01:03:32,326 --> 01:03:34,768
Even though we have a marvelous designer to do most of the dirty work,

554
01:03:34,848 --> 01:03:37,690
it is still a great way to understand modeling on a deeper level.

555
01:03:41,948 --> 01:03:46,233
And the dirty yellow shirt in the center was us trying to simulate Chico's muddy clothes.

556
01:03:46,613 --> 01:03:51,118
An artist actually went into the park in the middle of the rain and played in the mud in order to do this.

557
01:03:52,280 --> 01:03:57,065
And you could only imagine the look of utter horror on the face of this poor old woman who happened to see him doing this.

558
01:04:00,629 --> 01:04:05,352
And on the right, we have the top of an artist's desk.

559
01:04:05,372 --> 01:04:09,014
There are various items scattered about, branches, rocks, and the like, and these are used to

560
01:04:09,054 --> 01:04:10,575
study textures.

561
01:04:11,315 --> 01:04:15,237
Ironically, the more that technology evolves, the more we have to study and understand our

562
01:04:15,257 --> 01:04:16,078
physical surroundings.

563
01:04:16,098 --> 01:04:21,821
In that way, you could say that technology is a very important tool for helping us understand

564
01:04:21,881 --> 01:04:22,421
our real world.

565
01:04:26,749 --> 01:04:31,871
Even with regard to lighting, we've had to re-familiarize ourselves in the way that real light works in the real world.

566
01:04:32,491 --> 01:04:40,234
The majority of our artists have an idea of how lighting basics like key, fill, and rim lighting work in a CG environment, but not necessarily in the real world.

567
01:04:44,956 --> 01:04:52,599
But luckily, we had lighting director Yoshiharu Nishiyama, famous for his work on commercials and movies, who blessed us with his expertise.

568
01:04:53,444 --> 01:04:57,368
He demonstrated various real-world lighting techniques to our team

569
01:04:58,189 --> 01:05:00,371
and taught us how to use these techniques in our game.

570
01:05:01,753 --> 01:05:05,396
He has been to our studio to see our lighting in action within the Fox engine

571
01:05:06,057 --> 01:05:07,839
and has given us useful guidance.

572
01:05:13,519 --> 01:05:16,321
And here we see some pictures from a lighting study.

573
01:05:16,441 --> 01:05:20,582
And you can see that simply adjusting the light dramatically changes the mood and feel

574
01:05:20,602 --> 01:05:22,603
of the scene.

575
01:05:22,683 --> 01:05:27,105
As mentioned previously, it's interesting how advancements in game lighting have necessitated

576
01:05:27,165 --> 01:05:30,626
a deeper understanding of how real-life lighting materials and reflectance works.

577
01:05:32,807 --> 01:05:36,930
But it's also important to note that even though we can mimic reality,

578
01:05:36,950 --> 01:05:40,333
creating captivating visuals may sometimes necessitate breaking from reality

579
01:05:40,953 --> 01:05:42,274
in order to exaggerate certain things.

580
01:05:44,376 --> 01:05:47,858
Just because something is physically correct and realistic

581
01:05:47,898 --> 01:05:49,099
doesn't mean that it'll look good.

582
01:05:50,260 --> 01:05:52,642
Therefore, we shouldn't always strive for complete realism,

583
01:05:53,582 --> 01:05:55,984
but by using real-world simulations as a starting point,

584
01:05:56,504 --> 01:05:59,347
our artists can use their skills to meet their visual goals in a convincing way.

585
01:06:02,627 --> 01:06:07,208
So, what I'm trying to say is that in order to get realistic, physically accurate output,

586
01:06:07,248 --> 01:06:08,649
you need to study the real world.

587
01:06:09,249 --> 01:06:13,350
Observe with your eyes, capture with cameras and 3D scanners, measure the details of the

588
01:06:13,370 --> 01:06:13,950
world around you.

589
01:06:14,571 --> 01:06:17,512
To reproduce the real world, you need to study the real world.

590
01:06:18,403 --> 01:06:22,565
At the same time, however, creating captivating visuals is an artist's primary job.

591
01:06:23,025 --> 01:06:27,448
Perfectly replicating the real world may not necessarily be what a game needs.

592
01:06:27,548 --> 01:06:30,169
So to make a quality product, an artist's eye is essential.

593
01:06:30,189 --> 01:06:32,491
Simply reproducing reality would only be a traced image.

594
01:06:32,511 --> 01:06:35,432
So basically, yes, you really need an artist's eye in order to do something great.

595
01:06:49,949 --> 01:06:55,730
And these two aspects, realism and artistic quality, within the context of a game, are

596
01:06:55,750 --> 01:06:58,791
what we mean by photorealism through the eyes of a fox.

597
01:07:01,411 --> 01:07:02,052
Thank you for listening.

598
01:07:14,834 --> 01:07:15,974
But wait, there's more.

599
01:07:17,121 --> 01:07:21,325
Everyone, please welcome the studio head of Kojima Productions, LA studio, Tom Sekine.

600
01:07:21,345 --> 01:07:27,872
Applause

601
01:07:32,757 --> 01:07:36,801
Hello everyone. This is kind of different topics.

602
01:07:37,322 --> 01:07:38,963
Kojima Productions has been well known for

603
01:07:40,234 --> 01:07:43,517
always make high quality products and always surprise the people,

604
01:07:45,099 --> 01:07:46,961
to the excited people,

605
01:07:47,642 --> 01:07:48,963
multi-generation,

606
01:07:49,764 --> 01:07:50,805
multi-generation,

607
01:07:53,248 --> 01:07:56,011
multi-generation of all those parents and kids,

608
01:07:56,572 --> 01:07:57,573
my generation.

609
01:07:58,374 --> 01:07:58,614
Anyway,

610
01:08:00,824 --> 01:08:03,665
There was talk about Kojima Arts production has been built

611
01:08:05,205 --> 01:08:06,246
in Los Angeles area.

612
01:08:06,466 --> 01:08:10,067
And as you've seen, all those recruitment advertisements

613
01:08:10,167 --> 01:08:12,628
showing in our website and also Gamasutras.

614
01:08:13,628 --> 01:08:16,209
However, this is, as of today, it is official.

615
01:08:17,009 --> 01:08:21,250
And our studio is really building Los Angeles area.

616
01:08:22,651 --> 01:08:24,011
And this is our new logo.

617
01:08:25,531 --> 01:08:27,692
Red Fox was born from the fox.

618
01:08:35,635 --> 01:08:37,317
Kojima production philosophy is

619
01:08:39,519 --> 01:08:41,641
surprise and also excited people

620
01:08:41,921 --> 01:08:43,883
with a high value entertainment product

621
01:08:44,443 --> 01:08:46,105
surfaces the generation boundaries

622
01:08:46,625 --> 01:08:49,128
and always making a really high quality product

623
01:08:49,188 --> 01:08:50,109
bring to the users.

624
01:08:51,150 --> 01:08:53,512
And also create a product with a critical acclaim

625
01:08:54,012 --> 01:08:56,215
and also succeeding commercially.

626
01:08:57,276 --> 01:08:58,897
This is the Kojima production philosophy.

627
01:08:59,879 --> 01:09:08,098
So we inherited this core philosophy and tried building a unique studio and a new culture in Los Angeles.

628
01:09:12,948 --> 01:09:17,172
So our vision is create the highest quality interactive entertainment,

629
01:09:17,492 --> 01:09:19,054
which brings a deep emotional feeling.

630
01:09:20,015 --> 01:09:20,856
This is a must.

631
01:09:22,037 --> 01:09:24,679
This is a combination of all those new technologies

632
01:09:25,220 --> 01:09:25,700
and art,

633
01:09:26,381 --> 01:09:29,464
and also a unique game design element.

634
01:09:29,905 --> 01:09:33,228
To bring in all those three components

635
01:09:33,708 --> 01:09:34,329
is equally...

636
01:09:36,088 --> 01:09:40,132
putting together to make a really great, high-value entertainment product.

637
01:09:41,574 --> 01:09:44,837
Without touching people's emotions, we cannot survive.

638
01:09:44,938 --> 01:09:47,681
We cannot keep surprising people

639
01:09:48,181 --> 01:09:49,443
to the next generation.

640
01:09:50,795 --> 01:09:54,116
So our mission is to become the top studio in the world.

641
01:09:54,917 --> 01:09:57,718
This is very ambitious, but once we're building up

642
01:09:58,498 --> 01:10:00,879
very competitive market in the Los Angeles area,

643
01:10:01,719 --> 01:10:03,440
we have to become the number one,

644
01:10:03,980 --> 01:10:05,920
one of the best development studios,

645
01:10:07,001 --> 01:10:09,242
as like Parents Studio and Kusuma Production Japan.

646
01:10:11,282 --> 01:10:13,043
Our value is quality.

647
01:10:13,883 --> 01:10:17,344
Quality is so important, not compromise to the quality.

648
01:10:19,679 --> 01:10:22,301
Game experience comes first.

649
01:10:23,482 --> 01:10:24,803
This is no compromise.

650
01:10:25,643 --> 01:10:28,125
And then the collaboration is so important.

651
01:10:29,586 --> 01:10:33,529
Always cutting edge technology and also innovative art style

652
01:10:33,769 --> 01:10:37,912
is keep changing all art styles and touch the people's feeling,

653
01:10:38,172 --> 01:10:38,853
emotional touch.

654
01:10:39,753 --> 01:10:42,355
And also evolving interactive design elements

655
01:10:43,176 --> 01:10:45,718
by promoting a creative environment.

656
01:10:46,498 --> 01:10:49,200
So technology, the programming.

657
01:10:50,204 --> 01:10:53,947
and art and design and the production management.

658
01:10:54,367 --> 01:10:56,229
Those components are quite important for us

659
01:10:56,269 --> 01:10:59,051
and the collaboration work is very important to us.

660
01:11:01,854 --> 01:11:04,636
So we are hiring the best people possible

661
01:11:05,277 --> 01:11:07,359
and also give the best creative environment.

662
01:11:10,582 --> 01:11:13,084
So we are building our Los Angeles studio

663
01:11:13,184 --> 01:11:17,328
in the South Hurricanes campus in Playa Vista, Los Angeles.

664
01:11:18,823 --> 01:11:22,064
Studio design concept is open communication

665
01:11:22,565 --> 01:11:23,405
and collaboration.

666
01:11:24,305 --> 01:11:27,407
The space is about 30,000 square footage.

667
01:11:28,167 --> 01:11:31,589
We'll have a testing room and also a screening room.

668
01:11:35,671 --> 01:11:39,352
So this is the screening room and the next one.

669
01:11:41,233 --> 01:11:41,833
We're hiring.

670
01:11:44,975 --> 01:11:45,795
So we are hiring.

671
01:11:46,716 --> 01:11:47,856
Please join us.

672
01:11:49,657 --> 01:11:52,239
You guys can buy our booth in Recruitment Events space in

673
01:11:52,279 --> 01:11:53,419
the South Hall, I believe.

674
01:11:54,440 --> 01:11:57,502
The booth number is CP2308.

675
01:11:59,923 --> 01:12:01,204
We really need good people.

676
01:12:01,744 --> 01:12:05,026
And we really want to push the next envelope to

677
01:12:06,146 --> 01:12:07,107
make a great product.

678
01:12:07,667 --> 01:12:09,708
So please come to join us.

679
01:12:10,769 --> 01:12:11,349
Thank you very much.

680
01:12:11,649 --> 01:12:11,910
That's all.

681
01:12:24,008 --> 01:12:32,810
Unfortunately, we're not recruiting at Moby Dick Studios.

682
01:12:33,010 --> 01:12:35,051
This concludes our session for the Fox Engine.

683
01:12:35,531 --> 01:12:38,052
Thank you for waiting and checking out the session with us.

684
01:12:46,772 --> 01:12:48,412
In 2009, I gave a keynote speech titled,

685
01:12:48,492 --> 01:12:51,093
Solid Game Design, Making the Impossible Possible.

686
01:12:51,553 --> 01:12:53,094
Maybe some of our guests today attended

687
01:12:53,154 --> 01:12:54,394
or listened to the presentation.

688
01:12:55,374 --> 01:12:56,975
And maybe you have checked it out that time too.

689
01:13:14,888 --> 01:13:19,971
And at the keynote, I presented the fact how to make sure that technology is moving forward

690
01:13:20,011 --> 01:13:24,455
and how to make the idea move alongside the point where the advancement of technology

691
01:13:24,495 --> 01:13:28,978
and hardware is used as a ladder to make the impossible possible.

692
01:13:41,426 --> 01:13:44,628
I stated that I used an idea on top of a platform

693
01:13:45,148 --> 01:13:48,370
to make sure that we rose above with the game design

694
01:13:48,510 --> 01:13:49,271
and move from there.

695
01:13:49,291 --> 01:13:53,734
At the time, I said that instead of that,

696
01:13:53,854 --> 01:13:57,176
we should use Western-style technology

697
01:13:57,216 --> 01:13:58,497
and put a platform for technology

698
01:13:58,597 --> 01:14:01,499
and put a platform for game design on top of that platform

699
01:14:01,519 --> 01:14:03,700
to make a more accordant game.

700
01:14:06,282 --> 01:14:11,907
And finally, I mentioned, we would use the advancement in technology from the West to further elevate ourselves as well.

701
01:14:11,927 --> 01:14:22,656
It's been four years since that day, and I believe we have built that ladder we call the Fox Engine.

702
01:14:23,197 --> 01:14:28,822
It's been four years since that day, and I believe we have built that ladder we call the Fox Engine.

703
01:14:30,083 --> 01:14:31,804
It's not about making the game design impossible.

704
01:14:34,164 --> 01:14:38,292
We want to make technology impossible, but we want to put game design on top of it,

705
01:14:38,332 --> 01:14:42,179
and aim to make games that are more interesting and more high-level.

706
01:14:44,160 --> 01:14:48,601
From here on out, we will make the impossible possible using game design only.

707
01:14:49,001 --> 01:14:51,261
We'll make the impossible possible with technology,

708
01:14:51,782 --> 01:14:55,362
and then add on good ideas using good sense to formulate solid game design.

709
01:15:12,890 --> 01:15:27,240
And on top of that, not just technology, but we would like to incorporate storytelling ideas and anything that would really work with games from the filming industry and novels as well, and take that and move forward and elevate ourselves that way too.

710
01:15:34,697 --> 01:15:38,259
And we take in these things because we're not epic Metal Gear Solid.

711
01:15:38,740 --> 01:15:40,160
It's because we're Metal Gear Solid.

712
01:15:40,180 --> 01:15:46,344
Oh, and I also forgot to mention that we're hiring as well.

713
01:15:46,444 --> 01:15:49,926
Please come by if you want to help us make a new MGS on Fox Engine.

714
01:16:04,044 --> 01:16:07,605
Thank you for coming to this conference. Thank you. Thank you so much.

715
01:16:18,950 --> 01:16:19,170
APPLAUSE

716
01:16:19,190 --> 01:16:23,252
Okay, so it looks like we have a few minutes left, so we're going to have a quick Q&A.

717
01:16:24,273 --> 01:16:27,954
If we could strictly keep it technical, we'd love to answer your questions.

718
01:16:29,135 --> 01:16:31,076
So Josh, go ahead and please take over here.

719
01:16:32,380 --> 01:16:34,382
I think we have some microphones set up on the side over here.

720
01:16:34,442 --> 01:16:35,943
So if anybody wants to ask any questions

721
01:16:36,163 --> 01:16:37,524
about technical thing, we got somebody.

722
01:16:37,764 --> 01:16:38,224
OK, go ahead.

723
01:16:38,905 --> 01:16:39,145
Hello.

724
01:16:40,086 --> 01:16:42,047
Very impressive presentation.

725
01:16:42,147 --> 01:16:42,527
Thank you.

726
01:16:43,488 --> 01:16:44,448
First question, my.

727
01:16:44,849 --> 01:16:46,510
Can you speak a little bit closer to the microphone?

728
01:16:48,051 --> 01:16:48,291
OK.

729
01:16:52,734 --> 01:16:56,737
My first question is, since you use such a big ranger,

730
01:16:57,197 --> 01:17:01,820
but you focus on the lighting to do the adaptation.

731
01:17:02,575 --> 01:17:09,181
Then how can you avoid the image in some place, it's pure black and affect the gameplay?

732
01:17:10,643 --> 01:17:12,544
I didn't catch the last part of the question, I'm sorry.

733
01:17:12,865 --> 01:17:15,988
Okay, it's like that. The range is so big.

734
01:17:16,248 --> 01:17:16,448
Okay.

735
01:17:16,548 --> 01:17:21,032
And you've used the light as a reference for the eye application.

736
01:17:21,974 --> 01:17:29,679
Then, it may cause the problem is the image is super dark and the player cannot play it.

737
01:17:30,100 --> 01:17:32,501
It's the main problem when we develop the game.

738
01:17:34,563 --> 01:17:41,448
The artist feel, ok, it's ok, the image looks good, but for the game player, they can't play it.

739
01:17:41,528 --> 01:17:44,871
Because in some players, for example, the NPC is too dark.

740
01:17:45,511 --> 01:17:48,775
Okay, let me kind of rephrase what maybe I'm thinking you're asking.

741
01:17:49,456 --> 01:17:53,720
If we keep light real, sometimes we might run into places that are too dark,

742
01:17:54,241 --> 01:17:55,582
and that doesn't suit the game.

743
01:17:55,983 --> 01:17:58,666
And how do we go about overcoming that, is what you're asking?

744
01:17:58,886 --> 01:18:00,228
Yeah, on the technique side.

745
01:18:00,588 --> 01:18:01,929
Okay, let me kind of ask real quick.

746
01:18:07,424 --> 01:18:10,885
If you place a light that has a certain reality,

747
01:18:11,085 --> 01:18:13,646
if it doesn't match the game,

748
01:18:13,666 --> 01:18:16,006
for example, there are some parts that are too dark,

749
01:18:16,066 --> 01:18:17,467
and it doesn't match the gameplay,

750
01:18:17,487 --> 01:18:18,527
so how do you solve that problem?

751
01:18:18,547 --> 01:18:19,047
Is there a way?

752
01:18:19,067 --> 01:18:19,747
Change the level.

753
01:18:19,767 --> 01:18:20,568
Change the level.

754
01:18:20,648 --> 01:18:23,349
And match it to the level design?

755
01:18:23,489 --> 01:18:25,889
Match it to the level that needs the game.

756
01:18:34,697 --> 01:18:42,141
For these kinds of places where the light is too dark in some areas,

757
01:18:42,341 --> 01:18:45,784
we usually talk to the level designers or the game designers who are creating those levels

758
01:18:46,144 --> 01:18:49,246
to make the stage fit with that lighting style.

759
01:18:49,566 --> 01:18:53,068
And it's kind of a back and forth between the lighting designer and the level artist,

760
01:18:53,248 --> 01:18:56,650
or the level designer to get a good level to show.

761
01:18:56,670 --> 01:18:59,272
Does that answer your question?

762
01:18:59,992 --> 01:19:01,273
Okay, I understand. Thank you.

763
01:19:01,513 --> 01:19:02,493
The second question, yes.

764
01:19:04,987 --> 01:19:05,748
I just want to...

765
01:19:06,328 --> 01:19:06,468
No.

766
01:19:06,488 --> 01:19:06,688
Okay.

767
01:19:07,068 --> 01:19:07,268
Okay.

768
01:19:07,288 --> 01:19:07,629
I'm sorry.

769
01:19:07,849 --> 01:19:08,329
Sorry about that.

770
01:19:08,649 --> 01:19:08,929
No.

771
01:19:09,289 --> 01:19:10,570
Over here?

772
01:19:10,610 --> 01:19:10,730
Yeah.

773
01:19:10,830 --> 01:19:11,590
Yeah.

774
01:19:11,630 --> 01:19:13,972
First of all, congratulations on the Fox Engine.

775
01:19:13,992 --> 01:19:14,392
Thank you very much.

776
01:19:14,412 --> 01:19:14,852
It looks really good.

777
01:19:15,572 --> 01:19:21,695
And the second question is, Photoscan looks really cool, but how much detail you have

778
01:19:21,735 --> 01:19:27,198
to sacrifice when you make that model, which is hundreds of thousands of polygons, into

779
01:19:27,298 --> 01:19:29,199
an actually in-game asset?

780
01:19:29,459 --> 01:19:30,180
OK, I understand.

781
01:19:30,220 --> 01:19:32,101
Let me go ahead and repeat the question, if anybody.

782
01:19:32,622 --> 01:19:35,524
He's asking, when generating a model in PhotoScan,

783
01:19:35,564 --> 01:19:37,366
it comes with tons of polygons.

784
01:19:37,586 --> 01:19:39,487
How much detail do we have to sacrifice when actually

785
01:19:39,507 --> 01:19:40,148
getting it in the game?

786
01:19:40,228 --> 01:19:41,009
Yeah, exactly.

787
01:19:41,209 --> 01:19:43,531
I'm asking, when generating a model in PhotoScan,

788
01:19:43,591 --> 01:19:44,812
it comes with tons of polygons.

789
01:19:44,992 --> 01:19:47,054
How much detail do we have to sacrifice when actually

790
01:19:47,094 --> 01:19:48,235
getting it in the game?

791
01:19:48,275 --> 01:19:48,575
Yeah, exactly.

792
01:19:58,463 --> 01:20:09,893
We use a normal map in order and bake the normal map in order to overcome this limitation.

793
01:20:09,913 --> 01:20:10,133
Okay.

794
01:20:10,153 --> 01:20:10,294
Yeah.

795
01:20:22,470 --> 01:20:24,811
I was thinking more about polygon count, exactly.

796
01:20:24,911 --> 01:20:25,231
Oh, okay.

797
01:20:25,511 --> 01:20:27,732
How do you calculate the number of polygons?

798
01:20:27,772 --> 01:20:29,873
The ones that are made by photo scanning?

799
01:20:30,593 --> 01:20:34,775
Yes, the ones that are made by photo scanning are full of polygons.

800
01:20:34,995 --> 01:20:38,056
You mean photo scan model or actual game model?

801
01:20:38,836 --> 01:20:42,718
If you guys want to, so you can ask other questions, we can talk about it later.

802
01:20:42,738 --> 01:20:45,959
Alright, that's okay. We'll probably catch you later then.

803
01:20:46,203 --> 01:20:46,664
All right, cool.

804
01:20:46,684 --> 01:20:47,004
Thank you.

805
01:20:47,044 --> 01:20:47,244
Thank you.

806
01:20:47,284 --> 01:20:47,544
Thank you.

807
01:20:47,764 --> 01:20:50,525
I think we have time for maybe one more, if that's OK.

808
01:20:51,225 --> 01:20:52,185
I think we've got some people lined up.

809
01:20:52,205 --> 01:20:52,545
But go ahead.

810
01:20:53,186 --> 01:20:54,626
Just have a really quick question

811
01:20:54,646 --> 01:20:56,747
about the actual deferred rendering.

812
01:20:57,087 --> 01:20:58,687
Can you speak a little bit closer into the microphone?

813
01:20:58,927 --> 01:21:01,548
I noticed you have a lot of different buffers

814
01:21:01,568 --> 01:21:02,329
for your gbuffer.

815
01:21:02,449 --> 01:21:03,769
How are you actually packing those

816
01:21:04,069 --> 01:21:05,610
before you send those to the graphics card?

817
01:21:06,490 --> 01:21:08,390
SPEAKER 3 IN JAPANESE

818
01:21:08,410 --> 01:21:09,571
SPEAKER 4 IN JAPANESE

819
01:21:16,180 --> 01:21:17,520
You want to answer?

820
01:21:17,540 --> 01:21:18,921
No.

821
01:21:19,001 --> 01:21:20,662
If you cannot talk about it, that's all right.

822
01:21:20,702 --> 01:21:21,342
No, no, no, it's OK.

823
01:21:21,382 --> 01:21:23,363
He's trying to think about how to go about best

824
01:21:23,423 --> 01:21:24,064
answering your question.

825
01:21:26,705 --> 01:21:27,005
All right.

826
01:21:27,045 --> 01:21:27,565
Yo, material ID.

827
01:21:27,605 --> 01:21:30,527
It's got a little bit of a custom head.

828
01:21:31,427 --> 01:21:33,288
Well, first of all, we have the material ID.

829
01:21:33,728 --> 01:21:36,670
And we put a lot of parameters into the material ID.

830
01:21:36,690 --> 01:21:40,332
So that takes away a lot of those other rendering,

831
01:21:40,852 --> 01:21:42,212
makes the rendering pipeline a little bit simpler.

832
01:21:42,232 --> 01:21:44,013
OK, so we're going to eat.

833
01:21:45,697 --> 01:21:46,357
is his answer.

834
01:21:46,957 --> 01:21:52,279
I'm a little more thinking about as like the Crytek engine

835
01:21:52,639 --> 01:21:54,419
packs everything into three buffers.

836
01:21:54,799 --> 01:21:55,019
OK.

837
01:21:56,179 --> 01:21:57,620
I noticed they have six different buffers

838
01:21:57,920 --> 01:21:59,060
for the Fox engine.

839
01:21:59,080 --> 01:22:01,400
Are you packing that into like two or three different G

840
01:22:01,440 --> 01:22:02,181
buffers as well?

841
01:22:02,201 --> 01:22:03,881
So you're using multiple G buffers?

842
01:22:03,901 --> 01:22:05,061
So Crytek uses all of them?

843
01:22:05,081 --> 01:22:05,261
Four.

844
01:22:05,281 --> 01:22:05,401
Four.

845
01:22:05,441 --> 01:22:05,641
Four.

846
01:22:05,681 --> 01:22:10,102
There's four of them.

847
01:22:10,242 --> 01:22:12,083
So we're using four multi-render targets.

848
01:22:13,579 --> 01:22:15,680
We are using four multi-rendered targets.

849
01:22:16,680 --> 01:22:17,680
Is, what are you saying?

850
01:22:19,701 --> 01:22:20,761
That answers my question, actually.

851
01:22:21,681 --> 01:22:22,182
Say again?

852
01:22:22,422 --> 01:22:24,062
That actually perfectly answers my question.

853
01:22:24,162 --> 01:22:24,782
OK, well there we go.

854
01:22:24,802 --> 01:22:26,103
Awesome.

855
01:22:27,143 --> 01:22:28,123
How much time do we have left?

856
01:22:28,143 --> 01:22:32,985
We have like five more minutes left, but if you'd like to.

857
01:22:33,005 --> 01:22:33,765
OK, we can get one more.

858
01:22:33,785 --> 01:22:34,725
And I think this guy's over here.

859
01:22:34,745 --> 01:22:35,065
You go ahead.

860
01:22:35,305 --> 01:22:37,246
I have a question about photo scanning, too.

861
01:22:38,947 --> 01:22:41,627
How you get specular and rawness information

862
01:22:41,687 --> 01:22:43,288
to the photo scanning?

863
01:22:43,650 --> 01:22:44,631
the specular and what else?

864
01:22:44,891 --> 01:22:45,291
Roughness.

865
01:22:46,051 --> 01:22:46,331
Roughness?

866
01:22:46,491 --> 01:22:49,672
We do not use PhotoScan for getting the specular and roughness.

867
01:23:11,540 --> 01:23:12,641
as much as we're going to say.

868
01:23:13,121 --> 01:23:15,463
So it's difficult to get the specular and roughness

869
01:23:15,483 --> 01:23:17,745
from Photoscan, so we don't use Photoscan for that purpose.

870
01:23:20,166 --> 01:23:20,366
OK.

871
01:23:21,927 --> 01:23:24,149
I think that's going to be it for the Q&A session.

872
01:23:24,209 --> 01:23:25,810
So thank you guys for coming out,

873
01:23:26,310 --> 01:23:27,751
and have a good rest of the day.

