1
00:00:05,907 --> 00:00:07,588
Welcome to this presentation.

2
00:00:07,588 --> 00:00:08,929
My name is Anne-Sophie Mongeau,

3
00:00:08,929 --> 00:00:11,630
and I'm a senior sound designer at Hazelight.

4
00:00:11,630 --> 00:00:12,711
And I am Joakim Enik Kruiberg,

5
00:00:12,711 --> 00:00:14,952
technical sound designer at Hazelight.

6
00:00:14,952 --> 00:00:17,434
And today we're both here to talk about

7
00:00:17,434 --> 00:00:18,774
how the Hazelight audio team

8
00:00:18,774 --> 00:00:20,936
developed the soundscape of It Takes Two.

9
00:00:20,936 --> 00:00:23,317
And we will consider both the technical

10
00:00:23,317 --> 00:00:24,718
and the creative challenges

11
00:00:24,718 --> 00:00:26,179
that were brought by the split screen,

12
00:00:26,179 --> 00:00:28,700
but also that were brought by the creative vision

13
00:00:28,700 --> 00:00:29,200
for the game.

14
00:00:31,388 --> 00:00:35,692
Before we get started, let's first acknowledge and give due credit to the members of the

15
00:00:35,692 --> 00:00:37,353
Hazelight audio team.

16
00:00:37,353 --> 00:00:42,256
So everyone on this list has been essential to everything we're going to talk about today.

17
00:00:42,256 --> 00:00:46,839
Myself and Joachim are here as representatives for the team, but this project has truly been

18
00:00:46,839 --> 00:00:48,180
a team effort.

19
00:00:50,434 --> 00:00:53,335
This presentation is divided into two parts.

20
00:00:53,335 --> 00:00:55,956
In the first part, we will talk about some challenges

21
00:00:55,956 --> 00:00:59,038
and found solutions while designing the split screen sound

22
00:00:59,038 --> 00:00:59,758
of It Takes Two.

23
00:00:59,758 --> 00:01:03,420
This includes managing spatialization

24
00:01:03,420 --> 00:01:05,360
and maintaining mixed clarity

25
00:01:05,360 --> 00:01:08,262
through carefully thought out sound design strategies.

26
00:01:08,808 --> 00:01:13,971
The second part will focus on two selected sound design highlights from the game soundscape,

27
00:01:13,971 --> 00:01:17,352
where we will demonstrate our inspiration, our creative vision,

28
00:01:17,352 --> 00:01:21,795
as well as our sound design approaches for those two highlights.

29
00:01:21,795 --> 00:01:25,097
So let's dig in. First of all, what is It Takes Two?

30
00:01:26,744 --> 00:01:30,666
It Takes Two is an action-adventure-platformer-splitscreen co-op game.

31
00:01:30,666 --> 00:01:35,489
That means there are two main characters, Cody and May, played by two separate players.

32
00:01:35,489 --> 00:01:42,734
And the screen will always be split in two, regardless of the players playing in the same room or online.

33
00:01:42,734 --> 00:01:47,597
Cody and May are two human characters who are transformed into dolls at the very beginning of the game.

34
00:01:48,510 --> 00:01:53,516
And this is basically the story of how they navigate this new fantasy slash magical world,

35
00:01:53,516 --> 00:01:57,921
which is based on the real world, in order to get back into their real bodies.

36
00:01:58,389 --> 00:02:04,672
So overall you could describe It Takes Two and its creative vision as somewhere between Toy Story and Honey I Shrunk the Kids

37
00:02:04,672 --> 00:02:09,795
where all the usual everyday objects become huge in comparison to the characters tiny doll size.

38
00:02:09,795 --> 00:02:15,978
In all those objects they come to life, they gain a personality and they play a role in the story

39
00:02:15,978 --> 00:02:18,940
either helping the characters or hindering them towards their goal.

40
00:02:19,560 --> 00:02:24,264
So if you haven't played the game, I want to give you a few examples of how this vision is realized

41
00:02:24,264 --> 00:02:28,227
by showing you a few images of some of the objects or the characters you might meet

42
00:02:28,227 --> 00:02:34,151
throughout the story. You have a vacuum boss and all its vacuum hose tentacles.

43
00:02:34,151 --> 00:02:42,838
You have a talking hammerhead guiding you through the level and is also used as a smashing ability.

44
00:02:42,838 --> 00:02:47,241
A group of gangster squirrels sending you on a mission to kill giant wasps.

45
00:02:49,581 --> 00:02:53,062
The giant wasp queen who is actually an imposter in a wasp costume.

46
00:02:53,062 --> 00:02:59,925
An overly protected baboon determined to trap you into an outer space realm.

47
00:02:59,925 --> 00:03:05,507
A train track turning into an infernal railcar ride.

48
00:03:05,507 --> 00:03:10,850
A parallel kaleidoscope dimension.

49
00:03:10,850 --> 00:03:12,650
Giant evil microphone snakes.

50
00:03:14,600 --> 00:03:16,401
and so much more of that.

51
00:03:16,401 --> 00:03:18,821
So in short, this game presented many challenges,

52
00:03:18,821 --> 00:03:20,902
but also many opportunities for audio.

53
00:03:20,902 --> 00:03:24,042
And among those opportunities and challenges

54
00:03:24,042 --> 00:03:24,942
are the following.

55
00:03:24,942 --> 00:03:27,643
Concerning the split screen,

56
00:03:27,643 --> 00:03:30,624
how to manage ambiences and other world sounds

57
00:03:30,624 --> 00:03:32,364
from both sides,

58
00:03:32,364 --> 00:03:33,944
how to maintain mixed clarity

59
00:03:33,944 --> 00:03:36,285
as well as emphasis on the right things

60
00:03:36,285 --> 00:03:39,145
in relation to what is happening at each given moment,

61
00:03:39,879 --> 00:03:44,582
How to enable two spaces to coexist and be represented at the same time,

62
00:03:44,582 --> 00:03:49,324
or one space to be represented from two different perspectives.

63
00:03:49,324 --> 00:03:56,008
And about the creative vision, how to convey this sense of bigness of everything in relation to the character's size.

64
00:03:56,008 --> 00:04:01,711
How to maintain both playfulness and realistic immersion to support the tone of the game.

65
00:04:01,711 --> 00:04:05,713
And of course, how to live up to the latest animation sound design standards,

66
00:04:05,713 --> 00:04:08,034
such as Pixar, but in an interactive world.

67
00:04:09,272 --> 00:04:12,816
The solutions and the strategies that we have developed to answer these challenges

68
00:04:12,816 --> 00:04:13,938
are both creative and technical,

69
00:04:13,938 --> 00:04:18,823
and they would not have been possible without a close collaboration between those two aspects.

70
00:04:18,823 --> 00:04:21,106
That is why we are both here today.

71
00:04:21,106 --> 00:04:24,210
So first, to introduce our split-screen sound design strategies,

72
00:04:24,210 --> 00:04:26,813
let's start by clearing up a few terms.

73
00:04:28,775 --> 00:04:31,296
So the first concept to have understanding of

74
00:04:31,296 --> 00:04:33,897
as we learn about this game is that of the listener,

75
00:04:33,897 --> 00:04:37,518
which is a single world-bound point of reference

76
00:04:37,518 --> 00:04:40,959
from which we observe sounds in a three-dimensional space.

77
00:04:40,959 --> 00:04:43,280
And looking at this picture right here in front of us,

78
00:04:43,280 --> 00:04:44,681
it's not really that hard to imagine

79
00:04:44,681 --> 00:04:47,041
a more conventional single-player game

80
00:04:47,041 --> 00:04:48,722
where that listener will likely be attached

81
00:04:48,722 --> 00:04:50,262
to the character or the camera

82
00:04:50,262 --> 00:04:52,583
and serve as that singular point of hearing.

83
00:04:52,583 --> 00:04:56,604
But it Takes Two is not a conventional game.

84
00:04:57,513 --> 00:05:03,236
And part of our split screen setup means that we always have two listener presence, one for each character.

85
00:05:03,236 --> 00:05:08,698
So instead of adhering to the idea of a lone listener representing one absolute truth of hearing,

86
00:05:08,698 --> 00:05:15,880
we have to accurately represent both player perspectives as they are summed through one shared output.

87
00:05:16,711 --> 00:05:24,336
And speaking about that output, it's worth mentioning that it takes two is delivered for a channel based format of 5.1 surrounding.

88
00:05:24,336 --> 00:05:27,498
So we opted to not go for an object based approach.

89
00:05:27,498 --> 00:05:33,241
And what we just said here is that this is the governing principle of audio, it takes two.

90
00:05:33,241 --> 00:05:34,822
It is the fundamental law.

91
00:05:34,822 --> 00:05:45,829
And for the people tasked with filling this fantastic world with sound, it was of utmost importance that one learned how to live within these restrictions that this imposed.

92
00:05:46,468 --> 00:05:53,574
But more importantly, how to leverage the untold opportunities for us to tell new stories through sound

93
00:05:53,574 --> 00:06:01,500
and take the listening experience to places that the aforementioned conventional game couldn't really do.

94
00:06:01,500 --> 00:06:04,063
So next up on concepts is that of 2D versus 3D.

95
00:06:05,520 --> 00:06:10,405
So a concept of audio for games that we must have a firm grasp on is that of spatial audio.

96
00:06:10,405 --> 00:06:17,873
So that is to say a sound rendered to convey a point of emission within that three dimensional space.

97
00:06:17,873 --> 00:06:21,297
And commonly we would address those sounds as being 3D sounds.

98
00:06:22,318 --> 00:06:24,879
And as a counterpoint to this spatial audio,

99
00:06:24,879 --> 00:06:27,521
we have sounds that are non-spatialized,

100
00:06:27,521 --> 00:06:31,143
which means that they do not appear to occupy space

101
00:06:31,143 --> 00:06:35,165
in the world so much as they occupy space on the screen

102
00:06:35,165 --> 00:06:37,767
through which the world is then viewed.

103
00:06:37,767 --> 00:06:40,828
And we would refer to such sounds as being 2D sounds.

104
00:06:40,828 --> 00:06:43,130
So a direct contrast to those that live

105
00:06:43,130 --> 00:06:44,290
within the actual game world.

106
00:06:46,105 --> 00:06:53,751
And tackling the sound design of It Takes Two required a very conscious approach to these two different archetypes of sounds.

107
00:06:53,751 --> 00:07:00,296
Indeed. So considering all that was just said about spatialized sounds,

108
00:07:00,296 --> 00:07:04,760
one of our very first brainstorm sessions in the very beginning of the project

109
00:07:04,760 --> 00:07:09,684
was about how we were going to manage spatialized and non-spatialized sounds,

110
00:07:09,684 --> 00:07:11,825
so both 2D and 3D for split-screen.

111
00:07:12,278 --> 00:07:16,340
There simply weren't all that many good sounding split screen games out there

112
00:07:16,340 --> 00:07:20,101
that followed the similar type of gameplay and creative vision

113
00:07:20,101 --> 00:07:22,861
as us from which we could get inspiration.

114
00:07:22,861 --> 00:07:28,003
So our research basically told us we had to come up with our own way of doing things

115
00:07:28,003 --> 00:07:33,304
and follow our own intuition about how the game should sound.

116
00:07:33,304 --> 00:07:35,565
So to introduce our split screen strategies,

117
00:07:35,565 --> 00:07:38,906
I will start by talking about the ambience content in It Takes Two.

118
00:07:39,493 --> 00:07:42,915
Because ambiences and ambient world sounds

119
00:07:42,915 --> 00:07:46,517
form the bed of what players hear when entering the game.

120
00:07:46,517 --> 00:07:49,338
It was very important to us that we start by clarifying

121
00:07:49,338 --> 00:07:51,900
how those were going to behave from early on

122
00:07:51,900 --> 00:07:56,362
so that we could then build from that foundation.

123
00:07:56,362 --> 00:07:58,123
So in It Takes Two,

124
00:07:58,123 --> 00:08:00,424
each player always has their own ambience

125
00:08:00,424 --> 00:08:02,445
independent from the other players

126
00:08:02,445 --> 00:08:05,266
representing where they are in the world.

127
00:08:05,266 --> 00:08:07,688
All ambiences in the game are usually made

128
00:08:07,688 --> 00:08:09,228
from a combination of...

129
00:08:10,197 --> 00:08:14,759
a quad wave file playing the role of bass surround ambience.

130
00:08:14,759 --> 00:08:19,961
So that is a one four channel looping sound that includes as many details of the ambience

131
00:08:19,961 --> 00:08:22,002
as possible.

132
00:08:22,002 --> 00:08:27,285
We consider the quads in It Takes Two to be 2D, especially considering that they are static

133
00:08:27,285 --> 00:08:31,807
in the sense that all four channels of the quad will always be routed to the same four

134
00:08:31,807 --> 00:08:35,949
channels to the speakers, regardless of the player's movements.

135
00:08:36,089 --> 00:08:38,511
The reason for that is because of the split screen.

136
00:08:38,511 --> 00:08:42,354
So just imagine if we did allow the quads to be spatialized.

137
00:08:42,354 --> 00:08:45,036
That means if the player on the left side is moving around,

138
00:08:45,036 --> 00:08:47,217
let's say they turn to the left side,

139
00:08:47,217 --> 00:08:49,539
that means that the whole ambience bed

140
00:08:49,539 --> 00:08:51,741
shifts through the surround axis,

141
00:08:51,741 --> 00:08:54,483
which means some elements would go from the left side

142
00:08:54,483 --> 00:08:57,125
to the right side, basically on the other player's side.

143
00:08:57,125 --> 00:08:59,427
This could easily become confusing

144
00:08:59,427 --> 00:09:01,128
for the player on the right side.

145
00:09:01,128 --> 00:09:02,849
We simply thought that it would feel weird

146
00:09:02,849 --> 00:09:05,892
for both players to have their ambience moving that way.

147
00:09:05,972 --> 00:09:07,836
in the context of the split screen, that is.

148
00:09:07,836 --> 00:09:13,448
And the soundscape of each text too simply didn't benefit from this added layer of complexity.

149
00:09:14,955 --> 00:09:18,819
So then we have also randomly generated spot sounds.

150
00:09:18,819 --> 00:09:21,522
And those are helpful to add a bit of variety and randomness

151
00:09:21,522 --> 00:09:25,966
to the quads and help to world-dyes the ambience elements.

152
00:09:25,966 --> 00:09:29,029
So randomly generated spot sounds, or as the name says,

153
00:09:29,029 --> 00:09:32,852
spontaneous isolated ambience elements

154
00:09:32,852 --> 00:09:34,494
spawned at random 3D locations

155
00:09:34,494 --> 00:09:36,135
within the player's environment.

156
00:09:37,196 --> 00:09:38,737
And those we consider to be 3D.

157
00:09:38,737 --> 00:09:43,080
And what they include, of course, depends on the environment itself.

158
00:09:43,080 --> 00:09:48,224
But common examples might be wood creaks, random animals and insects,

159
00:09:48,224 --> 00:09:51,606
dust, wind gusts, rustles, things like that.

160
00:09:53,225 --> 00:09:57,828
On top of those random spot sounds, we have also manually placed spot sounds.

161
00:09:57,828 --> 00:10:02,051
And those are of a similar nature, so also 3D in the world,

162
00:10:02,051 --> 00:10:07,534
but they are placed manually in the level to match the visuals with a bit more precision.

163
00:10:07,534 --> 00:10:13,278
So for instance, extra wind gusts where there might be VFX to support the visual feedback.

164
00:10:13,278 --> 00:10:17,601
Same for leaves rustling or water lapping around water areas.

165
00:10:19,988 --> 00:10:24,532
And finally, there are objects from the world emitting their own sounds.

166
00:10:24,532 --> 00:10:27,775
So those are also 3D and can include, for instance,

167
00:10:27,775 --> 00:10:29,817
critters or animals passing by,

168
00:10:29,817 --> 00:10:32,539
could be machines or fans or moving platforms,

169
00:10:32,539 --> 00:10:36,562
basically any object that belongs to the world

170
00:10:36,562 --> 00:10:39,805
and is emitting their own sets of sounds.

171
00:10:39,805 --> 00:10:43,788
So all of this put together creates a consistently rich atmosphere

172
00:10:43,788 --> 00:10:45,029
without any dead spots.

173
00:10:47,249 --> 00:10:48,690
But that was only for one player.

174
00:10:48,690 --> 00:10:52,573
So then comes the question of how to convey all of this

175
00:10:52,573 --> 00:10:54,175
and maintain the clarity with two players.

176
00:10:54,175 --> 00:10:58,058
So before getting really into our technical solutions,

177
00:10:58,058 --> 00:11:00,139
let's first listen to a video that will show

178
00:11:00,139 --> 00:11:02,942
how these described ambience layers

179
00:11:02,942 --> 00:11:04,343
are combined into the game

180
00:11:04,343 --> 00:11:06,865
and what the sounding result is.

181
00:11:06,865 --> 00:11:10,268
So in this video, you will first hear the left ambience,

182
00:11:10,268 --> 00:11:12,329
so the quad on Mei's side,

183
00:11:12,329 --> 00:11:15,232
and then the right quad will be added on Cody's side.

184
00:11:16,127 --> 00:11:20,209
And then we'll one by one add the other ambience layers just as described.

185
00:11:20,209 --> 00:11:24,510
So the randomly generated spot sounds, you can listen in this case mostly for

186
00:11:24,510 --> 00:11:30,092
frogs, crickets and flies, which will be highlighted by the debug on the screen.

187
00:11:30,092 --> 00:11:34,694
And then some manually placed spot sounds, we have some water lapping around May,

188
00:11:34,694 --> 00:11:36,095
some leaves rustling around Cody.

189
00:11:36,635 --> 00:11:39,076
And finally, the critters are added.

190
00:11:39,076 --> 00:11:41,918
So in this case, we have dragonflies on May's side

191
00:11:41,918 --> 00:11:44,280
and some ladybugs on Cody's side.

192
00:11:44,280 --> 00:11:47,262
And the end result is a fuller mix of ambient sounds.

193
00:11:47,262 --> 00:11:49,204
And after the video, we'll start digging

194
00:11:49,204 --> 00:11:51,285
into how we made this work in split screen,

195
00:11:51,285 --> 00:11:54,748
along with how our strategies for these ambient sounds

196
00:11:54,748 --> 00:11:57,750
applied to all other types of sounds as well.

197
00:13:15,650 --> 00:13:21,695
So as we might begun to see, the gameplay of it takes two is incredibly varied and diverse.

198
00:13:21,695 --> 00:13:27,100
The most common case though will have the screen split vertically right down the middle

199
00:13:27,100 --> 00:13:33,786
with both characters views getting equal screen space there. And this very rigid scene view

200
00:13:33,786 --> 00:13:37,309
really defined our design choices all throughout the project.

201
00:13:37,400 --> 00:13:39,982
And before we had even begun putting sounds into the engine,

202
00:13:39,982 --> 00:13:41,923
we started having long discussions

203
00:13:41,923 --> 00:13:45,406
on how to manage our screen space.

204
00:13:45,406 --> 00:13:47,487
And this process of learning on how

205
00:13:47,487 --> 00:13:51,230
to build for our viewport was ongoing for the full project.

206
00:13:51,230 --> 00:13:53,552
And it became a concept that I like to refer

207
00:13:53,552 --> 00:13:55,733
to as sonic real estate.

208
00:13:57,338 --> 00:14:00,441
For It Takes Two, Sonic Real Estate meant that

209
00:14:00,441 --> 00:14:02,563
we at all times adjust audio content

210
00:14:02,563 --> 00:14:05,186
to fit within the given visual frame

211
00:14:05,186 --> 00:14:09,630
by using carefully placed spatial and non-spatial sounds

212
00:14:09,630 --> 00:14:13,854
that each occupy compartmentalized spaces on the screen.

213
00:14:13,854 --> 00:14:14,915
So in much simpler terms,

214
00:14:14,915 --> 00:14:17,737
it means that every sound is placed

215
00:14:17,737 --> 00:14:19,619
based on its visual position on the screen.

216
00:14:20,397 --> 00:14:22,338
And again, for the sake of clarity,

217
00:14:22,338 --> 00:14:25,059
it takes two uses a channel-based format,

218
00:14:25,059 --> 00:14:27,900
5.1 surround, not any object-based audio.

219
00:14:27,900 --> 00:14:31,562
So now let's take a look at a video

220
00:14:31,562 --> 00:14:34,063
that exemplifies Sonic Real Estate

221
00:14:34,063 --> 00:14:35,944
by showing how the soundscapes

222
00:14:35,944 --> 00:14:37,765
of the individual player frames

223
00:14:37,765 --> 00:14:40,466
contributes to the final shared output.

224
00:14:41,183 --> 00:14:44,346
So we'll watch a video now and at specific points throughout,

225
00:14:44,346 --> 00:14:48,130
we will transition from hearing the full mix of the game to hearing isolated

226
00:14:48,130 --> 00:14:53,756
layers of ambience and reverb, which will additionally also contain some voiceover.

227
00:14:53,756 --> 00:14:58,761
And now we really encourage you to pay close attention to the sounds that you

228
00:14:58,761 --> 00:15:01,363
hear and try to think about how they are placed on the screen.

229
00:16:15,187 --> 00:16:16,907
Is that water? What is this machine?

230
00:16:16,907 --> 00:16:20,188
Uh, who cares? Water pillars are cool.

231
00:16:20,188 --> 00:16:23,470
Help me with this wrench, Cody.

232
00:16:23,470 --> 00:16:35,794
So the first method developed to help us establish that groundwork of spatial placement

233
00:16:35,794 --> 00:16:41,156
is found in a basic technique aimed to play sounds on the horizontal plane.

234
00:16:41,156 --> 00:16:43,117
This approach, called speaker panning,

235
00:16:43,921 --> 00:16:48,644
is one of the most fundamental concepts of audio processing, even in linear media,

236
00:16:48,644 --> 00:16:54,889
but in It Takes Two, it became a very impactful tool. So the mindset we employed when we used it

237
00:16:54,889 --> 00:17:02,114
was that speaker panning served to impose kind of a soft ownership of sounds towards either player

238
00:17:02,114 --> 00:17:06,678
based on which player interacted with that moment at any, at that object, I should say,

239
00:17:06,678 --> 00:17:07,858
at any given moment.

240
00:17:08,482 --> 00:17:11,003
And this relationship was not at all static.

241
00:17:11,003 --> 00:17:14,684
Instead, we always reacted to how object player relationships

242
00:17:14,684 --> 00:17:17,066
change during gameplay and then pan those sounds

243
00:17:17,066 --> 00:17:19,767
towards the side of that player's viewport.

244
00:17:19,767 --> 00:17:23,128
So in essence, May's world is a little bit more to the left

245
00:17:23,128 --> 00:17:26,090
and Cody's is a little bit more to the right.

246
00:17:26,090 --> 00:17:29,191
And while this basic technique was instrumental

247
00:17:29,191 --> 00:17:30,932
in outlining the fundamentals of the mix,

248
00:17:30,932 --> 00:17:35,274
it was really only applicable to our non-spatialized sounds.

249
00:17:35,274 --> 00:17:36,675
So again, our 2D sounds.

250
00:17:38,010 --> 00:17:46,741
Taming spatialized sounds in a way that would allow us to control the sonic real estate like we wanted to would prove to be a much bigger task.

251
00:17:46,741 --> 00:17:53,590
And we'll return to that topic after Anne-Sophie has dealt a little bit deeper into what world dicing it takes to meant.

252
00:17:55,633 --> 00:17:59,035
So just to summarize what we've spoken about so far,

253
00:17:59,035 --> 00:18:01,857
what we've managed at this point is to build a foundation

254
00:18:01,857 --> 00:18:03,057
for a split-screen audio system.

255
00:18:03,057 --> 00:18:06,779
We've established a degree of ownership of the sounds

256
00:18:06,779 --> 00:18:07,940
through speaker panning

257
00:18:07,940 --> 00:18:10,261
by sending each player's respective sounds

258
00:18:10,261 --> 00:18:12,983
slightly more towards their own sides.

259
00:18:12,983 --> 00:18:15,004
We've also set a few ground rules

260
00:18:15,004 --> 00:18:17,105
regarding sonic real estate,

261
00:18:17,105 --> 00:18:19,246
so which sounds should be 2D or 3D

262
00:18:19,246 --> 00:18:23,028
and how much of the screen space they should be allowed

263
00:18:23,028 --> 00:18:25,149
to take in relation to gameplay.

264
00:18:25,229 --> 00:18:30,353
And we have carefully designed ambiences and other world sounds with as many details as possible in

265
00:18:30,353 --> 00:18:35,958
order to reinforce each player's environment and their perspective in it. But with split-screen

266
00:18:35,958 --> 00:18:41,642
audio, due to the nature of the medium and the fact that two environments need to be portrayed

267
00:18:41,642 --> 00:18:47,447
at the same time, we felt like we needed to take every possible step towards greater immersion

268
00:18:47,447 --> 00:18:51,330
and towards selling the world in order to make it feel natural and believable.

269
00:18:52,102 --> 00:18:57,225
which ultimately we think helps to minimize the distraction that the split screen might cause.

270
00:18:57,225 --> 00:19:02,529
And so due to the split screen itself, we needed to do that with some degree of subtlety.

271
00:19:02,529 --> 00:19:08,053
And so that meant not by trying to add more stuff, which might quickly start to compromise

272
00:19:08,053 --> 00:19:13,056
the clarity of the soundscape, but rather to make sure that the sounds that we do choose to include

273
00:19:13,056 --> 00:19:18,960
contribute to bringing the entire world to life. We do that through worldizing strategies.

274
00:19:20,998 --> 00:19:24,981
For it Takes Two, our worldizing strategies were these.

275
00:19:24,981 --> 00:19:27,582
Using convincing reverb, that meant convolution reverb

276
00:19:27,582 --> 00:19:29,744
with impulse responses that we recorded

277
00:19:29,744 --> 00:19:31,005
and designed ourselves.

278
00:19:31,005 --> 00:19:32,946
And 100% of the game sounds, in-game sounds,

279
00:19:32,946 --> 00:19:36,809
are going through the environment reverb.

280
00:19:37,755 --> 00:19:41,859
We also have real-time environment-based delay reflections.

281
00:19:41,859 --> 00:19:45,262
So thanks to our Raycast and environment type systems,

282
00:19:45,262 --> 00:19:50,226
which allow the game to know in what type of environment the player is currently in.

283
00:19:50,226 --> 00:19:55,191
So is it, for example, a small, a large, indoors, outdoors, and so on.

284
00:19:55,231 --> 00:20:01,435
and sounds that are sent to the delay include a veal, foley, weapons, gadgets and vehicles.

285
00:20:01,435 --> 00:20:07,900
And we also have sound designed baked reflection tails that are added to sounds like weapons,

286
00:20:07,900 --> 00:20:10,902
explosions and other large sounds and even footsteps sometimes.

287
00:20:12,995 --> 00:20:17,656
So to illustrate these worldizing strategies and how they contribute to the soundscape,

288
00:20:17,656 --> 00:20:21,736
we'll listen to a video showing how the world sounds with and without them.

289
00:20:21,736 --> 00:20:27,537
So you'll first hear the awesome weapons and explosion sound designed by Philip Erickson,

290
00:20:27,537 --> 00:20:31,158
where there will be initially no worldizing elements.

291
00:20:31,158 --> 00:20:34,059
So there will be no reverb, no delay, and no reflection tails.

292
00:20:34,059 --> 00:20:39,920
And then you will hear the same weapons and explosions with the added baked reflection tails.

293
00:20:41,080 --> 00:20:44,285
And finally with the reverb and the delay added as well.

294
00:20:44,285 --> 00:20:50,894
The video will also then show how the VO, foley and other environment sounds may be

295
00:20:50,894 --> 00:20:54,979
affected by the environment type, the reverb and the delay in real time.

296
00:21:49,042 --> 00:21:53,025
I wonder where that annoying book even came from.

297
00:21:53,025 --> 00:21:55,227
He said Rose bought him.

298
00:21:55,227 --> 00:21:57,028
He doesn't sound like a book she would buy.

299
00:21:57,028 --> 00:22:00,470
More like a pretentious self-help book you'd buy.

300
00:22:00,470 --> 00:22:03,693
You know, self-help books are very important to some people, okay?

301
00:22:03,693 --> 00:22:06,295
Forget about the book. Let's get to Rose.

302
00:22:06,295 --> 00:22:11,558
Rosie, get inside!

303
00:22:11,558 --> 00:22:14,340
Please be gentle.

304
00:22:14,340 --> 00:22:16,222
It smells moldy.

305
00:22:16,222 --> 00:22:18,803
Yeah, humid down here.

306
00:22:25,858 --> 00:22:27,699
Did you see that, Cody?

307
00:22:27,699 --> 00:22:29,420
I saw something. What was it?

308
00:22:29,420 --> 00:22:29,801
I couldn't tell.

309
00:22:29,801 --> 00:22:30,181
Maybe a rat.

310
00:22:30,181 --> 00:22:31,642
No, it looked huge.

311
00:22:31,642 --> 00:22:32,963
All right, thank you, Anne-Sophie.

312
00:22:32,963 --> 00:22:47,611
So like I previously said, our speaker panning solution and our ambient system, it allowed us to bring the split screen mix and balance to a good level.

313
00:22:48,668 --> 00:22:55,152
But we still experienced spatialization issues that were compromising the immersion.

314
00:22:55,152 --> 00:22:56,854
And this was a result of our two listeners.

315
00:22:56,854 --> 00:22:59,195
The problem was twofold.

316
00:22:59,195 --> 00:23:08,902
First problem was that we suffered from an unwanted increase in volume when both players observed the same spatialized sound source simultaneously.

317
00:23:08,902 --> 00:23:10,143
You see that visualized here.

318
00:23:11,909 --> 00:23:16,410
The problem was in the way that WISE inherently combined channels

319
00:23:16,410 --> 00:23:20,551
when a single sound source was being picked up by both listeners at the same time.

320
00:23:20,551 --> 00:23:25,451
The result was that for situations where both players experienced a sound from an

321
00:23:25,451 --> 00:23:29,532
identical or near identical point of reference to one another, we would double

322
00:23:29,532 --> 00:23:35,573
the signal ratio per channel, which translates to about six decibels of increased output.

323
00:23:35,573 --> 00:23:41,014
So in layman's terms, two players listening to the same spatialized sound would make it

324
00:23:41,014 --> 00:23:41,394
louder.

325
00:23:41,790 --> 00:23:44,031
compared to it being heard by only one player.

326
00:23:44,031 --> 00:23:49,332
This unwanted behavior was a massive thorn in the side for us.

327
00:23:49,332 --> 00:23:51,953
It would make it virtually impossible to mix this game.

328
00:23:51,953 --> 00:23:55,073
And we had recognized its unpredictable implication

329
00:23:55,073 --> 00:23:57,474
on the mix early on in our design.

330
00:23:57,474 --> 00:24:00,855
And our first response to balance the volume output

331
00:24:00,855 --> 00:24:03,055
was to implement and continuously update

332
00:24:03,055 --> 00:24:06,636
a parameter based on listener proximities to the sound source.

333
00:24:06,636 --> 00:24:08,877
So slightly reducing output volume

334
00:24:08,877 --> 00:24:10,517
when both listeners were close.

335
00:24:10,998 --> 00:24:14,984
effectively counteracting the added intensity from the double signal.

336
00:24:14,984 --> 00:24:20,372
But this was very much nothing more than an ugly fix to an even uglier problem.

337
00:24:20,372 --> 00:24:25,680
And we always knew that we had to go deeper to get a result that we would be happy with.

338
00:24:27,664 --> 00:24:34,912
The second problem was that attempting to use one output device to represent one sound source,

339
00:24:34,912 --> 00:24:41,739
but from the perspective of two listeners, always results in a third perspective

340
00:24:41,739 --> 00:24:44,942
that is the sum of both but speaks the truth of none.

341
00:24:45,946 --> 00:24:51,510
And this some perspective meant that not only was the sound of this explosion, for instance,

342
00:24:51,510 --> 00:24:55,394
louder than it should have been because it sums the signal from both players,

343
00:24:55,394 --> 00:25:03,380
but also that spatial positioning was not always truthful due to it only considering the closest player.

344
00:25:03,380 --> 00:25:09,485
So, for example, if May is standing closer to that explosion, but is looking slightly to the left,

345
00:25:09,485 --> 00:25:15,310
the explosion will be perceived as coming from the right, even though Cody might be looking straight at it.

346
00:25:17,232 --> 00:25:20,936
And we already knew that the missing piece of this puzzle

347
00:25:20,936 --> 00:25:24,239
here was a result of how spatialized sounds were

348
00:25:24,239 --> 00:25:26,421
considered in our two-listener setup.

349
00:25:26,421 --> 00:25:28,423
Energy distribution between the output channels

350
00:25:28,423 --> 00:25:30,165
was a summed result of both listeners,

351
00:25:30,165 --> 00:25:33,748
which means that the represented listener position was always

352
00:25:33,748 --> 00:25:34,929
a compromise of both.

353
00:25:34,929 --> 00:25:38,252
And we see that in this graph right here.

354
00:25:38,252 --> 00:25:40,394
One listener could have a sound source dead ahead.

355
00:25:40,817 --> 00:25:42,959
But if the other listener was closer to that sound

356
00:25:42,959 --> 00:25:45,340
and fully turned away, then that sound

357
00:25:45,340 --> 00:25:48,342
would still appear to have the presence in the rear speakers

358
00:25:48,342 --> 00:25:49,923
of the surround setup.

359
00:25:49,923 --> 00:25:53,566
So we decided that we needed to rewrite

360
00:25:53,566 --> 00:25:56,328
the rule set of how spatial light panning worked

361
00:25:56,328 --> 00:26:00,050
in our game and make fundamental changes to how we rendered

362
00:26:00,050 --> 00:26:01,711
output based on our two listeners.

363
00:26:01,711 --> 00:26:06,154
This took a bit of shifting of a mindset.

364
00:26:07,033 --> 00:26:11,917
So instead of pursuing the idea of always fully representing both listeners,

365
00:26:11,917 --> 00:26:16,079
we instead decided that we wanted to create a soundscape where a spatialized

366
00:26:16,079 --> 00:26:20,082
sound was represented from the perspective of the most attentive and relevant

367
00:26:20,082 --> 00:26:22,264
out of the two listeners.

368
00:26:22,264 --> 00:26:26,506
By constantly choosing just one out of our two perspectives and omitting the

369
00:26:26,506 --> 00:26:27,367
other one,

370
00:26:27,367 --> 00:26:31,250
then anyone's sound source would always be rendered in a way that made sense.

371
00:26:32,222 --> 00:26:35,764
And this new rule of spatialized audio in multiple listeners

372
00:26:35,764 --> 00:26:38,505
is what we decided to implement in an approach

373
00:26:38,505 --> 00:26:43,488
that we've simply called spatial panning.

374
00:26:43,488 --> 00:26:44,688
So we'll now take a look at a video

375
00:26:44,688 --> 00:26:47,450
to exemplify said spatial panning in action.

376
00:26:47,450 --> 00:26:50,372
So we have a sequence here and we'll listen

377
00:26:50,372 --> 00:26:53,253
to a series of explosions as they're happening

378
00:26:53,253 --> 00:26:55,534
around the players who will observe them

379
00:26:55,534 --> 00:26:56,935
from two different perspectives.

380
00:26:57,967 --> 00:27:02,610
We will run the exact same sequence twice, first with just the default panning,

381
00:27:02,610 --> 00:27:05,932
and then once more with our spatial panning engaged.

382
00:27:05,932 --> 00:27:08,554
And to help you out here, also visible on the screen,

383
00:27:08,554 --> 00:27:12,717
it will be a volume meter showing the overall audio output.

384
00:27:12,717 --> 00:27:17,260
So again, now try to listen closely to the difference in how you might perceive

385
00:27:17,260 --> 00:27:20,142
the locations of the explosions as they're happening on the screen,

386
00:27:20,142 --> 00:27:24,505
and more so how the addition of the spatial panning affects it.

387
00:28:24,936 --> 00:28:32,460
So what you just saw and hopefully heard was how spatial panning serves to improve accuracy in the mix.

388
00:28:32,460 --> 00:28:41,566
Its purpose is to take attenuation, so that is how a signal reduces in power over distance, take that and decouple it from the panning.

389
00:28:41,566 --> 00:28:52,032
So it works in such a way that whenever more than one listener is actively mixing the same sound source, we begin to look at and compare those listeners individual relation to that sound.

390
00:28:53,341 --> 00:28:57,665
The listener, the closest listener is chosen as a reference point for the attenuation

391
00:28:57,665 --> 00:29:03,229
and then the listener with the closest forward angle to the position of the sound source

392
00:29:03,229 --> 00:29:10,335
will be our observer for panning. Together these two structures are combined into our one

393
00:29:10,335 --> 00:29:11,557
final listener output.

394
00:29:13,553 --> 00:29:17,636
So in this slide right here, we see an example of a situation

395
00:29:17,636 --> 00:29:20,479
that without spatial panning produced

396
00:29:20,479 --> 00:29:22,740
very questionable results with regards

397
00:29:22,740 --> 00:29:26,183
to the idea of sonic real estate.

398
00:29:26,183 --> 00:29:27,865
One sound source, two listeners.

399
00:29:27,865 --> 00:29:30,847
One listener looking straight at the source,

400
00:29:30,847 --> 00:29:32,629
one listener with its back fully turned.

401
00:29:32,629 --> 00:29:36,712
But the combination of the two would sometimes produce

402
00:29:36,712 --> 00:29:39,454
as much signal in the rear speakers of a surround setup

403
00:29:39,454 --> 00:29:41,416
as it would in the speakers in the front.

404
00:29:41,828 --> 00:29:44,869
even though it can only be seen by the player looking directly at it,

405
00:29:44,869 --> 00:29:49,892
and who of course would expect this sound to be heard as if it's playing from the front.

406
00:29:49,892 --> 00:29:57,716
But spatial panning solves this for us by in effect linking to what we hear to what is on screen,

407
00:29:57,716 --> 00:30:02,659
and in doing so allowing those big sounds that really should fill the space provided by the

408
00:30:02,659 --> 00:30:09,002
surround channels to do so without being muddied by unwanted and untamed spatial sources.

409
00:30:10,955 --> 00:30:14,578
To make this whole procedure as transparent as possible,

410
00:30:14,578 --> 00:30:17,480
we introduced interpolation to help smoothen out

411
00:30:17,480 --> 00:30:20,482
any drastic changes in listener sound relationships.

412
00:30:20,482 --> 00:30:24,065
And a challenge in this was to make the panning update

413
00:30:24,065 --> 00:30:26,747
fast enough to be responsive to gameplay,

414
00:30:26,747 --> 00:30:30,169
but still smoothly enough to not make for any jarring jumps

415
00:30:30,169 --> 00:30:31,270
in panning or amplitude.

416
00:30:31,270 --> 00:30:34,673
That's not something that we could allow.

417
00:30:34,673 --> 00:30:36,854
But in the end of it all, spatial panning

418
00:30:36,854 --> 00:30:39,616
was a major benefactor to the soundscape of It Takes Two.

419
00:30:40,425 --> 00:30:43,850
allowing the spatial sounds to be rendered in a coherent and world-based way,

420
00:30:43,850 --> 00:30:46,513
even when in range of both listeners,

421
00:30:46,513 --> 00:30:51,399
and at the same time, help maintaining that all-important clarity in the mix.

422
00:30:51,399 --> 00:30:55,945
And the final output mix, and just pack everything together nicely.

423
00:30:58,368 --> 00:31:02,591
So to summarize what we've added to our split screen strategies over the last few slides,

424
00:31:02,591 --> 00:31:06,654
on top of the solutions we've already spoken about, like our speaker panning solution,

425
00:31:06,654 --> 00:31:12,398
our sonic real estate management and our carefully designed ambiences, we have added worldizing

426
00:31:12,398 --> 00:31:18,022
strategies such as convolution reverb, real-time delay reflections, space reflection tails,

427
00:31:18,022 --> 00:31:21,885
and of course spatial panning that compensates for those spatial discrepancies.

428
00:31:23,805 --> 00:31:29,587
But when it comes to developing audio for split screen, for all of those solutions to really live up to their full potential,

429
00:31:29,587 --> 00:31:39,551
it was important to be clever about our actual sound design strategies and to choose what were the elements that were the most important and that needed to be represented as such.

430
00:31:39,551 --> 00:31:42,712
And I like to call those the elements of subjective importance.

431
00:31:43,992 --> 00:31:50,895
meaning that we choose based on our own judgment, so subjective, which sounds are the most important

432
00:31:50,895 --> 00:31:55,996
in relation to all other game sounds and to what is happening on screen and in gameplay.

433
00:31:55,996 --> 00:32:00,198
And those elements are then prioritized in both the design, sound design, and the mix,

434
00:32:00,198 --> 00:32:05,159
so that they come through clearly, and so that the player is getting the information,

435
00:32:05,159 --> 00:32:09,861
the feedback, and the story that they need from their actions and from the narrative development.

436
00:32:11,710 --> 00:32:19,495
And this is where we relied on our Pixar inspiration and the idea of bigness and exaggeration as a basis for our creative vision.

437
00:32:19,495 --> 00:32:27,340
Bigness was very important in It Takes Two, because in order for that contrast of the characters being tiny in a big world to come through,

438
00:32:27,721 --> 00:32:33,466
objects that were meant to be large in comparison to the players needed to sound even larger.

439
00:32:33,466 --> 00:32:39,071
So in the end the elements that we decided were the most important were designed to be bigger,

440
00:32:39,071 --> 00:32:43,295
larger and more powerful than any other sound playing at the same time.

441
00:32:43,295 --> 00:32:47,058
And by focusing in such a way on one important element at a time,

442
00:32:47,058 --> 00:32:52,703
it helps in keeping to a minimum the chaos that can come from busy sequences such as combat scenarios.

443
00:32:54,693 --> 00:32:59,194
We also made an effort whenever possible to keep those important elements within the screen,

444
00:32:59,194 --> 00:33:05,036
and by that I mean within the left-center right speakers, rather than having them spatialized

445
00:33:05,036 --> 00:33:10,777
across the full surround axis, so that they really would remain in focus and in the frame

446
00:33:10,777 --> 00:33:12,417
of the screen space.

447
00:33:12,417 --> 00:33:17,578
And that way, we believe that this important sound would be perceived as more cinematic

448
00:33:17,578 --> 00:33:20,019
and would be allowed to take more space in the mix.

449
00:33:21,089 --> 00:33:24,470
In other words, just imagine a sound made for a movie,

450
00:33:24,470 --> 00:33:25,271
stuck to the screen.

451
00:33:25,271 --> 00:33:27,672
So for sounding events that remain

452
00:33:27,672 --> 00:33:29,833
within the screen visually,

453
00:33:29,833 --> 00:33:33,394
we preferred to simply leave them 2D as opposed to 3D.

454
00:33:33,394 --> 00:33:37,016
And finally, this bigness in the sound design

455
00:33:37,016 --> 00:33:39,977
was complemented with the use of HDR in Wwise

456
00:33:39,977 --> 00:33:42,818
to help us maintain this clarity at all times.

457
00:33:42,818 --> 00:33:44,539
And just to make sure everybody understands

458
00:33:44,539 --> 00:33:46,299
what I'm talking about,

459
00:33:46,299 --> 00:33:48,260
HDR refers to high dynamic range.

460
00:33:48,720 --> 00:33:55,024
And in game audio that means we continuously look at what is playing and prioritize some voices over others

461
00:33:55,024 --> 00:34:00,287
based on set conditions that are predetermined in the audio engine, and for us that means wise.

462
00:34:00,287 --> 00:34:09,352
And this is meant to create the illusion that the dynamic range heard in the game is just as wide as the one heard in real life, even if that is not true.

463
00:34:10,073 --> 00:34:16,118
So for instance, by lowering the volume of a category of voices, such as ambient sounds,

464
00:34:16,118 --> 00:34:22,023
while other types of more powerful sounds are playing, such as explosions, so that the explosions

465
00:34:22,023 --> 00:34:27,788
is perceived as being much louder than the rest. And to translate this into our game,

466
00:34:27,788 --> 00:34:33,273
you could say that those elements of subjective importance that I was talking about will always

467
00:34:33,273 --> 00:34:38,918
be given a higher HDR value than, for example, ambiences or other less important sounds.

468
00:34:39,490 --> 00:34:43,395
so that the important elements are always heard clearly.

469
00:34:43,395 --> 00:34:44,817
So if you want to learn more about HDR

470
00:34:44,817 --> 00:34:47,180
and especially about how it worked in Wwise

471
00:34:47,180 --> 00:34:48,401
and for this project,

472
00:34:48,401 --> 00:34:49,422
I recommend you simply visit

473
00:34:49,422 --> 00:34:51,845
Audio Kinetic's help page about it.

474
00:34:52,764 --> 00:34:58,107
So now the video we're about to watch shows a few examples of how we approach the sound design

475
00:34:58,107 --> 00:35:01,629
and the mix for those elements of subjective importance.

476
00:35:01,629 --> 00:35:06,092
You can listen carefully to the sounds that are highlighted in the text as being the most

477
00:35:06,092 --> 00:35:11,296
important ones and notice how everything else in the soundscape seems to disappear.

478
00:35:11,296 --> 00:35:16,780
And that is the result of our conscious choice so that these elements become the true focus

479
00:35:16,780 --> 00:35:19,702
and so that the confusion due to the split screen is minimized.

480
00:35:19,846 --> 00:35:22,148
We basically use sound for narrative purposes.

481
00:35:22,148 --> 00:35:24,910
We tell the player what is important, what to look at,

482
00:35:24,910 --> 00:35:27,892
and what to pay attention to in relation to the gameplay.

483
00:35:27,892 --> 00:35:28,753
I can see the key.

484
00:35:52,820 --> 00:36:08,982
Thanks for watching!

485
00:37:05,722 --> 00:37:10,251
Wow, I'm starting to like this place.

486
00:37:10,251 --> 00:37:12,937
So before moving on to the second part of this presentation,

487
00:37:12,937 --> 00:37:14,760
let's summarize what we've said so far

488
00:37:14,760 --> 00:37:16,544
about the split screen sound of It Takes Two.

489
00:37:17,336 --> 00:37:21,121
Two listeners sharing the same screen meant that we needed to represent both players'

490
00:37:21,121 --> 00:37:24,585
perspective while maintaining a clear mix at all times.

491
00:37:24,585 --> 00:37:28,690
We did so by using a speaker panning system that panned sounds coming from each player's

492
00:37:28,690 --> 00:37:33,817
environment slightly more towards their respective sides, by compensating for spatialization

493
00:37:33,817 --> 00:37:36,079
discrepancies through spatial panning.

494
00:37:37,001 --> 00:37:44,689
By designing detailed and rich ambiences and environment sounds that represent the world in as convincing a way as possible.

495
00:37:44,689 --> 00:37:51,297
By relying on worldizing strategies to make the world more immersive and reinforce the sense of being there.

496
00:37:51,297 --> 00:37:56,743
By using HDR and by considering the elements of subjective importance when sound designing and mixing.

497
00:37:59,665 --> 00:38:03,869
Now that we have described our main sound design strategies when it comes to the split screen,

498
00:38:03,869 --> 00:38:05,990
we will enter the second part of this presentation,

499
00:38:05,990 --> 00:38:09,714
and this part will further our demonstration of the sound design for It Takes Two

500
00:38:09,714 --> 00:38:12,516
by presenting two selected sound design highlights,

501
00:38:12,516 --> 00:38:18,041
which have also required a very tight collaboration between technical solution and creative content.

502
00:38:18,041 --> 00:38:24,087
The first highlight that we chose to share with you is called the time controllability.

503
00:38:24,970 --> 00:38:30,254
So across one level called the Cuckoo Clock, where all puzzle mechanics are time-based,

504
00:38:30,254 --> 00:38:33,557
Cody is given the ability to control selected objects in time.

505
00:38:33,557 --> 00:38:38,681
And this means that when he activates his ability, he's able to scroll through a timeline

506
00:38:38,681 --> 00:38:42,564
and move the selected object back and forth within this timeline,

507
00:38:42,564 --> 00:38:46,927
and can also pause it and basically have time stand still for that object.

508
00:38:46,927 --> 00:38:49,689
So it's 100% based on player input.

509
00:38:50,465 --> 00:38:54,368
So here's a short video first showing what this ability does in the game,

510
00:38:54,368 --> 00:38:56,430
and then we'll talk about how we made it work.

511
00:39:49,974 --> 00:39:56,964
Thanks for watching!

512
00:40:09,964 --> 00:40:15,215
So to make this ability work, we considered various complex solutions, including granular

513
00:40:15,215 --> 00:40:19,404
synthesizers and other custom tools to be able to read through a sound file in both

514
00:40:19,404 --> 00:40:20,026
directions.

515
00:40:20,086 --> 00:40:24,890
But we eventually put aside all those grand aspirations when we realized that the best

516
00:40:24,890 --> 00:40:29,653
sounding solution was not to develop a system that allows to manipulate and play a sound

517
00:40:29,653 --> 00:40:35,298
file in all sorts of ways, but to actually sound design both the forward and the backward

518
00:40:35,298 --> 00:40:39,461
sounds as two separate sounds, and have full control over what ends up being the sounding

519
00:40:39,461 --> 00:40:44,765
result of scrolling through that timeline, as opposed to designing just one forward sound

520
00:40:44,765 --> 00:40:48,008
and hoping it sounds good when we manipulate it in all directions.

521
00:40:48,722 --> 00:40:56,248
So in order to be able to do that, what it came down to was actually much simpler than what we originally thought would be needed for such an ability.

522
00:40:56,248 --> 00:41:03,375
So all we needed to know from the game was the scrolling direction, so is the player scrolling forward or backward?

523
00:41:03,375 --> 00:41:09,780
And the scrolling progress, so where in the timeline is the player currently scrolling?

524
00:41:09,780 --> 00:41:13,303
And by sending those values in Y as RTPCs, so as parameters,

525
00:41:13,873 --> 00:41:18,716
It was then fairly easy to structure our sounds based on both the direction and the progress.

526
00:41:18,716 --> 00:41:24,038
And so the layers to build a time controllable interaction in their simplest form usually

527
00:41:24,038 --> 00:41:25,019
look something like this.

528
00:41:26,833 --> 00:41:31,495
We have one forward and one backward sound that are the exact same duration as the timeline,

529
00:41:31,495 --> 00:41:37,377
and those are two distinct sounds, each designed separately to fit the picture as well as possible.

530
00:41:37,377 --> 00:41:41,999
We also have one forward and one backward tail sounds, and those will play at the end of the

531
00:41:41,999 --> 00:41:47,701
timeline in both directions, and are also designed as two separate sounds to match the visuals.

532
00:41:47,701 --> 00:41:51,802
And finally the looping sounds, used when scrolling is paused within the timeline and

533
00:41:51,802 --> 00:41:54,003
the object appears to be frozen in time.

534
00:41:54,905 --> 00:41:57,987
So there can be many looping sounds, basically as many as needed.

535
00:41:57,987 --> 00:42:01,269
For instance, there can be different sounds based on the direction.

536
00:42:01,269 --> 00:42:04,891
So was the player scrolling forward or backward prior to pausing?

537
00:42:04,891 --> 00:42:07,872
And there can be different sounds based on progress.

538
00:42:07,872 --> 00:42:12,595
For instance, to have more intense or busy sounds playing if the timeline was paused

539
00:42:12,595 --> 00:42:16,157
in the middle of a destruction sequence as opposed to during a quieter moment.

540
00:42:18,139 --> 00:42:21,660
In addition to the sounds specific to one time-controllable object,

541
00:42:21,660 --> 00:42:26,161
Cody is also manipulating a clock and has his own time-controllability sounds

542
00:42:26,161 --> 00:42:30,642
that will always play no matter which object the player is interacting with.

543
00:42:30,642 --> 00:42:33,662
The ability sounds follow the exact same logic as the object sounds,

544
00:42:33,662 --> 00:42:37,163
so they have forward, backward, looping sounds, and tails.

545
00:42:37,163 --> 00:42:38,763
So as shown in this picture,

546
00:42:38,763 --> 00:42:42,504
the object sounds usually come from the actual object being time-controlled,

547
00:42:42,504 --> 00:42:46,065
and the ability sounds come from Cody, who is manipulating the clock.

548
00:42:46,725 --> 00:42:50,509
And this helps to bring more depth to the overall time controllability sounds,

549
00:42:50,509 --> 00:42:54,172
as well as consistency throughout the level and through the various interactions,

550
00:42:54,172 --> 00:42:56,895
because it gives the ability something that is recognizable,

551
00:42:56,895 --> 00:43:00,558
and then becomes quickly associated with that action of scrolling through time.

552
00:43:00,558 --> 00:43:03,261
So to understand this a little bit better,

553
00:43:03,261 --> 00:43:06,944
we'll watch this video isolating the various layers, as I just explained,

554
00:43:06,944 --> 00:43:09,387
and then we'll move on to our second sound design highlight.

555
00:44:30,729 --> 00:44:33,258
Thanks for watching!

556
00:44:47,730 --> 00:44:50,252
So the second highlight that we wanted to bring you guys

557
00:44:50,252 --> 00:44:52,555
is called the singing ability.

558
00:44:52,555 --> 00:44:55,517
So in the music level, where all gameplay mechanics

559
00:44:55,517 --> 00:44:58,020
are driven by the background music,

560
00:44:58,020 --> 00:45:00,623
Mace singing is used to solve puzzles

561
00:45:00,623 --> 00:45:02,284
and progress through the game.

562
00:45:02,284 --> 00:45:05,147
The challenges here were that the abilities

563
00:45:05,147 --> 00:45:08,831
completely interactive, just like the time control ability,

564
00:45:08,831 --> 00:45:09,672
it's based on player input.

565
00:45:10,457 --> 00:45:16,660
and that it must always be compatible musically with the currently playing background music track.

566
00:45:16,660 --> 00:45:21,823
So this is a perfect time for us to really acknowledge the composition from Gustav and Kristoffer,

567
00:45:21,823 --> 00:45:26,586
our two composers for the game, responsible for all the fantastic music that you hear throughout,

568
00:45:26,586 --> 00:45:31,708
and also Sanja Rajabi, who is the vocalist who performed May's singing for this ability.

569
00:45:33,009 --> 00:45:38,755
So let's start this all by watching a short video showing you how this ability works within the game,

570
00:45:38,755 --> 00:45:42,039
and then we'll delve deeper into how we handle it from a technical standpoint.

571
00:46:02,652 --> 00:46:03,034
Oh

572
00:46:44,598 --> 00:46:49,419
So obviously we knew that we had to do something spectacular with regards to this ability.

573
00:46:49,419 --> 00:47:01,422
The requirements that I outlined previously and the whole way that this ability interacted with the actual music made us sit down and build glorious plans on how to make the singing always feel dynamic and musical.

574
00:47:01,422 --> 00:47:07,143
So we decided that we had to build a sampler.

575
00:47:07,143 --> 00:47:13,244
We started this by drawing up a sheet that outlined the kind of audio content we needed to make the sampler come alive.

576
00:47:14,016 --> 00:47:20,600
The conclusion that we came to was that for each scale of each music track, for each four sub levels,

577
00:47:20,600 --> 00:47:27,945
we would then sample each note of the scale with three different intensities ranging from low to high,

578
00:47:27,945 --> 00:47:36,711
so that the like the velocity setting on an actual sampler, this would allow us to have some control over the energy and the singing based on the gameplay circumstances.

579
00:47:37,897 --> 00:47:41,220
And to keep the vocals from ever feeling static or robotic,

580
00:47:41,220 --> 00:47:43,462
we would also record three different variations

581
00:47:43,462 --> 00:47:45,884
of attack and release per note.

582
00:47:45,884 --> 00:47:49,427
And then lastly, to follow the key of the current music,

583
00:47:49,427 --> 00:47:52,710
May would need to be able to go between sampled notes

584
00:47:52,710 --> 00:47:54,391
whilst singing.

585
00:47:54,391 --> 00:47:57,013
So to realize this in a way that felt natural,

586
00:47:57,013 --> 00:48:00,016
we would include additional layers of glissando

587
00:48:00,016 --> 00:48:03,058
covering each interval of going from every note

588
00:48:03,058 --> 00:48:04,420
to every note in the scale.

589
00:48:05,775 --> 00:48:08,236
And if you're trying to do math in your head right now,

590
00:48:08,236 --> 00:48:11,477
let me just end it by saying that we ended up in source material

591
00:48:11,477 --> 00:48:13,818
that would have ended up in thousands of files.

592
00:48:13,818 --> 00:48:16,560
And furthermore, at this point in time,

593
00:48:16,560 --> 00:48:20,141
we still hadn't sorted the question of who would actually perform

594
00:48:20,141 --> 00:48:23,043
the singing to be recorded for these assets.

595
00:48:23,043 --> 00:48:26,624
And after Filip and I spent two days mocking up a track just to try

596
00:48:26,624 --> 00:48:30,786
and see what it would take to see our grand plans through to success,

597
00:48:30,786 --> 00:48:34,528
it was very clear that we had given ourselves a mammoth of a task.

598
00:48:35,950 --> 00:48:38,533
And so we did something that we do not always do

599
00:48:38,533 --> 00:48:40,475
in the Hayslide Audio team.

600
00:48:40,475 --> 00:48:44,478
We asked ourselves, are we being reasonable right now?

601
00:48:44,478 --> 00:48:48,402
And so we took it back a step.

602
00:48:48,402 --> 00:48:51,745
A big finding in our prototyping is how clear it became

603
00:48:51,745 --> 00:48:53,947
to us that for this feature to be interesting,

604
00:48:53,947 --> 00:48:55,569
keeping the singing in the correct key

605
00:48:55,569 --> 00:48:57,350
would really only get us halfway there.

606
00:48:58,580 --> 00:49:02,182
In our plans to record the different type of source we thought we needed,

607
00:49:02,182 --> 00:49:06,005
we haven't really thought about the importance of allowing the recording singer

608
00:49:06,005 --> 00:49:11,469
to perform to the vocal track in a natural and musical way.

609
00:49:11,469 --> 00:49:15,092
And so we quickly formulated a new plan.

610
00:49:15,092 --> 00:49:19,415
Instead of building a sampler, we would have each music track of the game

611
00:49:19,415 --> 00:49:21,717
be accompanied by an actual vocal track.

612
00:49:22,714 --> 00:49:30,938
Implementing the singing in this way means that we could allow our vocalist to perform to the music in the same way that you would approach any conventional song.

613
00:49:30,938 --> 00:49:34,500
And just like that, the musicality of it all was back.

614
00:49:34,500 --> 00:49:49,307
Now, to make sure that our systems could stay synced with the performance of the singer, we came up with a method where we, our composers would, I should say, for every music track, create a MIDI track that would represent the lead melody performed by the vocals.

615
00:49:49,897 --> 00:49:56,920
The MIDI data then was parsed as wave markers and ingrained into the source files of the singing,

616
00:49:56,920 --> 00:50:02,803
readily available to be read by the game engine. So the result now is that every track has a

617
00:50:02,803 --> 00:50:08,886
full-fledged vocalist track with all the musical bells and whistles. And whenever the singing

618
00:50:08,886 --> 00:50:14,649
ability was activated by the player, this track would be introduced into the mix, playing alongside

619
00:50:14,649 --> 00:50:15,770
the background music.

620
00:50:16,170 --> 00:50:19,891
And by using the data parsed into the markers from the MIDI track,

621
00:50:19,891 --> 00:50:24,552
we could design around specific parts of every vocal track to make sure that whenever singing

622
00:50:24,552 --> 00:50:29,634
stopped, whenever the player stopped using the ability, the singing would fade out nicely

623
00:50:29,634 --> 00:50:36,376
based on the current passage that was playing. So instead of an incredibly complex sampler-like

624
00:50:36,376 --> 00:50:42,217
system that likely would have taken us weeks, if not months, to deliver on, we built a really,

625
00:50:42,217 --> 00:50:43,858
really nice volume slider.

626
00:50:45,044 --> 00:50:58,009
So a tricky aspect of our original plan had always been ensuring that whenever the singing stopped, it would fade out in a natural way, since that happens at a moment's notice, whenever the player decides to stop the ability.

627
00:50:58,009 --> 00:51:03,912
And short notes here were especially hard to keep from sounding bad when stopping.

628
00:51:03,912 --> 00:51:07,493
But our Marker Program fader really came through in solving that issue for us.

629
00:51:09,445 --> 00:51:10,847
So now in the following video here,

630
00:51:10,847 --> 00:51:12,728
you will see the effect of these markers

631
00:51:12,728 --> 00:51:15,171
as we progress through the music of the singing.

632
00:51:15,171 --> 00:51:17,853
And pay attention to the top of the screen,

633
00:51:17,853 --> 00:51:20,876
you will see gray bars that shows the markers

634
00:51:20,876 --> 00:51:23,378
and each of them denotes if the vocal track

635
00:51:23,378 --> 00:51:25,140
is currently allowed to stop

636
00:51:25,140 --> 00:51:26,761
when the player is no longer singing,

637
00:51:26,761 --> 00:51:28,863
and if so, how quickly it should fade out.

638
00:52:12,440 --> 00:52:17,383
And finally, here are a few summary points and lessons learned to conclude this presentation.

639
00:52:17,383 --> 00:52:24,088
The key words surrounding the story of creating the soundscape of It Takes Two include deterministic,

640
00:52:24,088 --> 00:52:28,651
we left as little as possible to chance, and as much as possible to remain in our control.

641
00:52:28,651 --> 00:52:32,654
So for example, by designing sounds made to fit the screen space as opposed to aiming

642
00:52:32,654 --> 00:52:35,656
for a fully spatialized mix and just hope for the best.

643
00:52:35,996 --> 00:52:40,339
We wanted to make sure both players would always experience the game as nicely as possible,

644
00:52:40,339 --> 00:52:42,861
and that meant taking control over a few things.

645
00:52:42,861 --> 00:52:48,064
So for example, by designing important sounds in 2D, meaning leaving them in the left-center-right

646
00:52:48,064 --> 00:52:52,147
speakers instead of spatializing them and risking them ending up sounding from the wrong side of the

647
00:52:52,147 --> 00:52:58,171
screen. The same goes for leaving our quad ambience static. While a different approach might have been

648
00:52:58,171 --> 00:53:02,954
beneficial for a different type of game, this deterministic strategy has been essential in

649
00:53:02,954 --> 00:53:04,635
creating the sound for It Takes Two.

650
00:53:05,654 --> 00:53:07,356
And then the simpler the better.

651
00:53:07,356 --> 00:53:10,298
The design of both the sounds and the systems

652
00:53:10,298 --> 00:53:13,060
needed to start simple and to be built upon

653
00:53:13,060 --> 00:53:14,121
based on pure necessity,

654
00:53:14,121 --> 00:53:16,623
as opposed to designing complex systems

655
00:53:16,623 --> 00:53:18,825
and complex environments just because we can.

656
00:53:18,825 --> 00:53:21,428
So what matters is really the result.

657
00:53:21,428 --> 00:53:23,850
Our experience in It Takes Two has shown us.

658
00:53:23,930 --> 00:53:28,393
that the most complex solutions are not always the best sounding result.

659
00:53:28,393 --> 00:53:32,816
And both the time control ability and the singing ability are excellent examples.

660
00:53:32,816 --> 00:53:37,960
Another example is choosing to deliver this game in stereo in 5.1 as opposed to object-based.

661
00:53:37,960 --> 00:53:44,705
And this was based entirely on what we believed would do the greater service to the split-screen soundscape and the clarity of the mix.

662
00:53:45,944 --> 00:53:48,605
And then prioritization.

663
00:53:48,605 --> 00:53:51,447
In a split-screen game, if everything

664
00:53:51,447 --> 00:53:54,608
is audible at the same time, it just becomes messy.

665
00:53:54,608 --> 00:53:58,490
So maintaining clarity is all about prioritizing and choosing

666
00:53:58,490 --> 00:53:59,531
what is important.

667
00:53:59,531 --> 00:54:01,452
And finally, teamwork.

668
00:54:01,452 --> 00:54:05,134
In our team, we rely on each other's strengths and skill

669
00:54:05,134 --> 00:54:07,255
sets to raise the bar to the highest level.

670
00:54:07,255 --> 00:54:09,896
Our collaboration between the technical

671
00:54:09,896 --> 00:54:12,758
and the creative designers has been truly essential

672
00:54:12,758 --> 00:54:14,278
to bring this project to success.

673
00:54:15,543 --> 00:54:21,265
And finally, it's important to say that all our solutions worked very nicely for this specific game,

674
00:54:21,265 --> 00:54:24,226
but split-screen audio is truly a Pandora's box,

675
00:54:24,226 --> 00:54:28,848
and a different project might require entirely different solutions,

676
00:54:28,848 --> 00:54:33,510
but that with those takeaways, we are confident that we are ready for the next challenge.

677
00:54:33,510 --> 00:54:39,672
Thank you very much for attending this presentation, and we hope you enjoyed it.

678
00:54:39,672 --> 00:54:42,493
You just stay right where you are, San Francisco. See you soon.

