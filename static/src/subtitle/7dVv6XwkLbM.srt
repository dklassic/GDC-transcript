1
00:00:08,374 --> 00:00:11,198
Hi everyone, my name is Guillaume Coron.

2
00:00:11,799 --> 00:00:14,142
I am a senior graphic programmer at Contic Dream.

3
00:00:15,584 --> 00:00:17,527
Contic Dream is a studio which creates games

4
00:00:17,567 --> 00:00:19,169
with strong visual and story.

5
00:00:20,391 --> 00:00:23,034
And we have our own in-house engine.

6
00:00:24,450 --> 00:00:27,211
This talk is an overview of various rendering techniques

7
00:00:27,391 --> 00:00:29,931
used in our two previous games and in the current one.

8
00:00:30,872 --> 00:00:32,992
It mainly focuses on lighting and shading.

9
00:00:33,713 --> 00:00:38,134
My co-worker Thibaut is credited here for his help

10
00:00:38,814 --> 00:00:41,735
on this presentation, but he's not with us today.

11
00:00:43,676 --> 00:00:43,896
OK.

12
00:00:44,516 --> 00:00:47,597
The first part will focus on our need to be physically best

13
00:00:48,137 --> 00:00:50,678
and the path we choose from Heavy Rain to Detroit

14
00:00:50,718 --> 00:00:51,238
Become Human.

15
00:00:52,488 --> 00:00:55,150
I will discuss why we are using photometric units

16
00:00:55,550 --> 00:00:57,411
and the need to have material calibration

17
00:00:57,491 --> 00:00:58,352
and validation tools.

18
00:00:59,632 --> 00:01:02,974
Then I will explain the direct lighting and shadow techniques

19
00:01:03,154 --> 00:01:05,555
you will use in your game.

20
00:01:06,196 --> 00:01:09,417
And I will make a brief talk about our volumetric lighting

21
00:01:09,457 --> 00:01:09,878
solution.

22
00:01:10,778 --> 00:01:13,319
And I will finish with our indirect lighting

23
00:01:13,399 --> 00:01:14,060
implementation.

24
00:01:14,960 --> 00:01:17,381
But let's start with a quick trailer of Detroit

25
00:01:17,421 --> 00:01:17,982
Become Human.

26
00:01:18,682 --> 00:01:20,403
I'm the android sent by Cyberlight.

27
00:01:23,572 --> 00:01:31,616
You have to accept the world as it is, or fight.

28
00:01:31,696 --> 00:01:32,697
My name is Connor.

29
00:01:33,057 --> 00:01:34,258
My name is Marcus.

30
00:01:34,598 --> 00:01:35,859
My name is Connor.

31
00:01:35,899 --> 00:01:38,320
This is our story.

32
00:01:38,820 --> 00:01:43,983
For the players.

33
00:01:47,265 --> 00:01:49,966
OK, get back a little bit in the past

34
00:01:50,186 --> 00:01:51,907
and talk about our previous game.

35
00:01:53,444 --> 00:01:57,247
Every run was the PS3 game based on forward rendering engine.

36
00:01:57,828 --> 00:02:00,229
All the shading and lighting was done in gamma space,

37
00:02:00,810 --> 00:02:03,232
and the BLDF was derived from BlinFoam.

38
00:02:03,532 --> 00:02:04,313
It's pretty classic.

39
00:02:05,814 --> 00:02:09,577
On Beyond Tosu, we converted our rendering engine

40
00:02:09,677 --> 00:02:10,678
to a different one.

41
00:02:11,538 --> 00:02:13,880
All material evolution remained in gamma space,

42
00:02:14,100 --> 00:02:16,442
but lighting and shading are done in linear space.

43
00:02:18,143 --> 00:02:21,604
We use a more refined BRDF based on micro-facet theory

44
00:02:22,244 --> 00:02:25,344
with some approximation to fit the PS3 capability.

45
00:02:29,485 --> 00:02:30,785
For Detroit Become Human,

46
00:02:31,106 --> 00:02:33,686
we get back to cluster forward shading

47
00:02:34,526 --> 00:02:36,607
to have more flexibility on all materials.

48
00:02:37,547 --> 00:02:40,167
All our rendering pipeline is now in linear space

49
00:02:40,388 --> 00:02:45,048
and we use micro-facet BRDF mainly based on GJX distribution

50
00:02:45,889 --> 00:02:47,489
with support of anisotropy.

51
00:02:49,277 --> 00:02:52,679
The diffuse part still use a vanilla Lambertian diffuse term,

52
00:02:53,859 --> 00:02:56,201
and we do partial energy conservation

53
00:02:56,261 --> 00:02:57,942
between diffuse and specular.

54
00:03:00,103 --> 00:03:03,184
Photometric units are used for all intensity

55
00:03:03,644 --> 00:03:06,266
on both analytical light and emissive surfaces.

56
00:03:09,807 --> 00:03:12,349
All our material are built by our artists

57
00:03:12,669 --> 00:03:14,009
with the help of a shading tree.

58
00:03:15,090 --> 00:03:19,191
This is very powerful and can be hard to control performances

59
00:03:19,351 --> 00:03:20,432
and global coherency.

60
00:03:21,412 --> 00:03:23,693
Some materials can have multiple specular lobes,

61
00:03:24,013 --> 00:03:25,954
like the skin shader, the car paint,

62
00:03:26,254 --> 00:03:28,094
or even the lid shader in some cases.

63
00:03:32,336 --> 00:03:34,337
To handle this kind of materials,

64
00:03:37,398 --> 00:03:40,679
we have implemented something we call a BRDF layer stack.

65
00:03:42,417 --> 00:03:45,559
We split our BRDF in multiple layers and stack them.

66
00:03:46,640 --> 00:03:49,502
Material can have two specular lobes, plus one diffuse

67
00:03:49,702 --> 00:03:52,303
and one subsurface or backscattering one.

68
00:03:53,744 --> 00:03:56,526
For example, the lead shader have only one specular lobe

69
00:03:56,566 --> 00:04:01,990
by default, but it can be possible to add a second

70
00:04:02,070 --> 00:04:04,752
for metallic materials with render effect on them.

71
00:04:08,320 --> 00:04:13,844
Energy conservation between layers is required, and each layer computes its reflected and transmitted energy.

72
00:04:14,925 --> 00:04:18,308
The remaining energy is reused to compute the next layer.

73
00:04:18,748 --> 00:04:24,613
To have a perfect energy conservation, we will need to pre-compute energy transfer over the entire BRDF,

74
00:04:24,933 --> 00:04:28,035
taking into account multiple scattering, Fresnel, and absorption.

75
00:04:29,417 --> 00:04:35,421
This approach was not retained by the fear of the costs introduced by multiple lookups needed to achieve this.

76
00:04:37,098 --> 00:04:39,699
And unfortunately, we just take into account

77
00:04:39,739 --> 00:04:42,560
the Fresnel interface to achieve energy conservation

78
00:04:42,600 --> 00:04:43,220
between layers.

79
00:04:45,080 --> 00:04:49,282
But a recent talk by Christopher Kula and Alejandro Conti

80
00:04:49,362 --> 00:04:51,482
at last year's Seagraph on this subject

81
00:04:51,563 --> 00:04:54,423
gave us some hope to use such a technique in our next project.

82
00:04:58,045 --> 00:05:01,886
OK, now you have an overview of how our shading is processed.

83
00:05:02,466 --> 00:05:04,087
And I can talk about the issue we

84
00:05:04,107 --> 00:05:05,427
faced in the production cycle.

85
00:05:07,443 --> 00:05:12,685
Before Detroit become human, each artist build their own level and add their own habit.

86
00:05:14,325 --> 00:05:21,607
Lighting from one scene to another could be very different, even under identical light condition.

87
00:05:22,988 --> 00:05:24,908
Materials was not spared by this issue.

88
00:05:26,259 --> 00:05:29,682
In this case, it was really hard to reuse props

89
00:05:29,762 --> 00:05:32,025
in different scenes and understand who is the culprit.

90
00:05:32,405 --> 00:05:33,966
Is it the material or the lighting?

91
00:05:34,627 --> 00:05:36,649
For all this reason, we decided to move

92
00:05:36,689 --> 00:05:40,172
to photometric units to fix a part of the problem.

93
00:05:43,675 --> 00:05:45,958
When we started to this development,

94
00:05:46,338 --> 00:05:47,939
light coherency was our main goal.

95
00:05:49,702 --> 00:05:52,282
With photometric units, it was easier to compare

96
00:05:52,322 --> 00:05:54,142
sunlighting to real-life references,

97
00:05:55,383 --> 00:05:59,864
and artists can use real-life measured value.

98
00:06:01,104 --> 00:06:03,264
It gives guidelines for artists to correctly

99
00:06:03,464 --> 00:06:05,645
lead their scene, and by the same way,

100
00:06:06,105 --> 00:06:08,085
it presents them from unconsciously back

101
00:06:08,205 --> 00:06:11,506
lighting information in their albedo.

102
00:06:11,606 --> 00:06:15,767
For example, when they do darker albedo for night scene.

103
00:06:17,572 --> 00:06:20,934
And finally, intensity range between bright and dark area

104
00:06:20,954 --> 00:06:22,296
of the scene are more plausible.

105
00:06:23,617 --> 00:06:26,899
For more information about photometric units,

106
00:06:27,079 --> 00:06:28,841
you can refer to a great presentation

107
00:06:28,921 --> 00:06:30,803
by Sebastien Lagarde and Charles de Roussier

108
00:06:31,383 --> 00:06:34,586
called Moving Frostbite to Physically Based Rendering.

109
00:06:37,468 --> 00:06:40,811
Let's do a quick reminder about photometric units.

110
00:06:43,233 --> 00:06:45,775
You have the luminous power that can be expressed in lumen.

111
00:06:47,003 --> 00:06:51,384
was the total light amount energy emitted by light.

112
00:06:52,865 --> 00:06:56,285
The luminous intensity that was expressed in candela

113
00:06:56,565 --> 00:07:00,086
is the luminous power per solid angle direction of a light.

114
00:07:01,826 --> 00:07:04,207
The illuminance that can be expressed in lux,

115
00:07:06,587 --> 00:07:10,088
that was the light amount falling on the surface.

116
00:07:11,348 --> 00:07:14,209
And the luminance that can be expressed in candela

117
00:07:14,229 --> 00:07:14,909
per square meter.

118
00:07:16,737 --> 00:07:20,219
And it's per unit area of candela in specific direction.

119
00:07:23,520 --> 00:07:25,761
Directional light can be expressed in lux,

120
00:07:25,981 --> 00:07:28,722
because as seen previously, lux is the light amount

121
00:07:28,742 --> 00:07:29,602
falling on a surface.

122
00:07:30,783 --> 00:07:33,464
Other lights can be expressed in lumen,

123
00:07:33,824 --> 00:07:36,425
or in candela per square meter if area lights are used.

124
00:07:37,904 --> 00:07:40,366
You can see some luminous power references provided

125
00:07:40,426 --> 00:07:44,070
by Sebastien Lagarde in this presentation of the subject.

126
00:07:44,230 --> 00:07:46,652
And as you can see, the range between values

127
00:07:46,712 --> 00:07:47,593
can be really high.

128
00:07:49,795 --> 00:07:52,457
Quadratic attenuation are mandatory for punctual light

129
00:07:52,477 --> 00:07:54,579
sources to compute correct illuminance

130
00:07:56,081 --> 00:07:57,362
at the surface of object.

131
00:07:57,582 --> 00:08:01,485
And illuminance can be really high near the punctual light

132
00:08:01,505 --> 00:08:01,846
sources.

133
00:08:04,384 --> 00:08:08,107
For emissive surfaces, we add an emissive intensity parameter

134
00:08:08,247 --> 00:08:12,530
on all materials in combination with a traditional emissive

135
00:08:12,550 --> 00:08:12,830
color.

136
00:08:14,171 --> 00:08:18,755
Emissive intensity is expressed in exposure value, heavy

137
00:08:18,935 --> 00:08:20,296
or stop in photography.

138
00:08:21,416 --> 00:08:24,599
But why are we using heavy and not candela per square meter,

139
00:08:24,839 --> 00:08:28,462
which might be a more logical unit

140
00:08:28,542 --> 00:08:29,923
to use for emissive surfaces?

141
00:08:31,844 --> 00:08:33,825
Candela per square meter is a linear scale,

142
00:08:34,506 --> 00:08:37,188
but is not perceived as such by the human eye.

143
00:08:38,368 --> 00:08:42,571
But EV is perceptually linear scale for the human vision,

144
00:08:42,992 --> 00:08:45,694
and adding one unit in EV

145
00:08:45,834 --> 00:08:47,615
double the perceived light intensity.

146
00:08:50,417 --> 00:08:51,898
To work with such high range,

147
00:08:52,279 --> 00:08:53,960
we need to correctly expose our scene

148
00:08:54,120 --> 00:08:55,401
even in our level editor.

149
00:08:56,720 --> 00:08:59,481
Using an auto exposure is not recommended.

150
00:08:59,881 --> 00:09:01,522
It can easily break your landmark.

151
00:09:02,482 --> 00:09:04,383
To keep real life comparison,

152
00:09:04,723 --> 00:09:07,945
we use measured exposure for triple light condition.

153
00:09:10,506 --> 00:09:12,967
And fortunately, all level are split

154
00:09:13,047 --> 00:09:14,207
in volume called scene zone.

155
00:09:14,788 --> 00:09:16,869
This scene zone are used for visibility

156
00:09:16,989 --> 00:09:18,509
in combination of portals,

157
00:09:19,430 --> 00:09:22,091
and usually match a room in a house.

158
00:09:24,139 --> 00:09:26,381
We add to them our exposure information.

159
00:09:27,121 --> 00:09:28,983
In this case, our director of photography

160
00:09:29,043 --> 00:09:31,926
provide exposure references for set artists.

161
00:09:33,287 --> 00:09:34,949
The scene exposure are fixed,

162
00:09:35,790 --> 00:09:37,452
are fixed value for the scene zone,

163
00:09:37,732 --> 00:09:39,894
and there is no camera transition.

164
00:09:41,395 --> 00:09:43,658
We instantly apply exposure

165
00:09:43,678 --> 00:09:45,640
when the camera enter in the scene zone.

166
00:09:49,410 --> 00:09:52,170
Scene exposure is expressed in EV100.

167
00:09:52,530 --> 00:09:55,051
It represents a combination of camera shutter speed

168
00:09:55,151 --> 00:09:58,911
and f-number for ISO100 sensor sensibility.

169
00:09:58,931 --> 00:10:04,492
Scene exposure is a great tool to ensure

170
00:10:04,512 --> 00:10:06,793
that our lighting was in coherent ranges

171
00:10:07,033 --> 00:10:07,913
for asset production.

172
00:10:09,013 --> 00:10:12,434
And it is really useful to pre-expose

173
00:10:12,534 --> 00:10:13,514
our accumulation buffer.

174
00:10:14,954 --> 00:10:17,015
But it's not enough for in-game exposure.

175
00:10:17,987 --> 00:10:19,147
where we need more control.

176
00:10:20,908 --> 00:10:23,328
And that's why we introduced camera exposure.

177
00:10:26,249 --> 00:10:28,670
Camera exposure is an exposure composition

178
00:10:28,850 --> 00:10:29,970
over the scene exposure.

179
00:10:31,031 --> 00:10:34,632
And it gives more control to dynamically change the exposure.

180
00:10:35,812 --> 00:10:38,593
Artists are able to choose between four different camera

181
00:10:38,793 --> 00:10:40,374
exposure types, depending on their need.

182
00:10:41,474 --> 00:10:44,855
Auto exposure are mainly used in gameplay phases,

183
00:10:45,055 --> 00:10:46,856
and manual exposure on cut scenes.

184
00:10:51,588 --> 00:10:56,171
Okay, the first one, we call it manual exposure.

185
00:10:57,332 --> 00:11:00,094
The exposure value is in EV100

186
00:11:00,154 --> 00:11:01,996
and can be controlled by animated curve.

187
00:11:03,857 --> 00:11:05,899
The second one is called camera.

188
00:11:06,439 --> 00:11:12,143
It computes exposure from physical camera setting,

189
00:11:12,764 --> 00:11:15,646
like the half stop, the ISO, and shutter speed.

190
00:11:17,333 --> 00:11:20,575
We have an auto average that computes

191
00:11:22,636 --> 00:11:25,878
the exposure from the log average luminance of the scene.

192
00:11:26,218 --> 00:11:26,998
That's pretty classic.

193
00:11:28,259 --> 00:11:31,141
And the last one is called auto UV zone.

194
00:11:32,001 --> 00:11:34,523
It's a little bit special.

195
00:11:35,564 --> 00:11:39,846
It computes the exposure from the value provided

196
00:11:39,866 --> 00:11:45,570
in the scene zone in addition to decals, exposure decals

197
00:11:45,650 --> 00:11:47,992
manually placed in the scene.

198
00:11:50,934 --> 00:11:55,357
This screen capture represents our camera auto EV debug view.

199
00:11:56,217 --> 00:11:58,859
As you maybe can see on the scale on the right,

200
00:11:59,959 --> 00:12:02,741
All the pixels in the room have neutral exposure compensation.

201
00:12:03,362 --> 00:12:05,483
This is because the camera is currently

202
00:12:05,583 --> 00:12:07,265
in the scene zone of the room.

203
00:12:08,646 --> 00:12:11,708
All the pixels outside of the house

204
00:12:11,948 --> 00:12:13,830
are in a different scene zone, which

205
00:12:13,890 --> 00:12:17,593
is approximately three steps above the current scene zone.

206
00:12:17,693 --> 00:12:19,254
This is the right pixel.

207
00:12:20,555 --> 00:12:21,896
It's the red pixel, sorry.

208
00:12:23,834 --> 00:12:27,336
And the dark pixel near the entrance

209
00:12:27,456 --> 00:12:31,459
was EV decal manually placed by artist to control exposure.

210
00:12:32,599 --> 00:12:35,381
This decal was approximately half a stop

211
00:12:35,421 --> 00:12:36,882
below the current scene exposure.

212
00:12:37,702 --> 00:12:38,943
And now let's see it in action.

213
00:12:42,325 --> 00:12:44,566
You can see the box of the decal near the door.

214
00:12:48,124 --> 00:12:51,206
And when the camera sees all the pixels in this zone,

215
00:12:52,427 --> 00:12:54,729
the exposure, the total exposure is down.

216
00:12:55,649 --> 00:12:58,392
And as you can see, when the camera goes out,

217
00:12:58,792 --> 00:13:00,113
the same exposures change.

218
00:13:00,794 --> 00:13:03,976
But the camera exposure do compensation

219
00:13:04,096 --> 00:13:05,677
to have a smooth transition.

220
00:13:12,983 --> 00:13:13,083
OK.

221
00:13:14,954 --> 00:13:18,355
To work with photometric units, we developed a lot of debug tools.

222
00:13:19,855 --> 00:13:21,035
Here is some examples.

223
00:13:21,375 --> 00:13:23,556
The first one is virtual spot meters

224
00:13:23,576 --> 00:13:25,476
that give us pixel absolute luminance

225
00:13:25,816 --> 00:13:28,037
in candela per square meter and EV100.

226
00:13:29,117 --> 00:13:32,818
It also gives us RGB value of our accumulation buffer.

227
00:13:33,618 --> 00:13:36,499
It's really useful to tweak emissive surfaces

228
00:13:36,659 --> 00:13:39,180
and debug high value in specular reflection.

229
00:13:43,960 --> 00:13:46,921
And the second one is a fast color debug screen

230
00:13:47,221 --> 00:13:50,262
that helps us to check if a scene is well exposed.

231
00:13:52,043 --> 00:13:54,924
It highlights range for correct exposed middle gray,

232
00:13:55,104 --> 00:13:58,905
skin tone, and ranges for creased black and burnt white.

233
00:13:59,905 --> 00:14:02,226
This debug screen is really useful

234
00:14:02,326 --> 00:14:03,967
for our director of photography

235
00:14:03,987 --> 00:14:06,828
to check if the scene was correctly exposed.

236
00:14:11,554 --> 00:14:15,897
Now, with all the work done on the photometric units and exposure,

237
00:14:16,417 --> 00:14:21,401
we have a good framework for lighting with real light references and consistent value.

238
00:14:22,922 --> 00:14:25,844
But if we don't want to break all the work done on the lighting,

239
00:14:26,204 --> 00:14:27,505
material needs the same treatment.

240
00:14:28,946 --> 00:14:32,929
Our first idea was to scan a huge quantity of material to use them on our game,

241
00:14:33,109 --> 00:14:37,072
but it was not possible for us to do it. We don't have the workforce for it.

242
00:14:39,417 --> 00:14:42,298
Even if we are not able to scan all materials,

243
00:14:42,398 --> 00:14:44,258
we really want to capture some objects

244
00:14:44,298 --> 00:14:45,319
and material references.

245
00:14:46,239 --> 00:14:49,660
To do this, we needed to build a controlled environment

246
00:14:50,800 --> 00:14:53,021
that was easy to reproduce in our engine.

247
00:14:54,601 --> 00:14:56,962
We built a black room with three incandescent bulbs

248
00:14:57,422 --> 00:14:59,542
and captured reference material and objects.

249
00:15:01,323 --> 00:15:03,403
All this process also gave us possibility

250
00:15:03,443 --> 00:15:05,624
to validate the work done on photometric units

251
00:15:05,764 --> 00:15:08,885
and capture our first full-range image baselight.

252
00:15:12,030 --> 00:15:15,914
Around this, we built a tool called the HighSync tool

253
00:15:16,154 --> 00:15:18,196
that provides calibrated environment

254
00:15:18,676 --> 00:15:20,758
and easy access to material properties.

255
00:15:21,779 --> 00:15:25,722
It is really important to use full range image baseline

256
00:15:25,762 --> 00:15:28,364
to have a result as close as possible to the reality.

257
00:15:29,685 --> 00:15:32,267
You could find some interesting information on this subject

258
00:15:32,888 --> 00:15:34,850
on a presentation by Sébastien Lagarde

259
00:15:35,970 --> 00:15:38,853
called An Artist-Friendly Workflow for Panoramic HDRI.

260
00:15:41,412 --> 00:15:44,374
Artists can easily check their props in this tool

261
00:15:44,574 --> 00:15:46,835
and check if the materials are correct.

262
00:15:48,576 --> 00:15:49,836
Screenshot of this tool.

263
00:15:50,217 --> 00:15:52,458
Let's see the screenshot.

264
00:15:54,059 --> 00:15:56,820
The panel of the left give easy access

265
00:15:57,240 --> 00:15:58,901
to display material properties.

266
00:16:00,202 --> 00:16:02,323
And the props and character of the game

267
00:16:02,403 --> 00:16:04,184
can be verified in this tool.

268
00:16:04,224 --> 00:16:07,346
It's pretty useful to detect wrong material setup.

269
00:16:10,829 --> 00:16:19,137
In addition to the icing tool, we provide some debug options to highlight values with out of range material properties.

270
00:16:20,579 --> 00:16:29,928
Wrong base color is highlighted in red, wrong Fresnel value for glass shader in blue, and material with wrong metallic setup in yellow.

271
00:16:30,828 --> 00:16:33,951
It's really useful to quickly understand what's wrong with your material.

272
00:16:35,896 --> 00:16:37,017
Let's see some example.

273
00:16:37,957 --> 00:16:42,420
This allows us to identify that the base color

274
00:16:42,500 --> 00:16:44,041
of the snow are often too high,

275
00:16:45,642 --> 00:16:49,184
and the glass shader often have too high reflectance value.

276
00:16:50,645 --> 00:16:54,308
And in some cases, we could find some strange setup,

277
00:16:54,788 --> 00:16:58,070
like for the sofa, that have metallic property on it.

278
00:17:04,634 --> 00:17:07,216
Now let's talk about our lighting and shadowing solution.

279
00:17:10,178 --> 00:17:11,839
Okay, we use photometric units

280
00:17:12,279 --> 00:17:13,480
and have calibration material.

281
00:17:14,060 --> 00:17:15,721
But what about analytical light?

282
00:17:16,662 --> 00:17:20,124
All of our analytical light were punctual sources.

283
00:17:20,745 --> 00:17:23,386
We have a direction light, a point light, and spotlight,

284
00:17:23,947 --> 00:17:26,969
and a projector light that is a directional light

285
00:17:27,009 --> 00:17:28,750
constrained in a box with attenuation.

286
00:17:28,970 --> 00:17:29,510
Pretty simple.

287
00:17:32,380 --> 00:17:34,141
Attenuation is quadratic by default,

288
00:17:34,281 --> 00:17:38,062
but artists can tweak the value from zero to two.

289
00:17:38,723 --> 00:17:41,104
It is useful to fake bigger light

290
00:17:41,184 --> 00:17:42,564
by decreasing the attenuation.

291
00:17:44,785 --> 00:17:46,966
The quadratic attenuation is combined

292
00:17:47,006 --> 00:17:50,228
with an attenuation radius that try to preserve energy

293
00:17:50,388 --> 00:17:54,510
as much as possible, but energy loss is unavoidable

294
00:17:54,570 --> 00:17:55,510
at the end of the radius.

295
00:17:59,452 --> 00:18:01,693
But punctual light sources.

296
00:18:03,545 --> 00:18:07,167
But with punctual sources, some really high intensity peak

297
00:18:07,187 --> 00:18:08,768
can appear in the specular reflection.

298
00:18:09,669 --> 00:18:12,470
This issue is mostly present in materials

299
00:18:12,510 --> 00:18:14,352
with mid and low roughness.

300
00:18:16,333 --> 00:18:18,874
To fix this issue, we have implemented area light

301
00:18:19,055 --> 00:18:20,195
using closest point techniques.

302
00:18:21,376 --> 00:18:23,457
But forward rendering mean all lights

303
00:18:23,557 --> 00:18:24,898
need to be an area light.

304
00:18:28,317 --> 00:18:31,340
This introduces additional cost to lighting,

305
00:18:31,480 --> 00:18:32,922
and artists should have to re-lit

306
00:18:32,942 --> 00:18:34,183
all the scene already lit.

307
00:18:36,165 --> 00:18:39,247
And unfortunately, it was too late in the production cycle

308
00:18:40,068 --> 00:18:43,071
to integrate them in the current game.

309
00:18:46,034 --> 00:18:48,336
Finally, we slightly biased the material roughness

310
00:18:48,356 --> 00:18:49,117
to prevent the issue.

311
00:18:54,041 --> 00:18:54,202
Okay.

312
00:18:56,029 --> 00:18:59,373
With light, with different shading,

313
00:19:00,274 --> 00:19:04,019
we were able to use custom geometry easily.

314
00:19:04,980 --> 00:19:08,545
It's up to constrain light in an arbitrary geometry

315
00:19:08,605 --> 00:19:12,289
to prevent them to leak from wall or even without shadow.

316
00:19:13,829 --> 00:19:16,632
But because we have a forward engine,

317
00:19:17,213 --> 00:19:20,016
it was not trivial to use custom light geometry

318
00:19:20,076 --> 00:19:20,856
like we've done before.

319
00:19:21,597 --> 00:19:23,259
To handle a part of the problem,

320
00:19:24,080 --> 00:19:26,362
we have added an orientable near-clip plane

321
00:19:26,823 --> 00:19:28,164
on all of our light.

322
00:19:28,685 --> 00:19:31,387
It's very useful and cheap to add light positioning

323
00:19:31,948 --> 00:19:33,390
without custom light geometry.

324
00:19:35,345 --> 00:19:38,707
We also had some visibility flag on our lights

325
00:19:39,127 --> 00:19:41,489
that give us the possibility to reject light

326
00:19:41,589 --> 00:19:43,350
per cluster and per pixel.

327
00:19:44,411 --> 00:19:47,153
A light can lit all the scene zone of a level

328
00:19:47,433 --> 00:19:51,276
or just the scene zone where the light is in

329
00:19:51,776 --> 00:19:55,298
or all the scene zone visible by the light,

330
00:19:55,899 --> 00:19:56,820
the first term of the light.

331
00:19:58,588 --> 00:20:03,312
It prevents leaking from light with a shadow and it's great for performances.

332
00:20:03,992 --> 00:20:11,519
By example, in a house, a light on the second floor won't lit the pixel of the first floor with this flag on it.

333
00:20:15,202 --> 00:20:18,265
Okay, now let's introduce our close-up lighting system.

334
00:20:21,018 --> 00:20:24,378
Our game are story-driven with many close-up camera shots.

335
00:20:25,059 --> 00:20:28,099
We want to be able to lit our close-up shot

336
00:20:28,179 --> 00:20:29,039
like on a movie set.

337
00:20:29,659 --> 00:20:32,240
And we pay special attention to the lighting.

338
00:20:33,860 --> 00:20:37,901
With our tool, we are able to edit the lighting of all

339
00:20:38,121 --> 00:20:40,161
camera shots on a post-production phase.

340
00:20:40,881 --> 00:20:43,102
Artists can choose for each camera track

341
00:20:43,562 --> 00:20:46,042
what object will receive our close-up light

342
00:20:46,222 --> 00:20:49,183
and can also add some exposure track on them.

343
00:20:51,710 --> 00:20:59,658
On the engine side, the close-up lighting is a set of light used to replace the regular lighting.

344
00:21:01,339 --> 00:21:04,702
Artists choose objects that will be lit by the close-up light set.

345
00:21:05,723 --> 00:21:12,229
They can also affect the indirect contribution with GEI and IBL color multiplier.

346
00:21:13,430 --> 00:21:17,074
They can flag a regular light in the scene as additional close-up light.

347
00:21:18,393 --> 00:21:21,715
And close-up light always use our close-up shadow system

348
00:21:21,936 --> 00:21:23,096
that we'll explain later.

349
00:21:24,317 --> 00:21:26,539
And it have its own light cluster

350
00:21:26,619 --> 00:21:30,902
fitted to the bounding box of the close-up selection.

351
00:21:31,663 --> 00:21:35,646
And the size of this additional cluster is 11 by 11 by 4.

352
00:21:37,827 --> 00:21:41,010
OK, let's see a screenshot with our close-up lighting on

353
00:21:41,190 --> 00:21:43,251
and another with the close-up lighting off.

354
00:21:43,972 --> 00:21:45,193
It's pretty useful in this case.

355
00:21:50,656 --> 00:21:56,421
Now that the subject of direct lighting has been approached, I can talk about our choices,

356
00:21:57,121 --> 00:21:59,123
the choices we made on the shadow part.

357
00:22:01,665 --> 00:22:07,270
We use classic shadow mapping techniques, but our percentage cross-filtering is done

358
00:22:07,451 --> 00:22:10,133
with 8 samples and temporal super-sampling.

359
00:22:11,314 --> 00:22:16,158
All the samples are jittering using blue noise, and the temporal anti-aliasing softens the

360
00:22:16,198 --> 00:22:16,859
result for us.

361
00:22:18,118 --> 00:22:20,320
The default blur radius is three pixel wide

362
00:22:20,600 --> 00:22:22,622
and can go up to 15 pixels.

363
00:22:25,023 --> 00:22:27,265
Shadow bias is automatically computed

364
00:22:27,345 --> 00:22:28,787
from the geometry normal

365
00:22:28,867 --> 00:22:31,128
and artists do not need to worry about it.

366
00:22:33,270 --> 00:22:37,774
We also implement soft shadow in the form of PCSS,

367
00:22:37,994 --> 00:22:41,057
but it's turned out to be not feasible for us

368
00:22:41,677 --> 00:22:44,279
because of the too high register pressure in your shadow.

369
00:22:45,170 --> 00:22:48,774
But PCSS is still used on all tooth shaders.

370
00:22:57,783 --> 00:23:03,008
Shadow was stored on an atlas of 8192 square pixel texture

371
00:23:03,088 --> 00:23:03,549
at 16 bit precision.

372
00:23:08,475 --> 00:23:12,816
Artists are able to choose between three different sizes for their shadow

373
00:23:13,636 --> 00:23:17,138
and all are multiple of 256 pixels.

374
00:23:19,298 --> 00:23:22,599
Shadows are resized depending on their distance to the camera.

375
00:23:22,840 --> 00:23:24,720
The resolution can be halved at max.

376
00:23:25,540 --> 00:23:29,242
We decrease resolution in four steps to prevent pixel quarrying

377
00:23:30,122 --> 00:23:33,903
and repack them in the atlas when reaching a multiple of 256 pixels.

378
00:23:39,931 --> 00:23:42,051
The shadow atlas was lazily updated,

379
00:23:42,211 --> 00:23:43,892
only if a light move in,

380
00:23:44,452 --> 00:23:46,472
or if something move in their frustum.

381
00:23:47,553 --> 00:23:49,933
Point light faces can be individually excluded,

382
00:23:50,233 --> 00:23:53,234
and we also have a tweakable near clip plane

383
00:23:53,314 --> 00:23:57,235
to help with numerical precision and light positioning.

384
00:23:59,775 --> 00:24:02,796
This clip plane can be correlated or not

385
00:24:03,096 --> 00:24:05,556
with the light near clip plane itself,

386
00:24:05,756 --> 00:24:08,817
but this one is not, don't support rotation.

387
00:24:12,196 --> 00:24:15,018
For the directional light, we use cascaded shadow map

388
00:24:15,519 --> 00:24:18,181
with the same filtering than on the other lights.

389
00:24:18,761 --> 00:24:20,963
I sample with temporary supersampling.

390
00:24:21,944 --> 00:24:24,886
With most transition between shadow split

391
00:24:25,087 --> 00:24:27,509
by using jittering and temporal anti-aliasing,

392
00:24:28,630 --> 00:24:30,911
our cascade have four split at max,

393
00:24:32,032 --> 00:24:35,395
but majority of our scene only have two or three split.

394
00:24:37,282 --> 00:24:40,843
And split distribution is automatically handled.

395
00:24:41,464 --> 00:24:44,625
No artist input needed except for the far distance

396
00:24:44,705 --> 00:24:45,426
of the last split.

397
00:24:48,567 --> 00:24:50,628
We handle a static shadow too.

398
00:24:51,209 --> 00:24:56,191
We try to have a shadow on all lights.

399
00:24:56,912 --> 00:24:59,333
And to do this, we have a static shadow system.

400
00:25:00,133 --> 00:25:03,615
The shadow of a light switch to a static shadow

401
00:25:04,396 --> 00:25:06,176
depending on the camera distance.

402
00:25:07,532 --> 00:25:09,373
They contain only static geometry,

403
00:25:09,733 --> 00:25:14,134
and we do only one sample with bilinear comparison.

404
00:25:14,995 --> 00:25:15,635
It's pretty fast.

405
00:25:17,135 --> 00:25:20,196
All the static shadow are stored on an atlas

406
00:25:20,336 --> 00:25:22,757
of 2,048 square pixels,

407
00:25:23,057 --> 00:25:26,938
and shadow itself are 16 full square pixels.

408
00:25:29,359 --> 00:25:32,520
We are able to have up to 1,024 static shadow in a scene.

409
00:25:36,628 --> 00:25:38,569
Static shadow for the directional light

410
00:25:38,649 --> 00:25:41,211
is handled by a huge texture storing

411
00:25:41,751 --> 00:25:42,731
all the static geometry.

412
00:25:43,252 --> 00:25:44,352
It's a pretty huge texture.

413
00:25:46,994 --> 00:25:48,095
Okay, close-up shadow.

414
00:25:48,915 --> 00:25:51,377
Like for our close-up light system,

415
00:25:51,597 --> 00:25:54,739
we want to have high-quality shadow on our close-up shot.

416
00:25:56,700 --> 00:25:58,621
We are able to have two additional shadow

417
00:25:58,861 --> 00:26:00,122
for our close-up light system,

418
00:26:00,802 --> 00:26:02,423
and the system is always on,

419
00:26:03,063 --> 00:26:04,945
even if we are not in a close-up shot.

420
00:26:06,605 --> 00:26:10,007
All the shadow can be promoted to a close-up one.

421
00:26:12,048 --> 00:26:16,969
Close-up shadow are used to add precision

422
00:26:17,030 --> 00:26:18,290
and contact and self-shadowing.

423
00:26:19,771 --> 00:26:21,971
Artists select a relevant object in the scene

424
00:26:22,012 --> 00:26:23,172
that receive close-up shadow.

425
00:26:23,352 --> 00:26:26,273
By example, all the characters are close-up shadow receiver.

426
00:26:27,594 --> 00:26:30,115
And only this object receive the close-up shadow.

427
00:26:32,156 --> 00:26:32,856
Okay, how it work?

428
00:26:34,668 --> 00:26:37,650
First of all, we compute a bounding volume

429
00:26:38,010 --> 00:26:41,312
of all visible close-up shadows receiver

430
00:26:41,432 --> 00:26:43,693
on the radius of 10 meter around the camera.

431
00:26:45,074 --> 00:26:47,235
The bounding volume of skinned object

432
00:26:47,415 --> 00:26:49,296
are computed from a point cloud

433
00:26:49,576 --> 00:26:52,898
to be able to fit to only the visible part

434
00:26:53,639 --> 00:26:55,360
of the character or the skin object.

435
00:26:56,980 --> 00:26:58,861
Then we fit the first term.

436
00:27:00,588 --> 00:27:04,610
to the binding volume of all the visible close-up receiver.

437
00:27:14,632 --> 00:27:16,513
An object between the light position

438
00:27:16,593 --> 00:27:18,573
and the near plane of the fitted frustum

439
00:27:18,673 --> 00:27:21,054
are projected on this near plane.

440
00:27:24,592 --> 00:27:28,812
In this case, we render only the object in the bonding volume

441
00:27:29,052 --> 00:27:33,173
and all the object between the bonding volume and the light.

442
00:27:35,974 --> 00:27:38,314
Okay, a screenshot with close-up shadow on

443
00:27:39,354 --> 00:27:41,875
and another without the close-up shadow.

444
00:27:42,575 --> 00:27:47,396
It's really help with light leaking and self-shadowing.

445
00:27:50,376 --> 00:27:52,597
Okay, our shadow memory budget.

446
00:27:53,998 --> 00:27:56,560
We have a big chunk of memory dedicated to shadows,

447
00:27:58,502 --> 00:28:01,144
which is about 280 megabytes.

448
00:28:02,385 --> 00:28:05,267
Close-up shadows are stored on the main shadow atlas.

449
00:28:05,728 --> 00:28:09,351
We are able to have between 10 to 1,020

450
00:28:10,132 --> 00:28:11,092
for shadow at a time,

451
00:28:12,594 --> 00:28:15,096
depending on the resolution of the shadow.

452
00:28:16,217 --> 00:28:19,039
By example, in the case of point lights

453
00:28:20,040 --> 00:28:22,362
with six face casting shadow,

454
00:28:24,867 --> 00:28:29,489
At 1024 pixels each, the atlas is filled up

455
00:28:29,749 --> 00:28:30,750
with only 10 lights.

456
00:28:31,250 --> 00:28:33,991
And trust me, this case appears more than once

457
00:28:34,071 --> 00:28:34,672
in the production.

458
00:28:37,453 --> 00:28:37,713
Okay.

459
00:28:39,194 --> 00:28:42,215
Now, a video that displays the shadow atlas.

460
00:28:44,056 --> 00:28:46,217
You can see some close-up shadow

461
00:28:46,697 --> 00:28:48,338
that constantly fit on the character.

462
00:28:49,351 --> 00:28:50,632
you have two close-up shadows.

463
00:28:51,313 --> 00:28:53,455
And on the lower left and lower right,

464
00:28:53,555 --> 00:28:56,398
you can see shadows that resize depending on the distance

465
00:28:56,438 --> 00:28:58,099
with the light source and the camera.

466
00:29:01,923 --> 00:29:04,205
And when the close-up lighting is enabled,

467
00:29:04,425 --> 00:29:06,367
the number of close-up shadows is proportional

468
00:29:06,407 --> 00:29:09,330
to the light count used for the close-up light shot.

469
00:29:19,297 --> 00:29:21,537
OK, shadow performances.

470
00:29:23,038 --> 00:29:28,079
We have 15 to 20 shadow updates on average per frame,

471
00:29:28,519 --> 00:29:29,959
but there is no limit quantity.

472
00:29:31,100 --> 00:29:32,560
It can get wide in some cases.

473
00:29:33,780 --> 00:29:36,001
And on the previous video, the shadow cost

474
00:29:36,061 --> 00:29:39,622
is between 1.5 milliseconds and 3.5 milliseconds.

475
00:29:40,222 --> 00:29:45,723
Majority of OSN don't go over 5 milliseconds for shadow,

476
00:29:47,704 --> 00:29:48,584
the most of the time.

477
00:29:50,567 --> 00:29:54,189
The cost for the close-up shadow are really scene-dependent

478
00:29:54,269 --> 00:29:58,010
and it can be really fast if few objects are reprojected

479
00:29:58,090 --> 00:30:00,991
on the near plane, but it can be really slow

480
00:30:01,652 --> 00:30:04,113
in the case of a tree covering all the first term

481
00:30:04,153 --> 00:30:07,594
of the light because of huge alpha test coverage.

482
00:30:10,456 --> 00:30:12,436
Okay, let's talk about volumetric lighting.

483
00:30:14,347 --> 00:30:18,751
For volumetric lighting, we use an unified volumetric lighting solution

484
00:30:18,811 --> 00:30:24,655
popularized by Bart Wonsky in 2014 and Sébastien Hilaire in 2015.

485
00:30:25,816 --> 00:30:29,979
The technique consists of storing all the medium property and the lighting

486
00:30:30,640 --> 00:30:34,122
to a volumetric texture fitted on the first sum of the light.

487
00:30:35,944 --> 00:30:38,886
It's a kind of deferred shading done on a volumetric buffer.

488
00:30:41,975 --> 00:30:46,378
For more information, I advise you to read the previous paper on this subject.

489
00:30:47,779 --> 00:30:51,781
In our case, we render our volumetric buffer with checkerboard rendering.

490
00:30:52,342 --> 00:30:56,645
The native resolution of our volumetric buffer are 192x108x64 on the base PS4,

491
00:30:56,665 --> 00:30:58,486
and we slightly increase the resolution on the Pro.

492
00:31:12,272 --> 00:31:14,973
The temporal component of the effect

493
00:31:15,073 --> 00:31:17,474
use blue noise jittering on the depth slicing,

494
00:31:18,434 --> 00:31:20,134
and all the features are supported,

495
00:31:20,975 --> 00:31:22,695
all lighting features are supported,

496
00:31:23,976 --> 00:31:28,157
like click plane on the light and shadow,

497
00:31:29,538 --> 00:31:31,119
as well as our indirect lighting.

498
00:31:31,639 --> 00:31:35,340
Fog contribution is supported in our JBaking,

499
00:31:35,500 --> 00:31:37,361
and it gives us an approximation

500
00:31:37,421 --> 00:31:39,282
of multiple scattering in the fog.

501
00:31:46,342 --> 00:31:50,364
Okay, volumetric light can leak through surfaces with this technique

502
00:31:51,025 --> 00:31:56,127
when the light is in the same depth slice than the surface of an opaque object.

503
00:31:58,429 --> 00:32:02,871
As you can see, the light can leak some sample in the cell

504
00:32:04,252 --> 00:32:09,715
and when we compute moving average of all the sample,

505
00:32:10,155 --> 00:32:12,376
the light contribution can be stronger than expected.

506
00:32:15,435 --> 00:32:18,177
For us, it is really important to fix this issue

507
00:32:18,237 --> 00:32:20,439
because we have a lot of small volumetric light

508
00:32:20,639 --> 00:32:21,840
attached to objects.

509
00:32:24,482 --> 00:32:27,704
To fix this issue, we store min-max depth per tile

510
00:32:28,064 --> 00:32:28,785
in two dimension.

511
00:32:30,366 --> 00:32:33,929
We use max depth to clamp voxel thickness

512
00:32:34,129 --> 00:32:35,230
at light evaluation.

513
00:32:37,572 --> 00:32:41,555
And we apply a ZBIAS when sampling the volumetric texture.

514
00:32:44,696 --> 00:32:46,760
that was storing the light catering

515
00:32:46,920 --> 00:32:50,447
when the type variance is above a certain threshold.

516
00:32:51,689 --> 00:32:53,152
That don't fix all the issue,

517
00:32:53,312 --> 00:32:56,177
but it can be really effective in some cases.

518
00:33:07,339 --> 00:33:11,462
OK, let's see a screenshot with the volumetric lighting off,

519
00:33:12,463 --> 00:33:14,865
and another with the volumetric lighting on,

520
00:33:15,185 --> 00:33:16,647
with some color setting.

521
00:33:17,467 --> 00:33:18,828
It's prettier in the game.

522
00:33:20,523 --> 00:33:27,986
In the majority of our scene, the performance has around 2ms and can go up to 3ms

523
00:33:28,186 --> 00:33:32,428
in scene with huge amount of moving light.

524
00:33:33,569 --> 00:33:40,352
We use some technique to reproject and prevent ghosting on moving light

525
00:33:40,572 --> 00:33:46,975
and this is why in this case we have more cost when huge amount of light are moving in the scene.

526
00:33:48,022 --> 00:33:51,884
but we don't go over 3ms all the time.

527
00:33:56,587 --> 00:33:59,828
Okay, just a little video because I love this effect.

528
00:34:07,573 --> 00:34:07,913
It's quick.

529
00:34:10,335 --> 00:34:14,637
Okay, now we can talk about our indirect lighting solution.

530
00:34:21,230 --> 00:34:23,731
If we go back in the past with Beyond to Soul,

531
00:34:24,412 --> 00:34:27,333
at that time we were using Half-Life 2 AmbientCube,

532
00:34:28,013 --> 00:34:30,234
stored per vertex for static geometry

533
00:34:30,434 --> 00:34:33,375
and with LightProbe for dynamic geometry.

534
00:34:34,596 --> 00:34:37,597
The indirect specular were the mix of various technique.

535
00:34:38,137 --> 00:34:40,878
We have planar reflection,

536
00:34:40,938 --> 00:34:45,380
and also with vertical blur pyramid to fake roughness

537
00:34:45,700 --> 00:34:46,300
and cube map.

538
00:34:47,694 --> 00:34:49,914
a capture without BureauDev integration

539
00:34:50,054 --> 00:34:52,875
and manually used in the shading tree.

540
00:34:54,016 --> 00:34:57,537
It was pretty ugly at this time

541
00:34:58,157 --> 00:35:01,339
and all the artists need to do

542
00:35:02,079 --> 00:35:08,061
the capture and integrate

543
00:35:09,362 --> 00:35:12,723
the high BL in their shading herself.

544
00:35:15,477 --> 00:35:20,801
And what we want is to have an unified solution

545
00:35:20,861 --> 00:35:22,762
for static and dynamic object.

546
00:35:26,124 --> 00:35:29,907
We start to work on a probe-based solution for everything.

547
00:35:30,687 --> 00:35:32,788
Our solution is typical this day.

548
00:35:33,269 --> 00:35:35,991
We use image-based light for specular component

549
00:35:36,211 --> 00:35:39,093
with ggx-ndf integration.

550
00:35:40,446 --> 00:35:44,069
Filtered importance sampling is used to prevent firefly,

551
00:35:44,369 --> 00:35:47,311
and we have influence and parallax box.

552
00:35:53,836 --> 00:35:58,479
For the diffuse part, we begin to use diffuse probe grid.

553
00:36:00,180 --> 00:36:02,602
But as we choose to use diffuse probe grid,

554
00:36:02,622 --> 00:36:04,263
some technical flow appears to us.

555
00:36:04,864 --> 00:36:08,086
Light leaking was one big issue introduced by some...

556
00:36:09,433 --> 00:36:14,757
introduced by PropGrid, and it's an ongoing research

557
00:36:15,357 --> 00:36:18,119
around with some interesting solution proposed last year.

558
00:36:20,241 --> 00:36:23,824
Interpolation irregularity are not often addressed,

559
00:36:23,904 --> 00:36:26,606
but was considered as problematic for us.

560
00:36:32,508 --> 00:36:35,990
By example, if we try to fix light leaking

561
00:36:36,050 --> 00:36:38,292
by rejecting probes based on occlusion,

562
00:36:39,012 --> 00:36:41,373
it often leads to interpolation artifact.

563
00:36:42,614 --> 00:36:45,055
We ended up to never discarding any probe.

564
00:36:50,899 --> 00:36:55,161
We store our probe in an adaptive sparse octree

565
00:36:55,301 --> 00:36:57,002
automatically built with RTSQ.

566
00:37:01,308 --> 00:37:05,710
They can provide density zone to out the automatic voxelization.

567
00:37:07,491 --> 00:37:10,893
And the scene voxelization help us to automatically adjust

568
00:37:10,973 --> 00:37:13,935
the resolution of the octree around the object

569
00:37:14,135 --> 00:37:15,036
and the wall of the scene.

570
00:37:20,539 --> 00:37:24,941
Okay, in our case, one octree cell contain eight probes

571
00:37:27,142 --> 00:37:29,484
on one per corner of the cell.

572
00:37:30,514 --> 00:37:33,755
A pointy space is always surrounded by eight probes,

573
00:37:34,115 --> 00:37:35,856
and we never discard any probe,

574
00:37:36,036 --> 00:37:39,498
but virtually offset them at the baking time instead.

575
00:37:45,000 --> 00:37:48,101
Thanks to this, artists can use a probe attractor.

576
00:37:48,901 --> 00:37:52,022
This attractor are closed mesh

577
00:37:52,723 --> 00:37:54,983
that attract all the probe in the volume.

578
00:37:56,688 --> 00:38:02,690
This attractor can be fit to a room or just on a certain object.

579
00:38:03,491 --> 00:38:06,512
And they are really cute, and they are...

580
00:38:07,232 --> 00:38:08,012
There, sorry.

581
00:38:08,992 --> 00:38:11,373
And they are useful.

582
00:38:11,393 --> 00:38:19,816
And they are usually close to all volume zones already used for visibility.

583
00:38:23,451 --> 00:38:28,473
Artists can also use mesh repulsor to offset probes outside of the geometry

584
00:38:30,833 --> 00:38:37,615
On the left, note how probes inside the single-faceted cube receive light information

585
00:38:38,136 --> 00:38:39,376
and introduce light leaking

586
00:38:40,917 --> 00:38:46,858
On the right, probes are offsetted outside of the cube and create a more natural occlusion

587
00:38:48,259 --> 00:38:52,920
Also note the interpolation error on the right side of the cube

588
00:38:57,063 --> 00:39:01,704
Okay, offsetting probes help us to solve majority

589
00:39:01,804 --> 00:39:03,584
of light leaking cases.

590
00:39:05,265 --> 00:39:08,946
As previously said, we virtually offset all probes

591
00:39:09,026 --> 00:39:10,586
during capture or baking time.

592
00:39:11,226 --> 00:39:13,707
But the evaluation of the GI

593
00:39:15,808 --> 00:39:19,949
is always based on the original grid position.

594
00:39:21,269 --> 00:39:23,269
The offset is only done at baking time.

595
00:39:24,630 --> 00:39:26,430
Probe inside the wall is undefined.

596
00:39:27,870 --> 00:39:32,173
because the wall usually uses backfascaling,

597
00:39:32,913 --> 00:39:35,875
and the probe was in a state that we don't know.

598
00:39:37,696 --> 00:39:40,857
We use a repulsor to virtually offset

599
00:39:42,038 --> 00:39:43,899
the probe position outside of the wall.

600
00:39:46,600 --> 00:39:51,423
In this case, this probe that was moved

601
00:39:52,523 --> 00:39:54,424
on the outside of the wall,

602
00:39:55,645 --> 00:39:57,226
takes some bright red color.

603
00:39:59,312 --> 00:40:02,112
We fix one side, but this creates some leaking

604
00:40:02,552 --> 00:40:04,233
on the other side of the wall that's,

605
00:40:05,273 --> 00:40:07,853
that was way dimmer than the first one.

606
00:40:12,434 --> 00:40:15,475
Here the leaking was always present and irrelevant.

607
00:40:15,935 --> 00:40:19,136
We subdivide the arg tree around the object, if possible,

608
00:40:19,956 --> 00:40:21,617
and it will fix the issue.

609
00:40:29,797 --> 00:40:35,104
If it is not possible to subdivide because we reach the maximum octree depth,

610
00:40:35,885 --> 00:40:37,987
we favor minimum indirect light error.

611
00:40:38,648 --> 00:40:42,012
Weak indirect is always less noticeable than bright indirect.

612
00:40:47,827 --> 00:40:51,309
Okay, in the cases we can properly handle,

613
00:40:52,610 --> 00:40:55,231
we also provide some probe color modifier

614
00:40:55,811 --> 00:41:00,553
with smooth quadratic transition for manual modification.

615
00:41:01,274 --> 00:41:06,236
This color modifier are post-applied on the JBEQ

616
00:41:07,337 --> 00:41:09,698
computation and provide really fast iteration.

617
00:41:14,132 --> 00:41:17,135
To prevent filtering discontinuity between octree,

618
00:41:17,996 --> 00:41:20,458
between octree level when using hardware filtering,

619
00:41:21,519 --> 00:41:23,821
we first color continuity at baking time

620
00:41:24,622 --> 00:41:26,643
by interpolating probes that are not,

621
00:41:27,264 --> 00:41:30,487
that are on the border of the octree depth size difference,

622
00:41:30,707 --> 00:41:31,888
like on T-junction.

623
00:41:34,130 --> 00:41:37,313
In this case, blue probes are never computed,

624
00:41:38,474 --> 00:41:39,755
but interpolated instead.

625
00:41:41,523 --> 00:41:43,464
It's helped to prevent irregularity

626
00:41:43,664 --> 00:41:46,385
and this allow us to use hardware filtering.

627
00:41:49,326 --> 00:41:52,867
Okay, let's talk about how we store data in Perlsock tree.

628
00:41:55,388 --> 00:41:58,869
Only leaves have content and we only need to store leaves.

629
00:42:00,270 --> 00:42:02,290
And remember, I previously mentioned,

630
00:42:02,750 --> 00:42:04,311
we have eight probe per leaf

631
00:42:04,831 --> 00:42:06,492
for the eight corner of the tree.

632
00:42:09,415 --> 00:42:13,056
Leaves are stored in a volume texture atlas.

633
00:42:14,416 --> 00:42:18,597
We pack the eight probe of each leaf

634
00:42:19,378 --> 00:42:23,119
into a two by two by two block of the volume texture atlas.

635
00:42:27,960 --> 00:42:31,101
Probe are shared on corner of the YOG3

636
00:42:31,161 --> 00:42:35,722
but need to be duplicated to support adaptive

637
00:42:37,544 --> 00:42:40,105
difference in the cell depth of the oak tree.

638
00:42:42,647 --> 00:42:44,888
And it gives us a lot of redundancy.

639
00:42:47,609 --> 00:42:51,731
To prevent this issue, we do not store the oak tree leaves,

640
00:42:51,972 --> 00:42:56,334
but its first parent cell instead.

641
00:42:58,135 --> 00:43:01,536
We pack leaves first parent into tree by tree by tree block

642
00:43:02,117 --> 00:43:03,938
of the volume texture atlas.

643
00:43:04,698 --> 00:43:06,499
Storing parent cell is way better.

644
00:43:09,841 --> 00:43:13,823
We still have some redundancy, but it's good enough for us.

645
00:43:17,865 --> 00:43:23,748
The irradiance is stored in each probe by using second-order spherical harmonics

646
00:43:23,868 --> 00:43:27,070
with geometric reconstruction for better quality,

647
00:43:27,910 --> 00:43:30,792
which means we need to store four coefficients by probes.

648
00:43:32,072 --> 00:43:35,434
In this case, we have three RGBA volume textures

649
00:43:35,954 --> 00:43:38,856
at 16-bit precision for our volume texture atlas.

650
00:43:40,607 --> 00:43:47,453
By example, 24,000 probes can be stored on 100 by 100

651
00:43:48,814 --> 00:43:52,438
by three volume texture, which gives us around 3 megabytes

652
00:43:53,058 --> 00:43:53,859
for all these probes.

653
00:43:54,940 --> 00:43:58,283
In the game, we are closer to 100,000 probes

654
00:43:58,503 --> 00:43:59,324
for each scene zone.

655
00:44:01,586 --> 00:44:06,010
This gives us approximately 15 megabytes by scene zone.

656
00:44:08,907 --> 00:44:11,430
Okay, how do we display our GI?

657
00:44:13,853 --> 00:44:16,536
We never discard any probe that allow us

658
00:44:16,576 --> 00:44:18,698
to directly sample volumetric texture

659
00:44:19,439 --> 00:44:20,781
by using hardware filtering.

660
00:44:21,782 --> 00:44:24,505
But for each probe, we need to store a hash key

661
00:44:25,206 --> 00:44:28,450
and to reconstruct atlas texture coordinates.

662
00:44:31,921 --> 00:44:34,283
We use one hash per octrelive.

663
00:44:35,044 --> 00:44:37,826
The hash code is formed from a 3D position

664
00:44:37,866 --> 00:44:39,688
thanks to Morton Key algorithm.

665
00:44:41,029 --> 00:44:42,670
It's a constant time algorithm

666
00:44:42,730 --> 00:44:46,254
to transform multidimensional data to one dimension.

667
00:44:48,055 --> 00:44:51,438
And the hash code is restricted to 32 bits,

668
00:44:51,758 --> 00:44:53,420
which limits the octrelive to 10.

669
00:44:56,583 --> 00:44:57,343
And finally,

670
00:44:58,937 --> 00:45:02,039
The hashcodes are used to compute textual coordinates

671
00:45:02,259 --> 00:45:03,601
to fetch the atlas volume.

672
00:45:12,007 --> 00:45:14,850
The bonuses provided with such technique

673
00:45:15,450 --> 00:45:17,932
is that we can easily blend between different,

674
00:45:19,173 --> 00:45:22,036
between multiple G-set with a compute shutter.

675
00:45:24,035 --> 00:45:29,477
It lets us to easily switch our GI when a light is switched on or off.

676
00:45:32,658 --> 00:45:37,940
And it can be useful to make GI global illumination transition for daytime

677
00:45:38,240 --> 00:45:43,702
or, by example, when opening or closing a curtain, like on this video.

678
00:45:52,975 --> 00:45:55,336
Because we use scene zone with portal,

679
00:45:57,118 --> 00:46:01,381
we want to avoid add transition between scene zone.

680
00:46:02,682 --> 00:46:06,264
Artists can set up transition distance around portal.

681
00:46:08,186 --> 00:46:09,767
All dynamic object passing through

682
00:46:10,567 --> 00:46:12,168
sample both global emission.

683
00:46:14,830 --> 00:46:17,352
The sample global emission of the both scene zone.

684
00:46:20,077 --> 00:46:24,379
Transition is based on distance to portal and normal direction.

685
00:46:28,740 --> 00:46:32,642
A screenshot here with the transition off

686
00:46:32,962 --> 00:46:34,723
and one other with the transition on.

687
00:46:36,904 --> 00:46:39,425
This helps us to have a really smooth transition.

688
00:46:39,585 --> 00:46:44,947
One character go to a room to another

689
00:46:45,547 --> 00:46:47,868
with really different lighting condition.

690
00:46:51,045 --> 00:47:00,487
OK, for static object, we also use global elimination

691
00:47:00,547 --> 00:47:03,027
transition for objects.

692
00:47:04,508 --> 00:47:06,848
Most of the objects are in a unique scene zone,

693
00:47:07,388 --> 00:47:10,029
like interior wall versus exterior wall.

694
00:47:11,189 --> 00:47:14,810
But what about door, window, and window frame?

695
00:47:15,370 --> 00:47:18,031
These objects are assigned to a scene zone,

696
00:47:18,071 --> 00:47:20,732
but are also visible from others.

697
00:47:23,877 --> 00:47:27,200
In this case, we flag object to sample both GI Atlas,

698
00:47:27,981 --> 00:47:30,643
and it solves the issue.

699
00:47:31,784 --> 00:47:33,385
On the left, the door and the window

700
00:47:33,586 --> 00:47:35,147
only sample the interior GI,

701
00:47:36,168 --> 00:47:37,989
and on the right, they sample both.

702
00:47:42,894 --> 00:47:45,996
Okay, now it's time to conclude this talk.

703
00:47:51,434 --> 00:47:55,457
First of all, the road to physically based rendering

704
00:47:55,477 --> 00:47:56,117
never ends.

705
00:47:57,218 --> 00:47:58,979
We need better energy conservation

706
00:47:59,039 --> 00:48:00,279
for light and materials.

707
00:48:01,700 --> 00:48:04,442
Materials are not physically accurate enough.

708
00:48:07,003 --> 00:48:09,385
And being physically based is good,

709
00:48:09,465 --> 00:48:11,886
but don't forget artist's visions and needs.

710
00:48:12,107 --> 00:48:13,007
It's really important.

711
00:48:15,352 --> 00:48:17,454
And remember that photometric units

712
00:48:17,655 --> 00:48:20,277
can provide a good framework to ensure

713
00:48:20,697 --> 00:48:22,039
coherent asset production.

714
00:48:23,901 --> 00:48:26,503
And always use referent environment

715
00:48:26,523 --> 00:48:27,945
to validate your materials.

716
00:48:31,708 --> 00:48:33,530
OK, what's next for us?

717
00:48:34,351 --> 00:48:36,733
We want to have area light and soft shadow everywhere.

718
00:48:36,833 --> 00:48:38,795
It's one of our big subject.

719
00:48:40,743 --> 00:48:43,325
We need to work on energy conservation

720
00:48:43,605 --> 00:48:46,007
and improve our BRDF layer stack.

721
00:48:47,788 --> 00:48:51,211
Adding more dynamic components in our global animation system

722
00:48:51,331 --> 00:48:53,593
is also really, really important for us.

723
00:48:54,874 --> 00:48:59,618
We haven't had the time to add pseudo-dynamic global animation,

724
00:48:59,698 --> 00:49:03,341
like adding spherical harmonic light injection

725
00:49:04,081 --> 00:49:08,384
and virtual point light or inject color modifier on the fly.

726
00:49:10,612 --> 00:49:13,794
For volumetric lighting, we want to add more flexibility

727
00:49:13,934 --> 00:49:17,657
on fog density volume and add volumetric shadow too.

728
00:49:18,958 --> 00:49:19,959
And that's it.

729
00:49:21,260 --> 00:49:24,142
I want to thank all the rendering team at Country Dream

730
00:49:24,182 --> 00:49:25,523
for their fantastic work.

731
00:49:26,243 --> 00:49:29,946
And I want to thank Julien Merceron for this advice

732
00:49:30,947 --> 00:49:31,787
on my presentation.

733
00:49:33,709 --> 00:49:35,630
OK, it's time for a question maybe.

734
00:49:46,302 --> 00:49:49,445
Did you experiment with BC6H compression?

735
00:49:52,868 --> 00:49:53,749
For your indirect lighting.

736
00:49:54,569 --> 00:49:55,770
For the global emulation?

737
00:49:56,010 --> 00:49:57,131
Yeah.

738
00:49:57,312 --> 00:49:59,173
Yes, we...

739
00:50:00,634 --> 00:50:01,615
All our...

740
00:50:04,177 --> 00:50:06,299
All volumetric texture...

741
00:50:08,621 --> 00:50:09,161
Sorry, I'm...

742
00:50:10,379 --> 00:50:14,762
don't do this, we don't experiment with compression, I think.

743
00:50:15,402 --> 00:50:18,725
The size was really small for us and we don't,

744
00:50:19,305 --> 00:50:21,227
we won't have enough precision

745
00:50:22,668 --> 00:50:24,289
to our global dimension.

746
00:50:25,010 --> 00:50:25,230
Sorry.

747
00:50:25,610 --> 00:50:25,930
Thank you.

748
00:50:27,752 --> 00:50:34,457
Hey, how did you guys handle the interpolation errors

749
00:50:34,497 --> 00:50:37,119
at the edge of the blocks that are stored in the

750
00:50:37,719 --> 00:50:38,240
pre-texture?

751
00:50:41,995 --> 00:50:47,778
We have some redundancy in your global elimination atlas.

752
00:50:48,399 --> 00:50:56,683
And we don't have to involve the different interpolation,

753
00:50:56,743 --> 00:51:02,046
because we have all the probes surrounding the position

754
00:51:02,106 --> 00:51:04,167
in space that was on the block.

755
00:51:04,868 --> 00:51:08,230
And when we have different level in the oak tree.

756
00:51:09,401 --> 00:51:12,863
We don't compute, can I go,

757
00:51:13,584 --> 00:51:15,625
we don't compute all the,

758
00:51:17,146 --> 00:51:20,388
the probe, but instead we interpolate,

759
00:51:21,089 --> 00:51:24,191
we do some interpolation between the two different probe.

760
00:51:26,072 --> 00:51:27,473
Oh, sorry.

761
00:51:27,873 --> 00:51:28,734
Oh, no.

762
00:51:30,191 --> 00:51:32,832
OK, the blue probes are interpolated

763
00:51:32,952 --> 00:51:38,235
and using the probe from the upper level.

764
00:51:39,036 --> 00:51:42,197
And in this case, we don't have a discontinuity

765
00:51:42,237 --> 00:51:43,978
when we use, when we fetch.

766
00:51:44,318 --> 00:51:46,560
OK, but like in the next slide, when you go,

767
00:51:46,820 --> 00:51:50,582
when you have the texture like, sorry, keep going.

768
00:51:50,602 --> 00:51:51,462
The one past this one.

769
00:51:52,708 --> 00:51:54,068
in the texture that stores the leaves,

770
00:51:54,509 --> 00:51:56,890
like when that two by two block is next

771
00:51:56,910 --> 00:51:57,951
to another two by two block,

772
00:51:57,971 --> 00:52:00,712
you guys said you were using like trilinear filtering

773
00:52:00,752 --> 00:52:02,313
on the texture to get the value.

774
00:52:02,693 --> 00:52:05,415
Like what happens if you sample near the edge of the block

775
00:52:05,455 --> 00:52:06,636
where it connects to the other one?

776
00:52:10,158 --> 00:52:14,100
We offered that to don't go over the half pixel.

777
00:52:14,500 --> 00:52:15,001
Okay.

778
00:52:15,021 --> 00:52:16,822
To just get on the,

779
00:52:17,702 --> 00:52:18,443
Okay, cool, thanks.

780
00:52:18,483 --> 00:52:18,763
On the block.

781
00:52:18,783 --> 00:52:19,643
Thank you.

782
00:52:27,057 --> 00:52:27,678
Another question?

783
00:52:27,698 --> 00:52:34,847
OK, I think we can conclude here.

784
00:52:35,729 --> 00:52:35,949
Thank you.

