1
00:00:06,218 --> 00:00:11,640
Hello, welcome to Environmental and Motion Mesh Interactions, Madden, FIFA, and Beyond.

2
00:00:11,640 --> 00:00:16,061
I'm Henry Allen, a senior software engineer on the Frostbite Animation team at Electronic

3
00:00:16,061 --> 00:00:19,802
Arts, and the product owner and primary engineer for our multi-character interaction system.

4
00:00:19,802 --> 00:00:25,804
The goal for this talk is to share some developments in our multi-character interaction system

5
00:00:25,804 --> 00:00:30,745
at EA that may be of interest or applicable to similar systems in other games and engines.

6
00:00:32,378 --> 00:00:36,239
First, we'll do a quick overview of Interact, EA's multi-character interaction system.

7
00:00:36,239 --> 00:00:41,361
We've shown this at GDC before, so we'll just spend a few minutes briefly clarifying

8
00:00:41,361 --> 00:00:45,423
what it is, how it works, and establishing key concepts relevant to the rest of the talk.

9
00:00:45,423 --> 00:00:51,145
Then we'll move on to the meat of the presentation, which is focused around two topics.

10
00:00:51,145 --> 00:00:55,006
First, extending this type of system to interacting not just with other characters,

11
00:00:55,006 --> 00:00:57,447
but also with the environment and or objects in the world.

12
00:00:58,183 --> 00:00:59,383
Take this kick, for example.

13
00:00:59,383 --> 00:01:01,485
It'd probably work better without the blindfold.

14
00:01:01,485 --> 00:01:02,965
That's off topic though,

15
00:01:02,965 --> 00:01:05,607
but it probably wouldn't work too well without that box

16
00:01:05,607 --> 00:01:07,628
for the athlete to brace his hand on.

17
00:01:07,628 --> 00:01:08,808
The box isn't a character per se,

18
00:01:08,808 --> 00:01:10,469
but it's integral to the interaction.

19
00:01:10,469 --> 00:01:12,590
We'll look at ways to handle this type of thing

20
00:01:12,590 --> 00:01:14,671
using a multi-character interaction system.

21
00:01:14,671 --> 00:01:17,993
And then we'll get into motion and pose matching.

22
00:01:17,993 --> 00:01:19,734
We'll take a look at two ways

23
00:01:19,734 --> 00:01:21,455
we've integrated motion matching tech

24
00:01:21,455 --> 00:01:22,435
with our multi-character tech,

25
00:01:22,435 --> 00:01:24,517
which have very little to do with this picture.

26
00:01:26,370 --> 00:01:27,811
So let's get into it.

27
00:01:27,811 --> 00:01:29,953
Interact is short for Interaction Scenario System,

28
00:01:29,953 --> 00:01:33,235
and as stated, it's EA's multi-character interaction system.

29
00:01:33,235 --> 00:01:36,837
Used for detecting multi-character situations

30
00:01:36,837 --> 00:01:39,218
that match available multi-character animation content,

31
00:01:39,218 --> 00:01:42,941
and then playing and synchronizing the chosen animations

32
00:01:42,941 --> 00:01:45,903
to create crafted multi-character gameplay moments

33
00:01:45,903 --> 00:01:49,205
in games that replicate real-world interactions like these.

34
00:01:49,205 --> 00:01:53,007
For example, all the blocking, tackling,

35
00:01:53,007 --> 00:01:55,008
and most other player contacts happening here.

36
00:01:56,435 --> 00:01:58,877
Our multi-character interaction system is responsible

37
00:01:58,877 --> 00:02:01,159
for detecting when these can and should play

38
00:02:01,159 --> 00:02:03,781
and coordinating the animations and alignment

39
00:02:03,781 --> 00:02:07,645
of the players involved.

40
00:02:07,645 --> 00:02:08,806
So briefly, how does it work?

41
00:02:08,806 --> 00:02:12,128
First, the game and or animation state machines

42
00:02:12,128 --> 00:02:15,071
control which candidates we can even consider.

43
00:02:15,071 --> 00:02:16,532
We'll only spend time looking at candidates

44
00:02:16,532 --> 00:02:18,434
who actually requested a particular interaction

45
00:02:18,434 --> 00:02:20,756
and have fast the conditions to enter it.

46
00:02:20,756 --> 00:02:22,397
The game creator has total control

47
00:02:22,397 --> 00:02:24,579
as to whether or when such a request is made.

48
00:02:26,618 --> 00:02:29,621
In the interaction evaluator, a centralized processor,

49
00:02:29,621 --> 00:02:31,162
we gather all requests for the frame

50
00:02:31,162 --> 00:02:32,884
and group them by interaction requested

51
00:02:32,884 --> 00:02:34,906
so that we can process all candidates

52
00:02:34,906 --> 00:02:37,088
for each unique interaction type as a group.

53
00:02:37,088 --> 00:02:39,770
For each interaction type being considered,

54
00:02:39,770 --> 00:02:42,452
we'll first identify a master candidate,

55
00:02:42,452 --> 00:02:44,174
a reference character around which

56
00:02:44,174 --> 00:02:45,255
we'll match the interaction.

57
00:02:45,255 --> 00:02:48,438
In our example, we've got the ball carrier as master.

58
00:02:48,438 --> 00:02:51,320
So for a given master candidate evaluation,

59
00:02:51,320 --> 00:02:53,062
we then do a broad phase check.

60
00:02:53,452 --> 00:02:57,195
to quickly rule out any candidates who are out of range of various

61
00:02:57,195 --> 00:03:01,679
physical match conditions in our database, distances, angles, speeds, etc.

62
00:03:01,679 --> 00:03:07,284
Then identify appropriate role and slot assignments for each remaining candidate.

63
00:03:07,284 --> 00:03:12,789
And finally, we search the database of animations to find a match or not. We're essentially just

64
00:03:12,789 --> 00:03:17,973
examining the relative trajectories of the master and the candidates looking for animations that match.

65
00:03:19,801 --> 00:03:22,702
If we do find a match, we ask the game or animation state

66
00:03:22,702 --> 00:03:24,843
machine to start the animation on each character

67
00:03:24,843 --> 00:03:27,484
and run some additional processing afterwards

68
00:03:27,484 --> 00:03:30,265
each frame to adjust the participants into alignment.

69
00:03:30,265 --> 00:03:33,486
Now just to clarify, these physical match conditions

70
00:03:33,486 --> 00:03:35,686
in the database are automatically

71
00:03:35,686 --> 00:03:37,987
generated based on the relative trajectories

72
00:03:37,987 --> 00:03:40,648
of the characters in each source animation,

73
00:03:40,648 --> 00:03:42,389
with some content creator-defined match

74
00:03:42,389 --> 00:03:43,309
tolerances applied.

75
00:03:44,776 --> 00:03:47,198
And we also automatically generate bounding ranges,

76
00:03:47,198 --> 00:03:49,319
which encompass the coverage in the database

77
00:03:49,319 --> 00:03:51,781
for each of these conditions, which

78
00:03:51,781 --> 00:03:54,363
is what we use in that broad phase step I mentioned earlier,

79
00:03:54,363 --> 00:03:57,425
so that we can efficiently check if a particular match

80
00:03:57,425 --> 00:03:59,846
condition, like distance to master,

81
00:03:59,846 --> 00:04:03,129
is outside the range supported in our database,

82
00:04:03,129 --> 00:04:05,150
allowing us to reject various candidates

83
00:04:05,150 --> 00:04:07,252
before getting to the point of searching the database.

84
00:04:09,008 --> 00:04:12,291
That's as deep as I'm going to go into how the system works today,

85
00:04:12,291 --> 00:04:17,375
but there's more detail in the previous Interact presentation for those interested.

86
00:04:17,375 --> 00:04:20,498
So let's move on to object and environment interaction.

87
00:04:20,498 --> 00:04:22,939
We've solved the blindfold issue with googly eyes,

88
00:04:22,939 --> 00:04:26,943
but how do we integrate environment and object interaction into this type of system?

89
00:04:26,943 --> 00:04:31,366
To lead up to that, we need to discuss passive participation and interaction,

90
00:04:31,366 --> 00:04:33,428
which we refer to as ghost interaction.

91
00:04:35,965 --> 00:04:37,086
This running punch is an example.

92
00:04:37,086 --> 00:04:39,267
We have two different characters interacting

93
00:04:39,267 --> 00:04:41,448
with the same victim, the guy in the middle.

94
00:04:41,448 --> 00:04:43,709
He's not joining into the animation or alignment

95
00:04:43,709 --> 00:04:46,551
of either interaction until impact.

96
00:04:46,551 --> 00:04:48,872
He's a passive or ghost participant.

97
00:04:48,872 --> 00:04:50,733
At the point of impact, he late joins

98
00:04:50,733 --> 00:04:52,634
into the interaction that is ready first

99
00:04:52,634 --> 00:04:54,175
with the guy on the right in this case

100
00:04:54,175 --> 00:04:56,116
and the guy on the left aborts and transitions

101
00:04:56,116 --> 00:04:57,377
into a new punch interaction.

102
00:04:58,578 --> 00:05:00,779
This ghosting or passive participation

103
00:05:00,779 --> 00:05:03,041
is an important feature for involuntary interaction

104
00:05:03,041 --> 00:05:04,261
like getting punched,

105
00:05:04,261 --> 00:05:06,162
as it lets us keep the user or AI in control

106
00:05:06,162 --> 00:05:08,544
until the point at which it actually makes sense

107
00:05:08,544 --> 00:05:09,985
to bring them into the interaction.

108
00:05:09,985 --> 00:05:13,567
It also leads to the realization

109
00:05:13,567 --> 00:05:15,208
that it can be useful to have interactions

110
00:05:15,208 --> 00:05:17,729
where one of the participants never participates at all

111
00:05:17,729 --> 00:05:20,851
other than to serve as a reference point.

112
00:05:20,851 --> 00:05:23,193
This juke is triggering two different interactions

113
00:05:23,193 --> 00:05:25,214
with the ball carrier as ghost in both.

114
00:05:26,124 --> 00:05:29,585
He's totally uninfluenced by the defenders as they respond to his move.

115
00:05:29,585 --> 00:05:35,368
This is essentially a form of context-driven animation where the context is provided by

116
00:05:35,368 --> 00:05:36,208
some other character.

117
00:05:36,208 --> 00:05:44,311
Now, since the other character is just providing context for an interaction, there's no technical

118
00:05:44,311 --> 00:05:47,533
reason that the passive participant actually has to be another character.

119
00:05:48,368 --> 00:05:50,630
Since the vast majority of interaction matching logic

120
00:05:50,630 --> 00:05:52,631
is based on trajectories, the partner

121
00:05:52,631 --> 00:05:56,613
could simply be a static object or locator in the world.

122
00:05:56,613 --> 00:05:59,955
Matching to a specific location should actually

123
00:05:59,955 --> 00:06:02,496
be simpler than matching against other moving characters.

124
00:06:02,496 --> 00:06:05,918
So we should be able to support interacting

125
00:06:05,918 --> 00:06:08,860
with objects in environment using this exact same system

126
00:06:08,860 --> 00:06:10,921
if we alter it to support interacting

127
00:06:10,921 --> 00:06:13,883
on some abstraction instead of directly on characters.

128
00:06:13,883 --> 00:06:16,985
So that's what we set out to do.

129
00:06:18,262 --> 00:06:19,943
The runtime was fairly straightforward.

130
00:06:19,943 --> 00:06:22,925
There's just a few properties we use for matching characters,

131
00:06:22,925 --> 00:06:25,907
but we don't want to represent interaction points

132
00:06:25,907 --> 00:06:26,707
using characters.

133
00:06:26,707 --> 00:06:30,049
So instead we support defining locators in the world,

134
00:06:30,049 --> 00:06:32,331
which are just identifying an interaction point

135
00:06:32,331 --> 00:06:35,193
that has these properties we need.

136
00:06:35,193 --> 00:06:38,495
The big arrow will represent a locator here.

137
00:06:38,495 --> 00:06:39,595
The other issue is,

138
00:06:39,595 --> 00:06:41,737
we don't want a special case all of our code

139
00:06:41,737 --> 00:06:44,098
to work with both characters and locators.

140
00:06:45,153 --> 00:06:48,735
So we just added a new interface for retrieving information needed for matching,

141
00:06:48,735 --> 00:06:51,757
and updated the system to, for the most part,

142
00:06:51,757 --> 00:06:54,678
use this interface instead of directly operating on characters.

143
00:06:54,678 --> 00:06:59,621
And this let us wrap locators in an implementation of the same interface,

144
00:06:59,621 --> 00:07:04,244
so the system can mostly be unaware of whether it's looking at a character or a locator.

145
00:07:06,227 --> 00:07:08,649
On the tool side in our sequence controller,

146
00:07:08,649 --> 00:07:10,410
we added support for locator tracks,

147
00:07:10,410 --> 00:07:11,791
where you can add a locator

148
00:07:11,791 --> 00:07:14,073
and specify its interaction slot,

149
00:07:14,073 --> 00:07:17,336
similar to how you would for another character,

150
00:07:17,336 --> 00:07:19,738
and support for positioning the locator in the scene,

151
00:07:19,738 --> 00:07:22,800
defining its expected relative position and orientation

152
00:07:22,800 --> 00:07:24,642
for this particular interaction animation.

153
00:07:26,774 --> 00:07:29,696
And we had to update the code that measures match conditions

154
00:07:29,696 --> 00:07:31,997
for our database to support detecting slots

155
00:07:31,997 --> 00:07:34,178
represented by locators and doing the distance, angle,

156
00:07:34,178 --> 00:07:36,980
et cetera measurements for those, the same as characters,

157
00:07:36,980 --> 00:07:39,542
but it wasn't anything crazy.

158
00:07:39,542 --> 00:07:40,982
So here's an early untuned prototype

159
00:07:40,982 --> 00:07:42,403
of the system in action.

160
00:07:42,403 --> 00:07:45,145
We've got an interaction with a few vaulting animations.

161
00:07:45,145 --> 00:07:46,566
Each has a locator in it,

162
00:07:46,566 --> 00:07:48,607
defining where the character's hands should go

163
00:07:48,607 --> 00:07:49,968
to achieve the vault interaction.

164
00:07:51,783 --> 00:07:54,485
And then we have locators representing the vault positions in the world,

165
00:07:54,485 --> 00:07:56,626
and the character is able to use the interaction system

166
00:07:56,626 --> 00:08:00,289
to match and play back vault interactions against those locators,

167
00:08:00,289 --> 00:08:02,610
selecting and playing appropriate animations

168
00:08:02,610 --> 00:08:05,012
based on matching the character's distance and angle

169
00:08:05,012 --> 00:08:07,053
to the vault locator in the world

170
00:08:07,053 --> 00:08:11,116
against the distances and angles in the original animations.

171
00:08:11,116 --> 00:08:12,978
In our game preview here, we've just placed locators

172
00:08:12,978 --> 00:08:15,259
at the vault points manually for now,

173
00:08:15,259 --> 00:08:17,341
with the idea they could be driven by content creators

174
00:08:17,341 --> 00:08:18,642
or world queries in the future.

175
00:08:21,033 --> 00:08:23,154
Vaulting is just one example of how this setup could be used.

176
00:08:23,154 --> 00:08:26,575
You could use it for something as simple as having a character reach out

177
00:08:26,575 --> 00:08:28,595
and feel the texture of a nearby wall,

178
00:08:28,595 --> 00:08:31,456
or when the player runs their character into a wall,

179
00:08:31,456 --> 00:08:35,576
you could have them push off of it rather than face-planting into it.

180
00:08:35,576 --> 00:08:37,677
Or for handling opening door interactions

181
00:08:37,677 --> 00:08:40,197
from different angles, speeds, styles, etc.,

182
00:08:40,197 --> 00:08:42,318
or even different character types.

183
00:08:42,318 --> 00:08:45,318
Or interacting with other objects in the world,

184
00:08:45,318 --> 00:08:48,159
like treasure chests, or furniture, or whatever.

185
00:08:49,727 --> 00:08:55,812
Now we do want to prevent things like attempting to use a door opening animation when a vault would be appropriate.

186
00:08:55,812 --> 00:09:04,378
So we also support exposing some content creator defined type info to, for example, let the content creator just distinguish vault locations from door opening points.

187
00:09:04,378 --> 00:09:12,364
And to support more complex situations we extended the locator interface to optionally expose game variables.

188
00:09:12,364 --> 00:09:17,488
That's just a means in our system to convey logical state from the game that can be used for matching.

189
00:09:18,499 --> 00:09:21,181
For example, in our tackle case earlier,

190
00:09:21,181 --> 00:09:24,023
we have a game variable indicating who's the ball carrier,

191
00:09:24,023 --> 00:09:25,804
and that's used as a match condition

192
00:09:25,804 --> 00:09:27,485
for the ball carrier slot in the interaction.

193
00:09:27,485 --> 00:09:31,808
Speaking of more complex cases,

194
00:09:31,808 --> 00:09:34,630
here's an example of how Madden is using this with tackles.

195
00:09:34,630 --> 00:09:36,471
They've placed a locator in the animation

196
00:09:36,471 --> 00:09:38,192
to indicate the relative position

197
00:09:38,192 --> 00:09:39,673
of a first down or end zone line

198
00:09:39,673 --> 00:09:41,495
for this specific interaction.

199
00:09:42,256 --> 00:09:45,617
So that in game, when a tackle occurs near one of these lines,

200
00:09:45,617 --> 00:09:47,657
we can use a locator on the line to match

201
00:09:47,657 --> 00:09:50,038
this type of animation that shows awareness

202
00:09:50,038 --> 00:09:52,419
and has the player reaching across for a first down

203
00:09:52,419 --> 00:09:52,959
or touchdown.

204
00:09:52,959 --> 00:10:02,801
As shown here in Madden, they're spawning locators

205
00:10:02,801 --> 00:10:05,562
as needed when the character is near the first down or end zone,

206
00:10:05,562 --> 00:10:07,563
allowing the system to match against them

207
00:10:07,563 --> 00:10:09,363
and trigger these multi-character tackle

208
00:10:09,363 --> 00:10:10,863
interactions when appropriate.

209
00:10:11,288 --> 00:10:13,249
where the locator is an additional persistent

210
00:10:13,249 --> 00:10:15,831
who just serves as context and a reference

211
00:10:15,831 --> 00:10:20,873
point for the interaction.

212
00:10:20,873 --> 00:10:22,013
Last bit on locators.

213
00:10:22,013 --> 00:10:24,354
Can this concept be applied to interacting

214
00:10:24,354 --> 00:10:25,275
with a moving object?

215
00:10:25,275 --> 00:10:26,655
Because this needs to be in the game.

216
00:10:26,655 --> 00:10:30,977
Main issue is with something on a ballistic arc,

217
00:10:30,977 --> 00:10:34,099
you definitely can't adjust its position or velocity

218
00:10:34,099 --> 00:10:35,499
to have it sync to an interaction

219
00:10:35,499 --> 00:10:38,101
because it doesn't want to look natural to, for example,

220
00:10:38,101 --> 00:10:40,142
have the ball change course midair.

221
00:10:41,437 --> 00:10:44,119
So the character or characters intending to interact with it

222
00:10:44,119 --> 00:10:45,581
really need to do the moving.

223
00:10:45,581 --> 00:10:48,644
But you really can't match your interaction

224
00:10:48,644 --> 00:10:50,666
with the current position of the object either

225
00:10:50,666 --> 00:10:53,328
because then the characters are aligning to an old position

226
00:10:53,328 --> 00:10:56,872
and chasing the object as it moves and they try to align

227
00:10:56,872 --> 00:11:00,395
as if they didn't know it was going to keep moving.

228
00:11:00,395 --> 00:11:02,177
So we really need to anticipate the movement.

229
00:11:03,219 --> 00:11:07,461
Well, since we support evaluating multiple candidates for interactions,

230
00:11:07,461 --> 00:11:11,123
what if we place multiple locators representing future positions of the object,

231
00:11:11,123 --> 00:11:16,066
then the system can choose to interact with any future position of the object as it arrives.

232
00:11:16,066 --> 00:11:22,529
This is the approach that Madden team came up with to get both single and multi-character catches using this system.

233
00:11:22,529 --> 00:11:25,971
This is some debug output from a Madden multiplayer catch.

234
00:11:27,252 --> 00:11:31,913
These circles are predicted future positions of the football.

235
00:11:31,913 --> 00:11:35,394
Each of these is represented as a locator to the system

236
00:11:35,394 --> 00:11:38,095
and is using game variables to convey the exact time

237
00:11:38,095 --> 00:11:40,195
the ball will arrive at that particular location,

238
00:11:40,195 --> 00:11:43,196
so that it can match an interaction with any of them.

239
00:11:43,196 --> 00:11:46,216
In order to create moments like these,

240
00:11:46,216 --> 00:11:48,537
where one or two characters interact with each other

241
00:11:48,537 --> 00:11:50,237
and the future position of the ball

242
00:11:50,237 --> 00:11:53,258
for a multiplayer catch or catch deflection interaction.

243
00:11:54,134 --> 00:11:56,355
I think this concept and even the implementation

244
00:11:56,355 --> 00:11:58,717
of using locators with the multi-character interaction

245
00:11:58,717 --> 00:12:01,799
system is pretty simple, maybe even obvious,

246
00:12:01,799 --> 00:12:04,100
but we're also finding it to be incredibly useful and powerful.

247
00:12:04,100 --> 00:12:10,404
OK, now let's move on to the second half of our talk,

248
00:12:10,404 --> 00:12:13,066
motion matching.

249
00:12:13,066 --> 00:12:14,847
For those not familiar, motion matching

250
00:12:14,847 --> 00:12:17,769
is an animation technique where, given a path to follow

251
00:12:17,769 --> 00:12:21,411
and a character pose, it selects the most continuous pose

252
00:12:21,411 --> 00:12:22,231
to play next.

253
00:12:22,694 --> 00:12:23,615
out of a database of poses.

254
00:12:23,615 --> 00:12:26,576
With more and more of our teams relying

255
00:12:26,576 --> 00:12:27,917
on motion matching technology

256
00:12:27,917 --> 00:12:30,158
to achieve higher fidelity animation

257
00:12:30,158 --> 00:12:32,180
without compromising player control,

258
00:12:32,180 --> 00:12:33,961
it was inevitable that we'd see demand

259
00:12:33,961 --> 00:12:37,022
for the same kinds of power in multi-character situations.

260
00:12:37,022 --> 00:12:40,945
One way we tackled this with Madden

261
00:12:40,945 --> 00:12:43,666
was integrating motion matching with our rally system,

262
00:12:43,666 --> 00:12:46,708
a system that helps get characters into position

263
00:12:46,708 --> 00:12:49,530
for pre-selected or predicted interactions.

264
00:12:50,980 --> 00:12:52,800
For example, take this case where the characters

265
00:12:52,800 --> 00:12:54,501
are too far apart to start a tackle.

266
00:12:54,501 --> 00:12:58,402
The system could look at future anticipated positions

267
00:12:58,402 --> 00:13:01,283
of the candidates and pre-choose a potential interaction.

268
00:13:01,283 --> 00:13:04,204
We can then use this information to,

269
00:13:04,204 --> 00:13:06,185
for the characters who want to interact,

270
00:13:06,185 --> 00:13:08,466
guide them towards the ideal position

271
00:13:08,466 --> 00:13:10,207
and rotation for that interaction.

272
00:13:10,207 --> 00:13:14,268
So now we support rallying characters

273
00:13:14,268 --> 00:13:17,769
who want to interact using motion matching.

274
00:13:17,769 --> 00:13:18,890
Here you can see the blue path

275
00:13:18,890 --> 00:13:20,670
as the predicted path of the ball carrier.

276
00:13:21,318 --> 00:13:25,100
And the gray path is the plotted intercept path for the tackler,

277
00:13:25,100 --> 00:13:27,341
limited to a time horizon for how far out

278
00:13:27,341 --> 00:13:29,743
we want to initiate tackles.

279
00:13:29,743 --> 00:13:31,924
If the paths intersect, we find an interaction

280
00:13:31,924 --> 00:13:34,145
that works for those future trajectories.

281
00:13:34,145 --> 00:13:37,167
Then use motion matching to drive the defender

282
00:13:37,167 --> 00:13:40,869
to the ideal location so that the interaction animation can

283
00:13:40,869 --> 00:13:43,150
start without any warping or alignment necessary.

284
00:13:44,966 --> 00:13:46,127
Here it is in motion.

285
00:13:46,127 --> 00:13:48,168
This gives us a much more flexibility

286
00:13:48,168 --> 00:13:50,769
to start interactions from a greater variety

287
00:13:50,769 --> 00:13:52,010
of distances and angles,

288
00:13:52,010 --> 00:13:54,251
without having to do much if any warping

289
00:13:54,251 --> 00:13:55,192
to achieve alignment,

290
00:13:55,192 --> 00:13:58,013
because participants are using motion match,

291
00:13:58,013 --> 00:14:00,955
locomotion and pathing to get into the ideal location

292
00:14:00,955 --> 00:14:03,356
before the interaction animation is actually started.

293
00:14:03,356 --> 00:14:07,658
But that's just single character motion matching

294
00:14:07,658 --> 00:14:08,699
to get into interactions.

295
00:14:08,699 --> 00:14:11,620
How can we apply motion matching

296
00:14:11,620 --> 00:14:14,802
once we are in the context of a multi-character situation?

297
00:14:16,128 --> 00:14:18,470
While I was doing this, the initial work at EA

298
00:14:18,470 --> 00:14:20,231
in this space actually started with the owners

299
00:14:20,231 --> 00:14:21,652
of our motion matching tech,

300
00:14:21,652 --> 00:14:24,154
the brilliant folks on our A team.

301
00:14:24,154 --> 00:14:27,577
They essentially modified their motion matching tech

302
00:14:27,577 --> 00:14:29,838
so that pose features used for checking quality

303
00:14:29,838 --> 00:14:31,360
of different aspects of the pose

304
00:14:31,360 --> 00:14:33,281
could be measured relative

305
00:14:33,281 --> 00:14:35,423
to user specified reference joint,

306
00:14:35,423 --> 00:14:39,546
the character's trajectory joint in this example,

307
00:14:39,546 --> 00:14:41,888
and then made it so that the reference joint

308
00:14:41,888 --> 00:14:43,749
could actually come from another character.

309
00:14:45,638 --> 00:14:47,639
So they could identify a reference character

310
00:14:47,639 --> 00:14:49,560
and perform pose and motion matching

311
00:14:49,560 --> 00:14:52,362
on multiple characters relative to that character's reference

312
00:14:52,362 --> 00:14:52,642
joint.

313
00:14:52,642 --> 00:14:57,304
This is one of their first prototypes showing this,

314
00:14:57,304 --> 00:14:58,725
using multi-character motion matching

315
00:14:58,725 --> 00:15:01,807
to select a two-character punch and punch reaction interaction.

316
00:15:01,807 --> 00:15:04,988
They were able to build some pretty compelling demos

317
00:15:04,988 --> 00:15:07,430
and even shippable tech for well-defined setups,

318
00:15:07,430 --> 00:15:09,651
like two characters paired and driven by game code.

319
00:15:09,651 --> 00:15:11,872
However, they soon started running

320
00:15:11,872 --> 00:15:13,653
into various multi-character problems

321
00:15:13,653 --> 00:15:15,454
we've solved over the years with Interact.

322
00:15:16,432 --> 00:15:17,772
Like how do you pick apart partners

323
00:15:17,772 --> 00:15:19,233
when there are multiple possibilities

324
00:15:19,233 --> 00:15:22,835
or efficiently rule out out of range candidates

325
00:15:22,835 --> 00:15:25,837
or deal with potential for multiple simultaneous instances

326
00:15:25,837 --> 00:15:26,638
of the interaction?

327
00:15:26,638 --> 00:15:30,320
Or support passive or ghost participation

328
00:15:30,320 --> 00:15:31,901
for interactions like this punch

329
00:15:31,901 --> 00:15:33,682
where it could look and feel even better

330
00:15:33,682 --> 00:15:37,204
if the victim joined on impact.

331
00:15:37,204 --> 00:15:39,605
Dynamic partnering, broad phase and ghost interactions

332
00:15:39,605 --> 00:15:41,666
are already key components of Interact

333
00:15:41,666 --> 00:15:43,547
along with a host of other solutions

334
00:15:43,547 --> 00:15:45,448
to multi-character specific problems.

335
00:15:47,052 --> 00:15:51,337
So it quickly became clear that continuing development of multi-character motion matching,

336
00:15:51,337 --> 00:15:55,422
independent of our existing multi-character system, was going to lead to duplicated effort

337
00:15:55,422 --> 00:16:01,810
on a large scale considering the years of development on Interact.

338
00:16:01,810 --> 00:16:05,674
And also competition where our users within EA would have to choose.

339
00:16:06,668 --> 00:16:08,769
I'm not making a comment here about one of these techs

340
00:16:08,769 --> 00:16:11,150
being Walmart in this poor analogy, by the way.

341
00:16:11,150 --> 00:16:12,831
Maybe this is more apt.

342
00:16:12,831 --> 00:16:14,972
So we realized our teams needed to join forces

343
00:16:14,972 --> 00:16:15,652
for this problem.

344
00:16:15,652 --> 00:16:18,053
But we have these two powerful complex systems.

345
00:16:18,053 --> 00:16:21,334
How do we get them working together?

346
00:16:21,334 --> 00:16:25,156
Well, with our motion matching now supporting multi-character,

347
00:16:25,156 --> 00:16:27,157
they're both doing their matching relative

348
00:16:27,157 --> 00:16:28,297
to a reference character.

349
00:16:28,297 --> 00:16:32,239
And they're both at their core animation selection systems

350
00:16:32,239 --> 00:16:34,480
driven by a database of animation content.

351
00:16:36,217 --> 00:16:38,299
So our initial proof of concept was essentially

352
00:16:38,299 --> 00:16:41,001
to replace the interaction scenario database

353
00:16:41,001 --> 00:16:42,422
with a pose matching database.

354
00:16:42,422 --> 00:16:44,264
This actually worked,

355
00:16:44,264 --> 00:16:46,907
but it was definitely not getting us access

356
00:16:46,907 --> 00:16:48,068
to the full power of both systems.

357
00:16:48,068 --> 00:16:51,731
We got the bare minimum amount of interact that we needed,

358
00:16:51,731 --> 00:16:54,614
but quite a bit of functionality was lost with this setup.

359
00:16:54,614 --> 00:16:57,457
So with our proof of concept,

360
00:16:57,457 --> 00:16:58,678
we went back to the drawing board

361
00:16:58,678 --> 00:16:59,979
to come up with a different approach.

362
00:17:01,225 --> 00:17:03,947
One possibility was consolidating the two databases

363
00:17:03,947 --> 00:17:06,690
into one solution with the features of both.

364
00:17:06,690 --> 00:17:09,992
The main issue with this idea is that the two databases

365
00:17:09,992 --> 00:17:12,694
function quite differently.

366
00:17:12,694 --> 00:17:15,797
For motion matching, each match condition or pose feature

367
00:17:15,797 --> 00:17:18,299
is assigned a cost based on how well it matches

368
00:17:18,299 --> 00:17:19,300
the original animation.

369
00:17:19,300 --> 00:17:23,043
And the sum of the costs determines pose cost,

370
00:17:23,043 --> 00:17:24,944
which we use to compare different poses.

371
00:17:24,944 --> 00:17:27,286
So it's kind of a soft matching.

372
00:17:28,725 --> 00:17:30,967
Well, for interaction, we do pass-fail matching

373
00:17:30,967 --> 00:17:32,208
on each match condition.

374
00:17:32,208 --> 00:17:34,830
And if any fail, we reject the match.

375
00:17:34,830 --> 00:17:39,733
Both are good for the different problems they're solving,

376
00:17:39,733 --> 00:17:42,335
and we felt that neither should necessarily change.

377
00:17:42,335 --> 00:17:45,057
So what we came up with instead was

378
00:17:45,057 --> 00:17:47,519
to keep the interaction system functioning exactly how

379
00:17:47,519 --> 00:17:49,541
it normally does.

380
00:17:49,541 --> 00:17:52,283
But if we have multiple animations or animation frames

381
00:17:52,283 --> 00:17:54,765
to choose from after interaction selection,

382
00:17:56,178 --> 00:17:58,239
We send those results in for motion matching

383
00:17:58,239 --> 00:17:59,659
to help refine the selection.

384
00:17:59,659 --> 00:18:03,541
The key piece to this approach would be entry ranges,

385
00:18:03,541 --> 00:18:05,641
a feature Interact already supports,

386
00:18:05,641 --> 00:18:08,262
which allows us to match against multiple entry points

387
00:18:08,262 --> 00:18:10,783
in the same animation.

388
00:18:10,783 --> 00:18:12,404
For example, here we've defined entry points

389
00:18:12,404 --> 00:18:13,945
every four frames up to frame 20.

390
00:18:13,945 --> 00:18:18,106
This leads to the database creating match conditions

391
00:18:18,106 --> 00:18:20,107
for each entry point instead of just frame zero.

392
00:18:21,477 --> 00:18:24,819
The asset and frame to be selected is on the left,

393
00:18:24,819 --> 00:18:27,860
by the way, and the match conditions are on the right.

394
00:18:27,860 --> 00:18:31,002
So for example, we can match and start this animation at frame

395
00:18:31,002 --> 00:18:33,023
16 if the characters are too close together

396
00:18:33,023 --> 00:18:34,604
to match it in an earlier frame.

397
00:18:34,604 --> 00:18:38,246
For the motion matching case, we could even

398
00:18:38,246 --> 00:18:39,687
match ranges of frames.

399
00:18:40,223 --> 00:18:45,705
figuring that frames that are near each other can generally share match conditions from an interaction perspective,

400
00:18:45,705 --> 00:18:52,047
and then send along the passing entries or batches of frames to our motion matching to refine the selection.

401
00:18:52,047 --> 00:19:00,290
This would let us keep the selection features of both systems and keep the two distinct matching styles intact.

402
00:19:01,477 --> 00:19:03,758
And we were hopeful that with interaction selection,

403
00:19:03,758 --> 00:19:05,880
matching, and rejecting batches of frames,

404
00:19:05,880 --> 00:19:08,122
it would serve as sort of a broad phase

405
00:19:08,122 --> 00:19:10,604
for motion matching, limiting the number of frames

406
00:19:10,604 --> 00:19:12,926
to examine and helping to address some performance

407
00:19:12,926 --> 00:19:14,387
and scale concerns.

408
00:19:14,387 --> 00:19:17,449
This felt like it could be quite an upgrade

409
00:19:17,449 --> 00:19:18,310
from our first attempt.

410
00:19:18,310 --> 00:19:21,572
Now, early in the presentation,

411
00:19:21,572 --> 00:19:23,013
I showed this video as an example

412
00:19:23,013 --> 00:19:24,955
of ghost interaction and late join,

413
00:19:24,955 --> 00:19:27,377
but it's also showing off motion matching.

414
00:19:27,377 --> 00:19:29,178
So let's look at a test case I started with

415
00:19:29,178 --> 00:19:30,199
using JustInteract.

416
00:19:32,037 --> 00:19:34,278
Again, we have a ghost running punch

417
00:19:34,278 --> 00:19:35,558
into a late join situation.

418
00:19:35,558 --> 00:19:39,219
At the start, the system chooses a punch

419
00:19:39,219 --> 00:19:40,519
from the front interaction.

420
00:19:40,519 --> 00:19:42,980
But the victim, being a ghost participant,

421
00:19:42,980 --> 00:19:46,200
that can do what he wants, happens to be turning around.

422
00:19:46,200 --> 00:19:48,541
So when it's time to late join, the animation

423
00:19:48,541 --> 00:19:50,761
is no longer a good match, and we bail.

424
00:19:50,761 --> 00:19:53,142
Then immediately start a new interaction,

425
00:19:53,142 --> 00:19:55,963
which is a good match in terms of distances, angles,

426
00:19:55,963 --> 00:19:59,323
velocities, but is really poor in terms of pose continuity.

427
00:20:00,583 --> 00:20:03,986
If pose matching was working and we have enough coverage,

428
00:20:03,986 --> 00:20:05,807
we should be able to get a much better selection

429
00:20:05,807 --> 00:20:07,228
when the animation changes.

430
00:20:07,228 --> 00:20:11,532
After a flurry of typing, here's that same setup.

431
00:20:11,532 --> 00:20:14,174
Exact same situation as before,

432
00:20:14,174 --> 00:20:18,677
but now we've hooked in pose matching on the hands and feet.

433
00:20:18,677 --> 00:20:20,658
We handled failed join and new selection

434
00:20:20,658 --> 00:20:21,899
much more gracefully.

435
00:20:21,899 --> 00:20:23,520
There's still a hitch, but it's a lot better

436
00:20:23,520 --> 00:20:24,962
than totally changing hands and feet.

437
00:20:27,333 --> 00:20:29,714
To clarify, the animation we chose initially

438
00:20:29,714 --> 00:20:31,354
had the ghost joining on this frame

439
00:20:31,354 --> 00:20:33,635
because the characters were facing each other

440
00:20:33,635 --> 00:20:35,935
at the time we did the selection.

441
00:20:35,935 --> 00:20:37,856
However, when it came time for the actual join,

442
00:20:37,856 --> 00:20:39,716
the ghost had rotated 180 degrees.

443
00:20:39,716 --> 00:20:43,957
So the join failed and a new post-matched interaction

444
00:20:43,957 --> 00:20:46,938
triggered, this bunch from behind,

445
00:20:46,938 --> 00:20:48,758
which looks a lot better than our initial test case

446
00:20:48,758 --> 00:20:52,339
since the frame chosen is taking into account post-continuity,

447
00:20:52,339 --> 00:20:54,439
specifically the positions and velocities

448
00:20:54,439 --> 00:20:55,280
of the hands and feet.

449
00:20:56,352 --> 00:20:58,494
The hitch is because we exit the interaction for a frame

450
00:20:58,494 --> 00:21:00,275
and start a new one.

451
00:21:00,275 --> 00:21:01,736
It could look even better if we had a way

452
00:21:01,736 --> 00:21:02,937
to just switch animations

453
00:21:02,937 --> 00:21:04,799
without exiting the interaction state at all,

454
00:21:04,799 --> 00:21:09,242
which leads to our next topic, continuous reselection.

455
00:21:09,242 --> 00:21:11,784
By this time we had a first adopter

456
00:21:11,784 --> 00:21:13,805
and they wanted continuous pose matching

457
00:21:13,805 --> 00:21:15,607
for their jostling feature.

458
00:21:15,607 --> 00:21:19,650
Traditional interactions involve choosing

459
00:21:19,650 --> 00:21:21,611
and playing out an animation.

460
00:21:21,611 --> 00:21:23,873
It's sometimes transitioning between interactions

461
00:21:23,873 --> 00:21:25,834
like this two character to three character tackle case.

462
00:21:27,330 --> 00:21:43,078
But part of the point of motion matching is the ability to switch from any frame of any animation in the database to any other frame of any other animation as needed to best maintain post continuity while respecting the desired path of the player, or now players in our case.

463
00:21:43,078 --> 00:21:52,383
For example, here the green path is the desired path and the animation and associated blue path is updating constantly to match it. I'll refer to this as re query.

464
00:21:54,372 --> 00:21:56,413
We wanted to integrate motion matching re-query

465
00:21:56,413 --> 00:21:59,336
in the same way we did for the initial selection,

466
00:21:59,336 --> 00:22:03,339
where motion matching refines interaction selection.

467
00:22:03,339 --> 00:22:05,782
However, Interact did not have this concept

468
00:22:05,782 --> 00:22:07,803
of continuous re-querying,

469
00:22:07,803 --> 00:22:11,467
but conceptually it should be able to.

470
00:22:11,467 --> 00:22:13,849
As an aside, once we went down the path

471
00:22:13,849 --> 00:22:16,011
of interaction matching as a broad phase

472
00:22:16,011 --> 00:22:18,733
for motion matching, there were multiple features

473
00:22:18,733 --> 00:22:20,214
and options we added.

474
00:22:21,282 --> 00:22:23,043
we ended up adding to the interaction system

475
00:22:23,043 --> 00:22:25,744
to mirror functionality available in motion matching

476
00:22:25,744 --> 00:22:28,405
to allow them to work together as seamlessly, efficiently,

477
00:22:28,405 --> 00:22:30,106
and effectively as possible.

478
00:22:30,106 --> 00:22:31,467
This is just the first such change.

479
00:22:31,467 --> 00:22:34,528
So we updated the multi-character system

480
00:22:34,528 --> 00:22:36,309
to support re-query,

481
00:22:36,309 --> 00:22:38,710
and motion matching hooked into this fairly naturally

482
00:22:38,710 --> 00:22:40,991
given the setup we had already put in place.

483
00:22:40,991 --> 00:22:43,532
And this is the example again

484
00:22:43,532 --> 00:22:45,153
with continuous re-query enabled.

485
00:22:45,922 --> 00:22:48,322
The hitch is gone because we're changing animations

486
00:22:48,322 --> 00:22:50,663
more seamlessly and without ever dropping out

487
00:22:50,663 --> 00:22:52,203
and restarting the interaction.

488
00:22:52,203 --> 00:22:55,284
The animation is actually switching twice before contact

489
00:22:55,284 --> 00:22:58,065
because of the extreme change in rotation of the victim

490
00:22:58,065 --> 00:23:00,225
between when the interaction was started

491
00:23:00,225 --> 00:23:04,567
and when the victim is in position to join.

492
00:23:04,567 --> 00:23:06,627
And here's the setup we used for stress testing this.

493
00:23:06,627 --> 00:23:08,508
There's no physics or collision enable here,

494
00:23:08,508 --> 00:23:10,828
so it's a bit sloppy, but it's a proof of concept.

495
00:23:10,828 --> 00:23:13,489
And we've been having fun with all this punching,

496
00:23:13,489 --> 00:23:15,090
but I mentioned earlier, we had a customer.

497
00:23:15,995 --> 00:23:18,137
So Sam on the A team threw together a bit of code

498
00:23:18,137 --> 00:23:21,661
to provide an input path based on a combination of input paths

499
00:23:21,661 --> 00:23:24,464
for multiple characters.

500
00:23:24,464 --> 00:23:27,007
And we used that to do this prototype for FIFA Jostling

501
00:23:27,007 --> 00:23:28,368
with 2,000 frames of animation.

502
00:23:28,368 --> 00:23:31,492
Two characters are user controlled here,

503
00:23:31,492 --> 00:23:33,514
and you can see their inputs in the top left.

504
00:23:33,514 --> 00:23:34,575
I think it shows off pretty well some

505
00:23:34,575 --> 00:23:37,178
of the benefits of the power and power of combining

506
00:23:37,178 --> 00:23:37,979
these two systems.

507
00:23:38,487 --> 00:23:43,630
The ability to maintain control of characters during interaction while still getting high-fidelity animation

508
00:23:43,630 --> 00:23:47,933
by allowing seamless transition into, out of, and between interactions at any frame.

509
00:23:47,933 --> 00:23:54,497
Multiple simultaneous instances of the interaction, automatic partnering and slotting of the characters,

510
00:23:54,497 --> 00:24:00,820
and automated match conditions of broad phase that let us easily avoid expensive queries when candidates are out of the supported range.

511
00:24:03,208 --> 00:24:06,771
So this brings us to the point where we felt pretty good about the systems working together,

512
00:24:06,771 --> 00:24:11,495
and it was time for FIFA to get involved as the first adopter.

513
00:24:11,495 --> 00:24:15,098
FIFA had a bunch of data ready to throw at the system and got things set up pretty quickly.

514
00:24:15,098 --> 00:24:17,159
These are just some of their animations.

515
00:24:17,159 --> 00:24:23,144
But as you might expect, there were a few challenges that presented themselves.

516
00:24:23,144 --> 00:24:25,346
I don't have time to go into everything, but I'll touch on a few.

517
00:24:27,712 --> 00:24:29,353
When FIFA initially hooked it up,

518
00:24:29,353 --> 00:24:31,314
we found that selection was very unstable.

519
00:24:31,314 --> 00:24:34,517
It would rarely choose and stay in the same animation

520
00:24:34,517 --> 00:24:35,658
for more than a frame or two at a time.

521
00:24:35,658 --> 00:24:38,700
It's kind of the point that we should be able

522
00:24:38,700 --> 00:24:41,062
to switch animations and frames as needed,

523
00:24:41,062 --> 00:24:43,544
but not constantly and seemingly arbitrarily.

524
00:24:43,544 --> 00:24:46,666
A big reason for this instability

525
00:24:46,666 --> 00:24:48,167
was the different matching styles,

526
00:24:48,167 --> 00:24:50,669
specifically the hard matching and interaction

527
00:24:50,669 --> 00:24:52,711
worked poorly with continuous re-query.

528
00:24:53,733 --> 00:24:56,034
That's because for each possible entry range,

529
00:24:56,034 --> 00:24:59,555
any one match condition failing or matching on a given frame

530
00:24:59,555 --> 00:25:02,496
could totally change the frames available for motion matching

531
00:25:02,496 --> 00:25:03,076
to pick from.

532
00:25:03,076 --> 00:25:07,778
So any time we're at the fringe values of any match condition,

533
00:25:07,778 --> 00:25:09,218
we'd continually shuffle the frames

534
00:25:09,218 --> 00:25:11,239
available to pose matching, which

535
00:25:11,239 --> 00:25:13,240
would lead to chosen matches jumping around.

536
00:25:13,240 --> 00:25:18,082
The main thing we did to address this was, for re-query,

537
00:25:18,082 --> 00:25:20,342
to expand interaction match tolerances

538
00:25:20,342 --> 00:25:22,923
for subsequent frames of the currently playing animation.

539
00:25:24,182 --> 00:25:27,163
In other words, once we pick a particular animation,

540
00:25:27,163 --> 00:25:29,083
the match tolerances to force us out

541
00:25:29,083 --> 00:25:32,965
should be more relaxed than the ones that let us in.

542
00:25:32,965 --> 00:25:34,265
This made things a lot more stable.

543
00:25:34,265 --> 00:25:39,767
Another big issue we faced was how we handled pathing.

544
00:25:39,767 --> 00:25:42,388
Typically, interact supports animation and alignment

545
00:25:42,388 --> 00:25:44,789
dictating the character path while interacting,

546
00:25:44,789 --> 00:25:48,130
which is using root motion.

547
00:25:48,130 --> 00:25:49,030
That's what we're showing here.

548
00:25:50,020 --> 00:25:58,843
We thought this looked really promising, but there was quickly a realization that using any sort of root motion to align these interactions would take away control from users and affect gameplay.

549
00:25:58,843 --> 00:26:09,067
Notice how the blue animation path is never quite taking the player where the green desired path indicates that they should go.

550
00:26:09,067 --> 00:26:15,369
This was a deal breaker for FIFA Jostle because we couldn't accept taking away any user control to make these interactions play.

551
00:26:16,304 --> 00:26:17,964
Fortunately, the FIFA engineer working with us

552
00:26:17,964 --> 00:26:20,085
convinced us to try something else,

553
00:26:20,085 --> 00:26:22,745
just playing the animation without modifying paths at all.

554
00:26:22,745 --> 00:26:24,206
So we tried it out.

555
00:26:24,206 --> 00:26:28,467
And we found that with enough coverage and tighter tolerances

556
00:26:28,467 --> 00:26:30,407
set for choosing the interactions,

557
00:26:30,407 --> 00:26:32,027
they may play slightly misaligned,

558
00:26:32,027 --> 00:26:33,888
but it's not so noticeable.

559
00:26:33,888 --> 00:26:35,608
And at the cost of precise alignment,

560
00:26:35,608 --> 00:26:37,549
this gets us higher fidelity interactions

561
00:26:37,549 --> 00:26:40,429
than we had before in these jostling situations

562
00:26:40,429 --> 00:26:42,790
with no compromises on player control and pathing.

563
00:26:43,632 --> 00:26:54,163
Essentially, this is the ability to use the system as a continuous multi-character animation selector, but not for alignment.

564
00:26:54,163 --> 00:26:56,185
Performance was also a concern.

565
00:26:56,185 --> 00:27:00,890
FIFA threw a lot of data at the system, 82,000 frames of animation last I checked.

566
00:27:00,890 --> 00:27:03,833
So I'd like to touch on just a couple of the optimizations that we did.

567
00:27:05,191 --> 00:27:08,133
Something we quickly noticed for this type of Jocelyn interaction, it's very

568
00:27:08,133 --> 00:27:13,717
possible and even common for traditional interaction matching conditions to stay

569
00:27:13,717 --> 00:27:19,021
static for many frames. Here's an extreme example. Notice how the relative speeds,

570
00:27:19,021 --> 00:27:25,746
positions and angles between these characters in this test animation isn't really changing at all.

571
00:27:25,746 --> 00:27:28,908
With our default setup of having entry ranges every four frames,

572
00:27:28,908 --> 00:27:32,270
we had 75 entries in the database for this 300 frame animation.

573
00:27:33,289 --> 00:27:35,431
Now we could have reduced that number of entries

574
00:27:35,431 --> 00:27:39,134
by going every eight frames instead, for example.

575
00:27:39,134 --> 00:27:40,775
But in general, the larger we make entries,

576
00:27:40,775 --> 00:27:43,217
the less precise our interaction matching becomes,

577
00:27:43,217 --> 00:27:47,360
because frames sharing an entry and share match conditions.

578
00:27:47,360 --> 00:27:52,124
But the match conditions for many of those frames

579
00:27:52,124 --> 00:27:54,246
in this particular animation are almost identical,

580
00:27:54,246 --> 00:27:56,748
because the characters' positions and angles

581
00:27:56,748 --> 00:27:58,930
relative to each other is largely static.

582
00:27:59,326 --> 00:28:02,208
So the optimization was to evaluate the data offline

583
00:28:02,208 --> 00:28:04,810
and automatically tune entry ranges

584
00:28:04,810 --> 00:28:08,233
to extend as long as all the interaction match conditions

585
00:28:08,233 --> 00:28:10,515
remain fairly constant, leading to examples

586
00:28:10,515 --> 00:28:13,537
like this, where we went from 75 entries in the database

587
00:28:13,537 --> 00:28:17,320
to four for this animation.

588
00:28:17,320 --> 00:28:19,462
This dramatically reduced the size

589
00:28:19,462 --> 00:28:21,284
of our interaction matching database

590
00:28:21,284 --> 00:28:23,285
from about 20,000 entries to around 3,000,

591
00:28:23,285 --> 00:28:25,227
which helped with performance during the interaction

592
00:28:25,227 --> 00:28:25,987
selection phase.

593
00:28:27,255 --> 00:28:29,877
and led to us passing in fewer larger chunks of data

594
00:28:29,877 --> 00:28:32,920
to motion matching, which could be collated more cheaply

595
00:28:32,920 --> 00:28:34,821
and which it could chew through more efficiently

596
00:28:34,821 --> 00:28:35,842
than many smaller chunks.

597
00:28:35,842 --> 00:28:38,164
This was a nice performance boost.

598
00:28:38,164 --> 00:28:41,986
The other optimization I want to mention

599
00:28:41,986 --> 00:28:44,048
has to do with path matching.

600
00:28:44,048 --> 00:28:46,830
The optimization was actually to add more match features

601
00:28:46,830 --> 00:28:48,631
to the interaction system to make it

602
00:28:48,631 --> 00:28:51,654
a more effective broad phase for the path matching done

603
00:28:51,654 --> 00:28:54,396
in the motion matching system and further reduce

604
00:28:54,396 --> 00:28:56,257
the number of frames sent to motion matching.

605
00:28:57,701 --> 00:29:00,683
For example, if the green arrow here is our desired path in game,

606
00:29:00,683 --> 00:29:03,745
motion matching would score the red path very poorly

607
00:29:03,745 --> 00:29:07,507
because it's going to turn the wrong way in the future.

608
00:29:07,507 --> 00:29:10,789
Interact didn't have this future match concept,

609
00:29:10,789 --> 00:29:13,091
so we added it in the form of distance and angle

610
00:29:13,091 --> 00:29:14,852
to future position match conditions.

611
00:29:14,852 --> 00:29:18,795
This let us rule out many more animations and frames

612
00:29:18,795 --> 00:29:20,996
that would score poorly in motion matching,

613
00:29:20,996 --> 00:29:23,458
both in bulk and much earlier in the process.

614
00:29:24,762 --> 00:29:27,726
These two optimizations and others helped us get performance to target.

615
00:29:27,726 --> 00:29:32,791
Even with the performance in hand, I do need to touch on scalability.

616
00:29:32,791 --> 00:29:38,158
To do these two character jostles, we needed a lot of post coverage

617
00:29:38,158 --> 00:29:41,301
from the same set of angles, distances and speeds for each character.

618
00:29:41,301 --> 00:29:43,684
Throwing a third or more characters in

619
00:29:43,684 --> 00:29:45,887
would exponentially increase the required coverage.

620
00:29:46,970 --> 00:29:49,931
But I think this is really powerful for interactions

621
00:29:49,931 --> 00:29:52,053
involving two or maybe three characters,

622
00:29:52,053 --> 00:29:55,435
for continuous re-query like we just saw with FIFA Jostling,

623
00:29:55,435 --> 00:29:56,996
or just helping pick a better start frame.

624
00:29:56,996 --> 00:30:00,158
And I think it can be used for larger interactions

625
00:30:00,158 --> 00:30:02,899
where they're just post-matching a few of the characters

626
00:30:02,899 --> 00:30:06,221
to help pick a better entry frame.

627
00:30:06,221 --> 00:30:07,442
Anyhow, here's a few cases in action.

628
00:30:07,442 --> 00:30:10,804
You can see this often very transient,

629
00:30:10,804 --> 00:30:12,005
just a moment of contact,

630
00:30:12,005 --> 00:30:14,426
because we're only using it when the game situation

631
00:30:14,426 --> 00:30:16,708
is very close matched to available animation content.

632
00:30:17,894 --> 00:30:20,495
And it's not perfectly aligned since we've chosen the trade-off here

633
00:30:20,495 --> 00:30:24,976
of keeping root motion weight at zero, sacrificing precise alignment

634
00:30:24,976 --> 00:30:27,456
to avoid influencing gameplay.

635
00:30:27,456 --> 00:30:29,477
I think we can improve on this in the future,

636
00:30:29,477 --> 00:30:31,457
for example, using root motion and alignment carefully

637
00:30:31,457 --> 00:30:35,759
in contexts where it does make sense to get higher fidelity visuals.

638
00:30:35,759 --> 00:30:37,859
But we're really happy with the results we got from this

639
00:30:37,859 --> 00:30:40,800
and looking forward to leveraging it in more games and situations.

640
00:30:40,800 --> 00:30:44,701
And that's everything I have for you today.

641
00:30:45,566 --> 00:30:47,409
Thanks to the Mata and FIFA and Frostbite teams

642
00:30:47,409 --> 00:30:49,192
for their feedback and helping collecting

643
00:30:49,192 --> 00:30:50,193
the videos I shared.

644
00:30:50,193 --> 00:30:51,575
And thank you for coming.

645
00:30:51,575 --> 00:30:54,520
I hope you found something interesting or useful.

646
00:30:54,520 --> 00:30:55,621
Have a great rest of your day.

