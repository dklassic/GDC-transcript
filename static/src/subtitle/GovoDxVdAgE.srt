1
00:00:05,495 --> 00:00:14,069
you guys for coming to enthuse about retracing along the way. Ponder the problems that we've attempted to tackle and

2
00:00:14,109 --> 00:00:16,914
problems that the industry as a whole will attempt to continue to tackle.

3
00:00:17,571 --> 00:00:20,474
My name is Ntale Titarcuk and I lead Unity's graphics group.

4
00:00:21,074 --> 00:00:24,057
Now this presentation is focused on the lessons

5
00:00:24,077 --> 00:00:27,040
that we've learned throughout the process

6
00:00:27,080 --> 00:00:28,882
of doing a production-oriented approach

7
00:00:29,623 --> 00:00:33,146
for integrating ray tracing into our rasterization pipeline,

8
00:00:33,166 --> 00:00:36,029
and I'll talk about that from the perspective

9
00:00:36,069 --> 00:00:37,550
of the engine lessons that we've learned,

10
00:00:37,590 --> 00:00:38,611
as well as some of the things

11
00:00:38,631 --> 00:00:40,253
that are related to content creation.

12
00:00:41,394 --> 00:00:43,937
We'll talk a little bit about the pitfalls that we've explored,

13
00:00:44,197 --> 00:00:48,662
questions that we did encounter and may not have solved that I want you guys to help,

14
00:00:49,703 --> 00:00:52,546
and also some of the thinking about where we go from there.

15
00:00:53,167 --> 00:00:56,711
There are two major contributors along me to the presentation,

16
00:00:56,751 --> 00:01:00,655
Sebastian Lagarde and Anis Binoub from Unity Technologies.

17
00:01:01,055 --> 00:01:02,677
They will be here for questions at the end.

18
00:01:03,778 --> 00:01:08,660
However, everything I'm presenting here today has been a real team effort, and a lot of

19
00:01:08,700 --> 00:01:11,601
people contributed to the algorithms and systems that I'll be covering.

20
00:01:11,682 --> 00:01:12,902
I'm here to represent.

21
00:01:14,803 --> 00:01:18,965
But before we dive into the details of the technical presentation, I want to briefly

22
00:01:19,005 --> 00:01:22,387
share the project we've actually used to drive it.

23
00:01:23,747 --> 00:01:24,368
Pun intended.

24
00:01:31,766 --> 00:01:35,796
Invent yourself and then reinvent yourself.

25
00:01:36,999 --> 00:01:39,105
Don't swim in the same slough.

26
00:01:41,003 --> 00:01:48,024
Invent yourself and then reinvent yourself and stay out of the clutches of mediocrity

27
00:01:48,864 --> 00:01:56,386
invent yourself and then reinvent yourself change your tone and shape so often that

28
00:01:56,506 --> 00:02:01,827
they can never categorize you reinvigorate yourself and accept what is

29
00:02:02,947 --> 00:02:07,568
but only on the terms that you have invented me self-taught

30
00:02:10,113 --> 00:02:12,437
and reinvent your life because you must.

31
00:02:13,819 --> 00:02:15,082
It is your life.

32
00:02:16,805 --> 00:02:19,270
And its history and the present

33
00:02:19,310 --> 00:02:21,073
belong only to you.

34
00:02:31,450 --> 00:02:32,790
So what did you just see?

35
00:02:33,670 --> 00:02:36,651
This is actually the demo that we're going to dive here

36
00:02:36,791 --> 00:02:38,372
throughout all of the presentation,

37
00:02:38,672 --> 00:02:41,233
and I've lost the control of the screen, always exciting.

38
00:02:42,433 --> 00:02:44,294
Drivers will solve ray tracing,

39
00:02:44,374 --> 00:02:46,914
will solve all sorts of complex problems

40
00:02:46,994 --> 00:02:48,915
about cloud gaming and so forth,

41
00:02:48,995 --> 00:02:52,196
but presentation screens and driver control

42
00:02:52,236 --> 00:02:53,456
will remain to be a challenge.

43
00:02:55,192 --> 00:03:01,295
Okay, so the demo actually is at the heart of the outline of what we'll be covering.

44
00:03:01,315 --> 00:03:05,917
We'll talk about the rasterization pipeline, we'll talk about integrating the ray tracing

45
00:03:06,037 --> 00:03:08,898
into our high definition rendering pipeline.

46
00:03:09,338 --> 00:03:13,880
Some of the effects that we used for this particular demo, we'll talk about performance

47
00:03:13,940 --> 00:03:18,282
and some of the sort of thoughts about where DXR may want to go.

48
00:03:19,183 --> 00:03:20,123
But what did you just see?

49
00:03:20,704 --> 00:03:22,565
What we've done in this particular project

50
00:03:22,625 --> 00:03:25,086
is we filmed a real world car on location

51
00:03:25,567 --> 00:03:26,787
and recreated the scene.

52
00:03:26,827 --> 00:03:29,609
We captured the lighting environment, the scene itself,

53
00:03:30,269 --> 00:03:32,370
using the exact camera and lighting conditions,

54
00:03:32,831 --> 00:03:35,913
and then using the official product design model

55
00:03:35,953 --> 00:03:38,574
with all its crazy geometry, we then

56
00:03:38,854 --> 00:03:41,596
recreated the CG vehicle to match the film.

57
00:03:42,076 --> 00:03:43,737
And then we transitioned the shots in the video

58
00:03:43,777 --> 00:03:44,798
from real world car.

59
00:03:45,278 --> 00:03:46,638
like what you see on the left here,

60
00:03:47,039 --> 00:03:49,179
to the ray traced car seamlessly.

61
00:03:50,520 --> 00:03:52,921
And in the film we rendered this car at interactive rates

62
00:03:53,241 --> 00:03:58,583
on RTX 2018, sorry, 2080 Ti,

63
00:03:59,043 --> 00:04:01,064
with a lot of different ray tracing effects,

64
00:04:01,144 --> 00:04:03,545
refraction, area lights, shadows,

65
00:04:03,705 --> 00:04:05,205
ambient occlusion and so forth.

66
00:04:05,265 --> 00:04:06,466
And that's what we'll be covering.

67
00:04:13,042 --> 00:04:16,043
And here is an example of some of the more complex visuals

68
00:04:16,103 --> 00:04:18,364
going on in a demo with a complex transparency

69
00:04:18,384 --> 00:04:20,746
and refraction, and you're seeing a comparison

70
00:04:20,806 --> 00:04:22,446
against the real world filmed version.

71
00:04:24,107 --> 00:04:27,989
The car was quite complex, it was very dense geometry,

72
00:04:28,029 --> 00:04:29,410
and of course it's actually the vehicle

73
00:04:29,450 --> 00:04:32,572
that's used for production, but the reason we actually

74
00:04:32,692 --> 00:04:35,613
use this aside from, well, rendering pretty cars

75
00:04:35,673 --> 00:04:38,615
is always a good looking result, is its density

76
00:04:38,735 --> 00:04:40,496
is actually quite representative of a lot

77
00:04:40,516 --> 00:04:41,496
of real world scenes.

78
00:04:41,957 --> 00:04:44,978
There's a ton of silly meshes, very dense geometry,

79
00:04:45,478 --> 00:04:47,659
lots of draw calls, lots of different materials.

80
00:04:48,220 --> 00:04:50,401
While it's not identical to, let's say,

81
00:04:50,581 --> 00:04:52,001
an open world forest scene,

82
00:04:52,081 --> 00:04:53,862
it still has quite a lot of moving parts.

83
00:04:54,282 --> 00:04:55,223
And there are moving parts.

84
00:04:56,063 --> 00:04:57,564
So first, let's take a brief look

85
00:04:57,604 --> 00:04:59,545
at our high definition render pipeline

86
00:04:59,565 --> 00:05:02,026
because that's the basis for our approach.

87
00:05:03,639 --> 00:05:06,522
It is a physically based rendering pipeline.

88
00:05:06,542 --> 00:05:07,803
We use unified lighting.

89
00:05:08,243 --> 00:05:10,625
What that means is the same lighting features apply

90
00:05:10,685 --> 00:05:13,808
to opaque, transparent, volumetric elements

91
00:05:14,369 --> 00:05:15,910
in all of the content in the frame.

92
00:05:16,311 --> 00:05:17,872
We use coherent lighting throughout.

93
00:05:18,613 --> 00:05:20,454
All of the light types have to work

94
00:05:20,474 --> 00:05:21,615
with all of the materials,

95
00:05:22,016 --> 00:05:24,638
as well as with all of the options of global illumination,

96
00:05:24,678 --> 00:05:26,400
light maps, light probes, and so forth.

97
00:05:26,880 --> 00:05:29,761
This is super important for content creation.

98
00:05:30,322 --> 00:05:32,002
And as you see throughout this presentation,

99
00:05:32,062 --> 00:05:34,344
we strived to maintain the same principle

100
00:05:34,364 --> 00:05:35,964
for our ray tracing approach as well.

101
00:05:36,585 --> 00:05:39,046
And while certainly, you know,

102
00:05:39,166 --> 00:05:41,087
we think of ray tracing as a panacea

103
00:05:41,127 --> 00:05:43,028
that will solve all of our rendering problems.

104
00:05:43,428 --> 00:05:45,069
There's some really interesting challenges

105
00:05:45,109 --> 00:05:47,550
with maintaining this unified approach.

106
00:05:48,190 --> 00:05:50,011
And in HD in particular,

107
00:05:50,051 --> 00:05:52,533
we also worked hard to avoid double lighting

108
00:05:52,593 --> 00:05:53,453
and double occlusion.

109
00:05:54,314 --> 00:05:59,056
Now, one of the important properties for our implementation, which may not be true for

110
00:05:59,076 --> 00:06:04,280
a specific game, is we need to be able to do either forward for VR applications, for

111
00:06:04,340 --> 00:06:06,341
example, or deferred approach.

112
00:06:06,401 --> 00:06:10,043
And again, when we were looking at ray tracing, we needed to think about how that's going

113
00:06:10,083 --> 00:06:13,565
to affect the particular set of choices.

114
00:06:15,209 --> 00:06:18,171
With our HD pipeline, we have classification of materials.

115
00:06:18,231 --> 00:06:21,513
They get output to GBuffer, so standard opaque,

116
00:06:21,553 --> 00:06:24,274
subsurface scattering, clear coat, iridescence,

117
00:06:24,394 --> 00:06:29,017
anisotropic, they're all stored in the GBuffer with a bit.

118
00:06:29,777 --> 00:06:33,739
Now, some materials in our deferred path are so complex

119
00:06:33,899 --> 00:06:35,700
or need additional information.

120
00:06:36,320 --> 00:06:38,221
For example, we want to store specular tin

121
00:06:38,262 --> 00:06:40,263
that we need to still render them as forward.

122
00:06:40,463 --> 00:06:41,943
Of course, our favorite, transparence.

123
00:06:42,464 --> 00:06:45,065
But then beyond that, we have a number of organic materials,

124
00:06:45,165 --> 00:06:48,827
skin, hair, fabric, sorry, not skin, eyes,

125
00:06:49,267 --> 00:06:51,048
that still need to be rendered with forward.

126
00:06:51,328 --> 00:06:53,389
And again, that has some interesting implications

127
00:06:53,469 --> 00:06:57,171
for being able to do that in a rasterization pipeline.

128
00:06:58,605 --> 00:07:01,046
The ray tracing pipeline that we built for HDRP

129
00:07:01,086 --> 00:07:03,866
is actually built directly on top of that pipeline.

130
00:07:04,086 --> 00:07:06,547
We plugged all the low-level layers,

131
00:07:06,627 --> 00:07:09,107
and in this presentation, I'm actually not gonna talk about

132
00:07:09,627 --> 00:07:12,228
how we integrated DXR to the low-level renderer.

133
00:07:12,288 --> 00:07:15,389
That's kind of a topic of a separate presentation.

134
00:07:15,909 --> 00:07:19,429
We did the layer that we exposed to C-sharp,

135
00:07:19,469 --> 00:07:21,610
so in Unity, you can actually access

136
00:07:21,710 --> 00:07:24,250
much of the rendering pipeline control through C-sharp.

137
00:07:24,782 --> 00:07:25,302
and shaders.

138
00:07:25,803 --> 00:07:29,728
And so after that, majority of the work on array tracing effect happened on that level,

139
00:07:30,489 --> 00:07:34,614
which of course meant that we can iterate really quickly on the effects once the architecture

140
00:07:34,654 --> 00:07:35,375
was established.

141
00:07:36,706 --> 00:07:39,649
And just a quick thing, I'll constantly be saying ray trace effect.

142
00:07:40,129 --> 00:07:45,073
Really, it just means, you know, a bucket of container for anything that goes on to

143
00:07:45,133 --> 00:07:49,237
render a particular ray trace algorithm, be it ambient occlusion or shadows and so

144
00:07:49,297 --> 00:07:54,541
forth. So in our case, again, I mentioned that we need to be really flexible with

145
00:07:54,581 --> 00:07:58,345
regards to forward and deferred support because we want ray tracing to be used

146
00:07:58,385 --> 00:07:58,885
regardless.

147
00:07:59,566 --> 00:08:01,308
of the particular directionality.

148
00:08:01,829 --> 00:08:06,915
And so for ray tracing, we start by shooting secondary rays

149
00:08:07,035 --> 00:08:09,318
from depth buffer and normal buffer.

150
00:08:09,998 --> 00:08:11,700
For a peak, of course, this is straightforward.

151
00:08:11,720 --> 00:08:13,703
We can use G-buffer as a starting point.

152
00:08:14,403 --> 00:08:20,486
Now with forward objects, we use a pre-pass, and we use that already for screen space reflection,

153
00:08:21,586 --> 00:08:26,208
to output depth normal during the pre-pass, and that's the information we can start secondary

154
00:08:26,268 --> 00:08:32,010
rays from. So in some ways, since we already have a good implementation of SSR, it actually

155
00:08:32,070 --> 00:08:35,451
needs the same data as ray tracing for a lot of the materials as you'll see.

156
00:08:36,706 --> 00:08:48,331
Of course, the next thing that we know is we'll never be able to shoot thousands and tens of thousands of rays that you'll see in a Weta digital Manuka or similar offline, you know, renders in order to maintain performance.

157
00:08:48,671 --> 00:08:57,315
And this theme is repeated throughout anybody who's talking about real time ray tracing, reducing noise through denoising and temporal accumulation is key to achieve frame rate.

158
00:08:58,395 --> 00:09:04,658
So, we mentioned we're going to start from, for ray trace, from primary rays from camera,

159
00:09:05,098 --> 00:09:06,199
shoot it in screen space.

160
00:09:06,219 --> 00:09:09,320
This is basically to obtain visibility, and I'll discuss where we use it.

161
00:09:10,080 --> 00:09:14,442
And for secondary rays, we start from the first intersection with the primary rays,

162
00:09:14,782 --> 00:09:17,163
and that's the G-buffer or pre-pass approach.

163
00:09:18,978 --> 00:09:22,481
In reality, every ray has to be thought about quite thoroughly.

164
00:09:22,541 --> 00:09:26,084
It's quite expensive to implement it, especially as we get to ray tracing.

165
00:09:26,724 --> 00:09:29,767
Now, of course, as we shoot more rays, the resulting quality is higher.

166
00:09:31,008 --> 00:09:34,450
The simple truth is if you don't shoot a sufficient number of rays,

167
00:09:34,811 --> 00:09:37,913
you'll end up with a terrible looking, huge degradation of quality,

168
00:09:37,953 --> 00:09:38,894
terrible looking effect.

169
00:09:39,802 --> 00:09:44,545
Now we supplement that with denoiser to keep the frays fast.

170
00:09:44,945 --> 00:09:48,228
However one important thing about denoising is we need to denoise every

171
00:09:48,268 --> 00:09:52,470
single effect because they actually have different qualities and we need to make

172
00:09:52,531 --> 00:09:53,811
sure that we account that.

173
00:09:55,013 --> 00:09:57,555
And so we're kind of in this sweet spot of trade-off

174
00:09:57,595 --> 00:09:59,436
between the quality of the actual denoiser,

175
00:09:59,876 --> 00:10:01,117
the cost it will take to run it,

176
00:10:01,597 --> 00:10:04,438
versus the cost that it will take to run more rays,

177
00:10:04,599 --> 00:10:06,520
evaluation of rays being the expensive part.

178
00:10:07,020 --> 00:10:09,281
Now we could choose to go to a high quality denoiser.

179
00:10:09,341 --> 00:10:11,842
NVIDIA has a very sophisticated denoiser available

180
00:10:12,303 --> 00:10:14,704
that uses light positions, specular roughness.

181
00:10:14,964 --> 00:10:15,945
It needs more information.

182
00:10:16,265 --> 00:10:18,546
So one, you'll pay the cost to output this information.

183
00:10:19,030 --> 00:10:21,131
two, you'll store it, three, you'll sample it,

184
00:10:21,211 --> 00:10:23,912
four, the actual algorithm of the denoiser is heavier.

185
00:10:24,453 --> 00:10:26,374
And of course, that might, in our case,

186
00:10:26,414 --> 00:10:30,616
when we evaluated, it dominated the cost of rate execution.

187
00:10:30,636 --> 00:10:31,777
So all of the savings we did

188
00:10:31,817 --> 00:10:33,738
by not shooting more rains were gone.

189
00:10:34,598 --> 00:10:37,400
And so that ended up not being a win for us.

190
00:10:38,060 --> 00:10:44,365
So our approach is launch minimal amount of rays, then reduce variance with good sampling,

191
00:10:44,405 --> 00:10:49,049
and we'll talk about some of the techniques there, accumulate temporally because that allows us to

192
00:10:49,829 --> 00:10:54,553
get more contributions of rays, and then the end result of that goes through the denoiser.

193
00:10:55,654 --> 00:10:58,775
It's very straightforward to understand the cost of rays.

194
00:10:59,255 --> 00:11:00,696
It varies linearly with length.

195
00:11:01,417 --> 00:11:04,338
We actually did a number of performance profiling

196
00:11:04,358 --> 00:11:06,019
to determine that.

197
00:11:06,679 --> 00:11:10,581
And for the live demo that you will see in a few minutes

198
00:11:10,621 --> 00:11:13,463
here, we actually use one ray, for example,

199
00:11:14,043 --> 00:11:15,044
for regular effects.

200
00:11:15,384 --> 00:11:18,385
For some of the more expensive effects, like reflection,

201
00:11:18,425 --> 00:11:20,607
we use quarter resolution.

202
00:11:21,007 --> 00:11:24,028
And then for AO and shadows, we end up using four rays.

203
00:11:25,062 --> 00:11:28,123
Now, of course, this is a sweet swat of perf versus quality.

204
00:11:29,864 --> 00:11:32,184
And so with respect to denoising, like I mentioned,

205
00:11:32,205 --> 00:11:33,405
we have to do it per effect.

206
00:11:33,425 --> 00:11:35,826
So we went with a very inexpensive approach

207
00:11:35,866 --> 00:11:37,066
that gives us good quality.

208
00:11:37,957 --> 00:11:44,361
Now, I want to say, so the way that we are approaching that is we do it in temporal,

209
00:11:44,561 --> 00:11:46,502
and then we use a joint bilateral filtering.

210
00:11:47,122 --> 00:11:51,925
With regards to temporal, just to clarify, it's not a TAA filter, very similar to the

211
00:11:51,985 --> 00:11:57,368
approach that Tomas Takovies described in last year's Digital Dragons presentation.

212
00:11:57,789 --> 00:11:59,209
It's only inspired by TAA.

213
00:11:59,830 --> 00:12:03,052
And so what we do is we run one sample per effect,

214
00:12:03,092 --> 00:12:04,973
which is accumulated over frames,

215
00:12:05,133 --> 00:12:07,615
and then we run eight sample TAAs.

216
00:12:07,735 --> 00:12:10,937
So we accumulate eight frames history's worth,

217
00:12:12,018 --> 00:12:13,939
and that's actually what we are doing

218
00:12:14,019 --> 00:12:15,681
to kind of supplement the temporal.

219
00:12:16,361 --> 00:12:19,223
We're not trying with this element to remove aliasing.

220
00:12:19,243 --> 00:12:21,224
We're simply trying to accumulate pixels

221
00:12:22,025 --> 00:12:23,826
to match history in the material properties.

222
00:12:24,266 --> 00:12:25,607
And at the end of the frame, like I said,

223
00:12:25,627 --> 00:12:26,768
we have the property.

224
00:12:29,039 --> 00:12:33,895
For each effect, we need to run essentially the custom history per effect.

225
00:12:33,916 --> 00:12:34,578
So this is where.

226
00:12:36,833 --> 00:12:39,794
the specificity about each effect comes into place.

227
00:12:40,214 --> 00:12:43,175
We actually store a history buffer per effect,

228
00:12:43,735 --> 00:12:47,077
one set per area shadow lights.

229
00:12:47,597 --> 00:12:48,937
It gives us better stability.

230
00:12:48,957 --> 00:12:51,118
Of course that comes at the cost of additional memory

231
00:12:51,798 --> 00:12:54,339
as we need to add memory for the history for accumulation.

232
00:12:55,340 --> 00:12:58,881
But that memory really allows us to reduce number of rays,

233
00:12:58,981 --> 00:13:01,242
thus increasing performance, so it's kind of a trade off.

234
00:13:02,582 --> 00:13:04,683
We use joint bilateral filter throughout.

235
00:13:05,444 --> 00:13:08,645
And in this case, it's using normal and depth

236
00:13:08,865 --> 00:13:10,606
as opposed to luminance that you'd

237
00:13:10,626 --> 00:13:11,907
see with a bilateral filter.

238
00:13:12,447 --> 00:13:14,528
It's a nice and inexpensive filter implemented

239
00:13:14,588 --> 00:13:16,229
as a separal computiator filter.

240
00:13:17,289 --> 00:13:19,651
And normals and depth allow us to sort out

241
00:13:19,671 --> 00:13:20,991
the discontinuity issues.

242
00:13:21,451 --> 00:13:24,093
And as I said, we output them either through G-buffer

243
00:13:24,113 --> 00:13:24,793
or pre-pass.

244
00:13:25,854 --> 00:13:28,295
And so that allows us to take advantage

245
00:13:28,335 --> 00:13:30,456
of opaque and forward materials.

246
00:13:31,992 --> 00:13:35,173
Now, the fun part is, well, that permutation of materials

247
00:13:35,213 --> 00:13:36,534
that we've mentioned early on,

248
00:13:37,134 --> 00:13:39,535
transparence have been a pain and suffering

249
00:13:39,575 --> 00:13:42,436
for people who are doing rasterizations for decades, right?

250
00:13:42,996 --> 00:13:44,856
Well, I'm sorry to say,

251
00:13:44,956 --> 00:13:46,897
but that doesn't quite go away with ray tracing,

252
00:13:47,597 --> 00:13:49,158
of course, if you care about performance.

253
00:13:49,818 --> 00:13:51,839
In this case, since we don't have depth,

254
00:13:52,279 --> 00:13:55,540
we actually can't really use anything for that

255
00:13:55,560 --> 00:13:57,560
in this particular case because we're not outputting.

256
00:13:57,881 --> 00:13:59,661
We'll talk about how we sorted transparency

257
00:13:59,701 --> 00:14:00,761
in a subsequent path.

258
00:14:01,746 --> 00:14:04,209
With regards to denoiser, we provide artists the ability

259
00:14:04,249 --> 00:14:05,230
to control the filter.

260
00:14:05,571 --> 00:14:08,114
For example, the video that you saw of the demo

261
00:14:08,134 --> 00:14:10,537
that we rendered for the matching of the real car,

262
00:14:10,937 --> 00:14:12,419
they were using quite large filters.

263
00:14:12,479 --> 00:14:14,642
Of course, that means that the cost is higher.

264
00:14:15,243 --> 00:14:16,825
And the content creators can basically

265
00:14:16,845 --> 00:14:19,348
control the cost of quality versus trade-off.

266
00:14:19,748 --> 00:14:22,451
And we intend to make it scalable based on essentially

267
00:14:22,471 --> 00:14:23,632
platform configurations.

268
00:14:24,473 --> 00:14:26,655
And that allows us to really amp up the quality

269
00:14:27,075 --> 00:14:30,138
on a per effect level, aside from just per platform level.

270
00:14:30,458 --> 00:14:33,460
So if you wanted to really spend more time samples

271
00:14:33,501 --> 00:14:36,223
in a particular algorithm, you can.

272
00:14:38,325 --> 00:14:41,107
Now, with simple bilateral denoiser, stability of results

273
00:14:41,247 --> 00:14:44,470
is very highly dependent on the actual qualities of the samples

274
00:14:44,510 --> 00:14:46,051
that feed into the denoiser.

275
00:14:46,807 --> 00:14:48,488
which is why sampling is crucial

276
00:14:48,528 --> 00:14:50,089
in order to generate a good frame.

277
00:14:50,489 --> 00:14:52,110
When you have good samples,

278
00:14:52,150 --> 00:14:54,872
your denoiser result will be much more stable.

279
00:14:55,292 --> 00:14:58,454
And Matt Farr in last year's 2018 advances talk

280
00:14:58,854 --> 00:15:01,395
gave a really wonderful presentation on the intuition

281
00:15:01,575 --> 00:15:04,617
of some of the approaches that you need to think about

282
00:15:04,657 --> 00:15:05,938
to achieve low variance.

283
00:15:06,598 --> 00:15:09,239
This is important to do before you apply the denoiser.

284
00:15:11,361 --> 00:15:12,981
So next we're gonna touch on sampling.

285
00:15:13,081 --> 00:15:15,503
How do we approach reduction of variance?

286
00:15:16,857 --> 00:15:19,459
So ultimately, everything is related.

287
00:15:20,020 --> 00:15:22,402
Everything that you're in the limit surface,

288
00:15:22,442 --> 00:15:24,525
essentially, we take infinite number of samples

289
00:15:24,565 --> 00:15:25,586
without any denoiser.

290
00:15:25,966 --> 00:15:28,368
The signal converges, and our result is unbiased.

291
00:15:28,388 --> 00:15:29,750
That's, of course, the Holy Grail.

292
00:15:30,451 --> 00:15:32,393
But as we imagine, it's quite not real time.

293
00:15:32,433 --> 00:15:33,233
That's the, you know.

294
00:15:33,994 --> 00:15:35,815
hours of frames in the offline renderer.

295
00:15:36,356 --> 00:15:38,798
So we applied denoiser, congratulations,

296
00:15:39,298 --> 00:15:40,599
well that introduces bias.

297
00:15:41,159 --> 00:15:45,262
And so the better we actually stratify our sampling,

298
00:15:45,282 --> 00:15:47,203
the better the end result will be

299
00:15:47,263 --> 00:15:48,684
with regards to reducing bias.

300
00:15:50,125 --> 00:15:53,508
And so even though we actually might pay more cost

301
00:15:53,788 --> 00:15:56,410
in the way that we're doing selection of rays,

302
00:15:56,910 --> 00:15:59,152
it's more than offset by the resulting

303
00:15:59,212 --> 00:16:00,553
quality improvement for the rays.

304
00:16:02,588 --> 00:16:05,571
And it's the same principle as multiple important samplings,

305
00:16:06,132 --> 00:16:07,573
where you have essentially a lobe

306
00:16:07,613 --> 00:16:10,316
and you bias the sampling direction toward that lobe,

307
00:16:11,317 --> 00:16:13,900
converting the texture to probability distribution

308
00:16:13,940 --> 00:16:15,341
for that lobe representation.

309
00:16:15,942 --> 00:16:19,226
And we sample from that sequence and then convert it to PDF.

310
00:16:20,447 --> 00:16:22,229
We actually execute similar approach

311
00:16:22,669 --> 00:16:24,811
for all of our ray launches per effect.

312
00:16:26,779 --> 00:16:29,001
So to hedge our bets, pun intended,

313
00:16:29,321 --> 00:16:31,802
we use the following sampling strategy.

314
00:16:32,503 --> 00:16:34,524
We rely on Owen's scrambled sequence,

315
00:16:34,564 --> 00:16:38,207
which was actually described in SIGGRAPH 2003 talk

316
00:16:38,647 --> 00:16:39,828
on Monte Carlo techniques.

317
00:16:40,868 --> 00:16:42,789
And essentially, Sobel's sequence

318
00:16:42,930 --> 00:16:46,392
is a really widely used low discrepancy sequence

319
00:16:46,952 --> 00:16:49,274
for numerical solving of multiple integrals,

320
00:16:49,294 --> 00:16:51,955
which is why, of course, it's relevant to Monte Carlo.

321
00:16:52,696 --> 00:16:55,017
And a lot of the quasi-Monte Carlo computations

322
00:16:56,047 --> 00:17:02,350
rely on using this sequence and then scrambling it through permutation that allowed us to

323
00:17:03,351 --> 00:17:08,714
him originally to maintain the low discrepancy. Now each extra sample increases the coverage in

324
00:17:08,754 --> 00:17:14,217
an optimal way and thus allows sampling to be temporally coherent. And next frame continues

325
00:17:14,277 --> 00:17:18,180
to build a sequence and this is actually the sequence that you see that we do in time.

326
00:17:20,672 --> 00:17:22,473
Each pixel uses identical sequence,

327
00:17:22,493 --> 00:17:23,693
which is stored in a texture,

328
00:17:24,373 --> 00:17:27,035
and we use a screen space blue noise to break up the pattern.

329
00:17:27,715 --> 00:17:29,636
It ends up being coherent in screen space,

330
00:17:29,676 --> 00:17:30,697
and here is the example.

331
00:17:31,357 --> 00:17:34,118
Kind of the pseudocode, we generate a ray direction

332
00:17:34,298 --> 00:17:36,440
using X sample in one direction,

333
00:17:36,460 --> 00:17:39,521
that's the first row that you see, to get one sample,

334
00:17:39,621 --> 00:17:41,802
and then we use the second row in Y direction

335
00:17:41,842 --> 00:17:42,783
for the second sample.

336
00:17:43,643 --> 00:17:46,084
And this allows us to use two dimensions everywhere,

337
00:17:46,765 --> 00:17:48,646
except with a special case of area light

338
00:17:48,666 --> 00:17:50,226
where we use actually three dimensions.

339
00:17:51,800 --> 00:17:53,340
We accumulate up to eight frames,

340
00:17:53,900 --> 00:17:57,181
and inside OneEffect we can actually go up to 32 samples

341
00:17:57,921 --> 00:17:59,282
because of our current implementation

342
00:17:59,322 --> 00:18:02,003
stores a 256 by 256 squares texture.

343
00:18:02,403 --> 00:18:04,303
But we also can play with changing the dimensions

344
00:18:04,343 --> 00:18:06,224
to basically go with a lot more samples

345
00:18:06,724 --> 00:18:08,664
by doing a two by 10 to 24.

346
00:18:10,085 --> 00:18:12,186
so that you can actually end up with 128 samples

347
00:18:12,227 --> 00:18:15,309
if you wanted to, so kind of your value will matter.

348
00:18:15,990 --> 00:18:18,151
And like I mentioned, scrambling happens with blue noise.

349
00:18:18,692 --> 00:18:20,233
We begin by grabbing the blue noise

350
00:18:20,253 --> 00:18:21,594
with the current texel position

351
00:18:22,115 --> 00:18:24,016
from a pre-computed texture.

352
00:18:24,336 --> 00:18:25,757
It gives us the XY noise.

353
00:18:26,278 --> 00:18:27,379
Then for each coordinate,

354
00:18:27,399 --> 00:18:30,141
we sample the own scrambled dimension texture,

355
00:18:30,181 --> 00:18:33,344
like I've described, scrambling the resulting blue noise.

356
00:18:34,024 --> 00:18:36,066
And then the scramble of the blue noise analysis

357
00:18:36,106 --> 00:18:37,747
to reduce the pattern repetition.

358
00:18:38,828 --> 00:18:43,672
Then, the blue noise is essentially allowing us to ease the filtering of the denoiser,

359
00:18:44,152 --> 00:18:46,674
since it provides a very common filter for denoising.

360
00:18:48,255 --> 00:18:53,119
And so this allows us to yield a temporally coherent sequence with a number of samples,

361
00:18:53,219 --> 00:18:55,040
and so it accumulates in a stable manner.

362
00:18:56,893 --> 00:18:59,915
So if we look at, now we've covered kind of like,

363
00:18:59,975 --> 00:19:02,136
we do noise, we figure out good sampling,

364
00:19:02,296 --> 00:19:05,097
and then we reduce the resulting bias.

365
00:19:05,618 --> 00:19:07,619
Now how do we approach ray trace effects?

366
00:19:08,139 --> 00:19:10,380
The general architecture is quite straightforward.

367
00:19:11,301 --> 00:19:13,902
So if we look at DXR, we have a number of different shaders,

368
00:19:14,002 --> 00:19:16,764
ray generation, closest hit, any hit, miss, and so forth.

369
00:19:17,224 --> 00:19:18,465
And then there's a surface shader.

370
00:19:19,545 --> 00:19:21,426
In a surface shader, there's a couple of options.

371
00:19:22,725 --> 00:19:25,429
Of course, people get really hyped up about ray tracing

372
00:19:25,710 --> 00:19:28,354
and I implemented my own PoV ray tracing,

373
00:19:28,394 --> 00:19:29,435
I'll age myself, you know,

374
00:19:29,475 --> 00:19:31,338
every one of you implemented it probably too.

375
00:19:32,560 --> 00:19:34,763
It was awesome, we got transparency, reflections,

376
00:19:34,823 --> 00:19:36,225
textures, we felt really good.

377
00:19:37,166 --> 00:19:38,969
And yeah, sure, it solves everything.

378
00:19:39,742 --> 00:19:43,924
Real production content is a tad different from them spheres.

379
00:19:43,944 --> 00:19:46,025
You have immensely varied material types

380
00:19:46,305 --> 00:19:48,286
and accounting for surface shader

381
00:19:48,346 --> 00:19:51,568
that I was just showing you is a must.

382
00:19:52,009 --> 00:19:54,510
However, we now need to deal with the vast permutations

383
00:19:54,550 --> 00:19:55,350
of material types.

384
00:19:55,551 --> 00:19:59,333
Opaque, opaque alpha tested, so you see lots of that here.

385
00:19:59,853 --> 00:20:03,595
Transparent, eyes and so forth, double-sided and many more.

386
00:20:04,155 --> 00:20:05,956
As we go through our effects and retracing,

387
00:20:06,337 --> 00:20:09,747
keep these in mind because we're actually trying to solve it for a production that,

388
00:20:09,787 --> 00:20:12,114
you know, isn't limited to opaque spheres.

389
00:20:13,427 --> 00:20:16,149
So a good way to think about ray tracing effects

390
00:20:16,229 --> 00:20:17,150
is ambient occlusion.

391
00:20:17,210 --> 00:20:19,392
It's kind of like the hello world of ray tracing,

392
00:20:19,452 --> 00:20:21,053
so to say, which is why everybody starts it.

393
00:20:21,493 --> 00:20:22,554
And when we say hello world,

394
00:20:22,594 --> 00:20:24,675
we really mean ambient occlusion for opaque,

395
00:20:24,816 --> 00:20:26,317
non-alpha tested objects, right?

396
00:20:27,678 --> 00:20:29,859
We trace the ray from G-buffer position

397
00:20:29,979 --> 00:20:31,841
in the direction of the normal for opaque,

398
00:20:32,201 --> 00:20:34,122
on alpha tested objects from the, you know,

399
00:20:34,563 --> 00:20:35,483
very straightforward.

400
00:20:36,024 --> 00:20:37,965
And then secondary rays used to compute

401
00:20:38,005 --> 00:20:38,966
the ambient occlusion.

402
00:20:39,466 --> 00:20:40,727
We pick the number of samples,

403
00:20:40,787 --> 00:20:42,128
that's just a parameter in a shader.

404
00:20:42,729 --> 00:20:45,771
Sample the hemispherical sine, this is the standard approach,

405
00:20:45,811 --> 00:20:47,572
and I forgot to include the proper reference

406
00:20:48,093 --> 00:20:49,614
for Matt Farr's amazing book.

407
00:20:50,615 --> 00:20:53,657
Simply requires a random number provided to,

408
00:20:54,318 --> 00:20:56,880
again, to feed the denoiser and we use the own sequence.

409
00:20:58,804 --> 00:21:02,905
So in terms of the hit, it's actually very straightforward.

410
00:21:02,925 --> 00:21:06,087
We know if we hit something for opaque surfaces,

411
00:21:06,127 --> 00:21:08,107
this means we actually don't need to continue.

412
00:21:08,147 --> 00:21:09,368
It's already occluded.

413
00:21:09,408 --> 00:21:11,828
It's purely a visibility computation.

414
00:21:12,189 --> 00:21:14,929
And so we can just use any hit to evaluate this visibility.

415
00:21:15,310 --> 00:21:15,890
Simple path.

416
00:21:16,950 --> 00:21:19,151
And shaders are just for you for reference for later.

417
00:21:19,511 --> 00:21:20,971
We actually don't need to spend time on them.

418
00:21:22,021 --> 00:21:23,862
Now for AO, we need to choose distance.

419
00:21:24,342 --> 00:21:28,104
If you choose infinite, that's your sky occlusion computation, right?

420
00:21:28,524 --> 00:21:33,346
Small distance is more like the regular AO, in some ways approaching the

421
00:21:33,426 --> 00:21:36,287
sort of SSAO-ish type of hemisphere distance.

422
00:21:36,827 --> 00:21:41,069
Now the distance drives the past performance, ultimately, and so that's your optimization.

423
00:21:41,469 --> 00:21:44,551
Longer A is far more expensive, as you need to traverse more BVH.

424
00:21:45,111 --> 00:21:47,352
The cost of ray, like I mentioned, was linear.

425
00:21:48,012 --> 00:21:48,312
And so...

426
00:21:49,753 --> 00:21:53,474
We need to think really, you know, thoroughly about the distance that we provide.

427
00:21:53,934 --> 00:21:56,856
And then the denoiser actually correlates to cost as well,

428
00:21:57,756 --> 00:22:00,177
because it's dependent on the size of the kernel.

429
00:22:00,977 --> 00:22:02,718
Cost is linear based on the size of the kernel.

430
00:22:04,515 --> 00:22:06,616
So why do we even bother with AO?

431
00:22:06,636 --> 00:22:10,657
Because I thought you said, you know, I said earlier, we're going to do shadows, right?

432
00:22:10,877 --> 00:22:13,778
That should technically take care of all of the occlusion issues.

433
00:22:14,918 --> 00:22:18,819
If we have strong environment lighting, and that's the example of HDRI skies, right?

434
00:22:19,279 --> 00:22:24,100
Either HDRI skies or light probes, global shadows will show you the sort of.

435
00:22:24,960 --> 00:22:27,022
crease details and of course the major movements,

436
00:22:27,362 --> 00:22:29,623
but you'll lose a lot of the information from far away.

437
00:22:29,923 --> 00:22:32,344
Because guess what, we didn't pick the infinite distance, right?

438
00:22:32,384 --> 00:22:36,187
Like we already constrained it to some particular area of the scene.

439
00:22:36,247 --> 00:22:40,229
And that theme gets repeated throughout because as we optimize performance,

440
00:22:41,049 --> 00:22:44,991
we walk away from ground truth and then we need to make up for the lack of ground truth.

441
00:22:45,051 --> 00:22:45,992
And this is the example.

442
00:22:46,452 --> 00:22:50,334
So AO can really be a good supplement for the areas where you miss the

443
00:22:50,574 --> 00:22:52,736
occlusion for the larger elements of the scene.

444
00:22:53,436 --> 00:23:00,378
For comparison, this is screen space ambient occlusion in HDRP on the car asset.

445
00:23:00,698 --> 00:23:02,759
And here you see the ray traced occlusion.

446
00:23:03,239 --> 00:23:05,300
Now, note some of the over-darkening in the images.

447
00:23:05,340 --> 00:23:07,680
That's our friends, the transparence.

448
00:23:08,341 --> 00:23:09,641
And we'll touch on that in a second.

449
00:23:09,681 --> 00:23:12,162
But of course, you can see as I kind of switch back and forth,

450
00:23:12,622 --> 00:23:16,683
how much more accurate occlusion results in terms of ambient occlusion.

451
00:23:17,484 --> 00:23:18,764
So, yes, transparence.

452
00:23:18,864 --> 00:23:20,845
What if we want to have more than just opaques?

453
00:23:22,340 --> 00:23:24,580
Okay, double-sided material is actually not too bad.

454
00:23:24,981 --> 00:23:26,661
We pass the flag to the API,

455
00:23:26,921 --> 00:23:28,982
and that basically disabled calling

456
00:23:29,182 --> 00:23:32,123
in the acceleration structure on the DXR side,

457
00:23:32,163 --> 00:23:32,803
and we're good.

458
00:23:33,303 --> 00:23:34,543
Okay, that was kind of easy.

459
00:23:35,444 --> 00:23:36,544
Transparency, right?

460
00:23:36,584 --> 00:23:38,605
Like, we thought it was gonna be totally doable.

461
00:23:40,123 --> 00:23:42,744
The problem is in ray tracing path,

462
00:23:42,784 --> 00:23:44,345
it's still quite a bit of a pain.

463
00:23:45,145 --> 00:23:49,507
There's not really actually an easy way to do this

464
00:23:49,547 --> 00:23:51,768
that's performant quite yet in real time

465
00:23:52,508 --> 00:23:56,189
because we need to account for accumulation of light

466
00:23:56,910 --> 00:23:59,291
and we need to account for rough refraction effects.

467
00:23:59,591 --> 00:24:01,552
If the object is 50% transparent,

468
00:24:02,052 --> 00:24:03,472
we need, for example, for AO,

469
00:24:03,492 --> 00:24:04,553
we need to accumulate 50% of AO

470
00:24:06,134 --> 00:24:08,215
and then continue to keep accumulating

471
00:24:08,255 --> 00:24:10,397
because some of the light propagates through the media.

472
00:24:10,877 --> 00:24:12,158
And if the object is rough,

473
00:24:12,618 --> 00:24:15,381
we have to actually then account for the ray distribution

474
00:24:15,521 --> 00:24:18,863
for, you know, this is the example of the spread here.

475
00:24:18,883 --> 00:24:21,685
And of course, perf head for doing this many rays

476
00:24:21,925 --> 00:24:24,828
is actually not, we're not quite there in terms of hardware

477
00:24:26,229 --> 00:24:27,690
to be able to do this at real time.

478
00:24:27,730 --> 00:24:29,511
So we need to special case transparence.

479
00:24:31,252 --> 00:24:33,654
As I mentioned, alpha testing is crucial

480
00:24:33,834 --> 00:24:34,875
for real-time production.

481
00:24:36,449 --> 00:24:41,073
Now artists actually author AlphaTested as just a sub-graph and a shader graph.

482
00:24:41,533 --> 00:24:45,077
We don't know what they're going to evaluate, what crazy surface elements they're going

483
00:24:45,097 --> 00:24:45,537
to pull in.

484
00:24:46,078 --> 00:24:50,021
And so we need to add support for AlphaTested objects in a generic way that allows us to

485
00:24:50,061 --> 00:24:54,085
sample this material model that is not in any manner of hard-coded.

486
00:24:55,608 --> 00:24:58,109
At Raytrace, what we do is we evaluate the subgraph

487
00:24:58,129 --> 00:25:00,951
from the alpha-tested evaluation,

488
00:25:00,971 --> 00:25:01,852
that's what you see here,

489
00:25:02,512 --> 00:25:06,575
and that evaluation increases the cost of the effects,

490
00:25:06,835 --> 00:25:09,677
because we now need to add it to the AnyHit surface shader.

491
00:25:10,537 --> 00:25:12,999
And all of the effects, like shadows, AO, et cetera,

492
00:25:13,019 --> 00:25:15,000
need to support it in order to render it correctly.

493
00:25:16,001 --> 00:25:18,162
So the hit processing needs to account

494
00:25:18,202 --> 00:25:19,223
for alpha's threshold.

495
00:25:21,535 --> 00:25:24,257
And what this means is all of the effects need to actually

496
00:25:24,317 --> 00:25:26,457
plan to account alpha testing holistically,

497
00:25:27,098 --> 00:25:29,359
which of course increases the complexity of the effects.

498
00:25:29,879 --> 00:25:31,660
And here's the example, you can kind of see

499
00:25:31,700 --> 00:25:37,122
that little foliage element and it's doing proper alpha

500
00:25:37,162 --> 00:25:38,803
testing for reflections in the mirror,

501
00:25:39,283 --> 00:25:42,344
as well as shadows and so forth.

502
00:25:44,285 --> 00:25:47,506
Now, this is the example of double-sided geometry.

503
00:25:49,183 --> 00:25:51,484
So we handled ambient occlusion examples,

504
00:25:51,504 --> 00:25:53,004
so we handled visibility, good.

505
00:25:53,024 --> 00:25:55,245
We handled some surface property,

506
00:25:55,325 --> 00:25:56,745
alpha tested, double sided.

507
00:25:56,805 --> 00:26:00,086
So let's kind of think about the next build of the effects,

508
00:26:00,167 --> 00:26:03,848
the opaque, the shadows.

509
00:26:05,164 --> 00:26:10,428
and reflection. So if we think about reflection, this is the contribution of indirect specular.

510
00:26:11,028 --> 00:26:15,592
The effect starts bringing a lot of the complexity for production pipelines. We typically want

511
00:26:15,632 --> 00:26:20,816
to bring them to replace screen space reflections because there's a lot of artifacts and it's

512
00:26:20,976 --> 00:26:25,560
a very challenging effect to do. But then we need to think about all the material permutation.

513
00:26:26,240 --> 00:26:27,942
There's another thing that we need to think about

514
00:26:27,982 --> 00:26:29,603
from perspective of engine architecture,

515
00:26:30,184 --> 00:26:32,646
which is, well, we're really, really accustomed

516
00:26:32,686 --> 00:26:34,668
to doing visibility on our frustums, right?

517
00:26:34,708 --> 00:26:35,568
Like, it's fantastic.

518
00:26:35,608 --> 00:26:37,890
My view, I declare it, I run the visibility,

519
00:26:38,491 --> 00:26:39,912
be it occlusion, calling, or whatever,

520
00:26:39,932 --> 00:26:41,113
I'm really proud of myself.

521
00:26:42,174 --> 00:26:43,956
Yeah, that doesn't work anymore,

522
00:26:44,016 --> 00:26:46,238
because now the object that I'm going to be reflected

523
00:26:46,318 --> 00:26:48,540
may be outside of my visibility,

524
00:26:49,180 --> 00:26:51,442
and that visibility is actually not accurate

525
00:26:51,482 --> 00:26:52,963
for the particular...

526
00:26:53,824 --> 00:26:58,447
situation. So that actually brings some of the complexity and we need to think about

527
00:26:58,507 --> 00:27:04,932
essentially using a cluster of volume around the camera for calling. What we also need

528
00:27:04,952 --> 00:27:08,775
to think about is store the data in the voxel around that camera because we need to bring

529
00:27:08,795 --> 00:27:13,558
the lighting data, the reflection probes, the planar reflections, decals, all of the

530
00:27:13,618 --> 00:27:18,441
payloads that we typically associate with a given view into the new structure because

531
00:27:18,481 --> 00:27:21,063
our visibility representation and results of that change.

532
00:27:22,639 --> 00:27:27,126
And in terms of lighting, we also have to consider the same thing, right?

533
00:27:27,166 --> 00:27:31,332
Like when we're computing reflection, we need to compute the lighting of the reflected object,

534
00:27:31,713 --> 00:27:33,917
which means we need to account for the light that's outside.

535
00:27:34,878 --> 00:27:35,219
And so.

536
00:27:36,896 --> 00:27:42,039
We need to ensure that we also evaluate the same identical light loop, and I'll touch on that in a second,

537
00:27:43,680 --> 00:27:47,982
regardless of whether we're doing the primary, this is our material lighting evaluation,

538
00:27:48,362 --> 00:27:52,224
or we're doing secondary, this is our reflection accumulation, for example.

539
00:27:53,079 --> 00:27:56,282
And so for indirect specular, what do we do?

540
00:27:56,702 --> 00:27:58,724
For every bounce, we evaluate lighting

541
00:27:58,844 --> 00:28:02,488
and we reuse the same code as the actual regular light loop,

542
00:28:03,028 --> 00:28:04,730
except for reflection hierarchy.

543
00:28:05,270 --> 00:28:07,912
Now, ideally, depending on LOD,

544
00:28:07,932 --> 00:28:10,295
you actually may want to use a simplified material

545
00:28:10,335 --> 00:28:13,477
for reflection for improved performance

546
00:28:13,497 --> 00:28:15,599
because evaluating the full stack of the material

547
00:28:15,639 --> 00:28:17,501
for multiple bounce can get really costly.

548
00:28:18,342 --> 00:28:21,305
Or you also may need to account for reflecting complex materials.

549
00:28:21,345 --> 00:28:23,347
So an isotropy subsurface scattering.

550
00:28:24,248 --> 00:28:29,693
This is the light loop evaluation from HDRP that we use in rasterization.

551
00:28:29,773 --> 00:28:32,095
And so we start from the sun kind of like top down.

552
00:28:34,392 --> 00:28:36,454
We evaluate all directional lights at the top,

553
00:28:36,894 --> 00:28:38,615
then we evaluate all the punctual lights,

554
00:28:38,675 --> 00:28:40,936
spotlight, point light, and all of the area lights,

555
00:28:40,956 --> 00:28:42,037
so lamps and so forth.

556
00:28:42,557 --> 00:28:46,500
We add sunlight, sky cloud, the reflection probes,

557
00:28:46,580 --> 00:28:50,082
AGRI, and then we finalize the sky evaluation.

558
00:28:50,843 --> 00:28:53,865
We do a very similar evaluation in ray tracing.

559
00:28:54,405 --> 00:28:56,046
The only thing that's different is now

560
00:28:56,106 --> 00:28:57,667
we'll replace the reflection probe

561
00:28:57,687 --> 00:28:59,388
with the actual ray traced reflections.

562
00:29:00,069 --> 00:29:01,569
And so if I kind of go back and forth,

563
00:29:01,589 --> 00:29:04,291
you can see that that sphere disappeared.

564
00:29:05,071 --> 00:29:06,352
And for performance reasons,

565
00:29:06,412 --> 00:29:08,773
we actually evaluate sky in the same manner

566
00:29:08,813 --> 00:29:10,674
as we do with rasterization,

567
00:29:11,174 --> 00:29:13,155
by using pre-integrated cube maps.

568
00:29:13,836 --> 00:29:15,456
So this is pre-integrated HDRI,

569
00:29:15,477 --> 00:29:15,877
and there's some.

570
00:29:17,197 --> 00:29:18,258
snags on that one.

571
00:29:18,758 --> 00:29:21,781
For game-oriented ray tracing scenarios,

572
00:29:22,121 --> 00:29:25,084
when we render out the full frame pass tracer,

573
00:29:25,124 --> 00:29:28,747
we'd actually do the proper computation of the HDRI

574
00:29:28,847 --> 00:29:31,289
in order to do this in a much more accurate manner.

575
00:29:33,461 --> 00:29:36,743
So, as I touched on that, we need to worry about visibility

576
00:29:36,823 --> 00:29:38,124
with regards to ray tracing.

577
00:29:38,204 --> 00:29:40,585
So, primary ray, we're still good.

578
00:29:40,626 --> 00:29:43,127
We're still in the view frustum, so visibility is good there.

579
00:29:43,627 --> 00:29:45,909
Secondary and beyond, we really are in a free fall.

580
00:29:45,969 --> 00:29:47,950
Like, this is where we start getting

581
00:29:47,990 --> 00:29:50,031
into production-specific solutions, right?

582
00:29:50,091 --> 00:29:53,273
Camera orientation, because your cost will basically,

583
00:29:53,313 --> 00:29:55,875
will vary both with regards of how big

584
00:29:55,895 --> 00:29:57,616
your acceleration structure needs to be

585
00:29:58,257 --> 00:30:00,218
and how long it's going to take to traverse it.

586
00:30:02,049 --> 00:30:04,171
And we need to account this on the engine front.

587
00:30:04,912 --> 00:30:07,455
With ray tracing, it's in global space,

588
00:30:07,475 --> 00:30:09,317
so we define a region around the camera.

589
00:30:11,059 --> 00:30:13,782
And evaluate the lighting environment globally

590
00:30:13,822 --> 00:30:15,644
for all of the elements that are outside.

591
00:30:17,344 --> 00:30:21,589
So we've talked about the fact that you actually have to change the low level architecture on that front.

592
00:30:21,649 --> 00:30:25,154
And there's some flexibility that you need to think about how you're going to structure again.

593
00:30:25,194 --> 00:30:30,300
That can be an artist specific effect or it can be a level of detail controlled.

594
00:30:30,360 --> 00:30:33,164
Right. Like it because depending on the complexity of the situation.

595
00:30:33,604 --> 00:30:37,908
you may want to scale down the region where you're going to be evaluating your global effects

596
00:30:38,828 --> 00:30:40,570
as it all affects the performance.

597
00:30:40,590 --> 00:30:44,052
And this is the rough outline of what you would actually need to be considering

598
00:30:44,613 --> 00:30:48,836
when you're building the Voxel around your camera with all of the payloads.

599
00:30:50,365 --> 00:30:54,751
So this is an example of evaluating the lights representation.

600
00:30:54,791 --> 00:30:57,695
It's basically accumulation of lights hitting a particular area.

601
00:30:59,217 --> 00:31:05,926
And in terms of parallel to the rasterization, this is kind of like we have the probe as the same parallel concept.

602
00:31:07,965 --> 00:31:10,067
Interesting bit about decals with ray tracing,

603
00:31:10,107 --> 00:31:13,529
because we're again, we're doing a production focused system

604
00:31:13,629 --> 00:31:15,670
and while artists love using decals,

605
00:31:15,710 --> 00:31:18,612
they allow them a really quick and customization

606
00:31:18,672 --> 00:31:20,293
to material properties of the surface.

607
00:31:20,934 --> 00:31:23,315
And decals is a really interesting case for reflections.

608
00:31:24,876 --> 00:31:26,858
How do we enable the contribution of decals

609
00:31:26,898 --> 00:31:27,858
in the correct manner?

610
00:31:28,579 --> 00:31:30,940
When do we determine, are they visible,

611
00:31:30,980 --> 00:31:32,842
are they not visible, do they still reflect?

612
00:31:33,322 --> 00:31:35,283
And how would they actually work with ray tracing?

613
00:31:36,490 --> 00:31:39,172
So what we did with rasterization,

614
00:31:39,232 --> 00:31:43,514
so if you look at Sebastian's SIGGRAPH 2018 presentation

615
00:31:43,534 --> 00:31:45,135
from last year's advances course,

616
00:31:45,735 --> 00:31:47,976
he defines that we basically maintain a frock cell

617
00:31:48,016 --> 00:31:50,878
around the camera where we keep the payload for decals.

618
00:31:51,478 --> 00:31:54,160
And so we can kind of think of the thing that we kept

619
00:31:54,220 --> 00:31:55,721
in the froxel for rasterization

620
00:31:56,221 --> 00:31:59,923
becomes the voxel representation for ray tracing world.

621
00:32:00,664 --> 00:32:03,606
In the rasterization world, we store our decals

622
00:32:03,706 --> 00:32:06,988
in a spatial structure around the froxel.

623
00:32:07,668 --> 00:32:10,070
Now, in ray tracing, we now put it

624
00:32:10,150 --> 00:32:12,852
in that camera aligned voxel.

625
00:32:13,412 --> 00:32:15,293
It's still used for partitioning, right?

626
00:32:15,313 --> 00:32:17,535
So we still can do cluster decal implementation

627
00:32:17,595 --> 00:32:19,136
for acceleration.

628
00:32:19,856 --> 00:32:21,578
But it's not centered around the camera,

629
00:32:21,638 --> 00:32:23,140
it's a spatial representation.

630
00:32:24,521 --> 00:32:27,244
And that essentially allows us to then find

631
00:32:27,264 --> 00:32:29,466
the appropriate decal, and now we need to think about

632
00:32:29,506 --> 00:32:30,528
how to evaluate it.

633
00:32:30,868 --> 00:32:32,650
And of course, artists evaluate properties

634
00:32:32,690 --> 00:32:33,591
from the shader graph.

635
00:32:34,708 --> 00:32:39,230
In HDRP, we apply decals if they're opaque

636
00:32:39,450 --> 00:32:41,912
by just rendering them as the debuffer decals.

637
00:32:42,852 --> 00:32:45,754
And for transparent decals, we do cluster approach.

638
00:32:46,534 --> 00:32:49,516
This actually modifies the appearance of the objects

639
00:32:49,556 --> 00:32:52,938
directly in the Gbuffer for deferred or opaqued.

640
00:32:53,518 --> 00:32:55,759
And alternatively, of course, in our forward pass,

641
00:32:55,819 --> 00:32:59,381
it will modify it as part of the shader evaluation.

642
00:33:00,662 --> 00:33:03,923
With ray tracing, we basically can follow the same route.

643
00:33:05,408 --> 00:33:07,830
Everything goes through the cluster decals and ray tracing,

644
00:33:07,890 --> 00:33:09,912
so the debuffer decals are gone.

645
00:33:10,733 --> 00:33:12,535
We evaluate the material properties,

646
00:33:12,595 --> 00:33:14,737
again, evoking the shader graph functions.

647
00:33:15,158 --> 00:33:17,960
We applied the resulting decal to the material

648
00:33:18,040 --> 00:33:21,003
by modifying it, store it in a similar manner,

649
00:33:21,464 --> 00:33:22,745
and then evaluate the light loop

650
00:33:22,765 --> 00:33:24,667
to make sure that we're computing the proper lighting.

651
00:33:25,508 --> 00:33:27,490
Again, the only changes were operating on Voxel.

652
00:33:28,290 --> 00:33:33,192
The only tricky thing is we cannot support extrusion decals in this route, and it's not

653
00:33:33,232 --> 00:33:37,834
even clear what do you do with regards to acceleration structure intersections in the

654
00:33:37,874 --> 00:33:43,056
ray tracing. So this is something that we need to be mindful when building content that's designed

655
00:33:43,096 --> 00:33:49,699
for ray tracing and rasterization because they're not interchangeable. The other thing that we want

656
00:33:49,739 --> 00:33:55,301
to think about is anisotropy, right? And in general, just thinking about reflection with different BRDFs.

657
00:33:57,329 --> 00:34:02,035
So at each intersection, we need to consider in the reflection

658
00:34:02,075 --> 00:34:05,619
paths, the direction of the ray needs to account for,

659
00:34:07,341 --> 00:34:09,863
needs to be actually be driven by important sampling.

660
00:34:10,224 --> 00:34:11,786
And the reason we want to do this again

661
00:34:11,846 --> 00:34:13,087
is to reduce the variance.

662
00:34:13,768 --> 00:34:15,990
So we have to make sure that it follows

663
00:34:16,031 --> 00:34:17,352
the distribution of material.

664
00:34:18,173 --> 00:34:20,355
Now, this is an example of an isotropic, right?

665
00:34:20,375 --> 00:34:23,157
And you see its reflection in the subsequent object.

666
00:34:24,338 --> 00:34:28,501
And we need to know the actual BRDF of the material

667
00:34:29,602 --> 00:34:31,723
in order to create the distribution direction.

668
00:34:32,284 --> 00:34:34,085
Thus, we need to know the material properties.

669
00:34:34,626 --> 00:34:36,927
And the same time, if we want to know the BRDF,

670
00:34:37,007 --> 00:34:38,428
well, that means two things.

671
00:34:38,789 --> 00:34:41,030
In a fun bit of current API design,

672
00:34:41,411 --> 00:34:43,292
you either need to have some sort of uber shader

673
00:34:43,332 --> 00:34:45,054
because, well, we don't have subroutines,

674
00:34:45,894 --> 00:34:50,356
Or we need to figure out some alternative way to get at the material information for

675
00:34:50,396 --> 00:34:51,437
the underlying system.

676
00:34:51,797 --> 00:34:57,179
And like I mentioned, we did store a lot of the material IDs in gbuffer, so congratulations

677
00:34:57,219 --> 00:34:57,659
to us.

678
00:34:58,260 --> 00:35:01,021
But forward materials, we don't really have a way to classify.

679
00:35:01,061 --> 00:35:04,242
This is an example of a lot of the, you know, fabric, hair, and so forth.

680
00:35:05,403 --> 00:35:11,884
So what we do is we important sample with an approximation of the BRDF by using GGX.

681
00:35:11,924 --> 00:35:15,905
And this is the example here that actually gets you pretty far.

682
00:35:15,945 --> 00:35:23,366
You can represent a reasonable approximation of an isotropy because we're really only picking the sampling direction.

683
00:35:23,466 --> 00:35:26,247
Right. And it's a reasonable approximation of the NDF.

684
00:35:27,707 --> 00:35:32,028
However, with clear coat, we need to account for it by using roughness in the clear.

685
00:35:32,068 --> 00:35:33,308
And this is the example here.

686
00:35:34,624 --> 00:35:37,346
And so this is the result kind of of the clear code

687
00:35:37,386 --> 00:35:38,187
and its reflection.

688
00:35:38,847 --> 00:35:40,449
And similarly for specular color.

689
00:35:43,471 --> 00:35:47,814
So we need to ensure that we're evaluating the light loop

690
00:35:47,834 --> 00:35:49,276
like we were saying for the specular.

691
00:35:49,456 --> 00:35:51,377
And what we do is during the trace ray,

692
00:35:51,437 --> 00:35:53,979
we evaluate the material, we apply our decal,

693
00:35:54,420 --> 00:35:56,041
you know, as we were discussing.

694
00:35:56,541 --> 00:35:58,943
And then we do the full light loop for the decal as well

695
00:35:58,983 --> 00:36:02,906
in order to get the accurate quality of the final lighting

696
00:36:02,946 --> 00:36:04,027
for that particular object.

697
00:36:05,309 --> 00:36:08,616
And what this means is allows us to have the surface shader

698
00:36:08,756 --> 00:36:12,824
at the appropriate point for faster performance.

699
00:36:13,505 --> 00:36:15,990
And you'll have all of this stuff for reference later on.

700
00:36:17,203 --> 00:36:19,825
Now, you have to be careful about another aspect,

701
00:36:19,925 --> 00:36:23,549
which comes along with real production-centric worlds.

702
00:36:23,569 --> 00:36:25,811
You need to mind your cascade shadows.

703
00:36:26,231 --> 00:36:28,353
Because remember that we're not gonna evaluate everything

704
00:36:28,393 --> 00:36:30,214
in the infinite distance, well, we can't afford it.

705
00:36:30,595 --> 00:36:32,016
So if you have a giant view,

706
00:36:32,216 --> 00:36:34,178
you might still wanna rely on cascade shadows.

707
00:36:34,979 --> 00:36:37,681
And they will encompass a region around the camera.

708
00:36:37,761 --> 00:36:39,863
And so now you have to deal with the merge

709
00:36:39,903 --> 00:36:41,665
of the cascade shadows around your camera.

710
00:36:42,025 --> 00:36:46,349
and your glorious perfect ray trace shadows.

711
00:36:46,929 --> 00:36:49,051
With cascade shadows, a view dependent,

712
00:36:49,431 --> 00:36:52,214
and so if you reflect outside the boundary of cascades,

713
00:36:52,254 --> 00:36:54,576
you actually won't even be picking up the right shadows

714
00:36:55,196 --> 00:36:58,199
from that super giant object that is coming in outside.

715
00:36:58,219 --> 00:37:01,161
And so you really need to be kind of

716
00:37:01,662 --> 00:37:02,702
paying attention to that.

717
00:37:04,544 --> 00:37:07,687
So what also happens if you have a metallic object

718
00:37:07,727 --> 00:37:09,008
inside a room full of mirrors?

719
00:37:10,647 --> 00:37:12,989
Multiple bounds are very expensive to evaluate,

720
00:37:13,109 --> 00:37:15,491
and how do you account for more than second bounds

721
00:37:15,511 --> 00:37:16,452
in the performant way?

722
00:37:17,513 --> 00:37:20,395
In our case, we ensure that you,

723
00:37:20,455 --> 00:37:22,937
obviously if you have something like a reflection of a knob

724
00:37:23,838 --> 00:37:26,220
that needs to reflect another metallic object,

725
00:37:26,640 --> 00:37:28,161
you'll want to blend multiple times.

726
00:37:28,662 --> 00:37:31,444
In general, we want to evaluate a reflection for one bounce

727
00:37:31,484 --> 00:37:33,226
because of the cost of the reflection shader.

728
00:37:34,006 --> 00:37:37,749
But in some cases, we can actually think about falling back to rasterization.

729
00:37:38,169 --> 00:37:39,851
And how did we approach in rasterization?

730
00:37:40,471 --> 00:37:43,814
For metallic object, we can use specular term as diffuse, right?

731
00:37:43,834 --> 00:37:49,378
So we basically use Fresnel zero in our implementation as essentially diffuse for metal objects.

732
00:37:49,738 --> 00:37:52,720
For second bounces, we fall back to Fresnel zero, right?

733
00:37:53,161 --> 00:37:56,363
Which gives you the sort of the color of the object.

734
00:37:57,124 --> 00:38:01,408
And if you don't do that, you actually will over darken the object, it gives you the black.

735
00:38:01,468 --> 00:38:06,974
And this is the example, maybe hard to see, but that knob that you see on the panel actually

736
00:38:07,014 --> 00:38:13,721
is the example of bringing in that tint for the metallic object to blend appropriate darkening.

737
00:38:15,440 --> 00:38:18,262
So as we mentioned, reflection is a very expensive path.

738
00:38:18,422 --> 00:38:20,764
We need to optimize it.

739
00:38:21,185 --> 00:38:23,426
So we default to using quarter resolution for speed.

740
00:38:23,767 --> 00:38:26,509
This is very similar to what EAC has done.

741
00:38:27,089 --> 00:38:29,171
And what we do is we select one of the four samples

742
00:38:29,231 --> 00:38:31,133
per frame, evaluate the lighting,

743
00:38:31,253 --> 00:38:33,995
store the resulting index, sample direction,

744
00:38:34,115 --> 00:38:35,917
do the probability distribution function,

745
00:38:36,317 --> 00:38:39,260
and then I'm sampled with all of the BRDF information

746
00:38:39,280 --> 00:38:39,880
for filtering.

747
00:38:40,240 --> 00:38:42,222
So this is accounting for variance, roughness,

748
00:38:42,723 --> 00:38:43,283
and so forth.

749
00:38:43,944 --> 00:38:46,785
Then it follows the same temporal accumulation

750
00:38:46,825 --> 00:38:48,966
and bilateral disjoint based on the radius

751
00:38:48,986 --> 00:38:50,407
of the filter that we specified.

752
00:38:51,628 --> 00:38:54,689
And so here is the example of roughness, normal.

753
00:38:55,470 --> 00:38:57,471
We use the full resolution results

754
00:38:57,491 --> 00:38:58,812
and I'll do a little back and forth

755
00:38:59,792 --> 00:39:02,053
so you can kind of see what happens with quarter res.

756
00:39:02,393 --> 00:39:04,655
In reality, if you're moving reasonably fast,

757
00:39:05,435 --> 00:39:06,376
it's not too bad.

758
00:39:06,876 --> 00:39:07,996
And performance is pretty good

759
00:39:08,537 --> 00:39:10,338
in terms of gaining the benefits for that.

760
00:39:11,522 --> 00:39:14,024
Okay, great, done with indirect specular.

761
00:39:14,064 --> 00:39:15,145
Let's talk about shadows.

762
00:39:16,746 --> 00:39:18,968
Rasterization, of course, is a really well-known

763
00:39:19,008 --> 00:39:20,108
and fast approach for it.

764
00:39:20,148 --> 00:39:24,492
When we evaluate shadows, we just do a simple shadow map.

765
00:39:25,293 --> 00:39:27,054
With ray trace, we actually can do

766
00:39:27,334 --> 00:39:28,895
a lot of these approaches as well.

767
00:39:29,496 --> 00:39:32,578
And evaluate rasterized shadow maps during reflections,

768
00:39:32,718 --> 00:39:34,680
because that's faster, it's an optimization

769
00:39:34,700 --> 00:39:35,781
for that particular pass.

770
00:39:36,261 --> 00:39:38,603
Because you may not need the actual precise,

771
00:39:39,063 --> 00:39:40,485
glorious ray trace shadows.

772
00:39:40,945 --> 00:39:42,648
The recursion can murder your performance.

773
00:39:43,168 --> 00:39:44,950
So for shadows, we have the full screen buffer

774
00:39:44,990 --> 00:39:46,673
for the shadow if you want high resolution.

775
00:39:47,333 --> 00:39:48,755
Or if your light is very soft,

776
00:39:48,795 --> 00:39:50,257
you actually can get away with less.

777
00:39:51,018 --> 00:39:52,760
And that's kind of like experiment

778
00:39:52,780 --> 00:39:54,462
based on your particular production screen.

779
00:39:54,963 --> 00:39:56,885
It is required to be full screen

780
00:39:56,906 --> 00:39:59,068
for area lights and for sunlight.

781
00:40:01,600 --> 00:40:04,162
We use ray-trained screen space shadow map for sun.

782
00:40:04,282 --> 00:40:05,563
This is the disk light.

783
00:40:06,124 --> 00:40:08,646
And note that this, again, breaks for transparence

784
00:40:08,906 --> 00:40:10,487
because if you go through the transparency,

785
00:40:10,507 --> 00:40:12,409
you need to handle the opacity correctly.

786
00:40:12,849 --> 00:40:14,730
The object is tinted in the color shader,

787
00:40:15,151 --> 00:40:17,632
which is, of course, expensive to evaluate in that pass.

788
00:40:18,373 --> 00:40:20,655
And in general, I mean, it's extremely expensive

789
00:40:20,675 --> 00:40:24,037
to evaluate to begin with if you consider, again,

790
00:40:24,137 --> 00:40:25,218
the rough refraction.

791
00:40:25,238 --> 00:40:27,820
So even in offline, it's not really to support it.

792
00:40:28,933 --> 00:40:33,724
And for reflection, we use a combination of screen space shadow maps, so that's the sun

793
00:40:33,784 --> 00:40:37,894
area lights, as well as shadow map for punctuals and area lights.

794
00:40:39,967 --> 00:40:41,847
Next, area light shadows.

795
00:40:42,287 --> 00:40:45,728
Of course, they're quite intensive to evaluate.

796
00:40:46,188 --> 00:40:48,389
We can switch between rasterized implementation

797
00:40:48,429 --> 00:40:50,670
of area lights or between ray trace per light.

798
00:40:51,010 --> 00:40:52,510
We also can do this dynamically,

799
00:40:52,530 --> 00:40:54,631
so we allow a lot of control based on LOD

800
00:40:54,751 --> 00:40:56,951
or based on artist preference.

801
00:40:57,011 --> 00:40:58,792
In future, we'll also experiment

802
00:40:58,832 --> 00:41:00,512
with importance-driven techniques

803
00:41:00,552 --> 00:41:02,553
to kind of see if we can do this

804
00:41:02,593 --> 00:41:03,713
in a more automatic manner.

805
00:41:05,074 --> 00:41:12,437
When selecting rasterization, we use Eric Heitz's linear transform cosine approach plus exponential shadow maps for area lights.

806
00:41:13,457 --> 00:41:20,180
And you want to make sure that you use a combination like I've described before to combine it in a safe manner.

807
00:41:22,383 --> 00:41:25,367
So ray traced aerial lights are actually correct.

808
00:41:25,788 --> 00:41:26,990
It's the glorious ground truth.

809
00:41:27,531 --> 00:41:29,153
But quite expensive, because you need

810
00:41:29,173 --> 00:41:32,097
to launch a lot of rays to cover the area, especially

811
00:41:32,137 --> 00:41:33,479
for those giant aerial lights.

812
00:41:33,940 --> 00:41:36,544
In the video, you probably saw this enormous textured screen,

813
00:41:36,584 --> 00:41:38,587
which is one enormous aerial light.

814
00:41:39,167 --> 00:41:40,449
And so as an optimization,

815
00:41:40,489 --> 00:41:42,672
we can evaluate visibility independently,

816
00:41:42,832 --> 00:41:44,114
which is essentially a shadow map,

817
00:41:44,955 --> 00:41:46,237
separately from direct lighting.

818
00:41:46,638 --> 00:41:47,259
And what we do,

819
00:41:47,539 --> 00:41:49,782
it's a very similar principle to rasterization.

820
00:41:50,503 --> 00:41:52,145
We render visibility to shadow map

821
00:41:52,286 --> 00:41:54,048
using exponential shadow maps,

822
00:41:54,569 --> 00:41:55,450
and then apply lighting.

823
00:41:56,682 --> 00:42:01,425
And of course, the regular shadow maps are incorrect in this case because they're not

824
00:42:01,445 --> 00:42:03,326
accounting for BRDF for the material.

825
00:42:03,947 --> 00:42:09,290
But again, you're thinking about performance and limitation, so it is a reasonable compromise.

826
00:42:12,532 --> 00:42:15,134
In our case, we fall back to the approach described

827
00:42:15,354 --> 00:42:18,756
in Eric Heitz's, well, Morgan, Eric,

828
00:42:18,836 --> 00:42:22,158
and Stephen Hill's presentation from last year's SIGGRAPH,

829
00:42:22,759 --> 00:42:24,380
which allows for better representation

830
00:42:24,440 --> 00:42:26,541
for separate visibility that actually takes

831
00:42:26,581 --> 00:42:28,902
into account material, and is a great reference

832
00:42:28,942 --> 00:42:30,263
with a lot of code and detail.

833
00:42:30,844 --> 00:42:34,106
And then, as I mentioned, we value Derek Lighting with LTC.

834
00:42:35,449 --> 00:42:40,733
So this is the example of a naive implementation for computing area light shadow without the

835
00:42:40,773 --> 00:42:45,258
approach LTC approach that we've just mentioned. And notice that it's you know it's not really

836
00:42:45,298 --> 00:42:49,321
representative of the complexity of the vehicle. I'll go back and forth between the

837
00:42:49,922 --> 00:42:54,946
approach from Eric's LTC implementation. Pretty close to ground truth so that

838
00:42:54,986 --> 00:42:58,470
complexity and evaluation actually really matters in regards to quality.

839
00:43:00,877 --> 00:43:02,459
For textural area light shadow,

840
00:43:02,479 --> 00:43:04,660
we require a full screen space buffer.

841
00:43:05,081 --> 00:43:06,542
We pack it for efficiency.

842
00:43:06,982 --> 00:43:09,344
Now, we actually need to have access

843
00:43:09,364 --> 00:43:12,166
to full material properties in order to evaluate BRDF.

844
00:43:12,887 --> 00:43:16,630
So in our case, we restricted to the G-buffer renderer.

845
00:43:17,711 --> 00:43:20,113
We approximate the standard materials for performance,

846
00:43:20,133 --> 00:43:21,994
so of course, you know, all of the special effects

847
00:43:22,034 --> 00:43:25,337
of anisotropy, et cetera, fell out,

848
00:43:25,377 --> 00:43:28,500
but it's okay for the current, for performance reason.

849
00:43:29,319 --> 00:43:32,484
and essentially along with a direct light evaluation.

850
00:43:34,687 --> 00:43:38,993
So what we do, we need to then look at optimization for area light shadows.

851
00:43:39,875 --> 00:43:42,218
We launch rate and evaluate every samples.

852
00:43:43,182 --> 00:43:47,988
So the shadow that we're doing is denoised, so we can't actually approximate the BRDF.

853
00:43:48,648 --> 00:43:53,254
And like I said, if we choose the standard material, we end up with a fairly reasonable

854
00:43:53,274 --> 00:43:58,881
approximation that gives a good quality without sacrifice to the final shadow experience.

855
00:44:00,903 --> 00:44:03,824
How we pack this texture is we use an RGBA FP16

856
00:44:03,864 --> 00:44:07,626
screen space buffer, and we packed three components.

857
00:44:07,826 --> 00:44:09,126
Essentially, the first component,

858
00:44:09,146 --> 00:44:11,067
and this is described in more depth

859
00:44:11,167 --> 00:44:12,907
in Eric's representation,

860
00:44:13,788 --> 00:44:16,068
we packed the luminance of direct lighting.

861
00:44:16,769 --> 00:44:19,590
So we launch, in our case, a sample directly,

862
00:44:19,630 --> 00:44:22,411
not using linear transfer cosine.

863
00:44:23,091 --> 00:44:24,411
Then we combine the

864
00:44:26,553 --> 00:44:28,294
Luminance with testing visibility.

865
00:44:28,334 --> 00:44:30,134
So this essentially brings in the shadow term.

866
00:44:30,555 --> 00:44:31,775
And then the final term we packed

867
00:44:31,835 --> 00:44:33,655
is the full evaluation of LTC.

868
00:44:34,856 --> 00:44:37,497
Invite you to read the paper as it's really, really great.

869
00:44:38,317 --> 00:44:40,557
We need to for textured area lights

870
00:44:40,597 --> 00:44:42,478
in order to get good quality and stability,

871
00:44:42,518 --> 00:44:44,899
denoise each term separately.

872
00:44:45,619 --> 00:44:49,500
And so this is required in order to get stability,

873
00:44:49,520 --> 00:44:51,280
but of course it means that you have to separate

874
00:44:51,300 --> 00:44:52,801
the signal and run two passes.

875
00:44:53,901 --> 00:44:56,583
We for efficiency of implementation

876
00:44:56,983 --> 00:44:59,405
did it in a single pass in compute for performance,

877
00:44:59,865 --> 00:45:01,066
which was much better.

878
00:45:01,086 --> 00:45:06,869
And we also used the U, the combined LTC evaluation result,

879
00:45:07,430 --> 00:45:10,992
as a parameter for guiding the denoiser

880
00:45:11,112 --> 00:45:13,314
in a similar manner that we would use depth and normal

881
00:45:13,914 --> 00:45:15,795
in the other set of effects

882
00:45:16,335 --> 00:45:18,517
to be able to deal with discontinuities.

883
00:45:19,178 --> 00:45:24,735
And then we divide the luminance by the SN in order to update the final shadow result.

884
00:45:26,805 --> 00:45:30,568
Now, one of the issues with area lights, of course, is they're quite large and the samples

885
00:45:30,608 --> 00:45:32,750
can go in a wide range of directions.

886
00:45:33,391 --> 00:45:37,234
So we need to think about coherency of rays in order to obtain good performance.

887
00:45:37,655 --> 00:45:40,697
And it really is one of the biggest costs for this particular effect.

888
00:45:41,578 --> 00:45:44,461
As you can imagine, the caches get quite trashed in the process.

889
00:45:44,921 --> 00:45:50,246
So the biggest win for area light evaluation is to think about how we can improve coherency

890
00:45:50,266 --> 00:45:51,007
of evaluation.

891
00:45:51,927 --> 00:45:56,350
In our case, what we do is, well actually let's look at the naive approach, right?

892
00:45:56,710 --> 00:46:00,632
So we want to do four samples for the area light and we shoot them in basically four

893
00:46:00,652 --> 00:46:06,535
uncorrelated directions. No guarantees of coherency whatsoever. God knows what point

894
00:46:06,575 --> 00:46:10,437
in the cache you will hit. As you can imagine, it gets quite poor performance.

895
00:46:11,037 --> 00:46:14,120
The alternative is to split the evaluation into four passes,

896
00:46:14,560 --> 00:46:18,683
and each rate per pass will use an approximately similar direction,

897
00:46:19,023 --> 00:46:22,966
which allows us to get much better coherency for the execution of that pass,

898
00:46:23,887 --> 00:46:25,388
resulting in much better performance,

899
00:46:25,408 --> 00:46:28,370
despite the non-obvious fact that we're going for four passes.

900
00:46:29,229 --> 00:46:32,110
And this is actually example of the result in PIX,

901
00:46:32,891 --> 00:46:35,873
evaluated in our RTX 2080 Ti at 1080p.

902
00:46:36,253 --> 00:46:37,594
And so the shadow for area light,

903
00:46:37,614 --> 00:46:38,915
this is that giant, you know,

904
00:46:39,035 --> 00:46:40,696
two thirds of the screen area light,

905
00:46:41,156 --> 00:46:43,318
executes at about 4.8 milliseconds.

906
00:46:43,858 --> 00:46:47,600
But if we do the non-obvious four pass, you know,

907
00:46:47,660 --> 00:46:50,202
separation, you actually save almost two milliseconds,

908
00:46:50,222 --> 00:46:51,543
which is quite significant.

909
00:46:53,144 --> 00:46:54,485
Transparency and ray tracing.

910
00:46:55,125 --> 00:46:56,766
Damn transparency are always problematic.

911
00:46:57,582 --> 00:46:59,847
Not possible to do noise, no gbuffer.

912
00:47:00,809 --> 00:47:02,532
I thought it was supposed to be a glorious promise.

913
00:47:03,314 --> 00:47:05,138
We also need to render from primary array,

914
00:47:05,158 --> 00:47:06,761
so it's expensive to evaluate.

915
00:47:09,661 --> 00:47:11,982
With regards to handling them correctly,

916
00:47:12,022 --> 00:47:13,763
what we need to think about is we need to handle

917
00:47:13,823 --> 00:47:16,645
transmission and we need to handle rough refraction.

918
00:47:17,185 --> 00:47:19,626
Of course, this is expensive even in offline world.

919
00:47:20,807 --> 00:47:22,728
First thing we're thinking about is when you're hitting

920
00:47:22,768 --> 00:47:24,869
a transparent object, you need to launch a ray.

921
00:47:25,370 --> 00:47:28,551
So we need to render primary visibility with ray tracing

922
00:47:28,591 --> 00:47:30,512
because we don't have a G-buffer.

923
00:47:30,532 --> 00:47:32,193
We don't have the starting point of information.

924
00:47:32,714 --> 00:47:36,376
So the very first you've just realized is YayPath Tracer.

925
00:47:36,876 --> 00:47:37,856
And what about performance?

926
00:47:39,237 --> 00:47:41,837
When hitting that object, we need to think about

927
00:47:42,497 --> 00:47:45,718
how we're gonna manage path tracer primary evaluation

928
00:47:46,138 --> 00:47:47,938
versus rasterization, because we also said

929
00:47:47,978 --> 00:47:49,179
we don't wanna do primary array

930
00:47:49,579 --> 00:47:50,999
for all of the opaque objects, right?

931
00:47:51,419 --> 00:47:53,739
So what we do is we allow essentially switching

932
00:47:53,779 --> 00:47:57,180
per object per effect of sending the primary array

933
00:47:57,400 --> 00:48:00,041
either through rasterization, so defer, gbuffer,

934
00:48:00,101 --> 00:48:02,461
whatever flavor of the day forward, et cetera,

935
00:48:03,181 --> 00:48:04,722
or send it through ray tracing.

936
00:48:06,273 --> 00:48:09,374
And so here is the example of a scene

937
00:48:09,394 --> 00:48:10,475
where that's actually really needed

938
00:48:10,495 --> 00:48:12,636
because you'll see a lot of complex transparency

939
00:48:12,656 --> 00:48:14,296
happening on the gear shift.

940
00:48:14,676 --> 00:48:17,697
Primary ray objects are rendered in a depth prepass.

941
00:48:18,497 --> 00:48:21,858
We output a mask for every element of the transparent object

942
00:48:21,899 --> 00:48:23,779
that we use in order to discard rays

943
00:48:23,819 --> 00:48:27,240
that shouldn't be actually used for primary ray rendering.

944
00:48:27,260 --> 00:48:28,821
This is our optimization, right?

945
00:48:29,781 --> 00:48:35,266
And furthermore, we also provide a parameter for primary visibility rate to the artist

946
00:48:35,767 --> 00:48:37,148
to control max recursion.

947
00:48:37,709 --> 00:48:39,711
And this is related to the refraction effects.

948
00:48:40,411 --> 00:48:44,655
And what we do then is we launch rays and screen space from near plane in the direction

949
00:48:44,695 --> 00:48:47,438
of the far plane, right, like for the visibility computation.

950
00:48:48,379 --> 00:48:51,820
And so illustrating kind of like the approach for max depth,

951
00:48:52,481 --> 00:48:54,822
what we do is we retrieve the index of refraction

952
00:48:55,042 --> 00:48:56,703
and calculate the refraction vector.

953
00:48:57,243 --> 00:48:59,804
We calculate the refraction, we launch ray,

954
00:48:59,864 --> 00:49:03,486
store the results of that refraction, continue onward,

955
00:49:03,786 --> 00:49:05,987
calculate the reflection, launch ray,

956
00:49:06,027 --> 00:49:07,848
store the results of that reflection,

957
00:49:08,369 --> 00:49:10,470
and in each point we evaluate light loops,

958
00:49:10,490 --> 00:49:13,151
so reflection value, refraction value, and so forth,

959
00:49:13,631 --> 00:49:15,952
and then we accumulate the final result and return.

960
00:49:16,873 --> 00:49:21,798
And the light loop has to take all of this into account, the results of reflection, so

961
00:49:21,918 --> 00:49:26,842
every ray that I've sent through, results of the two refracted passes, until we essentially

962
00:49:27,163 --> 00:49:28,204
reach the max depth.

963
00:49:29,185 --> 00:49:30,446
So quite a lot of complexity.

964
00:49:30,466 --> 00:49:33,789
So these, of course, you know, should be used with wisdom and sense.

965
00:49:33,809 --> 00:49:35,090
So

966
00:49:37,620 --> 00:49:39,500
That is actually what allows us to support

967
00:49:39,560 --> 00:49:41,220
multiple reflection and refraction

968
00:49:41,260 --> 00:49:42,501
for transparent objects.

969
00:49:43,241 --> 00:49:46,241
As I've mentioned, we only support smooth refraction

970
00:49:46,261 --> 00:49:47,822
and infraction, that whole scattering

971
00:49:47,862 --> 00:49:50,702
of the rough refraction, good, next year's GDC.

972
00:49:51,903 --> 00:49:55,263
Quite expensive, and there is a really good analysis

973
00:49:55,303 --> 00:49:57,604
from Colin's presentation on the subject

974
00:49:57,624 --> 00:50:02,465
from last year's SIGGRAPH intro to ray tracing course.

975
00:50:03,957 --> 00:50:07,578
So here's an example of, I think, nine level passes.

976
00:50:08,339 --> 00:50:10,160
So we're kind of going through multiple bounds

977
00:50:10,200 --> 00:50:15,362
as accumulating result for the final refracted and reflected.

978
00:50:15,862 --> 00:50:17,323
Now, note that this doesn't support

979
00:50:17,363 --> 00:50:19,104
total internal reflection.

980
00:50:20,465 --> 00:50:24,146
On Fresnel, so when we evaluate light loop,

981
00:50:24,166 --> 00:50:25,787
we actually fall back to a lot

982
00:50:25,807 --> 00:50:27,368
of the rasterization evaluation.

983
00:50:27,408 --> 00:50:28,769
So we evaluate Schlicht-Fresnel.

984
00:50:29,689 --> 00:50:32,230
And Fresnel is evaluated at every bounce pass.

985
00:50:34,500 --> 00:50:37,043
The reason this doesn't account for total internal

986
00:50:37,103 --> 00:50:38,244
reflection is because, well,

987
00:50:38,284 --> 00:50:40,386
Schlick-Fresnel is just an approximation.

988
00:50:40,787 --> 00:50:43,690
And it's only really good when IR is between 1.4 and 1.7.

989
00:50:44,831 --> 00:50:47,073
So, you know, quite limited in its representation.

990
00:50:47,794 --> 00:50:50,036
True Fresnel is something that we use for the full,

991
00:50:50,176 --> 00:50:52,959
you know, expensive, glorious frame path tracer.

992
00:50:53,459 --> 00:50:57,103
But for our pipeline with a more game-oriented

993
00:50:57,664 --> 00:50:58,645
rendering for the live.

994
00:50:59,185 --> 00:51:01,206
we actually can't represent it in the PBR.

995
00:51:01,246 --> 00:51:04,408
So we pre-integrate the cubemap,

996
00:51:04,488 --> 00:51:06,770
based on the fact, you remember the HDRI cubemap

997
00:51:06,790 --> 00:51:08,271
that I mentioned in the light evaluation,

998
00:51:08,291 --> 00:51:10,812
we pre-integrated based on the fact that it's slick.

999
00:51:11,393 --> 00:51:13,314
And that's the reason I mentioned earlier

1000
00:51:13,374 --> 00:51:16,276
that if we're doing the full path tracer,

1001
00:51:16,776 --> 00:51:18,497
we need to do proper evaluation

1002
00:51:18,557 --> 00:51:20,078
because that's where we need to actually

1003
00:51:20,118 --> 00:51:21,079
go back to the Fresnel.

1004
00:51:22,019 --> 00:51:24,240
in order to handle the total internal reflection.

1005
00:51:24,780 --> 00:51:26,921
Of course, that will come with significantly

1006
00:51:26,961 --> 00:51:30,122
more performance cost, and when quality

1007
00:51:30,202 --> 00:51:32,082
is more important than performance, fantastic.

1008
00:51:32,482 --> 00:51:34,183
Go wild, use the true Fresnel.

1009
00:51:34,903 --> 00:51:36,964
And when you're in a more performant route

1010
00:51:37,044 --> 00:51:38,344
and you really need to think about

1011
00:51:39,205 --> 00:51:40,725
dynamic elements of the scene,

1012
00:51:41,325 --> 00:51:43,866
we actually, one of the benefits is we get performance,

1013
00:51:43,886 --> 00:51:45,587
but the other benefits is you also match

1014
00:51:45,627 --> 00:51:46,627
more of the look to your...

1015
00:51:47,447 --> 00:51:49,269
evaluation from the rasterization path.

1016
00:51:49,289 --> 00:51:52,011
So one set of assets is also something that's worth thinking about.

1017
00:51:54,133 --> 00:51:59,257
So this is the example of the total internal reflection effect that, you know,

1018
00:51:59,357 --> 00:52:01,079
we're basically saying we're punting for this.

1019
00:52:03,361 --> 00:52:08,285
So in our case, you know, actually, sorry, it's a little bit repeated.

1020
00:52:09,063 --> 00:52:12,685
So we mentioned that we want to have ray tracing or rasterization.

1021
00:52:12,805 --> 00:52:17,486
What we've enabled is we allow actually switch between full ray trace,

1022
00:52:17,887 --> 00:52:22,008
so primary visibility or rasterization, either placed on camera.

1023
00:52:22,588 --> 00:52:29,070
It can be used for rendering that specific view entirely, you know, AO with ray tracing, etc.

1024
00:52:29,171 --> 00:52:33,512
Or you can actually have a view that's defaulting to SSAO, so a lot of flexibility in that regard.

1025
00:52:34,012 --> 00:52:39,874
The area light is something that's switchable back and forth based on either the object or distance.

1026
00:52:40,415 --> 00:52:45,216
And similarly, you can also mix primary ray objects, be it opaque or transparent.

1027
00:52:45,276 --> 00:52:51,038
It actually doesn't really quite matter with regular, you know, deferred and more standard pipeline objects.

1028
00:52:53,435 --> 00:52:57,977
Of course, ray tracing path, you know, for anything that you've selected is more performance

1029
00:52:58,037 --> 00:52:58,497
intensive.

1030
00:52:59,037 --> 00:53:02,838
And so you need to think about how are you going to fall back on rasterization when outside

1031
00:53:02,858 --> 00:53:03,819
the region of the camera.

1032
00:53:04,119 --> 00:53:07,820
And we talked about how we actually need to rethink about how we're approaching camera

1033
00:53:07,840 --> 00:53:08,440
and visibility.

1034
00:53:09,060 --> 00:53:14,804
What we do is we fall back to ray trace reflection in our reflection hierarchy.

1035
00:53:14,844 --> 00:53:16,285
So here's the example.

1036
00:53:16,745 --> 00:53:21,808
Basically this is your frustum view and the areas where you define rasterization fallbacks,

1037
00:53:21,848 --> 00:53:27,091
you can kind of see we fall back to SSR further away and we define the area where we're still

1038
00:53:27,111 --> 00:53:31,494
computing global reflections around kind of like proximity of the camera, again driven

1039
00:53:31,534 --> 00:53:33,115
by your quality and performance needs.

1040
00:53:33,575 --> 00:53:38,038
And then further away you start falling back to more and more and more LOD approaches for ... ... ... ... ... ... ... ...

1041
00:53:39,799 --> 00:53:43,501
SSR and similar approaches or even drop out that if you need to.

1042
00:53:46,063 --> 00:53:50,726
So when we use primary visibility ray rendering, it's very similar to opaque objects.

1043
00:53:51,527 --> 00:53:54,229
They're rendered in depth prepass output and mask, like I said.

1044
00:53:55,049 --> 00:53:59,332
If the transparent object is not registered in the acceleration structure, it actually

1045
00:53:59,873 --> 00:54:02,034
doesn't have ability to appear in our reflection.

1046
00:54:02,835 --> 00:54:06,656
And so what we do is we treat the primary visibility object

1047
00:54:06,896 --> 00:54:09,757
as an opaque object for the intents and purposes of that.

1048
00:54:10,658 --> 00:54:13,639
And what that means is the primary ray transparent

1049
00:54:13,659 --> 00:54:15,920
can see other object and you actually don't need

1050
00:54:15,940 --> 00:54:17,220
to require any compositing.

1051
00:54:18,021 --> 00:54:20,021
But that means we're back to sorting issues.

1052
00:54:21,320 --> 00:54:23,183
Because we don't intend to render, for example,

1053
00:54:23,223 --> 00:54:28,049
particles into a giant acceleration structure

1054
00:54:28,449 --> 00:54:30,592
in full glory, we're not gonna have to deal,

1055
00:54:30,632 --> 00:54:33,595
well, where is this opaque primary ray,

1056
00:54:33,615 --> 00:54:35,698
sorry, primary ray transparent object

1057
00:54:35,718 --> 00:54:37,340
with respect to everything else in the scene

1058
00:54:37,820 --> 00:54:39,603
when we're actually rendering the transparent part.

1059
00:54:41,790 --> 00:54:43,934
So there's some things that we need to think about for

1060
00:54:43,954 --> 00:54:46,418
transparency going forward in order to make sure that it's

1061
00:54:46,478 --> 00:54:47,179
really robust.

1062
00:54:47,340 --> 00:54:50,385
The next thing I wanted to hit is indirect diffuse.

1063
00:54:50,465 --> 00:54:53,270
And I realize I'm a little bit short on time, so we might go

1064
00:54:53,330 --> 00:54:54,372
through this a little faster.

1065
00:54:55,867 --> 00:55:00,330
The very simple thing that we've decided to do with indirect diffuse is replace sampling

1066
00:55:00,550 --> 00:55:06,395
of essentially pre-computed lighting illumination such as light probe or light map with either

1067
00:55:06,435 --> 00:55:12,340
a brute force approach where we do a ground truth approximation, basically do the full

1068
00:55:12,380 --> 00:55:15,082
cosine integration of the scene and denoise.

1069
00:55:16,373 --> 00:55:20,716
That allows us to compute really high quality but really expensive indirect diffuse.

1070
00:55:21,677 --> 00:55:27,361
And this is the example of light map that's been beaked and the resulted ray trace indirect diffuse,

1071
00:55:27,381 --> 00:55:28,661
which is actually fully dynamic.

1072
00:55:30,747 --> 00:55:33,148
Now the approach, you know, brute force approach

1073
00:55:33,348 --> 00:55:34,808
is very close to ground truth,

1074
00:55:34,828 --> 00:55:36,668
so it's fantastic for more expensive frames.

1075
00:55:37,088 --> 00:55:40,049
And in fact, the video of the car that I showed you

1076
00:55:40,109 --> 00:55:41,189
was using that approach.

1077
00:55:41,849 --> 00:55:44,089
But we can also look for the cheaper alternative.

1078
00:55:44,470 --> 00:55:47,630
And what we do there is we generate light probes on the fly,

1079
00:55:47,750 --> 00:55:49,550
actually in a similar manner as we do offline

1080
00:55:49,570 --> 00:55:50,731
when we bake light probes.

1081
00:55:51,251 --> 00:55:52,871
We store them in a 3D texture,

1082
00:55:52,991 --> 00:55:55,431
and this can be of course amortized over multiple frames.

1083
00:55:55,891 --> 00:55:58,352
And then we combine the resulting indirect diffuse

1084
00:55:58,432 --> 00:55:59,472
with ambient occlusion.

1085
00:56:00,452 --> 00:56:02,593
And so a light probe group, and this is the example

1086
00:56:02,613 --> 00:56:05,215
of a light probe group that's set up in a car,

1087
00:56:05,255 --> 00:56:07,376
it's super easy to set up, right?

1088
00:56:07,496 --> 00:56:09,477
And it's just used solely for the purposes

1089
00:56:09,517 --> 00:56:12,338
of rendering into that information for indirect diffuse.

1090
00:56:12,818 --> 00:56:14,719
You can also ensure to put more of them

1091
00:56:14,739 --> 00:56:16,820
in regions where you want more fidelity.

1092
00:56:17,661 --> 00:56:22,464
Now, you can use a different acceleration structure for the light probes in order to

1093
00:56:22,504 --> 00:56:23,745
have a faster computation.

1094
00:56:24,105 --> 00:56:29,088
So we actually use proxy geometry in order to speed up the indirect computation.

1095
00:56:29,448 --> 00:56:33,371
And we encode the light probes by using a stage second order coefficients.

1096
00:56:33,911 --> 00:56:37,654
It allows us to capture low frequency diffuse, so fantastic.

1097
00:56:38,034 --> 00:56:42,597
And we can get away with this, you know, proxy LOD crude geometry because it is really just,

1098
00:56:42,697 --> 00:56:44,778
you know, low frequency diffuse.

1099
00:56:46,260 --> 00:56:48,702
And in our case, we trace about 1,000 rays

1100
00:56:48,722 --> 00:56:49,623
for each light probes.

1101
00:56:50,123 --> 00:56:52,286
Each ray traverses the acceleration structure

1102
00:56:52,346 --> 00:56:55,248
that's using that generated proxy geometry.

1103
00:56:55,689 --> 00:56:57,771
And when the triangle is hit, we evaluate lighting

1104
00:56:57,811 --> 00:57:00,233
in that point and then convolve the resulting color

1105
00:57:00,273 --> 00:57:02,115
into the corresponding stage coefficients.

1106
00:57:02,916 --> 00:57:04,517
And so again, this is actually the same approach

1107
00:57:04,537 --> 00:57:07,460
that we used to generate offline beacon, just less probes

1108
00:57:07,580 --> 00:57:08,821
and slightly different geometry.

1109
00:57:09,923 --> 00:57:15,110
And we use a compute shader to resample the sage probes coefficients into the volume texture.

1110
00:57:15,971 --> 00:57:21,338
And the closest four probes for each voxel in the volume texture ends up being rendered

1111
00:57:21,358 --> 00:57:26,204
and interpolated around a particular voxel.

1112
00:57:27,120 --> 00:57:33,127
Now the final volume texture is set on an LPBE component, right, in the custom value texture,

1113
00:57:33,167 --> 00:57:36,991
and then every single object can actually sample from that particular element,

1114
00:57:37,672 --> 00:57:41,616
evaluating the SH coefficients, and then computing the final GI value.

1115
00:57:43,790 --> 00:57:49,675
So this is the example of how the SH coefficient texture looks when we go through all the layers.

1116
00:57:50,196 --> 00:57:54,840
And as you know, it consists of nine coefficients for each RGB channel, but we also can pack

1117
00:57:54,860 --> 00:58:00,506
them a little bit more efficient into the seven RGBA channels to an atlas of a 3D texture.

1118
00:58:02,555 --> 00:58:05,617
So of course there is a ton of performance consideration.

1119
00:58:05,657 --> 00:58:07,299
For the sake of time, I'm going to skip them.

1120
00:58:07,859 --> 00:58:11,382
The main thing that we want to say is around 27 probes

1121
00:58:11,422 --> 00:58:14,465
accumulation is about three millisecond on 2080 TI

1122
00:58:15,426 --> 00:58:16,026
evaluation.

1123
00:58:16,066 --> 00:58:19,449
And there's a bunch of optimizations for, you know,

1124
00:58:19,489 --> 00:58:22,011
a brute force approach of optimizing all of them.

1125
00:58:22,552 --> 00:58:22,992
However.

1126
00:58:24,425 --> 00:58:27,186
If we use essentially more SIMD evaluation

1127
00:58:27,206 --> 00:58:29,947
for compute cores, we can split the evaluation

1128
00:58:29,967 --> 00:58:32,308
of a single probe into series of samples

1129
00:58:32,908 --> 00:58:35,229
so that a single re-invocation can do a subset

1130
00:58:35,249 --> 00:58:38,370
of all of, you know, we said that 100, 1,024 samples.

1131
00:58:38,850 --> 00:58:40,771
And so we actually parallelize execution

1132
00:58:41,271 --> 00:58:42,992
within a probe for every single ray.

1133
00:58:43,592 --> 00:58:46,413
And when we do that, with the resulting parallelization,

1134
00:58:46,453 --> 00:58:48,714
we were able to cut down the GPU cost

1135
00:58:49,175 --> 00:58:52,536
to 0.5 milliseconds for about 40 probes,

1136
00:58:52,576 --> 00:58:53,856
and that's what we use in a live demo.

1137
00:58:55,306 --> 00:58:57,529
So, one node and acceleration structure.

1138
00:58:57,549 --> 00:58:59,651
I already mentioned that we're using cheaper geometry.

1139
00:59:00,192 --> 00:59:02,995
Now, there's some fun bits about the API

1140
00:59:03,356 --> 00:59:06,299
with regards to LOD, but to work around those fun bits,

1141
00:59:06,319 --> 00:59:09,043
we essentially allow an acceleration structure

1142
00:59:09,143 --> 00:59:10,104
unique per effect.

1143
00:59:10,965 --> 00:59:12,986
And so you can use it to drive

1144
00:59:13,026 --> 00:59:14,327
completely different geometry.

1145
00:59:14,347 --> 00:59:16,628
So for GI, we're using proxies.

1146
00:59:17,008 --> 00:59:18,469
For reflection, you might want to use

1147
00:59:18,509 --> 00:59:19,670
a higher fidelity pass.

1148
00:59:20,370 --> 00:59:21,991
It allows us to separate LODs.

1149
00:59:22,171 --> 00:59:24,352
It allows us to separate scene representation.

1150
00:59:25,253 --> 00:59:27,634
And we give this flexibility both on the effect

1151
00:59:27,694 --> 00:59:29,095
and on the specific.

1152
00:59:29,795 --> 00:59:32,157
I have a point to touch on for the designers

1153
00:59:32,217 --> 00:59:33,177
of the APIs on that,

1154
00:59:33,217 --> 00:59:34,898
but this is kind of a workaround on that.

1155
00:59:35,798 --> 00:59:38,699
And we also allow artists to flag objects

1156
00:59:39,279 --> 00:59:41,000
to say whether they go to a particular

1157
00:59:41,040 --> 00:59:42,420
acceleration structure or not.

1158
00:59:42,820 --> 00:59:44,560
It essentially is done with just a bit fill

1159
00:59:44,600 --> 00:59:46,801
for each ray trace effect per volume.

1160
00:59:47,601 --> 00:59:50,121
And we can have unique configurations per effect.

1161
00:59:50,701 --> 00:59:52,662
And what it does is it actually can allow us

1162
00:59:52,702 --> 00:59:54,042
to create an acceleration structure

1163
00:59:54,062 --> 00:59:55,963
that's dedicated to a particular effect.

1164
00:59:56,343 --> 00:59:57,763
What that means is, like for example,

1165
00:59:57,783 --> 01:00:01,104
for these headlights, we have a really complex effect,

1166
01:00:01,144 --> 01:00:03,064
lots of bounds and refraction and so forth.

1167
01:00:03,524 --> 01:00:07,550
So we've made an acceleration structure that only encompasses this particular headlamp

1168
01:00:08,672 --> 01:00:12,938
by again that exclusion route. And so yay, they're fantastically really high quality,

1169
01:00:12,978 --> 01:00:17,204
we can do more balances, whereas if we were to encompass the entirety of the world, well,

1170
01:00:17,565 --> 01:00:18,486
we know how that's going to end.

1171
01:00:20,244 --> 01:00:22,827
Similarly, we also support light layers,

1172
01:00:23,188 --> 01:00:25,350
which is something that our artists feel really keenly

1173
01:00:25,790 --> 01:00:28,914
fond of, for any type of light with ray tracing.

1174
01:00:29,094 --> 01:00:31,136
And it's actually the same way that we support it

1175
01:00:31,237 --> 01:00:32,758
for rasterization.

1176
01:00:33,199 --> 01:00:35,301
Same light representation means same content,

1177
01:00:35,642 --> 01:00:37,624
and then they can go to appropriate evaluation.

1178
01:00:39,149 --> 01:00:41,551
Let's keep a little bit on evaluation of light layers.

1179
01:00:42,372 --> 01:00:43,994
One important thing that we were focused on

1180
01:00:44,034 --> 01:00:48,079
is how do you represent the shaders for ray tracing

1181
01:00:48,139 --> 01:00:49,341
with a shader graph, because of course,

1182
01:00:49,381 --> 01:00:51,383
we want to enable artists for maximum freedom.

1183
01:00:51,823 --> 01:00:54,186
And you can kind of think about ray trace shaders

1184
01:00:54,447 --> 01:00:56,649
as a flavor of a subgraph that's encompassed

1185
01:00:56,669 --> 01:00:57,570
for a specific LOD.

1186
01:00:58,391 --> 01:01:01,735
In each effects we then have a separate shader table

1187
01:01:01,775 --> 01:01:03,057
because of course you need to ensure

1188
01:01:03,498 --> 01:01:05,080
you're actually compiling and linking

1189
01:01:05,140 --> 01:01:07,463
and able to evaluate that.

1190
01:01:07,983 --> 01:01:09,245
And with shader graph we can bring

1191
01:01:09,285 --> 01:01:11,468
a separate shader sub graph per effect.

1192
01:01:11,988 --> 01:01:14,271
This is also going to be used to be able to switch

1193
01:01:14,371 --> 01:01:16,093
based on distance as well as effect.

1194
01:01:17,917 --> 01:01:21,259
So a couple of things about the demo I'll show in a second.

1195
01:01:22,019 --> 01:01:24,741
On 2080 Ti, it was running at about 60 FPS.

1196
01:01:24,801 --> 01:01:25,762
I'll run it on my laptop.

1197
01:01:25,802 --> 01:01:28,403
We'll see how it does with running for an hour.

1198
01:01:29,604 --> 01:01:30,605
Apparently, I live on the edge.

1199
01:01:31,385 --> 01:01:35,008
This car is about 28 million polygons with tons of effects.

1200
01:01:35,228 --> 01:01:36,989
We did do a pass, and this is something

1201
01:01:37,029 --> 01:01:38,990
that you need to mind with ray tracing for sure.

1202
01:01:39,971 --> 01:01:42,452
As there are a lot more parameters set,

1203
01:01:42,492 --> 01:01:44,894
you need to think about optimizing meshes to avoid.

1204
01:01:45,958 --> 01:01:49,496
to basically do merging and so forth of smart things for the draw calls.

1205
01:01:51,093 --> 01:01:53,293
It was a little bit of an insane geometry, right?

1206
01:01:53,353 --> 01:01:54,874
And this is sort of the level of silliness

1207
01:01:54,894 --> 01:01:56,534
because this was a product design car.

1208
01:01:56,594 --> 01:02:00,355
They modeled the actual numbers for the text in the panel,

1209
01:02:00,455 --> 01:02:04,155
sub, you know, this is like the radio part.

1210
01:02:05,096 --> 01:02:07,916
Silly, but it has representation for some of the complexities

1211
01:02:07,956 --> 01:02:09,416
that we'll see in a good level.

1212
01:02:09,436 --> 01:02:11,577
I think 28 mil with a ton of details

1213
01:02:11,637 --> 01:02:13,137
is actually a fairly decent workload

1214
01:02:13,197 --> 01:02:15,638
representing this or next-gen games.

1215
01:02:16,558 --> 01:02:17,938
And so this is just the example

1216
01:02:17,958 --> 01:02:19,618
of the density of the geometry.

1217
01:02:21,677 --> 01:02:25,479
And the performance numbers, so I'll let you kind of peruse them later on,

1218
01:02:26,040 --> 01:02:29,622
capture it in 28 Ti for this wide shot that you've just seen.

1219
01:02:30,082 --> 01:02:32,244
You know, as you can see, the reflections is actually, you know,

1220
01:02:32,284 --> 01:02:36,647
about five milliseconds is where we spend our being quite extensively.

1221
01:02:36,727 --> 01:02:39,689
And then the ray tracing itself is only 14 milliseconds.

1222
01:02:39,709 --> 01:02:44,192
So it's actually not bad, despite the fact that it's a heavy polygonal model

1223
01:02:44,452 --> 01:02:45,933
and an enormous textured light.

1224
01:02:47,850 --> 01:02:52,672
So let's live on the edge and see how this will work.

1225
01:02:55,173 --> 01:02:57,815
And of course, if we're gonna get kicked out of the room,

1226
01:02:57,915 --> 01:03:00,816
you can come over and check it out on the live laptop.

1227
01:03:01,897 --> 01:03:04,478
And so this is that wide area light that you were seeing

1228
01:03:04,538 --> 01:03:06,479
and sort of thing I can show you the comparison

1229
01:03:06,519 --> 01:03:07,720
to the ray traced effects

1230
01:03:08,500 --> 01:03:10,161
versus the screen space reflections.

1231
01:03:10,501 --> 01:03:13,223
And you can start seeing some of the fidelity

1232
01:03:13,263 --> 01:03:15,904
that comes in with that effect.

1233
01:03:17,274 --> 01:03:21,639
The primary visibility ray is actually a lot better noticeable in the interior.

1234
01:03:22,260 --> 01:03:29,249
So if we go to this region, the gear shift box, and pardon my car terminology knowledge,

1235
01:03:29,269 --> 01:03:31,212
because I'll probably name something incorrectly.

1236
01:03:31,993 --> 01:03:35,916
has a really complex transparent and refractive object.

1237
01:03:36,437 --> 01:03:38,198
If I turn the visibility array,

1238
01:03:38,238 --> 01:03:39,419
you can kind of start seeing,

1239
01:03:39,499 --> 01:03:41,141
and in fact if I go a little bit sideways,

1240
01:03:41,561 --> 01:03:43,883
you can start seeing the loss of quality

1241
01:03:44,004 --> 01:03:46,125
of being able to get the internal effects

1242
01:03:46,186 --> 01:03:48,888
within that object from the bounces that are happening.

1243
01:03:51,110 --> 01:03:53,993
And if we look at reflections,

1244
01:03:54,173 --> 01:03:56,555
again, that's something that we can kind of start seeing

1245
01:03:56,595 --> 01:03:58,036
all of the dynamic elements of them.

1246
01:04:01,125 --> 01:04:02,628
Okay, I'm being hurried on.

1247
01:04:02,648 --> 01:04:04,851
That's okay.

1248
01:04:05,112 --> 01:04:07,595
Thank you guys for not displaying extreme impatience.

1249
01:04:09,498 --> 01:04:11,421
I'll beat the conference, it's less tolerant.

1250
01:04:13,344 --> 01:04:13,625
Okay.

1251
01:04:17,457 --> 01:04:20,760
All right, so a couple of small performance observations.

1252
01:04:20,900 --> 01:04:22,181
I have about maybe five minutes,

1253
01:04:22,461 --> 01:04:23,982
and then I'll finish my rant.

1254
01:04:25,023 --> 01:04:26,665
We noticed that, surprisingly,

1255
01:04:26,705 --> 01:04:28,366
payload had really small impact.

1256
01:04:28,386 --> 01:04:32,129
We did a lot of tests, varying 256 versus 1024

1257
01:04:32,449 --> 01:04:33,190
payload changes.

1258
01:04:33,650 --> 01:04:35,452
It was negligible in terms of performance,

1259
01:04:35,472 --> 01:04:37,273
and we actually found the same feedback

1260
01:04:37,293 --> 01:04:39,795
from Microsoft and NVIDIA when discussing.

1261
01:04:39,935 --> 01:04:42,738
Cost was roughly linear with the numbers of rays,

1262
01:04:43,178 --> 01:04:44,599
and of course, as I mentioned earlier,

1263
01:04:44,639 --> 01:04:46,220
ray coherency was king, right?

1264
01:04:47,321 --> 01:04:52,427
It's also super important to get rid of as much work as possible from the raytrace shader,

1265
01:04:52,908 --> 01:04:58,894
splitting work between compute and raytrace, so doing prepass is a good thing to do for performance reasons.

1266
01:05:00,176 --> 01:05:01,877
On our side, what are we doing next?

1267
01:05:02,058 --> 01:05:04,140
We're going to support particles, and it's going to be fun.

1268
01:05:04,180 --> 01:05:06,222
We're going to discover a lot of interesting challenges.

1269
01:05:06,863 --> 01:05:10,347
We're also going to support more sophisticated GPU animations.

1270
01:05:11,068 --> 01:05:15,333
You saw some of the animations in the car, but the really fun bits exist when artists

1271
01:05:15,353 --> 01:05:17,435
do vertex animations in the shader graph.

1272
01:05:18,716 --> 01:05:23,542
Lots of interesting challenges there with regards to BVHs and updated acceleration structures.

1273
01:05:23,882 --> 01:05:25,524
And of course, even more optimizations.

1274
01:05:26,881 --> 01:05:29,424
So, for the five minute rant, this is sort of,

1275
01:05:29,924 --> 01:05:31,365
if there are any IHVs people,

1276
01:05:31,465 --> 01:05:34,188
or people who talk to IHVs and or APIs,

1277
01:05:34,628 --> 01:05:36,049
I wanted to mention a couple of things

1278
01:05:36,089 --> 01:05:37,270
that are worth thinking about

1279
01:05:37,310 --> 01:05:40,373
with regards to current API and or state of algorithms.

1280
01:05:40,934 --> 01:05:42,175
So with regards to denoising,

1281
01:05:42,435 --> 01:05:45,117
we said we're going to denoising per effect.

1282
01:05:45,558 --> 01:05:46,759
We chose a cheap denoiser,

1283
01:05:46,939 --> 01:05:48,900
more of them per area light, et cetera.

1284
01:05:49,241 --> 01:05:51,723
Congratulations, profit, runs fast, we're good.

1285
01:05:52,584 --> 01:05:57,988
It's still not super well understood what is the actual intuition of when you want to choose,

1286
01:05:58,028 --> 01:06:04,172
let's say, a denoiser per frame versus a denoiser per effect. I would love to see more, you know,

1287
01:06:04,472 --> 01:06:09,576
deeper research in that domain of understanding of how the final denoiser...

1288
01:06:10,697 --> 01:06:12,338
Okay, matches, maybe I'll rent outside of the door.

1289
01:06:13,344 --> 01:06:16,428
So, a couple of things, I'll just mention them.

1290
01:06:16,888 --> 01:06:18,590
We have global acceleration structures

1291
01:06:18,710 --> 01:06:20,192
and global reflection tables.

1292
01:06:20,773 --> 01:06:22,234
How will this work with streaming?

1293
01:06:22,394 --> 01:06:23,896
How will this work with LODs?

1294
01:06:24,497 --> 01:06:25,999
How will this work with shaders

1295
01:06:26,059 --> 01:06:27,881
that need to be compiled iteratively?

1296
01:06:28,441 --> 01:06:30,564
How will this work with all the dynamic objects

1297
01:06:30,584 --> 01:06:32,025
that we want to procedurally create?

1298
01:06:32,706 --> 01:06:34,007
Lots of challenges there.

1299
01:06:34,547 --> 01:06:36,327
How will they work with GPU updates?

1300
01:06:36,387 --> 01:06:38,488
I can't update the BVH structure on the GPU.

1301
01:06:38,628 --> 01:06:41,049
So there's a lot of deep thinking that needs to occur

1302
01:06:41,289 --> 01:06:43,991
on that front before we can really start thinking about

1303
01:06:44,511 --> 01:06:46,752
truly integrating this in a proper way.

1304
01:06:47,252 --> 01:06:48,672
Then of course we need to think about

1305
01:06:48,753 --> 01:06:50,593
ray tracing and texture cache coherency.

1306
01:06:51,154 --> 01:06:54,777
The main thing I want to mention there is we think we understood texture streaming, right?

1307
01:06:54,817 --> 01:06:57,299
Like we can predict when the object needs to stream in pretty well.

1308
01:06:57,759 --> 01:06:59,240
With ray tracing, guess what?

1309
01:06:59,420 --> 01:07:00,201
You're out of luck.

1310
01:07:00,321 --> 01:07:02,323
You don't know when the texture needs to be streamed in.

1311
01:07:02,783 --> 01:07:04,605
It's not inside of your camera view.

1312
01:07:05,085 --> 01:07:07,988
So there's some really good thinking that I think is going to happen in the next three

1313
01:07:08,008 --> 01:07:14,873
to five years on how we combine the generality of our dynamic worlds, open world streaming

1314
01:07:14,913 --> 01:07:18,757
and so forth, with the lockdown of the black box.

1315
01:07:19,597 --> 01:07:23,300
always loaded and compiled at runtime BVHs

1316
01:07:23,380 --> 01:07:25,362
that are not in our control.

1317
01:07:26,062 --> 01:07:28,604
So in general, that's a pretty big challenge.

1318
01:07:29,465 --> 01:07:32,507
And mesh shaders and ray tracing,

1319
01:07:32,547 --> 01:07:35,329
and anything that does GPU generation and compute shaders

1320
01:07:35,369 --> 01:07:39,552
or GPU-driven pipeline, how do we do BVH updates

1321
01:07:39,592 --> 01:07:40,193
in that case?

1322
01:07:40,273 --> 01:07:42,114
This remains a really fascinating field.

1323
01:07:43,035 --> 01:07:44,636
I'm sorry, one little thing.

1324
01:07:45,880 --> 01:07:47,741
DDX, DDYs, they were our friends.

1325
01:07:47,801 --> 01:07:49,002
We knew them so well.

1326
01:07:49,542 --> 01:07:51,583
Well, with ray tracing, this is a problem.

1327
01:07:52,244 --> 01:07:53,564
We kind of worked around it.

1328
01:07:53,624 --> 01:07:54,805
There's an NVIDIA paper.

1329
01:07:54,825 --> 01:07:57,547
I advise you to look it up on MIP, MAP, LOD.

1330
01:07:57,907 --> 01:07:59,548
You can always fall back on MIP zero.

1331
01:07:59,628 --> 01:08:00,348
That's okay.

1332
01:08:01,349 --> 01:08:02,909
And then of course, support for beams.

1333
01:08:02,949 --> 01:08:04,510
So I told you we're doing a bunch of stuff

1334
01:08:04,530 --> 01:08:05,431
through primary arrays.

1335
01:08:05,511 --> 01:08:06,691
Congratulations to us.

1336
01:08:06,811 --> 01:08:07,892
How do we accelerate it?

1337
01:08:08,232 --> 01:08:10,774
We want to do beams through the acceleration structure.

1338
01:08:12,205 --> 01:08:14,907
We know their coherency, not supported through the API.

1339
01:08:15,288 --> 01:08:15,748
End of rant.

1340
01:08:17,830 --> 01:08:20,351
So there were a lot of people who contributed to this demo.

1341
01:08:20,512 --> 01:08:22,153
Couple more minutes, they need to be named.

1342
01:08:22,193 --> 01:08:23,113
They were fantastic.

1343
01:08:23,514 --> 01:08:25,875
They did really hard work and the results are amazing.

1344
01:08:26,296 --> 01:08:28,978
And this is both artists, engineers, and so forth.

1345
01:08:30,819 --> 01:08:32,000
Once more plug, we're hiring.

1346
01:08:32,040 --> 01:08:34,762
If you wanna solve all the hard problems I just mentioned,

1347
01:08:35,022 --> 01:08:35,643
come join us.

1348
01:08:36,663 --> 01:08:39,065
We're across the world, probably where you are.

1349
01:08:39,145 --> 01:08:40,506
We are at too, so.

1350
01:08:42,232 --> 01:08:42,673
and the rent.

1351
01:08:43,454 --> 01:08:44,395
Thank you for your patience.

1352
01:08:45,376 --> 01:08:48,360
And if there are questions, I'll be at the end of the talk.

