1
00:00:05,826 --> 00:00:06,747
My name is Chris Preet.

2
00:00:07,807 --> 00:00:10,149
I'm the founder and CEO of Two Hat Security.

3
00:00:10,789 --> 00:00:12,210
Today we're gonna talk about trolls

4
00:00:12,530 --> 00:00:13,771
and the cost of doing nothing.

5
00:00:14,671 --> 00:00:16,853
And I wanna just preface this kind of conversation

6
00:00:16,873 --> 00:00:17,693
before we get too far,

7
00:00:17,713 --> 00:00:19,174
because oftentimes when I talk about that,

8
00:00:19,214 --> 00:00:21,255
we think what we're talking about is profanity

9
00:00:21,796 --> 00:00:23,837
and silly little funny quirks that people say.

10
00:00:24,577 --> 00:00:25,378
And we've seen a lot of that,

11
00:00:25,398 --> 00:00:27,859
because we process about four billion messages a day

12
00:00:27,959 --> 00:00:29,120
for the games industry.

13
00:00:29,140 --> 00:00:32,222
And we've seen a tremendous amount of hilarious stuff.

14
00:00:33,346 --> 00:00:35,946
But what we are is we're an AI company that

15
00:00:36,086 --> 00:00:38,867
finds the most toxic, disgusting things on the internet,

16
00:00:38,887 --> 00:00:42,028
like rape and genocide and hate speech

17
00:00:42,468 --> 00:00:45,588
and sexual abuse of children and child pornography

18
00:00:45,608 --> 00:00:46,989
and the worst things that there is.

19
00:00:47,749 --> 00:00:49,329
And we also work with the games industry

20
00:00:49,349 --> 00:00:50,929
in order to deal with the trolling problem

21
00:00:51,550 --> 00:00:53,330
to build reputations and find our own users.

22
00:00:53,390 --> 00:00:55,130
And what we'd like to share today

23
00:00:55,190 --> 00:00:56,411
is a bunch of research we've been doing

24
00:00:56,451 --> 00:00:57,971
out of the research arm of our company

25
00:00:59,371 --> 00:01:01,432
where we dive deep into the problem of trolling.

26
00:01:02,141 --> 00:01:03,763
and try to understand how can we make it better

27
00:01:03,783 --> 00:01:05,285
and how can we be involved in it.

28
00:01:05,305 --> 00:01:07,107
So it's a bit of a serious conversation today,

29
00:01:07,147 --> 00:01:08,389
but hopefully we'll have a little bit of fun

30
00:01:09,230 --> 00:01:09,830
in light of that.

31
00:01:12,554 --> 00:01:15,537
So, this is me, long time ago.

32
00:01:15,557 --> 00:01:17,480
How many people had a computer like that, long time ago?

33
00:01:18,203 --> 00:01:21,185
Yes, I figured it. We've been in this industry for a long time, you guys.

34
00:01:22,166 --> 00:01:26,129
20 years for me going at this, having like a great time.

35
00:01:26,470 --> 00:01:28,471
I'm going to show you someone else. This guy here is my brother.

36
00:01:29,792 --> 00:01:33,595
My older brother. We used to make games together back when we were quite a bit younger.

37
00:01:34,396 --> 00:01:36,377
And my brother ended up making a really cool game.

38
00:01:36,958 --> 00:01:40,481
So he started off in 1999. He's like, okay, I'm going to build a game and it's going to be for kids.

39
00:01:40,501 --> 00:01:42,362
Now, nobody builds games for kids. Not in 1999.

40
00:01:44,042 --> 00:01:47,523
So in 1999, the chat rooms were very, very dark

41
00:01:47,783 --> 00:01:49,224
and not appropriate for children.

42
00:01:49,544 --> 00:01:51,305
And so there's two things about building a game for kids.

43
00:01:51,445 --> 00:01:52,525
One, you're gonna get sued.

44
00:01:53,365 --> 00:01:56,167
Number two, the kids don't have any money.

45
00:01:56,727 --> 00:01:59,088
So that was the mentality at the time.

46
00:01:59,148 --> 00:02:00,528
So he went out and created this game.

47
00:02:02,269 --> 00:02:04,610
And he built it and he was able to achieve

48
00:02:04,650 --> 00:02:04,970
300 million users.

49
00:02:06,812 --> 00:02:08,954
And if we look back on this game, it ran from,

50
00:02:09,054 --> 00:02:10,195
so the early experiments were in 99,

51
00:02:10,595 --> 00:02:12,977
and this month they're finally shutting the game down,

52
00:02:13,718 --> 00:02:15,219
and they're moving it to a mobile experience,

53
00:02:15,239 --> 00:02:16,019
which is really cool.

54
00:02:17,180 --> 00:02:18,441
But how did he go about and do that?

55
00:02:18,461 --> 00:02:19,342
What are some of the lessons learned?

56
00:02:19,362 --> 00:02:21,604
Well, one of them was that community

57
00:02:21,644 --> 00:02:23,405
was incredibly important, because he found out

58
00:02:23,445 --> 00:02:25,747
that if you put energy into making it incredibly safe,

59
00:02:25,767 --> 00:02:27,148
so if we're gonna make this for kids,

60
00:02:27,689 --> 00:02:29,470
it has to be exceptionally safe.

61
00:02:30,394 --> 00:02:32,615
And when we did that, it became a place where kids hanged out,

62
00:02:32,675 --> 00:02:34,055
built friends, built community.

63
00:02:34,115 --> 00:02:36,336
And their parents were like, hey, my kids are happy.

64
00:02:36,416 --> 00:02:37,296
They're having fun.

65
00:02:37,316 --> 00:02:38,016
I'll pay money.

66
00:02:38,456 --> 00:02:39,977
And it turns out that parents have credit cards.

67
00:02:40,017 --> 00:02:42,437
And if it's safe, the lawyers don't come after you as much.

68
00:02:43,218 --> 00:02:44,638
So that was really, really cool.

69
00:02:44,658 --> 00:02:46,939
And what I found out is that when later on Disney came by

70
00:02:46,979 --> 00:02:50,560
and they offered my brother $350 million for his game,

71
00:02:52,100 --> 00:02:54,101
I was in charge of doing a bunch of the due diligence.

72
00:02:54,921 --> 00:02:55,781
And they asked me this question.

73
00:02:55,801 --> 00:02:56,982
They said, what is your churn rate?

74
00:02:57,942 --> 00:02:59,142
I said, what the heck is churn?

75
00:03:00,479 --> 00:03:11,107
So I wasn't measuring churn because we didn't really have a concept of churn because people love the game and they would just stay and stay and stay and stay and I had to learn what it means is how fast are you users quitting.

76
00:03:12,207 --> 00:03:22,275
Because when you have a strongly engaged community you can end up with a product that lasts for well over a decade and you can still have people very sad after they've been playing for 13 years and more.

77
00:03:24,067 --> 00:03:26,949
But it's not just kids-based products that we're talking about.

78
00:03:26,969 --> 00:03:29,090
It's becoming very, very popular today

79
00:03:29,530 --> 00:03:32,391
that this issue needs to be dealt with of trolls, toxicity,

80
00:03:32,531 --> 00:03:33,712
and all that kind of garbage.

81
00:03:34,012 --> 00:03:36,813
We can see and watch what's happening with Twitter in the media,

82
00:03:36,833 --> 00:03:37,614
and they've been slaughtered.

83
00:03:37,654 --> 00:03:38,714
And they're trying really hard.

84
00:03:38,734 --> 00:03:39,715
They're doing a bunch of things.

85
00:03:39,775 --> 00:03:42,176
But they've just been slaughtered in the media

86
00:03:42,236 --> 00:03:44,977
about how much of a problem it is.

87
00:03:45,798 --> 00:03:48,181
And so you have famous people that are being onslaught

88
00:03:48,201 --> 00:03:50,164
with constant bombardment of toxic

89
00:03:50,204 --> 00:03:51,386
and trolling-based comments.

90
00:03:51,786 --> 00:03:53,028
And that's highly problematic

91
00:03:53,088 --> 00:03:54,590
because if you want to create a platform

92
00:03:54,610 --> 00:03:55,832
where there's free speech,

93
00:03:57,734 --> 00:03:59,537
if so much hate speech is allowed,

94
00:04:00,618 --> 00:04:03,000
that what ends up happening is nobody wants to share.

95
00:04:03,560 --> 00:04:05,241
You end up with this situation

96
00:04:05,641 --> 00:04:08,042
where everyone just shares pictures of puppy dogs

97
00:04:08,623 --> 00:04:09,863
and silly little emojis

98
00:04:09,923 --> 00:04:11,864
because if anyone engaged in a real conversation,

99
00:04:11,884 --> 00:04:13,685
if anyone engaged in their actual liberty

100
00:04:13,765 --> 00:04:15,966
of being able to share their true mind and their opinion,

101
00:04:16,327 --> 00:04:17,207
they'll be destroyed.

102
00:04:18,152 --> 00:04:21,455
Because 95 or more, maybe even 99% of users are good,

103
00:04:21,555 --> 00:04:25,139
but the 1% and the 5% are so toxic

104
00:04:25,159 --> 00:04:27,442
that they're making these platforms unaccessible

105
00:04:27,582 --> 00:04:30,866
to have true expression and truly reach their potential

106
00:04:30,886 --> 00:04:31,506
of what they could be.

107
00:04:34,172 --> 00:04:36,415
And so you have situations that gets even worse

108
00:04:36,435 --> 00:04:38,458
where you take your best users, your whales,

109
00:04:38,918 --> 00:04:40,300
the ones that believe in your platform,

110
00:04:40,320 --> 00:04:41,101
the ones that are building it up,

111
00:04:41,141 --> 00:04:42,583
the ones that are inviting other users,

112
00:04:43,264 --> 00:04:45,146
and they are the ones that are leaving en masse.

113
00:04:45,186 --> 00:04:46,708
And so you can see on places like Twitter

114
00:04:46,728 --> 00:04:49,612
where the most famous people are abandoning Twitter

115
00:04:49,632 --> 00:04:50,853
and they're doing this campaign of like,

116
00:04:50,913 --> 00:04:51,674
I'm quitting Twitter.

117
00:04:52,637 --> 00:04:54,819
And it's happening so frequent that it's becoming common.

118
00:04:54,839 --> 00:04:58,443
In this case here, it's Lily Allen was being attacked on Twitter

119
00:04:58,483 --> 00:05:01,726
because she lost her baby many years ago.

120
00:05:02,166 --> 00:05:04,108
And she's developed mental illness because of it.

121
00:05:04,168 --> 00:05:05,490
And because of that, people are telling her,

122
00:05:05,510 --> 00:05:06,311
well, it's your fault.

123
00:05:06,371 --> 00:05:07,452
You're the one who killed your baby.

124
00:05:07,472 --> 00:05:09,954
And they'd make little memes about a frog being stillborn.

125
00:05:09,994 --> 00:05:13,198
And it was like so devastating to her that she's like,

126
00:05:13,238 --> 00:05:13,818
I've had enough.

127
00:05:18,688 --> 00:05:23,190
And so the cost of doing nothing, the cost of allowing such toxicity to be pervasive

128
00:05:23,730 --> 00:05:26,350
has a direct impact on the financial bottom line of a company.

129
00:05:26,370 --> 00:05:28,111
And so this is Twitter's stocks.

130
00:05:28,711 --> 00:05:30,071
And you can watch kind of how they go down.

131
00:05:30,091 --> 00:05:33,652
Now there's many factors involved in that, but one of them that's being drawn out in

132
00:05:33,672 --> 00:05:38,613
the news and the media is that they have not been able to take this matter, not actually

133
00:05:38,633 --> 00:05:39,473
been able to deal with it.

134
00:05:40,093 --> 00:05:43,795
Because they've had a platform where this free speech is everything,

135
00:05:43,835 --> 00:05:46,136
and this is your own private room, and do whatever you want,

136
00:05:46,636 --> 00:05:49,097
except for we have to understand that the private room

137
00:05:49,137 --> 00:05:50,838
has a glass wall standing on Main Street,

138
00:05:50,858 --> 00:05:52,058
because we gave them a microphone,

139
00:05:52,078 --> 00:05:53,579
because they're supposed to tweet to the world.

140
00:05:54,619 --> 00:05:56,740
And there's a disconnect between those two concepts.

141
00:05:57,180 --> 00:06:00,421
And now they're actively working and trying to do some amazing steps

142
00:06:00,441 --> 00:06:03,542
to transform the situation and launch some new technology,

143
00:06:04,563 --> 00:06:06,083
but we hope it's not too little, too late.

144
00:06:08,405 --> 00:06:10,427
In comparison, you can compare them up to Facebook,

145
00:06:10,447 --> 00:06:11,188
which is in green.

146
00:06:12,289 --> 00:06:13,750
Many different factors involved in there.

147
00:06:13,770 --> 00:06:15,652
There isn't just one, but one of the factors

148
00:06:15,672 --> 00:06:17,674
that's different about them is how they've gone about

149
00:06:17,754 --> 00:06:19,495
taking care of moderation.

150
00:06:19,535 --> 00:06:21,277
If Facebook hires thousands of people

151
00:06:21,837 --> 00:06:24,119
to go and review content and user reports

152
00:06:24,219 --> 00:06:26,401
and take action against it and try to remove hate speech

153
00:06:26,441 --> 00:06:29,544
within 48 hours, they've been actively engaged in it

154
00:06:29,604 --> 00:06:31,666
and it makes a financial difference to the whole thing.

155
00:06:33,050 --> 00:06:36,071
And today we want to measure, we want to take a look at that cost of doing nothing.

156
00:06:36,111 --> 00:06:37,251
I want to follow up from a talk.

157
00:06:37,291 --> 00:06:40,832
There's a great company, a great presentation a few years ago.

158
00:06:41,312 --> 00:06:43,113
Riot Games did a look at what they were doing.

159
00:06:44,313 --> 00:06:46,754
And they said, oh my goodness, if we analyze our chat logs,

160
00:06:47,474 --> 00:06:52,875
honestly, we know that users are about 21% of the conversation is toxic.

161
00:06:54,295 --> 00:06:56,316
And they said they had to do something because what we've observed is that

162
00:06:56,336 --> 00:06:59,237
when conversations hit around the 20% mark, it's close to death.

163
00:07:00,354 --> 00:07:01,595
And so Riot Games got really smart

164
00:07:01,615 --> 00:07:02,416
and they started thinking about it

165
00:07:02,436 --> 00:07:03,557
and saying, well, what can we do about it?

166
00:07:03,578 --> 00:07:05,299
And Jeffrey Lin came on the stage of GDC

167
00:07:05,339 --> 00:07:07,261
and gave an amazing breakthrough research

168
00:07:07,802 --> 00:07:09,304
of what they needed to uncover and discover.

169
00:07:09,324 --> 00:07:10,705
And one of the things that they did in their study

170
00:07:10,725 --> 00:07:12,887
is they said a user who experiences toxicity

171
00:07:13,348 --> 00:07:14,129
is 320% more likely to quit.

172
00:07:18,150 --> 00:07:20,151
That motivated them to make a change.

173
00:07:20,691 --> 00:07:22,853
And they did things like they set up a tribunal system

174
00:07:22,933 --> 00:07:25,014
so that the community could take care

175
00:07:25,034 --> 00:07:25,775
of some of those issues.

176
00:07:25,795 --> 00:07:26,735
They started telling people,

177
00:07:27,116 --> 00:07:28,737
this is the reason why you were banned,

178
00:07:29,277 --> 00:07:30,898
or why you had action taken against you.

179
00:07:30,918 --> 00:07:32,499
And they noticed that there was a higher reform rate.

180
00:07:32,980 --> 00:07:34,381
At one point, they brought the toxicity

181
00:07:34,441 --> 00:07:35,141
all the way down to 2%.

182
00:07:37,202 --> 00:07:38,083
If anyone knows Riot Games,

183
00:07:38,123 --> 00:07:39,904
I'd love to connect and figure out some of the techniques

184
00:07:40,104 --> 00:07:42,926
and stuff and how it's going now for that,

185
00:07:42,946 --> 00:07:45,028
and then be able to present that more as we go on.

186
00:07:46,423 --> 00:07:49,775
But sitting in the audience at the time was my buddy, Alex,

187
00:07:49,795 --> 00:07:51,421
and he was from World Series Poker.

188
00:07:53,816 --> 00:07:55,097
And he was listening to it and he was going,

189
00:07:55,117 --> 00:07:56,917
he's thinking back about the different kind of feedback

190
00:07:56,957 --> 00:07:59,459
he's had from his users, the comments he's had,

191
00:07:59,499 --> 00:08:00,479
and all those things, he started thinking,

192
00:08:00,499 --> 00:08:02,580
okay, when you're playing poker

193
00:08:02,620 --> 00:08:03,861
and you put your money in the kitty,

194
00:08:03,901 --> 00:08:05,421
if another user can be toxic to you

195
00:08:05,481 --> 00:08:07,082
and troll you and make your experience terrible,

196
00:08:07,102 --> 00:08:08,022
and you're like, I've had enough,

197
00:08:08,063 --> 00:08:10,604
and you just throw the cards down and leave and fold,

198
00:08:11,164 --> 00:08:12,585
there's a disadvantage.

199
00:08:13,425 --> 00:08:14,926
And that person, by trolling you,

200
00:08:14,986 --> 00:08:16,366
can make a financial benefit.

201
00:08:17,131 --> 00:08:19,592
And that becomes problematic because in all of our games,

202
00:08:19,612 --> 00:08:20,713
we work on the game mechanic.

203
00:08:20,733 --> 00:08:23,194
We spend very careful time meticulously thinking

204
00:08:23,214 --> 00:08:25,116
about every single detail of what items

205
00:08:25,156 --> 00:08:26,056
are gonna be added to the games

206
00:08:26,076 --> 00:08:28,117
because that balance is critically important for fun

207
00:08:28,217 --> 00:08:30,319
and also for retention and growth and monetization.

208
00:08:30,919 --> 00:08:32,820
And if we allow one item to be there,

209
00:08:32,860 --> 00:08:34,821
like a giant sword that you can slash everyone,

210
00:08:34,841 --> 00:08:36,922
and every time you use the sword, you always win,

211
00:08:37,323 --> 00:08:38,183
that game sucks.

212
00:08:38,623 --> 00:08:41,165
Well, we need to put the same effort into community mechanics

213
00:08:41,225 --> 00:08:42,365
as we do into game mechanics

214
00:08:42,406 --> 00:08:44,707
because community is absolutely essential.

215
00:08:45,407 --> 00:08:49,610
to the growth of our game and we need to grow up as this whole thing and have more and more

216
00:08:49,630 --> 00:08:53,493
of this research which we're seeing coming out and saying how can we design our communities

217
00:08:53,653 --> 00:08:55,475
just as effectively as we design our games.

218
00:08:58,502 --> 00:09:00,944
And so we go into the question about what is toxicity.

219
00:09:00,964 --> 00:09:02,745
Toxicity is a poison, so if you imagine

220
00:09:02,765 --> 00:09:04,586
that you can put a poison into an organism

221
00:09:04,606 --> 00:09:05,926
like ourselves, our human body,

222
00:09:06,307 --> 00:09:08,808
and if it begins to spread, the organism will begin to die.

223
00:09:08,908 --> 00:09:10,509
And we see that when we launch new games,

224
00:09:10,549 --> 00:09:14,051
they start off with about 1% toxicity, roughly speaking,

225
00:09:14,511 --> 00:09:17,013
and then they go up and they start getting around 5%,

226
00:09:17,053 --> 00:09:18,413
and then it starts tipping the scale.

227
00:09:19,394 --> 00:09:21,455
And then they'll quickly grow up to around 20%,

228
00:09:21,495 --> 00:09:22,796
and it's a toxin, it's a poison

229
00:09:23,096 --> 00:09:24,397
that's spreading through the organism,

230
00:09:24,437 --> 00:09:26,798
and an organism that's toxic begins to die.

231
00:09:27,780 --> 00:09:31,065
which in the game industry means loss, death of users,

232
00:09:31,565 --> 00:09:33,468
users leave, it's no more fun,

233
00:09:34,149 --> 00:09:35,310
the game eventually shuts down.

234
00:09:36,775 --> 00:09:38,295
Now the troll, we have to define troll.

235
00:09:38,315 --> 00:09:40,056
There's a great discussion on YouTube

236
00:09:40,576 --> 00:09:42,156
on the GDC channel about this talk.

237
00:09:42,636 --> 00:09:43,997
And a lot of people were challenging and said,

238
00:09:44,057 --> 00:09:45,557
we need to make sure you define troll

239
00:09:45,577 --> 00:09:46,717
because a lot of people are just throwing

240
00:09:46,737 --> 00:09:47,718
this term out there everywhere.

241
00:09:47,738 --> 00:09:50,799
It's basically a lot of the accusation was that

242
00:09:50,939 --> 00:09:53,759
we use troll to say people that don't agree with me.

243
00:09:54,380 --> 00:09:56,740
This person is trolling me on there.

244
00:09:56,760 --> 00:09:58,761
And there was a very engaged, lively discussion.

245
00:10:00,275 --> 00:10:04,358
where one guy was, you know, tell me what you think, you worthless piece of whatever,

246
00:10:04,418 --> 00:10:08,681
you need to explain your position and he went on and on and on about this whole thing.

247
00:10:09,181 --> 00:10:14,505
The conclusion was that a troll has this intent of evil.

248
00:10:15,386 --> 00:10:18,748
They have an intent to destroy and it's an ongoing repetitive thing.

249
00:10:19,749 --> 00:10:22,291
And in the case of this one user, people accused him of being a troll

250
00:10:22,871 --> 00:10:25,854
and by his own confession he just said, no, I'm just an asshole.

251
00:10:26,940 --> 00:10:34,946
So we have to be able to tell the difference between some of the two because that is a slight difference, but a troll is the goal is just to be destroy the community.

252
00:10:35,746 --> 00:10:39,529
Where other people are just downright obnoxious now probably need to get rid of both.

253
00:10:40,850 --> 00:10:43,952
But we should make a little bit of distinction so that we treat them slightly different.

254
00:10:46,694 --> 00:10:54,039
So as we move through we want to understand the cost of doing nothing and trolling toxicity those kinds of things.

255
00:10:55,095 --> 00:10:57,229
So we said, okay, trolling, toxicity, where can we start?

256
00:10:57,290 --> 00:10:58,276
Oh, let's go start with Reddit.

257
00:10:59,702 --> 00:11:01,282
So we went and looked at the first year of Reddit

258
00:11:01,322 --> 00:11:02,923
before they developed a reputation,

259
00:11:03,423 --> 00:11:06,565
and we did a big study of how does each individual subreddit,

260
00:11:06,965 --> 00:11:10,227
how does health, how is it affected by toxicity?

261
00:11:10,547 --> 00:11:12,308
So we measured health as things like growth,

262
00:11:12,488 --> 00:11:13,868
you know, organism that's growing,

263
00:11:13,908 --> 00:11:16,530
so more users, more conversation, more whatever,

264
00:11:16,610 --> 00:11:17,990
just more of stuff.

265
00:11:18,711 --> 00:11:20,732
And toxicity we defined as basically

266
00:11:20,772 --> 00:11:22,413
let's take anything bad and throw it in there.

267
00:11:22,493 --> 00:11:26,695
So people raping each other, racism, vulgarity,

268
00:11:26,795 --> 00:11:28,095
just whatever, it's bad stuff.

269
00:11:29,274 --> 00:11:31,235
And we measured the two and tried to find a correlation.

270
00:11:31,255 --> 00:11:33,957
Well, the expected result of course is that you'd see

271
00:11:33,977 --> 00:11:37,558
that as the bottom line of toxicity goes up,

272
00:11:37,638 --> 00:11:39,119
the red line, which is health, goes down.

273
00:11:39,179 --> 00:11:40,260
Well, that kind of makes sense.

274
00:11:40,300 --> 00:11:41,340
That's what we're anticipating.

275
00:11:42,041 --> 00:11:43,662
What we like to do in a study is find stuff

276
00:11:43,682 --> 00:11:44,682
that we didn't anticipate.

277
00:11:44,702 --> 00:11:46,663
And what we didn't anticipate was the second column,

278
00:11:46,683 --> 00:11:47,744
which is the game industry.

279
00:11:49,045 --> 00:11:50,486
that the toxicity was starting around 4%

280
00:11:51,126 --> 00:11:53,468
and it grew all the way up to around 6 or 7%

281
00:11:54,089 --> 00:11:55,029
during the course of the year.

282
00:11:55,150 --> 00:11:56,230
And guess what happened to the health?

283
00:11:56,270 --> 00:11:57,071
The health went up.

284
00:11:57,091 --> 00:11:59,933
So when toxicity went up in the game sector

285
00:12:00,754 --> 00:12:03,016
on the subreddit, then so did the health.

286
00:12:03,236 --> 00:12:06,058
And so there's not an absolute direct correlation

287
00:12:06,118 --> 00:12:07,400
between toxicity and health.

288
00:12:07,440 --> 00:12:10,422
You can have a toxic community and you can still grow.

289
00:12:12,457 --> 00:12:14,578
Which is a drastically surprising finding.

290
00:12:14,638 --> 00:12:16,899
However, there's some caveats to that.

291
00:12:17,539 --> 00:12:18,700
Now our understanding for that is,

292
00:12:18,760 --> 00:12:20,580
notice that it's on the lower level of toxicity.

293
00:12:20,640 --> 00:12:22,301
So a community has enough resilience

294
00:12:22,401 --> 00:12:24,162
to put up with a little bit.

295
00:12:24,922 --> 00:12:27,063
A community can handle a little bit of toxicity.

296
00:12:27,363 --> 00:12:30,624
In addition to that, a community can begin

297
00:12:30,644 --> 00:12:32,265
to have an expectation that surrounds it.

298
00:12:32,285 --> 00:12:34,366
It begins to draw people of like-mindedness

299
00:12:34,506 --> 00:12:35,546
towards the same thing.

300
00:12:36,466 --> 00:12:39,127
and other people self-elect to go away.

301
00:12:39,187 --> 00:12:40,907
So the health could have potentially been faster,

302
00:12:40,927 --> 00:12:41,528
we're not sure.

303
00:12:42,128 --> 00:12:43,388
But one thing we did observe

304
00:12:44,789 --> 00:12:47,469
is that when there's a drastic change in toxicity,

305
00:12:48,210 --> 00:12:49,790
there's a drastic change in health.

306
00:12:50,450 --> 00:12:51,771
And it works on the positive as well,

307
00:12:51,811 --> 00:12:55,012
because World of Warcraft, on their individual Reddit,

308
00:12:55,352 --> 00:12:57,252
you could see that when they made a difference

309
00:12:57,292 --> 00:12:58,293
to the toxicity level,

310
00:12:58,313 --> 00:13:00,613
so when that toxicity level starts dropping on the bottom,

311
00:13:00,633 --> 00:13:02,974
you can see that eventually the health started going up.

312
00:13:03,034 --> 00:13:04,495
So when the community began to trust,

313
00:13:05,590 --> 00:13:10,296
the forum again, they began to come back and they began to engage again and began to be

314
00:13:10,336 --> 00:13:11,377
a place where they could share.

315
00:13:12,218 --> 00:13:17,585
And on a completely different nature of topics, of amateur, it's, don't look it up, it goes

316
00:13:17,825 --> 00:13:21,349
up, it goes down, it goes up, so there's a direct correlation between the two and whenever

317
00:13:21,369 --> 00:13:23,732
there's a drastic change, there's a drastic change to health.

318
00:13:25,394 --> 00:13:32,258
and toxicity is common other people are doing research and finding that things like half of people playing playing these kinds of games

319
00:13:32,618 --> 00:13:38,022
discover that they at one point are being attacked by this toxicity in addition to that.

320
00:13:39,082 --> 00:13:46,867
A third of us basically at some point in our life get pissed off and become that toxic trollish type person under certain conditions.

321
00:13:49,148 --> 00:13:51,069
So that becomes quite interesting.

322
00:13:52,272 --> 00:13:54,215
Now I wanted to really dive into and say,

323
00:13:54,255 --> 00:13:55,617
okay, what does this actually look like?

324
00:13:55,657 --> 00:13:58,080
And in the game industry, we love the idea of an A-B test.

325
00:13:58,100 --> 00:13:59,182
So let's separate an A-B test.

326
00:13:59,202 --> 00:14:00,985
So I'm gonna create two different kinds of games

327
00:14:01,846 --> 00:14:03,328
and illustrate for you their journey

328
00:14:03,829 --> 00:14:06,292
of how they're gonna go ahead and reach $21 million.

329
00:14:09,116 --> 00:14:13,458
and what difference it makes based upon the decisions they make using the data that we have now.

330
00:14:14,238 --> 00:14:15,559
So these are fake games.

331
00:14:15,899 --> 00:14:19,480
They're based on real stories and real data behind it,

332
00:14:20,240 --> 00:14:22,421
but they are fake for the purpose of this demonstration.

333
00:14:22,481 --> 00:14:24,002
I want you to consider them basically the same.

334
00:14:24,022 --> 00:14:26,863
Now the first one is a futuristic space game called AI Warzone.

335
00:14:27,843 --> 00:14:30,685
The second one is a medieval fantasy game called Trials of Serathion

336
00:14:30,705 --> 00:14:33,886
with an emphasis on the word wrath in Serathion.

337
00:14:35,266 --> 00:14:38,648
Now, they're both MMORPGs, they're both over 13,

338
00:14:38,688 --> 00:14:40,349
and they're predominantly male,

339
00:14:40,669 --> 00:14:42,089
with a good mix of female players.

340
00:14:43,270 --> 00:14:44,030
For the sake of this study,

341
00:14:44,050 --> 00:14:45,291
I want you to kind of think about them

342
00:14:45,351 --> 00:14:46,752
to be essentially the same.

343
00:14:47,852 --> 00:14:49,193
So, at the beginning of our study,

344
00:14:49,393 --> 00:14:50,854
they both have a million users.

345
00:14:52,087 --> 00:14:55,169
It cost them $2.78 to spend advertising money

346
00:14:55,229 --> 00:14:57,131
to buy a user to come and play the game.

347
00:14:57,831 --> 00:14:59,232
And that user, when they join the game,

348
00:14:59,272 --> 00:15:02,194
spends about $13.51 in miscellaneous little tiny

349
00:15:02,234 --> 00:15:04,155
things in order to give them power ups and whatever else

350
00:15:04,315 --> 00:15:05,136
inside the game.

351
00:15:05,596 --> 00:15:06,977
So in-app purchases, which is great.

352
00:15:07,397 --> 00:15:11,080
We love to have that kind of markup on our things.

353
00:15:11,100 --> 00:15:12,761
So oftentimes we're fighting for pennies in here.

354
00:15:13,601 --> 00:15:16,283
They started off with a 20% churn rate month over month.

355
00:15:16,303 --> 00:15:19,285
And I'm going to show you in a moment how they dropped that

356
00:15:19,325 --> 00:15:19,725
to 5% churn rate.

357
00:15:21,736 --> 00:15:32,862
And then there's executives walking into the room as they always do like me and they say OK this year you guys are going to reach this objective no matter what you're going to get $21 million of revenue.

358
00:15:33,943 --> 00:15:39,225
And the team goes looking at so OK to hit that number we have to add to our base user base 10% every single month.

359
00:15:40,866 --> 00:15:46,749
So they tend to see they went to this talk and they revealed another study that we did this year so we did a study of a first person shooter.

360
00:15:47,780 --> 00:15:50,281
I can't share the name at this time, but it's a first-person shooter.

361
00:15:50,341 --> 00:15:52,343
It's been around for a long time, mostly out of Turkey.

362
00:15:53,123 --> 00:15:55,685
And this game here, when we did the analysis of it,

363
00:15:56,425 --> 00:15:58,386
like most people do that understand churn,

364
00:15:58,766 --> 00:16:02,649
we looked at how many users were on day one that continue to day two,

365
00:16:02,709 --> 00:16:05,150
day two to three and five and blah, blah, blah, blah, blah.

366
00:16:05,590 --> 00:16:12,134
and you measure that that's a really important to know if you games mean successful or not of course this is pretty basic but then we segmented the users

367
00:16:12,614 --> 00:16:21,298
into different groups to try to find different behavior models that indicated that makes a drastic difference in behavior in the one that we identify was that users who engaged in chat.

368
00:16:23,226 --> 00:16:25,727
are three times more likely to come back on day two.

369
00:16:25,868 --> 00:16:28,249
So any user that types in one line of chat or more

370
00:16:28,829 --> 00:16:30,570
is more likely to come back on the second date.

371
00:16:30,650 --> 00:16:32,171
We didn't figure out the exact why.

372
00:16:32,211 --> 00:16:33,772
It might be because they brought friends with them,

373
00:16:33,792 --> 00:16:34,993
they may have already known people,

374
00:16:35,013 --> 00:16:36,414
they may have found a place of belonging.

375
00:16:36,934 --> 00:16:39,155
Whatever the reason was, more study to come,

376
00:16:39,635 --> 00:16:41,376
they're three times more likely to come back

377
00:16:41,436 --> 00:16:43,117
in day two in this story.

378
00:16:44,080 --> 00:16:45,801
And then it extends that after 2 weeks,

379
00:16:45,821 --> 00:16:47,923
they're also 3 times more likely to come back.

380
00:16:48,683 --> 00:16:50,705
And so what both of our games decided, OK,

381
00:16:50,725 --> 00:16:52,206
let's make chat a primary focus.

382
00:16:52,226 --> 00:16:54,847
Let's make sure that people somehow engage in chat

383
00:16:54,887 --> 00:16:56,308
and they find a place of belonging

384
00:16:56,949 --> 00:16:59,771
and they're able to extend their thing.

385
00:16:59,791 --> 00:17:01,692
So here's a mathematical form.

386
00:17:01,712 --> 00:17:03,313
It basically means the users next month,

387
00:17:03,333 --> 00:17:05,214
so the total number of users you're going to have next month

388
00:17:06,115 --> 00:17:08,236
is the total number of users you have this month minus all

389
00:17:08,276 --> 00:17:11,038
the users who quit plus all the users you added.

390
00:17:11,910 --> 00:17:15,213
Now that you can imagine it like you're climbing a mountain, but the mountains made of sand.

391
00:17:15,933 --> 00:17:18,475
And every time you take a step, some of the sand falls down.

392
00:17:19,676 --> 00:17:22,839
And so it's really hard to reach the top of the mountain because the mountains keeps eroding.

393
00:17:22,859 --> 00:17:30,985
So if you're going to reach your 21 million dollar goal, you got to go grab a bag of sand and you have to pay money to dump to buy those users and put them back and replace all the ones that lost.

394
00:17:31,765 --> 00:17:33,827
So you have to constantly be replacing all your users.

395
00:17:36,939 --> 00:17:38,480
So they each took a different approach

396
00:17:38,981 --> 00:17:40,242
to how they're gonna climb this mountain

397
00:17:40,282 --> 00:17:42,824
and get to the top of $21 million of revenue.

398
00:17:43,104 --> 00:17:44,305
The AI Warzone said,

399
00:17:44,325 --> 00:17:45,826
we're gonna have a moderation strategy.

400
00:17:46,506 --> 00:17:47,667
We're gonna take care of our users

401
00:17:47,687 --> 00:17:48,828
and we're gonna spend money on that.

402
00:17:49,409 --> 00:17:51,350
And Trials of Serathian just simply said,

403
00:17:51,370 --> 00:17:53,472
you know what, whatever.

404
00:17:53,872 --> 00:17:54,973
I've heard so many wonderful things.

405
00:17:55,013 --> 00:17:57,575
I've heard, those are our best users, but it's fun.

406
00:17:57,615 --> 00:17:58,455
That's what we want the game.

407
00:17:58,656 --> 00:18:00,217
I've heard so many different kind of stories,

408
00:18:00,537 --> 00:18:01,558
but that's the path that they took.

409
00:18:01,658 --> 00:18:03,139
It'll take care of itself.

410
00:18:05,782 --> 00:18:10,226
So when you run down the numbers and you watch and so the key numbers that we can look at is

411
00:18:13,592 --> 00:18:19,918
They began to diverge and so AI Warzone had to spend more money to pay for their moderation

412
00:18:20,018 --> 00:18:23,321
and the outsource, like those people that they were using to do all that.

413
00:18:23,802 --> 00:18:26,144
However, they were able to achieve more money in the end.

414
00:18:26,164 --> 00:18:30,768
So at the end of the first quarter, Serathian had to pay more money because they had to

415
00:18:30,788 --> 00:18:34,792
go and buy that extra users, the sand, to keep dumping on so they can replace all the

416
00:18:34,872 --> 00:18:35,853
users that they were losing.

417
00:18:38,209 --> 00:18:40,350
So for those numbers then you can roll it out

418
00:18:40,570 --> 00:18:42,511
and you can go down to the end of the year

419
00:18:42,831 --> 00:18:44,472
and the CEOs are sitting down with their meeting

420
00:18:44,492 --> 00:18:45,773
and they're saying, okay, so how did we do?

421
00:18:45,833 --> 00:18:46,713
How did the game perform?

422
00:18:47,994 --> 00:18:48,774
And at the end of the year,

423
00:18:48,814 --> 00:18:50,135
because they had to spend so much money

424
00:18:50,175 --> 00:18:51,195
replacing their users,

425
00:18:52,096 --> 00:18:54,637
they ended up spending $7 million extra.

426
00:18:55,698 --> 00:18:58,279
And going through one part I missed on the math.

427
00:18:59,097 --> 00:19:00,238
There's some little numbers at the top.

428
00:19:00,258 --> 00:19:02,840
So the math that I was using there is Seraphian,

429
00:19:02,920 --> 00:19:04,521
using that Reddit study, said that,

430
00:19:04,561 --> 00:19:06,962
look, our users can tolerate some toxicity.

431
00:19:07,042 --> 00:19:09,104
So they had about a 6% toxicity level.

432
00:19:09,904 --> 00:19:11,946
My eyes can focus close enough, 6.6, yeah.

433
00:19:12,666 --> 00:19:14,727
And they said, okay, our users can put up with that,

434
00:19:14,787 --> 00:19:16,569
and anything above that we're gonna take care of.

435
00:19:17,349 --> 00:19:19,190
And then Seraphian said, I don't care.

436
00:19:19,250 --> 00:19:21,152
And so what they ended up, they had the Riot Games study

437
00:19:21,192 --> 00:19:22,432
that a user experiences toxicity

438
00:19:22,472 --> 00:19:23,693
is three times more likely to quit.

439
00:19:23,773 --> 00:19:24,874
So you can see 10% versus 30% roughly,

440
00:19:24,954 --> 00:19:25,534
320% or three times anyhow.

441
00:19:30,896 --> 00:19:31,616
So going forward.

442
00:19:33,858 --> 00:19:34,578
So what did we learn?

443
00:19:34,598 --> 00:19:38,681
So Serathian ended up doing a study and saying,

444
00:19:38,701 --> 00:19:39,821
okay, we gotta change this.

445
00:19:39,841 --> 00:19:41,742
We're just losing money left, right, and center.

446
00:19:41,762 --> 00:19:42,523
We gotta make a change.

447
00:19:42,903 --> 00:19:43,884
So the first thing they did is said,

448
00:19:43,944 --> 00:19:45,425
okay, Riot Games did something cool.

449
00:19:45,465 --> 00:19:46,545
Let's rip off that idea,

450
00:19:46,885 --> 00:19:48,386
and we're gonna do it, but not as well.

451
00:19:48,807 --> 00:19:52,509
And so they decided that every single toxic chat message

452
00:19:53,009 --> 00:19:54,610
needs to be, or every human report,

453
00:19:54,690 --> 00:19:56,951
needs to be reviewed by their best users.

454
00:19:58,173 --> 00:20:00,675
So imagine this scenario, you got your best users

455
00:20:00,715 --> 00:20:01,996
who love your game, who tell everyone

456
00:20:02,016 --> 00:20:03,036
that they should play this game,

457
00:20:03,316 --> 00:20:04,957
who are deeply committed, playing a long time,

458
00:20:04,997 --> 00:20:06,018
and giving you all your money,

459
00:20:06,538 --> 00:20:10,520
and you send every single message that is toxic

460
00:20:10,560 --> 00:20:12,441
and the worst of the worst to those users.

461
00:20:13,262 --> 00:20:15,923
Now if 300, if user experiences toxicity

462
00:20:15,963 --> 00:20:18,804
is 320% more likely to quit, guess what's gonna happen

463
00:20:19,325 --> 00:20:20,846
if you take your best users and give them 100%

464
00:20:20,886 --> 00:20:21,286
of the toxic crap?

465
00:20:24,142 --> 00:20:27,204
You're gonna wear out and burn out and discourage

466
00:20:27,304 --> 00:20:29,266
the best users that are paying you all the money

467
00:20:29,306 --> 00:20:30,967
and bringing in all the next user base.

468
00:20:31,708 --> 00:20:33,809
That was like a really bad idea.

469
00:20:33,829 --> 00:20:35,851
That was just not cool.

470
00:20:36,311 --> 00:20:37,713
And the second thing they did is they said,

471
00:20:37,753 --> 00:20:40,315
okay, these users, they keep getting offended,

472
00:20:40,355 --> 00:20:41,836
they keep annoying me with all these complaints.

473
00:20:41,996 --> 00:20:44,298
I'm just gonna add a button that you can mute another user.

474
00:20:44,318 --> 00:20:45,599
So whenever that user says anything,

475
00:20:45,959 --> 00:20:47,380
it's still said, but you just don't hear it.

476
00:20:48,832 --> 00:20:50,693
So let's look through the logic of that.

477
00:20:50,793 --> 00:20:53,174
So if imagine that 95% of users are good,

478
00:20:53,234 --> 00:20:55,834
because only some of us sometimes make talks of things,

479
00:20:55,874 --> 00:20:56,595
but not all the time.

480
00:20:57,515 --> 00:20:58,755
If most of the users are good,

481
00:20:59,176 --> 00:21:00,736
and a few of the users are causing the problem,

482
00:21:00,776 --> 00:21:02,577
why is it that the majority of our users

483
00:21:02,617 --> 00:21:04,277
have to go and push a button every single time

484
00:21:04,297 --> 00:21:04,937
that they're offended?

485
00:21:04,957 --> 00:21:06,078
It's not like it's their fault.

486
00:21:07,297 --> 00:21:10,418
It's not like these toxic users are like making us tons of money.

487
00:21:11,198 --> 00:21:12,559
They're actually destroying our revenue.

488
00:21:12,579 --> 00:21:14,020
So why did we, it's kind of backwards.

489
00:21:14,040 --> 00:21:15,840
We should have put the algorithm on the other side.

490
00:21:15,920 --> 00:21:17,861
In addition to that, they just keep creating more accounts

491
00:21:17,881 --> 00:21:18,842
and they have to keep muting them.

492
00:21:19,402 --> 00:21:21,103
And they're still talking about them.

493
00:21:21,123 --> 00:21:21,923
They just can't hear it.

494
00:21:21,943 --> 00:21:23,884
So everyone in the room is laughing and they don't know why.

495
00:21:26,685 --> 00:21:28,366
So how do you know if you're a Serathian?

496
00:21:28,646 --> 00:21:30,047
So go into your forums.

497
00:21:31,178 --> 00:21:35,240
going to read it going to your app store if you're on the if you're on there and

498
00:21:35,260 --> 00:21:39,142
look at the comments and say if people are saying I love the game but I hate

499
00:21:39,182 --> 00:21:42,343
the community you know you're pushing towards that level.

500
00:21:46,105 --> 00:21:48,186
So what it what it a I was on do.

501
00:21:51,327 --> 00:21:52,268
So I was on.

502
00:21:55,061 --> 00:21:58,322
they realize that not every community is the same.

503
00:21:58,722 --> 00:21:59,782
Communities are created differently,

504
00:21:59,822 --> 00:22:00,942
so you have to figure out

505
00:22:01,042 --> 00:22:02,243
what kind of community you're creating.

506
00:22:02,703 --> 00:22:04,483
So in real life, we go and create communities

507
00:22:04,523 --> 00:22:05,603
like a playground for kids.

508
00:22:05,623 --> 00:22:07,044
And if we're making a playground for kids,

509
00:22:07,484 --> 00:22:08,764
it has certain cultural expectations.

510
00:22:08,784 --> 00:22:10,605
So if I'm hanging out there with my four kids,

511
00:22:10,985 --> 00:22:12,505
and some 13-year-old punk comes along

512
00:22:12,545 --> 00:22:13,845
and starts swearing to their friend,

513
00:22:14,425 --> 00:22:16,646
it's perfectly acceptable to turn to that 13-year-old

514
00:22:16,686 --> 00:22:19,246
and say, hey, this is a mixed audience, do you mind?

515
00:22:20,047 --> 00:22:22,487
And most logical people, oops, sorry, I forgot,

516
00:22:22,507 --> 00:22:23,167
and then they move on.

517
00:22:23,207 --> 00:22:25,008
Now, we can do that with kids-based products.

518
00:22:25,028 --> 00:22:26,748
We can say, look, you can't swear here.

519
00:22:27,168 --> 00:22:28,108
That's not appropriate.

520
00:22:28,449 --> 00:22:29,669
Now, if we're gonna go and create

521
00:22:29,729 --> 00:22:30,589
a different kind of community,

522
00:22:30,609 --> 00:22:31,749
let's say we're gonna create a nightclub,

523
00:22:31,789 --> 00:22:34,490
it's for 18 plus, there's certain kind of social expectations

524
00:22:34,530 --> 00:22:35,550
that can happen in a nightclub

525
00:22:35,570 --> 00:22:37,251
that are different from the neighborhood park.

526
00:22:37,891 --> 00:22:39,591
So each location, each community,

527
00:22:39,651 --> 00:22:41,512
each party that we create has a different goal,

528
00:22:41,532 --> 00:22:43,032
and we create a community for a reason,

529
00:22:43,052 --> 00:22:44,712
and we have to figure out what that reason is

530
00:22:44,772 --> 00:22:46,233
and design that community around that.

531
00:22:46,653 --> 00:22:48,613
And it's perfectly acceptable to stick a bouncer

532
00:22:48,853 --> 00:22:49,473
at a nightclub.

533
00:22:50,234 --> 00:22:56,655
Because we want most of the people to be having fun and a good time and if one drunk idiot comes in and starts disturbing everything, bounce them out.

534
00:22:57,635 --> 00:22:58,915
That's perfectly acceptable.

535
00:22:59,215 --> 00:23:03,976
And if we're going to build Burning Man and we're going to have to take everyone out into the desert and we're going to have a really good time,

536
00:23:04,616 --> 00:23:07,097
even there, there are certain things that are culturally unacceptable.

537
00:23:07,157 --> 00:23:10,157
Like you can't go and murder people and rape people and do those other kinds of things.

538
00:23:10,177 --> 00:23:11,938
Like that's just not, that's just not cool.

539
00:23:12,318 --> 00:23:15,938
So there's different cultural expectations that can be enforced for each area.

540
00:23:17,673 --> 00:23:20,854
So they realize that each zone has a different kind of threshold.

541
00:23:20,894 --> 00:23:24,075
So if you can think of a vertical axis, you can draw a line somewhere in the sand and say,

542
00:23:24,496 --> 00:23:26,756
look, we will put up with this and no more.

543
00:23:27,917 --> 00:23:30,518
And that needs to be age appropriate and game appropriate.

544
00:23:30,958 --> 00:23:32,899
So if you're targeting middle-aged women in housecoats,

545
00:23:33,219 --> 00:23:36,400
there's certain different expectations than if you're targeting hardcore gamers.

546
00:23:37,757 --> 00:23:39,840
So that's only one vertical axis.

547
00:23:39,860 --> 00:23:41,241
There's also a horizontal axis,

548
00:23:41,281 --> 00:23:44,084
because we all know that even if you allow swearing,

549
00:23:44,345 --> 00:23:46,167
there's a certain point where someone just swears

550
00:23:46,207 --> 00:23:47,228
and swears and swears and swears.

551
00:23:47,288 --> 00:23:48,930
It's like, get, like, what?

552
00:23:49,350 --> 00:23:50,451
You're so annoying.

553
00:23:51,292 --> 00:23:53,174
Like, contribute to the conversation,

554
00:23:53,274 --> 00:23:54,796
or like, at least contribute to the game,

555
00:23:54,816 --> 00:23:55,557
for crying out loud.

556
00:23:56,398 --> 00:23:58,420
So there's a point where we have enough is enough.

557
00:23:59,422 --> 00:24:01,382
And so they're actually vertical lines of two dimensions.

558
00:24:01,502 --> 00:24:03,223
One is the severity of the comment,

559
00:24:03,243 --> 00:24:05,544
and the other one is how frequently it's said.

560
00:24:05,984 --> 00:24:08,045
And for each age group or each demographic,

561
00:24:08,065 --> 00:24:10,326
you can draw a line and say, look, if it continues,

562
00:24:11,127 --> 00:24:13,267
I'm gonna draw a line in the sand and say enough is enough.

563
00:24:14,628 --> 00:24:16,429
And by doing that, you can break your users down

564
00:24:16,469 --> 00:24:17,429
into different kinds of groups.

565
00:24:17,469 --> 00:24:18,690
And so you know if you launch a game,

566
00:24:18,710 --> 00:24:20,290
the first thing, and you put chat there,

567
00:24:20,310 --> 00:24:21,731
the first thing a bunch of users are gonna do

568
00:24:21,791 --> 00:24:22,732
is they're gonna type in fuck.

569
00:24:23,735 --> 00:24:26,696
Because they want to know, does this system have a filter?

570
00:24:26,736 --> 00:24:28,297
What's this game for?

571
00:24:28,357 --> 00:24:29,697
What is the nature of this community?

572
00:24:29,757 --> 00:24:30,938
And most people do that because they're

573
00:24:30,958 --> 00:24:31,738
going to test the boundary.

574
00:24:31,758 --> 00:24:33,799
That's perfectly normal.

575
00:24:34,439 --> 00:24:36,440
And if they find out that they can't do that, they go, oh,

576
00:24:36,540 --> 00:24:38,741
this game is expected behavior of blah.

577
00:24:39,061 --> 00:24:41,302
And then most of them back off, and some of them are like, ooh,

578
00:24:41,522 --> 00:24:42,302
this is a mini game.

579
00:24:42,342 --> 00:24:43,062
Can I get around it?

580
00:24:43,702 --> 00:24:46,483
And so they keep pressing on, and they persevere.

581
00:24:47,859 --> 00:24:49,100
So you have different kinds of users

582
00:24:49,140 --> 00:24:50,260
and different kind of ways,

583
00:24:50,340 --> 00:24:52,282
but we can then take those users

584
00:24:52,462 --> 00:24:54,042
and we can deal with them differently.

585
00:24:55,023 --> 00:24:55,303
Thank you.

586
00:24:56,884 --> 00:24:58,665
So the way we deal with them differently

587
00:24:58,745 --> 00:25:00,166
is you take that line in the sand

588
00:25:00,206 --> 00:25:03,668
and anything that's above that line is blatantly obvious.

589
00:25:04,388 --> 00:25:05,969
Those are the things that you just don't say

590
00:25:05,989 --> 00:25:08,130
in that kind of context and automation can do that.

591
00:25:08,150 --> 00:25:10,151
So there's no need to crowdsource that comment

592
00:25:10,471 --> 00:25:13,953
and send your best users to look at the complete filth

593
00:25:13,973 --> 00:25:15,214
that you already know the answer for.

594
00:25:16,138 --> 00:25:19,060
So anything above your line, you just filter, block,

595
00:25:19,080 --> 00:25:19,841
whatever you want to do.

596
00:25:20,601 --> 00:25:21,982
Hell band, shadow band, whatever.

597
00:25:22,863 --> 00:25:24,123
The next thing that you want to do

598
00:25:24,263 --> 00:25:26,145
is the stuff that's just a little bit below the line,

599
00:25:26,165 --> 00:25:28,246
the stuff that's difficult for computers to find out,

600
00:25:28,706 --> 00:25:30,507
you want to have your humans help you with that.

601
00:25:30,527 --> 00:25:32,308
So you add a report mechanism, people report it.

602
00:25:32,328 --> 00:25:35,630
Well, if a human hates it and a computer's not sure about it,

603
00:25:35,670 --> 00:25:36,651
chances are it's not good.

604
00:25:36,691 --> 00:25:38,132
So you can auto-action that one as well.

605
00:25:38,952 --> 00:25:42,394
Now the only thing you're left with is the stuff that is subjective, the stuff that requires

606
00:25:42,434 --> 00:25:46,275
context, the stuff that's innuendo, the stuff that's difficult, and that's where you crowdsource

607
00:25:46,295 --> 00:25:46,735
your humans.

608
00:25:46,755 --> 00:25:51,117
And that's where a tribunal-like system becomes powerful because your humans feel valuable

609
00:25:51,157 --> 00:25:54,438
because they're dealing with a real problem and it's not the obvious and they're making

610
00:25:54,458 --> 00:25:56,259
a real contribution to the community.

611
00:25:57,557 --> 00:25:59,578
And then your trolls, the ones in the upper right hand corner,

612
00:25:59,638 --> 00:26:03,298
the ones that are defined as they keep ongoing, ongoing, ongoing, ongoing,

613
00:26:03,338 --> 00:26:05,779
won't stop, desire to destroy your community, get rid of them.

614
00:26:06,479 --> 00:26:09,460
Just expense it away because they're just going to cost you money.

615
00:26:11,800 --> 00:26:15,301
So I want to talk about how this is put out in real world situations.

616
00:26:15,341 --> 00:26:17,661
So recently, the great folks at Twitch,

617
00:26:18,281 --> 00:26:22,142
they implemented a system like this and they allowed for each channel.

618
00:26:23,301 --> 00:26:29,943
to set their own resilience level and say look for this the purpose of this community is going to draw the line here.

619
00:26:30,923 --> 00:26:38,245
And it's been incredibly well received it's amazing to watch the reception of people like yes finally this is so wonderful I wish everyone had this functionality.

620
00:26:39,725 --> 00:26:44,827
So kudos to twitch an amazing job on that product.

621
00:26:47,327 --> 00:26:50,628
So the 3 things that we can learn is that if.

622
00:26:51,965 --> 00:26:53,707
We take care of toxicity.

623
00:26:54,487 --> 00:26:55,148
We can make money.

624
00:26:55,188 --> 00:26:56,889
It was a $7 million difference

625
00:26:58,590 --> 00:27:00,111
in that one scenario that I was outlining.

626
00:27:01,092 --> 00:27:02,333
In addition, it'll help your brand.

627
00:27:02,933 --> 00:27:04,574
So if you wanna go and raise more money,

628
00:27:05,615 --> 00:27:07,556
if you wanna go and get more publicity,

629
00:27:07,596 --> 00:27:10,618
if you wanna have people share about your site

630
00:27:10,658 --> 00:27:11,599
and invite their friends into it

631
00:27:11,619 --> 00:27:14,241
so you don't have to buy those users, really, really good.

632
00:27:15,422 --> 00:27:17,503
We talked about, it began with the story of Club Penguin

633
00:27:17,523 --> 00:27:19,745
and how you can keep your users for a long, long time

634
00:27:19,805 --> 00:27:21,246
if they feel that place of belonging.

635
00:27:22,290 --> 00:27:24,512
But what's also really cool is when you launch your next game,

636
00:27:25,312 --> 00:27:28,235
you've got a massive user base that loves your brand,

637
00:27:28,956 --> 00:27:30,417
and they're going to come with you to the next one.

638
00:27:32,299 --> 00:27:33,120
So thank you for your time.

639
00:27:34,442 --> 00:27:43,824
I really, really appreciate it so from here we're going to take questions we're going to go out the hall down the side there's a little like place with a bunch things we can stand with take a whole bunch of questions there got some free shirts we can hand out.

640
00:27:44,625 --> 00:27:47,606
I got my team that can also help answer questions if you can't get a hold of me.

641
00:27:48,646 --> 00:27:53,447
In addition to that please fill out the survey and they told me a bunch of other stuff I'm supposed to do.

642
00:27:54,528 --> 00:27:55,648
Yeah, blah blah blah.

643
00:27:56,148 --> 00:27:59,649
Upload it to the Internet watch this share with your friends on the GDC vault.

644
00:27:59,689 --> 00:28:01,010
Okay, thank you for everyone for your help.

