1
00:00:06,578 --> 00:00:08,439
So to introduce myself, I'm Stephen McCauley.

2
00:00:09,640 --> 00:00:11,101
I'm a technical leader at Ubisoft Montreal.

3
00:00:11,781 --> 00:00:14,883
And I'm sort of the lucky guy standing up here today

4
00:00:14,943 --> 00:00:16,624
with a speaker's badge that gets to talk to you

5
00:00:16,664 --> 00:00:18,305
about all the cool rendering stuff we did.

6
00:00:19,706 --> 00:00:21,948
But really, you know, we have a big team at Ubisoft Montreal,

7
00:00:22,168 --> 00:00:24,049
and a game like Far Cry 4 is so big

8
00:00:24,089 --> 00:00:25,029
that it's a real team effort.

9
00:00:25,049 --> 00:00:26,931
So I'm going to try and make sure that I call out

10
00:00:27,271 --> 00:00:28,772
all the guys who worked on all the features

11
00:00:28,792 --> 00:00:29,832
I'm going to talk about today.

12
00:00:31,695 --> 00:00:36,119
So I joined Ubisoft to work on Far Cry 3.

13
00:00:36,619 --> 00:00:38,501
And this is a game that came out in 2012.

14
00:00:39,742 --> 00:00:40,363
It was really great.

15
00:00:40,423 --> 00:00:41,704
We actually found that loads of people liked it.

16
00:00:41,724 --> 00:00:43,565
It got a 90% Metacritic score.

17
00:00:45,187 --> 00:00:47,128
And when you're working on a game that's sort of game

18
00:00:47,168 --> 00:00:49,430
design is really fun, and you have a thing of really cool

19
00:00:49,450 --> 00:00:49,951
gameplay loop.

20
00:00:50,591 --> 00:00:55,597
It's pretty awesome when you get the chance to make a sequel and do Far Cry 4 based on that.

21
00:00:56,258 --> 00:01:00,042
So it's really cool as a graphics team as well, we're able to stick with a lot of the same people.

22
00:01:00,543 --> 00:01:02,826
So we knew the strengths of our engine and our weaknesses,

23
00:01:03,286 --> 00:01:05,729
and we knew exactly what we wanted to do to improve the engine.

24
00:01:05,970 --> 00:01:08,493
And it's obviously some of these improvements I'm going to go through today.

25
00:01:11,105 --> 00:01:13,407
So Far Cry 4, if you don't know much about it,

26
00:01:13,707 --> 00:01:15,389
it's an open-world first-person shooter.

27
00:01:16,811 --> 00:01:18,192
World about 10k by 10k.

28
00:01:18,272 --> 00:01:18,973
It's pretty big.

29
00:01:19,934 --> 00:01:21,355
We have a day-night cycle, as you'd

30
00:01:21,375 --> 00:01:22,556
expect for an open-world game.

31
00:01:23,277 --> 00:01:25,319
And with anything that's kind of dynamic time of day,

32
00:01:25,499 --> 00:01:27,041
as a graphics programmer, there's

33
00:01:27,081 --> 00:01:29,283
kind of really no hiding place.

34
00:01:31,045 --> 00:01:32,346
And we're setting Kherat, because that's

35
00:01:32,366 --> 00:01:33,587
a country based upon Nepal.

36
00:01:36,644 --> 00:01:42,087
We had cross-platform and cross-generation development, so we shipped for five platforms at a time, which was pretty tough.

37
00:01:42,747 --> 00:01:47,630
I mean, our mandate as a graphics team was to lead on current gen on Xbox One and PlayStation 4,

38
00:01:48,470 --> 00:01:52,393
and try to keep the last-gen version the same as what we shipped on Far Cry 3, because it did a really good job.

39
00:01:54,585 --> 00:01:58,169
It kind of gave us a lot of constraints, because we had to keep the last-gen version kind of running,

40
00:01:59,230 --> 00:02:01,792
which kind of affected a lot of our decisions throughout the project.

41
00:02:02,393 --> 00:02:04,835
And at the end of the project, as was kind of inevitable,

42
00:02:05,977 --> 00:02:09,080
like when we had to go back and optimize a few little bits about the PS3 and the 360.

43
00:02:11,062 --> 00:02:14,823
But in the end that kind of meant we had a better product on the Nesti 3 on all platforms.

44
00:02:15,943 --> 00:02:19,624
But really given our mandate as a graphics team was to develop new features for the new consoles,

45
00:02:20,205 --> 00:02:22,165
I'm really not going to talk exclusively about that kind of work,

46
00:02:22,545 --> 00:02:25,046
but I might throw a few tidbits in about the PS3 and 360 along the way.

47
00:02:28,838 --> 00:02:30,139
So what areas did we improve?

48
00:02:30,199 --> 00:02:31,660
Well, we kind of looked at five areas.

49
00:02:32,281 --> 00:02:35,102
So materials, lighting, vegetation,

50
00:02:35,402 --> 00:02:37,284
and anti-aliasing, and terrain.

51
00:02:37,764 --> 00:02:39,085
So I'm gonna cover the first four today.

52
00:02:39,365 --> 00:02:40,245
I'm not gonna talk about terrain,

53
00:02:40,265 --> 00:02:41,966
because hopefully you were all in Kar Chen's

54
00:02:42,006 --> 00:02:44,168
excellent talk just beforehand in the opposite room.

55
00:02:44,768 --> 00:02:46,789
And he talked about the virtual texturing work he developed.

56
00:02:47,210 --> 00:02:47,890
And if you didn't see it,

57
00:02:48,150 --> 00:02:49,251
make sure you go and check out the slides.

58
00:02:49,691 --> 00:02:50,712
It was really awesome work.

59
00:02:54,434 --> 00:02:56,255
So let's get started with materials.

60
00:02:59,088 --> 00:03:03,051
So, on Far Cry 3, I did a talk at SIGGRAPH 2012,

61
00:03:03,411 --> 00:03:06,574
talking about how we did some PhysiciBase shading stuff.

62
00:03:07,134 --> 00:03:09,516
We kind of had glossiness and reflectivity material parameters,

63
00:03:09,556 --> 00:03:11,537
and we only had a monochrome specular.

64
00:03:12,873 --> 00:03:17,294
As a bit of a side rant, I've kind of noticed nowadays this kind of definition of physically based keeps kind of changing.

65
00:03:17,775 --> 00:03:23,556
Like what I kind of consider physically based back in 2012 is now the old way of doing things and physically based now means

66
00:03:23,576 --> 00:03:26,097
you know layered material editors and other fancy things.

67
00:03:26,177 --> 00:03:30,699
So maybe we should talk about more and less physically based. It might be a bit more accurate kind of term.

68
00:03:32,679 --> 00:03:38,942
So the goal from Far Cry 3 was that we wanted to improve the appearance of our metals because we only had this monochrome specular reflectance

69
00:03:39,702 --> 00:03:41,283
Didn't look very good

70
00:03:41,523 --> 00:03:46,726
We couldn't get colored specular and if you look at something like the kind of concept art for a place like Nepal

71
00:03:46,746 --> 00:03:49,747
You'll see loads of gold and kind of bronze that we really wanted to bring out

72
00:03:51,087 --> 00:03:54,849
And also in a first-person shooter, you'll find the weapons cover quite a large portion of the screen

73
00:03:54,869 --> 00:03:58,751
So you can get your weapons looking really nice. You have at least part of the screen. That's gonna look pretty awesome

74
00:04:01,131 --> 00:04:04,013
So, like everybody else, we looked at the Disney model,

75
00:04:04,053 --> 00:04:04,953
nothing too original here.

76
00:04:05,753 --> 00:04:08,055
We took the anisotropic GGX BRDF

77
00:04:08,135 --> 00:04:10,136
and corresponding Smith geometry term

78
00:04:10,576 --> 00:04:12,577
and just used a standard Lombertian diffuse.

79
00:04:13,578 --> 00:04:15,079
We didn't look at other diffuse models,

80
00:04:15,099 --> 00:04:17,100
such as the Disney model, but really,

81
00:04:17,200 --> 00:04:18,741
I really struggled to see it's worth the cost

82
00:04:18,781 --> 00:04:21,482
at this moment in time, though, yeah, we'll keep looking.

83
00:04:22,543 --> 00:04:24,464
And we ended up with four parameters

84
00:04:24,504 --> 00:04:26,165
in this zero to one range.

85
00:04:26,505 --> 00:04:27,886
Again, really important, keep all your parameters

86
00:04:27,946 --> 00:04:30,227
in zero to one for artist intuitivity.

87
00:04:31,347 --> 00:04:34,369
So glossiness, reflectance, metallic, and anisotropy.

88
00:04:34,869 --> 00:04:36,710
So Disney call reflectance specular,

89
00:04:37,010 --> 00:04:38,291
and they call glossiness roughness,

90
00:04:38,331 --> 00:04:39,451
or inverse glossiness roughness.

91
00:04:40,772 --> 00:04:42,993
We stuck with glossiness for legacy reasons,

92
00:04:43,613 --> 00:04:45,394
for keep the Far Cry 3 kind of naming the same.

93
00:04:46,615 --> 00:04:47,595
And really what I'm gonna go across

94
00:04:47,715 --> 00:04:49,896
is just stay on to that bit into how we did anisotropy,

95
00:04:50,577 --> 00:04:52,938
and how we did like a metallic.

96
00:04:55,039 --> 00:04:55,119
So.

97
00:04:56,515 --> 00:04:59,055
Looks like a mechanic parameter, hopefully you all know about this by now.

98
00:04:59,455 --> 00:05:00,536
So, it's pretty simple.

99
00:05:01,096 --> 00:05:04,036
So, if you have this single float value that you can blend

100
00:05:04,697 --> 00:05:07,097
for your specular reflectance, you just blend from a monochrome value

101
00:05:07,597 --> 00:05:11,238
to your diffuse albedo, which really is then a kind of a specular albedo.

102
00:05:12,078 --> 00:05:13,979
At the same time, you blend out your diffuse albedo

103
00:05:13,999 --> 00:05:17,180
to make sure you get no diffuse lighting and lots of cool colored specular lighting.

104
00:05:18,800 --> 00:05:20,741
Simple, and it works really, really great.

105
00:05:20,761 --> 00:05:24,262
What it means is you just need a single channel in your G-buffer for colored specular,

106
00:05:24,282 --> 00:05:27,543
rather than having to store a whole other kind of three colored terms.

107
00:05:28,743 --> 00:05:32,384
And actually this is great because we could use this feature then for the old gen consoles as well,

108
00:05:32,584 --> 00:05:35,865
which got rid of the specular reflectance, fixed it at 0.03,

109
00:05:36,185 --> 00:05:38,786
and replaced the value in the G-buffer with a metallic instead.

110
00:05:41,234 --> 00:05:44,238
If you do this approach, though, you do need to give your artist a little bit of training.

111
00:05:44,258 --> 00:05:48,744
Because the behavior of your kind of diffused textures, which are no longer diffused really,

112
00:05:49,045 --> 00:05:51,108
it kind of changes with that use of the metallic value.

113
00:05:51,428 --> 00:05:52,850
And it can be a little bit confusing for people.

114
00:05:53,110 --> 00:05:56,115
Like, you kind of notice you're developing, say, a weapon, and you've got like a metal...

115
00:05:56,855 --> 00:06:00,297
a knife blade and, you know, like a, say, wooden handle.

116
00:06:00,857 --> 00:06:02,878
We will find in the texture, the wood looks quite dark,

117
00:06:02,958 --> 00:06:05,218
but the metal's all going to be really quite high in that range.

118
00:06:05,459 --> 00:06:07,699
So your artist might kind of want to kind of adjust them

119
00:06:07,759 --> 00:06:09,180
and kind of make them closer together.

120
00:06:09,560 --> 00:06:12,261
But we gave them some good Photoshop color swatches

121
00:06:12,301 --> 00:06:13,422
to make sure they kind of didn't do that

122
00:06:13,442 --> 00:06:14,362
and had some good guidelines.

123
00:06:14,882 --> 00:06:16,002
And, you know, after a couple of weeks,

124
00:06:16,022 --> 00:06:16,963
they really caught on pretty well,

125
00:06:17,003 --> 00:06:18,263
and they did some awesome kind of work.

126
00:06:22,479 --> 00:06:27,288
We also introduced anisotropy to get cooler brush metals and also for certain types of cloth.

127
00:06:27,989 --> 00:06:33,359
So, see how the anisotropy parameter increases there, across those spheres?

128
00:06:36,082 --> 00:06:38,565
So let's look at the anastropic ggx distribution formula,

129
00:06:38,945 --> 00:06:41,227
which is kind of long and confusing.

130
00:06:41,247 --> 00:06:43,009
This is a bit scary,

131
00:06:43,029 --> 00:06:44,210
because if we actually break this down,

132
00:06:44,230 --> 00:06:45,932
and we look at what we have to store in our gbuffer,

133
00:06:46,352 --> 00:06:48,454
well, we need two glossiness terms,

134
00:06:48,895 --> 00:06:51,157
plus a normal, tangent, and binormal.

135
00:06:51,677 --> 00:06:53,399
And that's really confusing then,

136
00:06:53,419 --> 00:06:54,921
because we have to pack a full tangent space

137
00:06:54,941 --> 00:06:58,244
into the gbuffer, and yeah,

138
00:06:58,284 --> 00:07:00,186
like, that's gonna take a lot of values, we think.

139
00:07:01,201 --> 00:07:04,973
But actually, we can actually borrow some ideas from animation programmers.

140
00:07:06,704 --> 00:07:08,965
And they wrote some interesting papers from Crytek

141
00:07:09,005 --> 00:07:11,145
and also Nicholas Frickholm on the BitSquid blog

142
00:07:11,585 --> 00:07:14,026
about storing tangent space as a quaternion.

143
00:07:14,566 --> 00:07:16,426
And they've kind of mastered the packing kind of for this.

144
00:07:16,466 --> 00:07:18,247
They want to get animation down nice and small.

145
00:07:18,267 --> 00:07:19,707
So what we're going to store,

146
00:07:19,727 --> 00:07:21,127
we're going to store a quaternion 10.10.10.2.

147
00:07:21,187 --> 00:07:25,188
We're going to store the three smallest components

148
00:07:25,308 --> 00:07:27,269
and they're in the range minus one over root two

149
00:07:27,369 --> 00:07:28,349
to one over root two,

150
00:07:28,369 --> 00:07:29,229
because if they're any bigger,

151
00:07:29,269 --> 00:07:30,490
they would be the biggest component.

152
00:07:31,710 --> 00:07:32,970
So we just need to do that.

153
00:07:33,010 --> 00:07:33,330
And that's great,

154
00:07:33,350 --> 00:07:35,111
because you can just pack those into zero to one range

155
00:07:35,131 --> 00:07:36,111
and we have to get more precision.

156
00:07:37,171 --> 00:07:41,614
And we also stored in that W component the index of the component we've dropped, the 0, 1, 2, or 3.

157
00:07:43,175 --> 00:07:49,979
You might be thinking, well, can't you just get away with storing X, Y, and Z in, say, 11, 11, 10, getting a bit more precision out, and reconstructing the W?

158
00:07:50,739 --> 00:07:56,843
Well, it turns out it doesn't work. You kind of lose a lot of precision, so you really need to actually drop this bigger component and reconstruct that one.

159
00:07:56,863 --> 00:07:59,885
And it turns out it's not too bad.

160
00:08:01,262 --> 00:08:02,283
You can kind of find the biggest component.

161
00:08:02,303 --> 00:08:03,443
It's actually only five instructions.

162
00:08:03,503 --> 00:08:05,884
If you use some kind of GCM-specific tricks.

163
00:08:06,605 --> 00:08:08,286
So it's kind of like a major access problem.

164
00:08:08,306 --> 00:08:10,727
So you already actually have the kubemap face ID instruction

165
00:08:10,767 --> 00:08:13,188
where you can just use that to get the major access

166
00:08:13,228 --> 00:08:14,128
out of the X, Y, and Z.

167
00:08:14,369 --> 00:08:16,109
And the max three to quickly help you get

168
00:08:16,230 --> 00:08:17,410
to whether the W is any bigger.

169
00:08:18,331 --> 00:08:20,291
And I'll put all the code for packing and unpacking

170
00:08:20,312 --> 00:08:24,233
quaternions in a G-buffer in the appendix to these slides.

171
00:08:24,293 --> 00:08:25,734
So you can go check all that out later

172
00:08:25,754 --> 00:08:26,935
when I release the slides next week.

173
00:08:28,335 --> 00:08:30,456
Um, what's the quality like?

174
00:08:30,496 --> 00:08:30,637
Well.

175
00:08:31,229 --> 00:08:32,330
I kind of worked out it's about

176
00:08:32,350 --> 00:08:34,873
quality equivalent to about a naive packing of normals and 888.

177
00:08:36,055 --> 00:08:37,977
You do get a bit of faceting on smooth surfaces, and

178
00:08:38,317 --> 00:08:41,121
we're kind of lucky on Far Cry, we don't really have that many smooth surfaces.

179
00:08:41,461 --> 00:08:43,604
But if your game is kind of like that, you might want to look again.

180
00:08:46,275 --> 00:08:49,098
I mean, overall, I mean, the problems you're going to get, you're going to have problems again,

181
00:08:49,118 --> 00:08:51,219
with what I said, the quality of the normals, they could be a bit higher.

182
00:08:51,700 --> 00:08:55,023
I do think there's a bit more research to be done here, whether we can use those 10 bits a bit better

183
00:08:55,063 --> 00:08:57,465
to distribute the kind of values better, to get precision where it's needed.

184
00:08:58,706 --> 00:09:00,887
You also can only store orthonormal tangent space.

185
00:09:01,978 --> 00:09:07,881
Now, that's actually so bad, because actually we don't have orthonormal tangent space for normal maps in Far Cry.

186
00:09:08,782 --> 00:09:12,264
But what we construct for the actual anisotropic shading is orthonormal.

187
00:09:12,284 --> 00:09:16,105
So you can kind of make those two different tangent spaces, and it actually works out okay.

188
00:09:17,286 --> 00:09:20,087
It might be a problem if you want to do something like lean mapping, which is kind of our initial plan,

189
00:09:20,828 --> 00:09:21,848
but we weren't, so that's okay.

190
00:09:23,609 --> 00:09:26,030
Obviously we'd like to make the speed of the packing and unpacking a little bit quicker,

191
00:09:26,090 --> 00:09:28,692
but you know, it never really came up much in our profiling once we optimized it.

192
00:09:31,577 --> 00:09:34,020
The main problem really we had was how to blend decals,

193
00:09:34,040 --> 00:09:36,302
because obviously now once you're doing something like a quaternion,

194
00:09:36,342 --> 00:09:37,944
you can't just do some simple alpha blending.

195
00:09:39,846 --> 00:09:41,468
So we only supported one layer of decals,

196
00:09:41,488 --> 00:09:42,989
and that was an art kind of restriction,

197
00:09:43,029 --> 00:09:46,453
and we had to kind of read back the current normal quaternion buffer,

198
00:09:46,773 --> 00:09:47,834
and then reconstruct things from that.

199
00:09:50,002 --> 00:09:55,906
What was cool though is actually how it worked well is with the virtual textures because all our decals on the terrain were stored in a virtual texturing.

200
00:09:56,366 --> 00:09:59,408
So it wasn't actually a problem for us at all on that. It was only on kind of buildings.

201
00:09:59,428 --> 00:10:05,452
It was kind of a nice thing about two different techniques working together and if our game was all like virtual textured, it kind of meant this problem went away for us.

202
00:10:08,925 --> 00:10:11,366
Um, for reflections, well, it's a little bit trickier.

203
00:10:11,386 --> 00:10:13,627
We'd love to do important sampling or something into a key map

204
00:10:13,647 --> 00:10:15,147
to get some awesome results, but we can't.

205
00:10:15,748 --> 00:10:18,008
So I'm kind of really grateful, actually, to, um, it was Matt Patino

206
00:10:18,028 --> 00:10:20,069
who brought, uh, Don Reavy's article in, I think, a GPO,

207
00:10:20,569 --> 00:10:22,490
GPU Pro 1 or 2, to my attention,

208
00:10:22,830 --> 00:10:24,891
about, uh, doing some, like, anisotropy and deferred shading.

209
00:10:25,211 --> 00:10:27,632
He just did a simple trick to distort the, uh, reflection vector

210
00:10:27,692 --> 00:10:28,633
in a different direction.

211
00:10:28,653 --> 00:10:31,434
And actually, you know, it's not perfect, but it looks pretty good.

212
00:10:32,214 --> 00:10:34,475
So, you know, on the, uh, left, we've got non-anisotropy.

213
00:10:34,895 --> 00:10:40,782
In the middle is kind of what we had originally, where we had this anisotropic highlight and anisotropic reflection, which is a bit kind of broken.

214
00:10:41,422 --> 00:10:46,968
And then on the right we have what happens when you actually do this little trick for the anisotropic reflection.

215
00:10:47,909 --> 00:10:52,013
Again, it's kind of not perfect, but you know, it's kind of a hell of a lot better than doing nothing at all.

216
00:10:55,294 --> 00:10:56,955
I really like showing pictures of these knives,

217
00:10:56,975 --> 00:10:58,395
I think our weapons team did an awesome job,

218
00:10:58,456 --> 00:11:00,176
and you know what, they used anisotropy everywhere,

219
00:11:00,196 --> 00:11:00,656
they loved it.

220
00:11:01,257 --> 00:11:02,237
And it's kind of really interesting,

221
00:11:02,277 --> 00:11:04,298
because it solved a problem we had on Far Cry 3,

222
00:11:04,338 --> 00:11:05,659
where these guys, this weapons team,

223
00:11:05,679 --> 00:11:06,979
they keep coming up to us and say,

224
00:11:07,379 --> 00:11:09,520
we really want some fake specular on our weapons.

225
00:11:10,081 --> 00:11:11,181
And we kind of say, no, no, no,

226
00:11:11,201 --> 00:11:13,182
we want to be physically based, no fake specular at all.

227
00:11:13,762 --> 00:11:15,263
And then we gave them this anisotropy,

228
00:11:15,383 --> 00:11:17,004
and that complaint just completely went away.

229
00:11:17,164 --> 00:11:18,604
They always felt they saw some glint,

230
00:11:18,665 --> 00:11:19,305
or some kind of like,

231
00:11:19,465 --> 00:11:20,886
something interesting going on in the weapons.

232
00:11:22,905 --> 00:11:26,309
So it's kind of made perhaps this fake spec that they wanted after all was actually just brushed metal.

233
00:11:26,329 --> 00:11:27,511
That's actually what they were looking at.

234
00:11:27,771 --> 00:11:29,854
And now we've kind of replicated the real world a little bit better.

235
00:11:29,874 --> 00:11:31,436
We've supported a wider range of materials.

236
00:11:31,856 --> 00:11:32,738
They can get what they want.

237
00:11:37,244 --> 00:11:38,926
So next topic is going to be our lighting.

238
00:11:40,266 --> 00:11:41,948
So there's kind of three improvements we wanted to make.

239
00:11:42,868 --> 00:11:44,750
The first was kind of our sky occlusion system.

240
00:11:44,770 --> 00:11:46,411
We wanted to kind of increase the resolution of that

241
00:11:46,852 --> 00:11:48,313
and the system that Jeremy Moore worked on.

242
00:11:48,934 --> 00:11:50,075
We also had our environment maps,

243
00:11:50,375 --> 00:11:51,596
where we wanted to make sure that they could

244
00:11:51,636 --> 00:11:52,997
deal better with time of day changes.

245
00:11:53,017 --> 00:11:55,159
And that's something developed by Gabriel Lassonde.

246
00:11:55,520 --> 00:11:57,141
And finally, we looked at the indirect lighting.

247
00:11:58,282 --> 00:11:59,723
We wanted to kind of extend our range

248
00:11:59,743 --> 00:12:01,064
beyond this kind of loading ring we have,

249
00:12:01,185 --> 00:12:03,286
so further out to about far in the distance.

250
00:12:03,727 --> 00:12:05,108
And we wanted a faster update as well

251
00:12:05,128 --> 00:12:06,790
from Far Cry 3 to prevent flickering errors.

252
00:12:11,417 --> 00:12:13,819
So let's start with our sky lighting model.

253
00:12:13,859 --> 00:12:15,640
Well, we use the Bruneton sky model

254
00:12:15,740 --> 00:12:16,641
and the pre-term sun model.

255
00:12:16,921 --> 00:12:17,882
This is something that actually developed

256
00:12:17,902 --> 00:12:20,424
by Assassin's Creed Unity that we managed to take

257
00:12:20,744 --> 00:12:21,845
and it worked really well for us.

258
00:12:21,885 --> 00:12:22,746
We kind of really liked it.

259
00:12:23,286 --> 00:12:24,347
And once you've got the sky model,

260
00:12:24,367 --> 00:12:26,068
we just need to generate the lighting

261
00:12:26,108 --> 00:12:27,309
in third order spherical harmonics.

262
00:12:28,090 --> 00:12:28,730
So that's pretty cool.

263
00:12:31,499 --> 00:12:36,825
So, why we went to Far Cry 3 was that we had stored our skylighting in light probes along with our indirect lighting.

264
00:12:36,845 --> 00:12:41,671
The problem is that our indirect lighting was based on probes spaced at over 8 meters,

265
00:12:41,932 --> 00:12:43,594
which is quite low resolution and we thought, hey,

266
00:12:44,475 --> 00:12:49,622
GI is kind of a difficult problem to solve, so hey, why don't we just increase the sky resolution, that's something we can definitely do.

267
00:12:50,602 --> 00:12:54,564
So we started to separate out our skylighting, direct skylighting from the indirect lighting.

268
00:12:55,145 --> 00:12:59,647
And we did something, the simple trick I think a lot of games have done, Assassin's Creed, I think CryEngine has it in.

269
00:12:59,947 --> 00:13:04,729
We have this just top-down sky occlusion map generated from a height field over the entire scene.

270
00:13:05,249 --> 00:13:09,051
And we make sure we actually generate visibility and second-order spherical harmonics from this height field.

271
00:13:12,680 --> 00:13:14,621
So the high field is kind of rendered on demand,

272
00:13:14,661 --> 00:13:15,662
but it's not something we stream in.

273
00:13:15,682 --> 00:13:19,064
So our world is split into 64 by 64 meter sectors,

274
00:13:19,504 --> 00:13:21,025
and whenever a sector becomes visible,

275
00:13:21,205 --> 00:13:23,606
we're just gonna render the high field of that.

276
00:13:24,127 --> 00:13:24,767
It's really, really quick,

277
00:13:24,867 --> 00:13:25,948
means we have no streaming cost,

278
00:13:26,668 --> 00:13:28,209
and it means we get quite a high resolution as well

279
00:13:28,249 --> 00:13:29,690
of 25 centimeters per texel.

280
00:13:30,410 --> 00:13:31,451
And we kind of blur this then

281
00:13:31,771 --> 00:13:33,432
before we generate the SH of visibility.

282
00:13:36,036 --> 00:13:37,497
I mean the visibility is kind of quite simple to do.

283
00:13:37,517 --> 00:13:39,557
Let's just take an SSEO kind of style approach.

284
00:13:40,058 --> 00:13:41,958
We just need to sample our kind of blurred height field

285
00:13:41,978 --> 00:13:43,259
with a rotated Poisson disk,

286
00:13:43,739 --> 00:13:45,720
store the proportion of the visible samples,

287
00:13:46,300 --> 00:13:48,541
actually just sum the directions of the visible samples

288
00:13:48,561 --> 00:13:49,782
then to get the directionality out.

289
00:13:54,644 --> 00:13:55,844
Once we've got that, we've got the direction

290
00:13:55,864 --> 00:13:56,805
and we've got the visibility,

291
00:13:57,125 --> 00:13:58,685
we just need to convert that into spherical harmonics.

292
00:13:58,786 --> 00:14:00,626
So what we're gonna do is just create a spherical cap

293
00:14:00,806 --> 00:14:01,647
based upon the kind of the up normal

294
00:14:01,667 --> 00:14:02,927
and then we're just gonna rotate

295
00:14:02,947 --> 00:14:04,168
into the direction that we need.

296
00:14:07,852 --> 00:14:08,792
So how do we apply this?

297
00:14:09,212 --> 00:14:11,013
Well, what we're gonna do in the deferred lighting,

298
00:14:11,033 --> 00:14:13,694
we're gonna sample this kind of SH sky occlusion texture.

299
00:14:13,714 --> 00:14:16,135
We're gonna do some tricks.

300
00:14:16,195 --> 00:14:17,055
Obviously this is kind of 2D,

301
00:14:17,095 --> 00:14:19,436
and we actually need to kind of modify things

302
00:14:19,456 --> 00:14:20,777
based upon our height above the terrain.

303
00:14:21,157 --> 00:14:22,998
So remember crawl, we have actually a blurred height field.

304
00:14:23,018 --> 00:14:24,619
So if there's something at the terrain height,

305
00:14:24,639 --> 00:14:27,120
we're gonna have this full, use full SH occlusion.

306
00:14:27,720 --> 00:14:29,501
And then as we blend up to something

307
00:14:29,541 --> 00:14:30,981
in the height of the blurred height field,

308
00:14:31,221 --> 00:14:32,362
well, we're just gonna kind of fade out

309
00:14:32,382 --> 00:14:33,182
to something fully visible.

310
00:14:33,202 --> 00:14:35,743
Gives you something that looks kind of 3D.

311
00:14:37,231 --> 00:14:40,232
Then once you have the primary visibility direction from SH,

312
00:14:40,272 --> 00:14:42,073
we can just construct a bent normal out of that.

313
00:14:42,993 --> 00:14:44,374
And we just need to then sample our

314
00:14:44,874 --> 00:14:48,096
second order SH visibility and the third order SH skylighting

315
00:14:48,376 --> 00:14:50,657
in this bent normal direction and just multiply them together.

316
00:14:51,677 --> 00:14:53,298
And we did look at using SH product here,

317
00:14:53,358 --> 00:14:56,359
but we kind of found it was a bit low res, I think, in the end.

318
00:15:03,289 --> 00:15:05,190
So just here's some code, quick code to bending the normal.

319
00:15:05,470 --> 00:15:06,930
So you just need to get the primary direction out.

320
00:15:07,931 --> 00:15:11,352
Scale it based upon the kind of the zeroth band of the SH,

321
00:15:12,072 --> 00:15:15,594
and then add that into our existing normal and renormalize.

322
00:15:17,874 --> 00:15:19,015
So let's look at some pictures.

323
00:15:20,895 --> 00:15:22,576
So this is kind of a scene without sky occlusion.

324
00:15:22,596 --> 00:15:24,717
I mean, even so, I think it shows some nice stuff

325
00:15:24,737 --> 00:15:26,597
with having like kind of cool skylighting, right?

326
00:15:26,637 --> 00:15:27,678
Can you look at the buildings,

327
00:15:27,698 --> 00:15:30,759
you can see different kind of shades on different faces.

328
00:15:32,429 --> 00:15:34,430
Here's how it happens if you add the sky occlusion in.

329
00:15:35,090 --> 00:15:36,131
Everything starts looking a lot better.

330
00:15:36,151 --> 00:15:37,431
It's still perfect.

331
00:15:37,451 --> 00:15:38,052
I mean, you can't notice,

332
00:15:38,072 --> 00:15:39,372
you can actually have quite a harsh fall off.

333
00:15:39,632 --> 00:15:40,573
That was actually art directed.

334
00:15:40,633 --> 00:15:42,153
We had a few tweaks in there to get it looking

335
00:15:42,173 --> 00:15:43,354
for how art direction wanted.

336
00:15:45,075 --> 00:15:46,255
And what's really cool is when we added

337
00:15:46,275 --> 00:15:47,316
the bent normals in as well.

338
00:15:47,556 --> 00:15:48,696
And what you might see, if you look, say,

339
00:15:48,716 --> 00:15:51,377
around the building, just between the building

340
00:15:51,397 --> 00:15:52,578
and the ground, obviously you can see

341
00:15:52,678 --> 00:15:53,578
very disparate lighting.

342
00:15:53,918 --> 00:15:55,919
You add the bent normals in, it really softens that out.

343
00:15:56,760 --> 00:15:59,201
So, something like that.

344
00:16:00,222 --> 00:16:02,263
Doesn't look quite as good on the big screen as it does on the monitor.

345
00:16:02,383 --> 00:16:04,444
So look at the slides later and you'll see, but I'll do that again.

346
00:16:05,624 --> 00:16:05,804
So.

347
00:16:07,205 --> 00:16:08,705
Yeah, just kind of gives a little bit of softness,

348
00:16:08,905 --> 00:16:11,146
a little bit unifies everything a little bit more in the scene.

349
00:16:11,166 --> 00:16:13,107
And Art Direction really liked that because they felt that things,

350
00:16:13,487 --> 00:16:14,947
sometimes, where the buildings join the ground,

351
00:16:15,328 --> 00:16:17,028
just they felt that things didn't look quite right.

352
00:16:20,569 --> 00:16:21,350
So environment maps.

353
00:16:22,050 --> 00:16:23,370
So let's ask ourselves this question.

354
00:16:23,390 --> 00:16:25,371
So how can we get a single key map to have

355
00:16:25,571 --> 00:16:27,712
the right intensity at every single time of day?

356
00:16:28,292 --> 00:16:28,372
Um.

357
00:16:29,645 --> 00:16:32,748
Well, one idea, of course, is why don't we just relight our keymap every frame?

358
00:16:34,529 --> 00:16:38,653
So, what we need to do to do that, well, relighting is something we're kind of good at doing.

359
00:16:38,753 --> 00:16:40,995
We kind of store gbuffers in our deferred lighting.

360
00:16:41,055 --> 00:16:43,437
So why don't we do something like that for our keymaps, where what we'll do,

361
00:16:44,498 --> 00:16:47,801
we're going to bake offline keymaps and store, instead of a fully lit kind of thing,

362
00:16:47,821 --> 00:16:49,042
we're going to store a gbuffer.

363
00:16:49,062 --> 00:16:51,184
We're going to store an albedo and we're going to store a normal.

364
00:16:52,504 --> 00:16:54,847
Then what we need to do in our kind of frame,

365
00:16:55,688 --> 00:16:57,309
we're gonna insert those along with a kind of

366
00:16:57,329 --> 00:16:58,871
a real-time generated sky texture

367
00:16:58,911 --> 00:17:01,574
to fill in those black albedo pixels.

368
00:17:02,215 --> 00:17:03,576
And we'll insert that into a lighting path,

369
00:17:04,057 --> 00:17:05,818
light based upon our sun and our sky lighting.

370
00:17:06,779 --> 00:17:08,661
Then we need to take that and do our pre-filtering

371
00:17:08,722 --> 00:17:10,924
so we can have the BRDF, GRGX BRDF,

372
00:17:11,324 --> 00:17:12,225
they're built in there.

373
00:17:12,746 --> 00:17:13,667
And then we're gonna get a final

374
00:17:13,887 --> 00:17:14,968
relit key map as a result.

375
00:17:18,633 --> 00:17:26,158
So how do the lighting? Well, we do our sun and sky lighting without any shadowing or occlusion because this is a required depth buffer. We decided to kind of save the memory.

376
00:17:28,917 --> 00:17:32,981
I think in the future we probably want to add that depth of back in so we can get world position out and

377
00:17:33,181 --> 00:17:35,423
I think it would help, definitely help improve things.

378
00:17:36,744 --> 00:17:40,066
We also get the indirect lighting from the nearest probe and we

379
00:17:40,807 --> 00:17:43,309
normalize everything again with the luminance of the ambient term.

380
00:17:44,390 --> 00:17:47,432
On Far Cry 3 we were normalizing our keymaps by the color of the ambience.

381
00:17:47,733 --> 00:17:50,315
It turned out actually that introduced loads of banding and color distortion

382
00:17:51,075 --> 00:17:53,057
and just normalizing the luminance works a lot better.

383
00:17:56,710 --> 00:17:58,272
So, here's the results.

384
00:17:59,232 --> 00:18:01,114
What's really cool, you can obviously see we have a real-time sky.

385
00:18:01,234 --> 00:18:03,516
There's no clouds in there, but you could have some fancy clouds moving.

386
00:18:03,756 --> 00:18:07,279
But you can see the sun moving across the sky.

387
00:18:08,240 --> 00:18:10,582
You can see that kind of in the mountains there in the distance.

388
00:18:10,642 --> 00:18:12,743
You can see how the lighting's shifting on those.

389
00:18:13,064 --> 00:18:15,846
And of course, obviously, you can see how the ground changes lighting at different times.

390
00:18:19,059 --> 00:18:22,324
Obviously though, we need to talk about the filtering, because it's really important we do this.

391
00:18:22,344 --> 00:18:24,947
So what we're going to need to do for successive MIP levels,

392
00:18:24,967 --> 00:18:28,692
we need to sample our GDX distribution and do some importance sampling.

393
00:18:30,254 --> 00:18:31,916
Just on its own, it's a little bit kind of slow.

394
00:18:32,857 --> 00:18:35,118
It's really, really key to use a filter in importance sampling.

395
00:18:35,178 --> 00:18:36,179
It was done in GPU Gems 2.

396
00:18:36,219 --> 00:18:40,180
It turned out that I think Seb Lagarde and Charles Derousier at Dice

397
00:18:40,200 --> 00:18:43,802
had the same idea and they kind of talked about this before me at SIGGRAPH last year.

398
00:18:44,842 --> 00:18:46,403
We came up with the same thing. It's the right thing to do.

399
00:18:46,423 --> 00:18:49,564
I found it's really important to match your keymap faces together

400
00:18:49,604 --> 00:18:51,125
in your compute paths to better occupancy.

401
00:18:51,965 --> 00:18:53,606
Obviously, if you're doing a 4x4 keymap face

402
00:18:53,626 --> 00:18:54,967
and you're sending that individually to the GPU,

403
00:18:55,007 --> 00:18:56,948
you're going to have a lot of wasted performance.

404
00:18:57,948 --> 00:18:59,608
And also if your hardware supports it, it's really cool.

405
00:18:59,648 --> 00:19:01,049
You can batch NIP levels together as well.

406
00:19:01,089 --> 00:19:02,809
Then you're going to really fill the GPU up with work.

407
00:19:04,889 --> 00:19:06,650
Turned out that all this all was actually pretty quick.

408
00:19:08,290 --> 00:19:09,210
Oh, yeah, filtering results.

409
00:19:09,750 --> 00:19:10,090
There you go.

410
00:19:10,790 --> 00:19:11,150
It works.

411
00:19:12,771 --> 00:19:14,231
So yeah, really, really quick.

412
00:19:14,291 --> 00:19:18,152
So we had 128 by 128 key maps with HDR key maps.

413
00:19:19,512 --> 00:19:22,153
Lighting, again, really quick NIP generation, quick

414
00:19:22,413 --> 00:19:24,773
filtering, a little bit slower, but still really, really

415
00:19:24,793 --> 00:19:25,153
reasonable.

416
00:19:27,262 --> 00:19:28,302
We have bandwidth found here.

417
00:19:28,322 --> 00:19:30,884
David Cook from Microsoft has suggested that we look at

418
00:19:30,964 --> 00:19:34,786
using R11, G11, B10 formats that might

419
00:19:35,006 --> 00:19:36,367
help speed things up.

420
00:19:36,547 --> 00:19:36,967
That's true.

421
00:19:37,187 --> 00:19:39,008
If we can deal with that for the precision issues, I hope

422
00:19:39,048 --> 00:19:40,689
these times will go down a lot further as well.

423
00:19:45,743 --> 00:19:48,765
So indirect lighting, our third kind of lighting improvement

424
00:19:48,785 --> 00:19:50,045
we wanted to make for Far Cry 4.

425
00:19:51,646 --> 00:19:53,087
So we have started off with a really cool system.

426
00:19:53,848 --> 00:19:55,269
If you were at GDC three years ago,

427
00:19:55,289 --> 00:19:58,551
you might have seen Nikolai Stepanov and Mikhail Zhilobar

428
00:19:58,611 --> 00:20:00,572
talk about deferred radiance transfer volumes

429
00:20:00,592 --> 00:20:02,093
that they developed for Far Cry 3.

430
00:20:03,494 --> 00:20:05,515
So these were light probes placed at various points

431
00:20:05,555 --> 00:20:07,976
in the scene that stored radiance transfer information.

432
00:20:10,338 --> 00:20:12,199
We came to looking at what we wanted to do for this system.

433
00:20:12,299 --> 00:20:13,099
We had a number of goals.

434
00:20:14,088 --> 00:20:21,390
Again, with this limitation of being this kind of cross-generational game, we decided, right, we actually want to stick with the same light probe set for kind of last gen and current gen.

435
00:20:22,350 --> 00:20:31,672
We really wanted to extend the range of the indirect lighting out, because in Far Cry 3 it was kind of stuck at around, I don't know, 64 meters around the camera, and we really wanted that to go further, because you can really see that kind of destroying.

436
00:20:31,712 --> 00:20:36,353
And we really wanted to have faster updates as well, and moving all the CPU work onto the GPU.

437
00:20:40,174 --> 00:20:41,695
So here's an overview of what we do.

438
00:20:42,396 --> 00:20:44,318
So offline, we're going to bake some probes.

439
00:20:45,078 --> 00:20:45,819
And we're going to bake this,

440
00:20:45,839 --> 00:20:47,520
then we're going to store radiance transfer information

441
00:20:47,540 --> 00:20:48,501
in second-order SH.

442
00:20:48,982 --> 00:20:50,803
So that's going to be three 4x4 matrices.

443
00:20:52,064 --> 00:20:53,866
On the CPU, we're going to stream this probe data in.

444
00:20:54,426 --> 00:20:55,707
We're going to upload it to the GPU,

445
00:20:55,827 --> 00:20:57,149
and we're going to update our page table.

446
00:20:58,129 --> 00:21:00,111
On the GPU, we're going to calculate our radiance transfer,

447
00:21:00,131 --> 00:21:01,712
and then we're going to inject our probes

448
00:21:01,792 --> 00:21:03,994
into the clip map and sample the deferred lighting.

449
00:21:04,955 --> 00:21:05,876
So I'm going to step through some of these

450
00:21:05,896 --> 00:21:06,556
in a little more detail.

451
00:21:09,429 --> 00:21:13,310
So, our world, as I said before, is split into 64 by 64 meter sectors.

452
00:21:14,031 --> 00:21:15,311
And probes are stored in cells.

453
00:21:16,612 --> 00:21:18,512
In each cell we have a grid of 8 by 8 probes.

454
00:21:19,553 --> 00:21:23,234
So, we're going to bake our highest level data, so just the top level of probes,

455
00:21:23,754 --> 00:21:25,015
where we have one sector per cell.

456
00:21:25,795 --> 00:21:28,916
And then we're going to generate MIPS from that, so you have MIPS data, five levels of MIPS data.

457
00:21:33,965 --> 00:21:36,728
So what's in a cell? Well, it's a radiance transfer probe list.

458
00:21:36,808 --> 00:21:39,130
So it's 64 probes, again, in this 8x8 regular grid.

459
00:21:39,831 --> 00:21:42,133
We also need to store our SH probe list as well.

460
00:21:43,334 --> 00:21:44,695
So this is going to be the final probe.

461
00:21:44,775 --> 00:21:46,257
After they've gone through the radiance transfer,

462
00:21:46,277 --> 00:21:47,898
they've gone through this kind of relighting process.

463
00:21:47,918 --> 00:21:50,921
We need to store that as well, and that's done once per frame.

464
00:21:51,482 --> 00:21:53,063
We also need to store the dimensions of the cell.

465
00:21:53,163 --> 00:21:55,846
So what MIP level are we? What size is it?

466
00:21:56,086 --> 00:21:56,847
Where are you in the world?

467
00:22:00,273 --> 00:22:05,035
And obviously once we've got all these cells, the thing is, we can't have these kind of buffers stored individually in GP memory.

468
00:22:05,055 --> 00:22:08,996
We can't have like a buffer put just in one structured buffer for radius transfer probes per cell.

469
00:22:09,016 --> 00:22:11,796
Again, it's not going to be really slow because you're working on small sets of data.

470
00:22:11,816 --> 00:22:14,637
What we need to do is come from virtualization to have one big list.

471
00:22:15,377 --> 00:22:19,258
So, that's what we're going to do. We're going to allocate this big, thick, size list of cells.

472
00:22:20,039 --> 00:22:21,819
Um, and...

473
00:22:23,022 --> 00:22:25,963
We're going to break that into a fixed number of cells allocated for each MIP.

474
00:22:26,503 --> 00:22:32,024
So in our case, we have 80 cells in total, 5 MIP levels, and that's 16 cells per MIP.

475
00:22:34,184 --> 00:22:36,305
As we were saying, along using the virtual buffer stuff here,

476
00:22:36,605 --> 00:22:39,205
we're not using any PRT hardware, so don't worry about that.

477
00:22:39,425 --> 00:22:40,225
It's all done in software.

478
00:22:42,866 --> 00:22:44,606
So as a cell is streamed in on the CPU,

479
00:22:45,006 --> 00:22:47,647
well, if a free cell is available for that MIP level on the GPU,

480
00:22:47,687 --> 00:22:48,707
well, we're just going to allocate.

481
00:22:50,395 --> 00:22:53,297
If no cell is available, then we just need to discard a more distant cell.

482
00:22:54,078 --> 00:22:55,859
Then, as a cell is streamed out on the CPU,

483
00:22:55,959 --> 00:22:58,721
we always need to mark the cell as free on the GPU.

484
00:22:59,301 --> 00:22:59,921
It's pretty simple.

485
00:23:03,003 --> 00:23:05,165
And what's cool, because we have this big long virtual buffer list,

486
00:23:05,305 --> 00:23:08,167
we now can perform, like, the radius transfer all at once,

487
00:23:08,907 --> 00:23:09,748
really fill up the GPU.

488
00:23:10,048 --> 00:23:10,748
It's really, really quick.

489
00:23:11,289 --> 00:23:13,170
So just insert our sunlight and our skylight,

490
00:23:14,330 --> 00:23:17,072
take a list, and output some SH probes at the end.

491
00:23:17,292 --> 00:23:18,913
And these are the final probes we're going to use for lighting.

492
00:23:21,888 --> 00:23:23,409
So let's talk a bit about our page table.

493
00:23:23,609 --> 00:23:25,330
So each MIP level actually has a page table.

494
00:23:27,651 --> 00:23:30,452
And these are kind of spatially indexed in a 2D grid

495
00:23:30,472 --> 00:23:31,312
on the XY plane.

496
00:23:33,233 --> 00:23:35,434
And this kind of page table covers the entire world.

497
00:23:35,454 --> 00:23:37,534
What we're going to do on the CPU, we have all these page

498
00:23:37,554 --> 00:23:38,395
tables, MIP for MIP.

499
00:23:38,475 --> 00:23:40,676
And we're just going to combine them into one, kind of

500
00:23:40,716 --> 00:23:41,636
filling in all the gaps.

501
00:23:41,936 --> 00:23:45,838
So in the end, we have this kind of page table, which

502
00:23:45,858 --> 00:23:48,058
contains all the data for every cell in the world.

503
00:23:51,752 --> 00:23:54,433
So the final page table is 160 by 160 sectors,

504
00:23:54,733 --> 00:23:56,034
at the highest MIP-level resolution.

505
00:23:58,115 --> 00:23:58,755
And what do you need to do

506
00:23:58,775 --> 00:23:59,936
if you want to sample a light probe?

507
00:24:00,056 --> 00:24:01,537
Well, what you need to do,

508
00:24:01,557 --> 00:24:03,278
we just need to sample into the page table

509
00:24:03,318 --> 00:24:04,978
to find our index into the cell list.

510
00:24:05,319 --> 00:24:06,839
So what cell are we currently, uh,

511
00:24:07,159 --> 00:24:08,480
is our lighting data currently stored at?

512
00:24:09,100 --> 00:24:10,261
We don't care what MIP-level it is.

513
00:24:12,302 --> 00:24:13,863
From the cell, once we know what cell we're in,

514
00:24:13,883 --> 00:24:15,504
well, we can calculate from our world position

515
00:24:15,984 --> 00:24:18,185
what probe index in that cell we need to look at,

516
00:24:18,885 --> 00:24:19,886
and we just need to fetch the probe.

517
00:24:29,327 --> 00:24:31,989
Now, that's great and all, but obviously that's not going to have any filtering,

518
00:24:32,249 --> 00:24:34,630
especially not between MIP levels and not between individual probes,

519
00:24:34,710 --> 00:24:35,551
so it's not too great.

520
00:24:36,091 --> 00:24:39,513
And it's actually quite slow to do that lookup for every pixel on the screen,

521
00:24:39,553 --> 00:24:40,293
so we don't want to do that.

522
00:24:40,313 --> 00:24:42,975
So what we're going to do instead, we're actually going to inject our probes

523
00:24:43,015 --> 00:24:43,735
into a 32x32x5 clip map.

524
00:24:45,995 --> 00:24:47,997
So that's like a 32 by 32 texture array,

525
00:24:48,137 --> 00:24:51,599
five array levels, and obviously the same size

526
00:24:51,639 --> 00:24:54,341
because each 32 by 32 is covering a larger area

527
00:24:54,361 --> 00:24:54,781
in the world.

528
00:24:55,542 --> 00:24:57,283
And these are centered about the camera,

529
00:24:57,723 --> 00:24:59,724
and the three of these textures are so we can store

530
00:24:59,764 --> 00:25:01,125
the 12 SH coefficients we need.

531
00:25:02,186 --> 00:25:03,567
So to sample, in the end of the day,

532
00:25:03,587 --> 00:25:05,408
we just need to find what cascade our pixel is in.

533
00:25:06,108 --> 00:25:08,370
We just calculate the UVs for that pixel,

534
00:25:08,390 --> 00:25:11,232
for cascades, the current cascade,

535
00:25:11,312 --> 00:25:12,653
and also the next level cascade down.

536
00:25:13,013 --> 00:25:14,834
And we can sample both of them and just blend together

537
00:25:14,854 --> 00:25:15,595
based upon the distance.

538
00:25:19,362 --> 00:25:20,925
So let's look at kind of what performance we kind of have.

539
00:25:21,627 --> 00:25:21,727
So...

540
00:25:23,812 --> 00:25:24,893
Memory is pretty low, obviously.

541
00:25:24,913 --> 00:25:26,533
The page table is 25 kilobytes.

542
00:25:27,333 --> 00:25:28,593
Total cell memory is about 640k.

543
00:25:28,633 --> 00:25:31,074
And you're probably thinking, well,

544
00:25:31,754 --> 00:25:32,675
so you're doing an next-gen game.

545
00:25:32,695 --> 00:25:35,015
We've got all these massive loads of gigs of data to use.

546
00:25:35,235 --> 00:25:36,776
Why is your memory so low?

547
00:25:37,216 --> 00:25:39,176
Well, again, as I said, we're showing data sets

548
00:25:39,256 --> 00:25:41,677
between current gen and last gen.

549
00:25:42,077 --> 00:25:43,177
So actually, what we have from here,

550
00:25:43,197 --> 00:25:45,018
we actually managed to optimize our last-gen memory a lot.

551
00:25:45,658 --> 00:25:46,398
Actually, our lighting system,

552
00:25:46,418 --> 00:25:48,178
I think we saved two megabytes or so in total

553
00:25:48,238 --> 00:25:49,259
across the last-gen consoles.

554
00:25:49,299 --> 00:25:51,439
So obviously, people were very, very happy about that.

555
00:25:53,020 --> 00:25:57,084
Performance again, the radius transfer is really really quick and so is our injection into the clip map.

556
00:25:57,785 --> 00:26:01,168
And the full screen pass here, the full screen pass is actually what does our sky lighting.

557
00:26:01,188 --> 00:26:04,932
So all the sky occlusion stuff I showed you earlier, applying the third order, actually sky lighting

558
00:26:05,432 --> 00:26:07,735
and sampling the clip map and getting indirect lighting out.

559
00:26:08,536 --> 00:26:09,557
We store that in a separate buffer.

560
00:26:11,899 --> 00:26:14,141
That's ready in the final deferred lighting pass.

561
00:26:17,297 --> 00:26:20,460
So, what's great about this, we solved all our problems in Far Cry 3.

562
00:26:20,540 --> 00:26:24,464
We had faster updates because now we had no kind of CPU-GPU synchronization.

563
00:26:24,824 --> 00:26:27,927
It was all going to be done on the GPU, all the radiance transfer, rather than before.

564
00:26:28,728 --> 00:26:32,311
We had a much larger indirect lighting range because now we had all these MIP levels of the lighting data.

565
00:26:32,571 --> 00:26:34,233
We could go all the way into the distance.

566
00:26:34,894 --> 00:26:38,637
And we had a lot lower memory requirements, which as I just said was awesome for our last-gen consoles.

567
00:26:40,817 --> 00:26:42,258
Obviously this has quite a few quality issues.

568
00:26:42,358 --> 00:26:43,999
So we have low frequency lighting,

569
00:26:44,019 --> 00:26:47,241
like every eight by eight meters are kind of at best.

570
00:26:48,662 --> 00:26:49,682
And also temporarily as well,

571
00:26:49,742 --> 00:26:52,264
because kind of second order SSH spherical harmonics

572
00:26:52,824 --> 00:26:54,145
and radius transfer,

573
00:26:54,165 --> 00:26:56,026
it just doesn't really pick up enough data.

574
00:26:57,366 --> 00:26:58,967
And also finally, we don't have our local lights

575
00:26:59,027 --> 00:27:00,008
kind of taken into account.

576
00:27:01,169 --> 00:27:02,569
So these are things obviously we want to look at

577
00:27:02,689 --> 00:27:04,110
and kind of improve for the future.

578
00:27:14,837 --> 00:27:15,538
So, vegetation.

579
00:27:16,639 --> 00:27:21,343
Now, vegetation was actually one area that we decided to completely redo for next-gen

580
00:27:21,363 --> 00:27:24,666
consoles, given it's a really important part of our Cry game.

581
00:27:26,448 --> 00:27:30,012
So I want to give credit to Philippe Gagnon and Jean-Sebastien Gay for working on this

582
00:27:30,052 --> 00:27:30,332
system.

583
00:27:30,852 --> 00:27:36,137
And again, it was a completely different data set for our current-gen and last-gen builds.

584
00:27:36,237 --> 00:27:38,199
So really, we did two completely different sets of trees.

585
00:27:39,315 --> 00:27:43,358
Our goals developing this new system were, well, we want to improve our visual fidelity up close,

586
00:27:43,418 --> 00:27:44,599
and we want to get really close to trees.

587
00:27:45,420 --> 00:27:48,702
We wanted to get improved lodding in impostors, as those kind of trees then go further away.

588
00:27:49,302 --> 00:27:51,664
And we want to get some core simulation, a physics simulation done.

589
00:27:54,005 --> 00:27:56,807
So to explain what I'm talking about, well, vegetation can mean quite a few things.

590
00:27:56,827 --> 00:27:58,148
We've got trees, bushes, grass.

591
00:27:58,929 --> 00:28:01,490
Really, our new system only touched kind of these trees and these bushes.

592
00:28:01,510 --> 00:28:03,051
We didn't really look at the grass at all.

593
00:28:07,619 --> 00:28:11,363
So what we're going to do, we're going to create our trees using SpeedTree, and we're going to port them into the engine.

594
00:28:11,723 --> 00:28:16,187
We're not going to use anything like the SpeedTree runtime, we're just going to take the mesh data generated and port that in a format that we like.

595
00:28:17,308 --> 00:28:23,914
And how we actually built a tree consisted of this. A tree consists of a trunk and these leaf clusters.

596
00:28:24,534 --> 00:28:26,736
And once we have a lot of leaf clusters and put them on a trunk, we get a tree.

597
00:28:29,624 --> 00:28:30,925
And these are all kind of loaded individually,

598
00:28:30,945 --> 00:28:32,545
and we have three LODs for the trunks

599
00:28:32,585 --> 00:28:33,726
and three LODs for the leaf clusters

600
00:28:33,786 --> 00:28:35,006
before a tree becomes an imposter.

601
00:28:35,747 --> 00:28:38,227
What's really cool is how we do the leaf cluster LODing.

602
00:28:38,247 --> 00:28:39,948
What we're actually going to do, we're going to generate

603
00:28:39,968 --> 00:28:41,509
when we want to switch LODs offline,

604
00:28:41,749 --> 00:28:42,909
and I can calculate the percentage

605
00:28:42,949 --> 00:28:45,330
of each leaf cluster visible from 12 distances

606
00:28:45,590 --> 00:28:48,452
and nine viewpoints around the camera, around the tree.

607
00:28:50,075 --> 00:28:51,696
So let's take a look at this.

608
00:28:51,916 --> 00:28:54,678
So let's look in the left-hand image.

609
00:28:54,738 --> 00:28:56,059
This is what happens looking at the tree.

610
00:28:56,659 --> 00:28:59,981
The red is going to be your kind of LOD 0 clusters.

611
00:29:00,141 --> 00:29:01,882
The green is going to be your LOD 1.

612
00:29:01,962 --> 00:29:03,783
And your blue is going to be your LOD 2.

613
00:29:03,823 --> 00:29:06,245
And if you kind of move the camera around to fix the

614
00:29:06,265 --> 00:29:08,646
color-coding camera, and you sneak a look around the side

615
00:29:08,666 --> 00:29:11,008
on the right-hand image, what you're going to see is that,

616
00:29:11,108 --> 00:29:13,089
obviously, the clusters closest to the camera.

617
00:29:13,829 --> 00:29:14,509
or on the highest slot.

618
00:29:14,529 --> 00:29:15,470
And as they get further away,

619
00:29:16,190 --> 00:29:17,731
more and more occluded by the clusters in front,

620
00:29:17,751 --> 00:29:19,251
so they're gonna be using the lower lots.

621
00:29:20,012 --> 00:29:20,832
And obviously, of course,

622
00:29:20,912 --> 00:29:22,073
as the tree moves into the distance,

623
00:29:22,473 --> 00:29:23,693
everything's gonna turn blue here

624
00:29:23,753 --> 00:29:25,114
and you're gonna have the lowest lot in total

625
00:29:25,374 --> 00:29:26,754
before everything goes to an imposter.

626
00:29:30,816 --> 00:29:31,316
Simulation.

627
00:29:31,777 --> 00:29:34,678
So, we have all our physics and movement of the tree

628
00:29:34,778 --> 00:29:35,578
simulated on GPU.

629
00:29:36,724 --> 00:29:40,226
What we do there, we have our instance bones transformed into world space bones.

630
00:29:40,586 --> 00:29:43,628
So what's going to happen is we have a model bone list of all the models in the scene,

631
00:29:44,149 --> 00:29:46,530
and obviously a list of all our instances, tree instances in the scene.

632
00:29:47,010 --> 00:29:48,711
They're going to go into a computer-aided simulation,

633
00:29:48,751 --> 00:29:52,293
and we're going to spit out a much longer list then of all the world space bones for every tree,

634
00:29:52,654 --> 00:29:53,854
which goes into our vertex shader.

635
00:29:54,755 --> 00:29:58,357
And this is great, because it allows some really cool physics effects.

636
00:30:00,018 --> 00:30:01,899
So this is the first point where I try to play a video.

637
00:30:06,028 --> 00:30:08,471
So I can see when you're flying a buzzer and it comes down,

638
00:30:08,851 --> 00:30:10,893
I can see all the trees moving individually,

639
00:30:10,913 --> 00:30:13,256
um, you see bushes reacting to the buzzer,

640
00:30:13,576 --> 00:30:15,398
and you can see all the grass waving as well.

641
00:30:15,478 --> 00:30:18,542
For the grass, you apply, actually apply some kind of cheap water-like simulation

642
00:30:18,842 --> 00:30:19,723
to get that going as well.

643
00:30:20,424 --> 00:30:23,668
And this is really cool. Not many games, I think, have this kind of, uh, kind of effects.

644
00:30:32,852 --> 00:30:34,713
So, that's great for close to the camera.

645
00:30:34,733 --> 00:30:35,853
What happens when you get far away?

646
00:30:37,134 --> 00:30:39,115
Well, we want some cool things to generate some good impostors.

647
00:30:40,076 --> 00:30:41,456
What we're actually going to do, we're going to take

648
00:30:42,197 --> 00:30:44,078
screenshots of nine viewpoints around the camera,

649
00:30:44,618 --> 00:30:46,439
eight perpendicular to the tree and one top down.

650
00:30:47,159 --> 00:30:48,860
So when we have an imposter, we can easily blend,

651
00:30:48,880 --> 00:30:51,142
depending on our view angle, what the tree should look like.

652
00:30:52,522 --> 00:30:53,483
But we're going to go further than that.

653
00:30:53,503 --> 00:30:55,344
Because actually what we're going to do

654
00:30:55,404 --> 00:30:57,125
is take G-buffer kind of screenshots.

655
00:30:57,325 --> 00:30:59,286
We want to capture the albedo, the normals,

656
00:30:59,906 --> 00:31:00,987
and the material properties.

657
00:31:04,317 --> 00:31:06,499
And that gives us a lot of textures for a tree.

658
00:31:07,160 --> 00:31:08,201
And again, we're not going to stop there.

659
00:31:08,221 --> 00:31:08,921
We're going to add even more.

660
00:31:08,941 --> 00:31:11,563
We're going to add this kind of depth billboard effect.

661
00:31:11,603 --> 00:31:14,566
So we have one capture low res depth data as well during our

662
00:31:14,586 --> 00:31:15,247
gbuffer pass.

663
00:31:15,967 --> 00:31:17,328
And when we render our billboards, they're actually

664
00:31:17,348 --> 00:31:18,710
tessellated into a 16 by 16 grid.

665
00:31:18,810 --> 00:31:21,312
And we're going to displace our vertices to fit according

666
00:31:21,332 --> 00:31:22,373
to the original tree depth.

667
00:31:25,327 --> 00:31:30,031
Watching these screenshots is not so great, but this is the front view on the left and the side view is the same tree.

668
00:31:30,391 --> 00:31:31,932
As you can see, all the depth applied.

669
00:31:33,173 --> 00:31:36,856
I've been told this actually really helps a lot when a tree is lit from the side.

670
00:31:37,357 --> 00:31:39,198
And also when two tree impostors intersect.

671
00:31:39,659 --> 00:31:42,201
So, that gives a much better blending between them.

672
00:31:42,781 --> 00:31:44,943
So, it's worth doing this technique.

673
00:31:44,983 --> 00:31:47,205
And I'll give you a few benefits later as well, as I'll explain.

674
00:31:49,906 --> 00:31:53,587
I'm in the occlusion, standard thing everyone did, AO volumes.

675
00:31:55,488 --> 00:31:56,248
You've all seen this before.

676
00:31:57,049 --> 00:31:58,869
But it definitely has a benefit to our tree lighting.

677
00:32:00,750 --> 00:32:03,031
And let's give some scary looking vertex numbers.

678
00:32:04,431 --> 00:32:10,013
So for our rosewood tree on the right,

679
00:32:10,033 --> 00:32:10,854
we might see 170,000 vertices for the leaves.

680
00:32:16,352 --> 00:32:20,797
It's worth noticing here because we have our loading system, we're never going to render that many.

681
00:32:21,017 --> 00:32:25,321
It's only going to be like 80,000 max for that because of the loading that we do.

682
00:32:27,583 --> 00:32:29,305
Which allows us to have this kind of high detail.

683
00:32:29,805 --> 00:32:33,128
Of course it's also probably fair to say that I'm not going to let artists make a tree like that again.

684
00:32:36,762 --> 00:32:38,563
And performance, performance is actually pretty good as well.

685
00:32:38,663 --> 00:32:41,286
Our tree simulation, again, on compute, is like really, really quick.

686
00:32:41,926 --> 00:32:44,368
Um, and given for this scene, um,

687
00:32:44,969 --> 00:32:45,890
there's a lot of trees on the scene,

688
00:32:46,090 --> 00:32:47,271
have shadows about a millisecond,

689
00:32:47,311 --> 00:32:48,933
g-buffer about five and a half,

690
00:32:48,993 --> 00:32:50,854
rendering all this kind of alpha test geometry.

691
00:32:51,275 --> 00:32:51,775
It's pretty good.

692
00:32:51,795 --> 00:32:56,720
But obviously we like to optimize because trees are always expensive for everybody, everywhere.

693
00:33:00,072 --> 00:33:03,253
Um, visually however, I think vegetation is a really tricky thing to get right,

694
00:33:03,293 --> 00:33:05,274
because you know, there's loads of things we're not simulating,

695
00:33:05,614 --> 00:33:08,355
and, um, you know, like bounces between blazes of grass,

696
00:33:08,535 --> 00:33:10,236
or the light scattering between leaves.

697
00:33:10,916 --> 00:33:13,877
Um, what's really great is when you have some really cool technical artists,

698
00:33:13,897 --> 00:33:15,818
you can kind of come in at the end of the project and just kind of

699
00:33:16,478 --> 00:33:18,219
do a few little cool tweaks to get things looking cool.

700
00:33:18,239 --> 00:33:19,820
I'm going to share a few of those with you.

701
00:33:21,784 --> 00:33:23,685
So what they wanted is a kind of a per cluster,

702
00:33:24,045 --> 00:33:25,626
per leaf cluster, random color tint.

703
00:33:26,567 --> 00:33:28,388
So this is an example, the first color's green,

704
00:33:28,428 --> 00:33:30,309
second color's red, and we just generate tints

705
00:33:30,569 --> 00:33:32,070
varying between those two randomly.

706
00:33:32,930 --> 00:33:34,311
Really simple, really effective.

707
00:33:34,771 --> 00:33:36,132
And this is a bit of an extreme example,

708
00:33:36,152 --> 00:33:37,553
but you know, it's not too different to trees

709
00:33:37,573 --> 00:33:38,853
you might see in Vermont in the autumn.

710
00:33:42,228 --> 00:33:44,429
We also need to bring impostors to life.

711
00:33:44,449 --> 00:33:46,171
Because we had all this cool simulation up front,

712
00:33:46,711 --> 00:33:48,973
but then when we did impostors, they looked a bit flat and boring.

713
00:33:49,033 --> 00:33:50,274
So what are we going to do?

714
00:33:50,694 --> 00:33:53,136
Well, we just simulate some branch motion first

715
00:33:53,217 --> 00:33:54,798
by doing some per-vertex sine waves.

716
00:33:55,198 --> 00:33:57,480
This is great because we have those tessellated billboards

717
00:33:57,500 --> 00:34:00,342
that actually the vertices are going to move when the trees are going to shift a bit.

718
00:34:01,103 --> 00:34:03,165
And we just simulate them by smooth triangle waves

719
00:34:03,285 --> 00:34:05,546
as they did with Crytek many years ago.

720
00:34:08,909 --> 00:34:12,011
And we're also gonna add some per pixel noise as well

721
00:34:12,331 --> 00:34:13,892
from a texture to simulate leaf motion.

722
00:34:14,432 --> 00:34:15,873
So you have the branch motion from these big

723
00:34:15,953 --> 00:34:18,275
kind of distortions and then this little per pixel noise

724
00:34:18,295 --> 00:34:19,255
to fake this leaf motion.

725
00:34:19,796 --> 00:34:20,336
Works really well.

726
00:34:21,837 --> 00:34:23,018
Again, I'm gonna play this video.

727
00:34:23,058 --> 00:34:24,439
I'm not hopefully about to see the difference

728
00:34:24,479 --> 00:34:25,800
between the noise on and the noise off.

729
00:34:26,220 --> 00:34:27,701
If not, again, take a look offline.

730
00:34:34,225 --> 00:34:34,926
That's working pretty well.

731
00:34:34,946 --> 00:34:37,347
I think you can see that things look a lot more dynamic

732
00:34:37,367 --> 00:34:38,008
when the noise is on.

733
00:34:45,349 --> 00:34:49,252
So, our final topic of improvement today is anti-aliasing.

734
00:34:49,753 --> 00:34:53,516
Now, I hope you all saw Mahal Jobot's talk

735
00:34:53,536 --> 00:34:57,159
at SIGGRAPH last year, where he went into a big overview

736
00:34:57,179 --> 00:34:59,160
of all the anti-aliasing techniques we tried.

737
00:34:59,681 --> 00:35:01,722
So really, all the credit to this work goes to Mahal,

738
00:35:01,802 --> 00:35:03,704
and also all the difficult questions at the end, please.

739
00:35:06,066 --> 00:35:06,566
Yeah, so.

740
00:35:08,144 --> 00:35:12,506
What I'm actually going to present here is a strip down of that talk, and I'm going to talk about the things we actually finally shipped with.

741
00:35:14,307 --> 00:35:22,172
So really, this hybrid reconstruction anti-aliasing is looking at about three different techniques that we're going to apply together to get good anti-aliasing results.

742
00:35:23,052 --> 00:35:24,433
So the first is edge anti-aliasing.

743
00:35:24,893 --> 00:35:30,516
So this is pretty self-explanatory. You all know what this is, what MSA tries to deal with when you have these edges in your image.

744
00:35:30,536 --> 00:35:36,400
You also need to look at temporal anti-aliasing as well, because images move in time, so you've got this kind of third dimension you need to think about.

745
00:35:37,895 --> 00:35:39,635
And finally we have temporal super sampling.

746
00:35:39,695 --> 00:35:42,577
So obviously super sampling is when we take a big image

747
00:35:42,597 --> 00:35:44,197
and we're gonna down sample it to something smaller.

748
00:35:45,518 --> 00:35:46,779
We wanted to do that temporally,

749
00:35:46,839 --> 00:35:49,060
where we take different samples and alternate frames

750
00:35:49,160 --> 00:35:50,760
and use that to combine this big image

751
00:35:50,800 --> 00:35:52,281
that we're down sampling.

752
00:35:56,201 --> 00:35:58,462
So this is a bit of an overview of kind of how things are going to work.

753
00:35:58,502 --> 00:35:59,983
I'm going to go through this in a bit more detail.

754
00:36:00,423 --> 00:36:01,904
So you start with our current frame.

755
00:36:02,084 --> 00:36:03,885
It's going to go into our edge anti-aliasing.

756
00:36:04,525 --> 00:36:06,306
That feeds in along with our previous frame

757
00:36:06,446 --> 00:36:08,727
into the temporal supersampling and temporal anti-aliasing shader,

758
00:36:09,087 --> 00:36:10,448
which one outputs our final frame.

759
00:36:11,048 --> 00:36:13,750
And that then goes back, fed in again,

760
00:36:13,950 --> 00:36:15,831
our frame n-1 and our accumulation history buffer

761
00:36:15,971 --> 00:36:18,572
gets fed back in again to do all that final temporal supersampling

762
00:36:18,612 --> 00:36:20,433
and temporal anti-aliasing for the next frame.

763
00:36:23,355 --> 00:36:24,195
So edge anti-aliasing.

764
00:36:24,235 --> 00:36:25,436
Well, we've tried a lot of techniques.

765
00:36:26,305 --> 00:36:30,026
So, we looked at analytic edge anti-aliasing

766
00:36:30,046 --> 00:36:32,027
for alpha-tested geometry.

767
00:36:33,348 --> 00:36:34,148
We also really wanted to,

768
00:36:34,168 --> 00:36:34,988
what we really wanted to do

769
00:36:35,028 --> 00:36:36,729
was the coverage reconstruction anti-aliasing

770
00:36:36,749 --> 00:36:37,990
that Mahal presented at SIGGRAPH.

771
00:36:39,250 --> 00:36:40,811
And this gave us by far the best performance,

772
00:36:41,251 --> 00:36:42,972
but we had a lot of content issues with small triangles,

773
00:36:42,992 --> 00:36:43,792
so we actually couldn't do this.

774
00:36:44,372 --> 00:36:45,773
But I'd advise checking it out for your game.

775
00:36:46,613 --> 00:36:48,574
So we actually ended up with SMAA.

776
00:36:49,154 --> 00:36:50,455
This is just temporarily stabilized,

777
00:36:50,775 --> 00:36:52,175
and we had a normal depth

778
00:36:52,215 --> 00:36:53,416
and Luma predicated thresholding.

779
00:36:57,329 --> 00:37:00,777
So for the temporal super-sampling, so this is based on work done for Killzone Shadowfall.

780
00:37:00,797 --> 00:37:06,370
So what we're going to do, this is two-time super-sampling, so we're going to use the current frame and the previous frame for our two samples.

781
00:37:07,950 --> 00:37:09,451
The previous frame sample is valid,

782
00:37:09,471 --> 00:37:11,512
but only valid if the motion flow

783
00:37:11,552 --> 00:37:13,614
between frames n and n-1 is coherent,

784
00:37:14,094 --> 00:37:15,455
and also the color flow

785
00:37:15,495 --> 00:37:17,856
between frames n and n-2 is coherent.

786
00:37:18,257 --> 00:37:19,497
So we need to look at those two frames

787
00:37:19,517 --> 00:37:20,818
so they have the same subpixel jitter.

788
00:37:20,998 --> 00:37:21,979
That's going to prevent flickering.

789
00:37:22,940 --> 00:37:25,021
Except that we didn't actually do the frame n-2 stuff

790
00:37:25,041 --> 00:37:26,522
for Far Cry 4, and you can actually do,

791
00:37:26,542 --> 00:37:28,023
can see some flickering present in the game.

792
00:37:28,683 --> 00:37:30,705
And thanks for those who already pointed out to me this GDC.

793
00:37:32,884 --> 00:37:35,667
So again, what we're going to do, so let's go over these metrics again.

794
00:37:35,867 --> 00:37:38,470
So if we have this geometric metric, which is looking at a motion buffer

795
00:37:38,890 --> 00:37:40,692
to make sure that we kind of stick with the same geometry,

796
00:37:40,973 --> 00:37:42,975
we interpolate between the same geometric objects.

797
00:37:43,575 --> 00:37:45,958
So interpolating from our n-1 to our n-sample,

798
00:37:46,839 --> 00:37:47,960
the motion ends up being incoherent.

799
00:37:47,980 --> 00:37:50,863
And we're still going to do some kind of color metric on our n-1 sample.

800
00:37:53,053 --> 00:37:55,075
So, we're going to look at the color bounding box,

801
00:37:55,196 --> 00:37:57,278
about 3x3 neighborhood around our sample.

802
00:37:57,899 --> 00:37:59,801
If it's close to the mean, we take no new information.

803
00:37:59,821 --> 00:38:01,043
If it's close to the minimum max,

804
00:38:01,503 --> 00:38:02,544
we think we have new information,

805
00:38:02,584 --> 00:38:03,465
we want to accumulate that in.

806
00:38:03,886 --> 00:38:05,027
If it's outside this window,

807
00:38:05,047 --> 00:38:06,349
then we think it's probably a fluctuation,

808
00:38:06,369 --> 00:38:06,990
we should get rid of it.

809
00:38:09,373 --> 00:38:10,494
And just to visualize that.

810
00:38:11,572 --> 00:38:13,393
This gives a good graph of how we're actually doing things.

811
00:38:14,314 --> 00:38:15,976
Hopefully that kind of makes a bit more sense of the visual.

812
00:38:16,076 --> 00:38:19,018
So we accept things around the min and the max of these peaks.

813
00:38:19,839 --> 00:38:21,320
It's actually worth looking at.

814
00:38:21,340 --> 00:38:23,362
We didn't actually use the mean at the end.

815
00:38:23,622 --> 00:38:27,125
We actually used the center of the pixels.

816
00:38:30,648 --> 00:38:33,090
So also it's worth checking out Brian Karas' talk

817
00:38:33,570 --> 00:38:34,571
at G-Graph last year as well.

818
00:38:34,591 --> 00:38:36,713
He went over loads of things on these acceptance metrics.

819
00:38:36,733 --> 00:38:38,615
So definitely worth checking that out.

820
00:38:42,908 --> 00:38:49,592
So what we're going to do, we need to look at what samples we're going to use, what sample pattern we're going to use to maximize our two samples to get the best image out.

821
00:38:49,612 --> 00:38:52,134
So there's various sample patterns we can try.

822
00:38:52,154 --> 00:38:53,835
Let's take a look at what they are.

823
00:38:54,756 --> 00:38:59,679
Well, obviously just for a one-time centroid, well we're going to get some aliasing and you can see kind of the edge there.

824
00:39:01,040 --> 00:39:04,543
A standard one, if you kind of two times MSAA, is your two times rotated grid.

825
00:39:05,023 --> 00:39:06,664
Well, you know, it gets a bit better.

826
00:39:07,024 --> 00:39:09,006
There's actually some form of anti-aliasing there.

827
00:39:09,446 --> 00:39:09,986
It's not great.

828
00:39:12,005 --> 00:39:13,265
We could do two times quincunx.

829
00:39:13,345 --> 00:39:15,406
Now, quincunx is interesting because it optimizes pattern

830
00:39:15,426 --> 00:39:17,926
by kind of sharing corner samples between various pixels.

831
00:39:17,946 --> 00:39:19,807
So you have kind of three unique rows,

832
00:39:19,867 --> 00:39:20,607
three unique columns.

833
00:39:21,407 --> 00:39:24,268
But of course, this does introduce a 0.5 radius blur.

834
00:39:28,609 --> 00:39:29,650
Or we could look at doing something like

835
00:39:29,710 --> 00:39:30,810
four times rotated grid.

836
00:39:31,710 --> 00:39:32,970
Again, that would be four time samples,

837
00:39:33,010 --> 00:39:34,231
so we can't really afford that.

838
00:39:35,691 --> 00:39:36,831
But it does give a better looking result.

839
00:39:38,546 --> 00:39:41,509
But there is a better pattern, and that's actually this thing called FlipQuad.

840
00:39:41,689 --> 00:39:45,552
So it kind of combines these ideas in the 4x8 grid and also your kind of quincunx pattern.

841
00:39:46,193 --> 00:39:49,896
So, what happens, you have 4 unique rows, you have 4 unique columns.

842
00:39:51,757 --> 00:39:55,060
And it does also, like quincunx, have this kind of 0.5 pixel blur.

843
00:39:55,281 --> 00:39:58,603
But you can actually recover that in post-processing with Unsharp Mask.

844
00:39:58,824 --> 00:39:59,724
So it's actually going to be okay.

845
00:40:02,717 --> 00:40:04,559
Actually, we just used some comparison of actually some images.

846
00:40:04,999 --> 00:40:09,623
Well, it looks kind of as if, like, the flip quad is looking pretty as good as the 4x rotated grid.

847
00:40:10,584 --> 00:40:14,387
And if we look at some kind of studies, it kind of turns out that actually flip quad is probably the best of them all.

848
00:40:15,168 --> 00:40:17,090
Out of all the things we looked at. So let's go with that.

849
00:40:18,331 --> 00:40:19,171
So how is that going to work?

850
00:40:21,514 --> 00:40:23,155
All we need to do is split the pattern in half.

851
00:40:23,775 --> 00:40:29,040
So, on frame A, we're going to look at samples, say, 0 and 1, 2 and 3.

852
00:40:29,681 --> 00:40:30,782
And on frame B, we're going to look at...

853
00:40:31,330 --> 00:40:32,871
the red 0, 1, 2, and 3.

854
00:40:34,532 --> 00:40:37,094
And for, say, for pixel 0, then, all we need to do

855
00:40:37,194 --> 00:40:40,456
is average your 0, 1 in blue and your 0, 2 in red,

856
00:40:40,476 --> 00:40:43,078
and actually give us our kind of super-sampled image.

857
00:40:48,722 --> 00:40:49,883
There are obviously some tricks with this.

858
00:40:50,984 --> 00:40:52,505
It doesn't work out quite as easy as you hope,

859
00:40:52,545 --> 00:40:53,546
because what you need to do, you actually

860
00:40:53,566 --> 00:40:55,287
need to interpret your UVs as sample positions.

861
00:40:55,887 --> 00:40:58,169
You just use some HLSL interpolator modifiers.

862
00:40:59,437 --> 00:41:02,978
Of course, then you have the second problem where you have incorrect derivative calculations

863
00:41:03,399 --> 00:41:06,660
because your spatial distances between the rasterization samples differ.

864
00:41:07,440 --> 00:41:11,181
And that causes some quite bad problems because let's look at, say, frame A.

865
00:41:12,221 --> 00:41:13,402
Well, this is rendered with the correct MIP.

866
00:41:15,342 --> 00:41:19,624
And then what happens when we render with frame B, the ddx, ddy changes and we get this

867
00:41:19,724 --> 00:41:20,524
oversharpened MIP.

868
00:41:21,064 --> 00:41:23,505
And obviously if we're going to blend between those two, well, we're going to have a few

869
00:41:23,545 --> 00:41:23,805
issues.

870
00:41:26,144 --> 00:41:27,865
So what do we do? Well, we actually just need to...

871
00:41:27,985 --> 00:41:29,326
We could do a few things.

872
00:41:29,406 --> 00:41:31,267
We could do some mip-blob-bias clean frames.

873
00:41:31,547 --> 00:41:32,087
Seems a bit tricky.

874
00:41:32,667 --> 00:41:34,709
We could obviously try to do things manually ourselves,

875
00:41:34,769 --> 00:41:36,950
but that's going to be expensive and a bit of a pain.

876
00:41:37,490 --> 00:41:39,711
Actually, the thing we can just do is actually just reorder our samples

877
00:41:40,131 --> 00:41:41,552
and to make sure that these derivatives match.

878
00:41:42,212 --> 00:41:43,613
And it turns out that's pretty straightforward to do,

879
00:41:44,153 --> 00:41:46,355
and it works pretty well.

880
00:41:46,595 --> 00:41:47,755
So this is the same as before.

881
00:41:47,815 --> 00:41:48,936
Frame A still looks great.

882
00:41:49,296 --> 00:41:50,237
Haven't changed anything there.

883
00:41:50,737 --> 00:41:51,377
But for frame B,

884
00:41:51,918 --> 00:41:54,159
now everything looks pretty much the same as frame A,

885
00:41:54,259 --> 00:41:54,739
and that's great.

886
00:41:57,440 --> 00:42:00,121
Um, now, so the temporal anteater thing.

887
00:42:00,581 --> 00:42:03,002
So we actually temporally stabilize, um, like a load of our buffers.

888
00:42:03,802 --> 00:42:06,203
Takes up loads of memory, that's cool, we've got it all on next gen, right?

889
00:42:06,684 --> 00:42:10,085
Um, but, uh, actually really gives a really good image quality.

890
00:42:10,225 --> 00:42:12,246
So we look at the final frame buffer, the SMA,

891
00:42:12,666 --> 00:42:14,987
the screen space bent cones, motion vectors bloom,

892
00:42:15,307 --> 00:42:16,528
they're all temporarily stabilized.

893
00:42:19,867 --> 00:42:22,128
So, we have this history exponential buffer,

894
00:42:22,928 --> 00:42:25,830
and what we need to do is use a multi-sum of visual changes.

895
00:42:25,930 --> 00:42:28,652
So, make sure we only accumulate new important data into it.

896
00:42:29,952 --> 00:42:31,693
We actually use the same acceptance metrics

897
00:42:31,733 --> 00:42:33,574
I just talked about for the temporal supersampling.

898
00:42:33,855 --> 00:42:36,396
So, geometric metric to compare whether the motion vectors

899
00:42:36,416 --> 00:42:38,597
are the same, a color metric to compare which colors

900
00:42:38,617 --> 00:42:39,578
were in the same bounding box.

901
00:42:40,298 --> 00:42:42,519
So now we're doing this not only for N minus one frame,

902
00:42:42,540 --> 00:42:44,701
but we're gonna do it separately to our full history buffer.

903
00:42:45,941 --> 00:42:47,502
You might need to tweak those values separately though,

904
00:42:47,903 --> 00:42:49,243
to get some good different results.

905
00:42:53,929 --> 00:42:57,331
However, after all this, we're going to lose a bit of detail.

906
00:42:57,351 --> 00:43:01,353
We need some wider and more complicated kind of downsampling kernel.

907
00:43:02,794 --> 00:43:04,956
And also we have this kind of half-pixel blur from FlipQuad.

908
00:43:07,172 --> 00:43:08,493
So this is pretty okay actually.

909
00:43:08,513 --> 00:43:10,534
We just need to approximate a four-tap sync kernel

910
00:43:10,594 --> 00:43:12,756
by doing a half-pixel blur.

911
00:43:13,016 --> 00:43:14,497
Hey, we've already done that with a flip quad.

912
00:43:15,018 --> 00:43:16,719
And we actually need to do a half-pixel radius

913
00:43:17,199 --> 00:43:18,140
on sharp masking as well.

914
00:43:18,960 --> 00:43:20,742
And then to match our super-sampled resolution,

915
00:43:20,802 --> 00:43:22,363
because now our resolution is a lot higher

916
00:43:22,403 --> 00:43:23,584
than what it initially was,

917
00:43:24,144 --> 00:43:25,946
we just need to do a MIP bias on all textures.

918
00:43:28,928 --> 00:43:30,629
And overall, we have then some really high-quality

919
00:43:30,649 --> 00:43:33,551
anti-aliasing, and actually the performance

920
00:43:33,571 --> 00:43:34,252
is really, really good.

921
00:43:36,077 --> 00:43:37,198
SMA is a millisecond.

922
00:43:38,178 --> 00:43:40,219
And look at the kind of temporal flip quad

923
00:43:40,239 --> 00:43:42,580
plus the temporal anti-aliasing takes about 0.65.

924
00:43:43,321 --> 00:43:45,822
And combine that with the shaft mask as well,

925
00:43:45,862 --> 00:43:49,303
we've got 2 milliseconds then for all anti-aliasing.

926
00:43:49,323 --> 00:43:52,985
If we did the, managed to do the coverage reconstruction anti-aliasing,

927
00:43:53,005 --> 00:43:54,566
we'd probably get a little bit back off that.

928
00:43:55,446 --> 00:43:57,107
But again, something to look out for in the future.

929
00:44:01,383 --> 00:44:03,344
So what's the conclusions gonna come to?

930
00:44:03,704 --> 00:44:05,625
Well, first of all, let's show you a bit of a typical performance

931
00:44:05,645 --> 00:44:06,726
of a typical Far Cry scene.

932
00:44:08,546 --> 00:44:10,567
It's awesome doing a cross-gen game sometimes

933
00:44:10,627 --> 00:44:11,827
because this is well in frame.

934
00:44:12,608 --> 00:44:14,228
Thank you to all the artists who made good data.

935
00:44:15,689 --> 00:44:18,230
So, as I said, the RTK noticingly 2 milliseconds,

936
00:44:18,350 --> 00:44:19,891
about 3 milliseconds of post-processing.

937
00:44:20,451 --> 00:44:22,171
G-buffer is obviously the most expensive path

938
00:44:22,211 --> 00:44:23,332
followed up by lighting.

939
00:44:23,352 --> 00:44:25,473
And there's a few miscellaneous things in there as well.

940
00:44:25,513 --> 00:44:26,733
That's just our tree simulation

941
00:44:27,273 --> 00:44:28,734
and various kind of buffer copying.

942
00:44:32,116 --> 00:44:38,058
So, Far Cry 4, we managed to make some significant rendering improvements to our engine whilst maintaining a last-gen build.

943
00:44:38,678 --> 00:44:43,960
We added some anisotropic metallic materials, we added some higher fidelity sky occlusion and some indirect lighting.

944
00:44:44,801 --> 00:44:52,403
We added a whole new vegetation system, and finally we built a new anti-aliasing algorithm that gave us some high image quality at the end.

945
00:44:54,704 --> 00:44:58,425
Really, thanks to everyone on the Far Cry 4 team,

946
00:44:58,665 --> 00:45:00,525
but especially these guys who worked on things,

947
00:45:00,985 --> 00:45:02,046
like I mentioned in the presentation.

948
00:45:02,626 --> 00:45:03,606
A special thanks to Stephen Hill

949
00:45:03,646 --> 00:45:04,846
for all the conversations we've had

950
00:45:04,906 --> 00:45:06,827
about ACU and Far Cry 4,

951
00:45:07,467 --> 00:45:10,108
and to Julien Merceron as well for being the GDC advisor.

952
00:45:11,668 --> 00:45:13,049
I have a lot of references.

953
00:45:13,069 --> 00:45:14,409
Please check them out.

954
00:45:14,429 --> 00:45:15,289
They're all actually pretty good.

955
00:45:15,329 --> 00:45:16,049
They're worth your time.

956
00:45:18,630 --> 00:45:19,670
Does anyone have any questions?

957
00:45:41,240 --> 00:45:45,332
No one? Okay, you can come and talk to me afterwards if you need. Thanks again for coming everyone.

