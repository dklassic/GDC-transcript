1
00:00:06,079 --> 00:00:09,762
My name is John Austin. I'm a lead engineer at Phenomena.

2
00:00:10,783 --> 00:00:13,425
So we build a lot of AR and VR projects, among others.

3
00:00:13,565 --> 00:00:15,086
Also, Wattam is coming out soon.

4
00:00:16,747 --> 00:00:20,230
In the past, I worked at Google, so on the Google Lens project.

5
00:00:20,290 --> 00:00:23,032
So our team was responsible for largely taking

6
00:00:23,072 --> 00:00:26,454
these big computer vision models and crunching them down

7
00:00:26,514 --> 00:00:27,715
and fitting them onto smartphones.

8
00:00:28,396 --> 00:00:31,078
So that's kind of how I got into AR and VR stuff,

9
00:00:31,478 --> 00:00:33,539
because a lot of the computer vision algorithms are very similar.

10
00:00:34,840 --> 00:00:37,322
On the side, I work for a game development collective

11
00:00:37,382 --> 00:00:38,362
called A Stranger Graffiti,

12
00:00:39,223 --> 00:00:41,024
and so we do a little bit of consulting work

13
00:00:41,064 --> 00:00:42,585
and some personal project work as well.

14
00:00:44,366 --> 00:00:46,687
So for Phenomena,

15
00:00:46,767 --> 00:00:49,268
we released Luna Moondust Garden rather recently,

16
00:00:49,448 --> 00:00:50,769
and this was a Magic Leap project.

17
00:00:51,690 --> 00:00:54,551
It was a reinterpretation of our virtual reality game,

18
00:00:54,591 --> 00:00:56,452
Luna, for the Magic Leap.

19
00:00:58,093 --> 00:00:59,734
And just in case you're not familiar with it,

20
00:01:01,035 --> 00:01:02,876
here's a quick little teaser trailer we released

21
00:01:03,056 --> 00:01:04,597
just so you have a sense of what it looks like.

22
00:01:15,608 --> 00:01:25,193
On screen text Wildlife programs are created using differentánatinom MetroArch software.

23
00:01:25,353 --> 00:01:29,055
On screen text Wildlife programs are created using differentánatinom MetroArch software.

24
00:02:03,733 --> 00:02:07,374
So it's sort of a storybook adventure about helping Fox find his garden.

25
00:02:12,867 --> 00:02:16,071
So at Phenomena, we work on a lot of experimental platforms.

26
00:02:17,212 --> 00:02:20,736
And this was kind of not unlike any of the others.

27
00:02:21,096 --> 00:02:22,718
And one of the biggest problems we face with these

28
00:02:22,778 --> 00:02:24,961
platforms is iteration time.

29
00:02:25,602 --> 00:02:27,664
So there we go.

30
00:02:28,024 --> 00:02:28,984
So, iteration time.

31
00:02:29,144 --> 00:02:33,386
So, on experimental platforms, one of the big problems is that they're generally a separate

32
00:02:33,406 --> 00:02:34,006
piece of hardware.

33
00:02:34,246 --> 00:02:38,467
So you might have, like, the Quest or the Magic Leap, and it's a separate device.

34
00:02:38,727 --> 00:02:44,309
So if you want to build and design a game to that device, you really have to play it

35
00:02:44,609 --> 00:02:45,209
on the device.

36
00:02:45,989 --> 00:02:49,970
You can't really use a mouse and keyboard to try out something that needs controllers

37
00:02:50,090 --> 00:02:51,651
or augmented reality.

38
00:02:53,171 --> 00:02:56,654
And so because of that, because Phenomena practices a very iterative style of design,

39
00:02:57,355 --> 00:02:59,817
iteration time becomes one of our biggest workflow bottlenecks.

40
00:03:01,549 --> 00:03:09,094
And so for the Magic Leap project, we designed a simulator for the Magic Leap in virtual reality to solve this issue.

41
00:03:09,654 --> 00:03:14,037
So we sort of reconstructed the experience of playing the Magic Leap on the Rift.

42
00:03:14,818 --> 00:03:18,240
So this clip here is all being rendered in virtual reality.

43
00:03:19,021 --> 00:03:22,283
The background and all of the compositing is all happening on the Rift.

44
00:03:24,043 --> 00:03:28,245
And so this is a big benefit for us because it not only did it cut down the iteration time

45
00:03:28,365 --> 00:03:31,647
from minutes that it might take to deploy all the way to the magic leap

46
00:03:32,468 --> 00:03:34,429
to just playing it in editor in Unity,

47
00:03:36,050 --> 00:03:38,991
but it also allowed us a lot more freedom and flexibility about how we worked

48
00:03:39,051 --> 00:03:41,813
because we didn't necessarily need to have a headset for everyone

49
00:03:42,293 --> 00:03:45,855
or it allowed us to work from home, for instance.

50
00:03:46,656 --> 00:03:48,677
So it was a benefit in a number of different ways.

51
00:03:49,377 --> 00:03:51,418
And so what I wanted to talk about today a little bit

52
00:03:51,458 --> 00:03:54,020
was how we technically implemented this simulator

53
00:03:54,540 --> 00:03:57,541
and some of the design decisions we went through along the way.

54
00:03:58,202 --> 00:04:00,483
And hopefully you should have a good idea of how you can make a simulator

55
00:04:01,303 --> 00:04:03,224
and also how you can design it for your custom platform,

56
00:04:03,244 --> 00:04:04,845
whether it's the Magic Leap or something else.

57
00:04:06,846 --> 00:04:08,727
So I kind of want to start off and think a little bit about

58
00:04:08,907 --> 00:04:10,167
what makes a good simulator.

59
00:04:12,005 --> 00:04:16,468
So, in my opinion, the most important thing a simulator can do, especially as an engineer,

60
00:04:16,548 --> 00:04:19,010
is give you confidence in the changes you're making.

61
00:04:20,672 --> 00:04:23,834
What you really want is to be able to work in the simulator, and it's never going to

62
00:04:23,854 --> 00:04:24,375
be perfect.

63
00:04:24,415 --> 00:04:26,857
It's not going to be a one-to-one match.

64
00:04:27,397 --> 00:04:30,300
But you want to have the confidence that when you make a change, that that change is going

65
00:04:30,320 --> 00:04:32,762
to reflect itself in the way you expect on the target platform.

66
00:04:34,597 --> 00:04:36,278
And so that's what I think a really good simulator should do.

67
00:04:36,678 --> 00:04:40,060
And that means we want to match the visuals, because for our artists and designers,

68
00:04:40,100 --> 00:04:45,783
we want them to put in their art assets and know that it's going to be fairly representative of what the final look is going to look like.

69
00:04:46,924 --> 00:04:50,406
We also want to match input for our gameplay designers and the engineers,

70
00:04:50,686 --> 00:04:53,327
so that when they're designing interactions and making them feel really juicy,

71
00:04:53,928 --> 00:04:56,329
and they go take them onto the device, it still feels the same.

72
00:04:57,980 --> 00:04:59,901
And then lastly, and maybe counterintuitively,

73
00:05:00,161 --> 00:05:02,243
we actually want our simulators to incorporate bugs

74
00:05:02,343 --> 00:05:03,884
and quirks of the target platform.

75
00:05:05,525 --> 00:05:07,547
You really want it to match as closely as possible.

76
00:05:07,587 --> 00:05:11,070
So a good example of this is on the magic leap,

77
00:05:11,230 --> 00:05:13,411
sometimes the controller doesn't connect

78
00:05:13,511 --> 00:05:14,552
for the first frame or two.

79
00:05:15,893 --> 00:05:17,855
And so, this was a big issue

80
00:05:17,895 --> 00:05:19,396
because a lot of our gameplay engineers

81
00:05:19,776 --> 00:05:21,417
would set up a little bit of gameplay

82
00:05:21,457 --> 00:05:23,399
and assume that they had input on frame one

83
00:05:23,459 --> 00:05:24,019
right at the beginning.

84
00:05:24,800 --> 00:05:26,241
And so it worked fine in the simulator,

85
00:05:26,321 --> 00:05:28,002
and then a week later we'd drop it on the device

86
00:05:28,682 --> 00:05:30,444
and everything would break and we'd spend hours

87
00:05:30,504 --> 00:05:32,665
trying to use the platform-specific tools

88
00:05:32,785 --> 00:05:34,006
to track down the bug.

89
00:05:35,527 --> 00:05:38,009
And we ended up actually incorporating this quirk

90
00:05:38,349 --> 00:05:40,390
back into our simulator and just had the simulator

91
00:05:40,550 --> 00:05:42,872
delay the input a little bit when it started up.

92
00:05:43,592 --> 00:05:46,514
And this allowed us to move the sort of bug workload

93
00:05:47,515 --> 00:05:49,516
from the end of the line up front to the engineer

94
00:05:49,536 --> 00:05:50,837
that's actually implementing it.

95
00:05:51,477 --> 00:05:53,458
And so this is a huge workflow issue for us,

96
00:05:53,718 --> 00:05:57,440
and it really helps give you that confidence

97
00:05:57,460 --> 00:05:58,140
that I'm talking about.

98
00:06:00,061 --> 00:06:02,862
So before we get into too many of the technical details,

99
00:06:03,242 --> 00:06:05,302
I kind of want to give a brief overview

100
00:06:05,322 --> 00:06:06,363
of how the Magic Leap works,

101
00:06:06,523 --> 00:06:08,964
because I'm not assuming that everyone necessarily knows

102
00:06:09,664 --> 00:06:10,384
kind of the pipeline.

103
00:06:11,405 --> 00:06:13,446
And we need to kind of know what we want to simulate

104
00:06:13,466 --> 00:06:14,426
when we're building our simulator.

105
00:06:15,996 --> 00:06:26,523
So, at a base layer, when you put on the magic leaf, you see the real world, which is really, you know, that's the thing that Augmented Reality is trying to do.

106
00:06:26,583 --> 00:06:28,605
It gives you the real world and your virtual world.

107
00:06:28,645 --> 00:06:31,407
So, we need some way to simulate the real world, because...

108
00:06:32,248 --> 00:06:34,790
There have been simulators for augmented reality that have been built before,

109
00:06:35,131 --> 00:06:38,995
and a lot of them use sort of stand-in geometry, IKEA furniture models,

110
00:06:39,436 --> 00:06:42,619
and it just doesn't feel like the experience of putting things in your world.

111
00:06:42,660 --> 00:06:45,523
And so it's important if we're going to be designing in this simulator

112
00:06:45,743 --> 00:06:49,167
to actually recreate something that's going to match the actual experience of playing.

113
00:06:50,880 --> 00:06:55,263
So that's sort of the real world layer when you want to simulate that.

114
00:06:55,423 --> 00:06:59,847
On the Magic Leap, there's a system of scanning the world.

115
00:07:00,287 --> 00:07:06,092
So all of these augmented reality platforms kind of create a mesh of the world as you're looking around.

116
00:07:06,252 --> 00:07:08,614
So it's constantly building a geometry.

117
00:07:09,639 --> 00:07:11,420
And this is really crucial for a couple of reasons,

118
00:07:11,460 --> 00:07:13,662
because it provides the ability to occlude objects.

119
00:07:14,222 --> 00:07:16,283
So unless you have this mesh,

120
00:07:16,944 --> 00:07:19,965
it doesn't know where the table is

121
00:07:20,005 --> 00:07:24,408
and how to block the rendering from the table, for instance.

122
00:07:24,808 --> 00:07:26,990
So we want to find some way to simulate this

123
00:07:27,050 --> 00:07:27,730
in our simulator,

124
00:07:28,530 --> 00:07:30,572
and I'll simulate some of the quirks of it too,

125
00:07:30,652 --> 00:07:32,833
because if we make a perfect scanned mesh,

126
00:07:32,933 --> 00:07:34,694
that's not really gonna be great.

127
00:07:36,571 --> 00:07:39,534
And then the last thing we want to simulate is just the virtual world.

128
00:07:39,634 --> 00:07:44,519
So this is just your normal gameplay kind of flow and rendering,

129
00:07:44,819 --> 00:07:48,263
but with a couple of considerations to make it feel a little bit more like the Magic Leap,

130
00:07:48,363 --> 00:07:51,386
because it's a fairly unique device in the way that it renders to your eyes.

131
00:07:53,188 --> 00:07:56,791
So that's the kind of broad overview of kind of where we'll be going.

132
00:07:58,052 --> 00:07:59,574
So let's start with the real world.

133
00:08:01,302 --> 00:08:03,864
So naturally, when we talk about wanting to simulate

134
00:08:03,884 --> 00:08:06,346
the real world, we probably think of photogrammetry.

135
00:08:07,346 --> 00:08:08,907
And so that's what I ended up doing.

136
00:08:09,788 --> 00:08:13,891
But I wasn't about to go buy a professional photogrammetry rig.

137
00:08:14,111 --> 00:08:15,832
I don't have a DSLR camera.

138
00:08:16,933 --> 00:08:20,175
So I kind of came up with a workflow that is kind of

139
00:08:20,255 --> 00:08:21,936
unique, but I think it's pretty interesting to talk about.

140
00:08:23,857 --> 00:08:26,459
So I ended up just using my phone, just my smartphone, my

141
00:08:26,479 --> 00:08:29,341
Pixel 2, to take all the images I needed for the scan.

142
00:08:31,993 --> 00:08:35,014
And so essentially what I did was rather than,

143
00:08:35,174 --> 00:08:36,994
so normally when you're doing photogrammetry,

144
00:08:37,014 --> 00:08:39,855
you want a couple of really nice high resolution images.

145
00:08:41,376 --> 00:08:43,496
But my phone's not gonna give me that really,

146
00:08:43,576 --> 00:08:46,117
so instead of quality, I opted for quantity.

147
00:08:46,557 --> 00:08:50,339
So I took this, basically this long video of our office,

148
00:08:51,379 --> 00:08:54,380
just sort of panning slowly around,

149
00:08:55,280 --> 00:08:57,181
and then I brought that into VLC

150
00:08:57,241 --> 00:08:59,961
and chopped it down to one frame a second or so.

151
00:09:01,280 --> 00:09:08,448
And the nice thing about that is it results in a very evenly distributed set of images around the room.

152
00:09:08,608 --> 00:09:13,653
So what you really want in photogrammetry is a nice uniform distribution so you can get a lot of different angles.

153
00:09:14,554 --> 00:09:19,479
I actually tried this manually at first by just kind of walking around and taking singular images.

154
00:09:20,079 --> 00:09:22,122
But while that kind of works if you're...

155
00:09:23,042 --> 00:09:25,744
taking a scan of something that's central

156
00:09:25,764 --> 00:09:27,865
and you can walk around and be very careful about.

157
00:09:28,205 --> 00:09:29,546
When you're taking a scan of an office,

158
00:09:29,566 --> 00:09:31,527
you really need to get into every nook and cranny,

159
00:09:31,587 --> 00:09:33,928
and so it's a lot harder to figure out

160
00:09:34,208 --> 00:09:35,369
where to take the images from.

161
00:09:35,389 --> 00:09:37,510
And so this technique actually worked really well

162
00:09:37,570 --> 00:09:40,191
because I could just sort of quickly wipe my phone around

163
00:09:41,272 --> 00:09:42,592
and get a bunch of great images.

164
00:09:43,513 --> 00:09:46,434
At the end I actually had 2,500 images from this process,

165
00:09:47,555 --> 00:09:48,696
which sounds like a lot.

166
00:09:49,556 --> 00:09:52,197
But luckily, the tool I chose to use

167
00:09:52,538 --> 00:09:54,819
for the photogrammetry was RealityCapture.

168
00:09:55,379 --> 00:09:56,740
And RealityCapture is a little bit different

169
00:09:56,780 --> 00:09:58,701
than maybe a more standard photogrammetry tool.

170
00:09:58,741 --> 00:10:00,482
So Agisoft is probably, I think,

171
00:10:00,522 --> 00:10:01,903
the front runner for photogrammetry.

172
00:10:03,063 --> 00:10:04,544
But RealityCapture runs on the GPU.

173
00:10:04,864 --> 00:10:09,086
So it can handle just an order of magnitude more photos.

174
00:10:09,427 --> 00:10:09,747
And so,

175
00:10:10,747 --> 00:10:14,070
This paired really nicely with my quantity over quality technique

176
00:10:15,051 --> 00:10:18,733
because I could just pump in 2,500 images and it would churn through it on the GPU.

177
00:10:20,074 --> 00:10:25,479
And after a couple of hours of tweaking the constraints and munging with the settings,

178
00:10:26,800 --> 00:10:27,880
I got to something that was...

179
00:10:28,953 --> 00:10:34,014
It looked like this, which, ugh, rough.

180
00:10:35,255 --> 00:10:37,395
So I kind of fell into the trap,

181
00:10:37,675 --> 00:10:41,156
well, the phone technique was maybe a little questionable,

182
00:10:41,517 --> 00:10:42,837
but I also fell into the trap

183
00:10:43,057 --> 00:10:45,538
of kind of blank walls and desks.

184
00:10:48,156 --> 00:10:54,541
The way that photogrammetry works is that it's looking at these images and it's finding feature points on each of the images.

185
00:10:54,581 --> 00:10:57,824
They're areas of high detail that it can then correlate with other images.

186
00:10:58,445 --> 00:11:01,707
And then you can use trigonometry to position those points in 3D space.

187
00:11:02,788 --> 00:11:05,971
But on a big white wall, you don't have any points for it to find.

188
00:11:06,071 --> 00:11:08,593
It can't find any detail points for it to use.

189
00:11:08,994 --> 00:11:11,756
And so these are actually really hard situations for photogrammetry.

190
00:11:11,856 --> 00:11:13,457
Really you want to use a depth sensor at this point.

191
00:11:15,221 --> 00:11:18,686
I didn't have that. My mesh really looked like a mess.

192
00:11:19,927 --> 00:11:26,075
But luckily I stumbled upon this technique from a guy on YouTube who's a photogrammetry person around San Francisco,

193
00:11:26,916 --> 00:11:31,602
which is, it sounds crazy, but you take your mesh back into Oculus Medium, which...

194
00:11:32,223 --> 00:11:34,305
happens to be the perfect tool for this job.

195
00:11:34,905 --> 00:11:37,007
And I basically spent a couple of hours

196
00:11:38,769 --> 00:11:40,610
reconstructing and patching up my mesh.

197
00:11:40,670 --> 00:11:42,972
I sort of built out some computer monitors

198
00:11:43,152 --> 00:11:45,414
and I filled in the desks and tables.

199
00:11:47,916 --> 00:11:49,298
And at the end you kind of get this sort of,

200
00:11:49,318 --> 00:11:51,880
it kind of looks like you went to the dentist maybe.

201
00:11:52,060 --> 00:11:53,501
I kind of filled in the cavities.

202
00:11:56,384 --> 00:11:59,729
But the nice thing is you can then send this back into RealityCapture and it will happily

203
00:11:59,829 --> 00:12:01,191
reproject the textures onto it.

204
00:12:01,611 --> 00:12:06,698
So after I've kind of done all these sort of fill-in steps, we get something that looks

205
00:12:06,718 --> 00:12:06,998
like this.

206
00:12:07,018 --> 00:12:10,803
So this is the final mesh coming out of RealityCapture.

207
00:12:12,646 --> 00:12:17,328
And it's interesting to note because we weren't really going for a perfect scan.

208
00:12:17,428 --> 00:12:20,909
We wanted something that was close enough to reality that's going to give us a good simulation,

209
00:12:20,990 --> 00:12:23,791
but we weren't going to use this as a production asset.

210
00:12:25,471 --> 00:12:28,833
But I think it's interesting to note that even though the geometry is not perfect for this scan,

211
00:12:30,013 --> 00:12:34,155
it still feels pretty real because it's really the textural aspects that make it feel real.

212
00:12:34,175 --> 00:12:37,497
You need the depth to kind of give you the groundedness.

213
00:12:39,057 --> 00:12:42,560
But it's really the texture, being able to read the writing on the walls

214
00:12:42,600 --> 00:12:44,962
that makes it kind of just feel like an actual office.

215
00:12:45,703 --> 00:12:50,347
And here's a shot of the full thing kind of in Unity.

216
00:12:50,787 --> 00:12:52,849
I sent it through a couple of poly reduction steps

217
00:12:52,909 --> 00:12:54,370
just to kind of clean it up

218
00:12:54,430 --> 00:12:55,851
and get it something that could be rendered.

219
00:12:55,871 --> 00:13:01,156
Yeah, and all the textures came out as 8K, which is high,

220
00:13:01,236 --> 00:13:04,218
but it's not production again, and it renders on the Rift fine,

221
00:13:04,278 --> 00:13:05,039
so it wasn't a problem.

222
00:13:07,952 --> 00:13:10,773
So, we've kind of got our real world set up,

223
00:13:10,973 --> 00:13:11,853
which is good enough for us.

224
00:13:14,975 --> 00:13:17,756
The next step is, okay, well, we have the real world,

225
00:13:17,776 --> 00:13:19,157
but that's not really Magic Leap yet.

226
00:13:20,458 --> 00:13:22,198
Next step is the Scander Room.

227
00:13:22,519 --> 00:13:24,139
So, as it's looking around,

228
00:13:24,179 --> 00:13:25,860
it's making this mesh like I was mentioning.

229
00:13:28,021 --> 00:13:30,543
And luckily, we already have a mesh that we just made,

230
00:13:31,563 --> 00:13:33,004
so this step is a little bit easier.

231
00:13:34,996 --> 00:13:38,858
The only key consideration is the mesh that's being generated

232
00:13:38,958 --> 00:13:42,320
is not perfectly one-to-one with the real world, right?

233
00:13:43,201 --> 00:13:45,122
When you're using augmented reality platforms,

234
00:13:45,822 --> 00:13:48,144
it's pretty accurate, but there's always some holes

235
00:13:48,224 --> 00:13:50,005
or some geometry weirdness,

236
00:13:50,045 --> 00:13:52,146
especially around the corners of objects.

237
00:13:52,546 --> 00:13:53,607
And we want to simulate that,

238
00:13:53,667 --> 00:13:55,548
because if we just give you a perfect scan,

239
00:13:55,848 --> 00:13:56,889
you're going to be building your game

240
00:13:56,929 --> 00:13:58,130
assuming you have a perfect scan.

241
00:13:58,210 --> 00:13:59,951
And then when you go into the real device

242
00:14:00,351 --> 00:14:01,812
and realize it's not a perfect scan,

243
00:14:02,372 --> 00:14:03,133
that's going to be a problem.

244
00:14:04,837 --> 00:14:08,258
So basically what I did was I took the full mesh here, which you can see,

245
00:14:09,139 --> 00:14:13,500
and then applied another further poly reduction and added a little bit of noise on top of it.

246
00:14:14,520 --> 00:14:16,581
And that ends up with something that looks like this.

247
00:14:17,081 --> 00:14:20,923
Which, in my opinion, having seen some of these scans that come out of these devices,

248
00:14:20,983 --> 00:14:22,223
is actually fairly accurate.

249
00:14:22,963 --> 00:14:26,844
You can actually see sort of if you trace along the edge of the desk there.

250
00:14:27,922 --> 00:14:30,386
It doesn't quite line up with it, and that's what we want.

251
00:14:31,207 --> 00:14:35,833
You can see, I've overlaid it here just a little bit more opaquely

252
00:14:35,893 --> 00:14:40,619
so you can see how it sort of penetrates and kind of almost like has this spiderweb effect

253
00:14:40,659 --> 00:14:42,221
that you can sometimes see with scanning behavior.

254
00:14:44,052 --> 00:14:46,672
So this actually worked really well and was pretty simple.

255
00:14:47,933 --> 00:14:51,054
But the last thing for the scan mesh that is really important for gameplay reasons

256
00:14:52,034 --> 00:14:54,495
is that the mesh doesn't actually come in all at once.

257
00:14:55,015 --> 00:14:59,697
So this is a common assumption by people who start working on inaugural virtual reality.

258
00:14:59,717 --> 00:15:05,298
They're like, oh, my mesh is all here, but then they put their physics objects in the world

259
00:15:05,378 --> 00:15:06,579
and it just falls through the floor.

260
00:15:07,959 --> 00:15:10,700
So what actually happens is the mesh comes in in chunks.

261
00:15:11,140 --> 00:15:13,500
So as you're looking around, it'll load in a chunk,

262
00:15:13,620 --> 00:15:14,761
and then you sort of look over here,

263
00:15:14,781 --> 00:15:15,661
and then it'll pop in,

264
00:15:16,081 --> 00:15:17,801
and it'll sort of keep updating them over time.

265
00:15:18,401 --> 00:15:19,862
And we really want to simulate this behavior,

266
00:15:19,882 --> 00:15:20,582
because if you don't,

267
00:15:21,102 --> 00:15:22,883
you start designing lots of physics things

268
00:15:22,943 --> 00:15:25,423
that don't have backups and backdoors and things like that,

269
00:15:25,443 --> 00:15:26,823
because you need to handle these cases when,

270
00:15:27,604 --> 00:15:29,584
for instance, in Luna Moon Dust Garden,

271
00:15:29,604 --> 00:15:31,324
when any of the seeds fall through the floor,

272
00:15:31,545 --> 00:15:34,105
we have a custom animation that pops them back up

273
00:15:34,205 --> 00:15:36,766
and makes sure that they're in a good place.

274
00:15:38,647 --> 00:15:40,308
So in order to simulate this in our simulator,

275
00:15:40,328 --> 00:15:45,611
I basically threw this through like a fracturing operation.

276
00:15:45,711 --> 00:15:48,193
So I use Houdini because I'm an engineer

277
00:15:48,353 --> 00:15:51,715
and so that's the natural, for me it's a natural artist tool

278
00:15:52,115 --> 00:15:54,517
but there's a Voronoi node and I just threw it through that

279
00:15:55,238 --> 00:15:56,999
and it was pretty effective.

280
00:15:57,039 --> 00:16:00,361
So this, not exactly the way that it chunks in Magic Leap

281
00:16:00,401 --> 00:16:01,822
but it was enough for our gameplay

282
00:16:02,142 --> 00:16:03,503
to match up with the Magic Leap.

283
00:16:04,375 --> 00:16:05,676
And when we load this into the editor,

284
00:16:05,696 --> 00:16:08,759
we basically sort of stream these chunks in one at a time

285
00:16:09,279 --> 00:16:12,421
with a couple of heuristics about where you're looking

286
00:16:12,481 --> 00:16:13,582
and which ones might pop in.

287
00:16:14,483 --> 00:16:16,024
So you kind of get this nice chunky behavior,

288
00:16:16,044 --> 00:16:18,105
which is pretty close to the way the Magic Leap would work.

289
00:16:20,987 --> 00:16:22,949
So now we have our scan mesh.

290
00:16:22,989 --> 00:16:24,650
We've got our real world.

291
00:16:26,151 --> 00:16:27,372
The last thing we do is you need to figure out

292
00:16:27,392 --> 00:16:31,074
how to composite all of the game on top of it

293
00:16:31,635 --> 00:16:33,136
and make sure that looks accurate.

294
00:16:35,180 --> 00:16:39,824
So the biggest trick with the rendering of the Magic Leap

295
00:16:40,886 --> 00:16:43,188
is that the Magic Leap actually renders in an additive manner.

296
00:16:43,528 --> 00:16:47,432
So it's not like a screen, it's more like a series of projectors

297
00:16:47,492 --> 00:16:50,776
that use mirrors and lenses to beam light into your eyes.

298
00:16:53,959 --> 00:16:55,781
So we want to simulate this in our simulator.

299
00:16:57,789 --> 00:16:59,070
And it's important for our artists

300
00:16:59,150 --> 00:17:03,033
because the way that additive rendering looks

301
00:17:03,173 --> 00:17:05,374
is going to be very different than a normal virtual world.

302
00:17:06,135 --> 00:17:08,456
If you have a little bit of darkness or shadows,

303
00:17:09,197 --> 00:17:11,058
it's going to be almost transparent in the Magic Leap.

304
00:17:11,438 --> 00:17:13,780
And so we want to make sure that the simulator is useful

305
00:17:13,800 --> 00:17:15,541
for our artists to do art tests and things like that.

306
00:17:17,162 --> 00:17:19,363
So basically, we split our rendering into two layers.

307
00:17:19,604 --> 00:17:22,585
So we rendered the game in one layer,

308
00:17:22,666 --> 00:17:25,007
and then we render our 3D scan in a different layer,

309
00:17:25,287 --> 00:17:26,728
and then composite them on top of each other.

310
00:17:28,310 --> 00:17:32,734
Which also gives us a nice spot to add some post-processing for things like the field of view.

311
00:17:33,474 --> 00:17:36,677
So one thing to note on the Magic Leap is that the field of view is fairly small.

312
00:17:38,339 --> 00:17:42,322
And because of that, you need to make sure your gameplay is all within those sort of boundaries.

313
00:17:42,362 --> 00:17:46,066
If you start putting your gameplay all out here, it's going to feel very different than when you

314
00:17:46,626 --> 00:17:48,948
then drop it on the device and it's all in this kind of box.

315
00:17:50,939 --> 00:17:54,864
So we actually simulate the Magic Leap's field of view in our simulator.

316
00:17:54,904 --> 00:17:59,149
So in VR, you kind of see this square you're looking through,

317
00:17:59,809 --> 00:18:01,171
which is, I think, pretty accurate.

318
00:18:02,743 --> 00:18:07,366
And then sort of the last kind of consideration and the side benefit of splitting it off into layers

319
00:18:08,386 --> 00:18:12,309
is that one of the sort of the subtle quirks about the Magic Leap is that

320
00:18:13,890 --> 00:18:19,874
the real world can't really interact with the virtual world. So the whole purpose of having this sort of scanned mesh layer

321
00:18:21,115 --> 00:18:24,017
is that that's the layer that the virtual world interacts with and understands.

322
00:18:25,098 --> 00:18:25,238
But

323
00:18:26,079 --> 00:18:31,820
If you disable the scan mesh and you take your Magic Leap and you look straight at a blank wall,

324
00:18:32,561 --> 00:18:35,322
and then you render a sphere five feet into the wall,

325
00:18:35,382 --> 00:18:38,823
the Magic Leap will happily render that sphere and give you a fantastic headache

326
00:18:39,683 --> 00:18:43,904
because your eyes think there's a wall but there's also a sphere rendering there and it's very disorienting.

327
00:18:45,445 --> 00:18:47,446
So this is sort of a property of the way that this device works

328
00:18:47,506 --> 00:18:50,947
because it's basically just rendering something on top of the world as it exists.

329
00:18:52,738 --> 00:18:55,701
But we kind of want to recreate this because, like I was mentioning earlier,

330
00:18:56,101 --> 00:18:59,424
when the scanned mesh has holes in it, you can kind of have some of these artifacts where

331
00:18:59,924 --> 00:19:04,648
objects that are virtually under the table will actually sort of show through the table

332
00:19:04,708 --> 00:19:06,769
if there's not scanned mesh there to block it.

333
00:19:08,511 --> 00:19:11,553
So the nice thing about doing this compositing layer is we just ignore depth,

334
00:19:11,733 --> 00:19:14,675
and so we get these behaviors as well, which is really good.

335
00:19:16,505 --> 00:19:19,187
And then just to sort of show how it looks overall,

336
00:19:20,648 --> 00:19:22,268
this is sort of the same clip as earlier,

337
00:19:22,368 --> 00:19:23,829
and we can see how it kind of comes together.

338
00:19:23,869 --> 00:19:26,971
So we have the scanned mesh as a base layer,

339
00:19:28,691 --> 00:19:31,273
and you can see how the additive compositing

340
00:19:31,333 --> 00:19:32,893
and sort of the field of view ends up looking.

341
00:19:34,114 --> 00:19:36,795
And if you look closely, you can see some of the grass there

342
00:19:36,835 --> 00:19:38,296
as it conforms to the scanned mesh.

343
00:19:40,454 --> 00:19:41,974
But overall, this was a huge benefit for us.

344
00:19:43,255 --> 00:19:43,995
It really worked out well.

345
00:19:44,015 --> 00:19:49,538
So one of the things I wanted to talk about as well was the

346
00:19:49,578 --> 00:19:50,098
input layer.

347
00:19:50,178 --> 00:19:54,541
So that's to talk about the rendering, but we also want to

348
00:19:54,561 --> 00:19:57,682
make sure that the input is simulated so that when our

349
00:19:57,702 --> 00:20:00,184
gameplay designers are playing, they can make juicy

350
00:20:00,224 --> 00:20:02,305
things that feel good on the device.

351
00:20:03,947 --> 00:20:06,809
And kind of over the course of development of the Magic Leap,

352
00:20:06,889 --> 00:20:08,770
it went through a couple of phases of input.

353
00:20:09,211 --> 00:20:12,733
So early on, it actually only had three degrees of freedom.

354
00:20:12,813 --> 00:20:14,014
So it was more like a laser pointer

355
00:20:14,054 --> 00:20:15,275
than a fully tracked controller.

356
00:20:16,436 --> 00:20:17,857
And it was important to us that even though

357
00:20:17,897 --> 00:20:19,518
we were running the simulator on the Rift,

358
00:20:19,679 --> 00:20:23,582
that you only have that level of fidelity,

359
00:20:23,622 --> 00:20:25,083
so that when you're designing interactions,

360
00:20:25,443 --> 00:20:27,184
you keep in mind that you really only have

361
00:20:27,224 --> 00:20:27,925
three degrees of freedom.

362
00:20:29,026 --> 00:20:37,982
So by having a simulator, it allowed us to sort of like pick and choose and kind of closely match the properties of the Magic Leap as it sort of evolved.

363
00:20:38,082 --> 00:20:41,428
And when they developed Six Degrees of Freedom, we just enabled that on the Rift.

364
00:20:43,017 --> 00:20:45,119
We also did a little bit of things to add a little bit of noise,

365
00:20:45,179 --> 00:20:47,721
especially early on there was more noise in the tracking.

366
00:20:47,741 --> 00:20:50,343
And it meant that you couldn't do very precise interactions.

367
00:20:51,585 --> 00:20:54,027
And so we really wanted to actually, the noise was really important because

368
00:20:55,088 --> 00:20:58,671
otherwise you'd design these really precise VR sort of interactions

369
00:20:59,011 --> 00:21:02,214
and you'd take it to the leap and then it just doesn't really work because of the noise.

370
00:21:02,475 --> 00:21:04,757
And they've improved a lot of the input now, but it really helped us

371
00:21:05,677 --> 00:21:08,340
in the development process to make sure we weren't getting ahead of ourselves.

372
00:21:11,211 --> 00:21:16,957
Then the last thing I kind of want to talk about on the technical side is just sort of like the way we structure our API.

373
00:21:17,458 --> 00:21:23,424
And I think this is an important point because it helps kind of rein in the scope of what we were trying to work on.

374
00:21:24,945 --> 00:21:29,350
We didn't try to make like a general simulator framework like we were in.

375
00:21:30,471 --> 00:21:31,771
We didn't try to design it that way.

376
00:21:31,831 --> 00:21:33,932
We basically took the Magic Leap API

377
00:21:34,032 --> 00:21:37,014
and we one-to-one built an abstraction layer

378
00:21:37,054 --> 00:21:37,634
over top of it.

379
00:21:38,294 --> 00:21:41,016
And that meant that as the Magic Leap API churned

380
00:21:41,116 --> 00:21:43,957
and moved, it was very obvious to us

381
00:21:44,517 --> 00:21:45,798
what functions needed to change.

382
00:21:46,178 --> 00:21:47,439
So we just needed to go implement

383
00:21:47,459 --> 00:21:49,180
their new mapping framework,

384
00:21:49,460 --> 00:21:52,941
as opposed to have to recalibrate our own design framework

385
00:21:52,981 --> 00:21:54,502
and make sure it fits into our simulator.

386
00:21:55,943 --> 00:22:00,197
So it really made the maintenance work of keeping up with an experimental platform much, much better.

387
00:22:02,994 --> 00:22:09,258
So, kind of at the end, this was an extremely useful tool for us.

388
00:22:09,999 --> 00:22:11,660
We had a very short timeline on this project.

389
00:22:11,680 --> 00:22:13,981
It was like six to eight months with a fairly small team.

390
00:22:14,822 --> 00:22:17,144
And on experimental hardware, that's pretty crazy.

391
00:22:18,244 --> 00:22:20,466
We wanted to reuse a lot of the assets from Luna,

392
00:22:20,486 --> 00:22:22,367
but we actually ended up making them from scratch anyway,

393
00:22:22,607 --> 00:22:24,069
just for a variety of other reasons.

394
00:22:24,749 --> 00:22:28,932
So, being able to ship this in six to eight months was pretty incredible.

395
00:22:30,881 --> 00:22:35,706
A big point I think I'd like to make also is that having a simulator lets you insulate

396
00:22:35,726 --> 00:22:37,508
yourselves from an experimental platform.

397
00:22:38,029 --> 00:22:44,175
So one of the tricks of dealing with an experimental platform is that it's moving really fast.

398
00:22:44,916 --> 00:22:49,440
And that means that if it hits a bug or even just like a software update,

399
00:22:50,301 --> 00:22:52,522
that is kind of incompatible with what you're working on,

400
00:22:52,602 --> 00:22:54,643
that can just totally tank your workflow

401
00:22:54,683 --> 00:22:56,764
because you have all these artists who are working

402
00:22:56,904 --> 00:22:58,885
and then all the headsets now need to update

403
00:22:58,985 --> 00:23:00,366
and like, okay, they don't work

404
00:23:00,426 --> 00:23:02,507
because now we're hitting this bug because of the new OS.

405
00:23:03,888 --> 00:23:05,989
So having a simulation layer means that everyone

406
00:23:06,709 --> 00:23:08,130
who's not working directly on the device

407
00:23:08,150 --> 00:23:09,190
can work in the simulator

408
00:23:09,510 --> 00:23:12,231
and even if the device hits a hot reload

409
00:23:12,291 --> 00:23:14,172
or gets a new OS,

410
00:23:15,013 --> 00:23:16,794
you can keep working in your simulator

411
00:23:16,874 --> 00:23:18,955
until the engineers have time to fix it.

412
00:23:20,584 --> 00:23:22,665
And so this is a huge deal for us because

413
00:23:24,766 --> 00:23:27,767
basically it allowed us to push a lot of these bugs that you'd have to,

414
00:23:27,987 --> 00:23:29,508
that would have been critical bugs otherwise,

415
00:23:30,248 --> 00:23:32,609
kind of later in our development to sort of clean it up,

416
00:23:32,689 --> 00:23:36,290
especially after the platform has maybe moved on from some of those issues.

417
00:23:37,891 --> 00:23:39,592
So that installation was a really big deal for us.

418
00:23:40,213 --> 00:23:44,155
Another big deal was that it really allowed us flexibility about how we worked.

419
00:23:44,475 --> 00:23:48,178
So, especially with a lot of these platforms, they're heavily restricted,

420
00:23:48,658 --> 00:23:50,339
and you may only have like a couple of headsets.

421
00:23:51,840 --> 00:23:54,802
So this meant that we could work from home on our Oculus Rifts,

422
00:23:55,222 --> 00:23:57,984
and our audio folks in LA didn't need a Magic Leap

423
00:23:58,264 --> 00:24:00,466
to do all the audio juice that they were kind of working on.

424
00:24:01,526 --> 00:24:03,849
And this was just a huge quality of life improvement.

425
00:24:04,009 --> 00:24:06,891
Before we had this simulator, everyone who was working on the device

426
00:24:06,911 --> 00:24:09,894
had to be in a very small room with 24-hour security.

427
00:24:11,155 --> 00:24:11,596
And it was...

428
00:24:13,037 --> 00:24:15,780
Sad is the wrong word, but, you know, it wasn't that great.

429
00:24:17,541 --> 00:24:19,523
So this allowed us to basically kind of integrate it more

430
00:24:19,543 --> 00:24:21,565
into a normal development workflow that you'd be used to

431
00:24:21,625 --> 00:24:23,367
with Unity and your debuggers,

432
00:24:23,427 --> 00:24:25,168
and it's just vastly more comfortable.

433
00:24:27,177 --> 00:24:30,599
So then I kind of just want to wrap up with a couple of more design thoughts.

434
00:24:31,740 --> 00:24:36,704
So I think one of the tricks, having seen a lot of different types of simulators that people have built,

435
00:24:36,905 --> 00:24:39,387
and actually Magic Leap even has a couple of theirs as well,

436
00:24:41,388 --> 00:24:45,411
but one of the tricks of working with a simulator is making sure not to design to the simulator.

437
00:24:47,532 --> 00:24:52,574
We spent a lot of time trying to make our simulator accurate so that when we design

438
00:24:52,594 --> 00:24:58,116
these very iterative gameplay mechanics that the people designing them wouldn't fall prey

439
00:24:58,156 --> 00:24:59,417
to designing to the simulator.

440
00:25:00,317 --> 00:25:03,458
One of the big issues we faced, just as an example,

441
00:25:04,839 --> 00:25:07,361
was when we were trying to figure out the scale of all the assets.

442
00:25:07,621 --> 00:25:08,742
So we wanted, we were trying to decide,

443
00:25:08,782 --> 00:25:11,805
okay, do we want all these things to be 6 inches or 12 inches?

444
00:25:11,865 --> 00:25:13,146
Like, how big should the trees be?

445
00:25:14,567 --> 00:25:17,410
And we found that people would put things in virtual reality

446
00:25:17,450 --> 00:25:19,472
and be like, oh yeah, that's 2 feet tall.

447
00:25:19,872 --> 00:25:23,195
And then we'd drop it on the headset and it would be like 6 inches

448
00:25:23,215 --> 00:25:25,597
because you could actually have a ruler and you'd be like, well, that's much smaller.

449
00:25:26,678 --> 00:25:29,019
And we were very careful in virtual reality

450
00:25:29,039 --> 00:25:31,340
to make sure everything was measured precisely.

451
00:25:31,400 --> 00:25:33,221
Like, I don't think this is a technical issue,

452
00:25:33,281 --> 00:25:35,342
it's just that in virtual reality,

453
00:25:35,402 --> 00:25:37,503
it's just kinda hard to judge the scale of things.

454
00:25:38,103 --> 00:25:39,884
It's great, but it's not perfect.

455
00:25:41,285 --> 00:25:44,506
And so we had this issue where they would design the scale

456
00:25:44,586 --> 00:25:46,487
to virtual reality and then it just didn't really work

457
00:25:46,507 --> 00:25:46,968
in the headset.

458
00:25:48,709 --> 00:25:51,571
And so it's very important that your simulator is accurate in the right ways.

459
00:25:52,792 --> 00:25:54,054
Another example is kind of input.

460
00:25:54,354 --> 00:25:56,636
And I sort of already touched on this already, but

461
00:25:57,917 --> 00:25:59,979
if you allow yourself full RIFT input,

462
00:26:00,379 --> 00:26:03,162
that's a very different experience than the way that the Magic Leap works.

463
00:26:03,602 --> 00:26:06,625
It's just like a slightly different set of behaviors and affordances.

464
00:26:08,623 --> 00:26:12,126
So, and especially to me, as the project goes on longer,

465
00:26:12,186 --> 00:26:13,607
the simulator becomes more useful.

466
00:26:14,328 --> 00:26:15,729
You run into less of these pitfalls

467
00:26:15,789 --> 00:26:17,971
because you're not doing as much design at that point.

468
00:26:19,493 --> 00:26:21,454
But yeah, anyway, that's about it.

469
00:26:21,835 --> 00:26:23,836
If you have any questions, feel free to ask,

470
00:26:23,917 --> 00:26:26,339
or I'll probably be in the wrap-up room hanging out.

471
00:26:26,599 --> 00:26:27,260
So, thanks.

472
00:26:38,978 --> 00:26:40,360
Oh, and fill out your surveys.

473
00:26:40,380 --> 00:26:42,564
Hi.

474
00:26:43,105 --> 00:26:47,052
So it seems like a simulator is just sort of a really useful thing for someone developing

475
00:26:47,072 --> 00:26:47,674
a product.

476
00:26:48,976 --> 00:26:52,162
Was it something that the Magic Leap didn't provide or the one they provided wasn't good

477
00:26:52,182 --> 00:26:52,342
enough?

478
00:26:52,670 --> 00:26:56,551
No, that's a really good question and I have a slide on it, but I ended up cutting it for time.

479
00:26:57,311 --> 00:26:59,272
So, the Magic Leap comes with two simulators.

480
00:26:59,752 --> 00:27:07,094
It comes with one that's basically more, you have some like handles,

481
00:27:07,134 --> 00:27:10,195
you can sort of be like, okay I want the camera here, and I want the controllers here,

482
00:27:10,635 --> 00:27:13,976
but it's not really something you can play in real time, it's like sort of number input.

483
00:27:15,968 --> 00:27:18,710
But the more interesting simulator they have is Zero Iteration mode.

484
00:27:19,070 --> 00:27:21,311
So Zero Iteration mode is actually quite good.

485
00:27:21,431 --> 00:27:24,733
It renders everything on the computer and streams it to the device.

486
00:27:26,374 --> 00:27:30,497
The only problems with that is that the streaming is at about 10 frames per second.

487
00:27:30,937 --> 00:27:33,358
So it's usable for debugging.

488
00:27:33,498 --> 00:27:36,460
And that's what we used it most for, but it's not that great for gameplay design.

489
00:27:37,982 --> 00:27:40,566
The other problem is that you still need the device.

490
00:27:40,926 --> 00:27:43,170
And so we had a team of like 10 folks

491
00:27:43,450 --> 00:27:45,133
and we didn't have 10 devices.

492
00:27:45,694 --> 00:27:47,597
So having a simulator for the Rift

493
00:27:47,657 --> 00:27:49,079
meant that everyone could work all at once.

494
00:27:49,620 --> 00:27:51,563
So that was a lot of the big reason we built one.

495
00:27:53,928 --> 00:27:58,010
Oops. So I guess that, there we go.

496
00:27:59,770 --> 00:28:03,552
This is more of a funny quirk of the Magic Leap comment than a question.

497
00:28:04,772 --> 00:28:08,634
I was building an augmented reality lab application so you could do chemistry experiments.

498
00:28:09,074 --> 00:28:11,255
Worked perfectly at home, never worked in my office.

499
00:28:11,675 --> 00:28:13,896
And that's because my office has metal tables.

500
00:28:14,256 --> 00:28:14,557
Yes.

501
00:28:14,577 --> 00:28:17,338
So it's a magnetic controller and it completely loses tracking.

502
00:28:17,358 --> 00:28:18,698
Yeah, exactly. Yeah.

503
00:28:20,182 --> 00:28:25,548
Took me a while to figure that out, so if any of you see your controller just hanging in the air, make sure you're not...

504
00:28:25,568 --> 00:28:31,054
Yeah, that's one of those things that I would totally integrate into it, just randomly cause some dropouts, you know?

505
00:28:33,516 --> 00:28:33,656
Hey.

506
00:28:33,896 --> 00:28:36,397
So, Magic Leap does dynamic remeshing, right?

507
00:28:36,437 --> 00:28:38,417
Like, so as you're going along, it's changing the mesh.

508
00:28:39,097 --> 00:28:41,298
Did you incorporate that into your simulator at all?

509
00:28:41,338 --> 00:28:42,618
And how did that, because you could probably

510
00:28:42,918 --> 00:28:45,759
drop some seeds through as it remeshes, right?

511
00:28:45,819 --> 00:28:46,799
Right, yeah, that's a good point.

512
00:28:46,859 --> 00:28:50,220
And we didn't consider, or we didn't implement that

513
00:28:50,280 --> 00:28:53,061
directly, probably could have had like a couple

514
00:28:53,081 --> 00:28:55,661
of variations of the mesh and then swapped out those chunks.

515
00:28:57,420 --> 00:29:00,122
It was basically a pragmatic time versus

516
00:29:00,623 --> 00:29:02,104
how accurate can we make this trade-off.

517
00:29:03,305 --> 00:29:04,846
But yeah, that's definitely a good suggestion.

518
00:29:04,946 --> 00:29:05,887
Yeah, great, thanks.

519
00:29:05,967 --> 00:29:06,587
Great presentation.

520
00:29:06,687 --> 00:29:06,968
Thank you.

521
00:29:07,788 --> 00:29:09,430
Hi, great talk, thank you very much.

522
00:29:10,050 --> 00:29:12,352
Quick question, you said the project itself took eight months.

523
00:29:13,052 --> 00:29:14,834
How long did it take you to build the simulator,

524
00:29:14,854 --> 00:29:15,855
or was that an ongoing thing?

525
00:29:17,372 --> 00:29:19,594
So the simulator, it's a little hard to estimate.

526
00:29:19,714 --> 00:29:22,517
I would say we had it at a usable state after month one.

527
00:29:23,038 --> 00:29:24,359
It wasn't honestly that much work.

528
00:29:24,960 --> 00:29:29,724
This sounds like it's a lot more work, but the main amount of work was in the scanning.

529
00:29:30,105 --> 00:29:32,567
And if I had bought a proper rig, maybe that would have been a lot quicker.

530
00:29:32,962 --> 00:29:34,484
Okay, so it was just you building that?

531
00:29:34,704 --> 00:29:35,404
Yeah, pretty much.

532
00:29:35,484 --> 00:29:36,405
Okay, awesome, thanks.

533
00:29:36,625 --> 00:29:39,548
Yeah, it was, basically the longest part

534
00:29:39,588 --> 00:29:41,689
was just like matching the Magic Leap API,

535
00:29:41,729 --> 00:29:43,131
so we just kind of went through it and was like,

536
00:29:43,171 --> 00:29:44,912
okay, for input, we'll map that to the Rift.

537
00:29:44,992 --> 00:29:46,173
And for, you know.

538
00:29:46,553 --> 00:29:47,794
Gotcha, okay, thank you.

539
00:29:48,055 --> 00:29:48,195
Yep.

540
00:29:50,637 --> 00:29:50,757
Cool.

541
00:29:52,327 --> 00:29:52,447
Hey.

542
00:29:52,587 --> 00:29:52,847
Hey.

543
00:29:53,588 --> 00:29:54,668
So I just want to check.

544
00:29:55,368 --> 00:29:58,169
So how did you make sure, because Oculus Rift has

545
00:29:58,389 --> 00:30:00,469
their own specs for the hardware side,

546
00:30:00,509 --> 00:30:01,510
and same with the Magic Leap.

547
00:30:02,410 --> 00:30:03,970
So how did you make sure that things

548
00:30:03,990 --> 00:30:05,391
that would run on the Oculus Rift

549
00:30:05,491 --> 00:30:07,431
would run well on the Magic Leap?

550
00:30:07,471 --> 00:30:08,652
Performance-wise, especially?

551
00:30:08,672 --> 00:30:08,972
Yeah.

552
00:30:09,252 --> 00:30:10,372
Yeah, that was definitely a trick.

553
00:30:11,432 --> 00:30:14,233
We definitely fell a little bit prey to over, yeah.

554
00:30:17,667 --> 00:30:20,589
Yeah, not being careful enough with what will perform well in the magic leap.

555
00:30:21,529 --> 00:30:25,951
We were definitely still using the device every day and testing it.

556
00:30:26,011 --> 00:30:28,732
So it's not like we had really big performance issues.

557
00:30:30,393 --> 00:30:33,274
But it did mean that if you were an artist and you were working on something,

558
00:30:33,314 --> 00:30:35,715
you didn't necessarily have that immediate feedback that it was going to be laggy.

559
00:30:35,976 --> 00:30:38,977
And so we had to do a couple of passes at the end on performance,

560
00:30:39,057 --> 00:30:42,459
just to sort of go back and be like, okay, this mesh is too big or whatnot.

561
00:30:43,279 --> 00:30:43,519
Yeah.

562
00:30:43,619 --> 00:30:44,299
Cool. Good job.

563
00:30:44,780 --> 00:30:44,920
Thanks.

564
00:30:48,360 --> 00:30:50,626
Great, well, thank you very much. I'll be around.

