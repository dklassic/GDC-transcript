everybody. I just got the sign that the mics are now live so we can get started and try to figure out. So apologies first of all for not standing up but we kind of want to talk back and forth and it's just a little awkward if we're constantly standing up and sitting down. So we're just going to stay here and do it that way. My name is Paul. The title of this talk is a playful approach to prototyping. I think that's the title of the talk. And I'm Dan.
this is Dan Hurd. I'm the CEO and founder of Playful. Dan is the design director at Playful.
A little bit about who we are and what we've done very briefly because I'm thinking maybe you guys might have some ideas about that since you are here.
The game we most recently worked on is called Lucky's Tale. It's bundled with Oculus Rift. It's a third person character action game. This right here is a picture of Lucky. We released this game earlier this year with Oculus. It's actually on the box. And it's free to anyone who buys an Oculus. It's a pretty short game. I don't know.
like to say three to four hours but really you can beat it in like two hours. There's some surprising things about it in terms of it being a third person game and all that kind of stuff.
What we're going to do today is we're going to use Lucky's Tale and several other things we're working on to talk about how we have been using prototyping as a studio in VR and try to give you guys some thoughts and...
advice on, from what we've seen, kind of the front lines of doing VR work and our use of prototyping to get that done. So I think we're going to talk about sort of three different vectors on to that. The first thing is we're going to talk about how we use prototyping during pre-production. So this is kind of using prototyping to figure out what we even want to make. And there's kind of a chronology here, right? So.
So we'll talk about the early work we did with Oculus. We were, I think, maybe the first group to actually work with Oculus at the very beginning. We're going to then talk about how we've been using prototyping during development. And again, we'll be talking about Lucky's Tale and kind of showing off some of the things that, well, nobody's ever seen before. There are things that aren't even in the game. There's a lot of pre-production footage and prototype footage in Lucky's Tale, things that maybe will show up in some future game.
And then the last thing that we're going to talk about is how we use prototyping to Explore the frontiers and this is something that's that I mean We're like right in the middle of but we're just kind of going to open the doors up a little bit into our studio and Talk about how we're using prototyping right now to explore where we think VR could be going from here. So This is a picture as I mentioned of the very first visit to Oculus. This was during the kick starter when I first met these guys and we flew out there and saw the very early duct tape rift prototype. And I was like, I'm going to do this. I'm going We had worked on some games before this. The last thing we worked on before Lucky's Tale was Words with Friends. We had been through somewhat of a similar transition. We had been before that making AAA games. We worked on Age of Empires series, Halo Wars. We left that to do mobile games. That was this brand new set of problems and really all the things we learned about making AAA games just didn't apply and we had to completely figure it out all over again.
We came up with a lot of prototyping processes during that. This was kind of that all over again. That's how it felt to us. We showed up with these guys. They started asking us, you know, hey, we love some of your previous work. Let's do something together. We said this device that you made is the most amazing thing ever. It feels like this moment again like the first time we held an iPhone. This feels like that. So we want to do this again. And we'll leave all the iPhone stuff behind and we'll do this now. We'll make VR games with you guys.
And of course the first thing they asked us is...
So okay, what are you going to make? What's your awesome idea? And there's kind of where the problem landed at, my door stopped here. So okay. So I came home and said, okay, Dan, what's our amazing idea? We want to work together. We want to make something in VR. So what are we going to do?
So to be honest, we had absolutely no idea. I imagine a lot of you who are deving are faced with similar things. Here's a whole new hardware set. So how do we even approach that problem? There's just so many things you can focus on. So one of the things we didn't know is that...
The set of things that was going to be really amazing in VR was probably something new, something that was so tied to hardware, something that fundamentally changed the way that a game feels or controls. But we didn't know exactly what that was. So we said to set ourselves up for success, for finding those things, we need to have as many kind of shots on goal as possible. We needed to do just a very, very rapid set of iteration with the focus of kind of communicating this idea rather than even communicating full games. And we only had a couple of months to show what it was that we wanted to make. So we kind of gave ourselves these numbers of maybe we'll look at making about 30-ish games. If you think about maybe come up with 100 ideas of those, we're going to try and make 30 of them. Maybe of those, one or two might show some sort of promise or something that allowed us to continue. But that was the scale that we were looking at for this. So to accomplish that, we started to think about what is the smallest, kind of leanest, prototype team that we could come up with that allowed us to move very, very fast but didn't just go at this break neck pace without anything else that we would want, including art, including in many cases sound, anything like that. And we settled on a team that was basically two programmers and myself as a designer. And that's where we spent most of our time, just a very, very lean team.
team and then we eventually added a third programmer. So everything that wasn't within the scope of our abilities, we had to fake or hack to get it done. We didn't start off and say, oh, Oculus, we're going to make 30 games for you guys over a couple of months. We really started off with them saying transparent about, we're not going to tell you what to make or what we think should be made here. We need to get our hands on these dev kits. We need to spend time in VR and start feeling what's working and figuring it out. And I think we, you know, so we said, the way we're going to do that, as Dan mentioned, we're going to show you a lot of different ideas. We didn't necessarily set out with the idea that we would be doing 30 games. But we just kind of felt, you know, we kind of felt desperate to explore this really wide landscape as fast as possible, which is where this process came from.
Yeah, basically just find the things that just completely did not work and then those things that did find promise and that was both a hardware and software problem.
and we were expecting to be surprised. To tie back to the mobile thing, going from that transition from AAA game development to mobile, the set of things that ended up being important and perhaps set products like Words and Friends or Angry Birds or Clash of Clans apart from a lot of other folks that were building mobile games at the time, including Electronic Arts building a Scrabble game. That's kind of a little bit of a case study.
Electronic Arts, the original version of Scrabble on mobile.
was very different than the original version of Wards of Friends. It focused on a very different set of things. It was very graphics heavy. It had a lot of sound. It was all these things that they took as stuff that they were doing on console and they just brought it on to mobile. We were focused on what is it that's important about mobile as a platform. In that case it felt like it was launch time, speed of getting into a game and just playing it. You had to have these experiences that lasted 15, 20 seconds because you're on a phone.
we just assumed the same would be true for VR. So going from triple A game development and mobile game development now into VR, we started with that assumption of we don't know what's important about this platform yet, but we have to do this process to begin to figure out what are actually the most things we have to focus on to deliver the right things for consumers. So the kind of the ‑‑ so the kind of the Once we decided this was the density of prototypes that we wanted and this is what our team looked like, then our focuses were speed and playability. How many things can we put out and through play communicate the absolute core of what it is, even if we don't show what the game could be.
and we knew about seven prototypes a week. And we also developed this kind of rough outline of four hours to live for each of our game prototypes. So you have four hours to make it to prove your point. If you can't do it, it's okay. We'll set it aside. Maybe we'll visit it again later. But that's all the time you should need to prove some sort of mechanic or experience to prove that it could work. And for those that didn't, we set them aside. For those that did, that would often buy it the second half of the day, maybe even a little bit more.
that's even kind of how we talked about it. We talked about these ideas in kind of a Darwinian sense. If an idea couldn't make it past the first half of the day, then we would force the team, I mean Dan and I would force the team to move on to the next idea if it couldn't show promise in that first half. But games and ideas that we were prototyping could by themselves the second half of the day or perhaps the first half of the next day.
But really we never, I mean if we're trying to do five to seven games a week, nothing could ever get more than about a day and a half. You had to let it go. So that common designer thing of you just don't see it yet, it's brilliant, but it's just beyond the horizon or whatever, we weren't able to do that. Which hurt my heart.
But, you know, and the death ratio of these things is like so high, right? Again, that rough wisdom that's kind of out there, which is like maybe one in ten ideas is even worth kind of thinking about for a little bit, that applies here. And it was just so high, that meant we just had to do as many as possible. So...
and what it actually looked like from Oculus' side is we would give them a drop every week at the end of the week and it would be a document and a folder full of builds on Dropbox.
There would be anywhere from seven to ten, well, I think the lowest we ever did was five and the highest we ever did was eight or nine. And we categorized them into two groups, it was above the line and below the line prototypes. And above the line were ones that we saw promise in and thought could go forward and below the line ones we were still showing them.
to show them our failures and our prototyping failures that we were doing because we thought they were educational to some extent. Of course, they didn't always agree with us. Some of the things that we thought were below the line they thought had a lot of promise and vice versa.
Yeah, and the document that we sent with that kind of was just one sentence like here's the idea, just so it wasn't absolutely devoid of context. And here are the few things that we like about it and here are the few things that we don't like about it. Just to give them full context and we kind of ‑‑ said please look at those things only after you experience it and form your own opinions about what you like and don't like. So I wanted to look at three of those ideas kind of plucked from the 30 plus that we created. And they come from different points in that timeline. So we're going to start kind of with earlier prototypes and show you then through the later ones. I don't think we've ever really shown this stuff before so I think this is going to be a cool opportunity.
So the discoveries that led to this first prototype were some of those fundamental pieces of what makes VR really impactful.
And these were things we were seeing.
Oh, yeah.
This is not what we guessed or intuited in any way other than we built a few things that in other prototypes may have expressed it differently, but we said actually that one piece was really cool.
And so some of those were physics.
Physics are just delightful in VR, especially when something reacts roughly how you would expect it to when you poke it or otherwise manipulate it.
very, very delightful. Things coming towards you are really cool. Throwing things away from you is not as great. And the illusion of life, small little characters, things just bopping around. Even if it's not fully fleshed out, the fact that something is moving kind of helps sell this narrative of you're transported into this new place. There's this common thread I think you'll see through several prototypes we showed today where we we're not, we're just, we're wandering on this uncharted frontier. And the set of things that end up showing us promise, there's not a science behind it yet. I think it's like the dawn of filmmaking. In 40 years, 30 years, we'll have a language, there will be books written about it, academics, all this stuff. None of that exists right now.
So we have to use our intuition to say, well, okay, that feels good. We don't know why. The example Dan used is what made me think of this. Physics is an example of this. Maybe it seems obvious now, but heading into VR prototyping and development on this stuff.
we didn't point out and say physics will be the thing that feels good in VR. I'm not sure. I have theories why this is the case. There's several things like this. We'll talk about miniature scale, the use of light mapping. They all have this common thread which is for some reason these techniques are ‑‑ coupled with the headset and coupled with the sense of immersion, they're working well. They're creating a higher degree of sensation or emotion or presence than other things.
But the reason I say all that is this is not science. This is still just an intuition driven process right now. So this video that we're about to show kind of combines those several things that we were talking about. I'll just get that started here.
And this is completely ridiculous by the way.
So what are they seeing here?
Right, so some of the context for what this is, so you're a role here, you're a chef, and we wanted to, a couple of cool things that we discovered here was when you attach something to your head, it was kind of cool and kind of bad in the same breath, and it was just a very high fidelity way to control something.
this was actually during when we didn't know what Oculus controller solution was. Half of our prototypes were actually controllerless games. They were controlled through the gestures of your head because we didn't know they were a controller. This was mostly that way. We did, I think, eventually have a controller button that we could press that helped you flip and sauté these vegetables up in the air. But the idea was things, chefs throwing vegetables to you, you would catch them in your plate.
That was the first skill. The second one is you'd throw them up as high as you could, which is really delightful because you'd see things go way up and then crash back down, catch them all on your plate and you get a score for how high you sautéed them. It's utterly ridiculous, but it kind of was a result of several of those beats.
combination of some things that we were seeing working. For some reason things that were close to you, there seemed to be this sweet spot and we still believe this exists today with VR headsets and I think it has to do with resolutions and other technical things. Things that are right about here in arm's reach are perceived to have a greater sense of depth and presence. And so we wanted to put game play right there.
as Dan mentioned, physics was another thing. So this idea in and of itself doesn't make a lot of sense, but it's the combination of several of those concepts and saying how can we make some prototype that combines these things?
Right. And so this next one is kind of a secondary approach, which is, okay, that was a wholly new experience. We had never played a game quite like that. So it was risky on a couple different fronts, right? This next one was Okay. So there are a lot of mechanics that exist already that we already love. We've played many different games and fallen in love with parts of them over the years. So is there a mechanic or set of mechanics that when in VR or leveraging some part of all the control that VR gives you, those things, can they become a better version of themselves? So how do we reinvent a mechanic that we've seen before but just in this fresh new way that is bolstered by VR's presence?
And so here's our example of that.
And the...
I hope somebody makes this game, by the way.
This was really great.
This one was pretty cool.
So this was our Katamari prototype, and it's based on kind of that central mechanic that Katamari uses, which is roll things up and stick them to the ball and get bigger.
But here's the cool thing about why this was a really intriguing fit for us in VR, is if you play the game in 2D...
Katamari.
Yeah, Katamari.
in 2D, what they're doing is they're saying, well, here's the game about you getting bigger and rolling up these things, and the scale of the world just shifting.
And they would do that periodically once you reached a threshold.
But that's actually VR superpower. So they had to fake it in 2D and say, well, this is kind of where you break and now everything is just shrunken down. But in this prototype, we hacked the IPD, the interpupillary distance, kind of moved your eyes further apart virtually and it made you feel much, much larger. And we did that slowly over time. So as you rolled up all these ingredients into your ball, You don't know when, but at some point you're just like, I'm a giant. I feel like a giant.
And the quality of the ball and those pieces felt like a tiny little model.
And it's impossible to see on a screen like this because it looks the same. And that's the point.
The same thing in Katamari when you're playing that game on a 2D screen, even though the perspective changes and you realize that house is now smaller, you don't get that sense. But in VR, yeah, you're a giant at the end of this. And it happens so subtly over time, you can't even feel the effect.
And one of the takeaways for us once we had kind of played with this experiment was that scale shifts can be exceptionally powerful. At the time, there was no direct access to modify that value.
supports it. Oculus has something in their SDK called camera scale that was added in response to us breaking their SDK and doing it ourselves. And you can change this value in real time in the different game engines and get this effect trivially. It's just a single number. It starts at 1.0, which is a one to one scale. The other thing I just want to mention, from a prototyping standpoint, this is a very powerful tool, this camera scale tool, because at least with the engine that we're using right now for most of the things we do, unity.
It's actually challenging to work with assets on different scales because the unity editor doesn't let you change things like how fast the camera flies around and things like that. So if you shrink the world down and you try to move the camera forward an inch it flies past all your assets and this other stuff becomes a real pain in the ass.
by using IPD you can build things at a normal game scale where a character is what unity expects it to be, 1.5 meters tall and your trees are tree size and your houses are house size and then you can use, and we do this a lot in Lucky's Tale, you can use IPD to effectively get whatever scale you want when the engine is running and when they're in VR and not have to deal with all those editor problems.
And so this last prototype that we're going to show from the early days is we called it Super Capsule Brothers. You might notice some of the inspiration. And it kind of hit us by surprise because it's something that we did not expect, which was here's whole hog kind of a type of game that we loved. But in VR, third person for the first time felt very viable.
Specifically, this demo sold us on that idea before it was very much an outside shot from an idea perspective. And I remember when this idea came to life, too, because as we're kind of looking across this, as you can kind of see, we had maybe half of our prototypes were brand new ideas that were crazy and the other half were ideas where we were taking things that we already loved and trying to map them into VR.
one of the things that came across our radar was games like Mario and these great character action platformers. This was when I think Oculus started to tell us we would have a controller.
You give me a controller, those are the kind of games I want to play. We started talking about it. Of course we went where everyone would go initially. How are you going to see over the jumps you're making? It's not going to be making you sick and all this kind of stuff. And Evan, who is the guy in these videos wearing the headset.
proposed this crazy idea, what if you're not the character and what if you're just the camera floating next to the character.
And it sounded like the worst idea when we first heard it because it just seems to go against everything you want VR to be. Yeah, exactly.
And so, yeah, actually, it isn't moving. But some of the cool things that came out of this prototype that, again, we carried forward were we messed with the scale a lot here, too. So everything had a quality of a little model in front of you, a little toy. And you felt like you had maybe scattered your toys in front of you when you were playing in the toy box.
And that was directly building off of what the Katamari prototype showed us.
It was. And there was this fantasy that I think we we love to explore in games, which is I love to walk around and experience and explore the nooks and crannies of the world. And this prototype, that hit us so hard that it's like, wait, I don't have to deal with the abstraction of camera anymore, camera controls. I just look where I want to go. I can peer down into the tunnels and I can see kind of far and I can visually judge how my jumps are probably going to end up and not have that feel very abstracted.
And another amazing thing that happened here is all throughout our early work in prototyping VR and still remains true, we struggle with locomotion like everyone else. You go into these VR experiences and if you're just describing to a friend who has never tried VR before, the friend might say, oh, it would be so cool, I want to walk through a park, I want to climb a mountain, I want to do these things. As VR developers, you immediately run into the fact that most of those things make you sick, at least the initial kind of implementation.
And for us, one of those core fantasies was like, I want to exist in a world, a beautiful world, and say, oh, there's a mountain over there. I'm going to go to that mountain. There's a volcano.
I'm going to climb into the volcano or whatever, which is something you do in one of the levels in Lucky's Tale. And this was this eye opening thing because it was the first prototype we had ever built that allowed for continuous fluid locomotion through a 3D space.
that hit a certain comfort threshold. What you're seeing here, by the way, in case it isn't obvious, is the first prototype of Lucky's tail. When we saw this, we sent it to Oculus and said, we actually want to make this game. We're done prototyping. And up to that point we had been operating actually kind of under this this idea that maybe we're going to actually ship a collection of mini games. So this prototyping process dovetailed really nicely with that. And this was the game or the prototype that kind of broke us out of that mold. And we're like, actually, I want to keep playing this and I want to see what else is beyond that ridge. And so therein Lucky's Tale was born.
All right. So I want to move on to the second part, which is to talk about how prototyping is now in use or has been in use. So fast forwarding a little bit. We signed that deal with Oculus. We started working on Lucky Stoe. We worked on it for two years. What I want to give you guys is just more of a tactical set of tips and tricks for the folks in the audience who actually are doing live VR prototyping or thinking about doing it or thinking about building a VR game. These are some of the things that we're using on a day-to-day basis to build our games that are in production.
Okay. So there's just a list here and I want to go through these things. So the first and kind of obvious thing that I think everybody is probably aware of is Unity rocks at this.
Like Unity has become the home for VR prototyping and VR game development because its workflow is so iterative. It allows you to come up with an idea and see it just a few seconds later in the headset. That's a breakthrough thing. There's nothing that has more of an impact on our ability to move quickly with an idea than the ability to see that idea.
come to life, even in the most janky form, and anything that creates a delay, even a minute delay between here's a thought I have, what would it be like if this thing was bigger and being able to see it can kill the desire, even on an individual developer basis, to even ask that question. And you're like, well, it's probably good enough and I don't want to go through a build process or I don't want to do a bake or whatever it is.
Unity is built around that rapid iteration. The second point here which really ties into that is Unity has the most amazing thing with the asset store. We have a policy at Playful and we started this when we were tiny that if there's anything that any developer wants to buy on the asset store, don't even ask, just buy it and expense it. And we probably own three quarters of the asset store right now.
And we do that because you break it down.
You say, well, how much is 30 minutes of a developer's time?
How much does that cost us?
And how much do these pretty high quality assets on the assets cost?
They're incredible.
And they're all less than $50, $20.
Exactly.
And it's just like, well, you could spend an hour doing that, but that's going to cost a whole lot more and slow us down.
So we use the asset store daily. This isn't just about building prototypes that are for games we haven't built yet. I'm talking about when we're working on Lucky Stale and someone has an idea for a new coin effect or something like that. We'll go to the asset store first before we even ask anybody to build that thing. It's just a natural part of our day to day process now.
Everybody uses that heavily as a resource.
It's a perfect frame of reference. It communicates the idea and you tweak the response to that and the level of feedback you get. Once you have the desired response from your audience, you say, okay, now we understand. Now we build it ourselves.
Sometimes we don't. In fact, we went to E3 the first time we showed Lucky's Tale. For the folks who saw this, I think it was E3 2014.
half the game was asset store stuff. Not half. There was a ton of stuff. All the creatures and the bad guys. You would think going into that, we're going to show this to the public, we're in the Oculus booth, everyone's going to be like, I can't believe you used these asset store assets. Not a single person noticed or mentioned it. So not that you should, I mean, you can ship these things. They're all open licenses. You can put them in your games if you want to.
As Dan is mentioning, we tend to replace, by the time we finished Lucky's Tale, we were on this quest in the last four weeks to make sure every last asset had been replaced by something we had made. But those things will survive in our games for quite a while. So, I'm going to kind of segueing from there, there's this asset on the asset store called ProBuilder that some of you guys might have used. The reason I call this out is because in terms of creating VR environments, ProBuilder and specifically the combination of ProBuilder and the light mapping engine in Unity is a godsend for rapidly building compelling VR environments. So here's the thing, if want to build a great looking house and I want you to feel like you're inside of a house, generally that's a difficult problem requiring a lot of art and assets and other things that, you know, there's a lot of effort there. We found, and you can see this directly in the art style of Lucky's tail which has no textures, is all mostly solid color surfaces, we found that the combination of geometry, and letting Unity's light mapper do the heavy lifting was like this magic trick for VR. We could take a cube and put a light in it and run the light mapper and get something that when you put on the headset was like, wow, I just really feel like I'm in a real cube right now.
And that's a key word, feel, because that's something that is hard to quantify and one of our main just prototyping is. So sure it can also technically work on the screen. You may have completed the task that you set out to do. But it's not accepted unless we've tested out in VR every single time. And that seems basic. But when you're going fast, sometimes that's the part you're just like, I'm pretty sure.
it works. But feel is so strong here. And with ProBuilder and lighting, we've done several, many, many prototypes where we just need to rough out a space and when we do that, it can feel real even though it even has default kind of ProBuilder grid texture all over it. The first time I was ever truly fooled in VR development, unexpectedly, was through a VR table tennis game we were prototyping and it was all done in pro builder and when I was done playing tennis I just went to put my paddle down on the table and of course it crashed to the ground and almost broke. But I had never been fooled in that way and it was like ultimately it didn't matter that there was a grid on it or that it didn't look exactly like a table. It felt like a table.
The reason this is a magic trick is because Unity is doing all the heavy lifting here. It's a pain and it takes time and it's getting better. Unity just announced a progressive light mapper the other day that makes this way better. But anyway, ProBuilder, what it is, it's a tool for building this geometry rapidly inside the editor. If you have an idea for a tree, almost anyone can build the shape of a tree using ProBuilder and you hit the light map button, you set some colors on it and you can get a surprisingly compelling result with no art and no work. I'm not saying the art is incredibly important. The overall aesthetic of Lucky's Tale is what it is because our artists use those tools to make a cohesive scene that was lovely.
But it started off with these techniques and in fact, this is kind of what...
Dan is touching on. A lot of developers are not doing this right now. What I see more often than not is using these super high end triple A game development techniques that we know and love, things like normal mapping and specular mapping and all these things. Some of these techniques are not that accurate. They work great on a TV and you can't tell, but in VR with binocular vision and all the things you get with a headset, your brain can tell that that specular highlight or that reflection or whatever advanced technique isn't actually correct. And you don't, you know, it doesn't leap out at you like that's wrong, that reflection is broken. But instead it just leaves this feeling of, I mean, I feel like I'm looking at a video game, not I feel like I'm in an environment.
by using these simple materials, we sidestep that. So as I mentioned, Lucky's tail ended up with just diffused surfaces on almost everything with color and high quality light mapping. The other side benefit of that is it forced us to have high geometry. If you're looking at a surface like a plank of wood, the difference between putting a texture of wood on that and carving out the divots, again in VR is a night and day thing. You move your head a little bit and you can see the parallax in the details of the geometry and you buy it way more and it creates that sense of presence. The last thing we wanted to mention here is just the strength of programmer animation. So, you know, we would have an idea for a creature.
and we want to build a concept and create the mob and animate them and do all these different things. What we found is we could get so much use out of this basic ‑‑ set of techniques. This comes from Disney. This is quite old. This is a great thing. You can actually find videos on YouTube about this. This is a one‑pager. These are the basic principles of motion design for animation. You can take just a square, just a cube, and make it feel delightful and come to life. This is especially true in VR using these techniques. We use this all the time. Before we even know what a mob is going to be, we can take a cube and make it something you want to endlessly play with.
in VR using these core techniques.
Just scale it at the right time, give it a little bit of a sound effect, just give it a wobble, a slow down.
Those things are very, very impactful.
But more importantly, when we're prototyping very quickly, they enable us to not say, well, it's good enough, but it doesn't read correct, but we don't have an animator.
It allows us to do several things that a programmer can very quickly whip up.
going to go through a couple of these pretty fast. We really want to talk about the last section of this. Just the thing I wanted to say here is when you're doing this process you may feel like a little bit of a fraud. We did sometimes and we still do sometimes. The reason is because we come up with an idea and then we go to the asset store and we download 50 different things and we wire them up in the most hacky way possible in unity.
We finished a prototype, here Oculus, look at this amazing thing we made.
And we maybe wrote 20 lines of code and basically just wired things together and we used this, we're cobblers, we're not game developers when we're doing this.
But we gotta get past that because the point is to come up with these ideas and do the most rapid thing to showcase the potential of them, to prove that they deserve to have more time and more investment and that's really our job at the end of the day.
it's to build the experience and not to build the game. The moment we start building the game, we're already sunk because we're solving all those really hard problems that come with making a cohesive experience like that. So we wanted to kind of wrap up this section by talking about some of the problems and that's one of them.
You know, one of the other techniques we use from a prototyping standpoint, the studio, is we run these game jams.
Game jams are very expensive.
We take the whole studio, we spend a couple days doing this.
It's always a fight with management, of which I'm a part, to make these things happen, but they're always valuable to us.
But one of the things that I see universally happens with game jam teams, half of our teams, well I don't know, some percentage of our teams will just, you know, no matter how many times we say this, they'll get hung up in, okay, I'm gonna make an RTS.
That's my game jam thing.
I want to show what a VR RTS could be.
And then they start listing out all the things that a VR RTS would need.
We're gonna need pathing, we're gonna need, you know, units that have certain, we're gonna need hit points and stats and game balance and all these things.
And then they are like, okay, and then they spend the three day game jam building pathing.
and at the end of that they have some units passing around and nothing about that demonstrates what would be compelling about a VRRTS. The flip side of that is we'll have teams that throughout that process are like, okay, what, and they're being really honest about it because they might want it to be a VRRTS.
and we actually had this video we cut out of this. There's this one thing we did, it was a tactics VR, it was a room scale tactics thing. And they had this big idea of doing this turn based tactics game. One of the things they started, that they threw in there at the very beginning of that was a dice mechanic where you could pick up, scoop up a bunch of dice and throw them on a board and they would roll around.
that was where the fun was in that prototype. They focused on that and put a lot of effects and things in the dice and that made for a much better result than if they had tried to actually stand up a fully working tactics game in VR in just a few days.
right? And you know, something that's not immediately intuitive, but so having been a part of a lot of these R&D teams is, so you're working on this stuff and you're going really quickly and you're building a lot of prototypes, but realize kind of, especially in the context of a larger organization, you know, so we have actual game teams building and shipping products.
and you're on this prototype team and you're like wow that's nice it must be nice to ship something and to feel accomplished and show people your work right? You may not think it would seem that way because it might be like oh that's so cool I get to just prototype a bunch of stuff but it's pretty fatiguing. You open all these loops and rarely do you ever get to close them.
So we have to be very, very cognizant of what we call prototyping fatigue.
Which is, you may not realize it, but it creeps up on you.
And we kind of like to, and we're defining this as we keep working on this, making it better.
We let people come in, and when they're burning with ideas, and we let them prototype, and then when they start getting fatigued...
We rotate them out. We look at our R&D teams and prototype teams as tours of duty. We kind of separate that out from the process of shipping something. It's a really enjoyable process, especially if you just shipped a game or you've been in production for a while to go and participate in this for a while. But it gets on fun over time just because of the, you know, you can fall in love with something and then it's immediately, let's move on to the next thing.
So anyway, that's how we balance that across the studio. The other thing I just wanted to call out here is, well, first two things. These new ideas and these prototypes, they have to be protected because they're, as Ed Catmull says in the book Creativity Inc., they're ugly, awkward babies. And they are. They're so easy to kill them with the wrong words of critique.
And we have to protect those things a little bit. The other thing is for us, we just have to figure out how we're defining success. This is more, it's kind of an aside, it's a little bit of a culture thing. Every time we, as Dan was saying, every time we dive into one of these prototypes, we ask ourselves what do we want the player to actually feel?
And despite this being a key part of our culture, we still get lost on this all the time and we'll find ourselves working on something and saying things like, this could be the next clash of clans. And it just doesn't ‑‑ none of that ‑‑ we're so lost when we're saying things like that because ultimately ‑‑ the way we define success is did we set out with a vision and at the end of that someone was able to play it and they said I felt this and that thing unprompted is what we said when we set out.
And so like Lucky's Tale is a good example of this for us recently because when we were building that game we used these phrases, we said we want it to feel like you're on a Disney ride. We want it to feel like for some people.
the first time they played a game like Mario 64. Then we released this thing into the wild and we go on Reddit and we're reading people saying it's like the first time I played Mario 64.
And other people saying it's like being on Pirates of the Caribbean or on Small World or something. And there's no greater measure of success for us than that. Even if it sells five copies. If that can happen, then we're being successful in terms of taking a vision and translating it into a final product using ‑‑ this prototype. I think that's the strength of VR. That's the promise here. I can make you feel something even more impactfully than we've been able to do before that. So. Okay.
Here's the result of some of these things put into practice. This is a couple minute video of Lucky's Tale I mentioned at the beginning. Things that have shipped and a lot of things that haven't.
So this is all pro-building.
you play lucky cell you recognize how many things we have not shipped yet. Okay. Last thing we want to talk about. We'll try to go as fast as we can. We have 15 minutes left. So this is something we're working on right now. We want to use this last section of the talk to give you guys a glimpse, really the first time we've even talked about this or mentioned the name of this, into something that we're working on right now and to explore the boundaries of what ‑‑ where VR could go from here and specifically where social VR might be going from here which is really fascinating to us. Just some caveats. This is not a product announcement. This is just a glimpse into our R&D labs. We don't have a product to announce here. This may never turn into anything and the last thing I want to do is disappoint someone. But this is, you know, for the sake of this talk and talking about prototyping, I think a useful view into what prototyping looks like right now today at Playful.
this is kind of like a container, like a fictional container that we want to pour in all of this new prototyping that's specifically geared towards social VR and social connection. And so it helps us talk about it to other people and even to ourselves internally. It's almost like a laboratory. That's what Wonderland has become for us right now. So we have all these questions, these things that we're fascinated by when we think about social VR.
and we created this project as a container, a playground effectively for us to run those experiments and learn and do this work. So why that? Why Wonderland? Why this vector? So we've been doing this work in VR now for three years and even since the beginning, especially since I got that very first DK 1 headset and it came in this polycarbonate case with foam and everything and I felt like I was living in a William Gibson novel.
And certainly since then, especially now recently with some of the things that you guys are seeing that Facebook is showing off and where it seems obvious that these things are headed when you think about social VR. This is what comes to all of our heads. It's the metaverse.
This is the ultimate dream of what it would be like to be in VR.
in a world with other players or people and experiencing this incredible alternate reality. These are some of the books that obviously inspire us. There's tons of other media, too. So this is what we're all dreaming about. And the question that I have for us and for the studio is, so if this will exist in the future because we all collectively are dreaming about this thing as a society, when will that happen?
and when I look at things like the Vive or Oculus Touch, what I see is the dev kit for that future. I don't have any false expectations that the Vive is going to go on to sell millions and millions of units and become the tool for the metaverse, but I can see the light at the end of that tunnel now. These things are inevitable. These devices will turn into a pair of glasses and they'll be mass market consumer devices in just some number of years depending on what you believe. Maybe 5, maybe 10, maybe 3, who knows?
But the point is, if that's where we're definitely heading, when is it too early or too late to have started to work on that thing if we're interested in it?
And my answer to that is now.
Now's the time.
I mean, some of those questions, they can be easily worked on right now because they actually are affecting the current products we're making, their challenges, huge outstanding challenges for making games in VR in general.
And they can mature over time into kind of these final solutions.
And you know, the way that I think about this as the CEO playful is I don't really think about this too much in terms of going for the long-term goal of this. Because like I said, I don't think that can even exist today with the way the hardware is and how expensive it is and all these other things. So I can't really build the metaverse yet. But I think I can start to figure out...
pieces of it and things that need to be figured out in advance of potentially being part of building that together with hopefully you guys. Of course our version of what the metaverse looks like is not necessarily what's on the covers of these books. We think about it something more like this maybe. I don't know.
It's a happy place.
It's a silly place.
Yeah, we draw inspiration from games like Animal Crossing and from these kind of lighthearted worlds that, you know, because when I think about where do I really want to hang out, I basically want to hang out on Main Street in Disney World.
If I'm given the chance to escape from reality, and of course I grew up in Miami and went to Disney World when I was a kid, so that's where I draw inspiration from.
everyone, different companies have different takes on this.
This is our take.
We want to give that delightful, and again I mentioned Animal Crossing, because it is such a wonderful example of that.
Animal Crossing is this place that it's almost less about the game and more about your experience of just living in that world and the ambience of it.
It's an escape.
And currently we can just hang out in an alleyway if we want today. So this is something we can't do today. I can't live on an island like this easily. Okay. So this is an immense, immense problem space.
I couldn't list off all the things that need to be solved by us as a community of VR developers to begin to realize the full dream of the metaverse. But let's just talk about some of them and we'll give you guys a view into our prototyping against some of these problems. So kind of going down the list, as I mentioned, this is a short list of some of the immense problems we face. Let's pick three of these and show you guys kind of our live prototyping against those problems.
Right. So we're going to live in this little or spend a lot of time in this new place. So we need some sort of representation of ourselves. And we've seen a lot of, even existing currently, a lot of different approaches to avatars and to what that can mean for your ability to express yourself. Most notably, we've seen a lot of just like the head and the floating hands. Specifically because bodies are really difficult.
well and it's also, I mean it makes sense right? VR headsets right now can only track your head and your hands. We don't have, there's not a consumer grade solution for tracking your entire body yet. Although it seems obvious that will be coming. But because of that, I think a lot of developers are choosing to say, okay, we'll just show the floating head and hands.
But for our goals here, which is I want to feel present in a co-location, I want to be co-located with another avatar and feel very present in that world.
Bodily present.
We need to have a body.
And so...
Well, that's what we saw from our prototypes.
Because we did try all the versions of this.
We tried floating heads, floating torsos, all this kind of stuff.
We just kept coming back to that when we did do the full body rig.
it felt more like I'm here with you than any other version of that that we've built.
And it works, you know, we've done some work to kind of help make it feel better and obviously in this prototype phase it's not about getting it perfect, it's about communicating gestures, big emotions through the face or through cartoon effects and just big gestures and we think over time those animation quirks and things will actually will get better.
Yeah, along those lines, one of the things that we've recently started to think about in when it comes to avatars for social VR is we've started to think about it more as puppeteering than avatars.
You know, there's just, and this again, we're a game company, right, so we're going to be drawn to stuff like this, but we just have so much fun when we create these leveraged things that you can do with your avatar so that, oh, if I go like this and I just make that gesture, my whole avatar responds to that. I make a face, I do all this stuff, I have these cartoon effects that come off of me. And what happens over time is you start to play that as a game. Oh, it's so much fun to control this puppet that is me. And, you know, it's delightful and fun. Beyond just being an avatar. We're putting on a show for our friends, right?
So another one is locomotion obviously. So we have some avatars co-located together.
So how do we move from place to place? How do we explore this interesting world we've created?
And so we are using in our prototyping right now, we've done a couple different approaches, so there's a lot that is out there right now that focuses on teleportation.
which has... We were convinced for quite a while that that was how this had to be solved.
We went in with that because one of our goals was, so say that you're standing right next to me and I want to hand you something. Well, if we're teleporting around, maybe one of the things that happens is I hand it, but a real world wall is right in the way between us. And then I'm like, well, how do I get to you? Do I need to kind of teleport back and then kind of rewalk forward? And there's all this complexity around that. And you lose complete idea of where you are in space in the real world. And so...
first attempt at this was we'll teleport and we'll stay here to kind of the chaperone area. An example of this is we were just dealing with simple things like a kitchen. So you're sharing a kitchen with a friend in VR, social VR. If I, if I, if I If my space, my room scale space isn't mapped exactly to yours, I could be standing over by the fridge and say come over here and look at what's in the fridge. You might start to try to walk with me, walk towards me and run into a wall because you're actually standing on the edge of your space. You can see this problem exist in lots of different social VR applications right now. One that I love is the pool nation guys. It's a good example of that. You can share your playing of the space.
pool table but you're constantly losing your orientation within your room and having to manage how do I take steps back and re-teleport and get aligned with my friend. This isn't so much a problem in single player VR experiences but in social VR experiences where that space between you and another person feels like, yeah, and if there's actually a physical wall there but you don't know it, it causes a ton of problems.
So it took us a while to be very candid with ourselves that actually our current approach was fighting against our goal which was still unifying this connection between social avatars.
And so we ended up kind of rolling our own version of something that electric night owl had worked out which is the arm swinger locomotion.
and kind of our thoughts behind that was, well, how can we make those controls fade into the background even more? So I'm not fumbling in the dark for some sort of D pad control that pushes me forward. And for those of you that don't know, it's essentially kind of grab the controllers and swing your arms like you're walking.
and it's not a smooth forward progression either.
It's kind of like a halting forward motion that you might expect if you were walking.
And these aren't perfect solutions.
That's one of the main things we wanted to really underline here.
But these are approaches that we're currently.
we like more than we dislike for various reasons.
Yeah, the thing that's neat about Arm Swinger, that we were running into when we had teleportation, is again, you'd have these moments of, okay, let's go over there and follow me, and then you'd have to follow this, like, teleporting trail of the other person, and it didn't feel at all like taking a stroll with somebody.
Yeah, it totally broke the fiction, because in this world, things are persistent.
Things have weight, and the moment you teleport, it breaks that.
It breaks it for anybody who witnesses it, but it also kind of breaks it for you.
breaks the social. And breaks the concept of distance. So the last set of, well, one of the things we've been focused on, another big thing we've been focused on is the persistent living world aspect of this. So one of my favorite experiences I've had in VR, and I think a lot of us have had, is the lab that was built by Valve.
This was shipped with the Vive. It's the neatest thing. It's got a collection of different experiences. They're all tied together by this lab environment where really you're just supposed to walk around and teleport inside of these different mini games, right? Well, after I played all those mini games, I found myself returning back to the lab just to hang out in that space. And there's a dog there and there's like a white board you can ride on and there's a couple of little toys you can play with.
And then there's these forklifts and stuff driving around.
And anyway, it just felt like the most real virtual space that existed in VR at that moment.
And I just wanted to spend time in there and really get a feeling for it.
So I did, I spent a couple hours in the lab.
And I did all this stuff.
I drew things on the whiteboard, and I played with the dog, and I did all these things.
And then I had the most disappointing moment when I came back the next day and that was all gone.
the dog was back where it started. Nothing I had written on the white board was there. All the changes I made to the environment were wiped out. It's because Valve wasn't looking at that as a persistent world. They were using it as a lobby for these various experiences. But what I realized in that moment was that's what I wanted to feel that somehow still doesn't really exist. Even in some of my favorite games like job simulator, I never have that moment, that feeling of I can go into the space, I can make these changes and they stay there. When I come back I'm going to pick up where I left off. That book I left on the shelf is going to still be on the shelf. So this was kind of a starting point for us. Well, that seems really important. Clearly having a persistent world is a key part of doing a kind of metaverse type of thing.
So we focused on that. The other thing that we realized as we started to build this in a social context is that just having persistence was great. But the most delightful version of that was actually when not, oh, that book is on the shelf because I left it there, but wait a minute, that book isn't on the shelf anymore. It's on the counter because my friend was here when I wasn't here and they read my book and put it on the counter.
Like, that was this amazing feeling, because not only am I coming back in to see the changes I made, I'm in a world where other people are making changes, and, I mean, it's just, it seems obvious, right?
But when you experience this in a persistent social VR world, it's kind of a mind-blowing thing.
And then the most, most delightful version of that, which we've just started to see in recent prototyping work that we're doing here, And this, to explain this, I'll tell a little bit of a story.
So in our pursuit of doing the great with friends games on mobile, we tried to make a lot of them and tried to get them to be as successful as Wards of Friends.
Nothing was ever as successful as Wards of Friends.
I have a theory for why that's the case.
And it's basically the fact that We did other games, chess with friends, we did these various puzzles with friends games.
None of those games had the same moment of personal expression that words of friends did.
When you get a words of friends move from your friend, it doesn't feel like it's a move an AI could have made.
It's your friend choosing the word that they want to play and you see them in that move.
You get, you know, it's like, there's my friend.
It's a little packet of their personality, their self-expression in that.
And when we did something like chess with friends...
and you get the move from your friend and it's pawned to queen six or pawned to e6 or whatever, it's like, okay, that could have been made by anybody. I don't really see my friend in this move. So applying that to this, the most delightful version of social persistence and presence is when your friend cannot just move the book from the counter to the tabletop, but can actually leave a note in the book for you.
That's where this stuff truly becomes, I mean from the sense of an emotional connection into these worlds, that's where it truly comes to life from what we're seeing. Last thing I wanted to show you guys and then we have a few minutes for questions. This is just a video, another couple of minutes showing this game, not even a game as I mentioned, just an R&D project in motion.
Yes, that is karaoke.
♫ Don't want you to just dance, dance, dance, come on ♫ All those things I shouldn't do but you dance, dance, dance ♫ Ain't nobody leaving soon so keep dancing ♫ I can't stop the feeling Thanks a lot for coming today, guys.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
If you have questions, there are microphones.
We have a few minutes.
Looks like there's at least one microphone right there, anyway.
Yeah.
So beyond interactive design, do you think that applications like Tilt Brush would benefit your current workflow for prototyping environments and characters and to see how they feel in VR?
absolutely. And there's some really neat experiments with this recently. If you Google, there's some people that are rigging up tilt brush creations, taking them into Z brush or Maya and giving them a rig and bringing them back into VR. The other thing that is kind of related to that that I'm fascinated by is unity on real, I'm not sure if you can see it, but they're putting a lot of effort into bringing their editors into VR and there's just these great experiences you can have where where you know You'll be in VR developing the game from inside VR and and and to tie back something I said earlier It's the most iterative form of that development because you can say that That monster is too big and then literally just grab them and make them smaller and be like yeah Actually, that's pretty good, and there's no there's no cycle time there You're doing it live and those changes are being saved so you can even see some of this work happening in a different form in Facebook's like their space pen where they're drawing in space and then using that to be part of your costume or something. I think there's another huge opportunity for how Tilt Brush interfaces with that process.
Yeah, so to answer your question, I think those kind of tools are going to merge. I think you'll see Tilt Brush like tools inside of Unity and Unreal and you'll see more Unity and Unreal game editing tools inside of Tilt Brush.
Hello. You spoke to what you went through with teleportation and other movement tests and you eventually came to the, you know, as of right now the arm swinging. As of right now. As of right now, of course. Do you find that that helps with the entire motion sickness thing? Does it help fool the mind a little bit better?
why it was one of the things that we eventually kind of wanted to explore more fully and bring into this world was there's something A, about standing, that helps, but that smooth sort of acceleration and deceleration of like a D-pad movement or analog movement is really rough.
and what we've seen from this is that because it's more self guided and you have this sort of context of what a step might be and it's not a smooth process. It's definitely kind of like a halting and there's a lot of different pieces you can modify in the way that you move. That has actually raised the comfort threshold. So not everyone is 100% comfortable but we're actually getting fewer reports of any sort of motion sickness and more kind of like when I stopped using it I felt like my motion was wrong in real life.
example Dan used earlier. If you've been skiing all day and you take the skis off and you're like I feel like I should be able to ski down this hallway right now. It takes a while for that to wear off. That's what happens here. You're walking all day doing this and your legs stop moving. You take off the headset and you're like I'm going to walk out of the room and do that without taking steps. I have to use my legs now. That's why we're exploring it right now. Thank you.
Hi, I'm Rob Yagno with the Google's VR prototyping team.
This is great work.
Your speed of movement is really impressive.
One of the things that we're finding is that especially as we're moving into the social prototyping space, it really multiplies the complexity having to work with different clients and get your networking code working.
Any tips for continuing to move quickly while prototyping social?
Yeah, I mean, that's one of the ones that we're trying to figure out ourselves.
Probably the most lengthy part of developing this was the networking piece of that.
So I can talk about a struggle. This certainly would be something for the VR hardware developers. The only trick that we know now or that we're currently utilizing to try and make social VR prototyping go faster is And, you know, I hate this too. Doing single player games is so easy. Doing multiplayer games is always hard. This isn't unique to social VR. When we were doing age of empires and I was doing the multiplayer stuff, it was a nightmare. All testing gets multiplied by and all user testing and play testing, the complexity gets multiplied by an order of magnitude. That's definitely true here. But it's critical to keep that up and running. We've had several times where we've kind of let it go for a little while and we switch back to single player play testing because it's just so much easier and we're getting totally false results out of whether something works or not, whether it's good or not. You know, the teleporting thing is a great example. It's a perfect example of that. We were so fixated on on solving for motion sickness, which is a good thing to be fixated on, that we pushed really hard in this realm of teleportation.
And while we were doing that, multiplayer stopped working for a long time, and we spent a while on it.
Finally, when we brought a playtest back up and running using teleportation in social, it was like, oh crap, this, you know, it's just really not feeling good to share a space and be teleporting around all the time with another person.
So anyway, the key is keep it running, make it a super high priority, otherwise you're gonna get false positives and negatives.
So maybe actually we can start taking some of our questions outside.
Yeah, we can do it right from the next meeting.
I was just going to ask, in the fictional examples that you put up there, the metaverse and Snow Crash and Ready Player One, we use that for everything, right?
Yeah, school, for...
Yeah, school, work, yeah.
What is your approach to your metaverse?
What are we going to use it for?
I think Dan used the right word, escape. We want to create a place where you can relax, you can chill, you can hang out with your friends. All those things will probably still exist eventually, will exist there too. I love how ready player one talks about that, starts off as a game and ends up having schools and things in it. Maybe that will happen or maybe it will come from the other way around. I don't know yet.
And we're also starting kind of focusing on you plus friends rather than you plus the whole world Yeah, that's key a lot of other social VR developers are like how can we get a hundred people in a room?
And we're just so it's like we can't even make one other person feel great yet So we're gonna stay focused on that until we can before we start worrying about a hundred people Which is an entirely different social problem even even in the case of like okay, you're gonna hang out at a concert, right?
You're not you can't It's not like you're going to talk to 100 of those people. It's a very different set of problems. We're very focused on just the one to a few, not one to a thousand. Thanks, guys.
We'll be hanging around outside if there are any more questions. Thank you so much.
