Thank you, you're welcome.
And goodbye.
do you Ah, I found one! I found one of the inflatable crocodiles!
Yes! Perfect! Now get the... get the... get the...
Let's see if it pops. Can we make it pop?
Throw a knife into the crocodile.
Okay, that is not enough to pop it. It's quite strong. Get the silenced gum.
Yes! It pops! Yes!
I'm so happy! It has a lovely little pop animation. That's the best thing!
This was the reaction of YouTuber John at the channel Many a True Nerd.
To me, it's very rewarding to see player reactions like this.
And it is also a reward to the player for interacting with the world.
This feature of a popping and inflatable crocodile was not needed to ship this game, but I believe it helped in selling the story of a detailed game world.
And in hindsight, of course, I wish I'd made Knives cause deflation as well.
What you just saw was work I did for Hitman from about two years ago.
My name is Joakim Mellegaard, and I'm a technical artist at Rare, the studio behind Sea of Thieves.
I started this role in October last year, and before this, I worked at IO Interactive on the Hitman franchise.
In this talk, I will be covering a lot of the experience I gathered while working on Hitman.
Today, I would like to talk about my view and ways of immersing the player in games.
I will be using examples from tests made in Unreal Engine as well as my work on Hitman.
But in general, the ideas I'll be presenting should be transferable to any project.
So hopefully you will be able to take some inspiration, ideas, or code with you home today.
We will also be looking at examples from other games.
There will be some theoretical elements, but mostly we'll be looking at practical solutions.
Much like the inflatable crocodile example, these ants from Skyrim helps in selling the idea of a highly detailed world.
It is an interaction of discovery.
VFX artist Mark Teer from Bethesda Softworks told me that these ants can only be found in a few places around the game world, but once the player sees them, it creates an impression of a much more detailed experience than the one the player would experience if the ants weren't there.
By adding this effect, Mark made the player think that details of this delicacy could be seen around every corner.
Also, other items in the game benefits from this by having the player believe in an overall richer experience.
I believe that triggering the player's imagination with ants and crocodiles is the key to achieving this from a visual point of view.
These two examples, ants and inflatable crocodiles, belongs to a category of effects we may label as cosmetic interactions, meaning they are pretty details you, as the player, did not necessarily expect to see or interact with.
Another type, which we will speak much more of today, is passive interactions.
This type of passive interactions are designed for grounding the player in the game world.
making them feel part of it.
There are so many experiences in games which we cannot do, like smell or touch, yet anyway.
And that's why passive interactions must be visualized.
The last category of interactive effects rewards the players for their actions.
It's about supporting gameplay.
Let's explain that by re-watching the slightly unpleasant scene.
Sorry about this.
The target is a patient in a hospital awaiting a heart transplant.
And there are many tools available in the surgery room.
There are, in other words, many ways to get to this target.
Each one leads to the visualization of the player's decision.
Every decision that the player may take has to be visualized so that she can experience the outcome of her actions.
These three categories show us what visualizing player interactions does for the player.
Together, they immerse the player more than any other element, graphical element, in the game because of their dynamic nature and direct feedback, whether it being a passive interaction or an intentional one.
We may speak of immersion quite a bit, but it is valid to ask why aiming for immersive experiences is important in the first place.
Psychology studies have shown us that the player reacts more authentically when facing decisions in game scenarios in comparison to the real world.
And this is likely to be because social constructions don't matter as much in games.
The player is in a flow of joy, having challenges and skill levels met.
This leads to an extreme focus and, as the studies show, even self-actualization.
And perhaps this is why video games are so popular.
As game developers, we of course want to pay attention to these behaviors and make the player stay in the flow where these qualities can be triggered.
This is true for anyone in game development, but I think it's well worth mentioning it in the context of visual effects.
By keeping the immersion high with our visual effects, we can enhance the flow of the game.
So, how do you make, and maybe more importantly, how do you know where to add effects like this?
Start by identifying things that you believe the player may interact with.
And this can be by being imaginative, but you will most likely get many ideas simply by looking around the game world for items or features that you think could benefit from an extra level of fidelity.
Know the tools you have at hand and use them wisely and optimize.
Typical tools for creating VFX, as you know, could be particles, cloth simulations, physics, scripting, shading.
Often, though, VFX creation is about problem solving.
And it can be difficult to know if a certain approach will succeed beforehand.
It's an iterative process.
If we go back and have a more detailed look at this inflatable crocodile we saw in the beginning, we can see that the setup is quite simple.
It was created using a mix of cloth simulation, shader runtime modification, and game logic for listening to the gunshots.
The resolution of the cloth simulation is quite low, so it makes sense to blend in this crumpled normal map when it deflates.
Another type of interaction is flattening car tires in games.
Apparently it's rewarding shooting tires.
This footage is from The Vision.
And I cannot say for sure how they made it there, but in Hitman, this effect, which was made by my former lead, Martin Nilsson, uses physics constraints, objects transformation, and finally a vertex shader, which flattens the tire to the ground, no matter the orientation of the wheel.
So if you're thinking to yourself now that I have no idea how to make a shader like that, then simply just do the first two steps.
Move the wheel down and have the hole being constrained to the wheel so that the car tilts over a little bit.
This is a good example of when it's better to go with a lower fidelity version than to not do it at all.
I believe that the player does not care too much for the additional fidelity when she's been rewarded for her actions.
So the clipping caused here by offsetting the wheel into the ground may not matter too much to the player.
Another example of player immersion and interaction, but in a more abstract way, are these computer monitors showing a video feed from security cameras in the game.
The purpose of the monitors is mainly to immerse the player and making the room look like a security room.
But they also come with somewhat of a hidden gameplay feature.
I'd like to think that the player's informed of where cameras are placed in the level simply by looking at the screens.
and recognizing locations inside the level.
The player is immersed by this live feed, besides the fact that there are no characters or events taking place on the screen.
That's because it's not really a live feed, simply.
It's just a screenshot taken from real locations of security cameras in the level.
The effect is done in three steps.
Zoom in to the image to make space for panning.
apply a fissure effect, which creates a perception of a perspective, and pan from side to side.
Finally, it can look kind of cool to keep the input signal on the monitor, rather than completely tearing it off when it's broken.
So, how do we efficiently add this type of effects to the game world?
Procedural development is something that is seen more and more in our industry.
The main selling point for making assets procedurally is the flexibility that comes out of it.
It's simple to manage and change the graphics or behaviors halfway through development if the asset was designed for being changed in the first place.
Also, this helps keeping the graphics consistent in the game.
Often it aids memory performance, having assets being reused for many purposes.
And it is also fun and challenging making assets that are meant to be reused.
This solution was built for having consistent water puddle decals with ripple interactions in the game using a procedural approach.
Previously, the environment artists had been baking the pit, sorry, had been baking the water plane into the texture and all the different versions of water shading affected memory performance and decreased the asset's flexibility.
So in this procedural solution, the artist would instead simply bake out a pit in the ground and have the shader fill it with water.
The assets support having interactive footsteps and gunshot ripples caused by the player and NPCs, as well as environmental effects, such as dripping from a broken pipe.
It gives the environment artists the ability to change the water height and mud color procedurally.
The water plane also has wind effects and simple refraction and a very rough visual effect of sinking into the puddle by setting the depth bias of the decal high.
to properly understand how this effect is created.
It's worth taking a quick look at the engine the solution was built for.
The decal system in Glacier, the engine used to develop Hitman, offers a flexible way of working with decals because decals can be transformed in UV space.
Per instance, per instance in UV space, which allows for optimal use of draw calls and for having many decals inside one texture.
They also have vertex colors, which the artist can set per decal.
And this is what I've been using for driving these procedural effects.
They can also be placed in a template along with other components, such as scripts, collisions, and volumes.
What all of that means is that we could have the player, the artist, place puddle decals inside a level.
like they normally would, and automatically spawn ripple effects when the character walks into them, and even find electricity current.
Now I will show you in depth how a puddle can be made procedurally through this interactive demo.
And it will get a bit technical.
What you're looking at is a puddle, as well as a slice of it, along an axis for visualization purposes.
The artist can set the preferred water height by changing the decal's alpha value.
We use a height map as the data for driving this effect.
If we look closely, there's a small gradient between there being water and no water.
And the creation of this gradient is the base for making this work, so let's get a deeper understanding of how it's created.
I'm using something called a remap function.
And don't be intimidated by the code, this function can easily be created through shader graph nodes, it's just not very presentable.
The purpose of the function is to map a certain value to another.
Under the code, you can see an example of what happens when we're running the function.
So we start by having this gradient.
We pass the gradient as the first argument to the function and values between 0 and 1 as the second and third arguments.
And the result of this is that we get a new gradient that is more narrow.
So instead of passing a gradient.
to the function, we'll be passing a sample height map.
And then we'll pass the user input, which is the value that the artist set on the puddle, minus the width we wish the water line to have.
And that is the same as this width.
Too large a width, and we'll start seeing aliasing.
The water will start to look undefined and too small, and we'll start seeing aliasing.
And don't pay too much attention to this value.
This just happens to work well for this application.
The last argument will then be the unmodified user input value, and that will give us a gradient between the two.
That's all very cool.
The puddle will shrink and grow, depending on whatever value we pass as this first argument.
But we can do a little bit more with this.
We can also add mud coloring.
or perhaps a wet area surrounding the water.
And all of this just by repeating the same code, but with different offsets.
Now on to the interactive part.
We were inspired by.
Naughty Dog and the way they use render targets, which was presented in the paper to the Technical Art of Uncharted 4 in 2016, I think.
So me and Jonas Meyer, the lead render programmer at Eye Interactive, we decided to try out something similar.
So what you see are sprite particles spawned into a top-down buffer.
It's basically a camera rendering a few defined assets in the game, and these, in this case, the ripples.
The camera is placed above the player, looking down.
So why does the render target look like vomit?
Well, the clear color is set to the neutral vector in texture space, which happens to be this color.
On the sprite particles, we simply write a low resolution representation of ripple normals.
We also write the height value of the ripple to the blue channel of the render target.
We can then sample the render target inside the puddle shader.
As you can see here, the water plane is disturbed by the ripples, the height changes.
We achieve this by.
adding the sample texture, the render target, to the user input, and scaling it by our preferred value.
Then we replace the second and third inputs of the water and mud levels with our new disturbed water level.
And notice, note that we choose not to do it for this wetness level.
And that is simply because we don't have any delta time for making the wetness sort of crawl back in a realistic fashion, as you would expect when wet ground dries up.
You notice that If we set the water level too low, the ripples will start to look a bit strange, kind of like if we're, as if we're adding water to the puddle, which we are.
But if you think about characters, for example, walking through the puddle, that wouldn't be the case.
So we can fix that, either by scaling the ripple height by the user input, or completely turning off the effect when we think it fails.
After this, we can start using our gradients for something.
We set the color of the wet area surrounding the water by multiplying our color sample, the ground color, with inverted porosity.
Assuming you don't sample a porosity map and want more physically accurate results, you can replace the porosity constants that I have here with the inverted roughness.
of the underlying surface, of the ground.
Perhaps that sounds a bit complicated and confused, but it's really quite simple.
Think of it as plastic and concrete.
The water would simply drip off plastic but be absorbed by concrete, and that is what we're trying to model here.
We then want to find out how bright the mud color is so that we can define dark colors as transparent.
Because as you may recall, we were using vertex colors as the input for the shader.
And this means there is no fifth float, which we could use for defining transparency.
So we will have to define transparency in another way.
And we will do that by having dark colors represent transparency.
Basically, if the artist would set the mod color to black, we will read this as fully transparent water.
The dot product of this value here does exactly that, but those values may vary a little bit depending on your rendering pipeline.
Note now that we know the brightness of the mud color, we can interpolate between the wet ground and the muddy water.
We also have to unpack the ripple normals since the texture, the render target, is read in the shader as an unsigned vector and we need it to be assigned.
And that just means that it goes from zero to one instead of negative one to one.
And we do that by multiplying the sample by two and subtracting one.
The set value is set here to one for simplicity, but you could recalculate a more accurate set value from x and y if you're required.
We have now finished all the steps of this effect, and we just need to composite all our layers, much like you would do in Photoshop, an encode that's easy as done through Lerps.
Puddles are great fun for the player, but another amazing thing we can do with this tech is having the player disturb the local plant life.
What we want to achieve here is to have the sphere bend and flatten the ferns as it rolls through the vegetation.
This can also be achieved using a render target as we see here.
To understand what's going on here, let's start looking at what we write to this render target.
There are two elements which we write to this render target, the first one being this single quad aligned with the sphere's position.
On the quad, we draw a vector from the center and outwards.
And along with this single quad, we spawn sprite particles and give them the velocity of their parent.
These particles are shaded using the particle direction vector.
and lifetime of the particle, as well as a sine wave for swaying the vector back and forth like this.
And that is to fake internal movement in delta time for the bush to reach its undisturbed state in a bit more realistic fashion.
We use the particle's lifetime to drive the sine wave, which results in faster swaying in the beginning of its life and slower swaying in the end of its life.
So if we have another look here at the render target, you can see that the particles are changing color.
And that is because the vectors are swaying, so to speak.
The blue channel of the particle will be used as a mask for flattening the plant.
In the plant shader, we will sample and unpack the render target in a similar way we did for the puddle.
Now, instead of using the vectors for a surface normals like we did for the puddle, we will be using them for rotating the plants.
So as you can see here, if the sample color is red, we will be rotating the plant in a positive x-axis.
And in the absence of red, we'll be rotating the plant in the negative axis.
When sampling the render target, it makes sense to think about what coordinates we should use.
I found out for this plant, the rotation vector should be sampled somewhere between the pivot and the vertex position.
But this is mainly down to the shape and size of plant.
You can almost see this blend value as the flexibility of the definition of the plant's flexibility, basically.
So if I set the flexibility to zero, it means we are sampling at the pivot position only, and that results in quite a rigid look, and the intersection between the sphere and the fern becomes quite noticeable.
However, if we sample the render target only at the vertex position, the...
Well, the vertices aren't very unified together.
It kind of looks like water or something.
In fact, they're not unified at all.
They're completely independent, as we see here.
So something in between these two extremes will work for most situations.
So, however, it's worth mentioning that if the plant was very big, there would be no sense in sampling only at the pivot position.
And in these cases, it may be worth looking at introducing baked pivots.
So if the plant looked like this, we may want these vertices that I've painted blue to share a pivot to rotate around.
And the easiest way of baking this data is to write the pivot positions to two UV sets in which we'll leave that last entry empty.
But you could also write the values to vertex colors or textures.
It's just going to make it a little bit more complicated to map those values out in the shader.
Similarly, we would like these vertices to share a pivot, and so on.
Anyway, that was a side note.
Now back to our plant, and in particular, what we need to do before we start rotating our positions.
So once we've created our coordinates, we can go ahead and sample the target, the render target, and unpack the vector to assigned range, just like we did for the puddle.
And we could also recreate the sed rotation in this crude way of adding x and y.
And this is absolutely not a true rotation by any means, but it makes the plant look a little bit livelier when it's sort of twisting in sed.
To know the amplitude, how much we would like to rotate a plant, we will also be using x and y as a base.
The amplitude can be created like this.
It is important to normalize your rotation vector.
And since we don't want this to happen, I added a small number to the vector.
However, this is not the right way of avoiding none.
If you want to be absolutely sure you don't get none, an if statement is required.
But for the sake of fast performance, we can sometimes take that risk.
In this case, however, it's completely safe, seeing as the smallest possible value of the texture is larger than our addition here.
So if you're wondering what the visual output would be of NAN, imagine flickering or similar crazy behaviors.
I won't cover how to do the actual rotation here, but you could find plenty of rotation functions online, or otherwise you're very likely to have one in your engine already.
So what else do we need to do to achieve this effect?
Well, we also want to flatten the plant.
And we can do that by using the blue channel of the render target as a mask.
To flatten the plant, we need to know how tall the plant is.
And either define this in a very simple per plant way, like I'm doing here, or in a procedural way, by getting the object's head bounds.
That is the preferable way, by the way.
Next, we need to make sure we only flatten the plant where the flattening mask, the blue channel of the render target allows.
Now we can add the flattening to our position offset.
This will have vertices that are being masked as flat to be moved, in this case, 20 centimeters downwards.
But that would also mean that vertices can pass through the ground, which probably is not what we wanted.
The desired result is of course that the plant collides with the ground.
And so let's fix that in one second.
depending on which engine you're using and if you're outputting an offset or an absolute position in the vertex shader, this step may or may not be required.
But in Unreal Engine, which this demo scene was made with, this is required, so we temporarily want to add the world positions to our offset.
We can then define a ground height for the plant to collide with.
This is probably just above the pivot, but it could also be a terrain height map if you really wanted that extra super fidelity.
I can also recommend adding a downscaled RB space height to the ground height, because otherwise you will be experiencing quite a bit of set fighting when all the vertices are compressed to a single height value.
So now we can make sure that the leaves will never go under the ground by using a max function, which will output whichever input is larger.
And finally, again, depending on your engine, subtract the temporary position which we previously added.
So in summary, how to disturb a plant.
Create a render target.
and draw some vectors and a mask to it.
Use the vectors for rotations and a mask for flattening it.
Now onto something a bit different.
Traditionally, we would spawn decals on a shot surface and it would look something like this.
Yes, these are not the most beautiful textures, but in general, this approach looks all right.
And with a few texture variations, it will be difficult to see repetition.
However, the decal often appears to be floating on the surface and appears like the stamp it really is.
So.
I think we could do a little bit better by using this method, which I call the destruction buffer.
We're going to get a bit more interesting results.
The idea is that we draw decals, again, at the impact point of the surface, just like we would do with normal decals, but in a separate pass.
We can later use this buffer in our materials to create more unified destruction effects.
And mind that changes to engine code will most likely be required in order for this to be fully implemented.
Anyway, we spawn and draw decals to our standalone decal buffer.
And this is what the buffer looks like.
In the wall shader, we read the buffer and use the grayscale value to peel off the tiles.
The data describes in more detail how the tile should break is stored in a texture, which looks like this.
What this texture tells us is that dark values will peel off easier than bright values.
We start by mapping the destruction buffer to the screen.
We can then sample our buffer, define a width of the peel effect, and finalize the peel mask using a smooth step.
When our peel mask is created, we can blend between the two materials, tiles, and concrete in this case.
But we also want some normals to shade the surface where it's broken.
And since we don't know how the surface will break, we cannot, we would have to define this in a procedural way, create these normals in a procedural way.
And to do that, we will be using the hardware functions, ddx, ddy.
And these functions are really cool, because they are aware, if you will, of the neighboring pixels in their current state.
By using them, we can convert our grayscale peel mask into pretty decent normals.
And this is kind of the quality you can expect from creating normals in this way.
They turn out a bit blocky, but still usable.
And we can have a closer look here in real time as well.
You can add an additional layer of fidelity by having the concrete, in this case, break even more as the wall takes damage.
I don't know if you've already noticed, but it's worth to point out that it's quite forgiving in the eye to see these type of decals fade off.
So let's revise how this wall became broken.
We created a separate decal buffer, a.k.a.
destruction buffer, spawned some decals into it, and then peeled off the tiles by combining the destruction buffer and a texture, defining how the material should break.
So that could be either tiles or wood or whatever you are about to break.
Now on to something quite different.
Actually not, because we kind of saw this in the earlier presentation.
So this is one way in how to solve the problem of having liquid placed in a moving container, in this case a glass.
There is no fluid simulation going on here.
It's simply a few tricks put together, and these are the basics for achieving this effect.
Start by filling the container with liquid, and by that literally, I mean literally, create a closed liquid mesh inside the 3D model.
Set all the vertices above our defined liquid height to that height.
you will now notice that some of the vertices will end up outside the glass.
Now we'll just tilt the glass to get a better idea of what's going on and ensure that all vertices stays inside the glass.
And we'll get into how this is done shortly, but basically it's a matter of finding the nearest point inside the glass and that is going to be the radius of the glass.
Now is a good time to tell you that this effect only really works for cylindrical containers.
To find the nearest inside point of other shapes is much trickier.
You may also notice that the plane starts to bend slightly.
And I just decided not to fix this because sometimes it kind of looks like surface tension and that's a cool side effect.
Finally, the fourth step is to fade off the effect when it fails, and it will fail in this angle.
Okay, so that's the idea, but let's run through it in greater detail.
First, we must define the essentials.
The height marked as blue represents how filled the glass is.
The set bounds of the contents marked as green and the maximum radius of the contents marked as red.
Next, we make sure that the height value can never go below the lower bounds.
What we will try to do now is to force all the vertices above our height value to that height.
However, the height that we defined is in local space.
So if we rotated the glass, the vertices wouldn't be aligned with the horizon, which is the whole point of the effect.
So that's why we need to transform our height value to world space.
And this essentially creates an infinite plane.
And now we can force the vertices to our plane like this.
When we've done that, we must go back to local space.
to carry on with the next step, which is to put the vertices back into the glass.
Because as you may recall from my GIF earlier, some of the vertices are outside the glass.
And we would like to put them back in.
We will do this by using the radius of the glass.
But how do we know the radius of the glass?
The radius is breaked into one dimensional texture, in this case, in this case, basically the way we do this is to create a height map from the tip of the glass, and in other words, measure the distance from the plane here to the liquid and invert that result.
Once we've done that, we can create some, we will sample our textures, but first we need to create some coordinates.
We will reuse our remap function here, which we previously made, to map the height to a zero to one range.
So in this image, you can see that the set position, which is this case in something like 60, turns into 0.5 in our new range.
We can then sample and multiply the radius texture sample with our maximum radius, which we defined on our first slide.
Now before we fix our little problem of having vertices outside the glass, we need to know if there are outside the glass.
And we can learn this by measuring the distance from the vertex to the center of the liquid and comparing that distance with the radius.
We are now ready to put the liquid back into the glass by creating a direction vector from the center of the glass to the vertex and scaling.
it by the radius of the contents and that way we will see that happen.
And I mean, I don't mean literally like this, but this is just a visualization.
But basically what we're doing is to place the vertex in the center of the liquid and scaling it outwards using the radius.
To fade off the liquid.
When the container rotates too much, you can use the Zebdo angle and remap the value range into something usable.
And that is, the same is used for fading off the waves.
Speaking of waves, here is how the wave function was made.
It could have been made in many ways.
The important thing here is that it takes the orientation of the glass into account.
So that the waves are going in the right direction.
Again, to summarize, fill the container with liquid, force all vertices above our liquid heights to that height, put the vertices back into the glass using the radius, and fade the liquid off when it fails.
I realize that this may be a lot to take in, so you can download the slides and the demo from this link.
Today we've been looking at cosmetic interactions, passive interactions, and payoff interactions.
We've been talking theory and looking at various implementations.
The facts I've been sharing with you today may not be applicable to your project, but I think it's well worth mentioning it in the context of visual effects.
So hopefully the methodology or functions will be useful to you.
I just want to say thank you to everyone who's been contributed to making this happen.
And thank you very much for listening.
Thank you.
Thank you.
Thank you.
Thank you very much.
Thank you very much.
Thank you.
Thank you very much.
Hi.
Hi.
Great talk, by the way.
In the example you did with the grass, you said you were using a render target, render texture to create all the information that the shader is going to use to deform the plants, right?
How do you account for bigger levels? For example, in your example there was a small square with about six plants, but if you got like a giant stage with a lot of plants, how do you account for that?
Yes, so the way it works is that the render target is actually following the player, so you wouldn't see deformation of plants happening in the far distance.
You would only see it close to you, maybe 50 meters at maximum.
So everything is like on a world scale UV?
Something like that?
It is in relation to the world.
The camera is in relation to the world, yeah.
Thanks.
Hey, so I just want to piggyback off that.
With all your render buffers, you have a lot of them just reserved for minute details in the game.
At any point, did you guys run out of memory for your actual render fetches?
So in Hitman, the render targets weren't very big.
They were about 512 pixels.
And We were reusing them for multi-purposes, so they weren't just used for plants or water, but to many things, and we don't need to have many of them, basically.
Cool, thanks.
Anyone else?
Oh, cool.
Thank you very much.
