Okay, hello.
So, I'm James Benson.
I'll give you a little brief rundown of my life in the games industry.
So I worked on Fable 3 for a little bit, that was fun.
And then I worked on Peter Malny's ill-fated boy simulator, Project Milo.
So that was a laugh.
And then that blew up, so I was out of a job and it was all very sad.
And then I went indie, and it was a great time to go indie.
And then Meat Boy and Limbo and all this stuff came out, it was fantastic.
And so I sort of de facto became the lead animator a very tiny studio with like, you know, four people at the beginning which was a bit of a weird situation because I don't made a 2d game and I started making a sort of lush painted 2d game and On fable and Milo. I basically hadn't really done anything I just sort of sat around and you know kind of tweaked some little things and fix some bugs So I worked on Ori for four years and on the last year I was transitioning off. I brought on a really awesome woman called Rahel Brunold who came and helped me finish the project. And whatever, now I'm giving a talk about it.
So what's Ori? If anyone doesn't know, which is probably almost all of you, Ori is a 2D painted open world metroidvania game with oodles of character animation, lots and lots of scripted stuff, and it's just very, very content-heavy game. As I mentioned, the team was very tiny.
So it wasn't really even a case of, oh, we've got one person of each discipline.
We had sort of like about half the disciplines that you'd ideally want.
For example, no technical animator.
And I have very limited skill set.
I'm not very good at many things.
So for example, I can't rig things, and I also can't draw, which is pretty bad if you're making a 2D game.
Okay, so this talk is basically about how to overcome personal failings.
Okay, so I've got a bunch of images here, which you may recognize.
This is Princess Mononoke.
This is Spirited Away, and then Mononoke again.
So the important thing to note about these images is these backgrounds are ridiculously rich and detailed.
You can see all the brush strokes, and it's gorgeous.
And the characters all sort of awesome, but they're really simple.
They're essentially just silhouettes, and there's a little bit of a rim light, but they're pretty much just flat-shaded blocks.
And then if we go to skip to this bit, this is a shot from Mononoke where there's like a curse on this guy's hand and it's these kind of riding snakes.
And it's actually all 3D rendering, but they do a really good job of tricking you into sort of not really noticing that at the time.
So the reason I'm showing you this is we wanted to hit the kind of same aesthetic tone of these films and then also the kind of emotional tone and the moral ambiguity and that kind of thing.
And I also wanted to kind of pull off a technical trick that...
they're doing, and kind of take this sort of snake-arm type thing and do that through basically every single asset in the game and make you think that the 3D stuff was 2D.
Yeah, so with that in mind, this is what I ended up making with the very talented people at Moose2do.
you Okay, so, whoo!
Thank you.
Thank you.
So you know what we were trying to do, and that's basically what we ended up doing.
And I'm now just going to run through, in excruciating technical detail, the pipeline and how we did it, basically.
And also, I always forget to mention this when I'm practicing.
We made this in Unity.
So you can make this game in Unity Engine if you want to.
OK, so this is 3D Ori.
He's 3D model.
He's got one texture, which is just a diffuse texture.
It's 100% self-illuminated.
There's no lighting on him.
That's kind of all he is, it's really simple.
His entire design is about being a silhouette.
I'm basically doing the same thing, hopefully that a Kadama looks like in Mononoke, those little white spirit creatures.
So there's a few animation concessions in his design.
We gave him a tail so that I could always show you the direction of travel that he's moving in.
We gave him double-jointed legs so that it's a platforming game.
You could coil him up like a spring and then have him bounce up.
So yeah, and also the zoom of the game is usually a kind of like a meat boy level sort of zoom.
So with all these super detailed backgrounds, having him just be pure white silhouette helps him read really, really clearly at all times, which is important.
So like I mentioned earlier, I can't rig.
Luckily, 3ds Max, which is the tool I use for the thing, comes with a really good proprietary system called Cat, and you don't have to be clever, you just click, click, click, and you make a rig, it's awesome.
And I can skin, so basically that kind of took care of all of that side of things.
And it also, coincidentally, happens to be, by far, my favorite rig to animate, because it handles scaling really well, and such, such, such.
So it's awesome, and I use the Cat rig.
And so for rendering, we render Ori with an orthographic camera from the side.
It's like a small detail, but it's actually very important that we don't render any of these things with perspective.
Because in the same way that not having any 3D lighting information is useful, not having any of that mathematical perspective information is useful, because having less of the detail makes it easier to trick you into thinking you're not looking at a 3D asset.
So that's crucial.
Yeah, we also do things like when I'm rendering the frame, I bake a nice object motion blur into it, because it's essentially free, I'm already paying the memory for the sprite.
So yeah, and there, it looks a little...
Ori's jumps, that's fun, isn't it?
OK, so if you throw a sprite into the engine, using that sort of rendering style, it looks vaguely like this in most cases.
So we can do a bunch of stuff to the frames before we start making them into atlases and stuff if we want.
Tend not to, because it's better to do effects in engine, because it's more reusable and you can iterate better and stuff.
But we do some things, like a GIF should play here.
So when the owl's coming out of the camera here, Baked into the sprites is a depth of field that's blending out, which would obviously be a relatively expensive thing to do in real time, and we just get to do it for free.
So once we've baked whatever effect we want to Atlases, we stuck it in the engine, it gets made, yeah, it gets made into big Atlases, the point being to save memory.
So there's a few sort of things to note though that are quite cool about the Atlas system we have.
There's a dynamic chroma keying system that we have where it samples all of the pixels in the various images that you're throwing into the machine, and it'll say, OK, well, blue is the least used thing here, and makes it a blue screen.
But it also does really smart sampling where, like, if a character has, for example, red eyes, it can tell that that's important.
And even if red is the actual, like, least used color in all those images, it'll make sure not to make the eyes transparent, because that would completely fuck up everything.
So, yeah.
There's also a lot of other, oh, these are some atlases.
That's not very interesting, is it?
Yeah, this is our atlasing tool.
There's some other cool things about the tool we have.
Like, you can see, maybe, if you can read it, we can specify for each individual animation, the scale of the sprite in-game is gonna be this.
The camera's roughly gonna be this kind of zoom.
And this is basically a massive bug prevention tool.
Like, the system will analyze, okay, this is how many pixels it's gonna occupy on any given screen.
and you've given us source frames with whatever resolution.
And if they're just gonna be too small and look shitty in game, then it just says, you can't build this atlas, go back and make your frames again, please.
Which is actually really awesome and just stops you from wasting time when you're making the game, which is good.
Okay, so the next layer on top of that is metadata.
And this is kind of where this sort of hybrid of a 2D and a 3D pipeline sort of comes into its own and becomes pretty awesome.
We're obviously making sprites, but the assets are all 3D assets.
We have all the bones, etc.
So we have a layer where we just, once we put an animation in the game, I can grab the whole rig and throw that as an FBX into Unity.
And we have another proprietary tool where it just spits out a little clean asset where I can track the eyes, I can track the feet, so we can do sounds for the footsteps, we can do particle effects, and blah, blah, blah.
We can also apply root motion to all of the sprites because it's just 3D, and as if you had the actual rig in the engine, you can do root motion, which makes making cut scenes and scripted events very, very easy.
So for example.
As the leaf is like tumbling around the wind here, it's a relatively kind of complicated shot to do, but it was really like kind of easy to do because the leaf is just using the root motion from 3D.
We have all, like the camera that's following it is just like following it in 3D because we know exactly where the thing is moving.
We've got these particle effects and the trail and the glow and all this kind of stuff, and it's just relatively trivial to implement something that looks fairly complicated.
Yeah, and then once we've done all that stuff, the kind of last part of the pipeline is, they developed, the programmers at Macy's developed a ridiculously awesome unified shader system where you can just do all kinds of crazy stuff.
You can apply awesome animated distortion, you can do really, really nice like real-time glow effect and things, and also like super clever, nice things like you can put like a additive multiply mask on one side of the character that sort of lights the character, you know, if there's a big moon behind him or whatever.
And then if the sprite flips or whatever, it'll still keep from that direction.
So you can kind of fake real-time lighting in your scenes and things.
So if you look at these gifs here, on the top right, you can see Ori, fictionally within the universe, he's kind of made of light.
So in a dark area like this, we want him to kind of light up everything around him.
So.
He has a kind of dynamic contact shadow with the ground, which is made of light.
On the left here, you can see this kind of ghostly figure, and that's using loads of nice little shadery things as well that all just kind of comes for free.
And in terms of implementing that stuff, it's literally kind of like pressing some tick boxes on this awesome proprietary tool.
So that's good.
Okay, so that's the whole pipeline.
I'm just gonna say what's good about the pipeline now.
Okay.
So the first bullet point.
is essentially the most important thing in the entire talk and the entire animation system.
You get to do perfect non-uniform scaling of bones, which is ridiculously, ridiculously important.
The two big things you get from this, essentially, you get squash and stretch, which is obviously great.
Every animator wants to do squash and stretch.
But way more importantly, being able to manipulate the bones to your heart's content essentially means you can draw whatever shape you want.
If I could draw and actually could get a pen and paper and do it properly, I'd be very careful about the separation of all the elements and the silhouette and all that kind of stuff.
And I can just do that same thing in 3D by just absolutely tearing the bones to pieces.
And you can cheat perspective.
I can, for 2D sometimes, you don't want to show both arms when the character's running or something like this.
And you can just shrink the arm down to a little nub and do all kinds of stuff.
Also, for things like breathing, rather than just having the spine rotating like this, you can just be like, I'm just gonna grab his chest and be like, and it's awesome.
He's actually breathing now.
As an example, on the left here.
you have an actual frame that is a nice frame that I'm happy about.
And on the right, you can see what it looks like if you just turn the camera 90 degrees.
And obviously, it's a fucking horror show.
So as you can see, all of the elements of those models are completely aligned along one axis and only make sense there.
And that's basically the whole trick of all of the animation in the game.
We've got another example here with Kuro the Owl.
Yes, again, she looks absolutely terrifying.
So we have like the nice silhouette of the arrowhead kind of shape and blah, blah, blah, and then she's a complete monster on the other thing.
So, oh yeah, and so for the sort of animated benefits of that I don't know how well you can actually see this.
On the left you've got Ori.
At the like the top of his jump, he kind of crunches down to about half his size.
At the bottom of his jump, he's like twice his normal size.
The frame when he hits the ground, he becomes like 10 pixels.
And then also with his tail, as he does little spins, it becomes like three times its normal length for a few frames and all this kind of stuff.
With Naru, as she jumps, her belly is kind of doing secondary motion.
Like when she hits the ground, her legs crunch down to nothing.
As she's falling, her neck kind of elongates like a giraffe for a few frames.
And it all just kind of helps to make it look a bit nice.
Okay, this is a slightly more controversial point, I guess, but using this system, you have complete control over...
The game can't render a frame that you didn't draw, right?
Obviously, if you're building your game to make use of real-time turning of bones for some kind of inspection thing or whatever, or you're doing lots of clever 3D stuff, it's great to have the rig running real-time in-engine.
A lot of time you find, like, I'd be doing dailies on Fable or something, and you'd have your play blast, right?
Of, okay, I've done my cool combat animation.
It looks awesome.
And then you put in the engine, and all of the edges have been rounded off through, like, compression and...
another thing that I'm forgetting, whatever.
Oh, yeah, through interpolation, like, you made a 30fps animation, and it's now 60, and, like, half the frames, they're not frames that you made anymore.
You get a kind of mushiness to a lot of animation.
And you don't get that if you're rendering sprites.
Another thing is, there's no such thing in a system like this as a blend between two poses that's like the computer is doing.
So, on the one hand, it's like, OK, well, I've now got to do a ton of work myself, because it's all just going to snap horribly if I don't put in individual transition animations.
But on the other hand, if you now do something like this, and you do all the animation transitions by hand...
If you record like 15 seconds of you playing your game, and then just like watch it back, it's gonna essentially look like the linear cartoon perfect version of what you would have animated, right?
If this wasn't an actual dynamic system.
And I was very blessed at Moon that the programmers really, really understood what I wanted and they gave me the absolute perfect system for this.
And I could do all kinds of cool stuff.
Like, you know, in the arc of a jump.
I could be really, really extreme with all the different key poses that I would animate because I could specify, well, there's a transition that's from frames zero to six, and I let go of the stick, or from seven to 14, or from 15 to 19, and I could just basically go nuts with content, which is what I like to do.
It was also really easy to debug and see what's happening in the system, which I find a lot of time, you spend your days just trying to work out what your assets are doing in the engine, and in this system, That's not really the case.
I just run a tool where I click on the character, I click record, and then you play and try and repro whatever issue you're seeing.
And then it just spits out all your states.
And for example, it's really easy to tell if a pair of states don't have a transition, because the main gameplay relevant states are in white.
And if you just see two bits of white text next to each other, it's like, that's missing a transition.
So it's little simple things.
OK, and then there's a smattering of other random benefits.
But like I mentioned earlier.
We've got the motion blur, which actually is pretty enormous, makes a really big difference.
There's things like the dark, and we do glows and certain things.
You can see whatever in After Effects.
And then this is kind of a huge one.
Because you're rendering from the rig in Max or whatever, there's no compression on those bones.
So it's sort of the equivalent of if.
You came into work on your 3D game on Monday, and the programmer said, hey, we're disabling all compression in the game on all of your animation.
It would be just like Christmas and birthday all rolled into one.
And you can treat your assets like film assets, because it doesn't matter.
Like, whatever you're doing, it's just offline rendering.
So you can have whatever polys you want.
You can do 10K textures, whatever.
I'm not clever enough to do lots of like fur simulation and fluid and things, I don't know how to do all this stuff.
But if you know how to do it, then you can bake it into your sprites and it all works.
So that's fun.
As an example, here's Koro, one of the main characters in the game, and she's whatever, she's got loads of turbo smooth and all sorts of nonsense on her.
She's got 150 bones and for some reason, I like to like individually animate every feather on her wings.
Maybe don't do that, that's stupid.
I like to do it, it's fun.
So you can do whatever.
Okay.
This is more like a workflow thing.
Even something simple sometimes in a game, like opening a door and I actually want my hand to attach to the doorknob and twist it and blah blah blah, it gets weirdly complicated, like okay, now we need an IK solution and blah blah blah.
All that stuff is really, really simple in this pipeline.
To give an example, on Fable 3, they wanted to kind of upgrade the way they did like emotes with the NPCs.
So instead of just waving at someone, you could like shake their hand or kiss them or whatever.
And the way this ended up being implemented was that there'd be a fade to black when you interacted with someone.
It would fade from black.
They'd have had like a new rig with all of the characters in the same rig.
They'd play the thing.
And then they do another fade to and from black, which is obviously not the ideal solution.
And it kind of shows that even at a massive studio with millions and millions of dollars, these are hard problems to solve.
So here's a random GIF of a situation like that in Ori.
He runs up to his mom here.
She picks him up when you jump into her little box there, throws him on her back.
They do a little cut scene thing.
And then now you're actually playing as both the characters at once.
You're controlling the rigs and now the same thing.
And the reason it's so simple is because They're just two sprites, and we have all of the metadata for where they should be, and it's just really easy.
If I was going to make this now in a traditional 3D way, I'd be pulling my hair out like, I don't know how the fuck I'm going to do this.
Yeah.
So it saves you a lot of time.
There's no such thing as check how it looks in game.
If you like what you did in Maya or Max, that's it.
You did it.
Well done.
You finished the animation.
There's so much time.
Obviously, there are enormous benefits from doing cool real-time 3D stuff.
But when your game relies very heavily on blending and additive stuff and layers and da da da, you spend a lot of your time like not working on making your assets good, but just working like, what the fuck are my assets doing in the engine? Like I don't understand.
I'm like trying to repro things. You just don't have that thing if you're working with sprites, which is lovely.
Okay, so now this is the bad part. What are the cons of the pipeline?
Okay, so...
Essentially, it's one big con, which is texture memory.
You're going to pay tons and tons and tons of texture memory to render all these sprites, especially like in Ori, we have this owl character that just fills the screen.
She's huge.
We're rendering 2K textures, and there's like 1,500 frames for this shot, which can be absolutely insane.
And you start competing with the environment artists and with sound and with everyone for.
very precious memory, and there's not a game in existence that isn't constantly fighting for memory.
So that's essentially the big cost.
There are other things, though.
If you decide halfway through your production, like, oh, the character should have horns, you can't really do that, right?
Because you've got to render every single frame in your game again.
It's not quite as terrible as that.
If you're actually hand-drawing everything, it's an enormous problem.
Because the assets are still 3D.
You can spend the time to make a batch script that re-renders everything, and you can swap in a new instance of the model and blah, blah, blah.
But obviously, the reality is that takes programming time.
That takes time for you to wait for things to render.
And you're going to create bugs, and it just isn't ideal.
You also can forget about various clever real-time 3D stuff.
So you can't adjust the feet to the ground.
You can't create any game that relies on this.
This doesn't really apply to Ori, but like LA Noire type thing where you pick up a pencil and look at it from all angles.
You can't do that kind of thing.
And you can't dynamically change the model.
If you want it so that there's an upgrade where he gets cool new boots, that's not going to happen because you'd have to double the memory of the entire game by having a boots version of the character.
You also don't get blend trees.
So the classic thing in any game would be there's an idle, there's a walk and a run, and I'm going to dynamically interpolate between those based on where the analog stick is.
You can't really do that, although in a minute I'll show you how you actually can do that.
You can't do things like the head tracking of like, oh, he's following an NPC with his head and all that kind of stuff.
Rendering's an issue as well, just a time issue.
If you're doing just like a jump, 30 frames, that's probably not gonna take any longer to render than just like exporting an FBX file.
If you're rendering a cut scene with like 2K textures and it's like 2,000 frames, whatever, that might be like 10 hours, and so you're gonna have to come up with some kind of solution.
a render farm or something, or you're gonna have to be very patient and wait a long time for rendering.
So, did any of that actually stop us and impede the game in any way?
Kind of, probably, mostly not is the answer.
So, for the foot placement example, there's some gifs here of different slopes.
We basically tackled this problem with like two things.
The first thing is the character is just rotated to the normal of the surface that he's on, which is kind of like halfway there, but he obviously just looks like he's going to fall over because the animation is not built for that.
So then it becomes a content problem.
So we do a version of the idle where...
He's looking up a slope and looking down a slope, and that's relatively simple, except that then you have to do all the transitions.
But if you like making content, and if you have tools that make it very easy to make content, like we did, you can do stuff like this fairly easily.
And now it's pretty robust, and basically there's no surface in the game that Ori can't stand on perfectly.
The other nice thing, actually, about this is that I mean, it's cool if you can dynamically put his feet in the right place.
But the fact that this is an entirely bespoke animation, I can completely change his posture and make it much nicer.
So blend trees, this is kind of a fun one.
We, for the idle walk run problem, what we ended up doing was all of the animations that affects, we rendered at four times the normal frame rate.
And then we would dynamically speed up and slow down the animation based on where your stick was.
So the 120 FPS version of the walk is playing at that threshold where you're doing the fastest version of the walk, and then we slow it down to 30 if you're doing the little, tiniest bit of stick.
And then when you hit the threshold from the 120 walk to the 30 jog, we just have a transition that covers it.
And it's not bulletproof.
I've got five minutes.
It's not bulletproof, but it does the job really, really well and isn't a big deal.
For a different version of how to circumvent the blend tree issue, for the swimming, we wanted to do a kind of like a 360-degree Rayman origins type thing.
So what we did was, we had like a swimming idle thing just going horizontally, and then we additively made like 11 versions with his back twisting like concave, 11 versions twisting convex.
And then the engine at all times is sort of simultaneously running all of those versions.
And depending on the angle you're going to and the angle you're coming from, the programming magic just picks dynamically through all these different animations, and you never realize that it's playing like 15 different versions of things.
It just looks like a fluid blend tree thing.
For the lookup targets, you could do that same blend tree, like have a million different versions of the idle.
That didn't end up being a big deal.
We just made like, it's a content issue again.
Here's one 45 degrees, here's one looking upwards, here's one in the background, and that kind of served our purposes.
So, here's the conclusion, one sec.
OK. So I had four years to make the game.
If you have, like, a year or eighteen months, this pipeline may just be completely unfeasible.
The guys at Moon built, like, completely custom tools for absolutely everything, and you might not have the time or the inclination to do that.
Also, just personally, as an animator, I like building content.
I like building tons and tons of content and doing little, clever, silly, weird things that maybe someone else would think was kind of strangely overdramatic and pointless.
I think it's fun to do that kind of stuff.
And also, I want total creative control over everything I'm seeing in the game.
I don't like giving leeway to, okay, well, they're gonna take my animation, do this, do that.
I just wanna know that it's exactly how I designed the thing to work and to look.
And maybe not everyone's as insane as OCD as I am.
So not everyone would see this pipeline.
It's the perfect pipeline for me.
I loved it.
I did not want to make a 2D game any other way, and I was very generously supported by the programmers.
They kind of just did whatever I wanted, and they entered the kind of quality I wanted.
That's the talk, thank you very much.
Yes!
Yes!
Yes!
Yes!
Yes!
Yes!
Yes!
Yes!
Yes!
Yes!
Yes!
Yes!
Yes!
Yes!
Yes!
Yes!
Yes!
Yes!
Yes!
Yes!
Does anyone want to ask a question?
Won't be offended if no one wants to ask a question.
Sorry?
I have to go to the mic.
Oh yes, and also, I was told to turn off your cell phones, but it's too late for that now, isn't it?
Yeah, so if someone wants to ask a question, if you just go to the mic, that'd be great.
Hey.
I was just wondering if you guys tested with having your characters made up of separate pieces and animating, even animating those separate pieces, but using a bone system in Unity?
Yeah.
I've messed around with stuff like that in the past.
The problem is, you just can't turn your character around.
I mean, like, in the video that I showed, the little sizzle reel thing, when he's hitting on those bounce pads and kind of going, jush, jush, jush, I'm spinning the entire character around, and I know I keep going on about, you don't make it look 3D, but there are certain elements of being able to see the character from any angle that you're very limited by if you're doing a paper doll thing.
and I didn't want to be.
And that would mean, it would have been completely impossible to do that.
I do so much stuff where I'm turning characters in everything, it would just not be possible.
Hey, what's the question?
How much of everything that you're talking about here is a benefit of Unity versus the, I guess, workflow of using a 3D asset to represent, instead of a Sprite?
So how much of this pipeline is just because of Unity?
Yeah.
To be honest, Unity's just really, you can kind of do whatever you want in it.
It doesn't come with, like, a super structured pipeline for things.
There's, like, a relatively basic set of things it comes with.
And I certainly, at the time, like, Mechanim didn't exist.
And like, this, when we started, it was like Unity 3, so there wasn't even, like, the 2D toolkits and stuff.
So it really was just, like, create it all from scratch, because, like, we kind of have to, but we also kind of want to.
So yeah.
Thank you.
Thank you.
