Hello, everyone, and welcome to GDC 2021.
This talk is Voice AI for Game Developers, and it's all about optimizing the narrative process.
My name is Treyas.
I'm co-founder and CEO at Replica Studios.
For those of you who haven't heard about Replica yet, we're an AI company.
We make AI voices for games and movies.
And so I'm really excited to be here today and talk to you all and tell you a little bit about this new technology that's coming your way and can massively compliment all of the wonderful work you guys are doing.
So to start with, some of you are probably wondering, what is an AI voice?
What is Voice AI?
So we've got a couple of demos for you right up front, and then over the course of this presentation, we'll be diving deeper and giving you more practical examples.
But check it out.
Hello stranger, needing a new set of armor, are you?
I mainly specialize in plated armor, but on the odd occasion, I've worked with leather as well.
That'll be two gold pieces.
And here's another one.
How dare you! If you speak to me in that filthy tongue again, I will cut yours out.
Now leave me, while I still allow it.
No, please! Don't kill me! I can help you regain the throne, but only if you let me live!
Okay so what you heard there are two of Replica's AI voices and so all of that spoken dialogue was synthesized by a neural net by a computer which is pretty cool and so hopefully by the end of this presentation you'll go away with a bunch of ideas, your head will be buzzing about cool ways you can use AI voices in your game or movie within the context of Game Narrative.
So, to start out, I thought we'd cover a brief overview of all the topics we're about to cover in this presentation.
So, we'll start with a quick who am I, a bit of background about me.
Then we'll jump right into game narrative and storytelling.
Why is it important?
Why is it great?
We'll then look at some of the challenges with regards to game narrative and storytelling.
and how voice AI could help overcome some of these challenges.
Then we'll look at a bunch of really cool voice demos.
There will also be visual parts to this voice demo, so you guys are going to love it.
Definitely stick around for this.
We'll then break down the process of what did you actually witness and hear.
how does that fit into the game narrative theme. And finally, key takeaways. Because we're covering so much stuff in 30 minutes, we'll just summarize before the end of this presentation. So in total, a lot of stuff in 30 minutes. Thankfully, this is a pre-recorded session.
and we'll be around to answer any questions you may have. And you can also go back and watch parts again that maybe was too quick the first time you saw it. So with that, let's get started.
My name is Shreyas. I started my career as an aerospace engineer. So yes, I'm a bit of a nerd.
been doing startups, hardware and software, for about 10 years. About four years ago, I got into deep learning, specifically voice AI. About the same time I met my co-founders, we started Replica.
The rest is history. But really, at the time, four years ago, we saw the enormous potential that voice AI as a technology has for creative people. We thought we would set out and build Photoshop for voice.
Outside of work, I do have some hobbies. I like playing the drums. I like playing all sorts of games, but specifically I like racing games because I also like to race in real life. So while I'm an expert on voice AI, I'm not actually an expert on game narrative, which is also part of this talk today. So the most popular Google search result says narrative in game consists of plot, sounds, music, atmosphere, dialogues, player choices, and of course gameplay, and it creates the overall impression of the game and allows the player to feel a part of the story. So that sort of makes sense to me. I've also spent some time asking experts in the field and while they more or less agree with the most popular google search result there are slight variations to this. Some feel more that it has more to do with the actual writing aspect, some prefer the ability for player choices.
But overall, I think we can all agree that game narrative is like good storytelling with the addition of player-driven choices.
So when I think back to Lord of the Rings when it was still a book, I had to imagine what all of these characters looked like, what they sounded like.
And Tolkien was amazing because he could do this. He could paint pictures and movies with words.
But when the movies came out, obviously it was fantastic. And so we think that game designers and narrative experts should really be using all of the tools and technologies that are available today to really help you tell your story in the most compelling way possible.
And if we think about how storytelling has evolved, the visual side of storytelling has really come a long way from our cave painting ancestors, where we're now using, we've evolved through books and we now have video games, thanks mostly to advances in 3D graphics, company like NVIDIA is doing a lot in the space, Epic Games is doing a lot with their Unreal Engine, Unity, Roblox, these are the ways in which stories are being told today.
Unfortunately, though, here's a problem.
voice acting is still too hard and this is despite how powerful the human voice is and how crucial it is to storytelling. From the previous slide, back in the days sitting around campfires we would still tell stories and so it's a shame that the voice acting component is often an afterthought and left to the final stages of any creative production. For those of you who have worked with voice actors you know that they're pretty expensive and the process can also be quite time-consuming.
And so what happens is most of you are using this guy.
Get to the chopper.
And that's a shame because generic TTS will break immersion.
It is not going to give you the superpowers that you need to really sell your story.
And so we think this is a challenge, but we think voice AI is the solution to this because voice AI does give you superpowers because it can sound like this.
One step closer, demon filth, and your general dies.
Right? It's pretty cool.
So voice AI is much more than just plain old text to speech.
We're about to be overrun.
Fall back to the fortress now.
right? It has the ability to inflect emotion, tone, and stylistic control. So even though you can still use text to go to speech using Voice AI, it is fundamentally different to the generic text to speech that you've probably been working with so far. In this presentation, we're not going to go into the technical details of how this works. We thought the best way to prove to you what it does is through a practical example. So...
Let's play a little game. This game is we're going to pitch you an idea for a video game, very meta, and you, the audience, are going to help us fund it. This game is called The Quest.
It's got two lead characters, male and female, like you can see on the screen.
and it's loosely inspired by the Witcher, it's inspired by the Lord of the Rings, so this game, this adventure is set in magical, mystical, fantasy land, but also our two main characters, they're warriors and they're hard-fighting people.
So we thought the next step, now that we have the general idea for what the quest is, we would progress to a rough visual storyboard because that is the best way to try and pitch your idea. So we've put together some scenes, I'll be taking you through it. We've also collected some sound effects and foley to really add to the atmosphere. So in this scene, we've got our two main characters, they're on horseback, they're riding through the woods.
And they're having a conversation.
Things are fine.
No problems so far.
Then things are changing.
They dismount from their steeds, draw their swords, because the enemy is advancing.
And then finally, there's a fight scene.
And in the end, they ride away on horseback.
Okay, so, so far so good. We've only spent a couple of minutes mocking up a visual storyboard to convey this idea. We've collected some sound effects in Foley, and I guess the next step is let's put some voices into this, right?
Remind me again what the plan is? Kill anything that comes our way.
Freya, behind you. Thanks, we're even.
There's too many. We must make more village.
All right, so, well, to take nothing away from generic text to speech, it's really not compelling. There's no acting going on. And so this breaks immersion, and it's not a very convincing pitch.
Let's contrast this with using Replica Voices, right?
That's the whole point of this little game that we're doing.
So this is how we're gonna do it.
We jump into Replica Studios, which is a desktop app that works on your Windows or your Mac.
And as you can see, we have a growing library of AI voices that you can choose from.
So in this menu, you can browse through voices, you can audition them, listen to samples.
You can also drill down into individual voice profiles.
For example, let's look at Colt over here.
So Colt's voice is inspired by your stereotypical sort of cowboy kind of guy.
As you can see there, he's got a few different moods or styles, so he can be charming, he can be intimidating, and he also has a battle style, so he can shout in battle.
And what we're gonna try and do is find a good fit for our two lead characters.
So this is what Colt sounds like.
There's too many.
We must make for the village.
Cool, so he sounds like what you'd expect him to sound like and that's not a good fit for the Lord of the Rings Witcher inspired theme that we're going for.
But it's a cool voice anyway.
Similar to Colt we have Vinny here and Vinny is inspired by your stereotypical Italian mob boss guy.
So this is what he sounds like.
There's too many.
We must make for the village.
Alright, so just like Colt and Vinny, surprise surprise, we also have a voice that's perfect for the quest.
And we're calling him Deckard. This is what Deckard sounds like.
There's too many! We must make for the village!
Alright, so...
Hopefully you've understood by now, Replica lets you audition and search for a number of voices.
So similar to Finding Deckard, we've gone ahead and auditioned our female lead character.
And now that we have our two characters, let's go to this interface, which is the main Replica interface, where we can start adding in the lines.
that our characters are going to be saying in these scenes.
And if you look there, you can also see there is a column for the default style that we're applying.
So you can see that initially, things are quite lighthearted and casual.
So they're having a casual conversation.
Then things turn serious.
The enemy is upon them.
and finally there's like battle scenes so there's battle shouts and all that stuff going on.
So this interface is really cool because it lets you experiment very quickly. You just type in text or we're also building a feature where you can import all of your dialogue and lines from a CSV and pre-populate all of these things in Replica so you can go from text to voice in an instant.
So this is a great way for you to get an overview of everything that's happening in your project or your scene, but you can also go one level deeper. So for a given line you can drill down and you can fine tune the performance.
And you can do this in a number of ways.
You can highlight bits of text and then apply some transformations using sliders and dials and knobs that we provide.
Some of these screenshots that I'm showing you in the presentation are in beta.
So you can download Replica Studios right now, but you may not see exactly what we've got here because we're still testing this with a smaller subset of users.
But this is coming very soon to everyone on the product.
So in this scene we're going to listen to a couple of variations of the same line, one with emphasis on the word anything and one without. Have a listen.
Kill anything that comes our way. Kill anything that comes our way.
So that was just to illustrate the ability of fine-tuning that you could do with this interface.
Alright, so now that we've spent some time populating all of our lines, we've even spent the time drilling down individually for lines that we wanted to fine tune and tweak.
And so now we're ready to go back to our rough storyboard and listen to what this sounds like with replica voices.
Here we go.
Do I hear a thank you for saving my life coming?
That's not what I'm saying.
Whatever you're trying to say, that's what it sounded like to me.
Pretty good. Next scene.
Speaking of smells, do you smell that?
It smells like...
Ghouls!
The girl.
They must have her scent.
OK, and the last one.
Kill anything that comes our way.
Freya! Behind you!
Thanks! We're even!
So that's not bad, right?
It's not bad, especially when you compare it to...
Remind me again what the plan is.
Kill anything that comes our way.
Okay, so hopefully that illustrates the point in a nutshell.
And hopefully at this point, you, the audience, actually like what you've been watching.
Well, we've kind of made the decision for you.
We think you really loved it, and we think you want to greenlight this.
You want to fund this project so we can go out and actually make it.
So let's do that.
We've gone now to Unreal Engine.
We're going to the Marketplace where we can go and find assets so that we can put them into a scene.
add some cameras, add some lights, and really start blocking out some shots for the visual aspect of storytelling. And that's when we ran into a really interesting challenge, because it turns out if you've got high fidelity characters on the screen and they're speaking, their lip movements really need to match what's being said, otherwise it breaks immersion.
Check this out.
Then, all of a sudden, you somehow were elbow deep with your obsidian blade in its jugular.
Do I hear a thank you for saving my life coming?
That's not what I'm saying.
Right, so...
Even though this looks really good, it's got high fidelity humans, way better compared to the rough visual storyboard that we had a couple of slides back, it's actually worse because it breaks immersion because all of your focus is on the lips and the fact that they're not saying or they don't seem to be saying what's actually being heard. So we decided that this was a big enough problem that we wanted to fix it.
and we started working on trying to fix this earlier in the year.
And so I'm going to show you a quick update on the progress we've made.
But before then, I'll just say quickly, we've got these plugins coming out that can do lip-sync, that work with Unreal Engine, and also works with Reallusion iClone.
and we're going to be working to add integrations and support with Unity and Roblox so that you have not only do you have voice acting with AI voices, you also have compelling lip sync as an automated solution. So this is our latest progress.
Then all of a sudden you somehow are elbow deep with your obsidian blade in its jugular.
Do I hear a thank you for saving my life coming? That's not what I'm saying.
Okay, so that was a sneak peek.
Don't worry, we'll show you the full video in a moment.
But it's a big improvement from the other video that I showed a moment ago.
So this is not bad given we've only been working on it for a few months.
And so we're fairly confident that with continued effort, we'll get to something that looks really, really good not long from now.
And so this is a demonstration of how we're solving lip sync for Unreal Engine MetaHumans.
So I'll play this video for you in a moment, but let me just explain what you're going to see.
We've got our developer here, and he's using an iPhone camera, which is running an app that scans his face, and based on the changes in his face and lip movements, that drives the MetaHuman visually in real time.
So that's really cool.
Thank you, Unreal Engine.
But the cool part here is, at the same time that he's performing the line and doing the face acting, Replica can take the audio input from your own voice and use that to direct the performance of the AI voice, which can then be applied onto the metahuman.
And so that's what you're about to see.
Have a look.
Do I hear a thank you for saving my life coming?
Do I hear a thank you for saving my life coming?
So I should explain that the visual side of things, where you're driving the MetaHuman through the face capture, that is in real time.
Thank you, Unreal Engine.
However, the part where your voice is being used to direct the performance of the AI voice, that isn't quite real time just yet.
It's going to get there.
Currently, depending on the length of the line that you're trying to direct, it could take anywhere from 40 seconds to a little bit more than a minute per line.
Before moving on, I thought I would play that demo for you again so you can just see that again.
Do I hear a thank you for saving my life coming?
Do I hear a thank you for saving my life coming? Do I hear a thank you for saving my life coming?
Okay, so that feature that lets you direct the performance with your own voice, this is coming soon.
It's not part of the app yet.
But if you think back to the slides that I showed you of replicas, product and UI, most of the controls for fine tuning now involve.
selecting bits of text and then applying transformations by changing a value on a slider or a dial to get the desired output. This new feature is another way that you could get the desired output where you don't have to use the sliders and dials you could just use your own voice to perform the line and Replica can transfer the energy, cadence, and tone from your own performance onto any of our AI voices.
To further demonstrate how this works, you start out with a default AI voice output that sounds like this.
There's no way you can copy how I speak. You then use your own voice to coach the performance.
There's no way you can copy how I speak. And finally, there's no way you can copy how I speak.
So what I've just played for you there is the default AI voice output for Deckard.
Then we had Gavin, who's a Replicas designer, sit there and record his version of how he wanted the performance to come out. And then you have the final output that combines Gavin's attributes in terms of his cadence and his tone and his energy.
and applies that through an AI voice.
This can be extended to any of our voices.
So here's a version with a female AI voice.
There's no way you can copy how I speak.
There's no way you can copy how I speak.
There's no way you can copy how I speak.
So.
All in all, really cool functionality.
This is still in development, but we're excited about this feature because this is how we think, at least for high-fidelity characters, you can solve lip-sync, or it's one of the ways in which you can solve lip-sync.
So finally, now that we've shown you all of the tools available, with Replica, we've actually gone ahead, since you were so kind to fund our project, we've gone ahead and created an entire cutscene for the quest.
And so we're really proud to present the quest.
Remember the time we fought the Dragonauts? Of course I remember.
I remember a dragon swooping down and almost lighting the whole field on fire.
Then, all of a sudden, you somehow were elbowed deep with your obsidian blade in its jugular.
Do I hear a thank you for saving my life coming?
That's not what I'm saying.
Whatever you're trying to say, that's what it sounded like to me.
At any rate, I smelt like dragon fuel for weeks after that.
Speaking of smells, do you smell that?
It smells like...
Ghouls.
The girl.
They must have her scent.
The village is only an hour's ride.
If we hurry, we may be able to warn them.
There's no time.
Get ready.
Remind me again what the plan is?
Kill anything that comes our way.
Freya!
Behind you!
Thanks!
We're even!
There's too many! We must make for the village!
Nope!
You get to the village! I'll lead them away!
Find the girl! She is the key!
No! I won't leave you!
I've got this! Go! Now!
Come on, you belt! Are you hungry? You want your fresh bones and all?
Well, we're hoping you really enjoyed that.
It's not bad given the fact that this entire cutscene was put together by one talented CG artist working for about two and a half weeks.
And so from an indie developer perspective, voice AI definitely gives you superpowers.
And this is also quite novel, I should mention, because it's one of the first...
early use cases of using AI voices to drive digital humans, especially in this case realistic Unreal Engine metahumans, to make a cutscene. So as the technology evolves all of this will start to look and sound much better, but it's really not that bad given where we are right now. In fact, one could go as far to say that It's kind of like we're comparing Toy Story 1 with Toy Story 4 and see how far they've come in a matter of several years.
The good news is I don't think audio technology and AI voice is going to need that much more time to get to very acceptable levels, even for big budget studios.
And we're definitely working on it.
And so we're finding that a lot of the biggest studios use Replica in the pre-production cycles and during the early creative process. And if you think about it from the context of game narrative, this is also a great chance to really help tell a compelling story without having to resort to voice actors, which traditionally happens much later on. So you've actually got all this extra free time to experiment with story ideas and dialogue. And that's what we mean by voice AI literally gives you creative superpowers because this was not possible before. So it's really hard to compare.
what was possible before voice AI with what's possible now because they're two entirely different things. You could use voice AI right now as a big studio in pre-production but as a smaller studio or an indie developer, well the voices are good enough for you to ship in the final game so you've gone from having no voices potentially or just text on the screen to actual voice acting pretty compelling in your game.
And doing this in an affordable way and in a way that doesn't take you too much time.
So all in all, voice AI gives you superpowers.
We hope that this will help game designers and narrative experts make bigger and more compelling games if they have tools like this early on in their cycles.
So here's an example of how a pretty big studio, Midwinter Entertainment, used Replica in pre-production in their title Scavengers.
And this is how they did it.
So they had writer, game designer, creative producers, and a bunch of folks all around the world.
being able to iterate on big parts of story and dialogue and get those changes in front of their 5,000 beta testers on an almost daily or weekly basis.
Again, this is an example of something that you could never have done without this kind of technology.
And, obviously, scavengers then...
brought real voice actors in to record the final lines once they had ironed out all the pieces of what they actually wanted to say.
So this helped them in a massive way.
It's important to say here that voice actors are a really big part of what Replica does.
We're working closely with a growing pool of really talented voice actors that help create all of these voices that are available in our library.
In fact, some of the voice actors we've worked with have made three or four different character voices that are all in our library. And we're developing profit-sharing models so that as these AI voices are used by millions of studios around the world, the voice actors who helped create them can earn a passive income stream alongside their regular day-to-day job. So this is really a win-win scenario. It's great for talent and it's really great for creative studios because now they can do things that traditionally were impossible.
So we're really happy about this.
And that brings us to our mission.
Replica is trying to build the world's greatest library of AI voices for games and movies.
And as the technology improves, we will expand our pool of talent to include premium actors, famous voices, celebrities, and work with the unions.
So we're really excited about all of that.
Finally, is the future bleak?
This is a joke title guys, the future of storytelling is not AI and NPCs alone, but we do think AI and NPCs have a part to play in the future of storytelling.
And so this video that I'm about to show you is actually a game created by a user of Replika, so the game is called Modbox, it's on Steam.
And so the developer here has done this really smart thing where he's combined OpenAI's GPT-3 with Replica Voices.
So in this game, which is a VR experience, you can walk around and have believable conversations with NPCs, and they will respond to you in almost real time. Check it out.
Hello, Bobby.
What do you want?
Where are you going?
I have to go to work.
I'm already late and my boss will punish me if I show up even later.
Please leave.
I can't help you right now.
Where do you work?
I work at City Hall.
It's a government building in the center of town.
So I paused it there to explain to you what's actually going on again.
As you can see, the developer who's actually made this video asks a question to the NPC, after which point there is a bit of a time delay or a lag.
it combines a whole bunch of different AIs strung together.
So there's one AI that listens to the developer or the player speaking and converts or transcribes his speech into text.
So that's part one.
That then sends the text transcript to GPT-3.
GPT-3 takes the text input and then comes out with a response based on that text input.
That takes a bit of time.
and then finally when gpd3 has its text response that gets sent to replica and replica converts that into bobby's voice and that takes a bit of time so all together you've got three separate ai systems that all add up in terms of how much time they take but we think it's really awesome you guys should definitely check out modbox on steam because it's a fun game to play We've covered a lot in this video, so hopefully you'll also go back and re-watch sections.
And if you have any questions or any thoughts or any feedback, that's our email, so we'd love to hear from you.
We also have an active Discord community where loads of Replica users have discussions.
This is where we make early announcements, where you can potentially sign up for the beta.
and get access to some of those features that are in early access.
And it's also a great place to share the kinds of work that folks are making with Replica and how they're using that to make games and movies.
So we hope you'll join and check it out.
But thank you again for tuning in.
It's been a pleasure speaking here at GDC.
Shreyas from Replica signing out.
Thanks.
