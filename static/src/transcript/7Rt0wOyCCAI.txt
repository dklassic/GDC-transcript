Alrighty, looks like it's time so We're going to jump right in because we have a lot of ground to cover.
But I know there's still some people coming in.
So looks like this session is pretty full.
So if some of you guys could scoot a little bit closer to the center so there's more room for other people, that'd be great.
And without further ado, let's jump right in.
Our subject today is the future of art production.
And I actually want to kick it off with a story that I really like.
Probably my most favorite story that I saw.
shamelessly stole from a speech by David Foster Wallace and it goes like this. Two younger fish are swimming at the bottom of the ocean minding their own business as an older fish swims by and the older fish goes, hey boys, how's the water and then just keeps on going. And a couple of moments later, one of the younger fish asks his buddy, hey man, what's water?
And while not that amusing, I think this anecdote very well describes the condition that all of us are very prone to, where we get so used to the circumstance around us that we stop critically analyzing it day to day.
We stop applying critical thinking, and especially being a person involved in Pipeline development and tool production. I find it to be crucial to constantly be asking. What is water?
What are the things that we're not consciously thinking right now that impact us dramatically that need improving that could make things a lot better And so this is something that we're kind of trying gonna try and do today with our production We're gonna try and see what are the things we're missing?
What things are we not thinking about and we're gonna do it through the prism of technology And this talk is obviously about technology, right?
We're going to be talking about the latest trends in all of the pipeline in our tech and sort of even tech outside of the games industry.
This is going to be shuffling its way into art production pipelines.
But at the end of the day, I think the most important part here is that Technology will force us to consider art more.
Because if you look at all these pipelines, they're inherently reductive to the amount of work.
We're gonna be giving things up.
There are gonna be things that we're gonna have to find minimally contributing, least contributing something that we'll have to let go off.
And on its own, it's fascinating because technology is gonna force upon us that conversation about what is art.
Because when you look at it the other way around, the things that we're not going to be able to let go of, the things that are going to be so inherently human and artistic that they're always going to be parts of pipelines, are going to essentially be art.
And to tell you the truth, this is probably the scariest talk that I'll ever have to do, because ...
This is no joke, right? It affects all of our livelihoods.
It's, you know, years and decades of skills that we acquired, and 10 years, 20 years down the line, some of them might be gone.
And, uh...
The biggest reason for doing this talk for me is I feel that everyone has the right to be informed on that question. Everyone has the right to be part of that conversation because this is going to be a debate that we're going to be having for the next 10 or 20 years and that debate is not going to happen here or any other conference. It's going to be each and every one of you going back to your studio and having conversations about how do you want to work? How do you want to create art?
and basically hopefully giving you some language and some context as to how to do that will help all of us end up in a situation where we're only improving.
And so, without further ado, let's jump right in, into the actual features.
And these are kind of the four major things we're going to talk about.
They are automating optimization, capturing reality, parametrization simulation and generation are all lumped together in one point and we'll talk about why. And then finally we're going to have deep learning and artificial intelligence and how that is going to affect.
art production. So let's start with a simple one. Optimization automation, that is probably a no brainer that we're doing that already and we're going to keep doing that. But something very interesting to the subject of what's water. I don't know how many of you folks got a chance to work during the NES days, but this is the original color palette from NES. And back in those times, color was a technical resource.
It was something that you managed because you couldn't afford to display all the colors at the same time.
So artists carefully picked their palettes and made compromises, and that was a very big optimization point.
But how many of you think about this today?
Probably none of us because it's no longer an issue.
Technology has evolved, it has caught up, so we don't have to worry about that.
But that inherently begs a question.
what other things in our pipelines today that we don't even think about, that we spend so much time on, that are gonna go away.
And there's obviously a lot of examples, right?
Anything from low-poly or high-poly to low-poly workflows to level of detail meshes, to separate collision meshes, shadow casters, IK meshes, gameplay features, even unwrapping UVs manually, all of that is basically a compromise that we have to make for the sake of technology that is still imperfect, that is still developing, that is catching up, but...
But inevitably we're going to reach a point where that doesn't matter anymore.
Where we're going to be able to afford to display anything we want to display.
And then from the other hand, we're tackling that problem on the software side.
Where we're getting better and better at automating those things.
We're automating level of detail meshes and improving UV unwraps.
And so the more that's going to happen, the more chunks of our pipeline are going to sort of fall off and become obsolete.
Which is great.
And this point is easy, right?
we can actually very easily and safely say that these processes do not have any artistic value.
So they're gonna go because we want to allow ourselves more time to focus on the things that are important, but that once again inherently begs the question, what is important?
And so now we're going to jump into something that is a little bit more controversial, or probably more controversial.
And this is Capture in Reality.
And I actually wanted to start with this slide, which seems very far removed from the subject.
But actually, I mean, obviously Prince of Persia, a lot of us, probably as kids or maybe not, played the crap out of it, got inspired, wanted to make some games.
And, you know, the fluidity of the animation there made the prince so lifelike that you couldn't...
couldn't help but be blown away.
But every time I look at this now, I can't help to think back to Jordan Mechner's talk in 2011 at GDC, where he was talking about how he produced Prince of Persia.
And the way this worked back then in 1986 is he and his brother went outside and he shot his brother running around in a parking lot and then he actually rotoscoped it and basically pixel by pixel painted it in into the game.
So when we're talking about all of these new and coming scanning techniques and sort of capture reality and animation.
it's not a new concept.
We can't treat them like they just appeared and they're gonna sort of circumvent what the art process was because they were there all along.
And we were doing them 30 years ago and we're gonna keep doing them because at the end of the day, Jordan's goal was to make a game and that got him where he needed to go with the resources he had and allowing him the opportunity to retain that artistic vision.
we're only going to keep going with that.
And same thing for facial scanning.
First time playing Max Payne, I remember being so blown away by the quality of his face.
I was like, this cannot absolutely get better.
This is photoreal.
Because it was a photo on a box, basically.
But this only keeps on going.
And there's no sign of stopping.
And there's more and more of that coming around.
Obviously, we're doing that for environments.
And we, I mean, predominantly dice at this point.
Hopefully you guys caught their talk last year I think it was.
And it definitely proves that it's already doable.
And technically, there's hardly anything in the world that we can't scan today.
We're solving these problems one by one where we can do characters, we can do organic environments.
There's obviously concern about, oh, hard surface, very noodly kind of man-made objects.
we still can do those. This exists today. And with enough pictures that you take of an object you can get the levels of reality and sort of sophistication and detail and history and wear and tear that would take you a stupidly long time to do by hand. And so We are solving most of the problems that exist, and a lot of them are solved.
The other one being reflective surfaces, which is obviously a big concern.
It's something that we have a hard time scanning, but you can already do that.
Either you're using a cross-polarized darkroom setup, or you're using a matte spray that's already starting to appear on the market, actual sprays for photogrammetry that you can just use as coating for an object, and then apply that.
So most of these problems are already solved, and they're only going to keep...
being incorporated more and more, right?
You can scan entire environments that are going to be 100% photoreal and your only limitation is memory.
And as we all know, that is only going to grow.
So at some point, once again, we'll be able to leverage that much more extensively than we do today.
But obviously there's still a lot of questions, right?
Photogrammetry is clunky to implement into a regular development pipeline when you're augmenting man-made art with photogrammetry.
And then also just flying places and getting your entire team and having them go somewhere is an expensive process and not everyone can afford it.
And we've made games just using Google, so I'm sure a lot of people are used and accustomed to that.
And I think by the time photogrammetry reaches mass penetration, we're going to over-compensate.
overcome most of these issues, but I think fundamentally what's happening is we got used to producing everything from scratch because there wasn't anything in the world at that level of abstraction where we could scan it and put it into a game.
Because the word did not afford us low poly models that could be transported into the game, but eventually, and this might not even be games, right?
That might be Google Earth coming in and just scanning the crap out of everything, and then we're gonna have accessible environments from across the world at a resolution that is.
at a highest level of fidelity that we can just borrow and then eventually we'll basically transition into the same thing that film is doing where you treat your environments as sets and you light them and you dress them and you modify them but you can still communicate art, right?
The art is not going anywhere.
If you look at Blade Runner, one of the most iconic and stylized films ever, it heavily leaned on the real life Los Angeles and the Bradbury building is still around and it's there, downtown LA, you can go there.
going to be a major part of our pipelines and most importantly it's going to be very cheap and that's why it's going to find traction because it's going to be a lot cheaper to just take an existing scan of an entire environment and use it rather than produce everything from scratch.
I'm actually going to skip this one.
But you can download it online later.
It's just more scam stuff.
But now I want to talk about parametrization, simulation, and generation.
And I wanted to start with this.
And this is an example of a visualized L-system, which was developed by a biologist and a botanist by the name of Lindenmeier, where he basically described a plant cell growth using something very close to an algorithm that basically used.
types of an element of a plant as a letter that he would organize into words that would describe the growth of a plant.
And so this particular system is inherently organic.
It comes from botany, but it lends itself very well to programming.
to basically being computer simulated.
And there are a lot of things like that in the world that we can definitely use and sort of apply in our current day technology.
And similarly, right, Epic for their kite demo had like a simulation of growing a forest, and that was two years ago on Unreal Engine.
This is basically old news, but you can simulate natural processes to get.
art or to get the content that you need.
And later today we're obviously going to have the privilege of checking out a talk about Horizon that leaned heavily on a lot of these procedural population technique.
And Guerrilla being the great example of a studio that embraced that approach and sort of how that approach is going to shape our future moving forward.
Same thing with our tools, right?
If you look at Speedtree, we're moving away from working with individual vertices or polygons.
We're actually working with trees now.
We want to treat virtual objects as if they were real objects.
We want to control the height and the density rather than the polygons and the faces.
And the same thing with Substance Painter, because you no longer work with...
pixels per se and textures you're applying materials your brushstrokes are abstracted to a particle simulation that will actually populate an entire sort of System of patterns that you want on an object and this is only going to continue Same thing with the sort of physicality and simulation because once again, we're treating objects as if they are virtual.
But further down the line, anything in our production pipeline, we're gonna wanna treat as if it's something in the real world.
If you're populating objects, they have physics.
They interact with each other, they lean on each other, and that will allow us, first of all, to create more believable worlds, but also save some time doing it, right?
Because you don't wanna sculpt every single fold on a curtain when you can actually just have a physics simulation of it.
So.
Another example of that is obviously characters.
And there's nothing today that is inconceivable about a system where we go in and we scan a whole lot of people and we use their facial features as sort of the extremes for different representation of facial features and then we automate that and blend between that.
wouldn't be surprised if ten years from now most of say indie studios that cannot afford the talent is going to be that much more expensive at that point to generate characters are going to be using an automated system like that that might be augmented with some deep learning or AI technology. But at the end of the day we're very close to it today. This is from black desert I think and it's a couple of years old probably video. And we can do nice believable characters in a modularized procedural way.
I think the bigger take away, and this is why they're all lumped together, is we're seeing this abstraction of interfaces. And abstraction is a programming term that basically means creating a higher level input into a lower level system. So say you have ones and zeros that your processor operates on, but you have programming language commands that you actually issue to execute something. And so this is an abstraction layer. And we're going to keep building those up to a point where the knowledge of computers is not necessarily...
necessary because you can interact with virtual objects as you would interact with the real world objects.
And so that attraction is gonna keep going.
It's not only inherent to art.
If you look at programming, right, Unreal Blueprint allowed people to make entire games without having a programmer on the team, meaning we're building up that functionality to go higher and higher level, trying to get people to express their intent to do what they wanna do faster without less sort of layers of execution.
And the final point for this particular section is obviously AI stuff. And we're actually going to start a little bit outside in consumer tech. This is a promotional picture from Google's new communicator, Allo. And the way it works is it actually has a neural net on board that is going to track your answers and it's going to remember how you reply to questions and it's going to analyze the questions posed to you and it's going to intelligently propose answers.
And this is not unheard of, right?
Chatbots, for most of the companies that you interact online, they rely on these deep neural networks that are taught to communicate with humans.
And we're only going to see more of that, where neural net is going to analyze, say, your entire game that you made previously and all the art choices you make.
And it's going to offer you solutions that you can then pick or modify or interact with.
But once again, this is a not as far off. So Google did a thing with their deep learning neural nets that they used for image recognition and they basically flipped it around. When you search for an image in Google, it would actually scan an image and spit out words that you would then match with your search pattern.
But when they flipped that system around and they put words into it, it was actually able to output images that look like this.
Which inherently proves that a system that is capable of that kind of analysis is also capable of some form of creativity.
Albeit driven by the information that is fed to it by humans.
But all of this is not as far off as it seems.
So there was a deep learning panel at SIGGRAPH this year and folks from NVIDIA were talking about how Remedy used a neural net based animation solver where they just basically taught a neural net to convert a raw video of actors talking into almost game ready animation.
And in general, deep learning becomes a bigger and bigger part of animation solvers today.
So it might sound like an episode of Black Mirror, but it's actually closer than we all think.
And I wouldn't be surprised if 20 years from now everyone has...
a deep learning net sort of as a partner that actually learns how we do things and then allows us to, once again, deliver on what we want to do by offering us suggestions as of what it thinks we're going to do, rather than for us having to do the whole thing by hand.
And once again, this very well feeds into this abstraction layer theory, right?
Because essentially when, say, Google LO sends a message for you, you're still communicating what you want to say.
It's just that you don't have to type every individual letter.
So we're going to that higher level of communicating intent without the.
manual labor of typing in letters.
And same panel as Seagraph, Frostbite Labs, we're talking about how they're looking into neural nets for the stuff that they're doing.
And also at Steam Dev Days last year during the keynote, Team Sweeney was talking about games industry being way behind on deep learning compared to a lot of other industries.
So that kind of leads you to believe that there must be someone at Epic looking into this right now.
Now here's the million dollar question.
So what is left when we scan the crap out of the entire world, when we have neural nets helping us populate it and everything's generated and scanned?
Where do people come in?
What's left of the artistic process?
And that is the most scary question.
And we're going to try and unpack that.
this as best as we can. But basically what's happening right now is we have a creative problem, we come up with a solution, say this environment looks boring, I want to add a puddle. That was the creative problem and a solution. But then the execution of it is I'm going to go to a shader, add a feature, make sure it has a vertex blend on it, go cut in some verts into the environment, paint in the verts, build the level, look at it in game, tweak the shader, bake the lighting, and then hopefully it's done. So that chunk...
is execution and it's by far the biggest part of any production.
And so what all of these things are doing, all of the technology that we're talking about, they're cutting down on execution time.
They're going to get you from your idea, from your solution, from your intent, to the final result as fast as possible.
Hopefully instantaneously at some point.
This basically means that the core skills that we rely on as artists are still as valuable and as needed as they're ever going to be.
But a lot of other skills that surround feeding a still imperfect hardware or software might go redundant.
And so the interesting thing that comes out of all of this is that intent is basically going to be our basic building block of any art production, but also of any interface.
If you're working on tools.
they'll have to be refactored into a manner where we don't treat content as something that pertains to a computer.
We have to treat content as something that's from the real world, and we'll want to interact with it based on intent, just like we would in the real world.
And once again, that very well feeds into the artistic process that we have today, because we're all masters of intent, right?
We don't just go in and do something for no reason.
If this plan has to have more angles and be sharp, it's because this environment has to be scary or foreboding.
We're trying to communicate something about it.
And then all of the choices we make during production hopefully all rely on some kind of artistic intent or meaning to back it up.
And so if we were to look at a process as to how it might look years down the line is you would have your high level intent or global intent where you would generate an entire environment space.
And then you have a regional intent where you go, oh, I want plants in this corner.
So you place your region, you specify a biome, and they just grow.
And then you can go in and be, okay, I want to actually add an individual prototypes.
and I actually want to modify them and add a particular color or something, but that will have to be the workflow.
And what's interesting is, this is kind of the way movies do it.
When you think about it, I don't think anyone's going to say that movies are not artistic.
And this is a great example from Rebel Without a Cause, and this shot is without a doubt art, right?
But it's art because the director and the director of photography infused it.
with meaning, because the character of James Dean is, you know, smack dab in the middle of the sharp corner that's dividing the screen in two halves, and the right side is the policeman, and sort of men in kind of the stern world of men that James Dean's character is getting into, and then the other side, it's women, it's his love interest, it's sort of more kindness, and the choice, for example, of the red coat is not accidental, it attracts our attention.
So the art part of this is not the fact that someone put a mug in the corner of that room.
or build that desk.
It's the fact that it was heavily infused with meaning that communicated something, and that part was art.
So in essence, deriving from this, you can say that creating art is essentially a process of assigning meaning.
And in that case, no matter how much you optimize the process, the art is not gonna go away because you're still gonna have to think about what are you communicating to your audience.
If your art does not have a meaning to back it up, then it will not be as successful because there's nothing for people to resonate with.
And so this part is, once again, not going anywhere.
There's obviously the bigger question, right?
How is it going to impact us as an industry?
And cinema is once again a great example of that because they went through it, through this.
They went through the process of democratizing their productions.
They used to be way more time consuming, laborious, required a lot more money, but then with this great abstraction came great democratization because everyone had a pocket camera that they could shoot a movie with.
And that brought a lot of different things and we're going to try and see how that applies to the games industry, or at least speculate and do our best.
So obviously productions are going to get cheaper, right? This is understandable.
When you don't have to model all of the art but you can just import real locations and dress them up.
the bulk of the cost of any production goes away.
And the same for animation.
20 years from now, you're going to have a 4D phone that captures holographic people that you can just drop into the game immediately.
And same thing for smaller teams.
Don't get scared just yet.
We'll circle around to that point.
But yes, you will need smaller teams, because you can do more with less people.
And that means that there's going to be a sort of a re-generalization where we used to specialize a lot, but then at some point it's not going to make sense anymore.
At some point all this is going to be automated and we're going to be more generalized again, and we're going to execute more artistry rather than technical communication.
Production times.
So I don't believe that the production times change much in the movie industry because a good story or a good gameplay takes time to mature.
It's not something that if you can produce an entire world in three days it doesn't mean that you're going to have a good game.
Because a good story takes iteration.
You're going to have to work with your audience, you're going to have to playtest, you're going to have to figure out what makes it great, and that part just takes time.
There's nothing technology can do to speed it up.
excuse me, speed it up. Another fun outcome is that Photoreal is going to become the new indie because it's going to be that much cheaper. Right now it's diametrically opposed. Independent studios do more stylized games because they cannot afford to compete with super expensive productions. The more AAA studios do that are very realistic and detailed and that way they also get to stand out on the market. But eventually when the cost of everything scanned is going to become dirt cheap.
everything's going to be very realistic and everything's going to look good, provided you can light it and give it enough context.
But that being said, if I were a big AAA publisher or a studio thinking of a franchise that's going to last for 20 years, I would probably consider something slightly less real.
And final one, I do not necessarily believe that a lot of jobs are going to get lost.
Same way in the movie industry when democratization happened, it didn't shrink.
There was actually more value being generated, there were more movies made because...
It's that much simpler now.
Many more people are coming in to do it, and all of them need talent, all of them need people to support it, all of them need artists, all of them need lighters and directors of photography, and what be it.
And I'm convinced that that is what's gonna happen in games because right now it's a very technical process.
It's a high barrier to entry, but eventually it's not gonna be, and then everyone will get a chance to express themselves.
And that's just going to mean that we're creating that much more value in that many more games, but it's just that on every individual project you're going to have less people.
So if you take one thing from this talk, it's hopefully that this is how I think it's going to be.
So take some comfort in that.
But then for the final point, is...
Every time you go from this big, huge, gigantic production that has a lot of people to just a handful of people being able to produce something of the same quality, you know, for every Captain America, you get a good wool hunting.
And this, to me, is fascinating because...
Every time I go to GDC, I get to meet all of you, I get to talk to you and see this sort of contagious passion for art and desire to do things.
And the people that are going to be making the next Good Will Hunting games are going to be you.
And if, you know, I used to model and I still do for 15 years now, and I come home after a long day at work and I do some modeling and texturing until 3 a.m., and more and more these days I'm realizing that I might not get to do this for much longer, but if this means that that many people get to have a voice.
if that means that that many people get to tell their stories, if that many people get to go back to what inspired them to make games in the first place.
Because I don't think any one of you saw someone do a UV unwrap and went, holy shit, that's what I want to do for the rest of my life.
You know, we're all inspired by stories that profoundly changed us.
We just want to be better.
We're all inspired by virtual worlds that made us want to go there, live there, and share them.
And this is what I think technology will allow us to go back to.
And yes, we're going to lose some things.
But if that kind of future means that...
I don't get to model or texture anymore, then I guess I'm fine with that.
And to be honest, I think we as a species are gonna be better off that way.
So with all that said, to tell you the truth, I can't fucking wait.
Thank you so much.
If you have any questions, I think we have a minute.
You can always just find me after the presentation.
Hey, man, one question.
One question over here.
Yes, yes, yes.
So I'm with you, I can't wait.
I think ultimately what we, I wanted to say for your first story, it's what is water, it's why is water?
I think that will be the question we have to ask.
That's a good question.
When we don't have all the worlds ready at our fingertips, it's like what do we want to tell in that world?
Exactly.
So that's what I hope, you know.
That's what I get out of your talk, and I'm inspired by it because I think ultimately we're going to be able to be more empowered to tell stories.
We won't have that barrier to tell those great stories.
So thank you for the presentation.
Thank you.
See you, bud.
Totally agree.
Cheers.
