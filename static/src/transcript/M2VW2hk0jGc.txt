All right, I think we can start. 3.30.
Let's settle down.
All right, we had some technical problems.
Hopefully, everything works now.
Thank you, computer.
So I'm David Dicutitze, sound designer at DICE.
I've been working on Star Wars Battlefront for the past few years.
And I'm Gordy Habb, I compose the music for Battlefront.
Oh, I don't get it.
OK, so our standing on the shoulders of giants is our session.
So what does that mean?
I didn't come up with the name, but I did the Photoshop.
So on the left here, we see sound designer Ben Burtt, and on the right, composer John Williams.
And both of these are very known for their work, especially on Star Wars.
And today we're going to talk in two parts about how we took their legendary legacy into a 2015 released game.
And I'm going to start off with the sound design.
So first, I'm going to give you an idea of what our initial target or goals were, some challenges we encountered, how we approached those, and a conclusion.
But first off, we did go to Skywalker Sound on the Skywalker Ranch on a few trips, which was amazing.
And through the collaboration with Skywalker Sound, we got the film stamps from the original movies and the prequels, which allowed us to listen to dialogue as effects music in separation while watching the movie, which is great for reference.
We did have a full day.
eight-hour Foley session at the Skywalker Ranch with the talent there.
And there we recorded Rebel and Stormtrooper movement sounds.
And we also received an extensive Star Wars sound effect library, as many games before us.
But we also had the ability to ask for additional content when we really needed something very specific.
We also had the ability to talk to legends like Ben Burtt and Matt Wood.
And this is here in Ben Burtt's office.
It's the only picture, it's blurry, but well, can't complain.
So it was great to hear some stories and get some insights of how things were done back in the days, which is mostly a lot more dangerous than today, regarding electricity and so on.
But first off, what is Star Wars sound?
Star Wars trademark sound?
I would argue it feels like a lived in universe that has many fantasy elements, but it still feels relatable and tangible.
And I would say it is the movie franchise with the most recognizable sound effects to date.
And here's a quick compilation of just some of those sound effects.
And all of those were from the game, actually.
All right, so what did we try to achieve?
First off, we wanted to embrace the original soundscape, the original style and tone.
And that doesn't just mean, of course, sticking to the sounds.
Everyone knows.
But also, when we make anything new, we'd have to embrace the way the old sounds were made, which means organic sound design and using analog synth.
as opposed to highly digital sounding, heavily processed sounds as you would often do these days.
And here's an example of some of those newer sounds.
So the thermo imploder effect was a combination of analog synth that we recorded out of the modular system of audio director Ben Minto and combined with real world sounds such as explosions, wire twangs, metal hits, tank shell fly-bys, plane wind-ups, etc.
And the R5 Scream as I was shooting it, that was actually a barely compressed scream of sound designer Gustav.
Take the picture, please.
And yeah, organic sound design.
There you go.
So from there, we wanted to extend, thinking about that we were making a game.
Of course, we had to think about the player experience.
What does it mean to be inside the world and not just an observer?
We had to, we knew that we had to remaster a lot of the old sounds to make them.
well, to expectations of today's audience.
And we knew that we wanted to worldize the sounds in a sense that even though they're sometimes crazy sci-fi sounds, they have to sound like they naturally propagate through those environments you're in.
And here's an example for the player experience.
So pay attention to the subtle things, like the foley and the breathing and the ambience, but then the in-your-face flashbang at the end as well.
So as a little fun fact, two days before I started working at DICE, I pierced my right eardrum with a twig, unintentionally, and I wanted to bring that experience to the audience through the flashbang effect. That's what it sounds like. Oh, I should mention, it has healed. I'm not, like, deaf. In fact, my right ear is better than my left ear now.
Well, next we wanted to enrich beyond the visual, which mostly relates to ambiences where we would add a lot of sounds even though we have no visual connection, so we would take any chance we have to add more Star Warsiness into the game.
And here's an example of when you are a stormtrooper, an imperial soldier, and you go close to an Ewok village on Endor.
they will start, the Ewoks will start throwing stones at you and might even hit you on the helmet and cause some hands, handshake.
And that whole system is basically faked through sound.
There is no visual connection to it.
So with all that in mind, here's the crossfade of Return of the Jedi, Episode 6, Endor Battle, into a multiplayer recording of the game on Endor.
So what were some of the challenges we faced?
And this is a short summary of that.
So there was very variable reference audio fidelity.
If you just compare episode four to episode five, there was a big jump in just raw frequency output.
And we obviously had to make all that content consistent, and also consistent with everything new that we created.
There were lots of new weapons and gadgets, environments, and events, such as Star Destroyer crashing into a planet, that don't have any reference in the movies.
And generally, when you take something from a linear environment like film into a dynamic environment like games, it's not a trivial task, because those assets were created for very specific situations.
And in the game, you can encounter a lot more.
different situations for those sounds, like different distances, perspectives, angles, environments.
And also, a sound that might appear once in all three movies might be turned into a gadget or weapon for players to use for many hours, right, to make it their primary experience.
And of course, if it's just one sound in the movies, the quantity and variety just isn't there to support that gameplay.
So there were a lot of blanks that we had to fill out, but in a seamless way that does not dilute the original sound.
And also, we often had to balance gameplay requirements and movie authenticity, which are not always the same.
Here's an example of that.
So these are all the weapons, handheld weapons in the game, or most of them.
And I'm just going to play a quick compilation of those.
So these are the weapons that actually do have sound reference in the movies.
And these are the weapons that have unique movie sound reference.
And what I mean by unique here is the character of the weapon never changes throughout the movies and they don't reuse the sound that previously appeared for something else.
Reusing sounds like that is never a problem in the movies because there's often a lot of time that passes in between those moments and what matters more there is what works for that scene.
But in the game you can have all weapons potentially next to each other and it wouldn't be good for player information to have some of them share the same assets.
And also when you unlock a new weapon you don't really want it to sound like what you just had before.
So how did we approach making most sounds in the game?
First off, we would define what the sound is.
We would look at the reference.
We would see how clear is the reference, and does it overlap with anything.
Often, if there is a reference, then we would remaster the assets.
Here's a spectrogram example of a Tatooine wind.
So you read it bottom to top, low frequencies to high frequencies.
And as you can hopefully see on the right side.
There's more content in the higher frequency ranges, which is what you lose mostly through older recordings on tape.
And we do that through a variety of tools where we bring out some of the weaker or filtered frequencies.
And we would also add content on top that fits to the source underneath.
When we make something new, of course, we have to make sure that it seamlessly fits into the soundscape.
Ideally, someone new to Star Wars, maybe someone like that exists, would not be able to tell the difference between an old Star Wars sound and a new one.
So speaking of fitting in, you don't want to end up with this, where clearly this person is Photoshopped in.
So when we have the content, we would then build a modular system for the runtime behavior.
And that helps us to make the experience very immersive through a high amount of variation and being very adaptable to the game's conditions.
So I'm going to go through an example with the classic E11 blaster that everyone knows.
And this is the.
This is the visual scripting.
This is a sound graph for the firing logic.
So here on the left, we see in these red boxes, it's six layers.
Each layer represents a sound in itself.
And it can be something like the bass punch, the core laser, and the short-term reflections and long-term reflections.
And some of those layers have sub-layers where the content changes based on environment and distance to the listener.
And each of those sounds has a number of variations.
So if you add everything up you end up with roughly 150 unique sound files used for the E11 blaster firing.
And 20% of those roughly are based on the movie reference and based in terms of modified to fit the gameplay perspectives.
And then if you do the math, you end up with roughly 700,000 variations for firing the weapon in first person.
And that sounds maybe excessive, but.
In practice, some layers stand out more than others.
And we realized that very early on, especially when there was just one blaster and everyone fired it.
You would run into synthetic sounding repetition very fast.
And we want to avoid that at all costs because we don't want the player to think about the game as sound files being played from a hard drive or memory.
We want the player to think the sound exists in the world.
So we add a lot of parameter randomization where we modulate individual layer amplitude, pitch, and timing offsets.
And that basically keeps the weapon constantly evolving and changing and it keeps it alive and organic.
We do some filtering, so...
Even though we change content on distance, we also help it out more with filtering, where we cut low end and high shelf.
We also filter based on perspective and angle.
So perspective being first person, third person, shooting from the hip, shooting when scoped.
And angle, well, if it's shooting towards you or away from you.
And it's most dangerous, most sharp when it's shooting towards you.
We do some further randomization through peaking filters, where we randomly dip or boost certain frequencies within a defined range.
And that basically makes every instance of their weapon that exists on the map always unique in the sense that it is a subtle, but if you have 10 players shooting the same weapon at the same distance in the same environment, still each E11 will have a slight unique touch to it.
here's a video that shows you uh just firing in first person in different environments. And uh it's a demonstration of how the content basically changes based on the environment.
Right, and here's a comparison of what the E-11 sounds on different distances.
And that's different filtering and different content for each of those distances.
There's some further stuff going on.
So we help out our obstruction system in combination with our area type system, where we make assumptions based on where the player is in relation to where the sound is.
We separate the pinpoint source of the content with the reflection content.
So reflections play more surround, and the pinpoint source plays in the 3D world.
We also derive a slapback echo from the laser layer.
And that also changes based on the environment you're in.
Here's an example of a different weapon, the RT97C.
Sounds like a microphone.
And it shows you how the content changes, again, for the different environments and how the obstruction works when someone moves from outside to inside.
Or, yeah.
And now, just to show you how basically all of this applies to, uh, the two other sounds in the game, um, here's the AT-ST Walker and it, again, it is made up of multiple layers, uh, that are individually randomized and modified based on game conditions. And the vel- uh, the video shows you each layer coming in one by one and until you hear the whole thing in the end.
Right, so what did we learn?
I would say we got a pretty intuitive understanding of the Star Wars soundscape.
We know what works and what doesn't.
We found some pretty solid ways of building systems out of the movie assets.
We learned how to utilize the power of the next gen, or now current gen, PS4, Xbox One, and PC, of course.
And where we were the first game to implement Dolby Atmos, and that's actually a big topic in itself.
So I just have it as a note here, but I guess you can learn more on the internet.
And I just now realize I should have said that you should turn off your phones, but nothing happened, so never mind.
Yeah, and then that's over to Gordy.
Thank you.
Hi again, my name is Gordy Hab, I compose music for Battlefront.
And when I was thinking about what to talk about, I decided to divide my talk into two halves.
First, more generally, I wanted to speak about composing for existing franchises, not just Star Wars, because I thought this could be a good takeaway for composers in the room or sound designers alike.
And the approaches that I...
sort of derived for composing for existing franchises.
Application, in my case, for Battlefront.
And then also talk specifically about composing the music for Battlefront and some of the tasks and goals that were associated with the game and the project.
My approach and production choices I made for hopefully a successful result.
and process and results, I'll play examples as well.
So, composing for existing franchises.
Here's a quote from one of my favorite composers, probably my favorite quote.
And I use this as sort of an example and sort of extracted these two methods that I've used.
believe are ways to write within certain set parameters, and one of which I believe is the better of two approaches that at least allows for more creativity or originality.
Here is the first approach, would be sort of a paint-by-numbers method.
Meaning, using maybe specific melodies, like for instance, in my case, if I was to take the John Williams force theme and then re-harmonize it, that might be an example.
Or the reverse of that, taking the harmony from the force theme, but writing a new melody over top of it to create something new.
Or using the exact structure.
or form from a piece of music as sort of a starting point and then filling in blanks.
That's one method.
The second method, which I believe is better, is using a painter's palette.
And I'll show you, here's an example of a piece of art that we probably all know.
This is Starry Night.
And paint by numbers.
Here's sort of the structure and form of this particular painting.
And if we were just to take the structure and form and then fill in the blanks, we might end up with something like this.
Which is good. It's certainly not offensive. It's pretty. But it's not original.
And the original is always going to be perceived as the better of the two with this particular approach.
So the second approach, the one that I firmly believe in, and had adopted for my work on Battlefront, is using a similar painter's palette.
And what do I mean by that?
By this, I mean extracting the general language, idioms or isms of the music or the colors, and then adding those to my own palette, my tools to pull from.
And then just composing original music the way I know best how to compose original music.
So my own.
you know, sort of method to writing, but then just using this new palette.
So here's our painting again.
And here is an example of a painting that I feel is similar, but uses a painter's palette approach versus the paint-by-numbers approach.
So here's a Dali painting.
And another example from Pollock.
similar palette, has a similar whimsical feel to it, but is very original and creative.
Or this Kandinsky painting, which I personally love and have a copy of in my house.
So the question is, how do you develop your painter's palette?
Score study is step one.
Studying and reducing scores, and spotting patterns and reoccurring motifs, and just reoccurring sort of isms, as I like to call them.
And you can spot them visually, and it's a good way to sort of start building your palette.
The most important probably is listening.
Listen to the source material.
know how to get this out. It's right in the middle of my notes.
There we go. Sorry, there's a window in the middle of my notes. There we go. Cool. So listening to the source material, find things that you like about the source material. So some things that you're attracted to because you're going to naturally latch onto those more and probably be able to bring those to your own work better.
Collecting the, you know, isms and, you know, the patterns that you really are attracted to and then adding those to your palette as well.
and then internalizing these things. So, listening to the source, internalize it, find the things you love most, make it a part of who you are, and then just forget about all of this and write what feels most naturally. You're just using a new color palette. So, here's an example from a piece of music from Star Wars that we probably, most of us probably know. This is from the asteroid field, John Williams.
I love that.
It's so great.
Okay, so after listening to multiple examples, that example included, and then of course all of the original scores, I started to collect my colors and my idioms.
And a few examples here.
just from listening to this one example, are melodies in harmonized brass, and in particular, melodies in closed voicings at the top and spread voicings at the bottom, what I like to call a perfect voicing because it imitates the overtone series.
Strings in spread voicings or in octaves to create space or a sense of grandeur.
parallel triads over a pedal bass.
In particular, John Williams likes to write a diatonic melody, but then harmonize it top-down in triads and move that parallel over a pedal bass movement.
It's a really interesting approach that keeps the ear believing it's diatonic music, even though it becomes chromatic.
Fast moving woodwind runs to bridge transitions or to add excitement.
Woodwinds doubling brass in an octave above to kind of add a shimmer or a brightness to the sound is a very typical John Williams orchestration trick.
Fast moving tremolo lines and strings that sort of add momentum to build into new sections or add some excitement or some anticipation, if you will.
And then counterpoint, this is something that John Williams, in my opinion, is a master at.
And if I studied anything more than anything else, it was his use of counterpoint and then started to internalize that for myself.
So here's our painting again, our reference painting.
And after having gone through all of this process and adapting my own palette, here's an example of what I was able to come up with.
And as always, thanks for watching.
Thank you.
I appreciate it.
So next I'll talk a bit about specifically composing the music for Battlefront and applying the things that I learned from these methods.
So some of the tasks and goals that I had specifically for Battlefront was that the music needed to be unique and original, but it needed to feel like Star Wars.
It needed to still have that nostalgia that I think we all know so well from this music.
The music needed to serve specific functions in the game, and I'll go into more detail in a bit about those and play examples as well.
And then the music needed to live alongside of John Williams' music, musically and sonically.
And I mean this almost quite literally because in some of these examples I'll play in a bit, I'll show you how I was able to transition from existing John Williams' music seamlessly into my own music and then back into John Williams' music.
So, I also had to take into consideration certain approach and production choices to hopefully, you know, have a successful end point.
It's kind of a tall order.
So, to accomplish this goal, I adapted my process and made these particular production choices.
So, composing with a pencil and paper like John Williams would do.
I did that for every single note for this entire score I wrote by hand, which is not common even for me.
I mean, I'd like to work that way, but it's certainly a new challenge.
But I think it allowed me to sort of get in the same mindset as John Williams might have been in.
I orchestrated all the music myself, and this was a conscious choice because it allowed me to have complete control over the end result.
And rather than doing mock-ups myself, I actually reallocated my orchestration budget to hiring a full-time synthestrator to create mock-ups from my manuscript sketches.
And that's how we were able to get music approved.
His name was Sam Smythe.
He's absolutely amazing.
If you want his number, I'm happy to give it to you because he's just phenomenal.
His mock-ups are great.
production choices that were certainly important to getting a great end result. We used the London Symphony Orchestra, a full 100-piece orchestra, which was certainly amazing, and recorded at Abbey Road Studios, much like John Williams did, at least on the prequels.
We only used live instruments in the final product, so there's no hybrid elements, just keep it completely symphonic score.
recording the entire orchestra at once.
So there was no striping, we didn't do sections at a time because I believe that the sound that John Williams is so capable of getting and the sound that we all know and love so well about the Star Wars scores is a completely symphonic performance, which I personally believe you can only capture having everybody play at once.
I hired John Rod to mix and master the score, which he's somewhere, oh there he is.
This is the man.
And my reason for doing that is because he's so unbelievably gifted at creating a symphonic sound, and he really understands the orchestra and how to get that sound.
But further to that, he understands me.
And we've worked together so many times that we have a shorthand at this point, so it made my job that much easier.
So next I'll play some examples and talk a bit about some of the musical needs for the game.
One of the musical needs was to create...
planet suites, so music for each planet, and in some cases, there'd be a 10-minute-long piece of music that could then be divided into five sections to fulfill certain needs, like we needed background music, we needed an introduction for every planet, we needed low-level action music, which we called exploratory, and we needed long stretches of this, because in the original scores with John Williams, because they're written to a finite timeline, you might only have action music for 20 seconds before it goes into Princess Leia's theme and then cuts to something else.
So we needed for the game's purpose to have longer stretches of action or a specific mood.
So here's an example from Hoth.
And this also shows you how I was able to transition from John Williams' music and into my own and then back as well.
And for the composers in the room, I actually have the scores up here as well, so you can kind of follow along, and hopefully you'll be able to see it, because it's pretty small.
Here we go.
So this is John Williams.
That's where that music comes in.
you Now we're back into John Williams here.
So another music need for the planets in particular was to have background music, but background music that specifically could sort of evoke a feeling of nostalgia, but also emotion and create mood or drama.
And here's an example from the planet Sullust.
And this planet for me was probably the most fun to compose because there was no reference to Sullust in any of the films.
So John Williams never wrote music specifically for this planet.
So this is all completely original without any source material.
Thank you.
So another music need that we had in the game was because the player is able to play as their favorite heroes in the game.
So we needed to have short introductions to introduce these heroes in the game.
And in most cases, we used the original themes that John Williams had written for these characters.
And in a couple cases where there was no theme, I'd write something new.
But in all cases, even with John Williams' music, it was.
me rearranging or reorchestrating it so that it was, you know, sort of the kitchen sink arrangement.
It's, you know, as full-blown as possible and had to fit with these, you know, shorter time constraints so that it was just a quick little fanfare. So here's an example from, I think, one of everyone's favorite characters.
And also, equally important to the planet music is, I needed to write music that could function depending on which side you were playing for, whether you're rebel or imperial, light side, dark side.
And then also to write various variations on these themes.
So I wrote a new theme for the rebels, and here's an example from that.
And then one last example, and this is the theme that I wrote for the Empire.
And since we were using the original Imperial March to theme Darth Vader, we wanted to come up with something new that would be specific to Battlefront for Imperial.
So here's an example from that.
Thank you guys. Now we can open the floor up to questions if you have any.
Just before the questions, I would like to thank the staff who helped us out fix our technical nightmare we had right before the session.
Applause And we should remind you that you can do the electronic evaluation afterwards.
But now we open up for questions.
Hi David, just a question for you.
I was wondering if you could go through your, like the various layers that you have in your weapon tails.
Sounded like you have both like real time, like slap back delay, and some other verb, and then some pre-recorded tail assets, like can you go through the different categories of assets that you have?
Yes, so.
There's generic reflections, which are similar to what we would do in Battlefield for the weapons.
But since lasers are a lot smoother, I would have edited out all the snappy, clicky parts.
And then that is layered together with a slapback that's derived in engine from the laser layer.
But then on top, there's another stereo asset with a bunch of variations that's based on.
well, the core, core character of the weapon. So it's kind of like three layers of reflection tail.
And how many different sort of environmental spaces did you guys design?
We had five different general, generally five different environments that we tag everything in the game with and each has their own characters.
Cool, thank you.
Good question Jesse, thanks.
Hello, thank you for the talk.
My question is probably as big as the Dolby Atmos subject, but I wanted to know what approach you had for mixing this kind of game.
And it's actually a question both for sound design and music because in sound design, uh you have that huge dynamic range between like standing here and nobody fires at you and there is just the ambience whereas uh sometimes I guess uh there is fires and explosions all over the place. And uh for music uh orchestral music like that also has a huge dynamic range between uh super pianissimo stuff and very uh fortissimo stuff. So I guess it adds even adds complexity to the mix to use music that has already a very large dynamic range in itself.
So I wanted to know where you were approached about that.
Did you use HDR?
Anything you can share about that?
Yes, we did use the HDR, as we always do.
And for Atmos, we didn't mix specifically differently for Atmos.
Atmos inherently makes sense for games.
projecting sounds in a 3D environment and we already have positional data on all the individual sounds, so it just makes sense. And all we did was wanting to make sure that Atmos sounds the same as in stereo or surround in terms of the overall mix, but Atmos is the, it is the most dynamic, has the most dynamic range and it gives you the most air in the mix basically.
Yeah, I don't know how much you want to say about music dynamics.
Yeah, I mean, what I can say is the deliverables, what I delivered for in-game, was volume mastered so that, and literally just using volume curves to sort of even it out a bit, but not compress it in any way that would be noticeable or create any artifacts, so that at least they had a sort of a flat basis to work from so that it wouldn't compete and you could...
essentially set the level and it would play where it should play.
And then it was still stereo assets that we delivered but it was then folded out.
So in the end, the final dynamic range after automation and stuff like that of the music was about how much?
you know, like minus 10 I believe, somewhere in that range.
Yeah, I don't remember exactly, but we would also do stuff like in a multiplayer match when a piece of music comes in, like a tension stinger, we would lower certain parts of the mix to make it come in smoothly, and then over time we would...
release that type of lowering so you can get more game sounds again. But first give the music some space and then over time bring back the mix.
Thank you very much.
Thank you.
Hi. My questions are in regards to, I assume that there is a bit of an approval process through Lucas, so I was wondering if you could talk a bit about what that was like.
and how accessible their assets were to you and that kind of thing? I'm just curious.
Oh, the approval process. Well, since we started off with the original sound effects, we got that going for us, but I mean, we had to make lots and lots of new content and the approval was mostly done for the whole game. It wasn't specifically done for sound. So there were certain deliverables, certain dates where we would deliver parts of the game.
and then we would get feedback on that. And actually on sound they were pretty easy on us, like they, either they liked it or, well, yeah. I hope they liked it. I don't want to say anything else. Yeah, okay, um, yeah, they were pretty easy on us, Lucasfilm, and there were just a few notes here and there, but I guess overall they liked what we did.
Thanks.
And for the music, approval process was kind of interesting too.
Because it first, of course, had to be approved from a mockup standpoint, just a synthesized version, by Dice and EA.
But then further, it went to Lucasfilm for approvals, and then Disney, and then finally to John Williams, who was the final say on everything music.
Yeah, well, with a franchise like this, nothing is really easy.
you have very high up layers to approve the end result.
Hi, guys.
I'm Guido, game composer.
Great talk.
Following the question about feedback, I really want to focus on the composer, Gordon.
Well, I have a question that maybe it's super simple.
What did John Williams think about all this?
And was any collaborative thing between both of you?
Yeah, so.
John Williams, it made me very nervous knowing of course that this was the final approval process.
And also because I needed to be finished with the music six weeks in advance of any recording session because I needed to allow time for each level of this approval.
So there was also this thing in the back of my mind of what if he hates it and I have to rewrite this thing a week before the recording session and that would be torturous.
proud and happy to say that I didn't receive any notes. It was all just approved, which was pretty cool.
Thanks so much.
Sure.
Hi, my question is directed towards Gordy. I just wanted to say, wow, congratulations.
The music is amazing. I think a lot of people would agree with me. You totally nailed it.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
And since so much of your speech was about the influence that you had drawn from John Williams' music, I was hoping that you might be able to speak about the influence that John Williams drew, because, you know, the obvious are, you know, Gustav Holst and Stravinsky, so.
Yeah, and actually I had a whole section about that in my presentation that I ultimately pulled just for time.
That was another step in my process of sort of building my color palette, as I like to call it, of not forgetting that the source may have a source as well.
And in John Williams' case, I mean, he's certainly, you know, he's, I think he, like myself, and probably every composer in the room, and if it hasn't happened yet, it certainly will have been put in the position of writing music that is based in something else.
And I mean, with film, there's always a temp score.
And...
you know, John Williams, you can hear the temp score in a lot of cases.
I mean, this Rite of Spring, Stravinsky's Rite of Spring is certainly a temp that was used on Tatooine and in The New Hope.
And the Gustav Holst Planets movement is, you know.
pretty obvious temp as well.
And then also even like some of his colleagues, I think Jerry Goldsmith's score for Planet of the Apes was temp score as well.
And you can hear those influences.
So I also, in addition to sort of studying John Williams' scores and then listening to a lot of it, listened and studied those scores as well to kind of internalize that as well.
Cool, thank you very much.
Sure.
Hey guys, great talk.
My name's Crispin.
My question is for David.
You had all these amazing layers in your weapons.
And I've played the game, and it's phenomenal.
And you get lots of weapons on the field at the same time, lots of vehicle sounds, lots of sounds.
And I'm just wondering, what kind of voice counts were you guys getting?
And how are you managing that?
Well, we use the HDR for one, helps us out with culling sounds.
So.
what it does inherently is focus on the loudest sounds, and other sounds will not play that are already inaudible.
So that it helps us focus on just a few sounds at a time.
But we still use a lot of scoping, where we have groups like explosions have only eight at the same time.
And that means even if there's still the reflection tail fading out, that still part counts as a sound.
We have these groups for all kinds of sounds where we try to keep it as minimal as possible without being obvious that we remove sounds. And I can't really give you a voice count number. It was a while ago when we did those optimizations, but it's a lot.
Thank you.
This is a question for Gordy.
Hey man.
Gordy, as you know, I've always been a huge fan, especially of this kind of writing that you do, ever since USC.
My question, the reason I'm asking in front of everybody, is when I do score study, like when I have to fake a composer like a Zimmer, I have my sheet of his usual favorite chord progressions.
And he has just a few.
And then I notice a lot of times he just kind of starts in the middle, and it's the same progression.
Right.
I was kind of curious to see, and especially trailers are ridiculously bad like that, as far as that goes.
Did you notice a lot of repetition in the Williams stuff, or was it?
No, there's very little repetition in his harmonic language, and the way he modulates almost, in some cases, just very randomly, what I've always called sort of a plop modulation, where you're in this key, and then suddenly, boom, you just plop into a new key.
That's something pretty common.
Same with meters.
And I mean, he's switching up meters constantly.
I mean, the only patterns I recognize, and I didn't recognize patterns in the sense of like common chord progressions, but I noticed patterns and types of harmony that he used.
So.
you know, like I was speaking about using the parallel triads or, you know, either major or minor triads moving parallel over a pedal bass note, that kind of approach. Or you know, in the case of the music they wrote for A New Hope, Tatooine, there was this, the use of superimposed augmented chords and, you know, I could find patterns in how he would transition from one augmented chord to the next, but there was no necessarily rhyme or reason for the longer scope of chord progressions.
So I think he, my opinion is he thinks very much from a linear melodic standpoint first and then kind of fills in underneath.
If I was to get in his brain, that's how I believe he writes a lot of his music is sort of from line first and then that dictates where harmony goes.
Kind of like Stravinsky counterpoint where they have the pentel.
Yeah, exactly. So cool. Anyways, awesome job. Hey, thanks man. Thanks Andrew.
Hi, my question is for David. Could you please discuss how you went about worldizing sounds particularly with a lot of synthetic content?
Well, we would meld real world sounds, usually I mean, for weapons, for example, we start off with real weapons like M16 or whatever, and then modulate that until it kind of melds well with the laser content, and then to create a good distancing effect, we would use a variety of just tweaking the sound in like a DAW, like Pro Tools, until it...
just sounds right for that distance. I mean there's no real world reference. It's kinda like a gut feeling type of thing. And just using reverbs and filters and so on until it works. And yeah, basically those two things combined.
Hi, so I'm curious, I know you guys said that you recorded the symphony all together, you didn't break it up into stems, so I'm curious if you had trouble if you went between like interactive music states, you know, from general ambience into combat and Right. Yeah, I mean the way we sort of treated it was almost as though we were just pulling music from original soundtracks.
So it was not necessarily interactive states for one particular cue, but there were just multiple cues that could function as different interactive states.
For the planet Hoth, for example, I didn't just write one long action loop and then build it in layers so that you could have it interactive in that sense, but I wrote five action cues. One that was just the most intense that it could possibly be.
and then everything down to just a very base level exploratory cue as we called it.
And then we also had small bumpers or transitions so that we could pull down from one level and then fade into a different cue.
And because John Williams music, like I was saying before, this style of music, and it's not even just John Williams music, but this sort of...
old school symphonic approach, harmonically is moving all over the place all the time and rhythmically modulating and tempos changing. So it actually made it in some ways easier because almost anything goes. I mean, you really don't notice just jumping from one cue to the next because John might have done that very thing in the film and it's, you know, it's sort of established what that sound is. So it was a little easier than doing just a typical, you know, like a looping.
you know, 4-4 kind of thing that you would certainly notice if suddenly you just jumped into a new key and the tempo is faster, it would call attention to itself.
But that's not as much the case with this kind of music.
Thanks a lot for the talk guys, very good.
My question was on the score.
Obviously with the orchestration, very dense orchestration, lots of detail.
How many minutes of music did you end up writing and what kind of time frame did you have to complete it?
Because obviously it was very complicated orchestrations you were doing.
Yeah, I mean I think I ended up writing somewhere in the ballpark of 90 minutes of music.
We recorded a little more than that because we recorded a few variations of things.
And all said and done, I mean I worked on the game for, quite a while, maybe a year and a half, but I was only writing on it for about a cumulative five months maybe.
Thank you.
Well it looks like that was all and good questions and thanks for listening.
