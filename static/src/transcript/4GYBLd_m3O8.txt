Hello. My name is Daniel Kelly. I'm the associate director of the Center for Technology and Society at the Anti-Defamation League.
And today I'm going to talk to you a little bit about what online games as digital social spaces can learn from the failures of traditional social media over the last 10 years or so.
So let's dive in. A little bit about me.
These are.
My identities, that's me at Sleepaway role playing slash computer game camp in 1999.
And there's me right before COVID-19 talking about online games and making them respectful inclusive communities for all people. I don't work in the game industry, but I'm a lifelong gamer.
Shout out to Dark Sun Shattered Lands, a classic.
And again, I don't work in the game industry, but I am a game advocate and I do game advocacy at an organization called ADL and in the department of ADL called CTS. So ADL is the Anti-Defamation League, which is a nonprofit that was founded in 1913 with the mission to stop the defamation of the Jewish people and secure justice and fair treatment to all. The mission of CTS, the Center for Technology and Society, where I work, is that same mission.
but focus specifically on digital spaces. So traditionally, we've worked with social media companies like Facebook and Twitter and Google, YouTube on addressing hate on their platform and making sure that their communities are respectful and inclusive for all people and are made more so. And sort of around the time that the center was established at the end of 2017, we started thinking and working on games and specifically online games as digital social spaces and thinking about what we can take from our work with social media and apply to online games as digital social spaces.
So we all know that online games are digital social spaces. I don't need to tell that this audience that. And they have been that for years. This goes back to the games that I played when I was younger like EverQuest and Ultima Online that were social.
and even back before that.
However, in recent years, we really seen an uptick in the degree to which games are social with the huge advancements in mobile gaming with cross-play allowing people to play across different platforms.
And in 2020, Newzoo, which is a data analytics firm that tracks data in the game industry, listed as their top sort of trend for the year.
and this is a quote from them, is increasingly difficult to find someone between the ages of 12 and 30 who doesn't play games, especially in Western and Asian markets. For these younger generations, games are replacing social networks as the go-to digital destinations to meet and socialize with friends. And so I put on the slide two examples of something that's happened just in the last few months. We saw Animal Crossing be used as a space for protest. So this is a picture of a Black Lives Matter protests in Animal Crossing.
We saw PETA use it for animal rights protests.
We saw a sitting member of the U.S.
House of Representatives use it to engage with supporters and constituents.
Alexandria Ocasio-Cortez.
And on the flip side of the coin, here we have Fortnite being used as a concert venue.
So Travis Scott, through his concert.
turn this sort of battle royale shooter into a concert venue for 12 million people.
So it's a really exciting time for all different uses of online games as social spaces. But at the same time, it's at the same time that we're excited about the expansion of these spaces.
It's a time to be a little circumspect and ask hard questions.
about the expansion of online games as digital social spaces and what that will mean for those who want to use those spaces to harm others.
For example, in Animal Crossing, it's being used for political protest.
But what is, you know, it may seem like a strange question, but what is Animal Crossing's policy about political disinformation, right?
If bad actors enter into Animal Crossing and start spreading misinformation about when, for example, election day is, how does Animal Crossing deal with that?
Right? If users are organizing white supremacist events in Fortnite, what capacity does the team, does the Fortnite team have to detect that? Right? What is Fortnite's responsibility to intervene and educate young people who have started on the path to radicalization? Right? I don't think these questions are answered yet. And And these and many others, if game companies are not already thinking through and working on these questions, they will only become more urgent as time goes on.
And what we can see here, this is a survey that ADL put out in 2019.
And what we can see in the survey is that a lot of the phenomenon of digital social spaces that social media is getting a lot of flack in the press for now.
exists in really meaningful and expansive ways in online games already. So here we have, this was a survey, a nationally representative survey of hate and harassment in American adults in online games, and 74% of American adults experienced some form of harassment in online games, and 65 experienced severe harassment, which is discrimination based on identity.
You can see the breakdown of...
of which identities were targeted on the right there, as well as sustained harassment, sexual harassment, stalking and doxing. So these are really serious issues that I think it's pretty clear that, you know, Facebook and the like are getting a lot of flack for not addressing these kinds of harms, but they exist and they exist in large amounts in online games as well. Similarly, we measured the extent that extremism, disinformation, and conspiracy theories exist in online games. So, for example, we asked players, did they hear discussions about the superiority of whites and the inferiority of non-whites, which is sort of textbook white supremacist ideology. And 23 percent of American adults responded saying, yes, they had been exposed to the conversation about that. Can we, we can't really extrapolate more from a, from sort of a survey.
But in terms of like, are they recruiting?
Are they just hearing it?
Is it just being normalized in the conversation?
We can't really know from the sort of broad coverage of a survey, but it is something to be concerned about.
It's something that the game industry should take notice of that as we are seeing extremists on traditional social media, so too there may be, and we need more research and information and work.
to determine the true extent, but this is definitely an indicator that it's worth the game industry turning their attention to. So I've sort of lumped together online games and social media so far, but they are of course very, very different, right? And so how do we determine sort of where in the life cycle of the digital social space online games are versus social media?
One way we can do that is to look at their terms of use, their code of conduct. So In theory, digital social spaces are ruled by these, are governed by these sets of rules, right?
A company puts forth their terms of use of code of conduct, which a user agrees to do, you know, to abide by on their service, and it is enforced. You know, in the cases of many sort of very large platforms, it can be very hard to enforce code of conduct or community guidelines consistently and at scale.
So it depends on the platform, whether these are rules that govern the platform in theory, or are they actually the way in which the platform is governed.
But at the very least, these rules and these codes are a public expression of that company's responsibility towards their players or users and their sort of philosophical approach to the idea of content moderation.
So if we look at League of Legends in 2020, this is what's currently on their website.
we can see a wide spectrum of different kinds of behaviors sort of incorporated in one rule, right?
Offensive, harassment is included here, sexual harassment, hate speech, right?
Racially charged speech or racial racism, defamation, all sorts of different kinds of...
of hate and harassment is sort of all bundled into one rule.
And in order to sort of get a corollary kind of rule in social media, you kind of have to look back at Facebook in 2006, which where we see these rules for all different kinds of content bundled into one rule.
And if we look at Facebook in 2020, this is sort of...
an excerpt from one tier of Facebook's hate speech rules.
It is a portion of tier one of their hate speech rules, which is divided into three tiers.
And this is one form of behavior, right?
And I'm not saying that Facebook is the example here, right?
They have a lot of problems, but I think if we look between their 2006 rules, which lumped all of these things into one, And we look at 2020, we can see the degree to which they've been faced with a variety of different kinds of behavior and had to adapt their rules to address these kinds of behaviors on their service.
And we can see a similar kind of comparison. If we look at Fortnite in 2020, we have these sort of lumps of different kinds of content all put in one rule.
And again, if we look at Twitter in 2006, right, we have a very similar.
kind of lumping the rules.
And Twitter has also sort of in the past 10 years or so, 14 years or so, and made their policies and the rule more granular over time.
And so if we think about Facebook and Twitter in 2006 and where they were, right?
That was the point at which Facebook was going from being a service that was purely for college students to a more open market.
That was a point at which, you know, the press was sort of marveling at Twitter and this sort of new incarnation of microblog, right?
I don't think anyone writing or working there was thinking that 10 years from this point, one of the main discussions of the 2016 US presidential election is going to be focused on these two services, right?
Facebook in 2006 wasn't thinking 11 years from now.
we're going to be implicated in genocide in Myanmar, of the Rohingya Muslim community in Myanmar.
They just weren't seeing that.
They didn't have the benefit of hindsight.
And so that's what I'm hoping to provide a little bit here for the game industry and for online games, to look at, OK, what did social media do?
What is the hindsight lessons that can be learned from how social media has failed over the last 10 years?
that can then be adapted to online games as we move forward.
So I'm gonna divide this into three sort of big failures as we see them for social media.
One is that social media was designed for scale and engagement first without centering the safety of users, especially for vulnerable and marginalized communities.
So the motto of Facebook at its outset was move fast and break things.
One of the big quotes from Twitter, over their lifetime, I think this was from 2012, was that we are the free speech wing of the free speech party.
So these are mantras and ideologies that are centering the mass expansion of these platforms, the engagement of users, and is not really thinking about, OK, when we talk about free speech, how are we thinking about the impact of speech?
When we're talking about breaking things, are we talking about?
Are we talking about the experience of targets of harassment?
Do we feel comfortable breaking the society that we are a part of?
I don't think these sort of large questions were being asked.
So for the game industry, we would recommend that they take responsibility for the experience of players and incorporate anti hate by design principles when creating online games. So this is just a small example.
When you're designing a new game or when you're changing an existing game, think about these couple of questions. What are the speech implications of design and policy choices in your game? Whose speech will be most impacted by the choices that you're making? If you're trying to address a disruptive behavior in an online game.
Is it best addressed through changing a product?
Is there a form of community moderation, empowering users to enact the norms of the community that you can work toward?
Or is there a need for a real global policy that will state both for users and for the public that this kind of behavior or these kinds of ideologies are not welcome on our service?
And how do you go about resourcing each of those different approaches?
And third, I'll say, what kind of research would be valuable as you are building these, your game platform or changing your game? Who's doing that research? How can you connect with them? Making sure that all of your design and policy and moderation decisions are informed by research that either you are finding or that even potentially that you are initiating and conducting yourself?
So failure number two of social media is changes as crisis PR.
So we had these platforms that were built for scale and engagement.
And when we see the real world impact of these of these systems, despite calls from ADL and other organizations over the years to change, the time where we see real change on these platforms is in response to real life tragedies that cost human life.
So.
There's three examples here.
One is in Charlottesville, Virginia in 2017.
So ADL and other organizations had been telling social media companies about the threat of white supremacy for many years and asking them to take it more seriously and take more steps.
But it was only when extremists got together and rallied in August of 2017 in Charlottesville and where we saw Heather Heyer lose her life.
that we saw internet companies really take significant steps to address white supremacy on their platform and to really rethink their policies. The same was true of the Pittsburgh Tree of Life shooting in October 2018. So before that, we were telling various internet service providers that Gab is a bad actor platform that does not engage in content moderation, that does not...
care about hate speech on his platform.
And it was only after the largest anti-Semitic attack in American history that various internet service providers cut off service to Gab.
And the same is true of the Christchurch mosque shooting in Christchurch, New Zealand in March of 2019, the Muslim community in Christchurch, New Zealand was attacked and the attack was live streamed on Facebook Live.
And it was only after the murder of many Muslims in Christchurch, New Zealand, that Facebook did this and that the Global Internet Forum to Counter Terrorism enacted a cross-platform collaboration that was more expansive than previously.
In all these cases, social media, responded to these, you know, was inactive and didn't listen to the recommendations of civil society before these tragedies and used the national spotlight of these tragedies to make the real substantive change after their platform had the tragic effect that, the tragic role in each of these and many other tragedies.
So what should online games do to get ahead of this, to make sure that they're not put in the same position?
So they should be proactive, they should be ambitious, and they should be inclusive in making changes to their products.
So think about problems that may either be starting to appear on your service, or may not even be on your service, but you've seen them over the past in social media.
How does your team identify and address extremism in your online game today?
How can your team support targets of repeated and campaign harassment in your online game?
And build these capacities internally and hand in hand, reach out to civil society organizations like the ADL and others who work in this space and who have expertise on how these things manifest in digital social spaces. We're here to help. Other groups are here to help and and represent the experience of various vulnerable and marginalized communities and how they operate and the problems that they face in online games.
And so failure number three I'll talk about is that, and this may seem a little wonky, but there's no real transparency from the social media companies about the nature of hate on their platform and the success they're having in combating.
So most social media companies at this point have produced something called a transparency report, which reports on the actions the platform takes on various kinds of content in various kinds of category, whether that's hate speech or harassment or violent content. But right now, all of the data that is provided is unverified by any third party and it uses self-selected metrics. So one of the stories that I tell is there's a major internet company who was talking to us at one point and said, You know, we did XYZ and harassment is down 7%.
So 7% of what, right?
And what does 7% mean in relative to the experience of targets on your platform, relative to the scale of the problem on your platform?
How is this compared to other attempts to reduce harassment?
So these kind of metrics and the data that's driving them are fairly meaningless, to be frank.
No platform at this point can answer these three questions, which is how much hate is there on your platform, what communities are being targeted, and is anything you're doing to address hate on your platform working? Are things getting better or worse? We don't know for any social media company.
And so what we would recommend for online game companies is to create expansive, public, and meaningful metrics of the problem of hate on your platform and how you are addressing it. And this is one sort of concrete example of how you could start that.
So most games have or should have a reporting form.
Add to the reporting form an option that allows users to select which of their identities were targeted when they are reporting harassment.
Use this data.
in aggregate, right, over the course of time, to inform how you build out and change your platform based on the needs and experiences of different communities of users, and share that data with civil society and the public to say, this is our, no, this is our platform.
This is the experience of the players on our platform, and this is what we're doing to address this problem, and here's what's worked and here's what hasn't worked, right?
it's really clear that online games could really be a huge leader in this space if they provided meaningful transparency about the nature of hate in their different game environments. Right now there is no game company that I'm aware of that releases a transparency report even at the level of social media. I think in doing so and in following these kinds of guidelines and other support by civil society and others, the game industry could really lead.
So in summary, be transparent, make your transparency reporting expansive, public and meaningful, prioritize real change and don't get caught in a cycle of crisis PR, be proactive, be ambitious in what you're trying to.
achieve in terms of changing and incorporating into the design of your platform, and include the perspectives of researchers and civil society. And then design for safety and inclusion first.
Take responsibility for what your players are experiencing in your game and seek advice on how design and policy choices that you're making, excuse me, design and policy choices that you're making are going to impact.
your players and especially those from vulnerable and marginalized communities.
So I talked a lot about how online games and social media are the same, but there are of course unique opportunities and challenges for online games in and of themselves separate from social media. So one of those is audio content moderation. Of course audio content moderation is not unique to online games.
but it is a large and prominent part of how people communicate in online games.
And currently there aren't really, so there are a lot of tools and techniques that are used for text chat moderation.
That's moderating comments in a text chat like you would have on Facebook or you would have on a chat box in an online game.
The tools and techniques to do that exist.
In audio content moderation, they're virtually non-existent at this point.
and so there is a lot of work that the industry needs to do to address that.
We know as a fact that spaces which are not moderated end up becoming, the disruptive behaviors in them end up becoming the norm.
And we really want to, you know, if the goal is to make online games respective and inclusive communities for all people, then the industry, researchers, all of society really needs to step up and invest more in audio content moderation.
In another vein, pro streamers and e-sports players are public figures with huge reach and are used primarily for marketing at this point, but can really have an influence in terms of setting norms for the community.
I know many great groups have done a lot of work on this, especially the good folks at Annie Key.
I think there's a lot of room for thinking through how do we reach and influence pro streamers and eSports players to help make online games respectful and inclusive for all people.
So, in summary, I guess I'll say, or rather in closing, I'll say two things.
So, why action to address hate in games and to learn from the past 10 years of social media is necessary?
There are two factors.
So the reason that we do this work, there's a lot of sort of knee jerk reactions to games and wanting to blame games for the ills of all society.
But I know, you know, from personal experience, I grew up as a gamer.
I know that games can be powerful and good.
And one of the ways in which we framed the survey from last year was to look at hate and harassment, but to also look at positive social experiences.
So.
88% of players experience some form of positive social interaction in online games, which include making friends, finding community, even finding a partner, or learning about themselves or others, right?
The reason why we fight hate in games and try to make them respectful and inclusive for all people is not because games are terrible and games are toxic, because games are great and we want them to be accessible and...
We want them to be places where people of all kinds, where people can have these positive social experiences and not feel harassed out of them or silenced. And it's super important for, as games become larger and larger part of our social fabric, that we move to create better spaces for all people. And the other, the less good side that I'll sort of close with is that The last 10 years, we've seen social media build up platforms focusing on safety second, engagement and scale first.
We've seen them disregard the requests of civil society and use change only as a matter of public pressure or when tragedy and the loss of life implicated their platforms.
And third, we are totally in the dark about...
the nature of their platforms and whether anything is getting better.
And so when lawmakers hear those three things, they question the ability of social media companies to govern themselves, right?
We've seen legislation passed in Europe.
We've seen, you know, we have a hearing coming up at the end of July here where tech CEOs are gonna be brought in front of Congress.
I don't think the online games or the game industry is there.
I think if we you know if the game industry doesn't learn from the past 10 years of social media, then I think we will get there and it's and I think neither us nor the game industry nor game players want to see.
game the game industry occupying the kind of space in the mind of legislators and and others that we are seeing right now so.
We want, we think games are good.
We want that goodness for all people.
And there is a real threat which social media is experiencing now of control of your platforms being taken away by government who thinks that you're having a deleterious impact on society.
So I'll end there and say, thank you very much.
My contact information is there.
And I look forward to continuing the conversation with many of you.
and making sure that online games are respectful and inclusive spaces for all people and that we continue to work together to fight hate in games and learn from the failures of social media.
Thank you.
