Hello everyone. Welcome to Rick and Morty Virtual Rickality.
And please silence your phones for the VR lessons learned with Alchemy Labs.
My name is Alex Schwartz, and I'm the Chief Executive Owl of Alchemy Labs.
And I'm Devin Reimer, Chief Technology Owl at Alchemy Labs.
So a lot of people know us from Job Simulator.
It was our first really big VR game.
After that, we worked on a game called Rick and Morty, Virtual Reality, that we'll be talking about today.
And we launched that on the Oculus and the Vive.
And on April 10, it's coming to PlayStation VR, thanks to Adult Swim and Other Ocean.
Right now, we're working on a game called Vacation Simulator, which we're showing off on the show floor at GDC for the first time this week.
And let's jump into things.
All right, so we're going to go through the origin story of how Rick and Morty Virtual Ricality got made.
First, a disclaimer.
This presentation has swearing.
It has spoilers for the game.
So just a heads up.
All right, let's begin.
So the origin of how this game actually began was that Chet from Valve ended up giving Justin Roiland, who is the co-creator of Rick and Morty, and also the voice of Rick and of Morty, one of the early Vive dev kits.
And so, again, we had been fans of the show and we were just sitting around, working on our game, Job Simulator, and he starts tweeting, oh my god, who are these Job Simulator developers?
I love them, oh my god, they're geniuses.
And so you see the creator of one of your favorite shows talking on Twitter about this.
And so we had to respond, and we're like, oh my god, we want to show you the latest levels we're working on.
And it's, I think, only about a week later, we happened to be in L.A., so we went to.
his home and we had some beers and Indian food and we showed him the game and it kind of led one one thing led to another our plan was actually to say hey Justin I think it would actually be fun to combine the worlds like what if Rick and Morty's like what if Rick's garage and Job Simulator's uh you know hand-based interaction what if they were together somehow so we have a couple clips of him seeing Job Simulator's new level for the first time and I'll play that for you now.
Oh my god, what the fuck?
Holy shit.
Oh shit!
Oh my god.
You guys, shut up!
Heheheheh Oh, it's like fucking Flappy Bird Hahahaha Like, the same kind of shit in Rick's garage, just like you guys had.
Hehehehe Are you fucking kidding me?
Heheheh So, uh, I guess he liked it, and uh...
He kind of was saying the pitch back to us before we really had a chance to mention that that would be a good idea to work together.
It was just so natural.
And a week later, we're actually in Atlanta at the Williams Street offices pitching Adult Swim on the idea of some kind of combined game.
And the rest is history.
We were going to build the game and have it funded.
So just to kind of show you some reference for what is the game, what does it look like, we've got a shortened version of the trailer which queue up now.
What is this, Rick? It looks like some sort of crazy video game about us or something.
It's not just a video game, Morty. It's a virtual reality game.
I sold our likenesses to some video game publisher for a lot of money, Morty.
I mean, who's gonna play this?
You're gonna play this, Morty.
Ha ha! Wubba lubba dub dub!
What? Oh my God! You killed it! I mean me!
VR for everyone! Everyone with the box on their face morning!
It's raining money here in VR land! It's raining money!
Ha ha! Wubba lubba dub dub!
All right, so how did we get here?
We had been working on something we called Alchemy VR.
It was our internal framework for developing VR games with rich interactivity.
And this is what we started work on right at the start of Job Simulator.
And so we got through Job Simulator and started work on Rick and Morty, and we knew we had this framework.
And we're like, okay, this will do the trick.
Turned out that there was a lot more features that we needed to add for Rick and Morty, and we ended up having to refactor and rewrite the entire thing.
But at least it acted as our base to start work on the project.
So, as Alex mentioned, we knew it needed to be focused on Rick's Garage.
Like, Rick's Garage was such a cool place to be, and it was so iconic.
But in Job Simulator, we ended up building all the environments around one play space.
So, like, when you go to the kitchen in Job Simulator, the environment is built right around that play space.
That's the only place you go.
But everyone knows what Rick's Garage looks like, and it wouldn't make sense to shrink it down to the size of a phone booth.
So, how are we going to handle that?
Because this was just so iconic in the IP, and we knew it needed to be bigger than one room scale size.
So we knew we needed some locomotion solution.
So for people that have seen our talks before, we're not fans of bad artificial locomotion.
Comfort and accessibility are just too important for us.
We never want to make anybody sick.
So one method that a lot of people use for teleportation right now in VR is something that we refer to as granular teleportation.
You physically point to a specific spot on the ground and then you teleport there.
It's very easy to drop into existing content and make work.
But it does have some limitations.
Because you can teleport anywhere, what we find is people stop physically moving in the real world space.
They end up locking their legs and just like pop, pop, pop, pop, pop around the environment, which ends up leading to more fatigue.
The human body is not used to standing very still.
The body wants to rock around and makes the legs end up feeling a lot less stress.
It ends up also being, in our experience, a lot less fun to actually not physically move around.
So we needed to kind of think about how to address this.
Another problem is you can get yourself into really bad situations.
So just because you can see an object that you can interact with doesn't mean that you can actually interact with it.
It could be just through your wall.
And you can end up creating really bad situations for yourself.
If you end up drifting over time, you can end up getting right up against the object you want to interact with.
not being able to reach it because it's a real-world physical wall, and having to take a step back and then teleport forward to then engage with the item.
And that's not very intuitive for people.
So the system that we ended up coming up for this is something we refer to as zone-based teleportation.
So you look in the direction that you want to go in a zone, and then you hit a button and then you teleport there.
This is incredibly easy for new users to learn, and it encourages movement because it's zone-based.
So every space is designed around your play space.
It means that you'll end up being able to move around left and right while also having a teleportation mechanic.
It means that each one of these zones is like its own discrete room.
In the IP here, I don't know if there's a little animation here.
Nope, nope.
It animates on the screen.
Gotcha. So there's a little teleporter thing above the head of the character, and it de-atomizes you and moves you to the next thing.
So it grounds the teleportation mechanic right inside the game.
And it's gaze-based, which a lot of people don't even notice.
They are just used to pointing their hands.
But generally when you're just pointing your hands, you're also looking in that direction.
So that works for us.
Yeah. Yeah, there you go.
So you mentioned you know 3 room scale spaces and so we're going to see here in this video that.
Each of those spaces is actually redesigned based on the amount of space available in your actual room so we hand layout just like we did in job simulator each of those separate room scale areas so that you could have for example.
a small version of that corner where the work desk is, and then a medium version, and then a large version, and then versions that are catered specifically toward forward-facing, 180-degree tracking setups.
So based on the platform and how big your room is, we end up scaling each room separately.
And so I'm going to take a top view of what the garage looks like in general.
And there's something, I think, if you're a big, big fan of the show, you might have noticed when you're looking at it from the top.
Essentially we flipped one part of the room, so I'm going to show you which part.
On the actual show, there's a shelf in what you would see on this image in the bottom left corner, and we moved it to the top left, so just that one mirroring element.
And the reason for that is that if you kind of bring up a couple arrows to show you, if you're on a forward facing tracking setup where that green arrow facing up is toward the cameras, then that means that you have good tracking forward, you have good tracking to the side.
good tracking to the other side, but your hands will lose tracking if you put them behind you.
So with this one small change, that means that each of the three zones that we move between has all of the active, interactable areas, either to the front or to the sides, just from that one shelf move.
And thankfully, this IP, because it's Rick and Morty, it's completely crazy and over the top, we're able to have a little creative liberty with the IP.
And so we actually moved the shelf from the bottom to the top.
We added some scrape marks right next to where the shelf is, so that anyone who's like.
super detail and looking at it and wondering what's going on.
They see the scrapes and then actually when the game opens up, Rick says something like, I had to move the whole garage around just to make this work.
And so we just kind of throw that line in there just to be funny.
And you know, the IP is really great for that.
Now that we have this concept of zone-based teleportation, we have this problem where you could be standing at any place at any time, and you don't have control over where you're going to go granularly, so you could end up inside of a piece of geometry.
So the way that we end up treating that is we go in from a top-down view, and we go and kind of box out what are the areas in which we don't want you to stand, otherwise you'd be inside a piece of geometry.
So you can see in this layout here, we have these three sets of boxes, one in the front, and the front and the right, and then on the right.
and we go and overlay them.
And so when you overlay them, you end up building this little bit of a map.
And so the green area represents a safe area that we know that if the player is standing there, they'll never be able to teleport into a piece of geometry.
So what we end up doing is just encouraging people through our game design mechanics and through the layout of the room to end up standing in those zones.
And it ends up working out pretty good. People don't think about, oh, am I going to be standing in the wrong location? It just kind of works.
So.
This zone-based teleportation was kind of our next step at how to build bigger worlds.
But it still was really limiting inside Rick and Morty.
In Vacation Simulator, we're taking it to the next step.
And we're really excited to talk about some of the innovations we're making there at a little bit later date.
So of course, we have to talk about portals.
So in the show, it is one of the most iconic things that happens in the IP.
It would be crazy to omit that from the VR game, and it would be so awesome, we're thinking, like as we're getting into the design, to walk through in room scale, through a portal and go into a new world.
So clearly we had to do it, and we needed to figure out how we're gonna pull it off in VR.
So when we started working with Adult Swim, they handed us a big multi-hundred page IP Bible that had all the details of what the characters look like and what they do and how portals work.
And we noticed that there was a bit of data that said that Portals need to be shot onto a flat surface.
And so our thought was, well, I guess you could put a portal on one of the exterior walls or at the edge of your play space.
But imagine you're in a room.
You've got a portal right at the edge of your play space.
You're going to jump through the portal and smack right into a wall or hit a TV or something.
So we need the portal to somehow be not at the edge of your play space, but on a flat surface.
And how are we going to do that?
So I've got this video here.
This is going to show.
a lot of things all at once, but I'll let you watch it once and then we'll kind of tear it apart.
So the player is standing at the quadrant in the top left of the garage and they pull a lever with their right hand, thus ensuring that they're standing in a specific spot when the portal wall comes up and opens. Now notice that there's two spots on the ground, one that's kind of one third of the way to the left and two thirds of the way to the left, so when you go through a portal You're going through your local space, you have the majority of your space and you walk into a smaller slice of this new room.
And then the wall closes and a new wall at the opposite two-thirds opens up behind you, thus preventing you from clipping through one pixel too much and then going back through the same portal.
There's all these weird issues that you would end up preventing by moving the two walls.
And there's a number of other like things.
So when the wall comes up, notice it's hard to see from this angle, it comes up as a small...
pillar and then opens up wide. We noticed that if we brought up a massive wall up in front of your face all at once it could be intimidating or scary or surprising so that animation is actually very specific and there's probably a bunch of other notes there. Do you have any more? Yeah it's it was a very tricky thing to design. We were like for example you'll see here that something needs to shoot the portal and we actually have a portal gun taped up, duct-taped up on the ceiling that shoots this beam and so we kind of had to think of everything because this universe people care so much about how it works.
So that was the game design part of portals.
Now we've got to think about how to actually implement them in the engine.
So the first challenge was visual, like how are we going to get this to work?
So the first thing we tried was render textures.
That seemed like the obvious thing to do.
But as you ended up walking closer to a render texture, obviously the quality is going to go down unless you end up making the render texture quite large.
Also, we ended up having problems where you need to be able to seamlessly go through this portal.
And using render textures ended up causing problems like shadow popping and then quality mismatches as you ended up stepping through.
And we wanted it to be seamless.
So the new method that we ended up using was we ended up using multiple cameras and depth masks.
So what we ended up doing is we rendered the local world, then the local skybox, then the remote world, then the remote skybox, and then used clipping to handle the crossovers in between.
So that's all well and good except for unlike traditional, most traditional games with portals, you have interaction with your hands and everything's a physics object.
So clearly you're going to want to throw things and move things in and out through the portal.
And our portals only count as I've stepped through it once your head goes through.
So just because your hand is through, that means your hand can be in a completely different dimension than on the other side of that.
So what we ended up having to do is a lot of work to do things like try to maintain velocity through the worlds here.
As you can see here, you're currently standing in space in this scene, and it has no gravity in space, but when it ends up entering through the portal, then gravity returns.
We ended up having to do a lot of tricks, like for example, when you end up reaching your hand through the portal, we actually duplicate that object and make it exist in the other world, so it can end up being seamlessly popping back and forth.
VR is really challenging from a rendering standpoint, and rendering two worlds simultaneously is incredibly challenging.
So we ended up having to do a lot of perf tricks.
And so it's a little bit hard to see here, but one of the perf tricks we ended up doing was turning off the lighting of the world that you weren't looking at at that moment when we knew it was completely occluded.
So you see, for example, here, it's just like, you know, popping back and forth.
Some other things we ended up doing was caching the shadows in the world that you weren't looking at the most.
So let's say you start looking at the portal.
Local shadows are totally real time.
But across in the other world, they're currently cached from the last time that they end up doing an update.
But then when the portal comes into view and it actually opens up, your local world shadows get cached, and then the other side becomes real time.
And there was a lot of things like this that allowed us to get to performance.
We knew we wanted this bathroom, so it was a really good gag in our game.
And bathrooms without a mirror would be lacking.
And having an avatar of the character seeing yourself in the mirror would be cool.
So we started work on mirrors, and we realized that mirrors had a lot of similarity with our portal stuff.
So we started integrating that.
But we ended up running into this rabbit hole with perf, because now that we have this mirror and this portal, you could end up looking in the mirror through the portal into the other world.
And you're doing all this rendering.
So the trick we ended up doing there was aligning things such that when you end up focusing on the portal, we turn the mirror off.
And as you end up turning away from the portal, we close the portal.
And then the mirror comes into view.
And people don't even notice this is happening.
So another design element to kind of talk through the challenges and the inspiration for it.
was the death world.
So in the game, the player can die at any time, and they could be standing in any location at the time of death, and we wanted to really avoid the, you know, if we didn't really think about it too much, it could be extremely punishing to die in VR.
It could be kind of terrifying.
There's a feeling of a loss of control, and so we wanted something that could feel comfortable or as comfortable as possible to allow for this type of mechanic of, going back and coming back into the game and kind of restarting from where you were.
So a quick video of one of the many ways that you can die in Rick and Morty Virtual Reality.
We've got a glass bottle that you throw into this pit.
And shrapnel comes up and it smashes you in the face and you die.
So you can see there what happened is the player got brought into this new world.
And so that is the death world.
And so it's an instant cut.
from the area that you're in into this brand new space.
So the first thing we did is we have a very specific color scheme and lighting.
And it's kind of a sparse environment so that generally you're in a world that's bright and colorful.
And then most of the pixels on your screen go to black or red.
And so it's a pretty instant understanding of that.
And the other thing is, again, you could be at any part of your room scale space.
And in this world, what if you're interpenetrating some object or we don't know where you are?
So the world is just a mostly empty space with a spotlight and a small phone on top of a small pillar.
And so the position and size of that pillar was actually really important.
We ended up tweaking it quite a bit.
And so it's small enough that you don't feel trapped inside of it if you happen to be standing right in the middle of the world right at the time that you died.
That if you look down, you see the phone and you just kind of step back about an inch or two and then you're there.
The button, so you pick up the phone, and there's this kind of joke that the devil's secretary has, you know, you died too soon, and the devil's not here, and the devil's secretary, we're going to bring you back and respawn you into the world.
But you could listen to these jokes that come through the telephone, or you could re-engage at any time if you feel sick of listening to that.
So you hit the button.
And all of this is taught in the first few minutes, but the key is that.
What we're trying to do is to recenter you back into the middle of your room scale space so that when you go back into the game, we know exactly where you're starting at.
And making sure that you're not, again, coming into and interpenetrating a piece of geometry.
So the task of how do you move the player right into the middle of the world and get them back in?
this whole IP and this whole joke and all the phone, that was all just to get the player position to the right spot.
And additionally to that, a lot of times when you die, like in that example, it's funny, right?
And that's really funny.
And we don't want people to be like, ha ha, that's funny, and all of a sudden to cut to like VO as the game restarts or anything like that.
And this gives the user a moment to decide when they want to reengage the content, which is really important to us.
So when we started thinking about this game, we started working through the who you were playing in VR.
In Job Simulator, you're playing you, you, the human, right?
But in Rick and Morty, we weren't quite sure who you'd be. Would you be Rick? Would you be Morty?
We knew this didn't really work really well because we'd love to see Rick and Morty, you know, communicate amongst one another.
So we knew we needed some other character.
The concept we came up here was Clone Morty.
So Clone Morty worked really well because Clone Morty was a silent protagonist, which you are in VR.
And then we could turn some of the limitations in VR into jokes about how, you know, wasn't capable of doing this stuff.
And it made a lot more, a lot of sense because as a player you didn't know anything about this world that you were coming into and all Rick's instructions and stuff like that.
And then Rick makes jokes like you're just being a floating head and hands and stuff like that.
which really lands really well.
Plus you're disposable as a clone, so you can keep dying and respawning over and over, and it just kind of fits with that.
Yeah, and then Morty can also make fun of you because you're somehow a character that's lesser than Morty in the universe.
One of the cool things that ended up coming out of this was that now that we have this avatar, you can do things like look in the mirror. And for a lot of people, this was really cool. And we saw a lot of videos of this. We ended up putting things like, I don't know, like a bar of soap here, there's a toothbrush. And people would just go and like groom themselves in the mirror, even though we have nothing that actually requires you to do that in the game. And it's something that we're thinking a lot more about in our future content. And we're diving a lot deeper into avatars and how they actually impact even single player games.
So as for getting the actual characters of Rick and Morty into the game, this was a massive challenge.
So as you know, the cartoon is a 2D cartoon.
And aside from a couple plush dolls that, you know, Adult Swim end up creating, there was never a 3D representation of what does Rick look like in three dimensions?
What does Morty look like?
So this was really the first time that we were making, that anyone was making a 3D version of the characters.
We got our IP Bible and the reference designs of what they look like in 2D.
but that doesn't necessarily translate directly to 3D.
So getting these characters who are going to look at you, stand in front of you, be at full height, animating and talking and staring at you, and not make that feel completely creepy or completely insane was a really big challenge.
So one of the things is we wanted the characters to feel present in the space and kind of be aware of where you are versus just going on long diatribes and saying things with you being like a.
invisible camera inside the world.
So one of the things we did is we have a head look and eye targeting system where no matter your height or where you are in the room, characters at times that they're supposed to be looking at you, they will follow your position.
We also implemented dynamic pointing.
And so dynamic pointing was an interesting thing that early on in the demo, we had a part that said, Rick was saying, Clone Morty, grab this thing on the shelf.
And.
He wasn't pointing originally, and no one knew where to go.
And just from the voice of like, grab the thing on the shelf, there's shelves everywhere.
And so once we added the pointing, it really helped direct the player to exactly where you need to go.
It's a very natural human way to point things out.
But because our worlds are built dynamically, and based on whether you're on the small size, or the medium size, or the big size, or the 180 size, the position to where the character needs to point changes slightly because we're rearranging items.
So we needed to have the point animation be dynamic.
And so all of that ended up helping player understanding and made it a much more dynamic and interesting system.
The other thing that we implemented was everyone went into the game.
And then the first thing that happened as the characters started talking, I would say maybe 50% of people would try to slap Morty in the face or push on Rick.
And it was just such a natural thing.
You're in this cartoon.
You're in a cartoony world.
You just want to do something crazy.
And we.
We give in to all of the other crazy player fantasies of throwing things at characters.
But having the characters do some kind of reaction was, I think, necessary.
Because when you put your hand and you just float right through the character and it doesn't do anything, it's very disappointing.
So we implemented a system of using a tech called Puppet Master, which ends up using dynamic colliders to follow along with a rigged system.
And it uses spring joints and targeting to make sure that the character can.
kind of be pushed out of the way and then return back to a structure, and then you'd blend between canned animations and the dynamic ragdoll.
So we customized this, and then the thing is it had a ton of perf overhead, and it really slowed down the game, and so there's a lot of optimizations late stage.
But also when we switched from the animations to adding Puppet Master, a ton of physics bugs emerged in the game because, again, the character could clip with things and then they start...
In here, there's a video of Rick getting caught on a barrier in the middle of his animation and getting stuck.
And I think, as far as a post-mortem of this tech goes, we feel like we didn't quite go far enough.
Because yes, you can interact with the character and just slap Morty in the face.
But I think you have to go one step further, which is to have Morty contextually respond to that kind of interaction and be interrupted in the middle of a sentence and go, hey, you know, we just didn't quite have the time to be able to make it a fully featured.
So it kind of feels like a lingering half implementation.
The other thing that a ton of people ask us about is, you know, how did the voiceover process work?
Because in Rick and Morty, the humor through VO is one of the most important and iconic things.
So, as I mentioned, Justin Roiland does both Rick and Morty in the show.
And so what we needed to do was we were actually at Alchemy writing the story, writing the lines.
and then we would do temporary recordings of impressions of how Justin would voice the character.
So we're doing impressions of Rick and Morty, putting them in the project, play testing with our lines, and then we would send the builds over to Justin.
He would get to play, feel out what was going on, and then re-record the lines over what we had recorded, send it back, we'd implement Justin's lines, and then we would again play test to see if anything that he changed ended up changing how gameplay worked.
So I'm gonna show you the.
kind of uh evolution with two audiophiles so the first one i'm going to play is going to be Andrew Ike the producer on Rick and Morty at Alchemy doing a line that we recorded in-house.
Come on Morty you must have done a shit job when you tried to fix the car we broke down and we need you to help us get out of this mess open up the portal wall so we can bring you here sent that to Justin and then he re-recorded it as, Hey Clone Morty, you useless piece of garbage.
You must have done a real shit job when you tried to upgrade the car.
We broke down and we need your help to get us out of this mess.
Open up the portal wall to the new location so we can bring you here.
So you might notice that Justin's line got a lot longer in time because I think one of the things is his iconic stuttering and pausing and the added humor and improv on it.
is super, super funny, but it also lengthens those times.
And we found that when you're standing there listening to voiceover, it depends on whether you engaged with that voiceover or whether it's coming at you and you didn't ask for it, that there's a certain timeout where you start to zone out, you just don't want to be yelled at and talked to for a long period of time in VR, and so we actually go through the intricacies of kind of the writing process, but also like the, The lengthy voiceover fatigue and how we end up.
Chewing up voiceovers on demand based on player action to make it feel more like you're engaged in what's going on and all the environmental storytelling in a another GDC talk that we gave that's on the vault called spatial storytelling lessons from job sim and Rick and Morty. So check that out if you're interested in learning more there.
So let's dive into some game design stuff.
Job Simulator had a premise that was really solid, but it didn't have a full linear story or anything like that.
We knew Rick and Morty needed to be different.
Rick and Morty needed to feel like an episode of the show, which means that it needed to have this through line, this narrative that drove you through.
We decided to use puzzles and different kinds of experiences as a gating mechanism through this world.
So to jump into some case studies, one of the early things we started working on was how to get Meseeks in the game.
Meseeks are my favorite character in the show, and I know there are a lot of other people's favorite characters.
One of the problems with a Meseeks, though, in VR is that you have to verbalize to a Meseeks what you want, and then the Meseeks will go and try to do it.
But you can't really talk in VR.
But you can direct.
So we need to kind of rethink what a Meseeks would be in this side of this world.
So I'll show a video here in a second.
We came up with this concept of a Useeks, something that would mirror your actions.
And so here what we're going to do is you hit this box and it spawns a ball.
And then you throw the Useeks ball and it spawns a Useeks.
And then it mirrors you one-to-one.
And this allows you to do a lot of really cool things.
For example, fetch something off the driveway and toss it back to yourself, which creates a lot of really cool gameplay.
And you can spot a whole bunch of these and do really crazy things.
But then some weird stuff came out of that. Because it's one-to-one, as you start moving closer to a U6, what ends up happening is they get closer to you, and then they start entering your personal bubble.
And it starts feeling very uncomfortable. So we need to figure out how to get rid of them.
So one of the concepts was, let's just pull off the HMD.
And see here.
And then it explodes.
So it's a really cool character in the sense that it's like a lesser version of you.
Because they kind of look the same, but you're just going to destroy them.
And then here, for example, if you end up getting too close, it just auto-explodes, which we thought would be really terrible, and it turns out it's a really cool mechanism to dispose of them.
And one thing I should mention is that we went and grabbed it.
There's another video we could show where you can go like this onto your own and pull off all the U-Seeks around you masked at the same time because they're mimicking your motion.
So one of the mechanics in the game that people talk about a lot is the use of the watch.
So in the game you are able to communicate by looking down at a watch.
So the watch itself was actually prototyped as one of the earliest bits of development in the process, but then we threw it out.
We kind of felt like it was pointless, it was annoying, it was really hard to use, and at the time we were using the other hand's interaction to try to pull something out of the watch, like a version of Rick that would stand there.
It just was very strange and we said, well, there's no point in this.
And then we got to the point where we were realizing that we needed some kind of...
Audio delivery system for Rick or Morty telling you things about like OK, you have a hint that needs to be deployed or I forget where I was in the task and I need to be reminded and so we thought well OK will put a speaker on the wall and then that's where they're going to come out of. But then we once we added portals and you go through a portal into space station or satellite. You're far from the garage and now you can't hear from out of the speaker and then we realized this is about.
10 months later, we're like, what if Rick were on your body?
Oh, what if we used the watch?
And we had actually just kind of walked away from that idea and came back to it strangely.
And so, yeah, the watch is always on you.
And then once we thought, well, how do we make the watch interaction better?
We're like, why don't we just look at the watch?
And I don't know why it took us so long to just use the natural paradigm of how you would use a watch.
But once we realized, oh, yeah, you just look at it.
It became one of the most natural and usable interaction methods in the game.
And it also has this great feature where if Rick wants to call you, you buzz the haptics on the controller, and you feel that on your hand.
And then you turn your hand and look at the watch.
And then Rick comes out and says something.
So the whole thing kind of came together as like a strange accident where we fell upon it.
And the other thing is that we noticed that there was this.
feeling back in Job Simulator that we were starting to have happen in Rick and Morty.
So the issue is essentially, it's a sandbox game.
We want people to be free to kind of explore and do what they want at any time, and then on their own, re-engage with the content and say, OK, now I really want to continue with the story.
But maybe I just want to sit here and play with this computer for the next hour.
And so in Job Simulator, we had the task follow up the next task, and the next task, and the next task.
And it felt like the game was barking at you to just keep playing instead of feeling like you could explore.
And then right near the end, we added this mechanic where you pull a ticket when you're ready to do the next task.
Or in the auto mechanic, you pull a chain to do the next task.
And that made people feel like they weren't being rushed, like they could choose the time interval at which they get the next thing coming at them in the game.
And yeah, Rick and Morty had the same exact problem.
and then the watch ended up solving it.
Is that Rick kept yelling at you to do the next thing, he kept yelling at you, and people felt like, oh, this game is very intense.
And then when we finally, again, remembered that the watch, we brought it back, we added the gaze base, that ended up becoming the progression gating mechanism, because then we added these VO lines that were like, all right, when you're ready to do the next thing, call me back on the watch.
And that moment allowed people to go.
OK, I'm just going to explore and look at this stuff and blah, blah, blah.
And then I'll go, OK, now I'll engage with the next task.
So we kind of forgot that we learned that lesson in Job Simulator again and then relearned it again in the next game.
So hopefully that is a lesson for others.
And there's a video of looking at a watch.
So, for people who play the game, there's this thing called the Combinator.
It allows you to take two objects and combine them.
We refer to it as the best and worst thing that we built.
We realized we wanted this kind of crafting thing.
Rick is all about taking parts and putting them together and building stuff.
And we wanted to kind of simulate some of that inside VR.
The challenge with our game is we have a huge amount of items.
Because every single item that you look at in the game you can interact with, that means there's a ton of different permutations of different items.
The way that a lot of crafting systems handle this is that there's failure state.
Oh, I try something, it produces junk, right?
Or it produces nothing.
So we started experimenting with this.
But in VR, in particular our games, it ended up feeling really poor.
Because what would happen is people would be like, oh, I'm going to go over to that zone.
I'm going to grab that thing.
And I'm going to bring that thing back here.
I'm going to put it on the thing.
And then you've done all this effort.
And then you hit the button and it's like, eh, eh.
And it's like, ah.
And then what we found is as soon as you do that more than once, it's like, oh, OK.
I don't really care about this thing.
So we knew that that wasn't going to work.
So we kind of went and thought about this again, and then we're like, what if instead of a crafting system, what if it was a combination system that worked with every single object in the game, that you can just combine them together?
So the first thing we did after screaming was we sat down and we're like, okay, let's look at a spreadsheet of every single item in the game, we'll put them on both axes, and we'll start working through and seeing like, oh, what would this mean?
So we started laying them out, we realized that there was 30,000 first order combinations.
And that's first order combination.
That's every object plus every object.
So what we ended up doing is trying to come up with different things like, OK, that item has a property that changes this geometry in this way, or this changes the material, or this changes a property, or this creates a different object.
And then putting a hierarchy of importance of which one was essentially funnier.
But that's just first order combinations.
But then you want to take that thing and combine it with something else.
And how do we handle that?
And so here's a depth example.
Now, so let's say you take a carrot in the game, and you take something that's made of glass, and you put them together, you end up getting a glass carrot.
Now, let's say you take the glass carrot, and you go combine it with a hammer, now you have a glass carrot on a hammer.
and then you take that glass carrot on a hammer and then you put it with a U-Seeks ball.
When you throw the U-Seeks ball, the U-Seeks spawns with a glass carrot hammer for hands.
And this thing is completely emergent and it just kind of expands like that. It was really cool.
But one thing I want to show you is just kind of how daunting this was.
This is the spreadsheet that we started making, and this was all the cases that we had met and come up with something for, and the ones we hadn't.
And as you can see, it's just...
daunting uh... is and so we started going through this and being like home and maybe we're making a horrible horrible mistake here seems unmanageable uh... and so i like okay maybe we can just like automate this thing or something like that And so we're just like, OK, is this possible?
And then we got thinking, it's like, oh, Scribblenauts.
Scribblenauts is a game where you can put two things together and it can do things like that.
And it's like, they did it.
That means that we can do it.
And how do we automate this?
And then we stumbled on this tweet.
Someone personally that worked on Scribblenauts said that, hey, everybody thought that Scribblenauts was this crazy data structure AI thing.
And then it turns out we just hand-authored it.
And we're like, oh, man, I guess we're going to have to hand-author this whole thing.
So the payoff in VR with this was super rewarding though.
We ended up seeing so many let's plays of people being like, like here's a video of people like, oh, I'm just going to make all the different types of poop.
And people just love that kind of emergence that comes out of a system like this.
So another thing that clearly we had to do was to address the elephant in the room for VR, which is Roy.
Anyone who's seen the show knows that in Blips and Chits, the arcade in the show, there's a arcade cabinet called Roy, and you put on this VR headset, and you play through the entire life of a human being, and then when you die, that's the end of the game.
And so, clearly we needed to somehow address this.
And even before we announced that we were building the game, and then right at the announce with all the articles and Reddit threads and everything, It was just, Roy, Roy, Roy, why are they not, like, they're just gonna have to build Roy, this is the big thing, we have to do it.
The fans had spoken, we wanted to do it, we couldn't just, like, avoid it.
Original Pitch Doc said, Rick's Garage and Roy.
Yeah, question mark, figure it out, yeah.
So, obviously this is a scope nightmare, you can't build a game with infinite choices that you make throughout an entire human life.
But we, you know, sat down to tackle it.
So our.
So our solution to joke our way out of it, but also to address it directly, was to make Troy.
So Troy, as described by Rick when he wheels it in, he goes, this is the intergalactic rip-off version of Roy.
And so Troy, the idea was like, OK, it's like the cardboard cutout version, but you still play through the entire life of a human being.
We just, you know, the constraints led to this hilarious, like, poorly designed version of what Roy would look like.
So.
you still, you know, spawn in the very beginning and play and you're in a crib as a baby and you get to pick up a toy and whether it's like you pick up the football to be like the maybe you'll be a sports hero if you go down that path or you pick up this other item and then you know the even from we used references from the show which is like there's a football coming toward you and you're like you know you're the high school football hero are you going to make the catch are you not going to make the catch and like it will affect your entire life from that point and you'll go down and maybe get some diseases and get a Like this is just everything that happens in a whole life.
I think there were hundreds of different scenes that we ended up putting together and like millions of different ways to play through all the different combinations.
But what was funny is that we prototyped it with the cardboard cutouts so that one person could kind of like do the shoddy art.
But then that same person who was prototyping this one mini game also did every single voice of every character that was in there.
And so it didn't matter what the voice was.
It was basically just like, oh, I'm Troy.
It was just terrible.
And so the terribleness fit with the theme of the whole thing being a ripoff.
And then I guess the idea was originally, well, clearly, I'll record it with my crappy laptop mic and we'll get professional voice actors later.
But then we thought about it and we said, no, let's leave that one developer's voices in.
And that's what shipped in the final version.
The cardboard cutouts ended up getting a polish pass.
But that's essentially it.
And another fun bit about that is that the developer who ended up building that, his name is Graham, he was one of the people who we originally worked on a game called Discourse together.
And Discourse, the entire design of the game was wildly branching, narrative, decision-based choice game.
And so again, just a lucky prior example of we had some tech that we could draw on and kind of build from there.
So that was a really funny case study.
The other is that.
we had to address the concept of secondary input.
So Alchemy, we try to make games as accessible as possible.
And in Job Simulator, we got through the entire design of the game without needing an additional button to just being able to pick something up with the trigger.
So we had a menu button to exit the game.
But essentially, the idea of, once I pick up an item, do I have to press a secondary button to activate the item?
And so we had a couple things in Job Simulator that, like a fire extinguisher, once you pick it up, We actually have a button on top, and you use your other hand to push down on the fire extinguisher.
And we just kind of got our way around needing a secondary button.
But then we got to Rick and Morty Virtual Reality, and we said, ah, crap, we're going to have guns at some point in the game.
How the heck are we going to get away with not using a secondary button?
Because again, we didn't want that have to be memorized by the player to remember what button it is to both pick up and to shoot.
And it's a big complex thing where you want to use trigger, but then trigger is already mapped to picking up.
So we had two examples of this and how we solved it.
The first was we had Rick's laser gun sitting on the counter in the garage.
And when you pick it up, this happens.
Initiating reverse safety.
So it said, initiating reverse safety.
Because it's not Rick's gun.
It's not you holding Rick's gun.
Or it's not him, sorry.
And so it just starts shooting wildly.
And that was the joke on that one.
So you just kind of throw it, and you're like, oh, God.
The other was that we had an actual shootout scene with guns in the game itself.
So, the way we solved it was you go through a portal into this other world where Rick has told you he needs your help to go fix his car out on alien land.
Spoilers.
And you go through the portal and then the portal closes behind you.
Most people don't notice that at the time, but there's no way back at this point.
And so you're doing some tasks for Rick and then he says, Alright, you're uh...
The car's working now, so I'm taking off.
You're kind of stuck here.
And by the way, we did something illegal, and now all the guards are coming after you.
So good luck.
And here's some guns.
And your hands turn into hand cannons.
And so we just replace your entire hand with two blast cannons.
And you have to have this crazy epic shootout with hilarious music, which will happen right here.
So you just kind of reach down.
Your hands turn into cannons.
And you go nuts.
And so the only way out of here at this point.
is actually to die.
So it's like a little mini game about how long you could stay alive and shoot the Gromfulmites.
And so once you, again, go back to death world, you have your normal hands back, and so you could go back to the mapping of trigger equals picking up.
So we were able to skirt our way around the secondary input problem that way.
So, one fun issue that came up was floor-level interactions.
So, if you've seen some of the VR talks we've done in the past, I'm very passionate about floors and how they work.
We don't think that force grab, at least in the content that we do, like reaching out and pulling something from a distance, works really well because it teaches the wrong lessons.
Just like the granular teleportation I was describing before, people stand really still, people also stop moving with their hands and they kind of just go like this.
which is not really what we want in our games.
We want our games to be really physically engaging.
So when things fall on the floor in Rick and Morty, if you're on a tracking solution that doesn't have floor-level tracking, we need to come up with some way to handle that so you'd be able to grab those things off the floor.
So we came up with this concept of levitation.
So what ends up happening is when you move your hand over top of an item and so like showing intent that you're gonna pick It up it actually floats up to you and then it's up to you to grab it It doesn't float up into your hand automatically you still have to make that engaging grab motion So we're still teaching all the right mechanics And so here you can see we're gonna reach down and grab that can and it just floats up to you In Rick and Morty we implemented this on Oculus 180 and it's on PlayStation VR One of the piece of feedback we got with play testers was some people actually really like this system Not because it fixed their tracking problem, but because it was less fatiguing on them And it kind of makes sense right reaching things on the floor is actually quite a motion to do particularly over and over again And so it's something that we've actually went and thought a lot about and remastered and built a much more robust system that is actually the default inside of Vacation Simulator.
And we found that it just actually makes the game more fun.
One thing that we ended up encountering just after launch is some people reported that there was this blocker, this progression blocker where they couldn't high-five Rick.
And we're like, okay, I guess that's a thing that could happen.
And so we started working through this and we couldn't figure out what was going on.
What ended up happening is Alex mentioned we have these different play space sizes.
It turned out on the medium play space size, Rick's hand was positioned just outside that medium barrier.
Which means if you had a physical wall in your real world right at the edge of that, you were progression blocked because Rick's hand was six inches too far through your wall.
And so this was a thing that we missed during testing because we didn't actually have a physical wall right at the edge of our play space.
So we've ended up doing a lot of work on this from a testing standpoint and ended up adding things like for our QA side, when I put my hand outside of the play space tracking, it'll actually drop the object in my hand and disable that collider. So I couldn't high-five, I couldn't reach something that was outside my play space. And we're doing some experimentation with like haptics and other feedback so that when we're testing we know that people won't get themselves in a bad state.
When you end up having control over a world and everything is physical, people like doing what they shouldn't do, right?
And so they'll encounter something and they're like, this is the most important object in the game, and then they'll go chuck it out the window.
So we ended up having to go through and try to figure out how to get people not to block themselves.
So we have these recycling systems that bring some things back.
But a big mechanic inside Rick and Morty was this PC, where you can go over to the PC at any time and reorder a part that you've had in the past.
And so you'll never end up blocking yourself, you just go back to the computer and order yourself another one.
All right, one last fun issue was the age-old issue in video games where any door that has a doorknob looks like it's accessible and you're going to reach out and you're going to try to grab it, and then you're going to want to expect the door to open and then see the rest of the Smith household in...
be able to walk in that household and have that all modeled and fully functioning.
So anyone who's seen any of our talks before, we're very, very concerned with the idea of interaction disappointment.
If something looks like it's grabbable, you have to make it interactable.
So we just, what, remove the doorknob?
But this is like a TV show.
Everyone knows the garage.
That's a real door.
We can't just get rid of it.
So we ended up, again, joking our way out of this.
And our solution was the following.
You reach out, you pick it up, real fake doors.
So instead of a moment where you're super disappointed that the thing didn't work, you get a little joke that's based on the IP, and everyone laughs, and we move on.
So yeah, I guess a lot of people also ask us, well, how was it working with a big company like Adult Swim on a big IP like this?
It was absolutely fantastic to work with them because I think what it came down to is the entire relationship was built on trust They really trusted that we would take the IP and do justice to it because we were such big fans and because we knew our Way around VR and so there was just I think starting at that mutual level of trust made it one of the best Relationships we've had and so yeah, we just really want to thank them the whole team adults from games for kind of making something like this happen Thank you So it looks like we have about 10 minutes for questions.
So if people want to come up to the mics.
Over here.
Hello.
Thank you for the talk.
I was just wondering if you could talk about any potential UI issues that you experienced during your development, if any.
I guess I'll step back and say that UI is not a thing when we build spatial virtual reality games.
But I know the translation of like, well, UI in virtual reality, well, how do you deal with a menu?
And how do you deal with that?
So I guess our approach has always been, don't make a 2D menu because that's how it's always been.
Try to do something spatially, physically interaction-based in our game.
And then anyone who's seen some of our older talks or played Job Simulator knows that we ended up making this thing called the exit burrito.
where you get a burrito and then you eat it to exit the game.
And so that's, I guess, a great example of a menu and us ditching the whole concept of traditional UI in exchange for actual physical actions and verbs that you could do in the game.
So hopefully that answers your question.
What sizes did you use for the small, medium, large?
And how did you come to those measurements?
Okay, so, it's 2 meters. The smallest size on 360 is 2 meters by 1.75 meters. Is that correct? 1.7 meters.
And then we scale that up on that same aspect ratio to 2.5 and then 3 meters.
And then on 180 it's 2.5 and 2 meters. Those were very early days guesses, and those were based on what we ended up using in Job Simulator.
and the reason that those rolled out was early on valves like minimum play space size was set to that minimum threshold and then we just kind of scaled it up for that up to three meters and it was like oh we kind of need these different subsets.
Since then, we've kind of been thinking a little bit more about is that the actual correct answer, and how many sizes do you need, and stuff like that.
Some of our thinking right now with Vacation Simulator is maybe to bring down the max size that we have, because not a lot of people fall into that.
And so by bringing down the max and min, sorry, the maximum size and the medium size a little bit, we can end up getting more people to fall up a size.
And so we're kind of playing around with that.
But yeah, it's.
There's no magic bullet with that.
It's just that's kind of the conclusion that we've come to.
Thanks.
Yep.
And we also had some analytics in there on our earlier games, which for us, getting us some data so that we can try to adjust the numbers and see, well, hey, let's get more people in the medium and kind of simulate what that would be.
So hopefully at some point, we'll have real data that shows that that's working or not working.
Hi, thanks for the really fun talk.
So you were describing how you had this object that let you combine any two objects.
And you started mapping the interactions one on one.
And then you thought maybe you could do it the Scribblenaut style.
And then you found out that the Scribblenaut style was doing it all one to one.
So at that point, what was your process going forward?
Did you manually go through each and every interaction?
Or how did you deal with that?
There was a little bit crying and then we, the mythology there was to like take every object and be like, hey what is the most important property of this item?
It's like, oh this item is very metal and it's like maybe there'll be like a cool metal shader that we'll put on that thing.
And then we ended up just walking through all the hundreds and hundreds of objects and then seeing what works, but then finding, oh, these things, when they put these two things together, you kind of want the specific case and things like that.
For example, it's like, oh, I want to combine an apple and a banana and it makes a...
fruit bar, like a protein bar with an apple, banana, protein bar.
And so it's not just like shader things, like physically, like the bar text will change and be like those physical things.
We found that that stuff works really well and we learned that really early on in Job Simulator.
One of the earlier gags that we ended up showing there was when you made soup and you put like a bunch of items in the pot and then it turned into a can of soup and then it said like, you know, like plate, banana.
and cockroach soup, and then people were like, oh, that's so great.
And we kind of just leaned into that on some of those, and it works really well.
OK, thank you.
Yeah.
Hi, a quick question.
Did you handle variation in player height in any way throughout the experience?
So, as Alex mentioned, we have like, you know, the eyes track you and head tracks you and things like that to make sure that they're always looking in the right spot.
We go and layout our counters to as close to like, you know, the acceptable size for dealing with like a standing desk, for example.
But then we also have in both games, we have a shorter human mode in Job Simulator and then a... what is it called?
Giant Morty mode.
That was like, we flipped it, so that was funny.
Which ends up scaling the entire world, which makes the world feel a little bit different.
But if you're not nearly as tall, it might make things more accessible.
So yeah, that's kind of stuff that we've done there.
Possibly dumb question, but how does the developer who is an amateur voice actor feel now that he's famous?
So, how does Graham feel? I don't know how Graham feels. Well, I do know that Graham has like the most titles of anyone, I think, at our company.
Well, it's arguable, but he's done development, he's done programming, design, art, some audio, and now voice acting, so he's able to add one more...
line item to his credits on the game.
He came in as a 3D modeler, now he's our tech director.
So he's a jack of all trades.
Thank you.
And if there's no further questions, I will just skip through really strange bugs and images and screen captures of terrible moments during development and see if any of these inspire any further questions.
These are some of the earliest prototype videos that we salvaged from the first couple months of development.
Turns out an AI pathfinding creature in a world where you can move stuff around is really hard.
We got to experience this stuff in VR so you didn't have to.
All right, last one is this one.
That bottom middle video where the head look was stuck on you, that is one of the creepiest.
Just look at that face.
He's still looking.
Yeah.
All right.
Oh, wait.
One more.
With that many items in the game, what did you have to do to optimize the engine for unity, I guess?
I mean if you can have like a thousand different objects of different types in the game all at once, that's gotta be something, right?
Yeah, the biggest overhead we end up having from stuff like that is physics.
Physics, in Unity in particular, it's all on the main thread, and your logic's generally on the main thread, so that ends up being problematic.
What we end up doing is we optimize the game not for the top.
And so a lot of game design is like, okay, I got it just under 11 milliseconds of frame, now I'm good.
And that's not good for us.
So we need to actually pull it down quite a bit to give yourself, to give the player a lot of clearance on top of that, so they can end up doing a lot of crazy things.
And if you end up getting really, really crazy, you can crush frame rate if you really want.
But for a vast majority of players, they never encounter it.
And the people that do are like, well, clearly the game was not going to work when I did that.
Yeah.
Yeah.
Do you guys have any thoughts on scaling your predefined locomotion system to more of an open world style?
So, I mean, that's essentially what we're doing with Vacation Simulator, is to take the idea of node-based teleportation and apply it to a much larger world.
And so we've learned a ton about how you design a world from the ground up when you know that you want to make different areas that are very specifically.
connected to each other and have very specific, you know, I'm at this area to do this thing and now I'm at this area to do this thing versus the granular just I'll go anywhere and I might have to click, I might have to teleport three times to go across this long field where there's nothing, it's just sparse and empty.
So, you know, trying to keep things filled with interactivity and interesting for players and logical and visible and understandable is a really big challenge.
And I think likely when we get to the point that we're post-morteming.
Vacation simulator will probably have many many slides about all the weird stuff that we learned as we're kind of doing that now In that game, it's very hard, but very rewarding Yeah, I had a question about the spectator mode and about the design and performance challenges you guys had creating that Yeah Well, I guess I'll start with like well, how did we even come up with it?
It was we think that you know in general it's like really not amazing to just watch the unwarped eye view on a screen of someone playing in VR.
And so the thought was, well, what if we had like virtual cameras and you could grab them and move them around and point them around.
And that was in Job Simulator.
And so we brought that into Rick and Morty directly.
But now take that idea and everything he said about portal rendering and mirrors that look through mirrors into portals and then combine that with, well, let's render the whole thing again from a different spot while also driving everything that the HMD needs to see on a single graphics card.
So.
Definitely challenges.
On PC VR, there's a lot of people with a lot of high-performance rigs.
When we enable spectator mode, we inform the user, hey, this could impact frame rate, and try to put it in their hands.
But we've been doing a lot of thinking about how to bring spectator, like the spectator experience to more people on hardware that isn't quite so powerful.
But yeah, we're still doing some experimentation there.
Thank you.
And with that, thanks so much.
