Okay, yeah, this is us. I'm Stephen Jarrett, VP of Game Design.
This is Bob Woodburn, Director of Design Operations.
And I think we have the longest title, which is Implementing Pixar's Brain Trust Model at King, How It All Went Wrong, and How We May Have Finally Got It Right.
So, first give you a bit of a background about King.
You know, we're from King.
These are a bunch of our franchises and brands that you probably know of, but we're most famous for Candy Crush, obviously.
So we got a little bit of a quiz.
Candy Crush has been played, how many game rounds do you think Candy Crush has been played?
You can just shout out a number.
How many?
Two billion.
One trillion game rounds, actually.
And time spent in the game, if you added up all the time spent in the game, how long do you think it could be?
Ten years?
Over five million years.
So that is actually the time that humans and apes separated from a common ancestor.
And then we have data people that obviously come up with this all the time for us.
So wall bounces, if you added up all the wall bounces for Bubble Witch...
You've got 384,000 kilometers and that's 24 times from Earth to the Moon.
That's how much that was.
So the reason I'm talking about this is because as we all know making games is hard, and making a great game is very, very hard, and we want to make these really successful great games.
And so because of that...
We're looking at other studios' processes, that we're doing it right.
And Pixar's Brain Trust, we read Creativity Inc.
and Pixar's Brain Trust was the one that we thought, okay, we can make this work, right?
And if you don't know what the Brain Trust was, it's where this group of high-end directors, like John Lasseter and a bunch of others, Andrew Stanton, and they meet together every few months to assess the kind of movie that they're making.
It's like very open, it's like, you know, like they're very honest with each other.
And I think it started round about Toy Story and they claim that it's made them have lots of really great hits.
So we did a lot of research about it and we thought it sounded, you know, this sounds really, really great.
You know, we have a lot of very experienced, passionate people at King.
We have these amazing values at King, like care and craft, creative champions, humble and open, fast and fluid, fun and friendly.
And we thought we can make this, make this work.
So we called ourselves the Creative Champions and we had this logo which was always good and we had a mission and the mission was to help studios and we could be called up at a moment an idea is conceived and we would work from the beginning of a game all the way to the end of the game and we had this experience like a team of tech, game design, UX, UI, artists and producer.
And then, like the Brain Trust, which puts smart, passionate people in a room together and charges them with identifying and solving problems and encourages them to be candid, we had a different problem with Pixar because we had studios all over the place.
So we would visit studios regularly, and then we would do these workshops and deep dives with the teams and with the producers and the game teams.
And we would help solve these issues all together in a candid way.
And it felt great, great.
We can do this.
But trouble was brewing.
One of the biggest problems we had is the word, we felt the word champion, like creative champions, was great because it was like we're going to champion a process, right?
We're going to champion a process, champion your teams.
But a lot of studios.
A lot of our studios, English is not their first language.
And so champion kind of meant winner, right?
And they were kind of thinking, oh, who are these guys, right?
They're calling themselves the champions and they're like these experts and they're gonna come and help us.
And this was a typical team member that we used to come and visit.
They would like freak out and go, the creative champions are coming, this is a gate.
Everyone worked like crazy to get the game ready.
They have the power to shut our game down.
They are the angels of death.
We were actually called the angels of death, mainly by this guy, but other people as well.
And it was very confusing for the creative champions as well.
They didn't even know how to define success, right?
They didn't know how to set goals.
How do you set a meaningful goal when you're just going to a team and then just giving them feedback?
And how did we show that we were actually adding value to that team as well?
and why won't a team listen?
And that was like a real big problem, right?
Because you go there and you're working together with a team and you're discussing problems and you feel that you're putting this knowledge to them and stuff and then they just don't listen and they go off and do something else.
And then we were used by the boss peeps to be sent in to like, when a team was in trouble, it was always like, send in the creative champions, they're help the team release.
So we kind of went from this A-team solving problems here to help, to looking for problems and don't disappoint me, which was complete opposite.
And it was kind of like this.
And so we had this expectation that we would support, but we were actually a review team.
And so it wasn't working well at all.
So one year later, we thought, OK, this is terrible.
This is not going well.
So we thought, OK, we'll redo it.
We'll call it Creative Champions version 2.
Yes, and we still called it Creative Champions.
And we decided to, okay, we can solve some of these issues, right?
And we did it from the creative champions' point of view and not from the team's point of view.
So we had about five or six champions and then we assigned different game teams to that champion.
And we thought, okay, this is really great because, you know, like...
like Sally who's a champion, she can work with these teams and she's part of the team but she's not totally part of the team so she can review stuff and see it from different eyes and that kind of stuff.
We thought that was pretty cool.
But the team started getting design feedback from multiple places.
So a team normally gets feedback from game design and producer.
Then from this creative champion that was giving this ad hoc feedback every time they played a build or they were reading documentations and giving like ad hoc feedback or they were providing workshops and giving guidance or they attended this like scrum thing like every two weeks and give feedback.
Then you would have the studio design director that would also give feedback to the team.
And then you would have the head of studio, and they would give feedback through the studio design director and actually through the producer.
And then you have myself, the VP of game designer, who would sometimes go through head of studio, sometimes through studio design director, and then some time from assigned creative champion.
And then you had the CCO that was just like, bam, just like everywhere.
So the team was like, ah!
So it was like this broken system, right? So who does the team listen to?
a year was into this as well, and then we completely said, OK, this is not working again.
But we're super fast and fluid at King.
So as soon as we find that something isn't working, and it was the actual creative champions that actually said, this is not working.
This is a disaster.
So we decided to completely redo it again.
So first we did an analysis of what is working.
When requests actually come from the team or the studio design directors or the head of studio, that was really great because they were actually asking for information and asking for help.
So requests for workshops, so they might say we need a social workshop or we need a workshop around level design or something like that, that worked really great.
And value was seen with helping teams get to greenlight.
The champions actually did help a lot of teams, like solve a lot of problems, and actually got them through pre-production and to greenlight.
And we do these things called FQAs, which Bob will talk about later, which is where it's called a fun quality analysis, where we actually, the team come up with something for us to review, and then we review it, and that was seen great as well.
And like I said, we did actually increase quality in problematic titles.
But what was not working, is when feedback was not requested by a team, when multiple sources of feedback with conflicting guidance, and who should a team listen to, and when teams were incredibly stressed to get a visit from the champions.
So the first proposal was completely remove the creative champions process, right?
And everyone that was a creative champion just ended up working on different projects.
Stop trying to copy another studio's process and actually create something better, something that actually fit our values, something that actually felt right for King.
And Bob's going to go into that.
So at this point, we still have the same problem.
We still need to come up with a way to support games, support teams, and also to review.
So the first thing we did is decide to unpack the two into two separate things.
We'll support on one end and review on the other, but they won't be tied together.
What we did find, though, is even though that we were gonna unpack them, they were essentially some common threads that went through it.
First of all, the teams need to trust the reviewers, which wasn't happening previously.
The feedback needs to actually be good.
And the teams need to want the feedback.
So.
To take a look at the first bit, getting teams to trust it, we started with the creative champions, which was the exact opposite of being trusted, if I'm fully honest, and got rid of that.
So we needed to replace it with something, and we decided to look in the wider King community of game designers and involve everybody that we could in this process.
So we have a game design leadership team, which is some of the most fantastically talented people I've ever worked with.
They're all across the globe.
They're extremely experienced.
And we've worked really hard over the last couple of years to make sure that they're connected with each other.
And we do this by every three months, we make sure that we get everybody in the same place so they can actually spend time, talk through issues, wear stupid Viking helmets, and go for beers.
Of course, Steve helps us out as well there.
And this group of people, and not just them, but the wider community of designers at King have a fantastic amount of experience.
These are the games that we've worked on, I think these are some of the most highly performing games that have ever happened in mobile.
But if you look a bit deeper, this group of people has worked on an amazing, amazing library of titles.
Some of the things from when I was a kid, some of the top performings of the day.
So what we did is we went designer by designer through the entire company and cataloged what their experiences were.
What were they good at?
Were there strengths?
What genres they know?
Were they great at balancing or great at narrative?
And we created this list of who was great at what.
So this is, I mean, it's not particularly our process, but at the same time, what we were doing is looking at our overall operating model and how we make games.
And one of the decisions was to make a more light, but decisive governance in the production process.
And if you look in the play test stage, that's where this came in.
We called it Senior Creative Review.
And the principle behind that was to make sure that the game would be reviewed by experts when it comes to design rather than just a random association of senior management.
We'd remove the feedback from any sort of formal gate.
I don't know how many of you, probably most of you have been through some sort of gate and the amount that people are actually interested in getting feedback when you're getting a decision is usually next to nil.
Especially if you get a positive response.
I mean, when people are told yes, they don't actually go, well, why are you saying yes?
They just go, okay, great, move on.
And we want to make sure that we are leveraging this creative talent from across King.
So this is kind of a snapshot of what the average SER would look like.
It's a combination of qualitative data and qualitative feedback about the design, and also we give numerical assessments of each aspect of the game.
So we look at core gameplay, we look at envelope, social, the theme, audience fit, and then we also discuss the reviewer's overall confidence level and how well they think that game is going to proceed, excuse me, how well they think that game is actually going to do and achieve the goals that they set out.
Uh, so reviewers are given a week to go through, play through the build, read documentation, uh, they fill out a Google survey, that's how we capture the data, um, and then ultimately report back to the game.
And that worked, uh, that worked perfectly actually.
Uh, it was super, super well received by the team.
I'm just kidding, it was, we screwed that up as well.
Yeah, we made a huge amount of mistakes and had to go back to the drawing board and come up with something better.
Right from the beginning we noticed that we were getting a lot of reviews saying that, you know, I don't think this game is going to achieve its goals, and the reviewers weren't actually aware of what those goals were.
So we started putting in a kick-off meeting to make sure that the reviewers and the team was aligned.
And I think that was after the second or third one when we did.
So it was an iterative process. We did work to keep making it better.
And then ultimately what we had to do is go out and talk to all the game teams.
We held workshops with not just designers, because one of the problems we made from the beginning is we knew what management wanted and we knew what the designers were capable of reviewing, but we didn't really talk to the game design, or sorry, the game teams in detail to make sure we were doing the right thing.
So ultimately we made a huge amount of changes.
What we did is make sure that that feedback was a lot more clear.
What we were handing people was about 42 pages of random thoughts.
So we found a way to actually concisely summarize that and take the biggest takeaways that a team can go and present that back.
And we launched that this year.
As far as the support side, which is the second part of the equation, what we did is we created a really, really robust menu, I guess, of different feedback channels that are available for the side teams.
The FQA is one of the ones that Stephen mentioned earlier.
This is similar to the other process in that it's a written documentation, it's fairly formal, but there's no evaluation, it's there strictly to the support of the team.
They can ask whatever they want.
It could be a small issue like, is this feature right?
Or it could be a big one like, is this game fun?
And we provide that and put it back to the teams.
We have another one called Playdates, which is essentially designed for early stage games that are iterating quickly, and they don't really have time to wait a week, because by the time that comes in, you're basically reviewing a game that doesn't exist anymore.
So this is, we get a load of designers together, they all get on video conference.
play through a game and the team can ask questions in real time.
We also run workshops, both face-to-face and virtual.
So the face-to-face ones is when there's a serious issue with the game, we get everyone together in the same room to work through a problem.
And the virtual one is the same basic thing, we just do it over email.
So, for example, teams want suggestions on blockers that they can use in their game, we get some of the designers who have strengths in that area across King, they put together a few slides and send it through.
And we are still iterating in these.
We're coming up with new ideas all the time for the future.
I don't know why I put a robot there having a coffee with a lady.
I think it has something to do with future and coffee.
But concept coffees are something that we're working on where people can discuss these early ideas.
So ultimately, whenever we do create one of these new channels, we go back to the three kind of core principles that we look for in all of our...
our feedback channels, which is that you need to trust the reviewer, it has to be quality feedback and the feedback needs to be wanted.
As far as actually me...
That is like the ugliest slide I think I've ever done.
As far as actually measuring how this is successful, it's a little tricky because we've only been doing this about...
I guess a year and a half at this point, so a lot of the games that go through this from the beginning have not actually reached launch yet.
But one of the things we wanted to do was to make sure that our pipeline looked a little bit more healthy.
Back in summer 2016, if you look, we had a huge amount of games that were in late rounds of production, either in playtest or prototype, or sorry, prototyper.
production or play test, and very few that were in prototype or concept stage.
And when we're actually able to implement this and get people to really think about is this game going to be big?
Can we have a huge, huge bar for quality?
And by introducing these various channels that people can do, if you look a year later, it looks a lot healthier.
We get a lot more bets in the early stage, a lot more things we're working on, we're failing quicker, and we're allowing teams to actually focus on the ideas they think are really good.
That's pretty much it for my part.
Yes, so just to kind of wrap up then, is that we made a lot of mistakes trying to follow another studio's process, right?
And so we originally went from this static group of experts, kind of like the Pixar Brain Trust, and that's what the creative champions were, to this rotating panel of experts throughout all of King's senior creatives.
And that was like...
super great because like you sometimes a creative would be going through the process themselves of getting Feedback and other times they would actually be giving feedback and just opening it up to everyone Really felt like it was trusting our creative creative experts throughout the whole of King And then the other thing, it was very, very team-focused, right?
So it actually came from the teams.
So we had these support channels that Bob mentioned, with these workshops, these FQAs and these play dates.
And they run from concept, from prototype to production.
We're currently looking about how we can apply this to live games as well.
And then we have this Senior Creative Review, and it's a review system.
It wasn't being hidden like it was before through the champions.
It was like...
it's obvious a review system and the team can actually ask for this review system when they want to ask for it, which is another great thing.
So it's not forced on them. When they feel they're ready, then it goes to the SCR.
And we've been doing it like this now for about a year, but we're going to probably end up involving it again, because it is kind of flexible, but it's uniform, right?
It goes across all our studios.
So now we feel that our teams have gone from this...
to this. That's what it feels like. So, we are hiring, obviously, so if you go to king.com jobs and you want to actually come through this yourself and actually create games with us, then please go there. Thank you.
uh is there any carry over between the SDRs like do you take some of the feedback from a previous SDR and see how the game has evolved in direct uh correlation to what was given in the in a previous SDR?
Yeah, I think that happens quite often.
Normally most teams will only go through the process once, but occasionally a second time.
The feedback's usually taken over, and then teams will come up with a plan on how they're gonna mitigate those risks that are raised.
And usually if we go back and we do another one in six months, it's one of the things the reviewers will look at is how well did they execute on their plans to mitigate those risks that were flagged up.
Do you think the brain trust would have worked if we just do it purely as feedback like here's some feedback Do what you want with it I don't know, I don't think so. We tried to do it like that but it was, I think part of our problem, maybe if we were in one big studio it might have been able to work like that, but I think this whole feeling of travelling to a studio and having these people travel there was kind of really stressful for the teams.
But like I was mentioning, I think we evolved enough for us to get to this point where rather than having this brain trust of experts, we have so much expertise around King, so actually bringing them all in together felt right for our studio.
Is anybody watching the watchers?
Do you guys give feedback to the SCR panel?
That's a very good question. To an extent, yeah. I go through, I don't actually write any of the reviews, but I always go through them all, and I've had a lot of conversation with the reviewers saying that your feedback's maybe a little bit too harsh or the criticism's a little bit off. I mean, ideally, you want to have different opinions. You can't just say somebody gave a bad review to a good game. You want to have that person say that they don't believe in the project.
Sometimes you get people who are a little bit rushed and they'll write about two lines and things like that.
But we don't have like a formal system. It's more on a kind of case-by-case basis.
I think a big change that we did recently though, it used to be anonymous, right? The SCR.
And then we changed it now to, like, you can actually, you know who the reviewer is now.
And that was something that evolved as it went along.
Hi, thanks for your talk.
So my question was, maybe I lost a little bit, but I saw that you evaluate the designers on your spreadsheet.
I saw some marks.
So how are you doing this?
How you evaluate if the guy is good or the girl is good?
It wasn't an evaluation of the designers.
You know, they had the different colours and...
Yeah, yeah.
It was more...
First of all, people would self-assess.
They'd say, I'm really, really strong in RPGs or I'm weak in puzzle games.
And the design director, the studio design director who's responsible for the designers in each studio would kind of go through and calibrate that before we put it into the system.
Okay, another question. You mentioned that it's important to build trust, so the team must trust the reviewer.
Do you build that trust somehow? Is there any process for this?
Yeah, I only touched on it briefly. We don't have a huge amount of time, but we created this game design leadership group a couple of years ago.
And we meet virtually every two weeks, and then every three months, so once a quarter, we all get together face to face.
This has been something that's been going on, we've been pretty religious as far as making sure that these meetings happen, so that people get to know each other, you know each other's strengths.
And that's kind of like a first step, but through that you actually talk about games, you get to know these people, and like I said, you go out for beers and wear stupid hats.
And the other thing is, because the reviews are done by people from the game design community, you might have your team's game being reviewed one week and then the next week you're reviewing somewhere else.
So you've been through the situation both as a designer and as a reviewer.
So it gives a familiarity with the process.
Well, it really helped to stop going from this central group, right, to this global group and take a creativity direction from everyone in the different studios.
Yeah, okay, thank you.
Thanks for the talk guys, very useful.
So I had a question, if this is successful for you in the future, do you plan to expand it to other disciplines as well, and not just the game designers, to involve more of the team members?
Yes. I guess we like art, right? We're doing the uh, we're currently, it was uh, we used to have art actually evolved in the SCR as well, but now they're going to get their own one, uh, their own kind of review and uh, UX as well. UX UI is another one that we're doing too.
Hi, given the poor reception to the creative champion approach, did you have to do anything to kind of like encourage the game teams to reach out to the new group for feedback?
No, I think because we were just very honest, right?
And King's actually, it's a very flat company, a very honest company.
So we just said, this is not working to everyone.
And then we went to all the teams that have actually been working with the champions and said, what would you like to improve?
What would you like to do that?
And like Bob was saying, having this design leadership group as well, where we could all talk openly about with each other and then that to filter down through their design teams, actually, you know, it became quite easy to everyone to embrace it.
Great, thanks.
Hi, this is Joni from Rovio.
So your experts are kind of like helping teams to get through the gates and green lights.
But who are those people the same that are actually approving the green light or approving the gate or how does that work?
Yeah, sure. I think the goal of the reviews are not to help get through a gate, they're to evaluate it, and that's used as one of the data points that would be in a gate. Our chief creative officer is one of the people who's involved in that as well, and he's one who would bring the opinion of the senior creatives to that meeting. But there's all sorts of other stakeholders as well. There's people from business performance, there's tech people to say, can we actually build this game? There's someone from human resources who looks at...
Do we have the people to make this game as well?
The creative reviews is, I feel, a pretty important data point, but it's just one that we use.
Last question.
You mentioned that you're starting to roll this out to other disciplines.
Are there any significant differences giving that review between different disciplines, or is it kind of the same system?
I think there will be. We're only just starting it off now.
Aaron, who's over there, is head of art.
So we're going to be working with him and trying to figure out the best process.
One of the problems we had in the original SCR is that we could never...
We weren't showing images or anything like that because we didn't want designers to take pictures of images and stuff.
But obviously art needs to show images, right?
So we'll work with him on the process and then maybe we'll be here next year talking about...
how it felt.
Cool.
Thank you.
Thanks.
Thanks.
Thanks.
Thanks.
