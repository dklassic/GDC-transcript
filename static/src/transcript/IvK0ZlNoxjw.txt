Great, thanks Dave.
Okay, so let's get started.
So what is modular AI?
Well.
It's a way to structure your AI architecture.
It's not a specific approach.
In fact, you can take a modular approach and you can apply it to state machines, behavior trees, task networks, whatever your decision making structure is.
You can always make that more modular.
In general, it emphasizes small, easily reused modules.
And if you do a good job, if you have a nice modular architecture, it can be absolutely transformative to your development process.
It can allow you to do things like fast prototyping, rapid iteration, it's even going to increase the stability of your code base.
So, the nuts and bolts, what we're going to talk about today in this session.
First off, we're going to go through some of the academic underpinnings.
So, we're going to present some of the theory and talk about how this stuff works.
Next, Kevin's going to come up and give some real specific implementation details, code samples, and really explain what this looks like.
And finally, Troy Humphreys is going to come up and give an example from a ship game and show what this looks like in practice, along with some general architecture discussion.
So this is going to be a bit of a slow burn.
But by the time we get going, hopefully we've lit a nice fire, and you're all going to be encouraged to go out and try to make your own architectures a little more modular.
So, my name's Christopher Draggart.
I'm an AI programmer at Ubisoft Toronto.
My background, I'm actually sort of a software engineer by training, and it has a lot to say as a field about modular reuse.
This is something that people have been looking at for 20 years.
There's lots of theories, there's lots of stuff in there.
What we want to do, and in fact what I did during my own PhD research, I took a lot of those sort of basic software engineering principles, and I applied them to modular AI in particular.
What I want to do in my portion of this session is really show how these first principles can allow you to develop techniques and create a good modularization for your own project.
In fact, I'd like you to be able to think deeply about this topic so that when you're making choices about how to modularize things, you can be working right from first principles and really understand the choices that you're making.
One of the biggest things here...
is understanding modular complexity itself, right?
Where does it come from?
What becomes harder and easier when you're doing modular approaches?
And importantly, how to manage that and how to reduce it, because that's what's going to make your modularization successful.
So let's talk in general about complexity.
This sort of breaks down into two main areas.
The first is essential complexity.
So this is the problem that you're trying to solve.
This is what you're looking at.
This is what you want to do.
The other kind of complexity is accidental complexity.
These are problems created by us, right?
When we say, oh, I want to put this in a special framework and run it on another thread and do this and that.
You know, all those problems are aside from the core thing that you want to solve.
So a good solution is going to preserve that essential complexity and make it so you're just working on that and it's going to limit the growth of accidental.
So, let's make this more specific now.
Let's get to the topic at hand.
What drives modular complexity?
First big driver is the module itself.
So, the more complex your module is, the more complex your modular solution is gonna be.
The interface, what do these modules look like from the outside?
How do we work with these?
How do we understand them?
And finally, what's the process for taking these modules and piecing them together?
How complex is that?
So for the remainder of my talk, I'm going to go through each of those three areas and just talk about how complexity grows at each level and how we can manage it.
So the first area, the module.
And if there's one thing to take away from my portion, I want it to be this.
Good modules do not try to do too much.
The key to a good modular solution is to have small, concise modules.
One of the biggest reasons is that a small module allows you to more easily understand what's going on.
It has a clear purpose.
If you go to reuse it, you can be very clear in understanding this is what I'm reusing.
This is the functionality I'm getting.
So you want a good small module.
One of the big ways to accomplish this is by limiting the scope of what you try to accomplish within a module.
So, one thing you want to do is try to separate cross-cutting concerns.
So that's a term from aspect-oriented programming.
And the idea is that there might be a functionality that gets repeated.
across a whole bunch of modules, right?
So, an example, let's say we have a melee combat module that selects a target, and then our range combat module is also selecting a target, and our flee module is deciding what target it wants to flee from, right?
The answer here should be pretty clear.
We need to take out that target selection and actually put it in its own module, right?
So we need a target selection module.
So we separate those sort of functional concerns.
Target selection is its own thing.
Melee combat is its own thing that just attacks whatever target it's given.
And we make all these modules sort of work from communicating with that other target selection module.
What's great now is that when you do something like that, you can then say, you know what?
I want to reuse just the target selection module.
And you have that clean separation.
Another thing you want to do is control the size of your module.
So this is just a more general comment.
Here, we need to do the stuff that we already do as AI programmers.
So traditional abstraction techniques, everything that we should already know and love.
If you're working with a state machine, for instance, you want to use hierarchical approaches.
If you have a lot of events going through your system, you want subsumption, maybe you want layering approaches to help manage your different modules.
If you're working with behavior trees, use parallelism where appropriate.
You know, all these kind of things that we do, it becomes doubly important in modular approaches so that we can control the size.
One thing that we don't think about as much as AI programmers is a well-defined semantics.
So what do I mean by this?
Well, your AI logic should operate in an understandable and well-defined fashion.
Normally, when we program things, we can often think about, how is this piece supposed to work?
How does it fit into the rest of my AI?
We can kind of solve that problem, and it works.
But if you can't communicate that, then you're going to fall apart at the next step, which is maybe moving that module between engines or moving it to a different game.
And I'll give an example that really clarifies this.
So let's say we have a super simple state machine.
We have a combat state.
It receives a flea event.
We transition over to the flea behavior.
OK, now let's add some hierarchy.
Now, in the combat state, you can see I've added this fire sub-state, and it actually has a transition on the flee event as well.
So if we're in that flee state, or sorry, if we're in that fire state and we flee...
What do we do?
Right, your implementation is gonna make some choice.
Do I follow the inner transition or the outer one?
I'm not here to talk about the right way to do state machines.
The important thing is that when you go to reuse this, wherever you put this, we have to make the same choice, right?
Our new context, our new engine, it has to make the same choice.
So we have to communicate what are, exactly how these things work, what our semantics are.
This example also applies to custom decorator nodes and behavior trees.
If we want to reuse those, we need to make sure that they're functioned correctly in the new context.
So, moving on, I'm going to talk about the modular interface now.
What does it do?
It should communicate the context for the module, so the expectation of that module, what is it trying to get from the rest of the AI, what is it providing to the AI, we should be able to understand that from the interface.
If you've done a good job making small, concise modules, then we should have a clear, easy to understand interface.
The big step here is that we're raising the level of abstraction now.
When we have a good interface and we can work from it, we don't have to worry about how exactly that module operates anymore.
You can just work directly at that interface level, which means you can focus on the essential problem of connecting our modules and not worry about sort of all the accidental stuff of how that behavior works.
So, I've said context a lot.
What do I mean by that?
State machines, for instance, they're an event-based formalism.
I'm just going to work through this example here.
Generally, you tend to think about input events.
They might be generated by other parts of the system.
They would get consumed by our module.
They might also generate output events that would go to other parts of the system.
So then, our interface should tell us what exactly this module is expecting.
So I'm just going to build one out here.
This is for an enemy position tracker module.
We might want to include some metadata.
So a description of the module.
This module is parameterized.
I can control the type of the enemy entity that I want to track.
And that's about it.
We don't really need to worry about the functionality.
Now, as input, it's going to be looking for a couple specific events.
The first would be an enemy spotted event.
The second would be an enemy lost.
So basically, this is telling it when to start and stop tracking.
We don't really need to worry about what it's doing to sort of maintain its own list.
That functionality, it doesn't really matter.
Those events are going to come from some other part of the system, and we'll be able to use them.
Now, as output, we can then generate this enemy position changed event.
So maybe you have a cover module, for instance.
It receives this, and it decides whether or not it needs to re-evaluate cover.
So now we can see how we would take this position tracker and sort of situate it within a context.
Moving on, a second example here, behavior trees.
So these are a bit different in that they're primarily data-driven.
What we want to think about here is sort of how our nodes are communicating with the rest of the behavior tree, or the rest of your AI architecture.
Well, primarily, they're going to be reading input off the blackboard to understand the context, and they're going to be writing output to that blackboard.
So when you think about building an interface here, we want to capture that data.
But a specific warning, that's not the full story for behavior trees.
The reason is that there can be a lot of different things going on, especially in newer behavior trees, where we can have nodes that, instead of just returning success or failure, they can also run over multiple frames.
Well, the question there becomes, how do we interrupt it?
Where does that interruption come from?
In other situations, you can even have the tree structure itself, which is providing this interruption.
So somehow we have to deal with this.
I'm going to give an example.
This is something that I've seen in production code.
We have a parallel branch here.
It goes to the top there, and we get an infinitely repeating decorator.
This is just checking a conditional.
When that conditional becomes false, this branch is going to fail out, and we're going to move on to do something else.
But at the same time, we also have another infinitely repeating decorator, and it's going to be going through and performing some behavior at the bottom.
Now, say I really want that behavior at the bottom.
I want to reuse that.
I want to put it somewhere else.
So then I trim that and move it away.
Well, what's going to happen is that I'm going to introduce a huge bug into my new system because that bottom branch, it doesn't know how to stop itself.
That was happening in the top branch.
Right, so I have this sort of functionality that's now split and there's a dependence between these two branches.
If I want to get that to work correctly, I'm going to need to reuse the whole thing, right?
I need to include that stop case.
So these are the kind of things that you need to look out for when you're specifically trying to use behavior trees.
So I'm going to move on to the third and final area, which is just an overview of integration.
So this is the process that we actually use to fit these modules together.
If you've done a good job in creating concise modules, clear interfaces, then integration should be straightforward, right?
If you've made mistakes, if you have big, complicated modules, this part's going to be really hard.
So a lot of your errors are going to become apparent here.
Essentially, what we're trying to do is connect the output from one module to the input in another.
Right? It's a fairly straightforward thing.
And we should be able to focus explicitly on that.
Everything else is accidental complexity.
So you really want to try and limit anything that detracts from that core problem.
The complexity of this, we can manage it a lot by making sure that module connections are derivable solely from the interface.
So, as programmers, we need to treat this almost like an API, right?
And, in fact, the other thing this does is that this preserves modular encapsulation.
This is just like object-oriented programming now.
where we want to make sure we're working through our high level interface and we're not creating spaghetti code and digging inside.
So for all the same reasons that, you know, encapsulation is good in normal code, it's just as good in modular AI.
So if you do this consistently and if you do it well, you can start to add tool support, right?
And this can tell you things like, I have an output from one module that's not consumed anywhere.
Or I have this data that I'm trying to read off the blackboard that no one else writes.
You can start to see those errors really quickly and really easily.
And then that will teach you, okay, I need to add this module or I need to have something contributing that data.
One last thing I want to talk about here is module coupling.
The goal here, is to create loosely coupled modules.
So these are, when you have a loosely coupled system, a missing module impairs only that behavior.
What do I mean by that?
Well, if you think about our target selection example earlier where we had our Melee module, let's say we take that target selection module and we pull it out.
So there's now nothing in your AI that selects targets.
Well, I would want my Melee module just to say, oh, I don't have a target, I'm not gonna do anything.
But other functionality within that AI, so a wander behavior, interacting with environmental objects, all of that should still be able to happen, right?
If you have this approach, then you can really quickly and easily start to add modules to do fast prototyping.
You can change your composition to rapidly iterate on this.
The alternative is a tightly coupled module.
So this is where maybe one module is actually calling a function that's written in another one.
If you pull one module out, you're going to have a compilation failure.
Maybe we have our Mealy module with no target.
It still tries to run, and it crashes.
These kind of things.
You don't want that.
That's what you need to try to avoid.
Everything should be as loosely coupled as possible.
When you have problems like this, a lot of times, it's caused by broken encapsulation, or you're not working through the interface.
Or you could have a modular concern, some kind of functionality that's spread across multiple modules.
Special cases in general are really dangerous.
I'm just going to go through one straightforward example here.
Let's say we have a sensor module.
And every time our AI spots a new enemy, it creates this new enemy spotted event.
And then we have a reaction module.
And every time it receives that event, it's going to play an animation.
It's going to play some reaction.
But we actually run this and we find, oh wait, I'm seeing that reaction way, way, way too often.
I need to turn that down.
So I want to add some hysteresis.
I'm going to make my event system.
All the events are going through there.
So I'm just going to add a filter.
It's going to cap generation of these new enemy spotted events.
No more than one per minute.
So now everything looks good.
But then I go to reuse it.
And I put my sensor and my reaction module in a new context.
and that same bug is going to appear again right because I lost that filtering bit and there's no obvious way about how this should work right I don't have a filtering module I haven't created a filtered reaction or anything like that so these kind of things they're kind of dangerous a lot of times they're because of broken module encapsulation here it's a functionality that's mixed across a few things but let's say we do all this right we're going to get a nice payoff.
The first is fast prototyping, right?
We can now quickly and easily add our modules.
We can fine tune.
We can parameterize these module interfaces so that we can say this specific module and this AI is going to have this set of parameters, and this other one is going to be slightly different.
So we don't lose that ability to polish our AI.
And probably the biggest thing here is that the development process, overall, is going to be better, right?
We can reuse existing behavior.
We can get to a baseline very quickly, and that means the bulk of our development time, we can spend innovating, and we can spend creating new behaviors, so that you can really try to push the boundary of what your AI can do.
So, I'm just going to summarize.
A good modular approach, it's going to check all these boxes.
We're going to use small modules that do a nice job separating functional concerns.
We're going to operate with a well-defined semantic, so we can always understand how this thing should run.
It has a clear interface so that people can understand how to connect it.
All of our connections are going to respect modular encapsulation.
And we're going to use a loose coupling approach so that we can really quickly and easily swap modules and swap compositions.
So if you've done all that, if you've checked all those boxes, you're off to a great start.
Thank you.
All right, there we go.
So I'm Kevin Dill.
I wanted to start with a little bit of motivation from my point of view, some of what makes modular AI so exciting to me.
So as I was thinking about this talk, and I was thinking about why it works and what makes it powerful, I remembered a talk that Chris Hacker gave back in 2008 called Structure Versus Style.
And he basically made the case that a lot of problems that we have.
made great progress on have this sort of structure versus style decomposition. And graphics is one example, where you get the texture map triangle, which is your structure, and then your style is all the ways you can use textures and triangles, and you get graphics, right?
scenes and beauty and awesomeness. And as a result of this decomposition, graphics, he argues, has made huge bounding leaps over the last 30 years. And AI has not. So his suggestion was part of the reason that AI has not made these leaps is that we don't have a structure versus style decomposition for AI.
So there was a lot of discussion back and forth in the community.
Some people said Chris is on crack.
Some people said Chris is brilliant, but I don't know what the structure versus style decomposition is.
I'd like to suggest that modular AI gives us the opportunity to have the start of this sort of structure versus style decomposition.
And I think that's why it allows us to work so much quicker, and hopefully will continue to progress forward for us.
So I should also mention that everything that I talk about is going to be pulled out of ideas from the game AI architecture.
The fact that it's game AI isn't interesting to this community, but I work for a military simulation company, Lockheed Martin.
So that's an important distinction to them, as opposed to traditional, more academic kinds of AI.
This architecture has been used across probably six very different projects to solve different kinds of AI problems, right?
Character AI versus flight simulators versus other stuff.
It's been integrated into a bunch of different engines at this point.
And something important to mention is...
I set out, of course, to create an architecture I could reuse, but I never was able to just sit down and build the architecture.
Ever.
All the work that I've done on this architecture has been done in the context of working on a project.
And by just making sure that I keep my architecture decoupled from the simulation so I can carry it with me, or from the game so I can carry it with me from project to project, I've got all of this, you know, now large reusable code base that's really powerful.
So the agenda for my portion of the talk, I'm going to talk about what I think modular AI is.
Of course, Chris just gave us a bunch of that.
I'm going to talk about some common conceptual abstractions.
And you know what that means by the time I get there.
I'm going to give just a brief example of a small portion of a sniper character.
I'm going to give a few implementation details as time permits.
And then I'll leave you with some parting thoughts.
So the big idea behind modular.
behind modular architectures is that I want to be working at the right level of granularity.
I want to be using sort of bite-sized pieces. And by bite-sized, you know, Chris said, well, they can't be too big, and that's definitely true. If they're too big, then I can't tune them and customize them to the needs of the specific instance where I'm sticking them in. But they also can't be too small.
and lines of C++ code are much too small.
As I'm defining behavior, I don't want to be thinking about implementation details, about how do I get the position, or should I use distance or distance squared, that kind of stuff.
I don't want to be worried about that when I'm defining behavior.
That's just as distracting.
Each piece that I plug in should ideally be sort of a single human concept.
So something like, how far away is he?
How long have I been doing this?
Or do I have any grenades left?
But it doesn't have to be just the decision making part.
It could also be the actions.
I want to move over there.
I want to shoot at that guy.
That kind of stuff.
So to get these bite-sized pieces, we start with what I've been calling conceptual abstractions.
Conceptual abstractions are the different types of pieces that we might plug together.
So for example, a consideration is one conceptual abstraction.
Considerations evaluate some aspect of the situation, and then I combine the considerations together to get an overall decision.
Actions are a different conceptual abstraction.
Actions are the things that I'm going to do as a result of some decision that I've made.
Once I've got my conceptual abstractions, then I start to build modular components.
These are implementations of the different abstractions.
So a distance consideration measures the distance between two points and gives some evaluation of that.
A move action handles moving from one position to, or moving to some specific distant position.
Another thing just to keep in mind is, no surprise, this is data driven.
So my implementation is all the C++ side.
And then I've got a configuration, which I'll often call my behavior specification, where I'm defining the behavior for a particular character.
And I'm plugging in these modular components to create decision-making algorithms.
So running through a few common conceptual abstractions, the first one to talk about is the reasoner.
The reasoner is the big thing that makes decisions.
So it could be any decision-making architecture that you want.
It could be utility-based.
It could be rule-based.
It could be a finite state machine.
It could just be a sequence of actions that are always run in the same order, no matter, you know, no considerations are used, right, if you want some scripted behavior or something like that.
And different reasoners make sense in different places, right?
Even if I am doing fighting AI in a shooting game, I might still have some sequences where I aim, fire, aim, fire, right?
That's just a sequence.
I don't need to make any decisions in there.
So I'm going to stick in a sequence reasoner just to do that one little bit.
Considerations evaluate a single aspect of the current situation.
Again, there are lots of different kinds of considerations, right?
A distance consideration.
An execution history consideration looks at how long I've been doing something or how long since I last did it.
The picker is a particularly interesting consideration.
It goes through all of the entities that I know about, and it can apply some filters, or it can actually use a reasoner internally to pick among all of the entities.
So for instance, if I want to pick a target to shoot at, I could have a picker consideration that picks a target based on how far away it is, how much cover it has, has it been marked as an officer, because if I'm a sniper I prefer to shoot at officers, is it firing at me, is it looking at me, whatever else I want to put into that decision I put inside the picker and then the picker just handles picking the one entity and scoring based on whether it finds something or not and it also by the way writes that entity on the blackboard so that I can reuse it when I want to shoot at it or chase it or run away from it or whatever I'm going to do.
Actions are the things that I'm actually going to do once an option gets selected.
So things like moving or firing a weapon.
Again, an interesting action is the sub-reasoner action.
The sub-reasoner action contains another reasoner.
So this is how I get my hierarchy, right?
I have a high-level decision that picks, I want to shoot at enemies, and then a lower-level reasoner inside of there that handles the aim-fire aspects, perhaps.
Targets are how I specify positions or entities.
I need to use those two things all over the place, right?
A distance consideration measures the distance between two targets.
What are the targets?
Well, they could be anything, right?
It could be me, right?
The character that's under control.
It could be a named entity.
Maybe the name of the entity is player, right?
I want to measure the distance between myself and the player.
It could be a fixed position.
It could be the camera.
It could be an entity that's been written to the blackboard.
Lots of different kinds of targets can just be plugged in, not only in the distance consideration, but in the move action, or the fire action, or anywhere that I need that sort of thing.
Weight functions are a good example of the kind of cross-cutting concerns that Chris was talking about.
So in considerations, I found a lot of considerations come down to they have a floating point number, right?
A distance consideration is a number, right?
The number, the distance in meters.
execution history consideration also gives me a number. It's the amount of time since something happened. So I want a standard way to convert from a number to whatever the output of my consideration is. And I'm not going to tell you what that should be today because there's not time. But the considerations that I use return three different values.
So, the job of the weight function is to, in some standard way, convert from a floating point number or an integer, or recently I've added the ability to have entities, so you can pass an entity into a weight function and it returns an evaluation on the basis of that, to the output of the...
consideration. So the Boolean weight function, for instance, just says, it treats it as a Boolean, right? So, for instance, that picker is going to return the number of entities that it finds. Typically, it uses a Boolean weight function, which says if I find zero entities, then return this set of weight values, and if I find one or more entities, then use this other set of weight values, right? Did I find it or not?
The distance consideration could use something like a float sequence, for instance, if I want to say, do one set of things if the distance is between 0 and 50, another if it's between 50 and 100, and a third if it's over 100.
The float sequence breaks the float into regions, and then it returns a different set of weight functions for each regions.
A simple curve is the kind of thing that you hear Dave Mark talk about all the time, where you want to take the number and maybe apply some sort of formula to it to turn it into an S-shaped curve or a parabola.
And then you're going to take that, maybe you want to normalize it.
You're going to stick it into one of the weight values that you're going to return.
The simple curve weight function handles all of that kind of logic.
And there are other special purpose weight functions that get used in other places.
The last thing I'll mention is a region.
A region is just a standard way to define some space in the world.
It could be a spawn volume.
It could be for my sniper, if he's firing down into a marketplace, I could define the kill zone for him.
And I might represent that as a circle, or a rectangle, or a polygon.
In the latest work that I've been doing on flight simulators, quite often the military has a line.
And when an aircraft crosses the line, that changes their behavior.
They change to a different stage of engagement.
So it could be, here's a line in the sand, and one side is one region, and the other side is the other.
Regions just have to be able to know if you're in the region or not.
And maybe if you want to do something like a random wander, it's useful to be able to pick a random position inside of the region.
So moving on to the sniper example, imagine that we have a sniper character.
And this is drawn from a real character that we did build, although it's not exactly out of that character.
And this sniper does a bunch of different things, right?
He can move away, he can whatever other things he needs to do.
But one of the most important things he's going to do is he's going to be in this sort of sniping behavior, where periodically, every minute or two, this is military simulation, now not games.
So every minute or two, he wants to take a shot at the enemy.
In games, it would probably be more often.
But also, this is military simulation.
So unlike most game characters, our sniper wants to live.
So if he doesn't have a line of retreat, he's not going to take a shot.
And that's pretty common for real-world snipers.
If they don't think they have a way to get away, then they're not going to engage.
Uh-oh.
Hopefully, is there a way to plug in?
Never say, uh-oh, when you're on a mission.
Oh, you don't see why.
Sorry, I just got a bad recording.
All right.
And also, with each additional shot, he wants to decrease the priority of taking further shots.
Because every shot increases the risk that the enemy will figure out where he is.
So he's going to have an option somewhere in some reason, or it's probably going to be a utility-based reasoner that's picking the high-level thing he's going to do that is the take a shot option.
And that option is going to have some considerations on it that tell us when we should do this thing, and then some actions that say what we should do in the case that it gets picked.
Are you guys good down there?
I have to dodge and wait.
This is great.
Extra challenge, right?
You have a line of retreat.
I really know I'm blocked.
I probably shouldn't take any shots.
So the first consideration we're going to have is an execution history consideration.
The job of this consideration is to make sure that we only take a shot every minute or two.
So execution history consideration can be configured in a couple of different ways.
In this case, we're giving it a stopped wait function, which is the wait function that gets used when the option is not currently running.
So this consideration is going to do its work when we're not in the process of taking a shot.
And that execution history consideration is going to just pass the amount of time since we were last executing into this wait function.
The wait function is a float sequence, so it's going to divide that floating point with possible values into, in this case, two areas.
One that's less than some random amount between 60.
Oh, you guys can't.
You're not going to be able to see the mouse.
60 and 120.
And in the case that it's in between, say, 73 is the number that's picked, right? Say it's less than 73 seconds, then the wait values that I'm going to return are to set veto to true.
And veto just says, I don't care what any other consideration says, you cannot do this right now. Right? It's an absolute veto. Otherwise, if it's over 73 seconds, then we're going to set veto to false, which is effectively a no-op. It says, you know what? I don't care. Right? Ask the other considerations. Do it if you want. It's up to you.
The next consideration we're going to have is going to be a picker consideration.
This one is defined globally, partly because there's not space on the slide, but also because this is picking a target.
And we likely would have other behaviors that would also want to pick a target to shoot at in different situations.
And the picker is going to do the kinds of stuff I said before, right?
It's going to look at the targets, check that they're in the marketplace, check the distance to them, check how much cover they have, look for ones that it knows to be an officer, if it happens to know that, and use all of those values to pick the best target to shoot at.
And then it's going to use a Boolean weight function to say, if I've got something to shoot at, then set veto to false.
Otherwise, set veto to true.
If I don't have anything to shoot at, then I can't shoot.
And it's also going to write that target to the blackboard for use later.
The third consideration is another picker that's defined globally.
The names on these, by the way, so globals are defined somewhere else and they're given a name and the name just tells me which global to stick in.
This one is going to use a region to define my area of retreat and it's going to use a picker just to check if there are any entities in that area.
It might well cheat and use all entities rather than just using known entities in order to get the behavior to do what I really want.
and avoid it looking stupid when the player goes, well, you should have known about that entity, but he didn't.
And last but not least, I'm going to use an integer variable consideration.
This just looks on the blackboard for a variable named numShots, which should be an integer.
And then it's going to pass that integer into a basic curve.
The basic curve is going to transform that integer into something that decreases the priority of this option with each as the number of shots increases.
So that's how I try and decrease priority with each successive shot.
If this option gets selected, it's going to do two things.
First, it's going to update that integer variable, numshot.
So in this case, the update we're going to do is an increment.
This action could also just set it to a static value, but that's not what we want to do here.
So this is how we keep track of how many shots we've fired each time this option gets selected.
This action increments the number of shots that have been fired.
And I also have a global action, because other people might want to do the same thing, that's going to fire at the target that we wrote to the blackboard. And that probably has some more logic inside of it that handles going through whatever sequence of fire actions, making sure I'm in the right animation and that sort of thing.
So what does all of this buy me?
The most important thing is that as I'm doing my work, as I'm specifying behavior, I'm thinking at the appropriate level of abstraction.
Not too big, not too small, definitely not implementation details.
So if you look at this execution history consideration, for instance, I enter about six values.
It's execution history, it's a float sequence, the minimum and maximum values, and what to set the vetoes true.
And that expands out to probably a couple hundred lines of code.
And it's not just the obvious keeping track of when the last time I did it is, but also little things like getting that random number and making sure that that random number is updated at an appropriate time.
So each time I take a shot, I want to pick a new random number for the next shot.
But I don't want to pick that every frame, right?
Because then it's quickly just going to be 60, because I'm picking it over and over as it gets smaller.
Sooner or later, it's going to be small enough that I fire.
So that's not hard to do, but it's a little bit tricky. You could introduce a bug there, right? So you'd rather implement it once and then reuse it.
The other thing to notice is that the values that I'm specifying are the relevant ones.
If I were describing to you when the sniper takes a shot, like I just did, the things that I would tell you are things like, he's going to take a shot every minute or two, right?
So what am I putting in here?
You know, the time since the last shot needs to be between one and two minutes, right?
That's exactly the same values that I tell you in my human description of what I'm doing.
This also allows me to have really broad reuse, both of the code itself.
This execution history consideration gets used lots of places.
This weight function gets used even more places.
But also the XML.
If there's something that gets reused a lot, then I can define it globally and then just plug it in.
Since I'm reusing something, I only have to implement it once.
The time it takes to implement is a cost I pay one time instead of paying every time I need to do it.
I also get fewer bugs, right?
Every time I write code, there's the chance of introducing a bug.
If I don't need to write some code, I'm not going to introduce a bug, hopefully.
And my code becomes much more mature.
It's much better tested because it's being executed lots of different ways.
So it's not only more tested, but better tested.
It's tested lots of ways.
And it also becomes more feature rich as I add new features and new capabilities, like the ability to pick that random amount of time instead of just specifying a fixed amount of time.
Now I have that capability and I can reuse it going forward.
And if I wanted it to be an exact amount of time, by the way, in the XML, I would just put exact equals and then I would put the exacts time.
So the bottom line is the developer flow, right?
The developer's sort of in this flow where he's thinking about the concepts that he cares about or she cares about in the specification that they're defining, not about implementation details and low-level stuff that's just a distraction.
So a few implementation details.
Obviously, the biggest thing is polymorphism, right?
No surprises here.
We're going to have a base class for each conceptual abstraction which defines the interface.
And then everybody else is just going to interact with a consideration or an action on the basis of those base classes.
And you guys probably saw I put the simplified versions of those interfaces in the slides should you want to go back and find them.
This lets me decouple the interface from the implementation, right?
So nobody needs to know that this is a distance consideration or how the distance consideration is implemented.
This also makes it possible for me to inject code from the simulation or from the game up into the AI architecture without the AI architecture knowing anything about that code.
So the move action, for instance, is gonna be game-specific, right?
How you go about moving a character around in-game and...
deal with physics and collision and path planning and all of that. That's going to be game specific.
The AI doesn't need to know any of those implementation details. It just knows it has a move action. It's supposed to give the move action the set of values. You have to have factories, which handle reading the XML and then creating all of the objects inside of it. So you have a consideration factory, for instance, which pulls the type...
value off of each consideration and then creates an object of the appropriate type. Um, what you pass to the factory is not only the XML node but also some contextual data, where the blackboard is, uh, what entity you belong to, if you're underneath an option, what option you belong to because the execution history consideration, for instance, needs to know which option it belongs to.
One nice thing about the factories that we have in Gaia, because we want to be able to reuse it across multiple projects, is they have this notion of constructors.
So a constructor is just an object that knows how to create some subset of that conceptual abstraction.
So a consideration constructor knows how to create a bunch of different kinds of considerations.
The factory could have multiple constructors, and it just asks each one.
Do you know how to create this?
OK, you don't.
Next guy, do you know how to create this?
Until it finds one that knows how to create the object that it needs.
This means that my simulation or my game can pass a factory into the AI architecture.
So this is how we inject code into the AI.
Last thing I'll say about factories, it's really powerful to have a single implementation, right?
I decided some time ago that duplicate code was of the devil, and I was going to do everything I can to get duplicate code out, and so far I have never regretted that decision.
So I'm going to have lots of different factories, one for considerations, one for regions, one for weight functions.
I want to make sure that I have one set of code that they all execute.
so that I don't have this situation where I have this one factory that's a little funky, it works in a slightly different way and I have to remember how it gets used, or I have a bug in one factory and I forget to fix it in the others, or, you know, that kind of stuff. I don't want to worry about that. The other nice thing is if I do it this way, where I just have a macro that creates the factory for me, then when I come up with some new kind of conceptual abstraction, and that happens more often than you might think, I just have to call the macro, and all the infrastructure is there. It's all created for me.
So this is roughly what that macro looks like for the factories. I use macros much more widely than this. Macros are a pain to debug. Figure out how to get your compiler to expand the macro out for you so that when you need to debug it you can do that. As I said earlier, I don't have time to talk about how we combine considerations. But there have been a bunch of good talks on this. I gave a talk yesterday on the trigger system, which used a very simple Boolean approach to combining considerations.
Mike Lewis and Dave Mark last year gave a fantastic talk in which they talked about how they combined considerations in their architecture.
I gave a talk with Dave a couple years ago, where I presented a dual utility-based approach.
I really recommend the third, the dual utility-based approach.
It's straightforward to implement.
It's not hard to get it up and running.
It's extremely flexible.
It lets you do either really hardcore utility-based AI stuff, or really simple yes or no stuff.
And you saw some examples of both of those in the Sniper.
And it's probably too strong to say it completely avoids the sort of combinatoric problems that Mike and Dave have, because it's utility-based, so of course it doesn't.
But they had a problem where the more considerations you have, the more it forced the values down when they multiplied them together.
And the dual utility-based approach gives you some different options for how you combine things to try and work around that in different ways.
But you don't have to pick one way, right?
So a consideration set is the thing that wraps a bunch of considerations and combines them together.
It's all in data.
So in the data, you can have a flag that says, combine in some different way.
Or you could have a different, you could make a consideration set a conceptual abstraction and have different consideration sets that use different types of considerations, if that's the thing that you feel like you need to do.
What I've done is I have a few flags that change the way I combine the values, but I only have the one kind of weight value that I use everywhere.
So final thoughts. Remember the what does this buy me, right? The important thing is it lets me think at the right level of abstraction. It keeps me in that good flow, um, so that I can implement much more quickly. I can iterate much more quickly. Um, I've seen modular approaches pay off in projects that are three months long, right? When we did the boss AI for Iron Man, we used a modular architecture and we were very quickly getting to the point where, you know, it's...
It was a three month project and I don't think we could have hit it if we hadn't had that ability to iterate so quickly.
And it also, you get much more reuse, so your code is better tested, you have fewer bugs, and your code becomes more feature rich, and it's easier to carry it with you to future projects.
You don't have to throw out your architecture and start over.
Look for opportunities to do something in a modular way in your architecture.
Weapon selection and target selection are common cases of plugging in some considerations.
In Red Dead, I was assigned to build the attention system that got characters looking around in town.
And I decided, even after Iron Man, not to do it modularly, because I thought it was just going to be very simple.
And we got eaten to death by special cases.
You know, I thought it was just going to be pick something nearby at random and look at it for a little while and then pick something that's not in the same direction and look at that.
But there was the, well, when this, you know, when the player does this, then you should look at them.
But if this event happens, then you should look at that.
But not if this other thing happens, then do that, right?
And so all of those special cases ate us to death.
And I really wish if I could go back in time that I could have just built it in a modular way.
In the end, Red Dead shipped with a pretty cool attention system, but it was a lot more work than it could have been.
And if you're going to do one thing, start with considerations.
Considerations are a really, really powerful way to lay out your decisions.
Last thing very quickly, the Mars game is out there.
I mentioned this yesterday.
It's open source.
So if you want to see code examples of how all of this works together, you can go grab the code from GitHub.
It's a simpler modular system, but it has all of the big ideas in it.
So that's it for me.
On to Troy.
All right.
How's it going?
My name is Troy Humphreys.
I'm the lead AI programmer at Turtle Rock Studios.
And I'm also going to talk about modular AI systems.
So why this talk?
Well, I think game AI architectures are pretty modular.
You know, like we have behavior trees, finite state machines, planners.
All these things are modular systems, and modular systems come with a lot of benefits, right?
We get code reuse, flexibility, ease of character creation, and so on.
And on Evolve, On Evolve, we used a behavior tree, but it wasn't giving us the modularity we wanted.
It was still hard to get the AI out the door.
The BT worked fine, but we simply weren't getting all the gains we should have been getting from a modular system.
So we decided to fix this.
We decided to focus on two things.
First was figuring out why the modular behavior tree that we were using.
wasn't giving us all the benefits that we wanted.
And we needed to do this without breaking any of the legacy characters in the systems, because we were still developing a live game.
We still had DLC characters coming down the pipe.
And we couldn't mess any of that stuff up.
So how do you fill up modular?
So how about a little example to help illustrate this point?
Do you have a mouse?
OK, that's better.
So in our example, we have a forest troll.
And he's going to do a very simple attack called the tree trunk tornado.
He uplifts the tree and spins around, knocking everybody back.
I think everyone can visualize how that would look in their minds.
But let's get into some details here.
First, he should only do this attack if he's currently surrounded by enemies.
If he is surrounded by enemies, he's going to do a point blank AOE knockback attack.
And after completion, he's going to be tired.
We want to set some kind of state of tiredness to be used in some other behavior later down the line.
So we can simply just make a node in the behavior tree to handle this stuff, right?
On start, we can check to see if there's enough enemies.
If not, we can fail out.
If so, we can go on and go ahead and play the animated attack part, which is triggering animations, playing sounds, damage boxes, and things like that.
And on completion, we can set some states in, like, the blackboard for tired, which we can use later.
And I think this is a perfectly reasonable implementation, right? This could shit. And it's, it is modular. I can find other situations in my behavior tree where I might want to use this same attack. But we all know what happens next, right? Designer comes to you and says, all right, I want to tornado in a completely different situation, maybe in a combo or getting up from a knockdown or something like that. And all of a sudden the is surrounded check is causing trouble, right, because he doesn't care in those situations if he's surrounded or not.
Sometimes the designer might want the tornado to trigger without setting the troll tired, right?
You might want to be able to use it in different situations, and all of a sudden our nice little modular attack isn't modular anymore.
So I'm sure you've seen similar examples in some form or another in a lot of codebases.
We had a lot of this in Evolve. It was getting, it's kind of a death by a thousand cuts type of thing.
So I started thinking a lot about what had worked on systems I used in the past.
I've gotten lucky, I've gotten to work with, ship games with hierarchical finite state machines.
We've shipped games with GOAP, HTN, and behavior trees.
And every time I think about all those systems, they all had one thing in common when they worked really well.
They had a really good separation of responsibility.
So I think separation of responsibilities is something we can all get behind.
We talk about good abstractions all the time in software engineering.
But I want to talk about three AI-centric responsibilities that I think are crucial to having a good modular system.
So let's use our tree trunk tornado example to help illustrate these three areas.
The first responsibility is sensing.
This is where we translate information about the game into something the AI can understand.
In our example, it's the is surrounded question.
Breaking the sensing logic out of the tornado allows us to ask the same question about different targets, which can be useful for other behaviors.
It also allows us to fire off the tornado if the troll's surrounded or not, which helps solve the earlier problems we had with our designer.
The next responsibility is acting.
This is where we see the AI actually do something.
In our example, it's the animated action part of our attack.
It's a logic that starts the animations, plays effects, sounds, triggers damage zones.
And now that our sensing logic is out of the attack, we can use that same animated attack action with different data to do all kinds of different attacks.
The final responsibility is deciding.
And when we think of most AI systems, this is where they would live.
Our finance state machines, planners, and for us, it's our behavior tree.
This is going to be the spot where we assemble all the other responsibilities into a reasoning character.
We do this by defining the why the character will do the things it does and how it will react to them.
In our example, we would use the animated attack action to do our tornado.
Then we could decorate that action with a condition using the sensing data that we got from our isSurrounded sensing logic.
And lastly, we can add an effect that would set state on successful completion attack.
This would satisfy the making the troll tired part.
So I'm betting a lot of you are probably thinking, mm, this sounds a little familiar.
And you'd be right.
This is sense plan act.
But I don't want you to get hung up on the planning part.
I'm not trying to push planners on you.
I'll save that for another talk.
But I wanted to talk about how this could be a guide for better modularity, regardless of what architecture you're using.
So let's dive into these areas in more detail with some guidelines and kind of what we did with our refactor and evolve.
But first let's talk about something that I think helps make all these areas work in concert, something called the world state.
So the world state's kind of like your glue.
If the game state is the actual data in your game, the world state is a simplified representation of that state as far as the character's concerned.
I'm sure you all have different flavors of this.
Blackboards, contexts, if you're using planners, it would be a world state.
So some guidelines for setting this stuff up.
Oh, the world state's really just a big block of data.
It should be easy to write to, easy to read from.
So some guidelines.
Every character should be able to have their own set, right?
Different characters need different information to be able to make decisions.
keep the structure very simple right fast access faster right here uh... an array is a perfectly acceptable world state For Evolve, we split this concept into two things.
Now, first we use a blackboard, is used to represent the simplest enumeration of the world state required for the decision system to make decisions.
Let's take the character's health, for example.
We could use the character's health percentage as a value in our world state, but 0 to 100% is a lot of state, right?
We aren't going to be making decisions on 101 different states if we're using an int.
If it's a float, it's even more, right?
But what we would like to make decisions on is if the character's wounded, if he's healthy, if he's dying.
This is the type of data we want to store on a blackboard, because that's the type of data we want to make decisions with.
The second part of our world state, something we call the whiteboard.
clever. But this is where we put all of our rich data in our world states. All the extra data that isn't used to make decisions but is used to run behaviors. So this might be like the best cover locations, the biggest threats and so on.
So let's get to sensing.
This is where we translate the game state into world state.
This doesn't just mean hearing and vision and things like that.
This can be as simple as taking that health percentage and translating it into the health enumeration, or as complex as picking good cover locations.
Some guidelines to help you go.
Modular and atomic.
You want to keep these nice and small.
Sensors shouldn't know about each other.
No sensitive sensor dependencies.
Use the world state to communicate if you need to.
characters should be able to have their own sets of sensors, right?
If they're going to have different world states, they're going to need different sensors to fill that world state.
Translating game state into world state can be very expensive, right?
So we want to be able to bin, throttle, defer our work, anything we can do to handle that workload.
Another thing that you should keep in mind is to keep sensing out of your deciding loop if it's possible.
We just said it's expensive.
We want to be able to quickly make decisions, so try to keep that stuff out.
For Evolve, we ended up making a new sensor manager to give us a formal and really easy place to do our sensing work.
It allows us to install sensors per character type.
It allows sensors to have a different max stale time per character type.
Meaning, this is how long the sensor can go without getting an update.
This is great because it shows the importance of that sensor to that character type.
So, as an example, imagine you have a line-of-sight sensor in two characters, a ranged and melee character.
Well, the ranged character is going to need a higher refresh rate because he needs to constantly check to see if he can hit people from range, right?
The melee guy, not so much. He just needs to know the general location of where the guy is and that can be updated kind of slow because he's just going to run up and smack you in the face anyway.
And to make it even simpler, the time, the way you specify the time is a simple enumeration.
Something like every frame, a lot, often, sometimes, never.
Why have our programmers come up with the perfect floating point time to do a refresh rate when we're just really just looking for what that sensor's importance is to the character using it.
So our manager will just burn through as many sensors as it can and it's a lot of time. It favors sensors that are getting closer to their stale time. And since we use an enumeration for time, we can tune those different frequencies behind the scenes without breaking the character's type's needs. We could also play with these too if we want to do LODing and stuff like that.
So acting, acting is what makes up what the AI actually does, right?
This is what the player is going to see.
These are your attacks or reloads, your interactions, your tornadoes, things like that.
Different systems will have different terms for this, right, HTN uses operators, GOAP uses actions, behavior trees use nodes, states are in finite state machines.
Some guidelines to keep in mind. Operations should be agnostic to the reason they're being done. We saw this with the tornado example. If the reason's baked in, it's going to be harder to use that tornado elsewhere if that is surrounded check is in there. The only conditions that should be baked in are what's actually needed for that action to run or that operation to run. So let's say we had a fire gun operation. You need the gun to be able to fire it, right? So that's an OK condition to put in there.
Operations should be agnostic to the world state it references.
Let's say the troll had a boulder throw, right?
The boulder throw operation shouldn't care if he's throwing it at an enemy, a building, or some other object.
It just needs a location where to throw that boulder.
Operations shouldn't try to do more than one thing, right?
They're just, the more they do, the harder it's going to be to be able to find situations where you can reuse that operation.
Operation shouldn't change the world state.
Going back to our tornado example, there are going to be times that you want to be able to do a tornado without the troll getting tired.
So we want to keep that world state change out of your acting.
And why do it?
If our deciding logic gives us a nice way to do this operation, why hide the state change from the person looking at your decision logic or your decision structure?
So for evolve, our acting is the number of BT nodes.
And what we ended up doing was refactoring a whole bunch of them, ripping out the sensing logic and deciding logic out of those acting nodes.
And if we didn't do that, we just made new nodes that just really focus on acting.
This gave us smaller and simpler building blocks to work with going forward with our new characters.
The last responsibility is deciding, right?
This is where we make decisions, or better put, this is where we translate world state into action, right?
It's the behavior systems that we use.
It's HTN, GOAP, behavior trees, finite state machines, kind of, right?
This is typically the structural part of those systems, right?
It's the tree structure of behavior trees and HTN.
It's the graph structure of our finite state machines and GOAP, or the priorities of a utility-based system.
Some guidelines to keep in mind when you're building your deciding logic.
Deciding should be fast.
That's hard to argue, but I mean, if you want to be able to react to changes in role state as soon as possible.
So try to keep all the heavy lifting outside of your decision system.
Deciding should also allow us to define the conditions required to execute operations and the effects on succeeding those operations.
It also should be fast to edit.
And I don't mean you need an editor, right?
You just need some clear way of defining your structures and your deciding logic.
For Evolve, we use a behavior tree described in Bill Merrill's Game AI Pro article.
It's now free on the website.
It's a great article.
You should definitely go check it out.
Luckily, we didn't need to change this at all.
It just worked.
We just had to change a lot of the nodes and the sensing logic.
So something I haven't talked about is our blueprints.
Evolve uses blueprints to have one location where they can set up a character.
This is the integration step that Chris was talking about earlier.
Here we load our designer-treatable data.
We define our blackboards and install our whiteboards.
We install the other different components that make up that character, their sensors, their behavior trees, things like that.
And as we install our sensors and build our BTs, this is where we're going to do all our wire work.
We're going to tell the sensors where to dump their data in the blackboard.
We're going to tell our decision tree what blackboard variables, or behavior tree, what blackboard variables to look at.
This was an incredibly important step to us.
Like, this is where we were able to build our new system side by side our own system.
If the AI was a blueprint AI, we had a whole different initialization call stack to run through.
If they weren't, it went through the old legacy systems.
And once we had this set up, we could quickly start using the new systems without worrying about breaking any of our legacy code.
So, let's talk about the different architectures and how they would kind of fit in these areas of responsibility because we all don't use the same things.
And hopefully you're already kind of thinking about your own systems at home, how they would fit into this stuff.
Maybe you're finding some that are crossing these boundaries that are giving you trouble.
So for Evolve, we use our behavior training.
We've already kind of talked about this.
So for our sensing, we'll use our sensor manager.
We have our surrounded sensor, maybe enemy distance sensor, things like that.
For our deciding, our behavior tree is going to live there.
But if you look, the nodes that we're going to be putting in this area are just the ones that help define the structure of the behavior tree.
It's our selectors, our sequencers, and our decorators.
for acting is basically the rest of our behavior tree nodes.
Anything that actually does things, right?
The fire node, reload, animated attack, navigate to.
The world state's gonna have our blackboard and whiteboard.
And if you were to follow the data, how it flows through this, our sensory manager and our sensing logic are gonna populate things in our world state.
It also might reference some of that stuff to help to do more sensing.
our behavior tree is going to pull data from our blackboard in order to make decisions.
And on the completion of different nodes, it might apply different changes to that blackboard as well.
And then when our acting is running, our behavior is running, it's going to pull all the data, whether from the blackboard or the whiteboard, in order to make those behaviors work.
If we're going to do this with an HTN planner, and very similarly a GOAT planner, sensing kind of works the same.
For deciding for HTN domain, we'd have a different kind of structure here.
Our compound task is going to help define the hierarchical structure of our domain.
while the primitive task is going to help define the conditions and effects in order to run the acting operations.
HCN uses operators, so the operators are all sitting in our acting side and the data flow is going to work roughly the same.
The world state, they actually use a world state, which is a very simple representation to do their planning.
Finance state machines, a little trickier.
Basically what we'd want to do is have a finance state machine that kind of goes over both sensing and deciding.
But the states that...
But we'll have states specifically designed to help sensing data, help collecting that data.
And then the other states would kind of work like a typical finance state machine.
But what we want to do with those states is kind of treat those as wrappers to the operator concept that we're going to borrow from the HTN stuff.
So if you look, we have a navigate to enemy state.
this thing will help define the transitions to other states and the data to supply to the NavigateTo operator.
I still think a world state's a great thing to have in a finite state machine.
It gives you a nice snapshot with everything that the AI understands at that point, and you can base all your transition stuff off this lot of data anyway.
So, in conclusion, modular systems doesn't really quite mean you're making modular characters.
Even though you're using a modular system, it may be implementing those modular pieces in a very unmodular way.
should really think in terms of responsibilities.
When you find something that isn't modular, I guarantee you, you've got some sensing and you're deciding, or some deciding and you're acting.
Crossing that responsibility boundary is a sure way to shoot yourself in the foot.
Look for the friction in your system and improve it.
Make it easy to do your sensing work in the right place.
Make it easy to do your deciding work in the right place.
Make it easy to do your acting work in the right place.
You don't need to start a new project or new code to do it.
We were able to do it with a live game while making DLC.
And we're already seeing the benefits from this refactor.
And you can do this.
Thanks a lot to Kevin and Chris for all their help, and Justin Cherry for the art, and my teams.
Thank you.
