Hi everyone, and welcome to Creating a Horror Score on a Shoestring Budget.
I'm Spencer Bambrick, I'm the composer for the game Evil Nun, and in this lightning talk, Gina Zdanowicz and I will be sharing our experience working on this indie horror game.
We'll be talking about some of the creative and logistical decisions we made during development.
So first, for anyone who hasn't played it, Evil Nun is a stealth horror game developed by Keplerians.
The game is first-person, and the player is tasked with solving a series of puzzles in order to escape an abandoned orphanage.
Of course, there's a terrifying nun that's there to chase you the entire time.
It was released in 2018 for Android and iOS, and it has since become quite popular with over 20 million players.
So we hope that you'll all get something useful and interesting out of this.
So let's dive in.
First, the takeaways.
You'll walk away from this talk with a better understanding of how to spot a nonlinear score in the horror genre, how to choose a musical palette that is both terrifying and low cost.
and you'll walk away with some tools for developer communication, which is always essential on any score.
So I want to start by talking about the very first step that we took on Evil Nun, and that is spotting.
If you're familiar with film scoring, spotting is when the composer and director decide on when and how music will be added to each scene.
So before we go any further, I want to show you a quick example of a film that I think very effectively scares the crap out of its audiences.
The film is The Conjuring and we use this scene in particular as a template to kind of decide how the music should work in Evil Nun, so check it out Uh, uh, Baron?
BELL RINGS BELL RINGS Baron?
There was a crooked man.
And he walks a crooked mile.
Okay, so taking this example as an effective template for spotting, what did we learn?
Well, the first thing, you probably noticed that most of the scene is actually silent musically.
So this is crucial for building tension. Silence is scary because it gives players room to imagine something much scarier than what they're actually about to experience. Try watching that same scene again, but from the moment the Crooked Man appears. It's actually a lot less scary without the build-up.
Silence also happens to be very cheap, which is right in line with our goal of coming in under budget.
So our next point is structure.
The structure in this scene is very loosely sort of a silent build plus a chaos plus a denouement or falling action.
So what we wanted to do was to take this structure and mirror it in Evil Nun.
So in Evil Nun, it looked more like our sound effects and ambience, so musical silence, plus a stinger, a chaotic stinger, and then a loop that could be faded out as the player's distance to the Evil Nun increases.
So as the player is running away from the Evil Nun, the loop could be faded out if necessary.
And that constitutes the majority of gameplay.
So here's what it sounds like.
So that's obviously a super short excerpt, but you can hear how it's all working together.
So the next big question we had to ask ourselves was what instruments do we use?
For us, we chose our instrumentation based on a few key factors, the number one being budget.
So full orchestra, at least live recorded, was out.
The orchestra you heard in the example was all samples.
And basically, this narrows it down to solo instruments only.
So for those solo instruments, we had to ask ourselves which instruments are the most flexible.
Does it have multiple methods of making sound?
How flexible is the timbre?
Does it have a wide range?
Basically, the more options, the better.
Third, we wanted instruments that could take effects processing well.
Adding plugins can drastically expand the timbral palette.
So remember, with horror games, instruments don't really have to sound natural at all.
In fact, it can be scarier when the sound source is unclear.
But some instruments take distortion and modulation effects better than others, which is why it's important to choose the right instruments up front before recording.
And finally, it's really important to remember that you're collaborating with people, not instruments.
This means you need to search your network for the person or people that can not only play their instruments well, but can deliver on time, record themselves professionally, take direction, possibly play multiple instruments, which will save you money, and improvise, which we'll get to.
So in the end, we hired two people to play three instruments, violin, saxophone, and clarinet.
We also used a prepared piano, which I played and recorded myself.
So here are a couple sound examples of the prepared piano.
So these are just very simple scrapes and screeches. We took off the top of the piano and placed some microphones inside. We also added things like chains for this second example.
It's really effective because the piano is so large it kind of adds its own reverb to it.
Plus it costs nothing because I just went down to a local community college and recorded and played it myself. So it was totally free.
So next I want to talk a little bit about improvisation.
So improvisation or aleatory is a staple of the horror genre.
So I always make time to let my collaborators run wild and deliver takes of whatever they think sounds cool.
Often I'll give them a directive like, play like you're being chased by a demonic clown, and that will return some amazing results.
But when I have a specific effect in mind, I'll deliver sheet music that looks something like this.
So this is the exact sheet music that I used for the stinger that plays right when the nun spots you.
The players recorded overdubs of each of these with some slight variations, and I mixed them together and added some fun effects.
One thing to remember when you deliver aleatoric sheet music to a musician is it's really important to be crystal clear on what you want.
The music needs to be readable and you need to do your research on what the norms are for techniques that extend the timbral range of the instrument or extended techniques.
For example, this triangle note head right here is universally accepted to mean play the highest note possible. So make sure you understand what symbols you're using so as not to confuse the player.
I can't stress enough how easy and fun this process is though, so if you're not experimenting with your own effects when you work with a musician, you're missing out.
So let's take a listen to what each of these sound like.
Again, these play right when the nun sees you, if you can remember back to the video, so it's basically the chaos that plays after the silence buildup and before the loop.
So this is the first stinger.
So you can see there's some improvisation on the pitch.
There's no pitch information written, but the rhythm is very specific.
So each of the overdubs come in line.
These are sort of a high cluster that glisses down to a low cluster.
Here's stinger B. And here's stinger C.
Obviously, that one contains prepared piano as well.
Also notice that I mixed these really dry and sort of close to the listener compared to the orchestra that comes in next and I did this intentionally so that it would be really uncomfortable and jarring for the player when the nun spots you.
To come up with your own ideas, it's best to check out contemporary aleatoric scores and use them for inspiration and for notation reference.
This is actually one of my favorite topics, but we do have to move on because of time.
So please don't hesitate to reach out after the talk.
I have tons of recommendations if you're looking to try this.
So the last point that I want to make is that even if you have no budget at all for live musicians, there is a lot you can do on your own to get some scary sounds and textures.
Just to be clear, I absolutely cannot play the violin, but I use it all the time, especially in horror scores.
So I have a few final examples here, and I'm going to take a simple raw recording of me playing the violin badly, and I'll use just a few plugins to turn it to something dark and scary and kind of musical.
So these examples outline the trajectory of one single take on the violin.
Here's the raw, unprocessed recording.
It's just me scraping the bow across the strings, basically.
Muted strings, no actual notes whatsoever.
You can hear it's pretty unimpressive.
So here's the same recording.
What I did was I took that recording and I threw it into a sampler and I played it an octave lower so it'll be stretched out as well.
So you can hear it's already a little more atmospheric, darker.
Then all I did was add a couple of plugin effects.
So I added some EQ to clean it up, just cut out some of the low end.
I added the effects rack from Sound Toys.
And all this is is a saturator, a little bit of saturation, a little bit of echo, and some panning so that part of the signal will just sort of pan through the stereo spectrum a little bit back and forth.
And finally, a nice big convolution reverb.
And what the end result sounds like is this.
So to my ear, that's something you could easily work with to get a tension track or an ambient cue for any kind of horror game.
So one more example This one's a bit bigger the last example had only one single take of violin this one I overdubbed a bunch of different takes and a couple different kinds of bowing so Here's one raw take where I was actually bowing again. No notes whatsoever. I'm just bowing the wood of the instrument It's so subtle it's tough to even hear. Then the second one is more of a soul ponticello which really what that means is I sort of muted the strings and I played closer to the bridge.
I just did some random tremolo effects there.
So what I did with each of these is I recorded a couple extra overdubs and split them into two separate buses.
So there's three overdubs of the wood.
Bowing and then I think a total of seven for the swole ponticello stuff I EQ them out again just to clean them up a little bit. I panned them Wide across the stereo space but nice and evenly so you can get like a big sound And then the plug-in effects are even simpler than last time there's a little bit of distortion here a little bit of reverb a convolution reverb and then these are just shooting off into some more delays as well. So just a little bit of reverb, a little bit of distortion and EQ and panning and the result is this.
Bowing the wood especially, I think, is very atmospheric.
And it's surprising how realistic the sul ponticello stuff sounds.
You can overdub that as many times as you want.
And as long as you're mixing it with clarity, it's going to come out great.
It even sounds a little bit more intimate than if an orchestra were to play that.
So that's all I have.
Thank you for listening.
I just want to give a quick shout out to Jeff Penny and Aunt Carrie.
They were the wonderful musicians that you heard in those stingers.
So Jeff played the sax and clarinet and Ant played the violin.
So next up, Gina will be talking a little bit about sound implementation and communication with the developer.
Thank you very much.
Thanks, Spencer.
My name is Gina Zdanowicz, founder of Serial Lab Sound.
So let's jump in and start with the budget challenges first.
When a game is developed and financed out of pocket, the budget's likely to be on the smaller side.
There are plenty of indie horror games developed on a slimmer budget, such as Five Nights at Freddy's and The Forest.
And rather than relying on realistically rendered gore, Five Nights at Freddy's uses atmosphere and tension to create scares.
And as Spencer explained, there's a lot of ways you can create tension with sound in a game, even on a tighter budget.
So Evil Nun was released and marketed prior to our team joining development.
And the game devs initially used library music and sound effects.
And then they saw there was a good amount of interest in their game and decided to give it an audio treatment.
The game uses a free-to-play model, so their audio budget came mostly from out of pocket.
We did hire a voice artist, Tamara Ryan, for the nun's role, and she was great, willing to work with us with our non-union budget, and really had fun with it.
I also recorded my nephew, a ten-year-old, for the boy-effort sounds, like the screams and the breaths.
And we were limited with the number of music loops we can produce under the budget.
So we added variety by using stingers and silence.
And in the end, it made for smoother transitions as the game states changed.
And as Spencer mentioned, live musicians can add nice tension element to horror scores by having that ability to produce interesting effects with their instrument that's difficult to uniquely produce with virtual instruments.
Both the sound design and music work together in horror games to create that immersive environment.
And we avoided the wall-to-wall music approach to save on budget and also to help the dynamics of the scenes.
We pushed for moments of musical silence as the developer originally had constant music throughout, and we made the sound design a bit more busy than it initially was.
Ambiances were louder in the game to add to tension when the music wasn't playing, and the game has a fine line between music and sound effects as they dance together and share the spotlight.
But getting back to how this worked with music, if the music were constant and very elevated, it'd be difficult to hear the footsteps.
Part of the tension building was hearing the footsteps or the nun singing as she gets closer to the player.
And then the stingers come in when she's within a certain proximity and that helps take the tension over the top.
So let's break this down a bit more.
Initially, we had the ambience very quiet.
It was just some room tone that we recorded.
And we wanted the music to be loud and scary, but if you remember, we used the technique which cut the music out when the player moved outside the nun's detection proximity or distance to the player.
And we did this to extend the use of the limited music we had in game.
And while this was a great way to get more mileage out of our music, it made for a very drastic drop in tension.
So let's watch an example.
So in the end, we decided to create a more textured ambience and boost its volume, so it acted like an extension to the music to keep the tension high.
This was much better, but the ambience was still a bit too loud in this iteration, but we ended up bringing that down slightly for the final mix.
So let's take a look at that.
and meet the others.
That is beautiful.
We also made use of DSP to add more dynamics to the game's audio.
Bringing the music down in volume and adding a low-pass filter while the boy is hiding inside the closet helps focus on the point of view of the player character.
We wanted it to sound a bit more realistic in that you would hear his breath more in the closed-in space, and the sounds outside the closet would be occluded.
This approach was mainly functional, but it also provided a bit of break in the ambience and sound effects.
So let's have a look at an example.
In this scene, you're going to hear a bit of ambience come through since there's an opening in the closet.
There was no ray casting done in the game to create the occlusion, so we had to work with a slight low-pass filter and volume ducking snapshots to make it work.
We also had to communicate this to the dev through video snapshots or video captures.
I'll meet the others.
That is beautiful.
Footsteps sound effects were important in the game.
It helps the player know when the nun is in close proximity.
And initially, we had an issue since there were two floors in game.
We could hear the nun walking above the player.
And we tried to have the devs change the 3D sound settings within Unity.
We started a new Unity project since we weren't doing implementation ourselves, and we tested the footsteps while creating proper setting in the inspector window.
When we took a screen capture of the component window, we sent it to the dev so that they can duplicate it, duplicate our settings.
It was still an issue though, even with a low pass filter on the steps after a certain distance.
In the end, the programmers added a script that only allowed footsteps to play when the nun was on the same plane as the player. So let's listen to an example of the nun's footsteps and how the music stingers worked when the players detected.
The end In addition to making the creative choices we just discussed, we had to manage the minimal resources so we used the Asset Canon implementation approach, so simply meaning the developer implemented all the sound effects and music.
If you've used audio middleware such as Wwise or FMOD, you're well aware of how much control the audio designer has over the mix, the memory footprint, fades, and randomization.
In this case, since we didn't have control of middleware, we delivered video mockups or sound paintings to demonstrate our sonic vision.
And this helped the devs get an idea of the overall use of sound, especially how the music stingers should be working in game.
And the videos also demonstrated our complete mix, what we had envisioned.
The loops were all MIDI, but recording stingers with live instruments, and them being the first thing the player hears, makes the loops feel a bit similar, as if they were recorded with live musicians as well.
A single overdub of one part of a music track can really change an overall production quality of the asset, and it's a good way to get more out of your budget and still have that live sound.
So let's have a look at some of the sound paintings.
The first one was our sound painting for the nun's footstep.
We presented this to the developer to say, this is what we envisioned for how it should work as it's implemented into the game.
So that mock-up was done in our DAW.
The next one is gonna be a sound painting for our music stingers.
Again, that was done in our DAW, but it was used to present to the developers, you know, an example of, hey, this is how we envision these, when they should come in, when they should play.
And sometimes we would show some of the other sound effects and music incorporated in the scene so that they get an understanding of what the entire scene should look and sound like.
As we mentioned, the game already had temp music and sound effects in place, and the fanbase had expectations as to what the game sounded like.
When we came on board, we wanted to change the original music direction to give it more tension.
When an update with our new music direction went live, fans of the game were uncomfortable with the new direction, and it no longer felt like the evil nun game that they were playing.
So keep in mind that this game already had some streamers playing it, and there was 10 million downloads, so quite a big fan base.
So we went back to the music and made some changes so it included some hints of the temp music.
We had to change our expectations as to what the game should sound like.
In the end, we should have considered the players might already be partial to the existing sound.
It's always about the player's experience. That's what makes great sound.
We discussed sound paintings through mock-up videos to communicate the implementation process, but there was also quite a bit of organization we needed to have in place to avoid communication issues.
Due to time zone and language barriers, we didn't have any face-to-face meetings.
We used Google Sheets to lay out assets and organize feedback and reference material.
This is an example of how we laid it out.
Basically, we wanted to have as much information as possible.
And even though we had a column for dev comments, a lot of times they would communicate through email and it proved to be tricky at times.
There was a lot of back and forth and waiting due to the time zone differences.
So let's discuss a few tips for organizing feedback from a developer.
It's important to manage how and where your dev provides feedback.
Imagine trying to locate feedback in an email when you have five to ten threads with 20 or more replies in each.
Try to set the precedent that one person delivers feedback from the dev side to avoid having multiple people providing feedback because paths can be crossed, confusion ensues.
If possible, it's a good idea to manage how often you receive feedback.
Not only is the game limited on budget, but also time.
And the developers had planned to release an update as a specific date and with all the new music and sound effects.
And we were asked to deliver the assets as they were completed.
So this meant we would receive feedback at different intervals for staggered asset delivery.
And it became difficult to continue creating new assets from our spreadsheet when we were also expected to start making revisions on the delivered assets.
So it's a good idea to try to set a specific timeframe for delivery and feedback.
For example, it would have been better if we delivered on a Friday and received feedback on a Monday.
So we had a few days to handle revisions and then didn't have to worry about creating new assets as well as juggling all the feedback and iterations.
Testing, the last thing I'll talk about.
There was definitely a good bit of testing once the sounds were implemented.
We had early builds on mobile and video capture of gameplay, but it's always helpful to have video capture from the devs because it can ensure that you're seeing all the game mechanics or the games being played the way they envisioned.
When you test on your own without a full understanding of the gameplay, you could miss important elements in the game.
So in the end, we managed to get most of the assets implemented based on all the hurdles that we, you know, jumped over.
And, you know, we did run into a few other issues like reverb zones, and so some of the reverb zones weren't implemented.
So some sound effects felt out of place in the scene, but most of those got fixed up with a later update.
But anyway, thank you for listening.
You've escaped the school