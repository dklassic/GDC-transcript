Good, alright.
Hello everyone, my name is Sebastian.
I'm the founder and CEO at Allegorithmic and I'm today very proud to start this session about how the people at Naughty Dog used the Substance tool set which we develop to texture Uncharted for one of the most anticipated game ever, basically.
It started about three years ago and the They will explain the journey, because it's been a journey, and it's working.
So today, without further ado, basically I want to introduce you to Brad and Rogelio from Naughty Dog here.
They will explain how they first discovered the tool set, then did a lot of tests, and I say a lot.
and decided on using it to texture their next project at the time which was Uncharted 4.
So it's my great pleasure to welcome Brad on stage to talk about that.
Thank you.
Thank you, Sebastian, and thank you to Legorithmic for hosting us. It's really a pleasure for us to be here. As we speak, the team is actually still working really hard to finish up the greatest Uncharted game ever made, and we can't wait to get it into everybody's hands. So to kick things off, we'd like to share the story trailer with you, and minor spoiler warnings.
If you haven't seen this, you may want to close your eyes and ears.
Ratings will be coming soon.
We were meant for this, Nathan.
You and me, together.
We were destined for something great.
For those who prove worthy, Paradise awaits.
Took a long time for him to get out of this game.
He's meant for this life.
Oh, oh crap!
Last I checked, we're all a bunch of thieves, digging around where we shouldn't.
Shame we're not on the same side.
I am a man of fortune, and I must seek my fortune.
So, are you ready to seek your fortune?
Hang on, Nathan!
Murder's the artifact.
That's all!
I made a promise that I was done with this life.
How long have we been chasing this thing?
Long time.
A real long time.
Just you and me.
No offense to these guys, but they don't get it.
If you're done lying to me, then you should stop lying to yourself.
The biggest pirate treasure of all time is within our grasp.
Watch out!
Look, Nate, I'm gonna make you a one-time offer.
Drop everything.
Go home.
Live your life.
Or we can just end it right here.
There's gotta be another way.
I need you on this one.
Stop!
You ever wonder, like, different choices, how we might have ended up?
No.
I like the hand we've been dealt.
Playstation.
Gets me every time, that trailer.
The team has a lot to be proud of, and as Sebastian said, it really was quite a journey, and one that Substance Designer was a huge part of from a texturing perspective.
So I'm here to talk a bit about the evolution and the pipeline that we created at Naughty Dog, along with Allegorithmic, to integrate Substance Designer into our internal and external tools.
My name is Bradford Smith, and I'm a texture artist at Naughty Dog.
So some of the artwork that our artists generated, this is Sam's, Young Sam's dirt bike here by Brian Kenny.
These are all substance materials.
And a city car by Tate Macessian and Jacob Norris.
And the Hero 4x4 that you might recognize from the trailer.
And it's Arch Nemesis, the Turret Truck by the fantastic Yen-Kyo Lee.
And here, Roelio has some great fully procedural tiling materials from Substance Designer.
And there's another one, some rough cobblestones.
And here's an example of mostly fully procedural textures in the context of an architectural level.
And then again, but in an organic context.
So what we could achieve with Substance Designer was very broad and diverse.
So our journey is gonna take us through the pipeline and the history and the evolution of the pipeline, and we're gonna look at how we really utilize Substance Designer to handle our outsourcing and our content management.
We're going to come back home and we're going to look at how we used substance products internally and just a few bits on what the horizon looks like moving forward.
So it's important to understand when we're evaluating tools, Naughty Dog has a culture that's very open, it's flat, and it's extremely creative.
It really lives and dies on collaboration, and flexibility is a key component into what really makes everybody successful there and ultimately creates successful products.
So we really were jumping into uncharted territory at the beginning of the project.
So we were, of course, rolling off of Uncharted 3, and this was 2012. The Last of Us was in full production, and resources were very tight. So it was really up to the art department to find solutions.
And like most of you are probably already familiar with, we were adopting physically-based renderings.
Of course, consistency and library materials were very important to us.
And as were material layering and inheritance.
We wanted robust libraries that artists could utilize quickly.
But the biggest thing that we knew we were going to run into was the scope and the scale of the environments and the props.
If you're familiar with the Uncharted franchise, you know that it's as richly diverse as it is large.
And we knew we had to be able to work efficiently and quickly and respond to changes on the fly.
So revisiting our culture and the needs for our tools, we really had to find that marriage between a standardized common workflow and still allow our artists to be free and creative and do what they do best.
And Substance Designer really fit the bill there.
So of course, we were looking at the time at Substance 2.5.
And it was really the start of an amazing relationship with Allegorithmic that we were thrilled to be a part of.
Not only did they help define our internal pipeline, but we helped inform some software design as well.
So it was a very special relationship.
And to have tools that really focus on the games industry and texturing in general was a big win, and very well-timed, too.
But of course, we started off with these very early questions of, well, can we really get high quality results out of a procedural and node-based system, as many of you are probably wondering or have encountered?
And can we prototype our pipeline?
Because again, our resources are tight, so we need to prove this out on the art side.
And can our internal artists and our vendors effectively use it?
Because there is a learning curve, right?
And it's node-based.
And not everybody responds to that.
So naturally, as you may know, you know, Uncharted is a very stylized but hyper real environment, and we hand sculpt and paint a lot of things.
There's a lot of pride and work that goes into every asset.
So it was natural to start in our ZBrush pipeline, and we simply took our height maps out of ZBrush, we brought everything in a substance designer, generated all of our material maps, and then blended our materials in Engine.
And it was very straightforward.
We could see that was very efficient.
So OK, well, that's great.
Now let's take those maps, and now let's prototype our material pipeline.
So let's look at how we can combine materials together, not just blend them, but find interesting ways to achieve material effects, like this rusted paint you see on the right.
So this was a very elaborate early prototype of a material layering system.
It's actually much simpler now.
But it proved to be very successful.
And of course now in practice, we have our height maps that are plugged into one of our early generators, this woodwork node.
And as we move through the graph to the right, you'll see we're blending a lot of materials and generating our final game textures.
And that was beautiful because we could simply swap the height map.
and tweak a few parameters. Whoops, too soon. Tweak a few parameters and you've got a whole new texture set. So the iteration and the speed and the power once you get things set up became really apparent. So we said, okay, let's take this one step further. Let's do a small scene. Let's really prove this out. And so we did that. We took a bunch of architectural and organic elements, made a lot of base materials. A lot of these are fully procedural or using Z brush height maps.
We also did a few props here as well.
And we thought it was largely successful at the time.
And this is the result of that.
While we were also doing that, it was important for us to gauge whether or not our vendors would respond to this. So with very little training and very little information, we actually did a test and were pleasantly surprised that it was a little bit of a hurdle, but the results were far exceeded our expectations. And we said, okay, this, we can move forward with this. So we were ready to take the leap. I don't know about that, though. I'm afraid of heights.
So now we have some implementation pipeline, so some implementation questions.
We need to turn this into a pipeline.
And we still need to really get the artists to rally around the procedural workflow.
There is still some hesitation.
But we also needed to standardize our asset packages.
And this is really important because we utilize outsourcing heavily for a lot of our props and objects.
So things had to come back consistent.
And a lot of times, these assets would go through changes internally.
And it's important that we utilize the non-destructive texturing aspects.
And our artists can quickly turn around changes.
So the next natural place to start would be to make a bunch of awesome nodes.
And the important thing about these library nodes is that they emulate existing workflows and applications that artists are already used to.
So the tools that you would use and software that you're familiar with, you would have access to right here inside Substance Designer.
And then we created some even more advanced ones that could do some material effects, like the chipped paint, and then some topology mask blending.
Ro's going to go into more detail a little bit about that later.
So we said, OK, well.
The workflow seems pretty straightforward. This is great.
We're going to use substance in the middle in the red here as our sort of content management system for a particular asset.
All of the required meshes, the Maya file, any bit maps, the high poly meshes, they're all going to get fed into substance and we're going to output our game textures from there. Pretty straightforward.
So we put a few restrictions on our sculpts.
So you can see on the left here, the primary and secondary forms are very well established.
And a lot of the surface detail in the sculpts are largely absent, because we're going to add that in Designer later on in the process.
And ultimately, that gave us the most flexibility.
We could take this asset, we could have a stone version, a marble version, or a wood version.
And so material IDs became really important.
And we used to have an old method on the left here that we would have a ZBrush plugin that would do mesh IDs for us.
Or you could use material IDs.
But it was kind of cumbersome until Designer released their name pair baking and their.
their mesh ID and their poly group ID bakers, it became very flexible.
Now we could just organize our assets nicely and automatically bake all of our IDs.
So we said, OK, let's just say we're going to use Substance as our baker.
And it gave us great results.
Everything was reproducible inside the substance package.
We got all of our bake maps here in the center, from world normal to curvature, tangent space, all the necessary maps.
And we, again, would output all of our game assets from there.
So we couldn't call a particular asset package complete until all those components were together into the delivery package.
The game asset, the high poly, any little bit of source.
And the important bit is that they were all tied together through substance.
That was essentially the little mini content management bit for each asset.
So great.
Mission accomplished, right?
Not so fast.
We have a lot of nodes now. We're starting to get a lot of assets. Management overhead became an issue, as did debugging and training, because we have a lot of standards in place. And then trying to stay on top of technical issues and updates became a challenge. And remember, at this point, we're still just an art team. So it was time to learn Python. So I rolled up my sleeves, right? And luckily I have the logic side, but not the math.
So the first step there, right, we want to automate this.
So let's compile the library.
And right away, this fixed a lot of the issues that we had.
And by compile, I mean take the substance source, the SBS file, if you're not familiar with this, and generate a SBSAR file, which is a black-boxed compiled node.
This right away solved a lot of the dependency issues we had with our external partners.
And it also meant we were source protecting our substance designer files now, which was great because we built a significant number of them, and some of them very complex.
And it might be slightly faster.
I don't know.
Sebastian might know.
Maybe by a millisecond or so.
So here you can see on the left hand side what a very simple asset would be where we're taking the bake maps, we're blending a couple materials, and you see that since it's red, that's an artist using the in-house nodes.
And on the, whoops, and on the right, you see that all the nodes are green, so that's gonna be a vendor using the compiled nodes.
Same results, same workflow, just different libraries.
So to manage those different libraries, Substance Designer allowed us to create custom configurations and project files.
And this became, this made it really easy in order for us to control what our in-house artists see and what our out-of-artists, out-of-house artists see.
But we also had a significant amount of software applications and configuration files to deploy.
It seems pretty lo-fi these days, but BatchScript was the best I can do.
And it worked really well, actually.
With one click, you got all the substance applications, painter, designer, bitmap to material, and everything was updated.
And there's a smiley face in the end, too, so that always makes you feel good.
This is one of my favorite shader customizations.
We're having some issues with the video, but the idea, are we?
Yeah, I'm not even gonna go there.
But the idea is that even the shader was customizable.
And what we're doing here is we're actually picking material IDs off of the model in the viewport, which for complex models you know would save significant time.
So that was a really nice win as well.
And I've been talking about substance being a little content management system.
And this is something kind of unique.
And essentially, the substance file is XML.
And that was awesome when we found that out.
Because now you can parse into it.
It's very open.
You can check for errors.
And you can fix errors.
So you can automatically, technically review and fix a lot of things.
So OK, let's take this automation thing a little bit further.
So we had a fairly robust Python package that was all just a bunch of, like, substance-related functions. And then we also used substance batch tools, which ships with Substance Designer. And this automated everything from our library maintenance, our SPSAR conversion process. We even automatically deployed a lot of our outsourcing tools so that burden wasn't on any of our in-house management team.
And then we also had some batch XML editing tools and I also would collect certain analytics. Unfortunately the UI didn't make it because I had to switch to art-related tasks. So it was largely me just, you know, running it in the IDE.
So we were in a pretty good spot to say, okay, you know, let's lock down production. This is really good. So a bit about our vendors. And this is where the amount of volume really comes into light.
So we work with about seven to 10 studios, and we're still working on these numbers.
As you know, we're finishing up production.
We're looking at about 3,000 assets that were done with our external partners.
And we estimate about 2 3rds of those are background and prop related.
So that's a lot of assets that are going through the substance designer pipeline.
So training became really important.
And ultimately, we tried a lot of documentation, but really, who reads documentation, right?
And example files, and then videos.
Ro and I did a lot of demos and time-lapse.
And those proved helpful.
But the important bit, you can see here on the right, is that the example files are all browsable in the library.
They are just assets.
But ultimately, what was most successful is we did a lot of in-house vendor training.
We actually flew some senior and lead level artists for a week or more.
And they spent time in the studio.
We were doing classroom sessions.
We also had in-house assignments and reviews.
And that proved to be incredibly successful.
And you can see here an example of what a typical asset package might look like. This is a weapon set done by original force. So this is what the artist would see upon return.
And this is a little more on the complex side, but the flow is the same. Materials are being blended, masks are being output, and there's a lot of flexibility in that graph. So what makes our back home or our internal workflows unique? Well, it's about the same, really, just a different library.
And again, we did a lot of internal training, and at this time, now that we have a lot of tools, our artists really embraced the workflow.
And our usage is, I would say, a majority of our artists have used it, but at different capacities.
Allegorithmic, also their own Jeremy, he would come up fairly often and do training sessions for us. And email updates actually ended up being a big win. Just weekly email updates, here are the library updates and changes. That constant communication during this growth process was really important.
And you can see our texture pipeline is actually very similar to our asset pipeline. Our 3D tiling scopes, they get baked inside Substance Designer, and all of our textures get output from there.
And here you can see these are actually all fully procedural base materials.
So not everything is sculpted.
A lot of stuff can be done fully procedurally.
And our character and our prop departments are actually starting to largely use Painter, mainly because of just how awesome it is to make masks and then do all of the runtime material blending.
So what does the future look like for the pipeline?
These are predictions, by the way.
I'm supposed to say that.
But we really don't know.
But we know that we need more base materials.
We wanted flexible tools that artists could use, but we didn't invest heavily in base materials because we don't want to black box anyone.
But we know that this is going to be a critical component to getting even more efficiency.
We're also looking at completely moving our vendor workflow over to Painter. And we're going to continue to automate the internal workflow, provide more deployable UIs, and really get these Python tools into the hands of the artists. So I want to thank you for listening to the evolution of the pipeline.
And I'd like to introduce my talented colleague, Ro, here, who's going to go into more depth. I hope you enjoyed it.
Hi, my name is Rogelio Olguin and I'm a texture artist at Naughty Dog.
And to get right to it, Substance Designer in its basic form is like Lego blocks.
You have different nodes and you just attach them together and get something magnificent.
So here's an example of a ZBrush workflow.
And what happened early on is that the pavilion of artists that came in were kind of scared of the initial tool because it's not like a traditional painting tool or like ZBrush where you end up being more artistic with like a pen or a Wacom tablet, for example.
So being a node based system, it initially was kind of scary to deal with. So we ended up making examples like this one where we showed how time wise we were able to do a color map and painting program.
The color map that you see there on the left side is, it took around like an hour or so, while the substance variations, all these three were around like 10, 15 minutes.
And here's a few more examples.
And as you see, this was when we were baking with X-Normal.
We bake now exclusively with substance.
So, in this case, we are also trying to see how we can do procedural materials and if it would fit our quality, our patriotic quality that we have in Naughty Dog.
This was one of the procedural materials, stucco, and basically you can get enormous amounts of variation and this was part of the vetting process.
So this is the same stucco generator and as you can see you can get plenty of variations from it. And then going back to what Brad was saying about this car, we actually ended up doing this layering process and vetting it because we are also working with our internal material system to figure out how we're going to layer all these materials into one asset We sent this same car to the outsourcing vendors so they can see the results and at the same time we gave them this test and we were surprised with the cars that they sent out to us.
And while looking into doing this test, we also found out some interesting tools within the node structure of Substance.
And within the node structure of Substance, we found adaptive masks like we're showing here.
And these masks would basically do is they grab information from like curvature, AO, world space, maps, or position, and you're able to move around the dirt or the.
grime and raindrops and stuff like that on top of it. Using these masks, you can mask away the dirt and or rust and or like, what is it, edge cracking and stuff like that.
this video doesn't work so I'll move on. Basically I was going to show the adaptive masks. And in this case, well, we ended up having a lot of discoveries. Things that we didn't initially even think were going to happen without our intention. This is one example of an asphalt flat material.
and it has an asphalt breaker attached to it.
Now what the asphalt breaker does is basically it breaks up the asphalt flat and makes it into, have all these kind of cracks.
So one thing that happened was happy little accidents.
We attached this asphalt, was a breaker, to one of the Brad's Substance rock material, and we were able to get a totally different texture that was not even intended.
And as we went on, these are the kind of things that just kept on happening.
Artists would come up with interesting things, and we would end up getting different results without even our initial push and knowledge.
And that's what makes Substance amazing.
It's like Lego blocks.
It's fun to play with, and at the same time, you get some amazing stuff just putting it together.
And well, greatness awaits.
This is a node by Jonathan Smith, a very talented texture artist at Nadia.
And this is a node that basically has a pattern node, and it goes into a stone carver node.
And what this does is that we can get multiple variations of this kind of material.
This node, as far as I know from talking to the artist at Naughty Dog, it was used in seven different levels in a very different context.
So when we see these kind of nodes just pop up, it just gives an enormous amount of variation and flexibility.
And the iteration process gets shorter and shorter because of it.
So we got to a point of no turning back. So the next images are from the E3 demo. If you guys remember for the chase sequence where the truck is going full speed ahead, et cetera.
So theory into action. Now this is a huge Vista scene and if you've seen that demo, the Vista scene is all over. Basically you can turn the camera around and it's going to be all around you. The artist that worked on this Vista scene is Artem and he did an amazing job of setting up the scene. Around 70 percent of this scene when it comes to textures was substance.
And these are various substance materials. Some of these went from C-brush workflow to the substance or fully procedural.
And these four are fully procedural materials. The cloth you can change it up and get more threading, less threading.
Change up the threading if you like. The same stucco and the same stucco combined with.
brick and rust material here. And all these you can change them up whichever way, change the color and et cetera. So we got to a point also that we are making all these awesome tools and for this demo specifically, since it was going to be a huge demo, we were able to get a lot of information out of it.
we had to do like patterns. In this case we end up making these patterns that could be used in multiple situations. This kind of pattern could be used for cobblestone but it can also be used for like wood by combining these nodes together. And this is an in game shot of that same cobblestone.
And we also did this for the city shape sequence. It was different kind of tiles for rooftops. We only have practically used probably two of these, but there's more of these. There's actually like seven or eight of these. And they're all based on actual architectural tiles. And you can make these look destroyed or clean, et cetera. And here's a few examples of them in game.
with the pattern showing where it is.
And here we're getting to the actual images of the level.
And in this case, there's a market sequence where you're battling it out, trying to get to your Jeep.
So here, what I want to point out is all the outsourcing assets that we have to do to get them into our levels.
A lot of these, actually all of them, are from used substance.
And this scene is an interior scene.
And I know that the artist, the texture artist that worked on this, Alice, as you see, the names below are the artists that worked on these scenes.
Alice, our texture artist here, did an amazing job of getting the quality for all the materials in here.
And she exclusively works with substance.
This scene for the downhill chase section, and this area that I worked with Zach Oliver, and everything here is substance as well.
There's another scene for the staircase sequence. I work with Jacob Norris and it's outsourcing a full substance.
And what's interesting about this one scene is that I don't know if you guys remember, it's a scene where the jeep is actually just pile driving through the staircase. And there's ‑‑ it's just like amazing how much detail is put into a scene that you're really only going to see for like 6, 10 seconds.
And right after that staircase there's a municipal area.
And there's a road that goes downhill and it's kind of like a community road.
And then we get into the vastness of the outskirts with more shanty town areas.
And you can see the art direction starts to change and it becomes much more saturated. These scenes are amazing actually. You can actually go and literally inside our game plop the character and she's walking around. This is great.
There's a place where Nate and Drake is dragging on the mud and hitting everything in sight. Another scene from that area.
There's a scene where the jeep actually tumbles over and Drake is trying to get out of the jeep and shooting the bad guys there while the evil truck is after you. And there's an industrial zone area where the grand finale for that scene. And then it goes into the cinematic sequence here.
So, yeah, I mean, this was all done with Substance, the demo, at least 80% of the assets when it came to textures were used Substance.
And I just want to say thanks to Algorithmic for letting us use an amazing tool.
And also to the outsourcing team, and props to Mark, our outsourcing manager, who has been amazingly patient with all of us dealing with outsourcing.
Thank you.
Thank you. All right. So that was amazing. I hope you enjoyed it. At the beginning it was not working. I have to tell you this. It's working now. But the tools three years ago were different than they are now. And thanks to these guys and a few other people in the studios, we've been able to make the tool evolve in such a way that it's really made for game developers.
I have to say a few words. So first, let me see. So it's not confidential obviously. But a few words about the road map for substance painter. So you've heard Brad say about painter and designer. So we have mainly two tools, substance designer and substance painter. So substance designer has been the hub tool and the management tool that the guys at Naughty Dog have been using a lot.
and painter came after this one.
And it's a 3D paint application, a little bit closer to what Mudbox, Mari, or 3D code can do.
So it's newer.
And we just released a version 2.0 today.
a few minutes ago. So if you want to have demos of both tools, substance designer and substance painter too, you can come to our booth at our booth 316, if I'm not mistaken. Not only will you get some demos from us, but also you will see more talks like this from Brad, from Rogelio, from Christophe and from and Glauco from Naughty Dog as well, from Lucas from Ubisoft, from other people, Josh from Infinity Ward, sorry. So you will have some more talks like this about how these guys, amazing talent.
use Substance for some of their creations.
So, a few words about the roadmap.
What will be added in 2016, or has been added already, like scripting features in Substance Painter, you will be able to, yeah, script things.
And it's available already.
You cannot do much right now, to be fair, but you can do some.
integration. We just presented it just a few hours also with NVIDIA. I don't know if you know that. It's a path tracer from NVIDIA. What that means is that right within substance painter now you can use the path tracer instead of a raster engine.
to come up with a beauty shot.
So if you're working on an asset and you want to shed the best light on it and potentially export that to Sketchfab or Artstation, now you can do that right within the tool without having to export all the maps and re-import them in a rendering application.
So you can do that right within the tool Substance Painter.
So it's a very, very nice workflow, look dev, look development workflow that you have now.
Layered material authoring and visualization.
It's, the visualization part is already available.
Again, we haven't, you can have demos about that.
So it's a little bit more technical.
So let's say you have a special type of shader that you're using in your game engine.
You can load it up.
I mean you can tweak it so that in the comments section, if I'm not mistaken, you make sure that Substance Painter will only display what's useful and will remap things here and there so that you can work within the context and within the constraints of that specific shader type you're using for your game.
So that's very, very powerful.
You can have demos on the booth as well.
So there's a new UI, new shelf, better quality content.
Obviously it's better now.
New painting tool, like clone and blur and smudge, that sounds stupid, like having a smudge tool or blur tool, but a clone tool.
But the thing is that Substance Painter is a fully non-destructive tool, which means that it's, when you actually use the clone tool.
Whatever you cloned, if you do a modification on what was cloned originally, it will follow the steps.
It will follow the clone steps.
So if you say, cloned a, I don't know, a part on a hard surface, if you want to change the screw, if you change the screw it will be repeated for you automatically. So that was kind of complicated to actually implement and we're pretty, pretty happy with it. Sub surface scattering, we have a fake one. At least you can do some.
And that will be coming, these two items are important, and 8K painting and UDIM support.
So we currently have an 8K export, it's hidden somewhere, but we don't talk about it, but it's an export function.
And it's because when you want to paint in 8K, to be fair, it's a bit laggy, so it's not a great experience, and we don't like the fact to not having our customers users have a bad experience with the tool, so we prefer to hide it for now.
So 8-bit painting, full painting will come eventually, we're working on that.
And we're not only hoping about the fact that hardware will get better, so we're actually actively working on it.
And UDIMM support, I don't know if you know what UDIMMs are, it's basically a way for you to not having to care about the...
the amount of data and texture information you want to paint on your object.
So you can get crazy with that.
It's a standard in the visual effects animation fields where they really want to have the finest details on every nails of King Kong.
So now if you want to have like the finest details, like 8K texture on the nail, each nail of a character, you will be able to do that.
So that's, I'm very happy.
Substance designer, same thing, scripting features are already partly here and will get stronger. This is a biggie here.
I mentioned the fact that we've integrated IRAE inside of substance painter. IRAE relies on...
Something that is maybe not more important, but super important, which is the MDL, is material definition language.
So this is something NVIDIA is trying to push now.
It's open material definition language.
It's been missing in the industry for years to be fair.
And we certainly hope, and we support it at least, and we think it has the potential to become a real standard.
When you want to describe full materials, not only textures, but materials, not shaders, it's between the textures and the shaders actually.
There is no lighting information instructions in the EMDL.
But if you want to define what makes a material, MDL is the, we think it's a good solution.
So we're turning basically Substance Editor into not only a texture editor, but also an authoring system, but also an MDL editor.
So we're adding one more type of graphs.
There were a lot of them already.
it's going to be a new type of graph that will let you define the materials on top of the textures.
And these materials can then rely and refer to textures that are minified by substance designer.
So you can get crazy with that.
Hard surfacing tools, we definitely want to have something like this.
Text tool, again, it's been missing.
But we want to make it right, again.
We want it to be really non-destructive.
the way it should be.
We're working on that and enhanced viewport, obviously having a better viewport.
You already have one-one parity with Unity, Unreal, all the best engines out there.
Because we basically use the same underlying principles.
And we also have been working closely with these guys.
So we made sure that what you see in Substance, either painter or designer, is what you will get eventually in Unity or all the other good engines.
Yeah, that's pretty much it.
So I guess time for questions.
And thank you.
Before the questions I want to thank you guys again. I cannot express how proud I am today. And really glad to have you here.
So thank you again. Any questions?
Yeah.
We will have to repeat the question, I guess.
So your question was, did we use it on the terrain textures?
We did, actually.
Ro can probably speak more about those particular terrains.
But we've used it on a number of different surfaces, from hard surface materials, organic terrain materials.
really, we've used it just about everywhere across the game.
Yeah, most definitely. We've definitely used it everywhere.
We also used World Machine. And I didn't do a lot of the whites, which are like the huge, you know, expansive vistas that we see. But the artists that did use World Machine and used the substance as well for the tile and materials that the masks were created from. So we definitely did use that.
There's a line. So there are mics here. So if you want to ask questions, please line up.
Hi. I have a question regarding the analytics. You mentioned that as part of your automation package you were gathering analytics. If you can elaborate on what kind of analytics you were gathering and how they were useful eventually?
Absolutely. So your question was what kind of analytics did I gather and how was it helpful? They were very basic. At the time I was really curious about what type of nodes people were using and what was working and what wasn't. Because we were really figuring all this stuff out. And one important thing I found is that really complex Uber node uber nodes weren't being used heavily. It was the small modular ones that allowed people to do one simple thing very well that were being used across a number of assets. So it was really just about how to better build a library of nodes.
Thanks.
Thanks a lot, great presentation, really enjoyed it.
I was wondering the enhanced viewport.
Can you get closer to the mic, sorry.
Yeah.
The enhanced viewport, is it possible we have our own lighting model and our own engine?
Would it be possible to adapt the lighting shaders as well?
Look at the what, sorry?
Can you repeat?
The lighting model of the viewport itself.
The lighting mode of the viewport itself?
You mean changing the lighting conditions and adding lights and that kind of stuff?
Well, we support Unreal and Unity.
We have our own engine.
Would it be possible to hack into the lighting shader somehow and try to get some results?
I don't know, actually.
Well, we would.
talk about that after. Go ahead. Sorry. I want to add one thing to that. It is just, it's open GL, right? So we were able to customize a very few things. We changed some of the energy conservation. And then we did a lot of weird things. I wish I could have showed you. We were able to pick material IDs from the view port. So anything you could do in open GL, we were able to do inside of the view port shader. I managed to find a compiled open GL shader.
No source.
What's the question?
Sorry.
Can you repeat the question?
Can you get closer?
I indeed found the viewport shaders, but I managed to only find the compiled version, and I couldn't find the source, really.
Oh.
I'm digging through the files.
They're actually in, they're somewhere installed on the system.
It's all open.
You can actually open it up and see what's in there.
I think it's in the app data location.
So it's open to a certain degree.
So this is why I needed to hear more about your issues.
All right, we'll talk later.
Sure.
Cyril.
Sorry, hi.
I have to apologize for my English first.
Sorry.
Two new questions.
What's the standard resolution of your textures in the game?
Well, that varies.
Depends on the project and what we need it for.
Most of our materials, we cap them at 1024.
that's what we've gone for. But when it came to memory management and stuff like that, we would have to bump them down to 512 or et cetera. And sometimes the quality was enough at 512. But our standards stayed at mostly 1024s.
and you can generate them at upper resolution because of substance. Each time if you want to make more HD textures, you just have to switch parameters. There is another... you know what I mean?
Oh, you mean like runtime?
Not runtime. If you want to... in the next Uncharted, if you want to use...
I don't know, on the PS5 you want to reuse all these materials because it's a very big problem.
You have to rebuild all your materials each time you switch your game.
And now you can make a material and then use it during five years, six years.
It's not deprecated because you can regenerate it with a better resolution.
Yes, I mean that's really the deepest core that we don't even understand.
That's like the future of substance.
That's a good question because we currently don't know how much it's going to expand.
I mean the tools that we're making now just keep on growing.
It's predictable that we're going to use many of these tools and our textures into the next game.
And that's.
And just because you mentioned one, World Machine, it's a software I used a lot, and I love this.
But it's very close to Substance Designer.
Finally, there is a fabulous blog called Erosion to make turrents.
And I was many times asking to myself if I have to rebuild it in Substance Designer to not use the world machine anymore.
Did you try to replace softwares with Substance Designers?
I actually, it's funny because I actually did a test.
very early on. Yes, you could. I don't think we went there because it wasn't practical and why remake the wheel if it's already done well for that example. Even though I got a really cool result from it and I was very proud of that initial node, it was a terrain node that could have expanded into something more but at the end the world machine did an amazing job for us and that's why we stayed with it.
Okay. Thank you very much.
Hey, so my question is for your foliage in world, did you guys use substance for that or was that a more traditional workflow?
That's a separate workflow. I'm almost wondering, I don't want to say too much about it because the people that worked on it are extremely talented. I almost want to leave that information for them. But there was some foliage that did use substance and some of them used a different work flow that's not necessarily see brush either. So I kind of want to leave that to those artists. Okay. Fair enough. Thanks. What's up, guys? I guess I sort of have a related question. And I'm just curious if did any of these like procedural texturing stuff with substance, the libraries, did that affect your character art at all? Did that or effects for that part of the team?
So your question was did the libraries and the workflow, did that go into the character department?
Yeah, did the character guys use it?
I'm supposed to repeat the question?
So it did, but to a different extent.
And Ro kind of touched on this with the foliage.
There was a lot of different pipelines within the art department that were being developed in parallel.
So what we covered is largely background and prop related.
And the character needs, while they're conceptually similar, are very different in a number of respects.
They actually ended up going more toward painter as soon as that was released because it's just a much more fluid, artist-controlled program for their type of work.
But that isn't to say that designer still has a very real use in the content management side of things and the baking, and I would like to see more of that for sure.
Hi, I'm interested to know if you've got say a metal shader in Substance and one day you go, we want that to be more shiny and you've got shed loads of materials using it.
If you've got some kind of workflow that can change everything that's using that metal to be more shiny and get it into your editor.
So your question was how do we propagate changes to everything in the editor if we're using the source.
Is that correct?
Yeah.
Brute force.
And many, many times.
And it sounds bad, but the reality is that we did standardize a lot of things.
But oftentimes when you get into the game environment, lighting conditions, g-buffer precision, you name it, there's a number of things that just create different results.
And it was easy in a lot of respects to go back to the substance package, re-export a modified output, and you're good to go.
Or we could also override things in our proprietary shader editor too.
So both of those methods proved to be really flexible at the end when you're really polishing.
Right.
To add to that, we do have an inherited base, the layering process in our shader system.
So if we were to take that one metal material and inherited into another material, then it doesn't break the information, the information goes with it, but it doesn't affect the hierarchy of the main material. So I'm able to change that metal and make it less shiny in that layer that's been put in. So that would help in some of those situations in our pipeline.
Hi.
Hi. So, in the way to build the library of materials, did you use a real reference with a character, or have you a more artistic way about the look of the materials?
I'm sorry, can you repeat the question?
Did you use references, like real life references, for coming up with the materials?
Yeah, you know, I actually cut those slides out.
What is the start of your materials?
Is it a physical reference of a reality, or is it more a vision of an artistic way?
It's actually a little bit of both.
We started with a lot of data.
In fact, we went out and we captured a lot of color calibrated photo reference to try to get accurate albedos.
A lot of material presets for different shellac and paints.
And I could nerd out on that stuff all the time.
At the end of the day, it wasn't getting the game done.
And ultimately, it came down to just let's just make tools that allow people to make awesome art.
And ultimately, that's what we did.
We had that data and reference to fall back on.
But for artistic control and also game limitations, we relied heavily on just our intuition and eye.
Yeah, nothing to add on that.
It's basically that.
Well, the conclusion is that you can do ugly stuff with Substance Designer as well.
It's a very capable tool for this as well.
Not a joke.
Just ask me to do something, for instance.
Hey, guys.
I know that your style is pretty stylized and that you do a lot of your detail sculpting first in ZBrush before you actually texture it.
Did you find yourself having to compromise on your style so that you could keep the efficiency of Substance Designer when you try to make the change?
Or could you still do your style in Substance Designer?
That's an interesting question.
I mean, it's a.
With ZBrush and changing, well, that's the thing.
Not everybody changed entirely to Substance Designer.
Our workflow is very open, and we enjoy seeing what the artists can put, because we have amazing artists, and many have different techniques.
And Substance being almost like a hub system, where everything eventually will get to Substance, to get into our engine, is part of it.
Yes, being in a stylistic game, we realized that we needed to test it further.
And as we tested it, obviously now at this point, we're very happy with the results.
We were able to get that painterly look within substance and almost eliminate the sense that these materials look procedural.
And that was quite a challenge initially, sure.
The learning curve, not all the texture artists had.
and have gotten to that point.
There's still many texture artists that go through the ZBrush workflow and then finish it off in Substance.
I'll add one small thing to that, too.
And that's when it came to the library nodes, that's really why it was important to focus on what our core workflow was.
So instead of creating like a make this thing painterly node, it was here's a color scheme generator.
Here's like an oil wash and like a direct opaque painting layer.
It's very traditionally based.
and it was really derived from existing workflows.
So it felt like a natural transition.
That was really kind of the goal.
Right, thank you.
Thank you.
More questions?
All right, one more.
Hi.
So I'm a modeler, and I have some questions about how you handle smoothing groups while you're texturing with substance.
Something I get stuck with a lot is using either one smoothing group for models or multiple smoothing groups.
I was wondering how you guys deal with that, when you use one smoothing group and when you use multiple.
your question is about how we handle smoothing groups. I assume you're using 3D max? I can't weigh in on that.
Well, I haven't used max in a long time. You're talking about the baking as well. So, you know, I can't weigh in on that.
you've got to make sure that the tools are in line with each other. What we did in studios is we used Maya. So we made sure with various tests that Brad and I and many other artists did is to try to find the gotchas of getting a good normal map fake.
and that was the situation that was really kind of in pre-pro.
And once we figured that out, that same workflow, step-by-step, was sent to the outsourcing team, and obviously we have it in-house as well.
And that will be the most important thing, too.
If you're trying to get substance into your workflow, make sure that the tools are talking to each other early on.
That way there's no surprises.
I use like, I watch a lot of the tutorials, algorithmic, which are great by the way.
And they kind of teach that like, one of the models they use is one entire swimming group.
And that works out for a lot of my models.
But I was wondering when you, when you decide a model doesn't have to be one swimming group because the normals will get weird, the normal net for instance.
clarify anything of that? Maybe Jeremy who is here. Maybe you can answer. Come up. Jeremy, he's the guy. He's the guy. He's the guy. He's the guy. He's the guy. He's the guy. He's the We spent a lot of time at Naughty Dog.
But I'm a previous Maxi user, so I can actually answer that.
So it really depends on your preferences and on the type of model you're using.
If you're doing something organic, usually one smoothing group for everything is fine.
Because even if you have some messy gradients on your normal map, it won't show in the game.
As soon as you're doing hard surface stuff, you may want to do actually hard edges and kind of split things up.
Especially when you're using, for example, math generators, that kind of thing, that are based on the normal map.
They will interpret the normal map to create a mask, for example.
If you get too many gradients on your normal map, did that just account for the smoothing errors?
Then your math generators may get you some weird results.
So it's really up to you to see what type of assets you're generating.
Do you see any artifacts with your current method and adjust as you go?
There's really no absolute rule about it.
learning a lot. Yeah, it's really like learn as you go.
There is no easy answer to that. I got one more question.
Actually, sorry. Before we get to our question, there is actually, if you guys are familiar with poly count, there is a wiki there that shows a lot of different baking techniques and it also shows a lot of great tips on how to bake in general.
So it might be one thing that you might want to look into is polycount.com and they have a wiki and right there they have many pages with many amazing artists dealing with this issue and they might actually have that information for you right there.
That's a good one.
So my second question was did I understand correctly that you only get height maps out of ZBrush or also normal maps?
Excuse me.
I personally, these days, I actually just export 3D models out of ZBrush.
So tiling textures and props for me are completely baked in Designer, just because of the type of maps that I can output there.
And it's a much more flexible workflow.
Thanks.
That's gone.
Good one.
Maybe I have a simple question or a request.
Since you're creating the geometry typically like coming from ZBrush, that's obj, and then we're adding the substance for the material, why don't you come up with a file format for simple shapes with their material, and we're done with that?
Thank you.
I like that idea.
Yes.
All right.
Hi.
So I was just wondering if did you guys get to try using photogrammetry into your texture pipeline?
And if you did, how effective was it?
I know in our pre-pro, we then tested out.
We looked at it.
And I think when it comes to Naughty Dog's artistic technique for how we arrived to these textures.
and a painterly approach, and especially the type of environments we make, these materials are not easily found. A lot of these materials are things that you probably won't even see in the actual world, so it becomes harder and harder if you're going to approach, especially with stylistic games. But there is a lot to gather from that. I mean, there's many amazing games that have done it.
have mentioned it and it's something to look into in the future for sure.
It really is a labor of love and that was one thing we really wanted to stay true to is just the artistry behind not only the tech but ultimately that hand painted, hand sculpted feel. So we wanted to stay true to that.
One more question.
We don't have no more questions. Sorry.
Thank you.
Thank you.
Well, thank you.
Sam, come on.
Sorry.
Thank you.
