Hey everybody. Thank you very much for coming. My name is Karim Schuman. I'm in the Audio QA department at Bungie. This is the talk. I hope you can read it. It's pretty big. So just a few quick things. Please silence your phones or put them on vibrate.
It doesn't look like we're gonna be super packed so you don't need to move into the middle or anything.
Also, at the end of this talk, you should be receiving evaluations in your email.
It would be really great to get some feedback.
So I'll try to remind you again at the end.
All right, let's get started.
We got a quick, fun intro.
Bungie is an exciting place to be.
Everyone's always looking forward.
Everyone's always thinking, how do we take destiny and evolve it to the future?
Leave them wondering how the hell you did it.
Bungie as an audio team has always had a hyper attention to detail.
That's a key part of the mantra of what our team is about.
We each bring something to it that wouldn't be there if we weren't here.
We work well together, we challenge each other.
Being a part of a much bigger team is exciting because there's a lot more collaboration and iteration on ideas.
You're constantly trying to achieve something. You're trying to get to a higher place.
It's a big goal and a big accomplishment to create a universe from scratch and then make it sound like that universe.
I really enjoy working with the people here.
It's been a fun ride and the ride's still moving.
What a great place to be.
Awesome.
So I have the distinct pleasure of working with that amazing team.
For those of you who don't know, let's quickly go over.
Destiny is an action shooter developed entirely by Bungie.
Rise of Iron, which we're going to be talking about today, is our latest expansion, which was released September 2016.
And for the audio professionals in the room who are curious, we use Wwise middleware implementation.
That's how we handle all of the audio going in and out of the system.
So what are we talking about today?
This whole project, which eventually turned into a presentation, started with a conversation I had with our audio producer, Victor, who is somewhere around here today.
And so my question to him was, what is the most painful part of development for our audio team?
And his answer was the mixing process.
And his reason for that.
was that our audio team tends to lose a lot of time dealing with issues that are not audio issues.
They're running into roadblocks and problems that aren't things that actually have to do with making it sound good.
And overall, because of various time factors and the way that the mix process works, it could get stressful for our team.
Now, for those of you who don't know, this is sort of a cross-pollination talk.
We've got people from all different fields in the room.
I'm going to quickly go over what an audio mix process is.
It basically occurs at the end of development when all of the sounds and music and dialogue is already in the game, but that doesn't necessarily mean it sounds great already.
A lot of work needs to go into making it feel cinematic and natural.
So for example, let's say there's a cutscene of two characters having a conversation and they're standing next to a river.
You do not want the sound of that river to be louder than the conversation to the point where you're having trouble understanding what the characters are saying to each other.
Even if it's a really big river that's rushing by and that might actually be more true to real life, you want something that's a fun cinematic experience.
You want to be able to hear that river.
But an important part of the audio mix is to make sure that what's important is louder and clearer than what's unimportant, even though we want to be able to hear and experience the whole scene.
The audio mix also involves a lot more than just volume manipulation.
It involves adjusting timing of various cues, it involves checking frequencies and making adjustments in that way as well.
It can even require going back to the drawing board at times, which is rare, it's sort of a last resort, but if certain sounds are regularly occurring in conjunction and that's not something we were hearing during the sound design process.
It might be something that's coming up in the mix and one or two of them might need to be reworked before they can be finalized.
So because of all this delicate audio work that needs to go into the final mix...
And it needs to happen at the final stage of development, when all of the sound and music and dialogue is already in the game.
Mix requires that our technicians are working in balanced audio rooms, full 5.1 surround sound, speaker setup.
So kind of like the image that you're seeing here.
It's one of our specialized audio rooms in the Bungie studio.
And it also requires our team to be playing and experiencing all the new content that we release for a project.
over multiple playthroughs. It's a long and intense process.
So the mix is handled by the audio leads at Bungie. With a lot of help. We have help from our head of audio, head of the entire department, our music director, our dialogue director.
There's a lot of input that goes into the process, but primarily it's being handled by our audio leads first and foremost.
We had three weeks scheduled for the mix process on Rise of Iron.
One of the biggest challenges about this for our audio leads is that when they switch from creating content to mixing content, they're suddenly put in a position where they need to be experiencing content like a player.
So if you take a look at the slide, which is just a super quick breakdown of part of what the audio dev process looks like for our team, you'll realize that Everything that occurs before the final mix doesn't actually require them to be playing the game like a player would.
They do go into the game engine, they go into test maps, they make sure that their content is functioning the way it's intended to.
But the final mix requires them to actually progress through the game and simulate the player experience.
And that can be challenging to suddenly be put in a different sort of work mindset.
On top of all that, time is really precious, and I can't stress that enough.
It's...
the last three weeks of development, and that deadline is a hard deadline.
It's close to ship, and everything needs to be as polished as possible.
So previously, what had been occurring and what Victor communicated to me in our original conversation is that a lot of time was being lost navigating in the game.
And we're going to go into that more deeply in a minute.
As well as that, multiplayer content, which our game has quite a lot of, proves extra difficult during this process as well.
And so my project can be summarized into two basic goals in order to improve this mix process.
I wanted to organize audio play tests to facilitate and improve our multiplayer experience and mix process.
And I ended up customizing tools that we have internally to make the work easier overall for our audio leads.
So let's get started with part one, multiplayer.
So Rise of Iron, the expansion, included plenty of multiplayer content.
Audio mix decisions in this type of scenario must be based on real gameplay.
So imagine you're one of the audio leads and there's a new PvP mode that you want to be mixing and you're in your specialized audio room and you load up the game, you load into the PvP map.
and you're running around and you're like, yeah, all the new sounds sound great.
Is that analogous to a full 6v6 12-player PvP experience on that map?
And the answer is no.
And of course, our leads know that.
It's just difficult to fully replicate the scenario.
No one before this had taken ownership of audio play tests.
And so while they did occur, they were inconsistent.
Now, to be clear, playtests at Bungie are very common.
We have a lot of balancing playtests and design playtests that occur, especially with our PVP team and our raid team.
A lot of work goes into that.
We have designated playtest areas.
The issue is that audio mix playtests come with added difficulty on top of that.
It involves connecting rooms digitally so that we have the playtest rooms where we can have large groups of people connected to one of our audio rooms where one of our audio leads would be making adjustments and improving the mix.
It involved planning a lot of extra time as part of that and reserving those rooms.
It also required support from other teams.
It required having those playtesters who handled the PvP content, the raid content, and getting them on board because we needed their expertise and we needed butts in the seats to really fill out a whole 6v6 experience and get a realistic scenario for our audio leads to make real decisions.
And so mostly this was an issue of timing and communication.
And it also involved a lot of explaining the importance of what we were trying to do to those other teams.
I mean, if you're in the audio department of whatever project you're currently working on, you know that you have to be an advocate for the importance of what we do.
And sometimes it can be unclear to those who aren't as experienced with working on audio.
So, scheduling a big thing and taking time out of everyone's day to say, hey, we're going to do an audio mix play test for the new PvP experience, a large part of what I was doing was answering the question, what, why, what is that, and why do we need to do that?
And so previously our audio leads maybe didn't have the luxury of sort of sitting down and making sure everyone understood what we were doing because their time was so precious this close to ship.
So, best example of multiplayer that I'll be digging into a bit deeper is the raid that we released with Rise of Iron, the Wrath of the Machine raid.
So for those of you who don't know what a Destiny raid is like, it's a six-player co-op experience.
There are giant boss encounters, rooms after rooms, jumping puzzles, and a lot of unique content, unique mechanics.
And so of course as a result we have a lot of unique sound design that goes into that and a lot of unique music that's triggered as you experience that content.
So it was really important.
This was one of the biggest elements to the release for the audio team.
with the new expansion.
So, allow me to show you why this type of content is extra challenging for our team.
I'm going to show you a video.
It's one audio lead.
It's an example of one audio lead trying to mix the final boss fight of this specific raid.
And they're fighting alone.
They've got a debug command inputted into the game, so they're receiving no damage.
And they're just trying to experience the final boss fight to make some audio decisions.
So, let's take a listen.
Okay, so that was a mess.
One of the loudest sounds in our game is getting shot.
uh... regardless of whether or not you're taking damage and there are enough enemies in that encounter balanced and designed for six players working together okay so all of those enemies based on their AI scripting were just targeting the only player in that scenario as a result of getting shot all the time not being able to really move around or hear ambience the external cues that are occurring It's really, really hard for our audio team to experience that content solo and really improve the mix based on what they're hearing.
So, here's a quick clip of the same encounter with a full team.
This is how the content is supposed to be experienced.
So that's the audio goal.
There's a lot of moving pieces, as you can see.
There's specific audio cues, and they need to be balanced with the overall experience.
It's very complex.
And so the first workflow upgrade was scheduling consistent audio mix playtests.
It was mostly a task of coordinating and planning.
It started with us on the audio QA side attending regularly the PVP and RAID balance playtests.
that meant we got lots of players experiencing the content as a group.
Another interesting effect was that they were playing like real players.
This was content that they were familiar with, that they knew how players would play it in real life, and they weren't running around in the game like our sound designers do, where they get all excited about the new thing that they made, and they're like, ooh, look, we can do this, and isn't that great?
And then you get people who are playing the game like real players, and they're running the boss fight real fast in real time.
This allowed our audio leads to get an improved perception of what the game was going to sound like at full speed play.
Overall, this proved very valuable, and we continue to expand on audio mix playtests today.
We're starting to do them earlier in development.
It's really an important improvement that we made with our workflow.
So part two, improving the tools to make the mix process easier for our team overall.
During Mix, time was lost just getting around.
And the reason for that is because Destiny is big and complex.
The leads want to access all the new content quickly.
They need to get to this specific scenario.
They need to hear this specific mission.
But unlocking and accessing content in our game is challenging.
So...
Here are some examples of how content naturally unlocks in Destiny.
It's just some, there's more.
Each item that you're seeing on the screen is tied to, in the engine, a hidden flag.
When you complete a mission, for example, you flip that flag, you trigger it, and it allows you to then access the next piece of content behind that.
Of course, working in development, we have debug commands that let us specifically trigger these flags without actually having to complete the content and play the game naturally every single day.
during development, those flags can change, those debug commands can change, more implementation occurs as we move closer to ship date, the build becomes closer to what is actually going to be released, and so it becomes more and more systematically set up for those flags to be in place and functioning.
where it's more like the player experience and less like the creation experience that we get used to.
And so leads wouldn't be encountering any of these challenges before they started working on the audio mix.
What I was saying before, that their work before working on mix is not based on experiencing the game like a player.
They're working in their DAWs, they're working in WISE, they're working on test maps, but now three weeks before ship they need to work on the mix, they need to be experiencing it like a player, and that means moving forward and experiencing one mission or one section as a player would.
And that meant dealing with all of these flags quickly and effectively.
So the goal was getting around and returning to specific states day after day as they iterated and improved on the mix process.
This is how our devs got around in Destiny before Rise of Iron.
Dev builds, all of our dev builds include command lines.
The challenge with that is you need to actually memorize every debug command that you want to send into the build.
That comes with its own challenges.
Most people use our debug menu, which is the image that you can see on the screen.
Now the debug menu definitely works.
It uses controller shortcuts, so it's regardless of platform, you just have a controller plugged in, you press a series of buttons to open up the menu and you continue to use the controller to navigate through those menus.
It's basically a series of nested menus, like a folder sort of structure.
It can be pretty slow navigating through it.
We're going to have a video briefly just to give you an idea of what it's like to move around in it.
It can also be hard to find what you need sometimes.
Most of our devs, they get used to going to specific audio locations where they know it has debug commands that they need, but if it's something new or it's something they're trying to deal with a debug issue that they don't normally deal with, it can be very challenging to navigate if you don't know where you're going.
And also, it doesn't include everything.
When a flag got changed, that doesn't necessarily mean the new debug command required to handle it was going to appear in that menu.
So here's a quick video just to give you an idea of what it's like.
You can be in-game, you can press the shortcut to open up the menu, and you can use the keypad to move up and down and hit confirm to enter a menu, turn on a command that you want, hit cancel to go back, select a different one.
And that's just the general concept of what it's like.
So.
To improve the process, I focused on this tool specifically.
It's a dev tool we have at Bungie called Guardian.
There are a couple caveats here.
Caveat number one, this is an internal tool that we use.
I had to sneak out just to show you this much.
So make of it what you can.
Caveat second one, I did not make it.
I customized it specifically for our audio team, and I'm going to go into how in a bit more detail.
But many thanks to the Bungie Tools programmers that we have, an amazing team, for not only creating this tool, but also including with it all the tools necessary to customize it for each team's use.
What I'm hoping that you'll get from me explaining all of this are some of the concepts and usage and feedback that I received that will hopefully help you with whatever project you're currently working on or will in the future.
So Guardian handles a lot of different functions.
We're not going to get into all of them.
It runs on a PC, that's important to know, so it's controlled by the mouse, and it connects to your game client regardless of what platform you're on.
So you give it the name or IP address of whatever dev kit we might be working on, and it can connect to it, recognize our game client, and allow you to make changes.
Specifically, the element we're going to be talking about with Guardian today is the command assistant.
And again, getting around in Destiny is hard, so the goal was to use this tool to improve accessing the content and make useful debug commands accessible with a single click.
This is Guardian's command assistant.
It's what it looks like.
If set up properly, Guardian can replace the need for the debug menu of the video that I just showed you.
It starts off blank.
So I created all of the buttons that you're seeing in front of you.
Basically, behind each button when clicked, custom scripts send multiple debug commands to the game client that you're connected to.
And so it's organized and created with the intent of easy functionality, grouped based on how the devs actually use those debug commands, specifically the audio devs.
So one of the other excellent features is that as soon as this was finalized and saved, I could automatically share the entire page of buttons with the whole office.
So the next time anyone in the office closed and reopened Guardian, it would automatically make this page available from them from the dropdown of buttons and command assistants that are saved into our system.
Before this, there had been no audio command assistant page.
Before this, no one in audio used Guardian pretty much at all.
But based on my experience, I was the one who believed that it could make things easier and faster, specifically when it came to the mix process.
Quick tangent.
Maybe you don't know what kind of debug commands are useful for an audio team.
And so I'm sort of going into all these debug commands, and you're wondering, why is this so useful and important?
So if you're a tools programmer, maybe, or an audio programmer, maybe you can look into creating some of these debug commands and tools for your teams.
If you're an audio content dev and you've been struggling with your own process, maybe you can ask some of the programmers on your project for some of these excellent tools.
So let's get into it a little bit.
Antimeters, this is my personal favorite.
It's used a lot by the audio team.
It basically puts, if you look at the bottom half of this image, you'll see some blue debug text that you will not see in the game normally.
This text includes the name of the event that's being triggered, the audio event that's being triggered by Wyze.
And it's placed directly over the object that is triggering it in the game.
This proves extremely useful as we navigate and we encounter issues.
We're searching for bugs.
We want to verify that a specific weapon, for example, is making the sound that that weapon has, the sound that that has been designed for that weapon.
So on and so forth.
It's extremely useful for quickly understanding why something is not sounding the way it's supposed to sound.
Distance, occlusion, obstruction, basically anything that gives us visual feedback of what is happening in the audio engine that Wwise is trying to create for us.
Whoa, I need to hurry up.
Okay.
So distance, occlusion, obstruction also adds some of that blue text.
It lets us know how far away things are from the camera as they're being triggered, lets us check falloff distances, things like that.
Environment info brings up a big blue window like the one you're seeing here that tells us what ambience loop is currently playing, what reverb settings we are in based on the environment.
Material info is this exact blue window that you're seeing.
Based on where your crosshairs are placed, it will let you know the exact material name, which gives us a lot of great information for gunshot impacts and footsteps.
And we also have a bunch of commands that let you wander around without actually playing the game.
So things like turning off damage, skipping ahead in a mission, these are all super useful for us, especially in the mix process.
Incorporating our favorite debug commands into Guardian.
Again, function and layout needed to be intuitive.
I spent a lot of time working on iteration.
It didn't come out perfect the first time.
A lot of changes were necessary at first.
Once it was completed and in a state that I thought it was actually useful and better than what we were currently doing, I then had to teach.
With the help from Victor, our audio producer, we had a demo for the audio team where I went through with Guardian and showed them, went through the paces and showed them what it was capable of.
Then in the next office-wide play test that we had while developing Rise of Iron, I went to each of our content creators' desks.
I had them load up Guardian.
I gave them a couple of examples of how it could allow them to navigate the game.
And I asked them to try using it if they wanted to use any debug commands instead of the debug menu that they were used to, just to give it a shot.
I also, throughout the process, was offering to take requests to make new buttons.
Each individual dev might have commands that they used, shortcuts that they wanted that would improve their particular process, and I was always happy to incorporate that.
Once questions and ideas for improvement started to arrive in my email inbox, I was really happy it meant they were using it.
And overall, just a quick display here.
It's organized by columns.
Player setup allows you to sort of skip the character creation system when you're loading up a new account.
Gameplay changes allow you to turn on things like turn off damage, increase your ammo, your ability, recharge rate.
Debug client allows us to turn on all of those debug texts that we were talking about in the previous slide, music information, ammo, investment shortcuts.
This is the general assist page that I made that continues to be useful for us throughout development.
So here's an example of Guardian in use.
So we've got Guardian page on a PC on the left.
We've got the game client running on the right.
We're in a very specific scenario.
I'm going to pause it real quick, because I forgot to explain what we're trying to do.
So let's say you're in the mix session, and you made a change the previous day.
It's a new build.
You want to check to see how it's working.
So you change the falloff distance and volume on a specific sound that only occurs at the end of mission 2.
Some monitors turn on, and you made some changes.
You want to see if it's working.
So.
This is the process that we're going to go through.
The first thing we did here was we selected Mission 2 from one of the command assistant pages.
And so now we've already started loading in to Mission 2 on the screen.
You're going to see the ship take off.
Now we're going into player state, and we're turning off damage.
So we don't have to worry about getting killed while experiencing the sound.
Now we're going into the debug client column.
We're turning on event emitters, so we can see the sound names.
And we're turning on distance emitters, so we're going to be able to really check the falloff rate based on the camera location to where the sound's being emitted from.
Now we're just waiting for the ship to actually load into the mission, and you can already see some of the blue debug text in-game.
This is all fully connected but running on two different screens.
We've set up the phase jump command.
We're going to skip ahead to the end of mission two.
We don't want to play through the whole mission, right?
So we're skipping ahead to the final phase.
Now we're in the game.
We've got all the debug text we need.
We can pick up the controller and immediately move to the section that triggers the monitor sound.
So we open up our ghost.
We're seeing all the debug information playing over the sound.
So we know what's playing and how far it is from the camera.
Overall, on 100K, would that be enough to figure out why it was falling apart?
And there's that unique sound that only occurs in that part of the game.
We wanted to make sure that the changes we made yesterday were sounding good today.
And that's the process and an example.
That video took a little over a minute, and a lot of it was spent loading into the zone, skipping ahead in loading the final phase.
Before Guardian, according to my conversations, that process could have taken 10 to 15 minutes.
Repeated dozens of times per day of audio mix process, the time savings were really high, and it reduced a lot of stress for our devs.
Keep in mind that more mix time overall meant that more content gets polished, because that deadline's not moving, right?
So any time saved meant that more content, more polish could actually go in, our devs could get closer and closer to the final product that they were really proud of.
So the results were in.
There were two pages of Guardian custom buttons created for Rise of Iron, a general audio assistant that I went through, and a Rise of Iron content page that specifically allowed you to access all of the activities that we created for Rise of Iron quickly.
The audio team adjusted to using this new system.
Devs no longer bothered with the debug menu at all.
I'm told today they don't even bring it up.
They are consistently using that system.
It also improved audio QA efficiency to the point where it's now crucial.
We on the audio QA team use Guardian and those command assistants to the point where the expectations of how long something will take have actually changed.
Other teams, it's also really useful for when other teams have audio queries.
It's really easy to point to, hey, Kareem, I think I found an audio bug.
Something weird's happening.
How can I check to see if it's triggering the right event?
Instead of typing or copy pasting along a specific debug command to them, I can just point them to the Guardian page, and they can bring it up and use it themselves.
Most importantly, it resulted in a better final mix, a better overall product.
Everyone wins when the game sounds awesome.
And so the teams helping us playtest were happy, and next time it's even easier.
In summary, if you aren't in audio, please know, audio devs need support.
In this specific scenario, me and Audio QA, that's where that support came from.
But it can come from anywhere.
The next thing as well is that audio decisions really need to be based on real gameplay.
And that's part of the reason why multiplayer can be so challenging.
I also implore you, please don't skip on project tools.
Customization is awesome.
If you have the time or the resources to create a system that allows you to customize your tools, I highly recommend it.
And it's important to recognize that even if you have a tool that can do something really awesome, it needs to be easy to use.
No one in our team had used Guardian before because it wasn't easy for them to understand.
And so by customizing it for them and for their needs and making it intuitive, that's when the changes really started to occur.
Development is hard overall.
Games are hard to make, especially as you get towards the end, right?
But by working early, looking ahead...
We can really do our best to make those final days as easy as possible.
Overall, this project proved to be really successful.
Here are some words from the audio team at Bungie.
Thank you very much. This has been my first talk at GDC.
It's been a real honor to speak in front of all of you.
And please fill out your evaluations if you can.
If you have any questions, you can follow me to the wrap-up room.
I know we're out of time. Thank you.
