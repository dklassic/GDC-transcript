All right.
Thanks, everyone, for coming.
Let's get started.
My name's Mike Booth.
I'm a product manager on the Facebook Spaces team.
I lead the development of Facebook Spaces.
So back in April, we launched Facebook Spaces.
This is our MVP Facebook social VR experiment, basically.
We included in that MVP sort of the bare bones of what we felt like we needed to get something out into the world and start seeing what people actually do with it and learn.
Because everyone here knows how early it is for VR.
We don't know much of anything and we wanted to see what we could learn from this experience.
So this MVP included stylized avatars.
The goal of the avatars is that they're friendly and inviting and charming, but they're automatically generated through machine learning to look like you.
We tried to remove the friction of getting into VR that way.
You can experience your Facebook content, 2D photos and videos, 360 photos and videos.
You can take selfies from inside of VR and post them out to VR.
We're trying to cross the boundary between VR and 2D Facebook as well.
We included a marker that lets you draw objects in space to give an open-ended bit of creativity to see what people would do with that.
And our reach goal was messenger video calling, which we'll talk about in a little bit as well.
Where you could actually make a messenger video call from inside of Facebook spaces out to the real world.
And people would answer their phone and see a cartoon version of you talking to them from inside of VR.
So...
Our philosophy of why we built Facebook Spaces really comes down to three things.
The first thing is being in person with your friends, regardless of where you are.
And I'll talk a little bit more about this, but the feeling of being present with someone else in VR is amazing.
I think that's the core piece of magic that we're sort of hanging all of this on.
That when you're in VR with another friend who's in VR, they feel like they are right there, so what better way to connect you with people that you care about than in social VR.
The second pillar is personally meaningful content.
So once you're together in VR, the obvious question is what do you do?
And as Facebook, we have access to all of this content that we know is interesting to you and your friends because either you posted it or your friends have posted it or you've reacted to it and shown interest in some way.
So we need to expose that sort of content to you in VR so you can consume it specifically with 360 content in a really powerfully immersive way.
And thirdly, you want to spend quality time with your friends doing things that you enjoy.
And this is sort of really what we're pushing on now, is now we have this sort of bare bones system where you can get together in VR with your friends, but we need to flesh out that sort of ecosystem of things to do in VR and spend quality time together.
So I want to talk, for the rest of this talk, I want to go through what we've learned so far in building Facebook Spaces and seeing what people are actually doing with it.
So first is representing you.
Now, I know a lot of us in the audience are game developers.
So there's the notion of an avatar.
This has been in video games, 2D and 3D for a long time.
In VR, things are a bit different.
Where it is an avatar, but this is literally you.
This is your skin.
When your friends are looking at you in VR, they're actually looking at your avatar.
So it's really important that we get this right.
So this goes, for me, all the way back to Oculus Connect 2015 when I, no it was E3 I think, where I did the Oculus Toy Box demo for the first time.
Now, as cool as it was to play ping pong and reach out and pick up objects in VR and stack things and all of the fun physics things, the thing that really blew me away was, my friend Jason Holtman was the one giving me the demo, he works at Oculus, that floating blue head and those disembodied blue hands, was Jason. Like it literally felt like Jason was right there. His voice was coming out.
And it really comes down to, you know, the sixth degree of freedom tracking of your head and hands. All that subtle body language, the way he holds himself, how he uses his hands when he talks, it all came through. And I've been in the game industry for a long time. I've seen all the AAA stuff, which is all amazing. I was up way too late last night playing PUBG.
was the most impressive thing I had seen to date.
So how can we take this and add to it, expand on it, make it even more intense?
So when I started with Facebook, it was just me, I didn't have any artists, so I hacked this up, trying to experiment, like could we do eyes, could we do emotions, and ended up with this really creepy cross between Max Headroom and Charlie Sheen.
What was really apparent from this is when you're in VR with this guy, he is really creepy and this is not what we want to do.
But, I can make eye contact with it and I could use a, like a thumb stick on a controller and sort of lurk between emotional states and I could see the emotions on their face.
So, it was, it was interesting and how could we actually make that something that was not awful.
So we actually got some real artists involved, and we built these early stylized humans.
And they're really charming.
They look great in 2D.
And this is where we discovered that there's a big difference, obviously, between 2D and being in person with something in VR.
When you're in VR with these avatars, there was something just a little off-putting and unsettling about them.
Part of that was the eyes.
Their eyes are kind of big and spherical and bulbous.
But what it really was is the mouth.
And specifically, which I'm not showing here, but the mouth motion.
The fact that you had this smooth mouth and it was smoothly lerping between shapes, but it wasn't quite right, made you just not want to be in the same room with that thing.
So, that's a little bit hard to see, he's a red rabbit on a black background.
Where this took us though, was what we ended up calling the Rabitar.
And this guy, there's a whole host of things that we learned based on this.
First of all, there's a torso and there are arms.
We're inferring that based on where your hands and head are.
The fact that we can do that and it's reasonably believable was great.
Now we don't actually show that for you because if you look down, your actual arms won't line up.
and that didn't work, but it works great for everyone else in the space.
Another thing that wasn't obvious is that the Rabbitard's eyes are 2D.
They're just 2D sort of tune eyes pasted on their head, but you could still make eye contact and really feel like you're making eye contact with another person in VR with 2D eyes, which is great because asset-wise, they're really quick to iterate on and very cheap assets to make.
Also, the emoting, the ability to make expressions and have those expressions read worked really well.
And the secondary motion, the giant rabbit ears that are flopping around, the hair, the whiskers, et cetera.
The amount of expressivity that the secondary motion brings to the table is really useful, especially when you have these limited channels that you're talking through.
Adding everything we can add to that to bring more personality is great.
The last thing you'll see here is the gestural emotes.
We'll talk a bit more about these, but the ability to put your hands on your cheeks and make an emotion happen was something that people found really fun.
We'll talk about that in a little bit.
Okay, so as charming and fun as that was and the number of things that we learned from it, Facebook is really about connecting you with your friends and presenting your authentic self.
And as I am not a giant orange rabbit, this wasn't going to work.
So for F8, we took a step back and we revisited the toy box and we had an artist use our VR markers to basically do a caricature drawing on these VR, these toy box heads.
And this is myself on the left and Mike Schrepp for the CTO on the right.
And we use this for a live keynote demo at FA 2016.
And that seemed to work really well.
I mean, these are very simple, but it was very clear who Schrepp was and who I was.
So moving on from that, for OC3 last year, we did another live demo, and we at that point had settled on these sort of stylized cartoon avatars where again, like this.
is more or less me.
It's not exactly, but it's friendly and charming and stylized, but it has all of the things we learned from the rabbitar.
There's a torso, there are arms, I can emote, I can make eye contact, and this worked well for our demo.
We continue to iterate on this, and by the time we shipped our MVP in April, of this year, this is where we landed.
And again, we're taking more of the learnings from our previous experiments, and you can see here, like the eyes have gone back to 2D eyes, and just general refinements to shaders and forms and whatnot.
And we've continued to iterate on this to our current avatars right now, with just subtle details, like now we have more controls for the user to go in, and like in this case, I was able to have a different color to show that my goatee is gray and my receding hairline is brown.
So this leads us to sort of our golden rule of avatars for VR.
First one is, you should be happy with how you look.
And I'm reasonably happy with that guy.
And the second one is your close friends should recognize you.
So this is, in other words, like this does not have to be a perfect representation.
Not everyone in the world needs to be able to look at you know, an avatar and go, oh that is exactly that person.
But if you're in context, in a social environment with friends, it should be very clear, you know, oh that's Mike, that's so and so, that's so and so.
So how do we create these avatars?
So here you see our current interface in Facebook Spaces, where again, we're using machine learning.
So you log into Facebook and we can bring up photos of you, and you basically can pick one of those photos, and it presents you with several guesses.
of what your avatar might look like. This was important because initially we really wanted to remove the friction so we just would, as soon as you grabbed a photo, just put a guess of what you look like in the mirror. And as good as the machine learning algorithms are, they're not always perfect. So sometimes this was jarring because it felt like Facebook was making a very clear judgment.
which is not our goal.
So by presenting you with five choices, it's clear to the user that these are guesses, pick the one you like.
And if you don't like that one, grab another photo and kind of keep going till you find one that you do like.
Even once you have selected the one that you like best, You then are free to modify any part of it.
So you can change colors, change eyes, change shapes, change nose shapes, et cetera.
And as you can see with this example, like, oh, that particular one didn't have glasses, so I'll put glasses on and I'll set them to blue.
On the left there, you can see we have a couple of images of pre-saved avatars.
So if you've made, you might wanna have an avatar for different occasions, so you can preset some avatars, bring this up and quickly switch back to an earlier creation you've made.
But the key point here is that you have the final say on how you look.
Okay. So now we have these avatars. We automatically generate them for you, give you the tools to tweak them just how you like. How do we actually bring them to life so it's actually you coming through?
This is a really interesting example.
These are white dots moving on a black background, but when we look at this, we can't help but see a person walking because these dots were motion captured and our brains are wired to see that sort of biological motion.
The good thing about this is anything that is captured in this way will seem alive and the current state of VR, at least with six degree of freedom tracking, is basically a built-in motion capture studio.
If you're wearing a six degree of freedom headset on your head and you're holding six degree of freedom trackers in your hands, then we get this biological motion and it comes through.
As long as we don't, like we did do some experiments where we tried to do some intermediate animations and whatnot and that washed out that signal.
We don't wanna do that.
Basically, that signal we wanna leave alone and let it just come through in your avatar because that's carrying all of your body language and mannerisms and it's really powerful.
So obviously we can't see where your eyes are looking in this headset, but we can infer based on where your headset is looking and what objects are in the scene, what you're probably looking at.
And we make an educated guess, and it actually works quite well.
Again, we've chosen the environment carefully, and people are the most interesting thing generally anyway, but this really helped.
to have eye contact, and you get quickly to a place where arguably this is more interesting than a video conference, because you can tell where people are looking, what they're paying, oops, sorry, where they're looking, what they're paying attention to, whether they're engaged or not, and you can get gaze following as well, where someone would look at something and you see them looking at that, and then you look over to see what they're looking at.
In addition, lip sync is really interesting and important, but in a particular way.
So with this lip sync, you can see it's very simple and very stylized.
We're using replacement animation, like an Aardman or a Leica sort of thing.
In our earlier experiments, we did try, as we mentioned earlier, like having more realistic lips and doing all the proper things with blend shapes and lerping between all the visemes, and it was never quite right, because we're just inferring based off of the audio, and that just seemed creepy.
It was close, but not exact, so we're in the uncanny valley.
So we backed off and we intentionally went very stylized with visemes that just snap to different shapes.
But this works really well, because your brain looks at this and says, oh, that person is talking, and it looks like they're saying what they're saying, because most of the visemes match up, but you do not believe it's real, so you're not trying to believe that this is a real thing in front of you.
Then we talked about this with the emoting.
This is really important and something that we're pushing on is that it's not enough to be there and to look like yourself, be able to make eye contact, you want to express yourself.
And these are your friends who are gonna do things that will make you angry or laugh or smile or be surprised or whatnot.
So we need some way to at least start to be able to do this.
So this is another example of the gestural emote.
So if you take your hands and put them on your cheeks.
It will automatically express this oh my gosh expression.
We have a whole set of these we're working on where you put your hands on top of your head and then you're scared.
You bring your hands up over your head and it's hooray like you saw with the rabbitar.
You do like this and you're confused.
And what's fun about these is they're inherently social.
So you'll see someone do this like oh, how did you do that?
And you just, well, you just put your hands on your cheeks and then they try it in a mirror and like oh, that's great.
And you can propagate that on that way.
With that said, If you are, say, putting on a show, maybe you're live streaming, as we added the ability to live stream from VR out to Facebook a few months ago, you wanna have direct control.
So we also allow you to use the thumb sticks to basically puppeteer your face.
So in this case, if you push both thumbsticks together, then your avatar will make that same oh my gosh face, but it will stay there as long as you hold it.
And you can quickly switch between emotions this way.
So you can build up muscle memory and get pretty quick at this, but clearly, these are early days, and this is very much like VR emoji, as in a text message you would add emoji.
But the fact you can do it at all, I think is really important.
Because at the end of the day, what we want to have, particularly for Facebook social VR, is we want to have avatars that are recognizable by your friends and are interesting and expressive enough that you actually want to take selfies of and post to Facebook, for example.
Physical contact, so physical contact I'm using, I mean, you're in VR, it's not physical, but if I reach out and actually make contact with your avatar, we should recognize that and something good should happen.
This is, I think, a really interesting example.
So we were at a previous trade show last year.
We were demonstrating this, but spaces at the time had a bug.
where you can reach out and shake hands with someone, which is actually really cool because you're holding a touch controller.
So when you actually grab the other person's virtual hand, you're squeezing the touch controller and it really feels like you're holding their hand.
But there was a bug.
So when you would log in initially, you'd be holding hands.
Your arms were stuck together.
So we had a person come in, and we're gonna show them spaces.
And we had Alicia, our producer, back in Menlo Park ready to meet them.
So he puts the headset on, and he finds himself standing about this far away from a woman he doesn't know, staring into her eyes and holding her hands.
And he blushed.
He blushed, this was awesome.
He physically blushed.
His lizard brain believed it enough that he turned red and blushed.
And he took off his headset and he said, I need to tell my wife.
The fact that we can, you can't fake that, right?
The fact that we can induce that sort of level of reaction is super powerful and gets me very excited about what we can do in social VR.
So here's another example, high-fiving a friend.
Like, there's a sound effect, there should be a particle effect.
Whenever someone actually makes the effort to do this, we should recognize it and celebrate it.
Now, as powerful as VR is, you really do feel present with these folks, right?
Now, Facebook Spaces is all about connecting you to friends using the friend graph in Facebook.
But some people have lots of friends, and some people have, you know, that guy.
So you want to make sure that you feel safe and comfortable.
in VR. So when we launched, we have these safety features. For example, on the left is the safety bubble.
So by default, nothing can get within about arm's reach of you unless you allow it.
If someone tries to reach into your space or put their face in your face, they just vanish.
You have to let them do that for that to happen.
On the right, you have a wrist menu, so you have a watch basically.
And on the inside of that watch is a big pause button.
So if someone is being obnoxious doing something you don't like, or someone puts up a really high resolution 360 video of a super violent roller coaster that does not make you happy, you can just hit the pause button and stop the world. Everyone disappears, all the content shuts off, you can gather yourself and decide what to do.
You also have the ability to mute and block and kick people that are in your space as well.
So we really take seriously trying to keep things friendly and safe.
Okay, so that was you and how you are in VR.
Let's talk about your space.
So when we started this project, like my assumption was that we would be hiring a giant team of 3D artists.
We'd be building this immense 3D space that we'd all be exploring and whatnot.
And this was one of our early experiments where this is like a clubhouse with all sorts of things to do.
For what we're really trying to do, of frictionlessly bring people into VR, connect them with people they care about and share personally meaningful content, this was a distraction.
Because locomotion is challenging, we immediately found that like, okay, well, there's the problem of what do we decide to do?
How do we get everyone to do this thing and not that thing?
It wasn't focused on the same things we were trying to accomplish.
Another experiment is fishing.
Fishing as an activity is ideally suited to socializing.
Right, it's not so intense that it's drawing all of your attention and you can hang out and talk while you're fishing and occasionally exciting things happen.
The problem here is that we literally got lost in the woods.
It's hard to see, but on the other side of the lake there is the other avatar, and they're way far away and the audio falls off and like, people would literally be like, hey, where'd you go?
And they'd be trying to find each other.
That was not, that didn't fit with what we were trying to do.
Another thing that everyone wants to do, thinks they want to do, is I wanna have a space, I wanna decorate it just the way I want, I wanna paint all the walls just so, and put all these furniture here and whatnot.
And this is true, and it definitely has a place, and I'm sure that we will come back to this.
And obviously we invested pretty heavily exploring this.
But ultimately, if I want to meet a friend and catch up with them, and see some latest videos with them, or share some personally meaningful content with them.
If I have to start VR and go in and select all my furniture choices and material choices and decorate my space and light everything and have my friends come over and evaluate how they think I am as an interior designer.
Like, that's a lot of, that's friction.
So we went in a different direction.
Where we ended up.
is this blue table at the bottom there.
Basically the idea was a dinner party for you and your friends.
So it's you and three of your friends in a space.
There is a table that you're all focused around and you always know where your friends are.
Okay, so the table itself.
It was not clear at the beginning that there should be a table at all.
And we sort of evolved our way there over time.
And this was our first demo with, the live demo with Shrepp at F8.
So here, very literal, right?
Okay, we have a table and here's all the parts and pieces we need to put on our presentation.
Obviously, that was not going to scale.
We have this lovely, on the left there is our bowling ball rack with our four photo spheres that we're going to show for the demo.
That's not going to scale to the millions of photos that are on Facebook.
Where we've ended up is this sort of arrangement where you have a table, in the center of the table is a display system so you can take content, put it there, display it to the room.
You have a tablet with a recognizable interface that you can access things like a shelf full of tools that are all useful.
So we've been sort of iterating our way, figuring out VR UI, which VR UI is at least as challenging as avatars and everything else that we've been doing.
It's extremely hard.
For example, here's what we started with with Photospheres.
This is super fun, magical, and charming, right?
You see this like magical orb you can pick up and look at, and you can orient it in just the right way, and you put it on your face, and boom, there you are.
Not super discoverable.
People did not, they were mystified by the orb, it was great, but no one thought, hey, I will shove this on my face, and that's how I will display it.
So what we did is we made this display center in the center of the table.
And although you don't see it here, as soon as you pick up content that can be displayed, the center of the table will glow.
So you're like, oh, it's glowing.
Maybe if I put it in the center of the table, it will display.
And that was much more discoverable.
We lost the ability to orient the photo, though, right, where you could sort of look at it and say, I want the Eiffel Tower to be there, and then you put it on your face.
So we had to iterate our way through that.
Plus, the center of the table is like the most valuable real estate.
of the table. So if you actually want to do anything else, like say play a board game or something, the display center made it very difficult.
So where we've evolved now, and we're just releasing this soon, is that we've moved the display center to hover above the table, and only appear when you grab content that can be displayed.
And as you saw there when I brought up the 360 photo, you can sort of put it in the display center and turn it, and orient the display, while keeping the portal only so big, because if we had the whole world swinging around you, that was also, could be upsetting.
So this is a schematic of sort of where Facebook Spaces is right now for VR UI and the different affordances.
We talked about the table and the display center.
Whenever you put 2D content into the display center, it goes on the big display there.
The dock and the projected UI.
So you have a watch.
that is on your wrist.
First of all, it shows the time, which is really freaking useful in VR to know what time it actually is.
But any messages that come in will appear there from Messenger and whatnot.
So it's sort of your notification center of what's happening.
And then any object, we'll see this in a bit, any object you pick up will have a context sensitive wrist menu for the object that you're holding.
So for example, these are dice, which we just recently added to the spaces.
And you can see that as we interact with the dice, the wrist menu updates.
Like if I'm holding a dice in my hand, the wrist menu becomes, you know, context sensitive to that dice.
So I can add more dice, I can gather the dice, I can delete the dice, et cetera.
It's one thing that you have to learn, but once you've learned that, every object in the space has a similar menu that's appropriate to that object.
So this is another interesting bit of VR UI.
So this is distance grab that we're starting to play with.
I know there's a lot of VR systems out there that allow you to grab things at a distance and bring it in.
In the case of social VR, there's a couple of additional things that we need to be thinking of.
This is not implemented yet, this is just early experimentation.
But if I wanna pick up that red tube, I can't just teleport into my hand.
What we need to do is we need a way for me to say, I want that red tube, but all of the other people in the space need to see that, hey, Mike is going to take that red tube and allow them to see what's going to happen and be able to intercept and change their mind, basically.
Like, I'm trying to steal something from you.
You need to be able to grab it and say no.
Okay, so what are we doing in this space?
We need to bring in things to do.
And when we launched Spaces, the thing that we had that enabled this the most was the marker.
You could pick it up, you could doodle, that's great.
But really it's a 3D printer.
So in this case, we could play a game of tic-tac-toe in Space, which is fine.
But you could also spend a little time and draw all of the pieces of a chessboard.
and then bring in a 2D photo of a chessboard and actually play chess.
You can save all those parts away and bring them back whenever you want.
So, you know, we're trying to create an open-ended verb to see what the community would do with an easy way to construct 3D objects in VR.
This was also wonderful for collaborative design.
This is a kind of a mock-up of the avatar creation that you saw earlier.
We actually did this in VR with Christophe Tassier as the lead designer on my team.
He and I were in VR together with markers and we would just draw different affordances and shapes and whatnot and arrange them in space and pretend to use them and see how it felt.
That was wonderful.
You can also, in this case, one of my goals for the team is I want to get my Dungeons and Dragons role-playing night back together.
All my friends are scattered along the West Coast, and I want to be able to go into VR and have a D&D game night.
So in spaces, if you go look at the drawing library, there are dungeon pieces for that reason.
But you can also see, it's a little hard to see here, these fighter characters and the dragon.
This is something that we're just adding to spaces called photo cutouts, where basically you can take any 2D photo, including your PC desktop, which is interesting, and with a cut tool, you can trace lines around and cut out shapes and bring them into VR with you.
So you can make any board game piece, any standee, a mask, et cetera.
So based on what we learned from markers, we're going to photo cutouts to allow people to be more creative.
Okay, so this is our current UI for exploring Facebook content.
We've recently added a search bar.
I immediately use this.
I grew up in Iowa.
I'm from the Midwest.
So I went in there and I hit the search bar and I typed in Iowa and I immediately saw a bunch of 360s of the Midwest.
And I was able to sort of wander around my hometown and look at rolling hillsides from Iowa.
It was great.
So now we've really opened up anything you can think of, you can search for and find.
I'm gonna have to go fast cuz I'm running out of time.
Okay, so I mentioned the PC desktop.
So this is actually your PC desktop.
In this case, this is Brian's Instagram feed and his favorite dogs, you can see here.
He grabs the cutout tool and he traces around his puppy and he will get a cutout of his dog.
Now, the thing with the PC desktop is this is literally your PC desktop.
Everyone in Spaces can bring in their PC desktop.
So you can have a LAN party where you're each playing whatever game that you wanna play together.
You could be all over the country, but you could be together in VR doing that.
And any website, anything on your PC, etc., you can access in Spaces.
If you put your PC desktop in the display center, it displays on the big screen for everyone in the space to watch as well.
So again, looking for open-ended verbs to express creativity in VR and see what the community does with these tools.
We talked about dice.
There's a couple, this is a good example of things that we can do where they're familiar objects, but we can do things, make things a little easier in VR.
So dice have the properties they do in real life.
You can pick them up, you can throw them, they bounce around.
But of course we show you the numbers and the sum total, because why not?
But also things like, in this case, these two are playing liar's dice.
It's a little hard to see, but you can take your dice and make them visible to only you.
That doesn't make your dice invisible to everyone else, but what they see is instead of numbers, they see question marks.
So we can roll the dice, we can play liar's dice, we're bidding back and forth, and then when it's all over and someone calls you a liar, you can say show to friends and then all the question marks turn to numbers and you can see what it is.
Essentially having a dice cup in a different way.
And of course, one of the most fun things in space is continues to be the ultimate VR photo booth, where you can take all of these creative parts and pieces that we're providing you, and people just have lots of fun goofing around with their friends, and then ultimately they take a selfie, and they post it out to Facebook, where the two billion people in the Facebook graph can see this and start to see what is this VR thing, and oh hey, this VR thing is interesting, and I might want to get into it.
So this gets into opening up VR for everyone.
The goal is VR is for everyone.
Selfies, obviously, are the biggest thing.
They're the simplest thing to start with, and as we just described, they're a lot of fun, but people out on Facebook who don't even know what VR is can start to see these artifacts and ask questions and get interested.
We also, as I mentioned at launch, we integrated messenger video calling.
So from inside of spaces, you can make a messenger video call to someone just out in the real world and they will see a cartoon version of you and they can interact with the space with you.
We've also recently allowed you to actually, we've added a keyboard inside of Spaces so you can respond to your Messenger messages.
This, like Search, it's really simple, but when you go from zero to one, like I can't do this at all, I have to take off my headset and go back to my computer to respond, or my phone, or I can just quickly respond from inside of VR.
It's really game-changing.
It lets you just stay in VR, and it feels like everything is wide open.
In addition, we launched the ability to go live.
So this is a example.
I was actually on an airplane 30,000 feet in the air on airplane Wi-Fi watching a live stream of my team testing live streaming.
And I commented, I'm watching you from 30,000 feet.
So when you're in spaces, you see this sort of magic mirror of the live stream that's happening, so you can see what everything looks like.
Reactions that people give, like hearts and likes, they come popping out of the screen, and any comments show up next to the magic mirror.
So what they're doing here is they reached out, saw my comment, grabbed it, and pulled it into the space and showed it back to the camera.
And when I'm sitting on the airplane and I saw them do that, that was just, it was amazing.
It felt like I was involved in the VR experience.
We plan to do, we want to do a lot more with that in the future.
Here's some examples of, you know, live streams from the community.
And there on the right, that's a live stream from Slate.
Slate has started to put on a weekly show called Conundrums, where they bring in celebrity guests, and they do a quiz show with them from inside of spaces.
Usually, Lindsay is in New York, and their guests are often in LA.
In the future...
We really want to get to this people-centric computing platform, and we really want to get third-party developers involved.
We're starting to look into ways that we can make this happen.
So in this case, if I'm there with Rachel, like I wanted to connect with Rachel first, then we decide to play, let's play a game of pool.
We didn't launch a pool game app and then invite Rachel in.
I was there with Rachel, and then we brought the pool table in.
We might decide, hey, this should be in a pool hall.
So put a 360 of a pool hall around.
Like, no, let's do it in a, in a back alley because, I don't know, why not?
And then while we're playing pool, we want to listen to music, so perhaps Rachel brings in her boombox where she can stream her favorite music service.
These things should all be built by third parties.
They should be brought into spaces, and we're just starting to explore how we can make that happen.
So as VR developers, think about how spaces could be useful to you and let us know.
So again, VR is for everyone, and we feel like this is one of the things that we're trying to communicate at Facebook.
I have been in the game industry for several decades.
I was up late playing PUBG, as I mentioned.
I understand that VR is amazing to do awesome games where you blow up robots and shoot zombies, but I think to get to the kind of scale that we're talking about with two billion people on Facebook, it's important that we communicate that VR is for everyone and find other ways to express the kinds of things that we all know VR can do.
Again, this journey is 1% finished.
Everything that I've said and displayed here could be entirely wrong and might change by next year.
But these are the things we've learned so far that we wanted to share with the community.
So if you wanna learn more, facebook.com slash spaces.
Thank you very much.
