I have this friend, he's a game artist, a brilliant freaking game artist and an inspiration to everyone around him.
And he went to the doctor recently and the doctor told him that if he keeps doing what he's doing for a living, he's gonna keel over and die from a heart attack in the next couple of years.
How fucked up is that?
And the scariest part about that story is that I'm pretty sure every single one of you guys haven't been in this industry for a while has a similar one about someone you know or maybe even you.
And I for one have sat through way too many friends literally with tears in their eyes telling me that they are probably going to have to leave the job that they love and their friends behind because if they don't they might not have a family anymore.
And it boggles my mind that we somehow ended up here.
That is our reality in many ways, because we're not in open sea hunting whales, and we're not in mines breathing in coal and dust.
It's somehow we ended up here.
And I'm very lucky.
I get to travel the world, talk to game developers about.
what they worry about and I get to hear all kinds of things from absolutely mind boggling like you know HR department starting betting pools on how many divorces they're going to get after after the product ships to to the very worst one that I've heard is actually a senior artist teaching their younglings at a studio that in order to survive in this industry you need to learn how to care less.
which breaks my heart on so many, many levels.
Because something that all of us are extremely privileged with in this room right now, is that we actually have something that we love doing for a living.
And it's a privilege that most people will actually never know in their freaking life.
They'll just go to work, spend a third of their life doing something absolutely loathing what they do, and then just waiting for that clock to run out to actually go home and do something that they love.
And the fact that we have to condition people to learn to love something less so that it doesn't have to hurt them back is absolutely mind-blowing to me and deeply disheartening and That kind of shit keeps me up at night and all of you guys keep me up at night because I've I I've met you I've been to many a GDC's and conferences and and I know for a fact that pretty much all of you have dedicated most of your life to building beautiful things that will entertain people and take them on adventures and share stories and give them memories and friends they wouldn't have had otherwise. And to think that this is how we treat people as an industry like this is the best we can do. And the worst part is usually that the most burnout are usually the people who actually give away most which is even more heartbreaking.
And honestly, this is why there's an AI talk in the middle of an art direction bootcamp, is because trying to solve this problem for many, many years, I do not know a better way to fix a lot of the things that are symptomatic of this, rather than technology.
You know, yes, there's talk about unionizing, great, but games are still ridiculously expensive to make.
You still have gigantic teams that we financially cannot justify, and we're gonna have to outsource more jobs once the next console generation comes around, and then how creatively engaged are you going to be?
And then, you know, on top of that, even if all the jobs are here, but there are 3,000 of us making one game, how exciting is it to place rock by a tree for a year, because that's all you get to do?
Because it's the quality and the dignity of the jobs that matters also.
And, you know, it's the crunch and the cost and the creative ownership and all of that.
And I can't think of a better way to fix it than literally make everyone 10 times more powerful than they are today. Making sure that you can accomplish a lot more than you think you can.
Making sure that whatever is out there does not require an army of craftsmen, but rather a tight-knit group of artists.
And that is what we're going to try to talk about today.
This is obviously a talk about technology.
There's going to be a bunch of technical things.
But fundamentally, it's about you.
It's not about trying to tell you, hey, a bunch of programmers got together, and we figured this thing out.
So now all of you got to live with it.
It's the exact opposite of that.
It's, hey, all of these people are doing all of these things.
And quite frankly, nobody has a clue.
Nobody has a clue apart from you because this has all been made for you.
And in order for you to make the most of it, you need to be vocal, you need to be educated, you need to be a part of that conversation.
And in order to do that, you need the ammunition, you need the knowledge to actually call bullshit when somebody gives you technology that is undeserving of the creativity that you possess.
And so that's what we're going to talk about.
And I know right now you're thinking, God damn it, Andrew, how the hell are you going to dig the presentation out of this hole?
And I'm not sure, but we're going to try.
We're going to try together, because the presentation is actually pretty fun.
We have videos, we have robots, there's a dance break in the middle, so it should hopefully go quite well.
And so, all right, here goes.
Building a creative future with artificial intelligence.
And I'm going to start with a very simple, aspirational video, because I think something that is very important is that.
I think culturally, we all realize that there is a certain critical mass of technology that is going to happen that is essentially going to make every single person the master and creator of entire universes.
And it's been in popular culture for the longest time, and this is obviously the newest Blade Runner movie, with the sort of section about mutant memories.
But, I think conceptually...
What is really important is that we knew for a while that we're going to get there anyway.
And I think that is the tricky part because it's very hard for us to reconcile all the science fiction we've been brought up with with the actual time in our lives when we see that science fiction become a reality. And then all of a sudden we go, wait, what do you mean I don't get to make my own laws? You know, it's and so that is kind of mind boggling. And we're going to try to talk about this a little better today. But we're going to start a little bit further. We're going to talk about in general sort of this idea that AI is kind of a hot topic today and everybody, you know, invests money and tries to figure out a way to make it useful and obviously, you know, every single industry is throwing bajillions of dollars into it, but games are a little different.
There's not as many tangible results as we would like and apparently there was the AI bootcamp yesterday and there's been a bunch of cool talks so I suggest you check it out, but there's not a lot of product that shipped with AI. There's tech and people have done experiments but we still are waiting for that, you know, tentpole moment of like, oh, this is now part of our everyday life and everybody uses that, which is both good and bad, but what that means is there's a lot for us to explore and so we're gonna try and unpack that and sort of the core subjects that we're gonna discuss are gonna be rendering, content creation, and then actually sort of the, as weird as it is to say, the social aspect of working together with an intelligent system, which is gonna be a fascinating conversation.
But first, let's just break it down a little bit.
And I think, a good definition of what AI can do in general, right, is one by Andrew Ying, which is basically whatever your brain can think of in a second, like a very simple operation that doesn't require a lot of your attention, is something you can technically conceivably accomplish.
And the other definition I've heard that I kinda like is AI is sort of like an army of 10 year olds.
They have the basic skills, but the attention span is really, really freaking tiny.
So whenever you're trying to solve a problem, think about that.
Can I apply AI to that?
Can you take an army of 10 year olds and will they be able to do it?
And it all boils down to patterns, right?
It's math, it's structure, we look at things and we predict how these things might end up down the line.
And so this is basically what we're gonna be discussing.
And we're gonna start with rendering, and I think that's just lends itself very well to an understanding of how you might perceive that information if you were an artificial intelligence.
And that is, an image is basically a pattern of pixels.
And if we were to present the simplest problem of what can an army of 10 year olds do, It's basically, take a bunch of 10 year olds, give them these little squares of the image, like tiny chunks of like 10 by 10 pixels, and go, could you fill in the missing black pixels, like with a reasonable result, even if you don't have an access to the entire image.
And that is technically a problem that even most of us, you know, without being exposed to the rest of the image could accomplish quite well.
and that would somehow be representative of the final image and that seems like an entirely asinine problem, but when you start applying it at a grander scale to how rendering is done, this is in many ways revolutionary and this is nothing new, it's a reasonably oldish NVIDIA research, but I think what it informs you of is this idea that we can actually do half the amount of rendering than we're used to and just.
kind of figure out the rest as if we had an army of, you know, little AIs just sitting there and painting in those pixels for us.
And what that allows you to do is basically dramatically scale down the amount of computation you need to do, speed up the rendering, add more stuff on screen, and just that one simple fact.
just that one simple thing is already in itself revolutionary and of course you've seen a lot that talks about the NVIDIA RTX and all of that stuff and not all of these denoisers by the way that NVIDIA is using today are AI based, but there's more stuff coming.
But just starting with a simple problem and simple solution, just that one thing can fundamentally change so many things that we know about rendering because once again, the Moore's Law given out, like we're not getting as much hardware gains as we're used to, which means that in order to get better graphics, we need to somehow figure out how to process.
And that is an interesting way of doing that.
And of course, the question you have is, well okay, but when will it be fast enough or ready enough for production?
And the fun answer is like about three years ago.
So this paper came out, SIGGRAPH Asia 2016, and I've actually talked to people who have it implemented in their studios as research projects.
it's working, but nobody's putting it in a game because we are very risk averse and games are very expensive and so there's gonna have to be an interesting point in my guess it's somewhere around the console generation transition where we're actually more sort of invested in the idea of trying riskier things and seeing what what shakes out especially as complexity grows exponentially and we actually are hard-pressed for you know bigger gains but that is just that interesting idea that like that technology exists It runs on GPU in shader, AI-based screen space ambient occlusion that is actually higher quality than most things you would get with the traditional method.
So there he goes.
But just taking that idea further, and we're just going to go through a bunch of cool videos because it's fun, and talk about all of the creative freedom that this allows you for.
So when we're talking about rendering, we're also talking about iteration.
Your ability to experiment as an artist is basically handicapped by how fast the computer can process the things you're working on.
And so this is the research out of Disney, where they can basically borderline real-time, visualize lighting, these very complicated, you know, volumetric systems.
And what that means is, as an artist at some point in a video game, you'll literally just sort of sculpt your fluffy clouds and see them immediately rendered in front of you.
And that is really cool, because this is something that has not been possible before and is going to ungate new opportunities for you as artists and allow you to express more cool things.
But something that's very interesting is that it turns out that if we take that simple idea of, I have a bunch of points, and then I remove some of those points, and then I can fill in some of those points, that translates to so many more applications that we have, like particle systems.
Particles, essentially, are just a collection of points.
generate less points and then just use an AI-based system to figure out what the rest of the points are.
And so what that means is imagine as an artist, you can actually have real-time flute simulations in a game that are full 3D and interacting with your environment.
Like, these are things that were not possible before, but they're gonna be inevitably, you know, and hopefully reasonably soon.
And there's some fun research for doing similar things, but this is basically more in 2D, but it's the same idea is that we can sort of take a lower res, you know, simulation and then just use AI stuff to basically accelerate and predict the next frames of how the simulation is going to look.
And I think the key phrase here is predict how the next frame is going to look, whatever this applies to, because there are a lot of mathematical connotations, but there are some that are artistic, that are incredibly fascinating.
And that is basically what happens in this process, right?
We're so used to like, we're doing particle simulation, right?
Let's take every particle and calculate how it bounces and bumps against every other particle, which takes forever, no matter how many transistors you put on a tiny piece of silicone.
And so what these systems provide us with is an actual opportunity to, instead of calculate it, just sort of figure out how that looks.
and then just sort of spit it out back at you.
So something you don't do as an artist when you're painting water is you're not sitting there trying to solve a fluid simulation in your head.
You look at it and you go, okay, I think these are nice shapes and they're kind of evocative of what I'm trying to tell.
You're not solving light transport equations when you're trying to just render something in 2D with watercolors or Photoshop or whatever it is.
And something that fascinates me about this technology is that it essentially learns how to be more like you.
how to not calculate everything, but learn and memorize how things look so that you can express it back to you.
And what that also ends up bringing us is dramatic increases in actual efficiency.
So that is very interesting, but I guess something to take away from this section is AI is more like you than traditional programming, which is kind of cool.
The next thing is style transfer, which is, by all intents and purposes, if you're an artist, kind of useless.
And we've all seen this gimmick videos going around, and you know, throw in an image, get another image that looks like the Starry Night by Van Gogh or something, and there's literally no good application for an artist.
But I'm gonna go through a bunch of steps that are actually going to explain to you why this could be really good for rendering.
And we're gonna start with a simple idea.
You can transfer from a simplified style to a more complicated style, right?
And we've seen the paint a cat or whatever.
If not, just come by, give me a business card, I'll send you a link to it, you can paint some cats.
But the cool idea that comes out of this is that you can basically take one type of video or one type of frame and then transfer it into another one.
Like this is research done at NVIDIA where they basically take self-driving or just regular car footage and then they transfer it from like, here's a spring version and a winter version, or like here's night and day, but then what they can also do is they can take a real, a real video and transfer it into something that looks like a video game.
which is a fascinating idea, and it's actually been trained on GTA V, so good on GTA V, but what this lends itself to is actually the reversal.
You can basically render a game frame and then figure out a way to convert it into something that looks photoreal.
which is, I mean, photo real is a bit of a stretch today, and I understand that, but something that's very interesting with all of that is that basically, potentially, down the line, the rendering process or how you used to visualize the things can be not focused on actually calculating, you know, the light that bounces off a pixel, but just rendering out the semantic segmentation map of this is a bicycle, this is a car, and then you have an AI system that actually figures out how to render it, and so this is an actual AI rendered video that...
takes a similar sort of segmentation map and renders an entire frame for you where you don't place the lights, you don't place the textures, you just go, this is a street, there are cars here.
Could you please just remember how it's supposed to look and sort of apply that artistic lens to it?
And this is an entirely different sort of paradigm shift of a concept that can apply to rendering.
And what's fascinating about this, and I'm sorry this is gonna get a little bit technical, but it's also kind of cool, so hopefully you'll appreciate it, is that conceptually the way...
neural networks work is they are stable and predictable as far as how many cycles in memory they take. They literally take the same amount of memory and cycles every single time. Because when you run your game and you render your frame, and I optimize many games, so I know that pain all too well, your game only runs as good as the worst spot you have in your environment.
Meaning, your entire beautiful, beautiful world that you've built is like 60% of how cool it could look because you can look out the window and through a glass statue that's going to be reflected and that one thing, and you literally have to account for that and bring down everything else because that's how the current rendering works.
And that's basically programming for you today.
You write an algorithm and then it might run more things or less things.
But when you literally run the same amount of pixels through a neural network that visualizes or renders this for you, it's going to be exactly the same every single time, which means that.
It scales more easily, it actually plays a lot better with different types of hardware.
And what that technically means is that it's just better suited for the problem we have at hand, which is quite fascinating to think about because it means that on a long enough time frame, it will inevitably be a better way to do it, which is quite fascinating.
But yeah, hopefully this is useful.
I know it's quite technical.
It'll lead somewhere, I promise.
The next cool thing is actually, we're gonna talk about content a little bit, but the focus is now going to be a lot more to applying to the things that we can do as artists.
And the one thing for any Blade Runner fan is obviously the iconic scene of just enhance, enhance everything.
And I remember watching that and thinking, this is not possible, this is silly, there's no information there.
And well, the fun thing is, even if there's no information there, it doesn't mean that we can just come up with that information.
And so super resolution is an idea of like, oh, I can draw a low-res piece of concept art and then just have something up-res it and fill in the missing detail, is pretty much a reality today.
There are all these fascinating projects of like, hey, let's take Final Fantasy VIII or something and just auto-up-res all of the backgrounds and then just re-release an HD version that is better than any source material has ever looked.
and that is very interesting, but that also just allows us to abstract the type of art that we produce.
We're like, oh, maybe I don't have to fill in all the details.
Maybe I can just, you know, have a baseline and then stuff can sort of work with me to accelerate it.
And it, you know, it works impressively well in a lot of different situations, but also it just helps with quality.
How many times have you looked at a texture and were like, geez, I have to redo it now because it's like a 512 and I need just a 1024 here.
And then you literally redo it.
repainting it or scaling it up, or like, oh no, actually I don't have the sculpt anymore for this, so I can use my normal maps, I'm just gonna redo everything.
And so like, all of this will technically not be necessary, which is fascinating because what that does, and I think what's really important about this, is it frees you from having to think about the technical limitations.
Your job as an artist is to be creative, to say, does this shape language work for me?
Do these colors work for me?
The fidelity, the amount of pixels, all of that technically should absolutely not worry you at all.
And some piece of technology should just automatically take care of that.
And so that is around the corner, which is interesting.
The next thing, however, that is interesting is that we can literally commoditize all kinds of sort of content creation.
So we, you know, a great example of one being animation.
So this facial capture on that dude over there is literally done with a just off-the-shelf iPhone that anyone can get and then stream it directly into Unreal and pair it up with a cheap $1,500 motion capture suit and get a full performance capture that you can do live.
Currently.
you know, at your apartment.
And so the idea that we can democratize the creative process to a point where you as an individual creator can just be like, oh, you know what, I wanna make a bunch of cool cinematics for my game, let me do that.
That is pretty mind-blowing, and it's only gonna keep going.
And I think something that's really exciting about all of this is that...
we kind of don't have to pull all the weight on our own anymore as just game developers because we're so used to being responsible for all of the advances in computer graphics and technology related to that but now all of these you know social companies and you know just general tech giants have figured out that they can make money off of you by buying poop face emojis so they're pouring crazy amounts of money into it and we as game developers can actually benefit from that because now they're doing all of the R&D that we can shamelessly use and so that is good.
And you can expect to take more and more advantages of that.
The other thing that is interesting is the actual content creation of 3D meshes.
And there is a whole bunch of research into like, oh, can we turn a picture into a 3D model?
And honestly, the quality is not that great.
Like, I'm not holding my breath for this one.
And I think something that is much more likely to happen is we're gonna take a process that has proven to have the fidelity first that we need, and then we're gonna look at it as a whole bunch of points, and then we'll be like, hey, where have we seen this before?
And it's basically the same problem.
Can we speed up photogrammetry 20 times more and use less images?
Because take a bunch of pictures with your iPhone, we super resolution them to double the size, then we speed up the process of turning it into a 3D model by filling in more of these missing points with AI, and then at some point you can literally generate high quality 3D assets with your phone.
And that would be really cool, because that means that now you can actually focus on composing your worlds and communicating vision and sort of telling stories and all of that.
And the technology will allow you to do that.
But now, of course, you're wondering, well, what about materials?
Well, I'm sorry to say that is also happening and the the cool thing is and I Like sort of that way of thinking if you can look at a flat image and figure out what is a highlight What is a shadow coming from the surface?
Sort of bump and what is just the base color and there's no reason we can't train a neural network to do that And so the ability to decompose a single image into like a BRDF is something that's been prototyped.
It's there.
You can probably find the source code online if you want to to mess around with it.
But the idea is that all of these technical steps that we're so used to taking are kind of slowly getting picked off one by one, which can be both scary and interesting.
We're gonna talk about the scary part, but for now the main thing that I'm trying to sort of get across here is just to make sure you are informed about what's happening.
The interesting thing that happens with a lot of AI training is that the whole point of it is to figure out the underlying features of whatever you're trying to teach it.
So if you show it a bunch of images, either they're labeled, or in this case they're just somehow grouped based on whatever properties they have.
You can have a system that figures out that, oh, there are all of these properties that correspond with something being old versus new, and then you can literally have a neural network, like in this example, that can actually just age your surfaces for you.
So you just drop in a texture and go, I want this to be old now.
And something that is fascinating about this is that the creative intent, the creative problem solving stopped with you saying this needs to be all down because the rest of it is like, oh, which pixel do I put where?
And and you still have the freedom to go in and retouch afterwards.
But a lot of the time in a production, when you have a lot of worlds to build.
all of this is a lot less relevant to you. There are only so many things you care about and what this technology would actually allow you to do is have the freedom to choose what you want to spend your time on manually finessing and adjusting instead of having to constantly be bogged down with trying to finesse or not even finesse just scramble to get everything in and that honestly one of the things that broke my heart a lot you know working with artists at a game studio that had deadlines that had to ship products was An artist once told me that he never gets to do his 100% because everything always gets to like 80% and then it's always taken away because there's so much game to make and you need to rush and just the sheer volume does not allow the freedom for an individual artist to say, this is really important, I wanna polish it.
spend three days on this and make it the most freaking amazing statue or crate or whatever else it is, but we kind of lost that freedom through the fact that the amount of content that we have to produce is just mind-boggling, and we're just scrambling all the time to cover our bases, and I think that this is going to be a very helpful sort of aid in that problem.
We're back to style transfer, which is still useless, but there's interesting applications to it which might actually make it a little more useful, and it, of all places, is going to be about stylization.
So.
Okay, we know that like I don't want to just build a final image and then go, oh, could you now stylize this for me?
Because artistically that I can't control the process.
It's of no interest.
But what if I already have a style?
I'm halfway through a painting, and then I have this piece of reference that now I just have to like repaint.
because it doesn't fit with the rendering style that I have, well, that is a lot different of a problem.
And then if you can have a system that will just sort of pick up on the artistic cues that you've set forth and automatically fill it in for you, now you're saving time.
Now you can still paint on top of it, do whatever you want, make it yours.
but the fact that you don't have to do the work that you don't care about is going to be extremely valuable. And there's just another example of that. And that I think is very interesting, because we care about preserving our creative intent. We care about preserving our artistic style. And this is actually an example of technology that is quite literally focused around that. It's not there to tell you how your style is supposed to look. It's there to learn from you, pick up on your cues, and then apply them to whatever you're doing, which I think is a lot more of a healthy approach to look at that.
Okay, the next is generation. And I'm sure you've seen a bunch of these videos going around.
Generative adversarial networks, generating fake faces.
If you go online, I think there's a website called These People Don't Exist, and it's basically just generating a new face for you every time.
And then someone really smart made a website called These Cats Don't Exist, where they generate you a fake cat every time.
So I highly suggest you check it out.
But the cool thing is we can generate things.
The big problem is we kind of can't control them at all, which also kind of makes them useless for us.
Because what we want is we want directability.
We want to actually articulate the features we care about.
We want to tell the AI how we want this to look, and then it should kind of do the job.
And so the best we have right now is basically navigating this weird feature space of like, oh, all of these images are kind of similar and I can blend between them.
And so that is sort of a step, right?
Because what's interesting is in all of this similarity space, there's possibility for discerning some actual parameters.
Like, oh, you know what?
I just want a bigger nose.
Or I want a different eyebrow shape or something like that.
And once we figure that out and we can actually expose that as controls to artists.
it's gonna save you time. Now creating characters is less about applying every single brushstroke and more about what is about this person that makes them who they are. What are their facial features? What is, you know, the particular, whatever, is there a scar that tells a story?
Is there whatever color of their hair or eyes or whatever else? And so that part is interesting.
And the interesting part is it also applies to other things.
most things and it's all being done in 2D. I think we're reasonably far from doing it in 3D yet but just I think something once again that's extremely important to take away from this is not the technology itself. It's that idea that your creative process becomes closer to art direction that as you work.
you don't have to apply every single brushstroke yourself, but you're actually directing a certain system to say, oh, I wish these cars were more like this, or I wish this interior space was more like this.
And then what that fundamentally allows you to do is it empowers you to do cool stuff.
And talking about this creative problem solving, right, where AI is sort of your junior artist just constantly pitching you ideas, and you're going, yes, I like this, I don't like that, let's go more with this direction, no, in this direction.
I don't think we should underestimate the amount of creativity that we can get out of this, and I think this video is going to be a.
In the first experiment, robots were asked to walk around while minimizing the amount of foot contact with the ground.
Much to the scientists' surprise, the robots answered that this can be done with 0% contact, meaning that they never ever touch the ground with the feet.
The scientists wondered how that is even possible and pulled up the video of the proof.
This proof showed a robot flipping over and walking using its elbows.
Talk about thinking outside the box!
Wow!
I think something that's really cool about that, and I think something that resonates with the art direction part of me, right, is whenever I bring a problem to an artist, I don't wanna tell them what the solution is.
I wanna present them with a problem because I know that they're gonna come up with way more creative things than I would ever have.
And I think that applying the same approach of being the person who asks the right questions, of actually presenting a system with the correct problems to solve, is in a lot of ways going to be the root of the creativity that we get to exercise, but also going to be the power amplifier for the work you do.
and also just going to expose you to a lot more ideas, right?
Because that's what we do with concept art all day.
I need 20 variations of this.
Or here's the problem we're trying to solve with game design.
How's that going to look?
And if you can just get options fed to you at all times, that is just going to make you that much faster.
Okay, there's another video just because it's fun.
These robots figured out how to use their limbs and now they're fighting for a piece of food, basically.
And now, and iteratively figuring out how to like push the other robot away.
All right, let's see.
Like, no, it's mine.
or one of them I think just figures out how to jump in.
Just knock it out, boom.
This one's cool.
But I think something that's really fun about that, right, is once again, it asks us and forces upon us this sort of very introspective line of questioning of, where's the value that I provide, right?
Is it in actually in setting up these goals right?
And we're gonna talk about that in just a little bit because we're sort of zeroing in on the next part, which is like, okay, what is an AI as a creative partner?
But first, we're actually gonna do a really boring bit that I strongly feel that not enough of the art community is informed about because I...
I can't stress how much this impacts our ability to be creative and we never talk about it, which is monies.
And the fact that teams are gigantic, the fact that people crunch, the fact that we have to stuff every game choke full of loot boxes and other freaking nonsense that we don't want to do in the first place, is the fact that we can't financially justify making a game because it's so freaking expensive.
And if you just look at how this breaks down, it's pretty ridiculous already.
Like, the cost of an average game from like a PS1 to a PS4 has grown almost a hundredfold.
We went from like a million dollars to like a hundred million dollars.
Which is crazy because our audiences have not grown a hundredfold.
The cost of a single game to the end user have not grown a hundredfold.
Yet somehow we are expected to build bigger worlds with better teams and somehow make money. And so I think that is the interesting problem because we always tend to assume that you know the evil money bag somewhere just going no you can't make fun creative things I need more loot boxes.
But the problem is that...
Just in order to break even like just for us to be sustainable as a business and have some creative freedom Like if we project it to like the next console generation, you basically kind of need eight million copies to sell just to break even Which is stupid, because breaking even is a horrible business strategy.
You can literally take $250 million, put them in a bank, take them out five years later, and you will have made more money than if you would have made a video game.
Like, how crazy is that?
And so I think that is basically something that is important to realize because it impacts creativity a lot.
When we're having these discussions on, like, why isn't there more risk taken?
It is because we cannot afford it.
It is because we as individual contributors to the process of making the virtual world are actually not productive enough and like that the productivity has not caught up with the exponential growth and complexity because all of us are expected to do 20 times more things than we were expected to do 10 years ago yet somehow we're nowhere near 20 times more productive.
And so that's the sad part.
And it affects people.
And I'm not going to rant about this again, just because I had to at the beginning.
But you all know about this all too well.
And yeah, I think we can solve this by literally making everyone a lot more effective than they are today.
At least, I don't know of a better solution.
But the other thing that is quite fascinating to me is If we were a movie industry, I think right now we literally only have figured out how to make superhero movies.
Because nothing else economically makes sense.
When you're making a video game, it has to be for everyone.
Because if it's not, you're just not going to make any money back.
And like, there's some sad examples, like I absolutely love vampire games.
There's been like two in the last 15 years that were of any reasonable quality.
Is that not crazy?
You know, there's like cyberpunk games.
There's like Deus Ex and the new cyberpunk that's not out.
And that's literally all you get.
I'm sure there's a lot more people that have very peculiar tastes that they would love to have, you know, an offer for on the market.
We can't do that. We can't take the creative risk.
We can't experiment because it's too damn expensive.
And now that I've ranted through the money part, I'm going to make it up to you by having a damn break.
This is AI-based dancing.
So next time you want to look cool on Facebook, five years from now, you don't even have to do anything.
Just put a picture of yourself and done.
Okay, but now we're actually gonna talk about more conceptual things, right?
We know that we want bigger, better, beautifuller virtual worlds, and in order to do that, we need more effective ways of doing that.
But I think the way this whole dialogue has been structured has not been great.
And I've been to tons of video game studios, from tiny indie ones to gigantic, you know, AAA production houses, and literally everyone looks at me as I walk through the doors, like either in an indie studio, it's like, oh, that guy's gonna take our jobs.
And I just go, okay.
fine, let's get through that.
Or the other part is like, there's no way this works because it's too complex to work because AI is very complicated.
And I get both parts of the argument, but the problem is I think is in the implications sort of that we put in the name because the word artificial is kind of silly, doesn't mean anything anymore, but also intelligence is very debatable because we not even very discerning when applying it or not applying it to humans.
So I think the...
The better way to put it and the way we've been focusing on that is actually calling the assistive intelligence because the whole point is how do we assist you because artificial kind of implies replacement of something natural and this is not in any way what this technology can accomplish or should aim to accomplish furthermore.
And something we've been using internally at Promethean is like, we're trying to build the mech suit for your brain, which is the entire idea that you are in the driving seat.
We're power amplifying every single user by allowing them to build more fun things.
And I think a more generic metaphor that I'm going to shamelessly steal from Steve Jobs is basically the bicycle for the mind.
And I think it...
is such a beautiful metaphor that lends itself very well to this situation.
So if you don't know the story, there is a study in the 70s of the most effective animals based on transportation.
So at the amount of calories spent per mile traveled, and the most effective animal in the world was the condor, the bird, which is cool.
But then one of the researchers had that idea of what if we take a human and put them on a bicycle and then also enter them into that competition?
It turned out that a human on the bicycle is the most effective animal in the world when it comes to transportation.
with the amount of calories spent.
And so basically the technology that we have created has empowered us to sort of beat our natural limitations and power amplify us to do things that we might not have evolved to do in the first place on a more sort of a natural level.
And I think that that is very interesting, but also that is something that's very conceptually important.
why I think it's very important that you are informed about this because whenever you're going to have conversations about AI technologies coming to you know potentially be used in our workflow. This is the question you're going to have to ask is this technology trying to replace me or enhance my workflow. Is it trying to amplify what I do. And the truth is that.
whenever somebody tells you that your workflow cannot be amplified, you don't have to take them at face value. You deserve the technology that will actually serve your creativity, right?
And once again, that is why I think you need to be informed of this. And so the entire concept of building good technology around this is that we can actually celebrate human input, just like you've seen with the style transfer for the little things that actually picks up on your creative style and reinforces that.
That's a big part of what we do at Promethean is figure out a way, how can we learn the style of every single person who's using it and try to reflect it back at you, which I think is paramount and critical and should be part of any AI-based technology that is going to assist you, because if we are to be creative, if we are to make sure that this technology empowers more things to be done, it by definition has to be built to celebrate and sort of amplify our differences rather than trying to homogenize everyone into the same pool of just generalized data.
And I think that that is very important.
And, okay, this is just a slight pivot, but I think it's gonna make everyone feel better.
Something I hear a lot is like, oh, in the future there's not gonna be any artists because there's just gonna be programmers writing AI and that's it.
And I'm so relieved to tell you this couldn't be further from the truth.
In fact, it's probably the opposite.
And so the statement I'm gonna tell you today, and sort of the case I'm gonna make for it, is that the future of programming is actually content creation.
All of you are the programmers of tomorrow rather than the real programmers, which...
Doesn't make much sense right now, but let me explain.
First of all, conceptually, something that happens a lot and that is kind of a problem, and I'm sure you've felt it plenty having technical people build tools for artists.
There's this gap of like, there's these people who know how to implement a solution, and then there's these people who have a problem.
And then in the middle, there's like nothing, and then you're just shouting at each other and nobody understands what's going on, and then you get subpar tools that kind of barely get the job done.
And the problem is that people who understand the problem actually don't understand the solutions and vice versa.
And so how do you solve that?
And the fascinating thing is that I think this technology will actually help us do it.
And then I'm gonna make another tangent that leads into this.
So bear with me, bear with me.
Sounds very scary, but there's this concept that sounds really cool by the way, neuroevolution.
But it's basically based around the idea that artificial intelligence can kind of write itself.
If you have a particular type of neural networks that you're building, then you can have another type of AI.
Just configure different types of neural networks for your particular task and figure out how to write a good neural network for you.
And so this kind of caused a little bit of an upset in the programming community when Andrej Karpati, who's the head of AI at Tesla, basically tweeted that gradient descent is an optimization algorithm.
He basically said that AI is going to write code better than humans will.
And that's a programmer who does AI for a living.
And the reason for that is very cool.
And that's also a slide from his presentation.
So when you're in academia, right, you're trying to make AI, all you're doing is coming up with these fancy models and all of that crap.
But the actual production realities of it, like when you're trying to teach a Tesla car to not turn on the wipers when you're pouring crackers on it or whatever, which people have tried on YouTube, by the way, it has auto wiper detection when there's rain.
And there's like, will it wipe?
YouTube videos, haven't seen them.
Check them out.
But basically, it is a fascinating area of research.
But so in order to solve these problems, we're like, okay, have your car not drive over kittens or something, like take something very mean.
In order to do that right now, at Tesla, you don't write code.
You basically go and take a bunch of pictures of kittens, mark them up, and say, hey, please don't ride over this.
Or if you can take a picture of that, you actually build it in Unreal, show it the content, and say, hey, this is what you can do, this is what you cannot do.
So the people programming the self-driving cars today, For the most part, 75% of their time are concerned with making content, digital content, virtual content, to actually show it examples so that it knows what it can do and cannot do.
And furthermore, there are actual services today.
Like, Google has their Cloud AutoML that builds image classifiers.
Like, it's a type of neural network that you'll basically show an image and it will tell you if it's like a hot dog or not hot dog, basically.
And you can train your own, like, is it elves or orcs or something like that.
And the way you do it is literally you take a bunch of images, you put them in a folder, you upload it to Google Cloud, an hour later you come back and it has created a custom tailored AI model for your problem that you can use now via a link on their cloud.
So you've basically created AI without ever writing a line of code, just by creating content.
And so, you know.
I rest my case. The future of programming is going to be content creation. When people say that everyone's going away about programmers, this couldn't be further from the true.
In fact, the opposite is true. We're going to need a lot of people building virtual worlds to help us make AI smarter, to help it build cool things, but also to just train it to the particular situations that you're trying to adapt it for.
And so that is very interesting.
if we were to continue with that metaphor, something that's very important through all of this is that future of art is kind of going to be art direction, which is pretty obvious on the surface, but I think something that happened with a lot of us is that as productions became more complex, they became more expensive, they started taking more time, we saw more value in specializing because somebody needed to figure out how that ZBrush thing works or whatever else, how to do normal apps.
And then after a while, you kind of realize that that part has nothing to do with art. Like the art part was the creative idea behind it. The shape language the forms the color and all of that. And we've gotten so caught up in this where all of a sudden we equate ourself with our value as an artist with how well we unwrap things or how you know how clean our bakes are which once again kind of has nothing to do with it. And I think that As these processes that do not contribute value sort of fade away one by one. Something that I absolutely love about this technology is that it forces upon us this conversation. What do I actually do. What do I actually want to say. What is important to me as a creator. And Keith talked about value today this morning. I think that was very valid valuable. No pun intended. Is that.
We now get to re-inspect those.
What got us into this in the first place?
And how can we live out these values more through our work?
And we, for the first time, will actually have the freedom to do that because of technology, which I find very fascinating.
And a good example that I really love is, if you haven't guessed so far, Blade Runner.
So this is actual Blade Runner, the shot from the original movie.
And up there, it's a Broadway downtown in Los Angeles, the street where they shot it at.
And so Blade Runner is one of the most iconic visual movies ever.
And yet they did not have to build everything from scratch to make that movie.
Nobody modeled a chair for the 28th time.
Nobody, you know, created another exploding crate or whatever else.
You take a piece of content that is there and then you adapt it to communicate a vision, right?
If you're making a movie, you go on location, you light it, you dress it, you add custom props that actually make sense for your fiction and then that is what's going to resonate with your audience and to me, I think that is very important because it's going to be more of what we are going to have to do.
This is the value that we add as artists.
When you're building your virtual world, it's not that you know how to move a triangle or a vertex or whatever else, it's that you actually know where to move it.
And so that's going to be the process, and it's very exciting.
And shamelessly, this is the first ever GDC talk that I did back in 2013, and it kind of echoed all the same subject, is that at some point, we will be able to create absolutely everything in the world.
And at 2013, it seemed kind of pretty far out.
Now it seems a little closer.
inevitable and it's all going to happen within your lifetime.
You're going to be able to create any kind of virtual world to the level of fidelity that you want to.
And then the question is, what are you actually going to create?
Right, because just replicating reality couldn't be more boring.
I don't want to look at another parking garage or...
the things that I look at in life.
The value that all of you bring to the table is actually putting a twist on it, figuring out how to actually transform it in a way that's going to be meaningful for your audience.
And there's been a lot of interesting conversations today during the bootcamp about this.
I'll hopefully give you some inspiration on this.
But I think that that is very important.
And I'm gonna quote Pablo Picasso here.
He had a very fascinating quote in the 50s where he said that computers are useless because they only give you answers. And I think that that really hits home on what we do as creative people because our job is not to have answers to a particular problem. It's actually knowing which questions to ask because the questions are the valuable part. And you know the public because it was smart because you can tell from the picture.
But I think that's what this brings us towards.
This brings us to the realization that we actually need to focus not just on methodologies or processes or knowing which buttons to click, but the actual focus on knowing which questions to ask.
And I'm gonna propose you some.
How about where's the value in what I do?
That is the number one thing and you know it's going to be different for every artist. Some artists are fantastic with color for example and they just want to drive that point home and sort of stimulate you in a way that's consistent with that. Some actually just want to straight string together stories and compositions and that's perfectly fine. You can focus on that. But the question that you cannot.
not ask yourself is basically that because if you don't then you're not going to know what to do once all of the sort of extraneous processes just fall away. This amount of introspection that is forced on us by technology is fascinating because it gets philosophical really quickly but it's also kind of really exciting because that's literally who we are. We are artists and yet we don't know what that means and we'll have to figure it out really quickly which is which is really exciting.
And then the next question is a little bit more pragmatic, but I think it's relevant.
There are things that you think are a value add, but then the other question is, what does your audience think?
Do they agree with what your value add is?
Because there are some people who absolutely love whatever, modeling crates, and there's nothing wrong with that, but it's going to be very hard to do this for a living if everyone else doesn't care.
At that point, it's a hobby.
And that is a very important distinction that you will have to make is, OK, what am I in love with here?
Am I in love with building worlds?
Am I in love with a particular process that might exist?
There are people making pottery by hand.
And it doesn't scale, but it's a thing.
And you can still pursue it.
And if you do it well enough, you'll make a living off of it.
But it's just something that you unfortunately need to think about.
And then the other question that is potentially at the intersection of the two is, if there's something that I love doing, just hopefully building worlds and, you know, trying to inspire other people, and then people actually wanna pay money for it, how can I focus on that more?
Because this is, literally, these three questions are gonna drive how your work is going to change years from now.
Or, I mean, maybe weeks from now, who knows?
But basically, these things are fundamental, they're going to be behind that.
bring home that point is that through all of that this basically forces you to distill what is art for you which I think is very interesting and for me the thing that I love about it most having spent a decade trying my best to serve artists and not wreck microphones is that.
Artificial intelligence fundamentally if we do this right and if is a very big if and that's important is a great power amplifier But what needs to happen is you need to be informed about it And you need to demand that it's the power amplifier that you deserve you need to actually be vocal in communicating the needs for technology that you have.
Because, you know, the masters of old made their own paints and mixed their own colors and all of that, because it was important to know your tools.
Right now, they're so incredibly complex that it's borderline impossible to expect people to have, you know, competence in producing these tools.
But what you actually have is the knowledge of the problems that they have to solve.
And that is paramount, and that needs to be vocalized as much as possible.
And then just going back to that idea of something that...
It really warms my heart as someone who worked hard to try and empower artists is that this technology whether you like it or not will make it a lot harder to be insignificant.
You can't just sit in a corner make your UVs and just expect to make your paycheck and go home.
it's a power amplifier, which means that, you know, now you'll have to embrace it.
Now you will actually have to tell stories and build worlds and bring everything, every ounce of your personality and your inspiration and the things that made you wanna do this in the first place into your workplace and start realizing that they're important, that you are important, that what you have to say is valuable and you don't just have to sit there and assume that all you're gonna do for your entire creative career, just...
pick which type of crate you're going to model.
And I know a hammer and crates a lot, but you get the point.
And so if there is a takeaway from this entire presentation is that.
I really hope that you can start applying that logic now.
You can start realizing that what you have to say actually has value.
You can start thinking about what are you going to say when the time comes, because it's gonna come sooner than you think.
And then when the time is right, you're gonna shoot for the moon and make amazing things, but also demand that the tools that people are making for you are actually deserving of your inspiration and your creativity.
That's all I got.
Thank you so much.
We have like 10 minutes for questions if anybody has some, or if you just want to throw something at me for making AI.
I guess my question would be, how do we start using it?
So like, as a lead artist, one of the things that's very important to me is eliminating all crunch, while at the same time not limiting creativity, and those things don't go very well together at all.
So we're always looking for ways to improve pipelines in Houdini and procedural texturing is a way to do that.
But I can already kind of see the pipeline for an AI workflow in my brain, but I can't.
How do I get into it?
Like how do you start using it?
No, that is a very good question.
It's definitely very nice.
And something that I'm gonna say actually that I think is really important talking about procedural pipelines.
where I think conceptually they're not gonna have the longevity that we expect.
They're a very worthwhile investment right now, but something that happens with them is that conceptually the people creating procedural pipelines are not the people who have the core expertise in the problem.
So you're a tech artist, you're a programmer, you know how to write code, you're gonna give me three sliders to make my art.
That is basically the process.
And then there's like some back and forth with like, okay, I kind of tell you how to fix it.
But conceptually, once again, this is not the best way to do it.
Because for example, the way we do it internally with Promethean, right, is you build environments, it learns from that, and then it reflects that back at you.
So the people producing the art and people executing on the core competence are the programmers of the technology that is going to empower them.
And I think conceptually that is.
just long term a much better approach not just in games everywhere.
If we can have people who who have the knowledge of all of this problem solving actually be the creators of their own empowerment that is that much more worth it and on how to create it or how to how to get into it.
It's going to take a little bit more time where you.
By the way, super welcome to reach out to, obviously, us.
We're working with a bunch of game studios and sort of working through these steps and trying to empower people to make content.
But as far as this general rollout, I think it's going to take a little bit, but probably not as long as you think.
I'd say a year or two, where most people will be able to get into it.
So that would be my prognosis.
Oh, hello.
Hey.
Sorry.
Fascinating talk.
Thank you.
I have a question which is kind of an open-ended question, I guess, but it relates to, let's call it expectation creep.
It's basically, if you look at PS1 games and how they looked like, I mean, it's not like the people who created it were less talented than people are nowadays, it's just they had worse tools than people have nowadays.
So if we look at AI as just another tool to make things more effective, what, to just boil it down to one simple question, what gives you the impression basically that the, a new workflow won't be me sitting in the office just feeding the AI till 1am?
Oh that's a great question in fact I get it a lot and it's basically the question is conceptually won't we just crunch more with different tools if I were to replace that and the answer is actually money.
which is fascinating because if you're making, so right now we're making a 40-hour game and it's big and everyone's content and no one's saying, hey, I need a bigger game.
If at some point, instead of making a 40-hour game, you're making an 80-hour game, what you're doing is you're doubling your cost without potentially increasing your profit at all.
And so there's going to be some sweet spot that is going to figure it out of like, you can work more, but what that means is you're just.
wasting time potentially.
So it's way more self-indulgent.
And I think actually it's very useful for an artist to keep track of that because sometimes it's actually a good rebuttal for feature creep that comes from game designers or producers when they're like, oh we need 25 times more content.
And you go, can you prove me that this will have any significant value on the return of the game, for example.
But the other thing that is important that applies to this that I had and that I think I totally forgotten was Yeah, I don't remember.
Sorry, I had a second point, but feel free to come by after this and maybe I'll remember.
Okay, love to.
Thank you.
Me and my friend tried to make a graphic novel.
those technologies seems like we can invest in our sketch or our artwork.
My question is, does AI require super expensive hardware like a high quality GPU or CPUs?
You'd be surprised at how performance friendly this can be.
There's a lot of purpose-built hardware that's being released these days with whatever TensorBoards and units and stuff like that.
But a lot of it can be run on GPU.
But also, it's costly when you're trying to do it for every frame when you're doing it in real time for a video game.
And that's what NVIDIA tries to have you pay a lot of money for.
But if you're just using it as a tool that you can just run once, then it's actually reasonably fast.
Like I don't think you're gonna be very hard-pressed to find modern day hardware that works with it okay.
So.
Thank you.
Yeah, of course.
Hello.
Well, first off, thanks for the talk.
I always appreciate your talks, they're awesome.
Thank you.
So I was just wondering if procedural tools can help bootstrap more advanced AI systems because you have inputs and outputs and you could tell it what's good and bad.
So I mean do you think that's a potential for...
I totally think so. It's interesting. You know we had this conversation recently and the question was essential essentially about efficiency. Right. And if you look at the internal combustion engine its efficiency in transforming fuel into actual motion is about 20 percent 80 percent of the energy is lost to just heat and just being 20 percent effective is enough to fundamentally transform the world to do.
these amazing things that we couldn't do before.
And so conceptually that's fascinating, but that's where you're not gonna get AI day one that's like, here's a final thing for you from just like three button clicks.
What's gonna happen is you're gonna have a tool that's gonna accelerate your workflow 10%, then 20%, then 30%.
And so yeah, you might be able to kickstart it with like a.
a procedural, whatever, like substance-based texture pipeline that then you feed into this system that then accelerates your workflow a little bit more and a little bit more.
But something else that's really exciting about this, there's this concept of a positive feedback loop.
Every time you use it and then you change it and you correct it, you basically go, okay, now learn this.
And now you've increased the amount of data that you have.
And so the more you use it, the more it actually learns from you and the better it becomes, which is very unlike any other tools that you will use.
And so that's...
Yeah, you're absolutely right in that point, and I think there's just more to it that will basically, once we sort of get the ball rolling, it's gonna snowball pretty fast.
Thank you.
Thank you.
Hi, really great talk.
Thank you.
Do you have maybe an example, you being in that field of any games that are out that you can point to like a system where this has been applied?
Well, like the one on the surfaces, Remedy uses a bunch of like facial animation where they can just convert video to actual animation per character and they use it based on like neural network solvers.
So that's a simple one, and that's in content creation.
And then there's a lot of use cases around, like Ubisoft has this division called LaForge, and they do a lot of also facial animation from different text based on different languages.
So in different Assassin's Creed games, depending on the language, it'll just auto-generate facial animation.
So stuff like that, but it's interesting because there are two main fields that people are researching right now outside of content, which is testing, because the games are so big, nobody can actually effectively test them.
There are areas of like...
Assassin's Creed games that like literally no tester has ever been to potentially or like tested a particular counter in and all of that stuff And then there are other parts of this that are gameplay, which I'm super happy about So something that valve did that was brilliant and like what left for that to where they had the director concept of there was this?
Hard-coded AI that basically figured out how exciting the game is for you based on a set of metrics and then I was like Oh, you look like you don't have enough of a challenge Let me throw in some zombies in here and then you're you know cursing it left and right and screaming at your friends over the network and it was a lot of fun.
But that's basically that concept kind of hasn't been tried much afterwards and now people are investigating more where you can have an AI game master essentially over your virtual you know D&D game that is actually just a 3D interactive experience and I think that is really cool because that enhances the core competence and while there's research there's different types of games that use that you can really easily do it for like a racing game right where you can train a model.
that is reinforcement learning basically, or anything competitive with a limited set of inputs you can probably do today convincingly well.
But you know what the scary part is?
When you start doing these reinforcement learning models, they actually learn from the player and so they will inevitably learn how to beat it.
So then the problem is how do we actually make it fun now?
Because you can teach it how to play, it'll play really well, it's just that no human will want to play it.
So it's a different set of problems.
Thank you.
No, my pleasure.
Hey. So my question was, there are a lot of games that are not, their structure is not based on this story. So they're more on level design or not even level design, just shoot, kill and go forward. So do you think later on it's going to be more like, it's going to be more valuable to make story in games or things like that?
I'm so happy you asked that.
Because I think something that's really important, and that's going back to that concept of like, if we were the movie industry, we can literally only make Spider-Man games, or whatever, like superhero movies.
Because I don't know what the equivalent of like a good will hunting is in video games, or like a million other amazing, dramatic.
fascinating, gripping stories that are absolutely life changing.
And if we can dramatically improve that, what's going to happen is we're going to dramatically expand the amount of people enjoying video games, because right now there's a limited amount of people.
And, you know, you talk to.
A lot of people, you know, they're on the financial side and they go, no, video games grow so much money.
We have everyone's playing Candy Crush.
Great. Everyone's playing Candy Crush.
But if we can figure out a way to actually give people an experience that they can relate to, that is of enough quality that they can see themselves in it and it gives them an interactive view on what their life is like or someone they know life is like and just let them experience something in a way that wasn't possible before that doesn't involve blowing everyone's brains out, then I think we're just going to have a lot more people.
actually enjoying that and I think that that's great because even the word game is kind of antiquated in a way because fundamentally what we're trying to do is we're trying to take you on a journey we're trying to give you an experience and then whatever that experience is it doesn't have to have rules it doesn't have to have as you mentioned like a linear structure it's all about what do you want people to do and it's weird and it's kind of off tangent but I think it's extremely valuable because it ties into that Walmart does training for its employees in VR like interactively.
And one of the things they do is they actually have them fire someone as part of their management training in VR.
But then what they do with that is as you're firing someone in VR, they actually capture your performance.
And then the next stage of your training is you're actually sitting there as an employee watching you fire yourself.
And the ability to create interactive experiences like that, that are actually going to speak to us as humans, and actually allow us to experience what it's like being in someone else's shoes, are kind of sort of paywall locked behind the ridiculously expensive production costs.
And once that dissipates, there's so much social value that is going to be ungated by this, where we're like, oh, we can do all of these things to actually understand each other better as humans and not be assholes, which is valuable.
I'm sorry, I rant, but yes.
So the short answer is yes.
My other question is if we have time.
Of course.
Was, so the structure that you talked about in terms of just image processing and everything, we have the same structure in literature.
we have literature, books, stories for thousands of years.
So we have those structures.
So do you think in future we're gonna have stories made by AI?
Oh dude, let me tell you.
Sorry.
I literally, I was lucky enough to hang out with someone from OpenAI recently.
And OpenAI did that research where they created this model that basically you give it a couple of sentences and it continues the text for you and it can go on for pages and pages, it writes you an essay.
And we've given it like two lines of poetry that actually rhymed and it was like.
And the first two tries, it spit out absolute garbage.
But the third one was actually very sensible.
Like, it was like, oh, I could believe that a human wrote this.
So the scary part is OpenAI did not release the train model that they built for this because the potential for this to be used to troll people on the internets with fake whatever...
propaganda bullshit is ginormous, but the potential for it to write interesting narrative is also ginormous. And it's interesting because it all becomes about what is the creative part about writing. Because if you look about writing in general, it's also very scientific. There is like I have my structure, I have my story beats.
Something has to like, I need the inciting incident on page 10.
My darkest night at the end of chapter two has to be this.
And so like there are all of these very scientific things that exist around the writing process and the question is exactly like with art, like what is the shape, the tone, the color, the lighting, the subject that you're trying to communicate?
And that's where, yeah, absolutely agree.
In fact, we did a demo of Promethean for guys at Chaos Group, the creators of V-Ray, and they were actually talking about wanting the same interface that Promethean has for creative writing, because of the same process.
You go from the big shapes to the small shapes.
You define the overall theme, and then you go, let's zero in on this, let's zero in a little smaller, let's zero in a little smaller, and I think that's gonna apply to everything.
That's basically how every human process is going to be, which is, you're gonna have things you care about, and you're gonna have things you don't care about.
And if you can have something else take care of everything you don't care about so that you can specifically specify the things that are important to your story, to your narrative, to your characterism, that that is what we're going to end up doing. Thank you. Thank you.
Hey, thanks for the very cool talk.
I might be on the pessimistic side.
One of your slides said the future is in art direction, and I really like that.
Say if in the future every one of us in this room becomes an art director, we make our own game without worrying any of the production things, do you think AI could be a better art director than every single one of us combined?
That is a good question and I think something has been very interesting to us. And you know what. So I'm going to start with a segue because I think it's important. There is a very optimistic future but it's a potential future something that I don't want anyone to get sort of very blase about is the idea that someone can't come in and just go.
here's a tool, it's going to be crap, but economically it's going to solve a problem for you right now, and then we're all going to be locked into this.
And so that's where I think it's very important to actually, for everyone to be informed and know that it's up to you to say, you know what, this tool does not deserve me.
This is not good enough, let's figure this out.
And I know you can do better, I don't take no for an answer, and then we'll do something.
But then just to go back to your point, something that's very fascinating to us, for example, building Promethean, Promethean builds virtual spaces.
And it doesn't have, it understands a lot of concepts, it doesn't understand all of them.
And sometimes we'd see interesting combinations of like it created a composition in a space that a human looks at and starts projecting sort of a story on.
It's like, oh, something happened here.
Like, oh, this vase on the floor.
Like, oh, somebody had a fight.
And it's entirely an accident, but we as humans tend to project a lot of interesting sort of internal reflections that we have.
It was a fascinating discovery, but that's where I think there are two types of experiences.
There are experiences that we will find for ourselves.
like with music. Sometimes musicians say that they want to write lyrics that resonate with everyone and that's kind of fine because there will be experiences like yeah you can make a very generic AI based experience that everyone will see a little bit of themselves in. You know a super generic pop song when you describe the love interest like oh that literally sounds like every single person you know she has two legs and two elbows or whatever like you've heard the.
radio, but it's kind of like that, like that part might work, but then the other part I think that's very interesting, there are very directed experiences where, at least for me, art is about making choices and sharing these choices, and there's, you know, for every generically broad pop song, there's a Bob Dylan song that's like, this thing happened.
Like if you've never heard of it, I'd highly recommend check out The Lonesome Deaths of Hattie Carroll.
And it was recorded like 1964.
And it's literally about an incident of basically a rich white man killing a woman for no reason with a cane because she was a woman of color and he was drunk.
And it was literally a song exactly about that and nothing more.
And it has such profound impact because it has so many layers of very deliberate intent that it tries to impart onto you.
And I think that, these experiences can coexist. It's fine if people want to see themselves in something very broad, but also if somebody wants to tell you a very specific story, I think it's going to have potentially a higher impact because it's tailored to you, which is very interesting.
So right now we have to make video games that everybody has to like because we need to sell them to everybody. If we don't need to sell them to everybody and we just need to sell them to like 20 people, we can make something that these 20 people will not just like, but they will absolutely freaking love it.
And I think that's where the value is.
And I don't think AI will able to do that.
It's good at generalizing rather than making something extremely particular.
Hopefully that answers that.
Hey.
Just a quick follow up question to that.
So if we proceed down that kind of line of thinking and AI ends up generating a lot more of the generic kind of typical movie kind of.
kind of, uh, just generic stuff.
Uh-huh.
Um, do you think that could end up in a situation a bit like, kind of, was typecast with a Steam Greenlight situation of...
the good gem games and whatnot being developed by kind of creative people being lost in the rough of like thousands and thousands of AI generated kind of not so great games. That is a very good problem it actually gets brought up a lot also yeah like how much more content can we want to have because there's already so much that nobody has the time to consume it which makes sense. I think there's part of this like cultural phenomena that we all want to make sure we consume the same content so we can talk with our friends about it.
which is interesting, but that kind of limits the ability to cater content to people.
But something that's very ironic about this problem, it literally Netflix is pouring like bajillions of money to cater the content to you and go, oh, you like this character in this movie, let us literally cut out the screenshot from the movie and show you a thumbnail with this guy who's in this movie for three seconds.
But we're going to show it to you. So you click on it and watch it.
And basically, I think what's going to happen is the more content appears, the better the technology becomes that actually finds the right content for you.
And so it's going to be like an arm race of sorts.
But I think it's also a good problem to have where we have more good things rather than less good things.
Sure. From a financial aspect of that then, if there is so much content and everyone gets their own personalized kind of...
Experience.
...library of games that they want to play, does that not mean that each individual one would technically get less sales and whatnot because they're being tailored to individual people and it's not getting the broader audience and therefore the financial investment?
Potentially, if you look at a lot of indie games, right, like you can, depends on how your budget is structured, the development, but you can sell whatever, like 100,000 copies and actually make a decent amount of money, which is, in, you know, grander scheme of things, is not that many people.
But also the other thing I think that's interesting is, you can create content that can, in marginal ways, cater itself to different people, where you can have the one broad experience, but then it's like, oh, whatever, like in my game, this guy's going to be a little bit more of an asshole, because I happen to like it.
That sounds horrible, but you know what I mean.
The experience adapts.
to you to a point where it's still the same experience.
You can still monetize it sort of more broadly, but you actually sort of in that D&D game master for you that everyone shares an experience, but it's a little different.
Not unlike the interactive Netflix Black Mirror episodes that basically had choices for different people so that they could express themselves.
Great.
Hopefully that works.
Thanks for talking, really fascinating.
Oh, well I appreciate it, thank you.
Andrew, thank you. Super interesting stuff. I have a question. Do you see like a kind of recursive learning like you know as you're training AI and then AI is training from you and you essentially start repeating the same patterns and as you train from AI and AI trains from you, what do you see happening? Do you see like cats within cats kind of stuff?
Oh, it's interesting.
I think there's a certain realization that is occurring right now where a lot of data is kind of pointless.
Like self-driving cars is a good example, where we have millions of hours of recording of just driving down the road.
And it will work fine, and so that sort of, you have like a bell curve distribution, right?
Like that middle section, it's kind of taken care of with like 10,000 hours, you don't need a million hours.
And so at that point, you can kind of stop.
The problem is what's called the long tail.
It's like all of these cases at the edge of your bell curve where we're like, oh, there was a cat that was wearing like a traffic cone on its head running across the street.
Like what the hell does your car do at that point?
And like all of these is where you actually need your data.
Like that's where like people sitting at Tesla in Unreal are making cats with traffic cones on their heads.
But.
So not necessarily that, but I guess the idea is that the point is not to just feed it as much data as possible because there's different types of quality to data.
And you want to make sure that the data you're feeding it is actually valuable in terms of giving it new skills or new features.
Like something we're aware at Promethean, for example, when we build a new type of environment, we sit down and we break it down, what is valuable?
Like how would I want to art direct it?
What are the adjectives that apply to it?
And then we kind of build towards that.
It's not that let's just throw everything we know about the space.
How would this look if this was messy?
How would this look if this was destroyed, dilapidated, new, old, and just applying all of these concepts?
And that's where I think at some point you just stop training just for the sake of training and you actually look for the quality of the content.
Hopefully that answers that.
All right, thank you guys.
You made it through Tuesday.
Come on, round of applause for you.
