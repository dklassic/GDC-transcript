Thanks for that.
Well, good morning everybody. It's so nice that you guys all showed up.
It's crazy how many people are here. I wasn't expecting this many people.
Thanks Alana and Mike for hosting this.
I mean, you guys have an amazing lineup and it's going to be an awesome day.
So it's such a pleasure to be here and actually kicking this thing off.
For those of you who don't know me, I'm Richard Audin.
I'm the lead animator at Guerrilla Games, and the talk will be about the animation process of the machines in Horizon Zero Dawn.
A little bit about myself, I studied at the Utrecht School of Arts for animation and my main goal was always to become a feature film animator.
So in my third year I was actually very lucky to have an animation internship at DNA Productions during their feature film The End Bullion.
That was such an amazing experience.
I mean, I learned so much about the animation industry, animation itself, the workflow, and I got to meet a lot of cool animators that eventually just sort of like spread out through the entire industry after DNA got closed down.
So getting back to the Netherlands and graduating, I knew I wanted to be a feature film animator, but I knew my reel wasn't strong enough.
So I figured, okay, let me just work on my own and hopefully see from there what will happen.
But I still wanted to get some of that industry experience and the only studio that was actually doing something was Guerrilla Games in Amsterdam back then.
And it was like ten minutes away from my house, so I figured, okay, let me just at least send in my review and we'll see what happens.
And luckily enough, they called me up and said, yeah, you have an interview.
And a couple of days later, I actually got hired as a junior animator on Killzone.
The crazy thing is as soon as I started to work in-game, I just fell in love with that process so much that I knew I never wanted to do anything else and like 10 years later I'm still with Guerrilla Games.
Did a little bit of finishing off on Killzone 2, but got to really get my hands on in Killzone 3 doing the first person weapons, the new ones, and the Brutal Melee system that they had.
I skipped Killzone Shadowfall because I was already working on the R&D team for Horizon Zero Dawn.
The only thing that I actually helped them out with, just because the schedule was so tight at the end of Shadowfall, that I had to help them out with some of the cinematics.
But basically the last five years of my life have been all around Horizon Zero Dawn.
Recently, we just finished the expansion, the Frozen Wild.
So that's sort of me in a very short period.
I'm going to start a little bit with how the project actually evolved on Horizon Zero Dawn and the initial idea and the back story.
And I'll shortly discuss some of the prototyping phase that we went through, where we started exploring how these machines would actually move and how do it look.
But then I'll just cover a lot of in-depth production of the machines with multiple topics like the team structure, reference, movement, and the tech behind it.
And I'll finally end up with some of the polish pass that we did.
But if you're not that familiar with the project or you just need a refresher, here are some snippets of the machine.
I mean, how did this whole thing actually came about, right?
Back in 2011, we just finished Guilds on 3 and Guerrilla really wanted to change the direction so we basically just went to Sony and said, hey, can we just explore something new and they just said, yeah, go for it, which was amazing.
Basically what the studio did was they sent out a mail and they said okay if you have an idea just pitch it to us and you can actually pitch a whole game, you can just pitch a game mechanic and then eventually we'll just pick the top three that we like and we'll start exploring those.
So roughly around...
45, 50 ideas got pitched in a week, and Horizon was already the one that actually was standing out from the crowd from the beginning.
It was just like such a cool setting, and the theme in Majestic was amazing, but it was also the scariest one to develop because it was already a third person open world game from the get go, and we were just this first person studio.
Like, what do we know, right?
We explored a little bit of the other two, so there were three, but then eventually we just ended up with Horizon because everybody was just drawn to that thing.
And basically the pitch itself was nothing more than Earth being reclaimed by nature and it's now inhabited by these robotic machines that are now the dominant life species.
And the gameplay itself was still a mystery at this point, it was just that backstory that everybody just was drawn to.
Guerrilla put together a small R&D team of roughly around 25 people, and just a couple from every department, and we just needed to figure out what the gameplay was going to be about.
I was already the one from the beginning to actually start working on the robots.
Since it was such a new genre for us, we knew we needed to get some new insights.
And for me personally, I actually never animated a quadruped before this game.
So I had to become an expert really quickly.
And luckily enough, Animation Mental was doing this Animals and Creatures course back then.
where I learned tons about actually the approach of animating quadrupeds, the workflow, the rigs, all the different gates.
So that was really nice.
And then next to that, Guerrilla also hired a bunch of industry experts to start educating the studios.
To give you some examples, we had Stuart Zimida over.
who was a very famous paleontologist, to give us a class on animal anatomy.
We had Matthew Lund from Pixar do a story class.
We had Scott Eaton do a human anatomy course, for example.
So those were really nice educational moments.
And also what happened is we had to get a lot of hires in a lot of departments.
So it was either for capacity reasons, just because we were understaffed.
but also just because we had no knowledge of this game, right?
So we hired a bunch of industry experts that had done these games already, so they could just start filling us up in the gaps that we were missing.
And last but not least, study as much nature as possible.
I think I've watched every BBC Nature Planet documentary out there, like 50 times already.
And it was also like, it was just getting to know the behavior, but also the movement, etc.
And you learn so much from this thing.
And there's so many cool nature footage out there that...
Yeah, that's something that we just did a lot during the course of this whole thing.
So like I mentioned, we had no idea what the gameplay was, right?
So we started with a small R&D team just to explore the possibilities in our prototyping phase.
Basically the prototyping phase was all the search, okay, what is this gameplay?
And the idea behind it was to go as fast as possible with a limited amount of development time and see what works and what doesn't work.
And if it doesn't work, instantly throw it out.
If it does work, just keep iterating on it until we actually have something that's sort of like a nice gameplay feature.
And since our resources were so limited, we basically had to work with what we had or just create some super basic assets.
So.
We actually started out with this Lego Thunderjaw.
And the player character is actually Jammer from Killzone 3, which was the only female character that we did up until that point.
But we already knew from the first pitch that we wanted to have a female protagonist.
So that was actually something that we were very much pushing to, to get this in.
And looking back at this, it's actually crazy how many of the initial mechanics made it into the final game.
I mean, there's charges there, there's close combats, and it's all super basic, but I still like to see it.
Even in this movie, we actually already put in the option to shoot off the weapon of the Thunderjaw and then use it against himself with this awesome physics.
Look at that.
So after playing around with this.
So after playing around with a lot of the ideas that we had, this just took a couple of months, we finally created our first proof of concept that we showed to the higher peeps of Sony, and it looked like this.
And as you can see, the environment is a little bit more fleshed out, and we actually have a first proper Thunderjaw model, but everything is still very basic, and it's basically just a full playthrough of this boss battle, using all the mechanics that we developed up until that point.
As you can see, there's actually traps there.
The play is already setting tripwires as well.
But then all the other stuff that you saw, like the charges, close combats, etc. etc. is actually in this.
I showed this to Sony and they really liked where this was heading.
So they said, yeah, just keep going.
Find whatever you want to see, like what you want.
And then eventually, this sort of like concept turned into the reveal trailer that you guys saw on E3 in 2015.
Whoa, someone's angry.
Alright, time to shut you down.
So that whole track of finding the gameplay on the Thunderjaw took roughly around two years to get right.
And the idea behind it is if we can actually have all the states and mechanics and everything that we want out of this big boss battle, and if it's still fun to play, we can just chop all the small pieces up and apply it to the smaller robots.
So, that's why it actually took a very long time and that was kind of frustrating sometimes, but it definitely was worthwhile in the end.
And so like during this stage as well, I started to actually search what the style and movement of these machines were going to be as well.
And during our prototype phase, my art director actually sent me this video and said, yeah, this is what I think the robot should move like.
And as you can see, it's actually very jittery and mechanical, and that's just because there's no ease-ins or ease-out on the movements.
It's all these linear, grip and pneumatic parts that cause for a lot of overlap on this very unstable installation.
I know, right? So sad.
But just because of the fact that the movement is so unpredictable, that's the thing that he liked.
And it reminded him of this sort of zombie-esque type of feeling to that machine.
So with that video in mind, I started the prototype on this smaller bot that we were creating back then, which is also looking a lot more mechanical than the previous Thunderjaw.
Unfortunately, I couldn't find my initial test anymore.
But what I can tell you is that I never got it to look right.
As soon as I thought I had something, I exported it to the game.
in game it actually looked like there was a frame rate bug or like it was just a very bad attempt at stop motion.
So I just started to tone it down and eventually sort of like found a nice middle ground into this walk cycle that I made.
As you can see, it has this sort of like fluid motion, but it's still mechanical, and it does feel kind of creepy.
So I was actually sort of happy with this.
It's like, let me just sort of like start iterating on this.
And then as soon as you actually go into higher speeds, everything is out the window.
Just because you have that fast movement, it's almost impossible to actually keep this sort of like jittery mechanical motion.
And the only thing that I actually tried to apply to is on that chest, and you just see it popping back and forth.
But it was just like a last attempt trying to get something mechanical into this thing.
On this turn on spot I tried it again, but to me it just became this cluster of movement noise to these things.
And again in this jump, it's just completely out the window.
Eventually I found that I was actually animating these things more and more like realistic animals with an occasional jitter.
Or like not perfect spacing, especially in the starts and the settles.
Because that's where you can actually have a little bit of a wind up time.
It actually started to seem to fit the designs that we were making for the new machines as well, to actually make them move realistically.
And it also started to relate to the player a lot more.
So if you look at this grazer for example, which was our first terraforming robot, I started to animate that thing super close to a real deer antelope type of creature.
And as soon as playtesters started fighting against these things, they actually felt bad to hunt them.
Especially when they were limping.
Oh, is it not looping? Sorry.
It's not looping anymore, sorry.
But let me see.
But that actually is the fact that I actually started to feel bad for these things.
That's actually something that was also incorporated into the story where Aloy is actually being brought up to be very respectful towards these mechanical creatures.
So that was a nice combination of elements of coming together naturally in this process.
The only robots that we actually did apply some of the robotic movement to was the ancient war class like this Deathbringer.
Even here, it was just because it fitted the design and the behavior more.
But on these things, we actually started to look more at industrial machines like they use in car factories, since they have that nice combination of fluid motion and mechanical stuff combined.
So that whole track of defining the gameplay, going through this pre-production phase, searching for the style, was done at this point.
And at the same time, the rest of the studio was done with Shadowfall.
So the entire team basically transferred over to Horizon.
And from a production point of view, it actually makes sense for the producers to have these dedicated teams.
So we had a team robot, we had a team alien, we had a team living world, et cetera.
And the nice thing for us was that we could actually only focus on the robots, and that was the only thing that we had to take care of.
Before the team actually transferred over, I started to make a list as a guideline that we could hold up to our own work, but also made it very clear for the rest of the team what the intention of these things was.
And for me, the first and foremost was that these things actually feel like they belong in the world, right?
So to make them as believable as possible.
I knew we were gonna end up with roughly around 25 to 30 robots, so...
It was very important to me that they actually all felt unique with their own personality shine through within their movement.
The third one was that I really wanted them to feel bulky with lots of weight, which turned out a lot harder in the end than I was thinking in the beginning because you can make them as bulky and heavy as you want, but if they're not responsive in terms of gameplay, your game sucks.
So there's a lot of back and forward that we had to do in the end on this, but I'll cover that a little bit later.
Last but not least, they should be very scary to fight against.
So Team Robot, this is sort of like the list that was in there.
Three AI coders, four to six animators, three visual designers, two asset artists, three game designers, three effects artists, two sound designers, and TechArt was always there to support us.
Even on this, we had like three subgroups.
So two animators, one designer, and one AI coder was just working on one machine, and we had three machines in production at the same time all the time.
So there was a very steady flow of creating these machines.
The way we worked was very much layered and we had multiple sign-off moments.
So basically game design started with around 50 to 62 pages that basically described the basic functionality of the machines and what mix of animals they wanted to use as an inspiration.
And eventually the game director chose roughly around 25 to 30 machines that he wanted to see in the final game.
As soon as we had that information, Visual Design actually had enough to start working on their stuff.
And instead of just drawing, they actually went straight into ZBrush, skid-bashing these things together to make mock-up models.
And once they had their first pass done, it got into TechArt to be rigged, and we started to test it out.
And it became this sort of like back and forward in a loop.
between those three teams.
And eventually we had that sign-off moment where the mock-up model was done, and then AssetArt could actually start making the high-res model while we could actually start animating on the mock-up model.
By the time the designers were actually done with their low-level design, which was like a 60-pager book for each robot individual, and we could actually start animating the actual machines from that point on.
As soon as we had a good chunk of animations done, we created the animation networks, which is something that all the animators at Guerrilla handled their own.
We handed that off to AI to actually start working on the behavior and the combat.
And here we got like that second circle of so like iterations based on feedback from all the teams.
And eventually once we sort of like halfway through that production, effects and sound design got to do their best.
And at the end of that track we had a alpha ready machine, what we called it.
The nice thing from a production point of view was in terms of scheduling, that everything had the staggered approach.
Everybody was just working one month behind each other.
So yeah, always had.
So nobody was actually waiting for each other.
We just kept on going without actually ever stopping.
And for us, like I said, two animators would work on one machine for three months, and then we had an alpha ready version.
And that eventually ended up with 25 unique robots, sort of like ranging from...
120 to 350 unique animations per robot, depending on how big the game design was.
So I think that workflow actually turned out to be pretty successful for us.
So when we actually started a new machine, of course, the first thing we started to do was to search for reference.
And sometimes it was actually really obvious what the real-life counterpart was.
We still wanted to keep into things with an open mind.
And that meant doing a lot of research and really keeping our eyes open, which is where all those hours of nature footage really comes in handy.
So if you look at the Bellowback, which is a transporting class machine that actually carries liquids.
If you look at it and just break it down, it's basically just a bipedal animal.
So, but it's not your most obvious creature design.
So we just started to search for things like birds and kangaroos, and I stumbled upon this really nice piece of footage of an emu, so like fighting a kangaroo.
And the thing that I liked about it is how much of a shape change and posture change is into that thing.
And it's so fluid.
And I really wanted to get some of that into the bellow back.
And in the design document, it said that it actually needed to shoot projectiles.
And instead of just having a boring shooting straight animation, I wanted to do something else.
And a little bit further in the video, he's actually doing this sort of gesturing thing, but it reminded me of him actually throwing a baseball.
So I figured, okay.
Why don't we just throw out the projectiles and that basically just turn into this animation.
So the Rock Breaker, this was an acquisition robot that had to mine for resources on the ground.
And if you look at it, it's basically designed, at least from a visual design, it was based on a mole lizard type of character, but I know I never wanted to actually animate like that on land.
And I had no idea what to do with him either.
So we just started to work on the underground movement and actually the submerged type of movement, which is all based on worms, but I still had no idea what to do with him on land.
And then...
As soon as we had to make all those animations, I was actually walking around the studio and I'm not kidding, like somebody was actually watching a nature documentary on their screen of these two sea lions fighting each other and The thing that I liked about it is how heavy they look, but they're actually still pretty agile and there was so much power behind it.
So I figured, okay, let me just do a test animation with it because it's still reminding me a little bit of that rock breaker.
So I made this test animation and showed it to our art director to say, hey, what do you think about this?
And then he loved the idea.
So the entire ground movement was based on sea lions from that point on.
So for the Frost Claw on the Frozen Wilds, I mean this thing was clearly designed with a bear in mind.
And it was really nice to actually have that posture change going from walking on fours to going on a bipedal stance.
So we started to look for a lot of footage of bears and we made a bunch of claw swipes and a bunch of roars.
But it was all, to me, it was all very predictable and it never had that one characteristic that started to make this machine feel unique, in my opinion, so.
I started to think, okay, what else can we actually do with him, right?
And then I remembered my girlfriend having this huge weak spot for red pandas.
And I thought, okay, those could be interesting, right?
Let me just start looking for footage.
And I found this piece of footage, where they're basically just doing these really cool rolls.
And it's also something that you don't really expect out of the frost claw.
So I figured, okay, they're basically like regular pandas, but they're so feisty.
They actually can be really angry towards each other.
So I really liked it.
So I just tested out some of those rolls on the Frost Claw.
And that's actually the moment when I started to click with the Skerritt.
And I thought that this was the stuff that I really wanted out of this thing.
Of course, I had to put a lot more weight on it.
But that rolling thing was that one thing that actually made him stand out from the rest of the machines that we had done up until that point.
And then the last example is on the long leg, which is a recon class that actually uses echolocation to scout for threats.
And in the design document, there was this attack that said that it needed to do a scratch attack.
And whenever I looked at this thing, it always reminded me of a very big chicken.
So just for fun, I typed in chicken scratch in YouTube, and I found this really cool piece of footage.
They're so angry at that lady.
So I just straight copied it over to Doortoon to make this animation.
I didn't even try to make something else out of it.
So before we actually started the machine, we really tried to define what the main characteristics of a machine would be.
And we just took a couple of words per machine to describe the overall behavior and personality of these things.
And here's just a bunch of examples where we tried to distinguish them as much as possible from each other.
So if you look at the watcher, he was supposed to be aware, always curious, but also very calculated.
And then the shell walker, who's like this cargo...
crap type of thing that's super protective of its cargo on its back.
We just wanted him to be very grumpy and obsessed about that whole thing on his back.
And then the stalker was supposed to be like this angry guy that's always into combat.
So it was just like describing them with a couple of words so everybody knew which direction we needed to go. And as soon as we had a nice overview of what all these machines needed to be, the next thing that we actually did was...
make personality videos which we call movie mood like sort of mood board videos and This is not so like straight-up reference for the animations It's more to actually communicate what the characteristics of the machines were going to be and to get an overall feel of the character going and It's basically just whipping something up really fast without spending weeks of animation time on their first And it was just a simple way of communicating the ID without just words or pictures So everybody's like got a very clear view of what this thing was going to be So finally, now that everybody had a good idea of what the machine would look and feel like, instead of just going in and animating all the individual cycles and animation sets, we started with something which we call the personality test.
And that was just to see if we can actually capture the personality and the behavior that you just saw in the previous slides, but then see if we can actually make a test animation out of it.
And what you need to look at it is like concept art, but then in motion.
just to come up with a short scenario and put all the characteristics in there.
And it shouldn't take you more than one to four days to actually make these things.
And it had so many advantages looking back in retrospect.
And of course, you can actually see.
if we could actually communicate the personalities that we wanted out of these things.
But we also found that it was a lot easier to actually find your base poses this way.
Instead of forcing yourself to go in and out of a base pose all the time, these things were already working in motion.
So we just started to search for the poses within the movement that time.
And it was also really nice to actually tackle some of the challenges and design limitations up front.
Here's my first initial test that I did with the watcher.
And to me, it still holds all the characteristics of the watcher.
I mean, it's alert.
It's super aware of its surroundings.
It's very curious.
And I just tried to get some of the group behavior in there.
We're just posing a bunch of those guys around them.
But you don't need to move them.
But it instantly gives the feeling of, OK, these guys were close in groups.
And let's see if I can actually play it again.
It's not looping.
But then the good thing is if you actually break it down, there's actually, like everything is in there.
You have start animation, you have a cycle, you have some of the gestures going on, you have a run cycle.
So what I did, I actually just chopped this up and put it into game and started working from there.
Another example is with the grazer, and that was just more to actually get a skittish, nervous behavior out of this thing that we wanted.
And again, just threw in a couple of extra machines around him to get that group behavior.
That was basically it.
And I was very lucky that the effects had nothing to do at that point, so they made this nice composition for me with a real-life background.
So that helped.
Last example is on the stalker.
And this was actually to capture that agile and fast nature on that thing.
And again, everything is just in this.
So there's a cycle, there's transitions.
And this thing is actually a get up already.
There's an attack.
Just chop it up, put it in game, and you'll be surprised how good that works.
The thing that I really want to emphasize is that it's basically just concept art but in motion.
And it's really something that we try to do a lot.
For testing and design, so game design really wanted this sort of like crocodile type of machine and our art director was super skeptical about that and he had really big doubts about having that long of a body that close to our very sort of like crazy terrain that we had and also in terms of combat he was not convinced that this thing was going to be fast enough to compensate for Aloy just running around him all the time without having those weird AI adjustments going on.
I just started to search, and I really wanted to help the game designers out because I actually really wanted the alligator in there as well.
I just started to search for how these things actually hold them up in nature when they're being attacked.
They basically just use their tail a lot to whip themselves around, but if they're being attacked from the back like that, they actually just whip themselves over with their tail and then figure, okay, that's actually a really good 180 attack when Aloy is standing behind him.
With this video in mind, we did a little bit more.
of an effort on this thing just because we needed to sell the idea so we just made a walk cycle We actually made a swimming cycle as well And then we also sort of like whipped out this little scenario of what it would feel like if a lawyer was being hunted by These things in water Is he gonna get her new And then I actually just straight up copied over that move that you just saw on the video.
And showed this to our art director and at that point he was like, okay, this might actually work, let's just go for it.
And it worked out in the end, which I'm really glad about, because this is still my favorite machine in the game.
And sometimes we also take this personality test just a little bit too far.
I wanted to have this in game, but the game designers really didn't want that, so unfortunately.
So now that we actually have a good idea of what these characters are and what we can actually do with them, it's actually time to start animating these things.
And how do we animate these things, right?
When I actually started on Horizon, I just started to break it down into very simple shapes.
And the biggest difference for me between the two things is a human is basically this vertical capsule.
where there's no lead or follow in the body.
It's just running around like this all the time.
And a robot, you can actually break it up into three sectors.
So you have that rear end, the body itself, and the head leading the motion.
So if just simplified, it actually looks like this.
So if you're actually going to make these things move, what do you need to navigate?
Of course, you need a zero walk.
Damn, nothing's looping.
Of course, a zero walk cycle, but to get that change of path.
Sorry about this guy.
It's not playing.
Okay, I can just tell you it walks around a corner like that.
So you basically need that 90 degree change within one cycle.
And when we put that in, it wasn't actually enough for AI to start navigating these things in the world.
As well as mounted action, we basically just needed a tighter curvature for cornering.
We animated this.
Yes, this one works.
So we animated this 180 degree cycle.
So basically, he's just turning 180 degrees from itself within one cycle.
And if you have those five cycles, you'll be able to move your character around freely for just one speed.
So of course, you need to make multiple speeds for these things and start and stop.
So it's not just like, then it's done.
But I just wanted to point that out really quickly.
And it kind of looks weird when you look at it from a top perspective.
Oh, come on, nothing is playing anymore.
And go.
No, no.
Everything is good.
Everything is good.
OK, so let's get everything up and running again.
So, left corner of course a zero cycle. The 90 degree cycle is basically back at its original position again in four cycles, and the 181 is basically back at its original position again in two cycles.
And as long as you keep your foot planting and your body rhythm consistent, you're perfect for blending.
And the way we actually calculated the trajectories, if your distance for one cycle is value x, the 91 is basically just...
take x and divide it by half and then go the same amount to the left or right and that's your end position for your 91.
And then for the 181, divide x by 4 and double that trajectory.
And we just basically just drew NURB curves on the ground as guidelines and made sure that we followed the trajectory exactly.
so that AI can actually start calculating with these values as well.
And to really get that nice and fluid motion and really feel that change of direction, you really need to push the poses as much as possible.
So if this is your zero cycle, you really need to lean into that 91 and then even further in your 181.
And if you do that, then...
this is your end result.
As you can see that I captured that in our test environment.
And what you want is that the player actually feels that change of direction and how the head is actually leading the motion and the rest of the body is sort of like following into that lean.
Since this is all player control, we also needed to needed to get things right from an AI driven character as well and we were very lucky that they were fully invested into getting this thing right from their side as well.
And they basically had to rewrite a completely new AI mover that was driving these machines exactly the way as you see here where they would just make use of the full range of navigational animations that we provided for them.
So the basic logic behind the AI mover is that if you change your path of direction, your forward velocity decreases while your sideways velocity increases.
And here it's just giving a lot of commands to go to new spots, and because of that logic, it almost looks like the system is animation driven.
And at the same time, it uses the full range of motion provided by the animators.
And this way, you would get actually minimal foot sliding as they're cornering.
And if you want to have.
More info on this, Julian Bertling is doing his talk right now in the next room.
And he's covering this topic like quite in depth.
So go check it out in the vault.
It's really interesting and it's really something cool that he whipped up.
And here you can actually see the same system working on higher speeds where the marks become a little bit more visible because of that bigger radius.
And I'll explain what they mean in a more close-up look.
So when AI is actually giving the command for a new direction, the inner circle is basically the tightest radius that it can handle.
So that's that 180 degree cycle.
And then the outer circle checks if the space is actually available for the machine to move.
And it's also actually calculating the transition from going from that outer circle to the tightest circle with the logic that I just described, where forward and sideways velocity increase and decreases.
And the green line itself is basically the actual path that it's taking.
Again, check out Julian Berdling's stuff.
So our animations for the machines are all done in Maya.
And to create our animation networks, we use Natural Motion's Morpheme.
And it's something that the animators actually take care of themselves in-house.
And it had a lot of possibilities to make these robots way more believable with all the features and tech that it provided.
And I'll talk you through some of the setups that we made for the features that we wanted to implement.
And one of the examples we had to deal with was actually that long and narrow body that I was talking about with the SnapMaw.
Here's actually the example of the SnapMod from the top, the way we started it.
And as you can see, it has a lot of like flapping in the tail and the body.
And this just looked ugly to me.
It makes the machines feel way lighter and less believable.
So we had to come up with a solution to counter this.
The way we actually did it was to have feather blends.
And feather blends basically sort of like describe, okay, you can actually just take a bunch of bones and it will only influence those.
And so we just split it up into three sections.
So if you change the direction, the head.
and the neck actually play instantly, and then the body is delayed by a certain percent, and in this case, actually, you have six frames behind the original animation, and then the tail is actually following even later, so in this case, it's 12 frames behind the original animation, and it causes for a little bit of foot sliding as soon as you go into a new direction, but it's actually catching up really fast, so you don't notice it in game, and especially with our higher grass and stuff like that, you don't really see it, but as you can see, it actually feels and plays a lot nicer, and there's way more weight to this, so we were actually really, really happy with this setup.
The second example is actually getting rid of the random cycle feel that you don't want out of a character.
And it started to become really obvious to us with the machines once we were actually writing these writers.
Whenever you were just sort of behind it, you could just see that it was a cycle.
And instead of actually Using physics, we felt that we would have more control over the whole setup if we actually create a bunch of extra cycles and have Morpheme sort of like in a randomizing setup play the animation.
So if you look at this thing, the middle one is basically your vanilla straightforward cycle.
And then I made two variations on the left and the right where the body's sort of like tilting sideways.
But also the legs actually go underneath him from left to right as well.
And with these three animations, we plug those into Morpheme.
As you can see there right there in red highlight, that they're plugged into this blend node.
And we have this random node that actually gives a value randomly.
And in this case, we set it to 1.2 and minus 1.2, and it changes every 1.5 seconds.
And that number gets smoothed out through this smooth node.
And that's sort of like actually what's driving this blend node.
And it's actually constantly being updated.
So that's actually determining how much of the game of animation are being played in.
Here you can see the whole setup in action.
And as you can see, the blend node is constantly changing the value because of the two nodes in front of it mixing all the animation together.
And this is basically just enough to make it feel like a believable character.
And instead of looking at this random cycle all the time.
And you can just see a little bit of the foot like going in and out underneath him right there, for example.
And again, it's really nice.
So, uneven terrain, I mean, of course we knew we were going to have this really crazy terrain that we had to deal with, and my plan was always to create slope up and slope down animations.
Since our schedule was so tight and we had to animate 25 robots, there was just no way that we could actually make those anymore.
The uneven terrain nodes that are available straight out of Morphine worked way better than expected.
It took some extra corners for us to get there, but once we had the way we wanted it, it had really nice results.
To me, the only downside is that we're actually missing friction.
So when you're running up and down a hill, you want to feel that friction and it's not in there, but it's just one of those trade-offs that you have to make when you make a game this big.
This is the setup in a nutshell.
And without going too in-depth in all the operator calculations, the colored skeleton that you're going to see is the original animation right there.
And then the white skeleton is basically the end result with the terrain prediction on.
And as you can see, you can actually solve some really extreme angles.
And what happens is that we get the slope and lateral angle from four ray spheres that we have in our physics rig, and it's basically on front, on the back, and then two on the sides.
those values actually drive the hip IK and the chest IK.
And these come actually standard in Morphium, so that was really nice.
But besides actually just adjusting the height to the terrain, we also counter the body to the terrain angle.
So if you're standing against the hill, like in this example, your body basically gets pushed forward to readjust for the center of gravity and vice versa as well.
When you're standing downhill, you wanna be able to transfer your body backwards.
And then for the feet itself, we used the terrain prediction setup, and these are basically just four raycasts being used from under the ball of the feet, and they just snap the feet to the ground.
The only thing is, what we ran into, is that the terrain prediction is basically a two-bone IK solver, and more of them is just made for humans and not for creatures.
So we just had to get this three-bone IK solver, especially for the back legs, because they have a different setup.
So we came up with this.
in a two-way, so we put helper joints in our rigs, and next to that, our tools department actually wrote something that we call an end node.
And it's all based around the following theory.
If you look at the back legs of a quadruped, basically the femur and the metatarsal stay close or parallel to each other.
And it's basically like a folding chair going in and out all the time.
It's both in stretched and in squashed position.
So with that in mind, we created these helper joints in the back leg, which you can actually see highlighted in green in the movie.
And the idea behind the helper joints was to actually create a two-bone IK solver that supports the three-bone setup.
And the length of that first helper joint is basically A and C combined.
and that actually always stays parallel to joint C.
So that actually helped us to determine what the maximum stretch of this thing was gonna be.
And next to that, like I said, our tools department actually wrote an end node in Morpheme and what the end node did was try to keep the same angle between the joints all the time.
So it doesn't really matter if you have three joints or like 10 joints or 15 joints, it always tries to keep the same angle on every joint.
Which is based on that theory, like I said, with the folding chair.
So if you have those two combined, we were actually able to snap the feet to the terrain.
And it actually was holding itself pretty well without just going nuts all over the place with these weird angles in the knees and in the ankles and stuff like that.
And the last example that I want to show is how we had to work with longer necks when dealing with our look at targets that were being set by AI.
And basically, This wasn't really working out.
So we first made everything animation driven and it was causing for a lot of problems.
So normally when you actually, for example, make a turn on spot is you want the head to actually lead the action and show the intention of the machine.
But since our look at target is being set from the direction where the root point is pointing, which is that yellow arrow that you see in the top view, you can see that the head is already far more rotated from the position where the root bone is.
So we ended up with getting these double calculated rotation on the neck, as you can see in here.
And it's always off, and sometimes it actually turned inside of its own body.
So this wasn't really working out for us.
And then the solution that we actually tried after this was to have a fully overridden IK system.
But that basically ended up with losing all the data on the neck.
So we had a really nice animated body, and then the neck was just completely static.
So that wasn't really working out either.
And eventually we came up with the solution of adding additive rotations on the joints to replace our IK system.
So we basically still animate our robots like you saw in the first example.
But then once we were done with an animation, we just basically just took out all the Z rotations on the neck, so it looks really weird like this, but you basically just end up with up and down and tilt animations on your neck, and AI programmed it in such a way that the target is actually being set before they play an action.
So the head is still leading the motion, the only thing is that it's AI driven instead of animation driven.
And if we actually needed a full control over the head and the neck, we had this thing in our markup files where we could actually disable the head IK system.
That way we can actually blend in and out of the head IK.
And then you basically just end up with this result.
And it's basically just AI setting the targets.
And we also took out the neck rotation on all these 90 degrees and 180 degree cycles.
So we could actually really keep that focus on alloy as they're sort of like swaving around to really get that predatory feel in the machines.
And here's a quick overview of the setup in Morpheme.
So again, the colored skeleton is basically your original animation, and then the white skeleton is the result after the target is being set.
And as you can see, we're not just affecting the neck, but also the chest and the spine to some degree, so you have that really nice lean into the motion when they're looking left and right.
So once we had all our animation blocked out, and all this tech was up and running, we could start our polish pass in the beta period.
And because the game had such a long track, we knew a lot of balancing and tweaking needed to happen near the end of the project.
So what we did, we just blocked in the attack super rough, and made sure that all the movement and gestures and the hit reactions were already pretty much done by the time we actually hit alpha.
So at that point, we could have basically focus our beta phase only worrying about polishing these attacks and making sure that this was happening while the tweaking and the balancing of the game is happening as well.
So the goal of the attacks, of course, like with any game, is make it look clear and readable from any angle.
But we really started to look at it from a front perspective.
since 85 to 90% of our attacks are being played from a front perspective, so we really wanted to get that asymmetry and opening up the body from that perspective.
So here's an example of the earliest bite swipe of the Ravager, and it's not the prettiest animation, but it works for game design.
It basically has the anticipation that they want, the forward movement and distance, and also the timing for the settle.
But if you look at it from a front perspective, there's basically no sense of forward motion in this thing whatsoever.
It all looks very boring and symmetrical as well.
And the thing that I hated the most about this thing is that you're actually losing the weight in that jump forward.
It just gets transferred so quickly.
So when we started polishing, it became like this.
So I open up the character in sideways to make the body a lot more readable, but then I put in a moving anticipation instead of like that holding anticipation, so we're closing the gap already.
So we can actually add a lot more weight into the jump since we don't have to cover that much ground anymore.
We really started to look at clear lines of actions, so in this case it's very clear from screen right to screen left, and in the end just add some characteristics with a little head shake and then you have your polished version.
Again, open up the machine.
close in and then have that really nice clear line of action and then a nice way to jump in there.
So yeah, like I said, very clear from every angle now.
The beak set for the long leg, same trick, right?
It's super boring to look at, but it does the trick for game design to start testing out the combat.
And it was also very easy for us to just adjust this within a couple of minutes and then put it back in game again so that they were happy with all the timings and distances and stuff like that.
But once we start polishing it, I open up the character again from the start for a better silhouette, and then follow up with that nice clean line of action going from screen right to screen left.
If you look at it from slow motion, open up the character, close in, really present what you're gonna attack with, and then strong line of action to finish the job, and nice weighty jump again.
And then this is the end resulting game.
And as you can see, I really emphasized that motion going upwards.
And then to keep the same angle that he's going in, just because the player actually might miss the attack since they're dodging or there's so much effects or rake as being projected on the screen that they might miss it.
So as long as you keep that swiping motion upwards, the player still registers what's going on.
And then the last example, for the tail swipe on the snap mod, this was actually a lot clearer from the start already, when I look back at it, but I really wanted to push that swiping motion in terms of that tail being whipped.
So this is what it ended up with.
And as you can see, the tail's already coming up from a front perspective, so the player gets to see what's coming.
And then I open up that character completely right there before he actually slams down again.
And the biggest difference, that game design actually wanted this thing to face forward instead of with his back towards Aloy again, so we added that turn in as well in the end.
So again.
clearly present the tail, strong poses, and then finish off with a strong line of action so that it's always clear what's happening towards the player in that turn.
And then this is your end result in game.
And even like effects is actually emphasizing these attacks with all the motion trails going on.
So even though there's so much noise going on, hopefully the player just always registers what's being attacked with and what the attack actually is.
Basically 80% of the polish was spent on this.
So we just went through every attack for every machine and then just really started to break it down.
Okay, what is it that we wanna make clear?
Start looking from the front angle and then really start polishing things up from there.
Also, since there was so much balancing going on, this is where you can actually really start playing around with your animation.
And we just broke it up into three sections, so anticipation, attack, and settle, of course.
And that's where you can really start playing with your timing and spacing.
And basically, the remaining 20% was spent on whatever looked out of place or whatever wasn't up to standard.
And to give you just one example of that.
One of the issues we actually ran into was that the machines were way too overactive and that the movement was actually too big as well.
So the hardest part about that was that the weak spots almost became impossible to shoot for the player.
So both AI and animation had to tone it down very drastically.
And even if we were pretty happy with the movement sometimes, it was a bit of a pain.
If the player has a bad time, you're basically just screwing up as an animator and developer.
So you have to really take care of that.
And it was really obvious in The Corrupter, so I show you that.
And this was actually the initial walk cycle.
And since I knew this was going to be one of those ancient war class type of machines, I wanted to get something else out of him than that realistic animal type of feeling.
So to me... Oh, let's see if I can actually play it again.
You...
Just go back and forth.
Okay, doesn't matter.
But the hardest part for me, like with the big up and down, was it became impossible to actually shoot that drum barrel on top of its head.
So as soon as I sort of like implemented this into the game, like within half an hour of the game, the director stood next to my desk and said that I had to take it out instantly because he hated that thing.
As soon as he was aiming at the drum barrel, the corruptor would stop and then would just pop up again and then he would just shoot into nothing.
So we had to tone it down drastically and then let's see if it actually plays.
I'm just going to see if I can end slide show and then move it up again.
So this is what we ended up with and it still has some of that up and down motion in there but we completely took it out almost.
The only way that we could counter this is with actually rotating the body forward to still have some of that motion in there but if you look at the drum bearing and you're aiming at it, it's always going to stay inside.
Yeah, he was way happier with this one than the previous one.
So we just went through all the cycles as well and made sure that the weak spots were always still pretty clear to hit from a player perspective as well.
So some of the takeaways.
First and foremost, like you saw with that LEGO Thunderjaw, you don't really need anything fancy to prove your gameplay.
It's something that we hadn't done much up until this point, but it helped us a lot focusing on the gameplay first before we started to make things look nicer.
And that really helped us out in the end.
The second is to really do your research and really go into things with an open mind.
It really helps shape the character a lot more creative, but it actually makes the character also a lot more believable.
And the thing that actually really helped us out the most was if we actually took some time out to test our characters.
So I'd really advise everybody to take two or three weeks out of your schedule and start making those personality tests and start making those mood board videos.
So you have a really clear plan in mind before you actually start animating these things and you're basically just finding your character as you're going through it because that wasn't really working out for us in the end.
And last but not least, all the details and all the polish that we put in, it really matters. It really makes a difference and adds immersion for the player.
That was it. Sorry for all those crashes, guys. I have no idea what was going on.
I made it in time, right?
Do we actually have a Q&A question thing right now? Anybody has any questions?
Oh, there's mics in the middle.
Barely.
Yes, in there.
Hi.
Hi there.
Hi.
So when you showed the production, towards the beginning you showed the production sort of cycle of the design and then animators and the feedback.
Is that something that you kind of found in retrospect that that's how it worked?
Or that was the plan?
No, that was actually the plan.
So the first thing that really helped was actually creating these things already in ZBrush.
So for asset art, you know what I mean?
So we actually had our models pretty fast and pretty clearly already from the start.
And then that whole track started happening.
And then we just found out.
Like AI can start if we don't have anything.
And it started to evolve naturally from a beginning point of view, you know what I mean?
Because we have to have something animated before they can actually start implementing things.
So the first ones were a little bit longer.
But once we had three going into production, it just happened naturally from there on.
Cool, thank you.
Hey, Richard.
Hey, man.
Real quick, did you guys establish level design standards, like slope extremes, arena sizes, and if you did, when during development was that established?
Gotcha.
Okay, we didn't.
It's one of the, okay, so the thing is like, and I'm not quite sure, you probably can find this on the vault as well, but a lot of the world of Horizon was actually auto-generated in the beginning, and we just had to deal with it up until a certain point.
So basically, I think in our nav meshes, there's only to a certain degree that the robots are allowed in it.
So I think it's like 40% or something like that, and then after that, they just stop, the nav mesh just stops.
So we knew we had to deal with, So we can actually find what the most extreme angle was that we had to deal with, but then, yeah, we had to deal with it.
There was no way around it.
But for, like, I think from a player perspective, they actually did establish a lot of the angles up front already, but for the machines, we just had to deal with it.
Unfortunately. I hope that answers the question. Okay.
Hi.
Hi, so for the strike teams, were the teams dedicated on like a per monster basis where they'd follow it through all the way from start to finish or was it more like an assembly line where different parts were handed off down the lines of the teams?
So during the alpha phase it was actually very dedicated.
So two animators were working on one machine for three months and they weren't working on any of the other machines.
After Alpha, that polish, everybody was just picking up whatever was available at that point.
So everybody was working on every machine at every time.
The only thing that we did do was we really started to focus on a machine for two to three weeks, make sure that we went through all the attacks and then showed it to our art and animation director back then and he just gave feedback.
And then we just, as a team, did an entire feedback loop again on the same machine and then we just started going on another machine afterwards.
That way, looking back in retrospect, it probably would have been nicer if we switched things around.
On the other hand, it's also very nice that you just get to focus on one machine for three months in a row, and you don't have to think about anything else.
And you really get the feeling of a character after the first week or two or something like that, and then it's just making things nicer and better from there on.
I think it actually, there's some pros and cons towards it, but yeah.
Thank you.
You're welcome.
One more?
Oh.
There's only two more standing.
Can we?
OK.
Quickly.
Great job on the game, by the way.
Thank you.
Appreciate that.
I have a question, a little bit more technical I guess.
How did you account for design changes?
Like all the mechanical bits and pieces, I imagine they probably changed throughout each creature design.
Not really, no.
That's what that whole mock-up model process was for.
Funny enough, game design was actually really dictating a lot of these things from the get-go.
They said, okay, we...
We have this machine in mind, and in that 60-page design document that I told you about, everything is in there.
So all the weak spots that they wanted needed to be on there, all the weapons, et cetera, all the text.
But then as soon as we did those mock-up reviews, those were the first things that we really started to look at.
And then as soon as we had that mock-up, we just exported it to games so they could actually start feeling what the size of the creature wanted to be as well.
The only thing that actually happened was, Some of the machines were too small in the beginning and we had to scale those up afterwards.
And that was sort of like a big hassle because you have to completely re-export everything again, etc, etc.
But actually changing the weak spots, those were actually pretty much set from the start.
Yeah, so and every once in a while we got something.
Eventually once we had the high res model in there, we did change a little bit, but that was more for readability, but not in terms of gameplay.
I can't think back towards that.
Thank you.
You're welcome.
One more?
Yeah, OK.
Hi. You were talking about how you use a lot of references, like video references.
How do you decide which part of the crazy emu fighting the kangaroo to use in your animation, or what part not to? What was your approach to copying or taking pieces from those references?
So that was more sort of like I knew we had to animate something and then I sort of like started to search for things.
So I spent like with that shooting thing for example.
I knew we wanted to have like a, we needed shooting animation and I just looked more like a video reference.
Like the first thing that I actually started to look at more is like okay what's the energy that's being.
what energy does the character have instead of just going through it like, I just got to copy this frame per frame, you know what I mean?
So as long as I sort of like the energy or what's going on on screen, I'll just take that as a base first and then just start working from there and then just test out either with a couple of poses or just a really quick animation test and then to see if it does work or not and then just get going from there.
But most of the time it was very specifically that we started searching for animation, for reference per animation basically.
Does that answer a little bit or?
kind of like, how do I say it, the process of looking for a reference, like how did you translate that reference into your animation?
Like what were the specific, were you looking at the speed, were you looking at...
That's like, that's different on any vid, like any reference, like so sometimes like I said, like with the chicken thing, I just straight copy that over, so I just went frame by frame and then took all the poses and then eventually that's sort of like what I had as an end result, but sometimes I just look at...
Like I said, like an energy or whatever, or then it's so hard to explain.
Shit.
Sorry.
It's just like a case by case thing.
Like it's not so like always the same.
You know what I mean?
Is that, I don't think that answers your question.
I have no idea what to say about it to be honest, like how I can explain that.
Sorry.
It's okay.
I got a girlfriend.
You just like from every single one of them, you just pick what animation or what energy or what movement you want from it and just like...
Yeah.
Yes.
It was...
It...
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
It's so hard to...
Because sometimes I already know what I want and then I don't even look for reference and then every once in a while I just have no clue and then I just start looking for videos and see if I can actually find something cool and see that, like, oh yeah, I like that a little bit and then, oh yeah, I like a little bit from that and then I just take a couple of videos and start mixing and matching those and then eventually you have that end result.
So it's always different for every animation that I make.
No, I mean, that does sound right.
I wanted to know if there was like a logic behind it or it was like...
No, there's no logic.
We're in a chaotic process, so thank you.
No logic whatsoever.
That was it, right?
I'm sorry.
I'll just...
I thought we'd have to cut it, I think, so.
You're done now.
Okay.
You can ask me afterwards, sorry.
