All right.
Hello?
I'm very happy to see that people are still filling in.
And there are so many people here who care about video game cameras, because I haven't really found a community of game developers who specialize in game cameras.
It's true that there's at least one book on the subject, Real-Time Cameras, by Mark A. Hutchinson.
But I feel like there's still a lot of room to delve deeper into this discipline.
I want to see more role models talking about how they solve problems with their camera designs.
But, actually, I guess it kind of makes a little bit of sense that there's not a whole lot of attention being paid to cameras because the whole point of cameras is to focus attention on something other than themselves.
Cameras are most noticeable when they fail.
As players, we only talk about cameras in order to complain when they're distracting.
So, I decided that in order to really talk about camera design, I have to embrace failure.
So this talk is about all the things that go wrong when you're developing a game with a third-person camera design.
I am John Eske, I'm a field engineer at Backend Company.
I was sort of thrown into this camera design thing by accident actually.
I just hired as a general designer but I became really passionate about improving the camera in the game.
It was my first time developing a game with a dynamic camera and I discovered that it's a massive challenge and I now know that this is probably the hardest style of camera to design for a video game.
We can certainly learn a lot from cinematography, but game cameras, I think, have a lot of their own special rules.
They're pretty hard to begin with for any kind of game.
Like in movies, camera operators can deliberately plan out a shot in detail, but as game designers, we don't have that luxury.
Everything in the game, including the camera, has to react to what the player is doing, and it has to adapt to the situation.
And in order for the game camera to adapt to the situation, we have to formalize the rules of good camera design and teach it to the computer, to the software, so they can do that on our behalf.
And I call this discipline, gametography.
Not the first person to use this word, but I think it's a good one.
There's basically three gametography styles in video games.
The one on the left is fixed angle third person.
So these little diagrams are representing an avatar standing in the middle of a square room with a camera pointed at them.
And the one on the left is fixed angle third person, meaning the camera never rotates.
The one in the middle is dynamic angle third person, and the one on the right is first person.
And there's a lot of differences between these, but the main difference, I think, that kind of everything else revolves around, is the distance between the camera and the avatar.
On the left you have a camera that's basically intrinsically far away.
Or at least far enough away that you pretty much have to tear down everything between the avatar and the cameras in order to be able to see through all that and see the avatar.
You're basically tearing down the fourth wall.
This is common in basically all two-dimensional games do this, as well as, honestly, many three-dimensional games with an overhead perspective have basically the same effect, like League of Legends.
just tears down the upper fourth wall.
First-person games, on the other hand, just have a distance of zero.
The camera's literally inside the skull of the avatar.
This means you never have to worry about losing track of where the avatar is, because you are the avatar.
And since there's no danger of losing sight of the avatar, we can leave in the fourth wall that we removed for the first camera style.
and leaving in all of the parts of the environment allows the camera to spin around without losing sight or without like seeing a gaping hole where the camera used to be.
The middle one, dynamic angle third-person games are on this weird sliding scale between close and far camera distances with kind of all the downsides of both.
For Journey, we did want a game where players could look in any direction and explore on their own.
So we couldn't use the fixed angle third person.
But we also wanted the player to have a clear view of the avatar's body, so we couldn't use first person.
And we needed something in between.
And that means we need a camera that physically fits inside the world alongside the avatar and That means we have to worry about all of these collision detection problems And keep just in general keeping the space between the camera and the avatar empty so that you can always see what you're doing And these design constraints leave us with a whole lot of problems.
In fact, there's definitely at least 50 problems, which I have taken the liberty of enumerating for your convenience.
I encountered most of these problems working on Journey, and usually I got it wrong the first time.
It's only through iteration that these problems get fixed.
Many mistakes remain in shipped products often.
And some of these can even still happen in Journey.
As a side note, I actually started with a list of a hundred problems and had to narrow them down to fit into the space of this talk.
So I'm going to have to talk a little bit quickly.
So let's get started.
Number one.
Using a...
Let's see. Yes. OK, good.
Yes, they're both animated. Good.
using a dynamic camera when another poach would work.
Dynamic third-person cameras are, as I said, are the hardest kind of camera to design, and really there's no shame in taking the easy way out if it lets you focus on other parts of the game to make them better.
Dynamic cameras don't automatically make games better.
In fact, they frequently make them worse.
For example, the early 3D Mario and Zelda games all had dynamic camera angles.
But the more recent ones, like Super Mario 3D World and The Legend of Zelda A Link Between Worlds, these have reverted to fixed camera angles.
And these are highly respected sequels.
So, yeah.
Pay attention to the, for example, the background on the image on the left, and how it swings around as the camera turns, while the right video has a stable background, because the camera angle is fixed.
So for student projects, game jams, and other games developed under tight constraints, I highly recommend picking an easier camera style, such as first person or fixed angle.
Next problem is designing levels and camera behaviors that don't match.
Level design and camera design are closely related disciplines, and they need to cooperate to help players navigate.
If you know the camera angle ahead of time, you can design the entire level around that.
And if you don't, if you have a dynamic camera angle, then you have to make sure that the levels gracefully flow from one point to the next with the camera easily showing you where you need to go.
Meanwhile, the camera itself has to be good at navigating the kinds of environments that are in your game.
I like this video because I find it telling that the author chose to include the original side-scrolling game in the top left corner of the screen.
Yeah, you can see it.
So that the player can actually tell what's going on.
I think that's a clue that this is not a good camera for this game.
Using global coordinates or quaternions to persist the camera's state.
Obviously this is sort of a programmer-oriented issue, I'm afraid.
So I wanted to get this one out of the way early.
But it is also sort of a design issue.
It's easy to assume that a third-person camera for a game should behave like...
like maybe a human holding a camera who can pivot around in place.
But in third-person games like this, the focus of attention is really the avatar, not the camera.
It's not a first-person game.
So whenever the camera rotates, it should always be pivoting around the avatar, like a moon orbiting around.
That means it's not important to store the global XYZ coordinates of the camera, because you can always just derive those as an offset from the avatar, finding where it is on the orbit.
And the other issue is the quaternion thing.
Quaternions are often considered the correct way to represent orientations of things by programmers, and they're very useful.
But that's not how players think.
Players think in terms of Euler angles.
That means pitch and yaw.
They rotate sideways and they look up and down.
That's how players want to control with, for example, an analog stick, or whatever it is that you're using to control the camera.
So, use Euler angles to represent the orientation of your camera, or at least at some point in the code.
You can convert to quadraniums later.
And...
As for the position, instead of storing global X, Y, Z coordinates, store like distance from the avatar and maybe like a vertical or lateral offset if you want to frame the avatar somewhere other than the center of the screen.
Using a camera distance that's likely to break line of sight.
This means, well, the line of sight, this, like, imaginary line between the camera and the avatar is very crucial.
Kind of the entire camera code is basically designed around keeping this line of sight clear.
Not all the camera code, but quite a lot of it.
And here's an example of an important game, Popo Iiyo.
But this game nevertheless fails to preserve line of sight.
For example, this pipe on the left.
Yep.
And if the camera was closer to the avatar by default, it would be a lot harder for this sort of problem to occur.
Um...
Do-do-do-do-do.
Allowing obstacles to break line of sight from the side.
This is the most common way that obstacles will break line of sight.
And the simplest way to fix the problem is to just detect by casting a ray from the avatar to the camera.
Detect when the avatar has been occluded and just push the camera immediately closer to the avatar.
But that is a cut.
That is a camera cut.
If all you're doing is changing the position of the camera, that violates the 30-degree rule.
In cinema, the 30-degree rule means all camera cuts should change the angle by at least 30 degrees.
And failing to do that creates a jarring sense of motion.
So it's much more pleasant when an obstacle is threatening to break line of sight to preemptively turn out of the way.
So, for example, in this case, the camera swings to the right to avoid the obstacle on the left.
And you can detect these obstacles early with raycasts that I call whiskers.
You can see the green arrows on the diagram.
And if any of those whiskers detect an obstacle, you can use that to preemptively swing away.
And if necessary, you can reuse results from previous frames to reduce processor load.
if that's a problem.
However, we have our first conflict.
Pushing away from an obstacle like that, while the player is trying to swing towards it.
So, in Journey, and in many games like this, the player has a control stick or something to control the camera.
And it is important to always honor the player's intent.
So if the player wants to turn the camera one way, the camera must turn that direction.
Otherwise, the player will be very frustrated.
Which means we come across these situations where the camera wants to swing away from an obstacle, but the player is swinging it towards the obstacle.
And in that case, the only solution, as far as I know, is to pull the camera closer.
But as long as we know ahead of time that the obstacle is on the side that we're trying to avoid and the player is swinging towards it, we can gradually interpolate the camera closer towards the avatar so that by the time the obstacle is in the way, we're already squeezing by it by getting closer.
Letting the player push the camera inside an obstacle.
We still want to prevent breaking line of sight, of course.
So, as I said, move the camera closer to avoid the obstacle.
And we may need to use some actual sphere collision detection.
I'll get into that a little bit later.
To avoid, to make sure that the camera doesn't accidentally find itself inside the obstacle that you're pushing the camera towards.
Letting independent forces compete to push the camera.
As we've seen, we need to deal with this special case where obstacle avoidance says to do one thing and camera control says to do another thing.
But this is hardly the only special case we have to deal with.
The camera has to satisfy many constraints at a time.
And if constraints are allowed to compete with each other by applying forces in opposite directions, they'll often cancel out without satisfying either constraint.
But we can organize the constraints a little bit better because we know that there are seven axes, or degrees of freedom, that matter to the camera.
There's yaw, pitch, and roll, and the horizontal, vertical, and forward-backward offsets, and field of view.
Those are the seven degrees of freedom.
And we can organize all of the constraints according to which degree of freedom they matter to.
This is separation of concerns, basically, which is a programming principle.
the problem that I described earlier with the swinging toward and away from the obstacle, those are both applied to the yaw axis. So we can get all of the forces that apply to the yaw axis and prioritize them. And in this case, we know that the player control has the priority.
Number nine is keeping narrow columns from breaking line of sight.
It is important, as I've said, to avoid breaking line of sight. However, there are cases where here you can see that this column breaks line of sight with the avatar on the right. And it would be more trouble than it's worth for the camera to try to avoid letting that happen.
It actually looks pretty graceful in this case to just swing around the obstacle on the outside.
And you can accomplish this, or in Journey we accomplish this by tagging obstacles based on whether or not they're allowed to break line of sight.
And this one, this particular obstacle is very narrow.
The player should be able to track the avatar with their eyes even though the avatar is temporarily eclipsed.
Ten is letting the camera intersect narrow columns.
So, I just explained that it's okay to let this narrow column break line of sight.
However, it's not okay to let the obstacle actually collide into the camera itself.
That would be confusing to the player.
So this is where more ordinary collision detection algorithms like a sphere collision check is helpful.
You can check if the camera itself is touching the column and if so, just push it out until it's not touching anymore.
interpreting a hill as a wall to be avoided. Journey is full of sand dunes with smooth slopes and like any other obstacle, it is important to keep line of sight from colliding with the sand dunes. However, we don't necessarily want to swing sideways away from the hills.
It actually makes much more sense to rise the camera above the hill.
So in the case of Journey, I actually just skip collision detection with whiskers and sand dunes.
But you can also try checking the surface normal of the slope to see if it's the kind of obstacle that you should be swinging away from or rising above.
Swinging sideways when occluders come from behind.
So far, all of the obstacle avoidance has been these sideways whisker swinging around.
But line of sight can be broken from many directions.
There's the sides, and then there's also behind.
For example, if the avatar, if the player's making the avatar run towards the camera and the camera's backing up, it can be backed up into a corner.
And if the camera finds itself backed into a corner, then swinging either direction won't actually get it out.
It won't help at all.
So in this case, you should use a ray cast like immediately behind the camera to detect if it's being backed into a corner.
And if so, just pull closer without swinging sideways.
13 is letting the camera's near-clipping plane intersect the avatar.
This is a technical problem that pretty much all virtual cameras have what's called a near-clipping plane, and anything closer to that gets cut off and leaves a big gaping hole in the object.
So We want to make sure that this almost never happens or never happens preferably.
So there needs to be enough space between the avatar and any adjacent walls for the camera to fit as near a clipping plane through the space.
And one way you can do that is by making sure that the avatar's collision radius is wider than the actual avatar, so that they'll never actually like press up, right up against the wall so you can just like still fit the camera between the model and the wall.
Fourteen is using the same camera distance for all angles.
In particular, I'm talking about up and down tilting.
If you're looking up, that means the camera has to swing downwards to keep the avatar in view while you're looking at the sky.
But if your camera is swinging downwards, it's going to crash into the ground unless you make it closer.
So some games will make the camera crash into the ground and then pull closer, but I prefer to have a smooth curve that kind of knows in advance what the shape of the floor is and it can...
kind of glide into the position at the avatar's feet for a worm's eye view.
It's also good to extend this curve the other direction, so when you're looking downwards and you swing the camera up...
Um, this, uh, looking downwards means the horizon is the long, no longer in the view.
And if you can, you can just see this little patch of ground around the avatar and it can feel a little bit claustrophobic.
Uh, so I recommend pulling the camera out a little bit when you're looking downwards so you can have a little bit more, uh, uh, to, to see around the avatar so you don't feel a, uh, closed in.
uh, 15, using the same field of view for worm's eye and standard angles.
Um, the, uh, the sky is really, really big.
It's nice to be able to take in more of the sky at once, and in reality, uh, as humans, we use our peripheral vision to, to see the most or all of the sky.
Uh, we can see almost 180 degrees, uh, to our sides.
Um, so...
In order to create the same feeling when the game is looking at the sky, it should expand its field of view as it's transitioning to a bird's eye view.
You can kind of see the sides of the canyon filling in the sides of the video clip here.
And that just makes you feel more like you are the character looking the way the character would look.
Let's see, 16 is shifting pitch, distance, and field of view independently.
So as I explained, as the camera is pitching up and down, the distance needs to change and the field of view also needs to change.
But if these degrees of freedom are not completely linked together, then you can create this weird effect where, like, as you look up or down, the field of view will change, and that will affect the size of everything on the screen, because field of view is zoom.
But then the distance will also change and it'll change in the opposite direction.
So you might end up with the avatar appearing to expand and then shrink or shrink and then expand.
So it's best to make sure that the distance and the field of view are both like derived from the pitch, so that they transition together like gears.
However, you do end up with situations where other, other factors want to affect the distance of field of view.
So in that case, you can kind of have like a base distance of field of view that drive from pitch, and then other modifiers can like be multipliers or offsets to the base field of view.
17, not cutting when the avatar passes through opaque areas.
This is a case where the line of sight is being threatened from the front, which is actually super rare because the avatar itself has Collision and will prevent obstacles from hitting the front of the line of sight But there are cases for example this the sand fallen journey where an opaque surface can still be passed through.
And in that case, the only thing it can really do to bring back line of sight is to cut.
18 is letting cuts remap directional controls.
Up on the analog stick means go forward, but forward.
is determined by whatever direction the camera is looking in.
And when the camera suddenly rotates to a different direction, forward changes and then up on the control stick changes.
And players, they physically can't teleport their thumb when the camera cuts.
They need a moment to adapt to the new direction.
So this is a good opportunity for either like a cutscene or some kind of transition effect.
Or just put the player in a situation where they're not in danger of being attacked or anything like that when the cut happens.
Because players do need a moment to adapt.
Alternatively, you could also try to interpolate the forward direction during the cut.
I don't know how well that works, but some people do it. I've seen it happen.
19 is breaking the player's sense of direction.
Remapping controls is a temporary problem because the player can quickly adapt to whatever the forward direction is on the camera.
But cuts that change the camera angle also create a longer term loss of the player's sense of direction.
I think players use primarily two different techniques for navigating.
Head reckoning, which is keeping track of all the...
changes in your position and orientation. So, like, if I rotate my body 180 degrees, I know that north is now south or... But a camera cut... Sorry, the second technique is recognizing landmarks. So, dead reckoning and recognizing landmarks. And camera cuts, they make dead reckoning impossible. You can't tell all the time when a camera cuts how much it has been rotated. So, you don't know how much to rotate your mental model of the map.
So this is a crucial moment to make sure that the camera is showing the player either recognizable landmarks or something to help them understand where they are when the camera is cutting so that they don't lose their sense of direction too badly.
20 is violating the 180 degree rule.
This is a commonly known rule in cinematography.
The 180 degree rule means.
Don't cut the camera such that two subjects, like characters talking to each other, swap sides.
That means, like, don't rotate the camera behind them, that kind of a thing.
But fortunately, we don't actually have to worry about the 180-degree rule very often in games because, as I've explained, cuts are dangerous and we should avoid using them whenever possible.
However, there are situations where 180-degree rule does apply, especially during cut scenes.
Um, so like at the end of a cut scene, uh, you should be showing the, the player, uh, what they, they need to be seeing to be able to navigate. Um, yeah.
21 is focusing only on the avatar.
So far I've only been talking about the avatar, but the player also needs to see other stuff in the environment in order to navigate.
For example, the player needs to be able to see the terrain immediately around the avatar's feet to see whether or not they're going to bump into a wall or whether or not they're going to fall off a cliff.
And they also need to keep track of things that are far away like the mountain on the horizon in Journey or the partner they're traveling with.
So, number 22 is relying on players to be controlling the camera at all times.
For many players, controlling an avatar and the camera at the same time is a lot like patting your head and rubbing your belly.
You can see this is Beyond Good and Evil, and this player is probably pretty good at this game, but they still end up, like, jerking the camera around because this game doesn't have any automatic guidance for the camera.
So I recommend, whenever possible, the camera should be doing its best to look where the player wants to see in advance so that the player doesn't have to be controlling it.
23 is leaving the camera yaw alone while the player is running.
And the simplest way to help the players see where they're going is to show them where they're already going.
Just take the direction that the player is running in and map that to the yaw of the camera.
So it kind of like drifts behind the avatar as they're running.
However, even this rule has a little bit of nuance.
For example, if the player is running right into a wall, it doesn't do them any good to, like, show them a direct view of the wall because there's nothing beyond it.
So use the player's velocity to figure out where they're going rather than the direction they're pressing on the analog stick.
Because they may be pressing in, like, or even worse, they may be running into an invisible wall.
EDITED-88DF-ACP-MGN-DQ you don't want to taunt the player by showing them beyond the invisible wall.
You want to swing the camera around the other direction to show them where they should be going.
Uh, 24 is making it hard to judge distances.
Uh, I love this game a lot, but this is a, uh, a situation where the challenge is created entirely by the camera kind of refusing to align with the direction you're going in.
The problem is that the screen is two-dimensional, and even if you've got some kind of three-dimensional screen, depth perception is pretty weak.
Players are much better at judging distances that align with the plane of the screen.
And there's the...
So, for example, if you have a top view...
you're good at judging all horizontal motion.
Whereas if you have a side view, you're good at judging vertical motion and also horizontal motion on one axis.
And in this case, for this catwalk, the most important thing for the player is to know how far they are from either side of the catwalk, which means that the camera really should be pointing right down the catwalk so you can see, so you can align that axis with the sideways axis of the screen.
25 is looking straight ahead as the avatar approaches a cliff.
When people walk towards a ledge, they will look down to see what's below, and the camera should do the same thing.
You can cast more rays, kind of a downwards ray in front of the avatar to see if there's any drop in front of the avatar.
And if you detect a drop, the camera can rotate its pitch to swing into a bird's eye view.
And an additional benefit of this, in addition to just showing you what's down there, the camera is ready to get out of the way if the player falls off the cliff.
Otherwise, if the camera is level when you fall off a cliff and the avatar falls, then the camera wants to fall with it and will crash into the cliff itself.
But if it's looking from a bird's eye view, it can just slip over the edge.
26 is keeping the camera level when the avatar is running up or down a slope.
The same kind of technique for cliffs applies to slopes.
Detect what the height of the ground is in front of you.
And if it's above or below, you can look up and down.
However.
Some people might try to just use, like, the shape of the terrain directly under the player's feet.
But if it's bumpy terrain, that might give you noisy information, so you should be really doing some kind of rate cast ahead of the player to figure out, like, the average slope of the terrain.
27 is misusing rule of thirds.
Rule of thirds is another well-known rule from cinematography.
It basically says that pictures are more attractive when the subjects are off-center, usually facing inwards.
This is a simple way to improve the perceived quality of your camera design, but the wrong way to implement it is to rotate the camera in place.
Like, if you're trying to implement rule of thirds by holding a physical camera in your hands, you'll probably just rotate your hands a little bit and you're pivoting in place.
But again, a game camera should never pivot in place.
It should be rotating around the avatar when it's doing the rotations.
So instead, in order to create an off-center avatar, you can just slide the camera sideways.
There's a problem here, however, which is that players use the center of the screen to aim their analog stick. If you have the player on the off-center while they're running, they'll get confused about what direction they're running in. So, in Journey, we only use rule of thirds when the player is standing still. When they have to be running or when the player is pressing the analog stick, we make the avatar drift back to the center.
And I'm showing a clip from Shadow of the Colossus here, because it's actually an interesting counterexample.
In this game, I think it's OK that the horse is off center as you're riding it.
Because in this game, you're not using the analog stick to aim, actually.
You're pressing the gas pedal to go forwards.
And then you just use the analog stick to press left and right to steer.
So in this case, I think it's OK that the player doesn't need to associate up on the analog stick with the center of the screen.
because you don't use the analog stick to go forward.
28 is using the same logic for ground and air motion.
I've mostly been talking about ground motion so far.
But depending on the kind of game you have, there may be different kinds of locomotion in the game.
In Journey, you have running and flying.
Shout out to the Colossus has, as we said, the horse.
And these different transportation modes take different paths and trajectories through space.
And the player needs to be able to make different kinds of judgments.
And in the case of flying and journey, what goes up always must come down.
And it's important to always show the player where they're going to land.
So...
Especially when you're running out of juice.
In Journey, you have like a special amount of, or a limited amount of flying juice.
It's like at the very beginning, you might be flying upwards and the camera will look up to show you where you're going.
But as you're running out of juice, it's important to tilt the camera downwards so that you're prepared to land at any time.
To see where you're gonna land.
29 is relying entirely on procedural camera behaviors.
Pretty much all of the camera behaviors I've described so far are just automatic things that it does to respond to the environment and to the player.
But ray casting is only gonna tell you the shape of the terrain.
It doesn't tell you what's important.
We, as game designers, need to decide this, this, this other character in the game is important or this, this mountain is important. And the, the player needs to see these things.
So, in, in our, in our maps or in levels, we, we add scripted hints to tell the camera in this context sensitive situation, the camera should be pointing at this particular target.
I think camera hints become even more important in small closed environments because dynamic cameras are pretty good at open environments where there's not very many obstacles.
But in small closed environments, there's a lot of stuff for the camera to watch out for.
And the more we can help it out, the better.
And here I have an example from Journey of a large tower.
It's a very, it's a mostly complex, sorry, convex shape, which means there's like a pretty well-defined center of the tower.
And as long as the camera is on the other side of the avatar from the center of the tower, then you can have a pretty clear view of what's going on here.
So this is a scripted hint in the game that's not a general purpose behavior.
30 is letting players make themselves lost and confused.
Players do love to explore, and we want to enable them to do so.
But we also want to make sure they don't get too lost.
And the simplest solution employed by minigames is to put an arrow or radar on the screen.
I feel that these are a bit heavy-handed.
We do not use them in Journey.
I prefer relying on subtle camera tricks to suggest the direction to go.
For example, as I said, when you're running up against the boundary of the world and journey, the camera will spin around to show the opposite direction, to point you back towards the center or where you're supposed to go.
Another thing you might try doing is detecting whether or not the player has backtracked a significant distance. And if they have, then spin the camera around to point them forwards again. 31 is rotating to look at nearby targets. When you have a scripted hint that's telling the camera to look at, for example, another character or avatar who is standing right next to you.
Maybe your first approach would be to make the camera rotate to point at it.
But if you keep doing that, on the left you see Batman Arkham Asylum, and the camera just keeps spinning around because these two things that are in close proximity keep kind of basically dancing around each other, and it's hard to keep up with that kind of rotation.
But fortunately, there's an alternative approach here, which is to just pull the camera either to the side or back to include more in its view.
In Journey, for example, what happens is the camera pulls out right about now to show both avatars without doing any rotation.
And that just is less disorienting and more graceful.
32 is translating to look at distant targets.
This is the opposite situation.
If you have a nearby thing, you should slide the camera sideways or backwards to include it.
But if you have a distant thing, like something on the horizon of the screen, or like the sun, for example, no amount of sliding the camera around would change the position of the sun on the screen.
So the correct thing to do in that case is to rotate.
33 is letting the avatar's own body occlude targets ahead.
If you're rotating the camera to point at something and the avatar is in the center of the screen, there's a danger that the avatar itself will actually eclipse what you're looking at. You can point either to the side or you can, this would be a good opportunity for rule of thirds to slide to the side so that the avatar is on the side of the screen. But in any case, you should just be aware of this situation.
Often, the easiest thing to do is to just make sure that the camera's tilted down slightly so it can see over the top of the avatar's head.
34 is giving the player control over the camera and then taking it away.
It's very frustrating to give players control only to take it away again later.
So when you're making these scripted camera hints, you should be aware that, or at least enable the player to override the hints whenever possible.
And if you have to make a hint that will override player control, make sure it's in a situation where the camera is already looking at everything that the player needs to see so that they won't feel the need to control it. 35 is immediately applying a hint to, a scripted hint to control the camera after the player has finished turning the camera to look at something.
If the player is deliberately controlling the camera, they probably want to be looking wherever they point at the camera.
And if you have a, like, a scripted hint that's always on and always trying to push the camera in a certain direction, as soon as you stop overriding it, it'll start, it'll kick in again and turn the camera.
So the, there should be, like, a little delay.
after controlling the camera where the camera will continue to look where the players want it, wants it to be pointed. And either after delay or after maybe the player started moving again, then you can let the hint kick in again. 36 is not letting experts explore.
Even if the player is technically still in control of the camera and constantly controlling it, it can be frustrating when overbearing hints are constantly trying to get them to go in a different direction.
Especially when experts are replaying a game, they're likely to want to go to new places.
So after the hints have helped the players establish their goals, the hint can be disengaged to allow the player to find their own way to get there.
37 is not providing inverted controls.
This is a big problem.
I think pretty much everyone in the game industry kind of knows about this problem, especially first-person shooter developers.
But a significant fraction of the game-playing population wants up to be down.
and the other half or large fraction wants down to be down and up to be up.
And they probably will either refuse to play your game or just complain a whole lot about the game if they can't set the controls to be the way they want.
So make sure you have an option somewhere in the game to invert the axes.
This is actually the only option we have in Journey for controls.
38 is responding to accidental controller input.
In Journey, we made the decision to support two different inputs for controlling the camera.
There's the analog stick, and there's also the actual gyroscope or orientation of the PS3 controller.
And this is partly left over from Flower, where you control the game with tilting the controller.
Honestly, I think it made a lot more sense in Flower because it's the only thing you do in the game.
Whereas in Journey, it's more of a pat your head and rub your belly type of a problem.
And we end up in Journey with people often tilting the controller accidentally and accidentally making the camera swing around.
There are reasons why we supported the tilt.
I think it is an intuitive control for especially new players.
But I think, at the very least, we probably should have had an option to disable it.
39 is using linear sensitivity, especially on the analog stick.
Analog sticks don't have much range.
Often it doesn't matter much, honestly, because players have a tendency to push the stick all of the way. You kind of saw this in the Beyond Good and Evil clip where the player kept twitching the camera. But I think it would have been nicer to provide sort of an intermediate or a very slow way, a way to control the camera very slowly for fine tuning the camera direction. And you can do that by stretching the input axis from the analog stick into sort of an S-curve that reduces the neutral positions.
40 is letting the camera pivot drift too far.
So this means...
Well, in order to smooth out camera motion, for example, if you have an avatar that is jerkily...
dashing back and forth.
It's nice to smooth it out by letting the avatar drift from the center of the screen.
But if you do that too much, if you let the camera be too lazy, then the avatar might actually run outside the screen, and that's a problem.
So if you're using an elastic band type thing to make the camera attracted to the avatar, make sure it has a limit to how far the avatar can get from the center of the screen.
And you might actually want the camera to look ahead of the avatar.
For example, in Yoshi's Island, if the player is running in a certain direction for a little while, the camera will adjust by looking ahead of Yoshi.
However, problem 41, using a small field of view.
When the camera zooms in on a tiny little thing, then tiny little motions become large motions.
And zooming in exaggerates the speed of everything.
And zooming out makes everything appear to move much slower.
And here's a game that is, I think, nostalgic for a lot of people.
I enjoy the game quite a lot.
But when I tried, this is an example of a game where when I tried to show it to some of my friends.
they're not able to play the game because the camera just moves too rapidly.
This is something I care about a lot.
This is called simulation sickness.
It's when people play games and just from playing the game and watching the screen, they feel sick.
I wish that Yoshi's Island, for example, or many other games, would zoom out a bit more, so you have a bit more space to look around, and the camera wouldn't have to move as quickly to keep up with the action on the screen.
And on the subject of zooming out, this is also applicable to first-person shooter games.
I don't have a clip, but you could easily put a first-person shooter clip on the screen.
First person shooters are actually probably the most common trigger for simulation sickness.
And the way that people usually recommend that players deal with it is by going into the configuration for the game they're playing and expanding the default field of view.
And as I explained, this has the effect of making everything appear to move slower.
And I think this is a good way to deal with this situation.
And if you're making a first-person shooter, especially for console where you don't always have as much configuration options, include a way to expand the field of view or just have it expanded by default so that you don't exclude players who would otherwise be made sick by your game.
42 is rapidly shifting field of view.
This is actually increasing a problem in first-person shooters.
When aiming with a sniper rifle or other type of weapon with a scope, the camera often zooms in rapidly.
And also racing games do this.
When you're boosting, the camera will zoom out to make it feel like you're going faster.
And these kinds of things are also triggers for simulation sickness.
So be aware.
43 is shaking the camera.
Screen shake is an effect that is commonly used in all kinds of video games.
It's popular because it emphasizes impacts that happens in the game world.
And alongside vibration, this is used to make the game feel more real.
Some people say that screen shake is the easiest way to make a game feel more polished.
So it's clearly a very useful tool for game developers.
But I want you to be aware that not all players experience shaking in the same way.
The right amount of shake for you might be too much shake for someone else.
So again, I urge you to have accessibility settings for tuning down effects like screen shake.
I have a clip from...
TowerFall here. And I'm told that TowerFall actually does include a setting to turn off the camera effects. So I'm putting it here as a good example. 44, bouncing the camera with the avatar's walk cycle. This is another common one, especially in over the head games, over the shoulder games. This again is to make the camera feel more real.
feeling real to you might not feel real to someone else, might feel nauseous to someone else.
Um, nauseating, rather.
The goal is to...
the same as screen shake again, to make it feel more real.
And the effect is similar.
Camera bobbing is just a longer, slower shake, and equally likely to trigger simulation sickness.
So you should be able to disable that as well.
I have seen plenty of games with an option to disable this.
This is a common one. Do it, please.
translating or sliding up and down or rotating up and down when the avatar is jumping.
A lot of games, both third person and side scrollers, have the camera kind of locked onto the avatar when they jump.
And that means, like, at the moment when they jump and when they land, the camera has this abrupt start and stop.
And that can be triggering as well.
This is another situation where we know what goes up must come down.
And we know that the camera, the avatar is probably not in danger of going off the top of the screen.
So we can just let the camera stay in place as long as they're just jumping up and down in place.
And often what happens, like in Mario games, what happens is the camera waits until the player has landed on a higher surface before moving upwards.
In Journey, we use sort of a rubber band to smooth out the rapid vertical motions that happen on the screen.
46 is rapidly transitioning to a new camera position.
This happens often in games.
I think actually some game developers take the rule of not cutting a bit too far in games.
Um, Zelda games are...
The 3D Zelda games are especially bad at this.
Uh, I think these camera transitions might as well be camera cuts.
Um, but because they're smooth transitions, um, but they're really fast, smooth transitions, they create a sense of motion that wouldn't be there with a cut.
47 is maintaining pitch speed until hitting the limit.
Um...
One of the downsides of using Euler angles is that there's gimbal lock and other problems if you look straight up and down.
So you pretty much never want to have the, allow the player to look straight up and down.
You want to have like some limit of how high and down they can look.
But I've seen a lot of games.
will make it so that if you're pressing like up on the camera control stick, it will rapidly move the camera upwards up until hitting the limit and then it'll come to an abrupt stop.
And it's much better to anticipate hitting the top end to slow down as you approach the limit.
This is probably a controversial thing to put as a mistake, but what I mean by this is that as games get more and more lifelike, and they're getting better and better at simulating motion, they're also getting better and better at triggering simulation sickness, because simulation sickness is what happens when there's a mismatch between what you see, the motion that you see and the motion that you feel.
And I know that the Oculus Rift developers are doing their best to improve it, and I'm sure they are improving it.
But for the purposes of maximizing your audience, and not excluding anybody, I urge everyone to not make games exclusively for the Oculus Rift.
Make sure there's always some other way to play the game, because some people, I think, will probably never be able to play an Oculus Rift, or at least not in the next few years.
49, testing with a narrow demographic.
Children, especially, are eager to point out flaws and other people who don't have a personal relationship with you will be eager to criticize you.
But, you may need to pry a bit with testers because I know from experience that some people who have simulation sickness don't want to admit it.
It feels like a weakness.
And you want to make sure that they feel comfortable telling you when there's a problem with their game because I'm sure that none of you want your customers to feel sick.
And 50, writing a general constraint solver.
Given the complexity of all of these constraints that I've been describing, it's probably tempting to just come up with a function that, like, evaluates how effectively each of these constraints has been satisfied, and to just try to optimize and pick the one angle that satisfies them all the best, and let the computer kind of figure out which one that is, which angle that is.
But I believe this is actually almost never the right approach.
Because when you let the computer do all the work, it can be very difficult to predict what the results are going to be.
And if you can't predict it, then you can't really design it.
You have to be able to iterate on the design with changes that affect the behavior in somewhat predictable ways.
So I think it's important to deeply understand the relationship between the different camera constraints so that you're able to prioritize or otherwise figure out how to satisfy all the constraints as best as possible.
Um...
Let's see.
So...
The devil is in the details.
These solutions that work for Journey might not work for you.
So this list can serve as criteria to help you evaluate how well your solutions work.
But it's not a replacement for doing your own research.
So many of you will have to do some of the same kind of research and development that we have to do on Journey.
So good luck.
And first of all, I think I have two minutes for questions.
One, two?
Two minutes for questions.
Anyone have any?
Hello?
Hi. So you mentioned a few options that you think everybody should have, view bob, field of view, camera shake. Do you think it's worthwhile to combine all those into a single option for people with simulation sickness?
That may be a good idea, although I think there's some differences in how people experience simulation sickness. So some things that are triggering to some person, some people might not be triggering to someone else.
Did you find that a lot of people with simulation sickness were very familiar with what precisely it was that caused their simulation sickness?
That is actually a good question.
That is not always the case.
But if these options can be surfaced, you can let people know about them so that they'll know what to look for to figure it out.
Okay.
Thanks.
So I know a bunch of us are probably going to go run and try to fix our third person cameras.
And while you mentioned that like there's not a one size fits all, there's definitely also some principles that maybe extrapolate.
Yeah.
Not to put you on the spot, any chance you're going to like make a Unity plugin or something that's like a starting point that already acknowledges some of the major stuff so we can start from there instead of like having to recreate some of these foundations.
I'm deeply considering it. It's a matter of having time.
Fair enough.
Thank you.
Um, you can, I think I have one more person.
So you mentioned modifying field of view in order to help with simulation sickness.
However, in competitive first-person shooters, field of view can also be important to the player's ability to react to things on the edge of their vision.
So it's actually a balance concern.
Do you have any thoughts or experience with how to strike a reasonable balance between those two constraints?
Well, I remember reading about in Quake people deliberately expanding field of view for an edge.
So, sounds like expanded field of view is an advantage for everyone, just do it.
Alright, you can contact me on Twitter, I can probably find my way over to the wrap-up room somehow.
Thank you.
