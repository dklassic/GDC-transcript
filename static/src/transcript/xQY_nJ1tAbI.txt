Welcome to Creating Dr. Grobort's Invaders for Magic Leap 1. Uh, I'm James. I've been doing a lot of weird stuff in my career, but this one was definitely the weirdest. I started a long time ago making PC games from four months on the Lift Tech Engine, uh, which were interesting, uh, worked on, do you remember what this is?
Yeah, there we go. A few people remember the N-Gage. We did a big tactical RPG for the N-Gage shortly before the platform went away. Worked on PlayStation 2 era and GameCube and Xbox stuff in Montreal with some really lovely folks.
Went down to New Zealand the first time and did a couple more Xbox and PlayStation games down there and even did a game for the iPhone 3GS, which was new and shiny at the time when mobile games were a thing that was just like, what is this?
How does this work?
Shipped a bunch of stuff in the Xbox 360 PS3 era, and then was offered an interesting opportunity to go back to New Zealand.
I'd gone back to Canada, was living in Toronto, working with Ubisoft up there.
We did Splinter Cell Blacklist, which was a pretty exciting project, and was invited back to New Zealand to work on something that was new and shiny.
And it didn't look like this at the time.
To be fair, this was a few years before the form factor was really finalized.
So I went to New Zealand to work with the crew on a really exciting game for the Magic Leap 1, which shipped last August.
So the Magic Leap, just I'm sure everybody's kind of aware, but they're a spatial computing company from Florida.
We've got offices now everywhere from Zurich to Tel Aviv to Austin to Wellington, New Zealand.
And we've just launched the first round of the hardware in August last year, and it's been been really exciting to see what happens.
And we work out of Weta Workshop. Our crew is in Wellington, New Zealand.
And Workshop is a physical, award-winning physical effects and props company.
So if you've seen anything like all the Lord of the Rings films, and the Hobbit films, all of the armor and the swords and everything that came out of that, District 9, the guns from that and the mech suits, Kong, all kinds of films.
Workshop makes really incredible stuff.
And so it was sort of a strange thing to have a physical props company making a video game.
So we work out of a new studio that we call Weta Game Shop, which is just down the road from the main workshop because we sort of outgrew our space there and we needed to go somewhere.
And it's fairly typical as game studios go, you know, you've got desks and those sorts of things.
What isn't typical about the space?
is that we have one area that is a testing, we have two testing areas, one of which has got movable walls and furniture, a bunch of cubes, really nice to be attached to a props company, they can make us all kinds of fun stuff.
And so we can reconfigure our spaces to try and experiment with the different ways that people's homes and offices might be set up.
We have a more locked down, kind of full-on testing space.
And then, of course, our areas for hardware storage and things like that.
But otherwise, it's kind of what you'd expect from a game studio.
So just to clarify a couple of things.
So spatial computing, what do I mean by that?
So we're all on the same page.
VR is something that, it's a completely digital environment, right?
It shuts out the real world and it takes you to a whole different place.
It's amazing for immersion into whole other worlds.
Augmented reality sort of knows about, it's geospatially aware usually, it knows about the world and it can tell you some information about what's around you, but it doesn't actually integrate with the world.
Spatial computing and mixed reality really does, it's digital content that interacts with your real world.
Um, and that is where lots of the excitement came from me, was how are we gonna put games into your house, into your office, into the spaces around you, and interact with them in a meaningful way.
So, the first game that, uh, we've made, uh, is Dr. Grubort's Invaders.
Um, it's a fairly large-scale experience.
It's a long-form, uh, action game, uh, which is, uh, kind of unusual for this space.
I'll show you a quick clip from the trailer rather than the full trailer, but you'll get a sense of it.
The trailer itself is actually a lot of fun, but it's a little bit long for the presentation, so I recommend you check that out on YouTube.
So how did we get to this?
How did we get to that experience?
Long and winding road, it turns out.
We had to build a team.
As I say, Weta Workshop didn't have a games team prior to this happening, right?
This is a new thing for them.
They tend to make physical products, not digital products.
And so...
It actually worked out really well for us because we're making digital things that go in the real world, so there's still that sense of, this is a thing that I need to be able to interact with.
It needs to feel real.
So you take a bunch of people who are really amazing at making physical stuff that feels real but shouldn't actually exist in the world.
Like if you pick up a Weta Workshop Ray Gun and you turn it over, you'll notice that there's a serial number on one side.
There's details built into every aspect of everything that they do.
And it's that attention to detail that companies keep coming to them for again and again and again.
We had to build a game, which as you all know is, you know, real easy, right?
No?
So we had to build a team, we had to build a game, and we had to help Magic Leap build a platform.
So you know.
No pressure.
And we stacked all these things together.
And it was a very interesting, very exciting challenge, which is why I signed on.
What was really important for us was that Magic Leap did recognize games as foundational to the platform, right?
So our colleagues at Magic Leap Studios in Florida made some really wonderful experiences.
Project Create is a really beautiful sandbox that lets you do all kinds of fun stuff.
I highly recommend letting some knights fight it out before you drop a T-Rex on them.
And Tenandi, which is a collaboration with Sigurd Ross, that is a beautiful music...
It's like living in a music video from an alien planet.
Check it out.
And of course us and Invaders, and lots of other partners have come along for the ride and built lots of other cool things as well.
And really, what's important to note about this is that...
There are going to be lots and lots of people coming to this platform, right?
Mixed reality and spatial computing, as I'm firmly convinced, is the future of this stuff.
And it's gonna be used by everyone everywhere.
But at the moment, the only people in the world who actually know how to build stuff for this new medium are game developers.
We're the only people who do real-time, 3D, interactive content.
And it's going to happen very, very quickly when as all of these folks start to go, we need to be in this space and using this stuff, you're gonna start to get approached by all kinds of interesting people.
So I encourage you to please welcome them with open arms because we've got so much to share with them.
Um, so as I said, we were helping them build this platform.
Um, the purpose of the team really was to be the end point from hardware, software, operating system.
As everything came together, we were there at the end to go, cool, we're going to use this and break it.
And then we will provide you with feedback.
So to do that we used the absolute latest of everything.
I'm on the big bench there, which was like literally you were locked into position so you could make sure that everything was visible.
Eventually some stuff made it to a hard hat at one point.
Then to what we called the wearable device three, which Jake is wearing down there with the big handles on the side, which you'd often be kind of balancing because you had to strap the thing on yourself and then crank down.
It sounded a little bit like a medieval torture device when you put it on somebody because the way that you cranked it, it just went click, click, click, click, click, click, click.
And it was, um, trying not to squeeze it too tight.
Um, and Joe's hanging out there with one of the early PEQs.
Um, so whether it was the SDK or anything else, it was really quite interesting to constantly have this stuff.
Also, the conversations you get to have with customs as you come back hand-carrying one of these prototypes, uh, through the airport.
Um.
So we were in this constant feedback loop.
And we would fly over to Florida several times a year.
We would spend time with all of those different teams and explain to them what we were trying to do, where we were breaking stuff, what we were excited about, and what opportunities we saw so that we could help them steer their efforts as well.
And one of the big things that we had to do there was to learn the language and the goals of these other teams.
I'm not an electrical engineer.
I am not a...
A interface designer who's worried about how the very first experience of like opening the box works.
All of those other things.
So we had to learn their language as much as we could so that we were able to communicate more effectively with them.
And one of the things that I think helped us a lot in doing that and being involved in that process was showing up with something fun.
This is one of the early Magic Leap offices.
Oh, sorry.
Um...
And this was one of our earlier demos on the WD3.
And we set up the whiteboard you can see over there.
And people just wrote their names down to come and get a demo with us.
That board was full for five days.
Everyone came to play.
One of my favorite experiences I've ever had as a game developer was an electrical engineer who spent all of his days working on low-level circuit board stuff that I do not understand at all.
Who doesn't play games?
who just knew that he had one of the world's most interesting problems to go and solve, and he was just curious what the heck we'd actually been up to.
So he came over to play.
He had a giant grin on his face the entire time he played.
He kept laughing.
When he took the device off, he looked at me and said, how did you do that?
I just said, well, with the thing you made, dude.
And he was just ecstatic.
He was over the moon.
And I saw him for the rest of the week, and he was walking on air.
Because he didn't have that opportunity to see the end result of all of his hard work, to see it all come together.
And that's one of the beauties of what we do in games, right?
Is that we take all of this hard work by all these other people, and then we distill it down and make something exciting.
So that was always really wonderful to be able to go over and share those things.
So Dr. Robots Invaders is an action game.
And to make this game, we wanted to make sure that everybody could play it, because we didn't really know for sure who the audience was going to be, right?
We were fairly confident there would be fellow developers, some of whom would be game developers, but many of whom would be application developers, enterprise developers, those sorts of things.
So we weren't, you know, and it's a brand new medium.
So we don't have a lot of conventions to go by.
Historically, action games have been used on, you know, input devices like this.
Lots of buttons.
I think the dual analog stick control thing is amazing.
I mean, I worked on Splinter Cell for a while.
If you want to see my 2014 talk all about how those systems are tuned down to a nutshell, go for it.
But for a lot of people, that's a very intimidating input system to approach.
So.
What we use instead for Magic Leap One is the control and gesture.
So control is a six-off control.
It's tracked by the device, no external lighthouses or anything required to see what's there.
It's got a touchpad on the top, an analog trigger, bumper button, and the home button there.
It's basically like your start or pause button.
And gesture.
And the device can recognize left and right hand, and about eight or 10 gestures at this point, with more being added all the time.
And so for us, our mandate right from the beginning from Greg Broadmore, our creative director, was make sure that it's a two-button game.
So trigger for something, the thumb button for something else, trigger obviously.
Well, we'll get to that in a second.
That's pretty obvious.
And the hand.
So simplify this whole thing down.
And this was really, once we wrapped up, this was really exciting for me as well, because my mom has never played my games.
My dad's never played my games.
They appreciate what I do, and they like that I'm happy doing it, but they don't play them.
Well, that's a shield.
Oh, that would be awesome.
I mean, where is that hole in my couch?
Holy shoot! You girls gotta put this on!
That was one of the coolest things that ever happened to me.
My mom got to play my game and had a good time.
And that was pretty special.
So I feel like we kind of checked a box on the everybody can play button, or list, whatever that is.
So the game itself starts with these ray guns.
Ray guns are the heart of the Dr. Gordbort's IP.
Greg, who created it a little over 10 years ago, started off with just some paintings of ray guns.
And then they started making physical ray guns and then comic books and a lot of other things that have come along since.
And so we wanted to, that's really where we started with, and so we wanted to make sure you could get it.
A ray gun?
Cool, right?
Also quite dangerous.
Probably should sign a waiver.
And the nice thing about ray guns is that once you, that's Gimbal, once he hands you that ray gun, now it's in your hand, attached to the control, being tracked accurately.
And the thing with the ray gun is that we've made the game, at its heart, it's quite simple.
You are under attack and you have a solution to the problem.
Everybody kind of understands what to do very, very quickly.
The game has a lot more depth to it as you get further into it, but at the very heart of it, at that initial experience, it's really like, what is this thing in my hand?
What is that?
Oh, no.
OK.
And the time to solve is pretty quick.
One thing I'll mention is when people get their first virtual object in their hand, or the first time they can actually experience a virtual object in the real world, in mixed reality, give them time to appreciate that thing.
As I mentioned, you know, we... Workshop is really about details.
Excuse me. Um, and so we had like a variety of skins, for example, for the ray guns and stuff. Each one of these things has got so much detail and texture to it. Um, and you'll see the very first time someone gets a hold of a ray gun, they sit there and they just go like, what is, okay, this is a thing. There are bits on it moving, there are dials, there are bobs. When you fire it, it almost feels dangerous because the whole thing kind of vibrates and shakes. The effects are great.
So yeah, give people a chance to look at stuff.
Also, players will just like, they'll put their head in stuff.
So you can't control that, right?
So make sure that you sort of consider your virtual content in a way that you don't get that, because that's really disturbing.
What we came up with, James Brown, one of our graphics programmers, did this really wonderful.
Um, technique of an, what we call an outline shader.
The device has a clip plane sitting at 37 centimeters.
So it's just out from your face.
Um, and that's to avoid, uh, virgin's accommodation conflict, right?
So we, we can render content 37 centimeters all the way out to infinity, multiple depth planes.
So stuff feels like it's in exactly the right place.
Your eyes naturally adjust to it.
It's great.
But we want to make sure that if you bring something in too close, it's doesn't.
hurt basically. So one way around this for us, for all of our content, was we used this sort of outline shader to make sure that at that clip point you weren't getting things like the backs of people's eyeballs. Another thing we found was that putting UI on a raygun didn't actually work out great. When people are playing.
They're really looking out here because of, and this is going to be different, of course, for every experience that you make.
But in our case, when we were playing a shooting game, where there's objects out at a distance that you need to target, people are looking at that and they're doing this and they're going, blam, blam, blam.
with the ray gun.
And so we thought, well, hey, this object's going to be in field of view.
They'll see it kind of regularly.
We can tell them about stuff.
So at one point, we actually had like a health system that was like a three hits sort of system.
And we put these like heart bulbs on the back.
Reality is, everybody looks past that object.
And occasionally, they use it to aim a little bit.
But often, of course, if you try and do this for any length of time, you get this and then this.
And it gets quite tiring very quickly.
So, um, uh, what we found was that people don't actually, after they're done examining the object, it's become a real thing to them and they don't, you know, object permanence kicks in.
They don't need to look at it all the time. They're like, cool, I got this.
Um, so yeah, having stuff directly on the control.
If you had an up close experience, I think, where you're doing sort of something fine on a table or whatever, uh, that might work, but for us, we found it wasn't super helpful.
So with all of these ray guns, where we ended up, we experimented a lot.
We had these dispensers, for example, that sat in your room and you had to stick your hand in them to get ammo out of them and a bunch of other things.
We had Shake to reload.
And what we found generally was the more complexity we put outside of the player's experience, the harder it was for people to understand.
A dispenser seems like a really cool idea hanging out, but remember you're in the real world.
So now I'm taking up real estate that could be occupied by a robot or some other gameplay object.
So it was like, what if I don't have a good place to put that?
And all of the complications that come out of that.
So where we ended up with it was actually putting the variety inside of different classes of ray gun.
So we had heat ray guns that, you know, melted things and burned the armor off.
We had force ray guns which shattered things and pushed them around.
And then we had the grappling hook which allowed you to.
And all of these ray guns sort of, over time, the player learns how to use them through the different missions and you get this different kinds of challenges inside of the caverns I'll talk about in a minute.
But generally speaking, what we found was keeping things in the player's hand, keeping stuff, you know, centered on the player was generally better than trying to externalize it in an action experience.
But there are times, which I'll get to in a second, where we externalize stuff because we're in a much quieter environment, or more gentle environment.
But if we give you three of these things, how do you use them?
How do you get a hold of them?
We came up with what we call a tool bangle.
Which basically, as soon as you touch the top of the trackpad there, it pops out these three, each of the classes of tool that you've got, and then you just swipe your hand through it, or just tilt even in that direction, and it very quickly just swaps over to that.
People get into that rhythm quite quickly, because it's always heat, grapple, force.
So people very quickly get into this rhythm where they're just like, oh, I need my force.
And they just flick their wrist, and the next thing they know, they've got it.
Works really well.
So we're in this strange new world.
We're in mixed reality.
We're throwing robots at the player and everything else.
So how are we going to teach the player how to learn about this space and enjoy it quickly?
One of our primary ways was Gimble, and Gimble is a companion character who features very, very heavily throughout the game.
He's a companion.
Oh, cool!
You must be my human.
You look so... lifelike.
Um, and just having a friend there is really quite, someone who just addresses you directly and is able to, you know, be nice about what's going on around you.
Very helpful.
Um, he was, uh, he's also the kind of the core protagonist of the story and the story teller.
I'm Gimbal.
I'm Gimbal.
I'm Gimbal.
I'm Gimbal.
I'm Gimbal.
I'm Gimbal.
I'm Gimbal.
I'm Gimbal.
I'm Gimbal.
I'm Gimbal.
I'm Gimbal.
I'm Gimbal.
I'm Gimbal.
I'm Gimbal.
Nice to meet you!
An introduction is in order.
I am Dr. Grodbort, and I am broadcasting to you from my headquarters at the Dr. Grodbort's factory.
So Gimble was able to bring all the human characters in the world through a holographic projection.
We did some fun stuff with these guys.
They will look at the player, so they'll head track to you.
There's a few moments where Dr. G will point at you, for example, and he points directly at you.
And those are really...
kind of spooky moments where you're staying there and this character just looks at you and you're like, okay, hi, all right, we're here now.
Couple of little tricks you can get away with when you're using holographic projection.
If you keep walking around him to a point where he can't look at you anymore, he'll just sort of flicker and reorient because that way you don't have to do a bunch of footsteps, which was quite helpful.
And it meant that we could kind of pick good spots for him no matter what.
The other valuable thing that we found was, you can see from Gimbal there, the projections coming off of the ring on his neck.
That means that when Gimbal starts projecting, you can sort of immediately tell where that character is going to be and follow to it.
And he's your guide.
So obviously, you've got a limited field of view.
It's fairly large, but it's still limited.
And because we're introducing objects to the world that were not there previously, how are you supposed to know that this thing's behind you?
Well, audio cues help a lot, but we need to get you there.
So one of the things that Gimbal does, it's super valuable, is he'll gesture at a thing, look at it, move to it, and you naturally just follow him there.
And he was also a teacher, so this is explaining, like, Gimbal is throwing a wrench at you so that you understand what pain is.
And the way that we communicated pain to the player was the, or that they were taking damage was all virtual content would go red for a second.
The world would actually slow down.
That's a really, really valuable tool you've got access to.
When the whole world is moving at normal speed, but suddenly game time changes, people notice that very, very quickly.
It's super, super effective.
Um, and then, uh, through he'll do an animation to explain to you how to put your hand up, see your hand up, see your shield, um, and now you blocked it.
So.
And finally, also really helpful, the character when you're in combat and he hides out in his hidey hole and he calls out where the threats are coming from to help you orient yourself.
Yesterday, my colleague Jordan did a great talk at the GDC AI Summit and so if you want to know more about Gimbal, definitely dive into that one, it'll be on the vault afterwards.
So we've got people moving around, we've started to show them where stuff is, we're guiding them through this space.
with a companion, but you're still standing and you're doing all this stuff.
So our core game loop actually incorporate quite a lot of breaks in it to give players a chance to rest.
And we loop between two kind of main spaces, what we call home base.
Which is where players have this map of the robot planet that allows them to select missions and they can buy ray guns and do other things like that.
It's also where we deliver story content, so that projection of Dr. Gorburt for example.
Those are always moments where the player is operating at their own pace and they can be kind of calm about things and take a moment to investigate stuff.
When you go into missions, now you're fighting robots, you're collecting gubbins, which are the currency in the game, and you're destroying these big caverns and things like that.
And what we found was that, generally speaking, in the mission space, we put players in there for about two to five minutes.
Any more than that, you're moving around and it can get quite tiring to do that.
And so we, and it's also just like, stuff is in your face and trying to kill you.
You need a break.
So we come back into home base, and you spend as much time as you want to there.
And what we tried to get to was a point where players felt that rhythm, and they knew that whenever they came back to home base, they can take a break.
And they can step back, and maybe they'll come back tomorrow, or later in the day, or something like that, after they've played for half an hour, or whatever it is.
Because movement just can be tiring.
Not all of us are like our animator Jake.
Sorry, when I saw that I just had to throw it in.
It's just they were going to do a mocap test, and I was like, really?
OK.
One of the things that we also, again, we're trying to make a game for everyone, we did a lot of work around accessibility for our second update.
This is a very difficult space.
This is because, as with everything in mixed reality, this is new, right?
And so.
We were trying to get into, just think about the different ways that players could interact with the content.
So for example, shield is on your left hand, or on your off hand actually, so you can play left or right handed, doesn't matter.
So we added in our second update, we added the ability to put the shield on the bumper so you could play with one hand if for some reason the other one...
was not being detected well or you had an injury or for any other reason.
We put an aim beam in there.
Generally speaking, the visual effects guide the player's shots really well, but if you're having difficulty with depth, that will help.
Aim assist.
Um, which allows you to interact with objects at a distance.
So the robot planet has moments where you're plugging things in and grabbing stuff.
But this lets you kind of step through those things, even if you can't quite reach that.
Um, invincibility, um, was, and, uh, the ability to skip mission parts.
It's like people are there to see what's in this experience.
It's a.
It's, I keep saying this, but it's new, right? So, um, we want you to be able to see all of it.
Um, there's no reason not to. So why not? The other nice thing about invincibility is a great way to stop and look at the art. Also pause the game because the game content doesn't disappear.
So if you want to take a walk around a robot, just pause the game. Um, and subtitles. And we're pretty excited about this one. I had my doubts, but they assured me you were the one for the job.
Sorry about that. The video capture unfortunately cuts off the side, but the way that our subtitle system works is that it pins itself to the speaker.
If you look away from them, it drags to the corner of your field of view, but it's still quite legible.
And it biases towards the side that the speaker is closest to, and as you look back, it comes back to them.
It scales depending on distance.
I think the steps after this would be being able to dynamically scale the font and a few other things that are kind of new standards.
But I feel like these were good first steps, and I'm excited to see what other people get up to.
And of course, it's all quite experience-dependent.
So how do we get all this stuff in the real world?
One of the first big challenges is figuring out where to put stuff.
So at the beginning of the game, the first time you play.
If we don't recognize the space immediately, because once we've got a scan of the space and we know where it is, we can just recall that and bring it back up.
But if we don't, we have this scanning experience.
So a player walks around, you can see this shader, and it fills in in a really interesting way.
It feels like you want to try and cover the whole space in this funky stuff.
We've got these buttons in the space that just float and hang around, and as you walk around and press them, they're there to encourage players to walk around and get a better scan.
And so you can kind of, it also helps you understand, ah, this is the space that the game currently understands.
And so it hopefully encourages people to do a fairly robust scan.
Once we've got that, then we use a world search to figure out where to put stuff.
So this is us just moving the colliders there, the player, and so we're just moving the player around and trying to figure out, okay, that's where the stand can go.
Control's trying to be, okay, I need to be about here to the player.
You can't quite see it, but there's stuff on the walls that's moving around.
Of course, the player would never see this, but in debug we kind of go, all right, where is stuff going to fit?
So once we've figured out where we're going to put stuff, we need people to be able to find it.
One of our primary tools was what we call a glint system.
So you can see that those waves kind of pulling off to the side.
At any given time, there's really one thing that we want the player to be looking at, and we just have a priority system which sorts that.
And so these glints sit in the corner of the field of view and just draw your eye to it.
It's quite subtle.
It's not as – it's more subtle than getting out of this in-editor capture.
But we found that that was really valuable and it extended into a few other parts of the gameplay.
Gimbal, of course, as I previously mentioned, will always go, hey, things are over here.
Wait until seen.
So the look-ats were really great.
Basically – oh, sorry.
Yeah.
It was great.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
So that's an example of objects waiting until the player looks at them before they activate.
So we could have all these great animations of like portals opening and all this other cool stuff going on.
But if a player never sees it, well that's a bummer.
And it doesn't, you know, it doesn't sell the fantasy as much.
So what we would do is leave, for example, in the case of the porthole being closed there, we would leave a glint on it and the porthole had a closed state.
And you'd be kind of looking around going like, oh is that, oh what's that?
And then it would.
And we did that with lots of different objects so that players were always sort of aware that this was a living mechanical thing happening to them.
Or around them, I should say.
Sometimes we have to.
Spatial audio is super, super important.
Figuring out where things are, I mean, being able to hear stuff, the non-occluding speakers on the Magic Leap One are quite good for basically positioning stuff around the player.
You would hear things coming out of walls and all around you all the time.
Again, not a lot to get in there from me, but Dave Shumway is speaking about this on Thursday and his examples from Crate are amazing and he can get you lots of details there.
So if you're into the audio side, I'd strongly recommend that.
Again, stuff happening outside of your field of view, the porthole sparks were a really valuable thing.
So as portholes were opening and being, basically we were like cutting them into the wall and doing that we would cast these sparks off and we'd always try to make sure the sparks would cross the player's field of view.
And that was really effective because of course they had directionality and so it would pull your attention towards them and you'd see them happen.
And lastly, this one's really subtle, but it was a really neat thing that Simon, our VFX guy came up with, was ambient motes of stuff in the air.
So we just kind of filled the space with this little gentle bit of dust.
And then that dust was always being sucked into whatever porthole was open.
So there's always this sort of like subtle background thing drawing your attention towards where stuff was going on.
It's a little thing, but it was one of those, you know, We've gone through like six things, right? It's like everything on top of everything.
You just try and layer this stuff in correctly.
So how does all this stuff actually work? Now these are all like these weird contraptions, right?
You've never dealt with this stuff before.
I've got the robot planet, we got miscars, we got a store, all of this stuff.
These are fantastical objects. You've never interacted with them before.
So one thing we found pretty quickly was making stuff physical was absolutely key.
Every time we tried to abstract something away, we found that people got lost.
So making it physical, making it something where you're really doing this with your hands and your body and you're moving to it, was really important.
So in this example, the players plugged in to get a mission, their mission card prints out, and then they put it in the thing.
So they put it in the briefing stand, and then now they can go and set up their load out of what ray gun they want to use.
Each step was discrete, and you could go forwards and backwards in the chain depending on what you were doing.
And that was really helpful for us because we knew where the player was at at any given point in this set of interactions.
So we could make sure that you were guided through nice and cleanly.
and not confused by, you know, basically any time that you were doing two things at once, people kind of lose track of it. Eventually we'll probably get to the point where, you know, operating in virtual spaces like this, or sorry, with virtual content in the real world like this, is, you know, kind of normal and will have some set of, you know, regular standards and norms that like WASD kind of stuff that people are used to. But in the meantime, You know, playtest the crap out of it and you'll be surprised at just how quickly you can overload somebody's awareness of things. Um, and you know, make it fun. Oh no, there we go. Um, the briefing cards and a lot of other bits and pieces that we had, you can just grab and throw around. Just like, people would spend like minutes just chucking this card in the air and then catching it and chucking it and catching it. People make a game out of anything, right? Um, and we just reprint you another card. Why not?
And making it smooshable was really important.
So smoosh is something that Tom Hall, one of our programmers, came up with as a way to avoid object interpenetration.
Because nothing ruins immersion quite like going, oh this virtual object just goes right through this virtual object and it has no sense of weight or presence.
That's me using my hand. The render on the capture is not great but you get the sense of that. So each one of these physical objects, or virtual physical objects, including things like the robot planet and whatnot, as you touch them and push them, they smoosh, they bounce around. They've all got physicality. And so nothing ever clips through anything else. And that was He just, he came up with that one day, showed it to us, and everybody kind of went, everything has to do this. Like, everything. Which made our lives slightly more complicated, as you can imagine, but it worked out for the best.
And lastly, making this thing really physical, um...
The Grappling Gun came out of one of our feature jams.
So we would take some time off from core development every few months, and even sometimes we were doing it once a month, to try different things out.
And the Grappling Gun came out of one of these jams.
And again, it was one of those things that was like, we need this.
This is really cool.
It lets you reach out.
grab something at a distance, pull it to you, and examine it.
And if you rip off a robot's leg, and then you've got this object in your hand all of a sudden, you're looking at it, and then throw it back at him, it's a good time.
There's just lots of bits and pieces you can interact with.
What gets even weirder is that you reach into the robot planet through the portals that are in the wall, and grab a virtual object from beyond the wall, and then pull that back to you.
And that is quite an experience the first time you do it.
That also led us to some puzzle mechanics that you'll encounter later on in the game, which are basically these robot planet security locks.
So again, this is another way to sort of control the pacing of the environment, or sorry, control the pacing of the gameplay.
You're in there, you know, later missions and Things are kind of intense and there's lots of robots and we want to like slow stuff down a little bit.
So we get into combat, we do some stuff, and then the robots like lock you out for a second.
Now you pull this thing out of the wall and it's got all these boxes and bits and bobs, it's almost like a busy board.
And you're bopping and changing and moving stuff around and they're just really fun to interact with, but again, it's at the player's own pace.
So it slows things down a little bit, lets you take that moment to kind of enjoy and appreciate.
So how do we get these robot invaders into your living room?
Well, this is what we call a human-scale combat.
So you see we've got these robots that are of different sizes.
They navigate the environment a little bit differently.
And we're just putting them in your space with you.
And the different robots, we started with our probe bot.
This is like a small flyer, like a really nasty wasp.
It's the first thing you encounter.
Flying stuff is great because it can clear your couch, your table, your whatever.
It can just get around to the player very quickly.
Super helpful.
It was also actually like the very first thing we put into mixed reality from workshop.
That's Sam Miller, one of the original Magic Leap engineers demonstrating.
They were just, they were trying to take a picture and go like, is this thing really here?
It's a lot of fun.
But yeah, I can't recommend strongly enough, like if you need something that is quick and can get around, look at flying stuff.
And these use the same flight graph as Gimbal, so we got a bit of reuse on that space.
The Simpletron are these tall, gangly, kind of like creepy dudes.
They're about eye average, kind of eye height for most players.
And we wanted them to be like a melee enemy.
So they just originally their attacks, like they'd walk up and they'd take a swipe at you.
It turns out that that was like getting really close and really kind of in your face.
So we gave them a ranged, like a ranged punch where they wind up and throw this punch out from quite a, they can do it from quite a distance.
And then eventually when.
As we were getting closer to kind of the final form factor of the device and we were able to move around more, we went back to giving them some melee attacks as well that were like this spinning attack, for example, where he just like sticks his arms out and helicopters at you.
And you can hear it coming and it sounds like a million razor blades.
It's really, it's a bit freaky.
Fun fact though, everything is physical, including that attack.
So if you sit down, it will miss you.
It goes right over your head.
And then we had our Thugmabot, and these guys were waist high, they're just like permanently angry little dudes.
They've got a jetpack so that they can clear obstacles in your room and in the caverns.
And they had a couple different ranged attack types.
And you can see all these robots are wearing different types of armor.
The armor for us was really valuable because it let us challenge the player's ray gun choice in different ways.
So like the rubberized one over there melts when you hit it with heat, but will reflect force and just the grapple bounces off of it.
That shiny chrome armor there can be obliterated with a force weapon, but again the grappling hook will just skid off of it and it reflects the heat ray guns.
And these are the fully armored versions, but when we introduced them to the player, we would give them just the torso armor or just the leg armor, and that let us challenge the player's precision and also start teaching them where they were going to be vulnerable to certain types.
And lastly I'd say, um, it's really important to keep this stuff kind of silly.
Or at least it was for us.
Because again, we're attacking you with these characters.
This is really, it's in your space. It's quite personal.
So we made sure that everything, they've all got really goofy voice lines.
They've got these fun little animations that they're idols.
The rockets that get fired from the Thugma bots are these like super angry little things that make goofy noises as they fly by your head.
Also really good for spatialized audio.
And we've just added kind of humor wherever you could.
If you use the grappling hook on the walls of your room, like just against the wall there, you'll find that you can rip things out of the wall that you wouldn't expect.
There's all kinds of stuff hidden behind the, you know, the boards of your house.
So the robots all shared a nav mesh that was made up of grid positions that were constantly being weighed to find the best spot, taking into account things like player position, particularly line of sight based on whatever attacks they had available, the position of the other robots, the height of surrounding geometry, and the available movement states from one position to the next.
So do I need to be able to jet pack over there?
Can I walk there in a straight line?
So this was a really important, and I think it's one of those challenges that you'll find.
And it feels like a traditional game challenge until you go, I have no control over the world.
All of my level design stuff goes out the window because I don't know where your couch is.
So being quite dynamic about this is really important.
And the attack tells, so that glint system that we use to kind of indicate where stuff is at for the player was really valuable and we ended up with that.
So you can see how, um, you can see how there was those glints there where they were yellow to indicate, okay, that's the position of a thing. They would go red, uh, when the robot was about to attack. And that's how you knew where the, where the threat was coming from, uh, if you didn't happen to be looking at it.
And so we had to manage the intensity of all this.
We built a thing we call the action timeline.
And that's set up in such a way that we can stack and base, sorry, we can decide who's going to attack the player and when based on a variety of criteria, like their distance to the player, did they last attack?
How close to my field of view are they?
We want to bias attackers to the ones that you're looking at versus the ones outside.
Create kind of that Kung Fu fight circle feeling.
Um, so the action timeline, basically everything has a buffer of exclusivity and we can address, adjust that. So it says no other attack action can take place during this time. Um, we activate the tell, which is that red glow at a certain point. Um, there's a wind up time on everything.
So how long does it take before the robot's actually able to attack? So in the thugging bots case, you could see him like standing there, embracing himself to take a shot. Um, and then the attack itself.
And so by dynamically scaling this, we could really quite dramatically change the difficulty level of the game.
And so as you get later in the game, the exclusive buffers come down and down and down so that robots are attacking more frequently.
And that was actually, that one variable became the one that we kind of focused on the most.
So where are all these robots coming from?
It's the robot planet.
So we have these caverns.
So to sell the idea that this robot planet is this big space where these robots are being manufactured and invading the Earth from, we had a few of these really big caverns that would open up.
And you can see, if you walk up towards them or you stand to the left or right of them, you can just see all of this detail and depth inside of them.
And we also use them as sort of a form of environmental storytelling.
So they start off in the furnace where they're like melting down metal for building something.
And then in the smelter you can see them manufacturing the parts for whatever that thing is.
And then in assembly you can see them putting it together before we get to, well, the bit at the end, which I won't spoil.
And these caverns, all of them ended up with these light, what we call gates, which were kind of light puzzle elements, like the heat-based one over there, this little robot who just pulls a lever, the idea being that you're sabotaging the robot planet.
Each one of these responded to different attack types, like the heat, the force, the grapple, and some of them were compound and had two.
One thing I'll note about that though is that we were, you know, sure we're dynamically placing stuff in the environment, we're trying to get it all right all the time, and we've gotten our stuff out beyond the player's wall, but you've got to make sure they can see it because if that cavern happened to get placed up against the side of the wall...
And the thing that they needed to shoot, the gate they needed to shoot, was like over there somewhere.
You can't walk through your wall, right? So you can't even physically get yourself to a position where you can see it.
So we had to, we developed a, like a test harness basically in Unity that allowed us to kind of look through and figure out, okay, we assume that players can stand, we had to make a few assumptions.
One of them was players can stand about this far away and see roughly this much.
And the caverns themselves, again, to adapt to the player's space, could also lift up a sill.
So they started off, and they're about yay high, and if there was a couch or something and that was just where we had a piece of clear wall, we would lift a sill up and then the robots could actually jump over out of it.
And again, you had to make sure players could still see what was in there.
So how do you get this consistency in diverse environments?
We've got the scan.
We've got the world search to make sure stuff is there.
We did end up with a small minimum spec.
During the scanning phase, ideally, players just look around, and we get what we need very quickly.
But if necessary, if they hit the Pause button, we'll show them what the minimum spec is.
And so for us, that was like two 50 by 50 centimeter spaces, one 50 by 50 centimeter floor space.
and an 80 by 90 on the wall if we needed that.
Once the scan satisfied those requirements, then we knew we could play the game in that space.
So basically, you can't control the level, right?
The level's not there for you anymore.
That's the player's room.
You can encourage people to move their furniture around, probably.
I'm sure that there will be experiences that do that, but we wanted to make it work.
So you really need to focus on what a systemic experience is.
How are you going to govern the play?
The game's really got to fit the player's space.
So we focused on mission design.
So that was which robots get introduced when, what type of armor shows up when, which combinations of armor, the rate of spawn, the rate of attack, all of those kinds of things.
And so we were able to pace out the experience so that everyone had roughly the same order of experience tap into them, and roughly the same sort of intensity of experience.
And so I think it's really important to kind of, you can create, and we did this a few times over the course of development, where we create a bit of a, like a target ideal of like, oh, the best experience would kind of be this.
What would we do?
What variables would we need access to, to try and get us to that point?
And then make that true so we can kind of paint that experience everywhere.
So we had to plan to be wrong.
This was the thing, like, we've got all these robots and stuff, but as we were doing this, we were, you know.
We had quite a bit of hardware change over time.
This was the WD3.
And you can see here, as Richard's playing, he's really, you know, he's standing in one place because he's got this tether to a PC and he can't move around so much.
And so we knew for a fact that we were going to be untethered, our sixth off would work with, you know, attached to it, people are going to be able to walk everywhere.
This was certain.
This would be true.
We were helping, you know, the Magic Leap team get there.
And it still blew our minds how wrong we were about all of the assumptions that we had around player movement and everything else.
Where we got to in the end, you can see how different this is with what Jimmy Baird, one of our lead designers, calls a game about movement, where really we're trying to get people to move around in this space.
And it turned into a much more dynamic experience.
So yeah, when you're developing on early stage stuff, you can prepare to be wrong.
You know you're going to be wrong.
And it still shocks you a little bit about how wrong you are.
And I will say that ambiguity is difficult.
This was a long road for us to help develop the platform and develop the game.
We had to really conserve our energy throughout development.
We were in research and development phase for quite a long time.
And we could have been sprinting at every milestone and throwing ourselves up against this thing.
But we knew that at some point.
You know, the time for that would eventually come.
But in the meantime, we needed to just be experimenting and be cognizant of it.
It was amazing how fast the Magic Leap Engineering groups moved, right?
They were moving mountains to make a brand new platform from scratch.
Like, I still can't quite comprehend how they pulled all that stuff off in the time they did.
But for us, it meant that we sort of, we tried to build something to share with them, to help them guide their process, to get them excited and engaged with what we were making.
Um, but when we got to, and, but then we still had gas in the tank once it was like, okay, we've got the final form factor, away we go.
The good news is, um, you know, it's probably not going to be this kind of hard again.
Uh, we now have a platform.
We have the operating system, we have the SDK and it's getting better all the time.
Uh, just in December, we did a game jam and in three days we built nine prototypes.
And, uh, it used to take us three days to get something to work.
So it feels really good.
It feels like we're in a very exciting space with this.
So we shipped it.
We launched Dr. Robots Invaders at the LEAP convention in October in Los Angeles.
We built four of these demo bays.
You can see they look quite big and quite open compared to probably what your living room would be.
And that's partly, you know, it gives the robots lots of space to navigate and everything else.
But it's also because.
You can play in a much tighter space that you're familiar with.
When you're in an unfamiliar space, like, it's a health and safety hazard.
Because you'll be running around, and I saw some great stuff.
I saw somebody actually like dive behind that thing and shoot from underneath a coffee table, which I thought was great.
Um, so yeah, bear in mind that if you're demoing things, uh, any space that you're familiar with, you've, you've got like a built in kind of proprioception and, and sense of that space that other people won't have.
So we try to make it safe for everybody.
Um, of course because it's what a workshop, we couldn't.
you know, just do it normally.
We had to have lots of folks there.
You know, our scientists were great.
They were welcoming people into the experience, getting them to sign their lives away on a blood-spattered piece of paper, and then handing them off to us for demos.
We had Lord Coxwayne himself there, and the Lady Victoria.
It was a good time.
And people just really enjoyed it.
It was really gratifying for us to spend, having spent all that time, you know, quietly hiding out in New Zealand, making this funky thing.
for people to just go and have a real good time with it.
The press reception was really positive, which was gratifying.
And I think lots of folks have said that it's been helpful for them to see what a full experience can be in this medium.
So just to wrap up, if you have the opportunity to help develop on a platform, communication is key.
I mean, that's true always and forever, right, of anything we do, but it really is.
Be prepared to live with friction.
This stuff was really hard for a long time and you just kind of have to get zen about it.
Our technical director, Mike, I swear is some sort of Buddha.
You've got to figure out what's under your direct control and maximize for it.
So we knew.
That we could control, for example, like we're working in Unity, we're on, we're in editor on PC, fine, no problem. We can build lots of stuff there, figure out how we take that to this early stage hardware as quickly as possible. But then how do we, you know, make as much as we can, and then push it over, make as much as we can push it over to speed up. And lastly, of course, bring the fun to your partners. If you're a game developer working with non game teams, you can you can make their month by showing up with something great.
So, spatial computing is super ridiculously exciting.
I'm very excited about it.
It's why I moved back to New Zealand.
And I hope you all have a crack at it.
Everything is new again, including our audience.
One of the things, as I said at the beginning, we're really Like, people can just get into this.
You put it on, and you're like, oh, I've got a thing.
Oh, I've got a ray gun.
Oh, things are happening.
And we've seen this with all of our experiences.
Tenandi, you just reach out and touch stuff.
And it's quite different.
And so you're going to meet all kinds of people who have maybe never played games before, certainly never played an immersive game before like this.
And so be prepared for that.
Get physical.
You know, we found that we could prototype a lot of stuff by, you know, just basically acting it out.
You know, this is like, where does Gimbal need to be in relation to the robot planet as the player goes through different steps?
You know, so there's Greg, Jimmy, and Jordan acting out like what would happen as you're working, as you, as the player goes through this stuff.
You've got almost no control over the player's space, and that's a feature, not a bug.
Build to it. You know, it's going to be hard. It's going to be tricky.
But take advantage of that. Take advantage of really thinking through systemic design.
And focus on player comfort.
You know, both the physical and the mental.
You know, take like, even light physical activity can be tiring over time.
You know, you think about like the minority report interface where he's moving stuff around.
It was an interview and Tom Cruise said it's one of the hardest things he's ever done in film because he had to keep his arms out there for shot after shot after shot.
You know, so think about things like that.
Make sure that you're not building something in a vacuum where you're like, cool, I built this on my computer.
Always, always, always push to device, stand up and test.
Move around, play it in the environment that you expect it to be played in.
And defend the planet from the robot invaders.
Thanks very much.
So, from Wednesday through Friday, we'll be at the Unity booth.
We're showing the Dr. Goreborts Invaders single player demo.
And we also have a brand new experience called Gore Battle, which is an early look at our first multiplayer experience.
It's a lot of fun.
And it's... yeah.
I don't want to spoil anything, but there's also a tea party.
So I do recommend checking that out.
Sign-ups will be open, I think, from first thing in the morning at the booth.
Also, as I say, we have offices from Zurich to Tel Aviv to Austin to Seattle to New Zealand, and we are always hiring.
And David Martin, one of our senior recruiters, is here if you want to talk to him about all that fun stuff.
And otherwise, I think we've got about three or four minutes for questions.
Great job. I played the game myself actually my mom had the same experience as your mom didn't she actually almost knocked down a wall painting trying to like Robot and so a number of people we've had almost put their heads through walls trying to look at portals It's like it was it was really amazing for me to see and that kind of brings me to you know, you mentioned the physicality of this and then how you know players can get a little bit tired and so forth and I'm wondering, given that you've, you know, you've spent years on this.
Do you have a sense of what you think the breakdown might be going forward in mixed reality between these kind of more physical experiences do you think that's going to be what really drives the popularity of these platforms, or will it be kind of a little bit more kind of casual, almost more like.
Kind of how traditional games are, maybe something more like the, you know, the Angry Birds experience.
What's your take on what you think people are actually going to be doing?
And do you have any statistics on what people have been doing in the game out in the wild, like in terms of playtime, you know, and so forth, completion rates and things like that?
So, I'm trying to read somebody's question, but, you know, are we expecting to see casual experiences, more physical experiences, more seed experiences?
I think the answer to that is we just don't know.
I think we'll see probably a lot of stuff, right?
Like it's just, you know, just like on your phone or your console, you've got everything from a match three to God of War.
And I think people are, you know, people are going to find and want different things depending on their mood.
So we'll see how that goes.
The second part was about the stats.
Yeah, so we have some, yeah, we do have some analytics.
And basically, we were looking for, yeah, how long are people playing for, you know, average session length, things like that.
Off the top of my head, I think our average session length is somewhere between 10 and 40 minutes, which is quite a range.
But we see, you know, you obviously see outliers, people who play for a couple hours, the battery will go for almost three hours playing.
So.
Yeah, it's quite variable, I think. But yeah, it's also like, it's worth noting, I think that because we're so early in this in this stage of the platform, like people are, people are engaging with it, both as players, I'm here, I want the experience. And as developers going, how does this thing work? And so like, they're just jumping in going like, okay, buttons are kind of like this.
That's cool. That's a reference for me in the get out. So I think our actual like, the reality of our stats is probably not.
It's not indicative of players per se.
It's indicative of this wide range of people who have got access to the device.
Cool, thank you.
You mentioned how unusual it was for Weta to make a video game.
I'm just wondering how that decision came about.
Like who was like, we need a game studio, let's go talk to the guys that did Lord of the Rings swords.
Oh, so the Magic Leap Weta Workshop relationship predates Magic Leap.
So Rony Abovitz, who's the CEO of Magic Leap, first got in touch with Weta to work on a sci-fi world that he wanted to create, because that's what we do. And so they were already had that relationship going and as Magic Leap became a thing, he was like, we need games, we need content. Hey, guys, I love this. The Gord Bort's ray guns and stuff seems like a good fit. And away they went. Awesome. Thanks. Okay, hop this way and then this way. Sorry. Ladies first.
Thank you. This was great. I'm wondering what you see different considerations or like net new things developers should keep in mind for multiplayer when it comes to spatial computing.
So things to keep in mind for multiplayer in spatial computing.
Space obviously is like, I mean the spatial part is the huge one.
We've had four or six people running around, you know, playing with each other and the, there's a reason there's a tea party to kind of start the experience to keep things chill before we start moving people around a bunch.
I think, yeah, I think space is honestly the single biggest consideration.
And then like what's, um, interactions with other people are amazing in mixed reality.
Like it's just, there's something really special about being able to do something unreal and a little bit weird just together in the real world.
So yeah, I would strongly encourage like anything that's cooperative or, um, like direct one-to-one interaction is, is, yeah.
Thank you.
Cheers.
So I played the game and I was really impressed with the transparency.
I was curious how you guys achieve that because most of the games have all the assets, they still look really transparent in the real world.
Do you have any new tricks how to fix that?
Yeah, so ways to make the virtual content appear more grounded.
I think it primarily is just our lighting model.
That, we tweaked that a long time.
And I'm unfortunately not the best person to speak to the specifics of that.
You probably, if you swing by Unity booth, Tom Hall's there.
He can probably tell you a little bit more about it.
Cool.
We got, oh, you can go for it, yeah.
Two minutes, okay, cool.
In my understanding, Magic Leap 1 has a two-layer display that contains two different focal lengths.
And what is the usage of any game title?
near layer is dedicated for the RayGans, or when the robot comes close to the user, do you use the near layer and the far layer?
So when are we, how are we choosing, excuse me, how are we choosing which depth plane to be using?
It's driven primarily by Excuse me, eye tracking.
So based on what the player is looking at, so if you're looking at a robot at a distance, we're rendering far plane.
If that robot comes up really close and you're looking at it right here, it's like a fundamental part of the platform is really to make sure that the rendering is as accommodating to the eye as possible.
So it's eye tracked that way.
So we just, we drive it based on the standards that the SDK sets.
Is it smooth on switching between layers?
Um, it's quite, I mean it's a fraction of a second and people are blinking enough that usually you don't notice it so much but um, sometimes you'll see it switch a little bit but that's, yeah. Um, it's not, yeah. Don't notice it really.
Uh huh. Okay. Thank you.
Cheers.
Real quick, did you ever think instead of like having people like skip certain sections if they're having difficulties, did you ever think of maybe setting up a sort of scaling difficulty where like the exclusion buffer that you're talking about was kind of like maybe increased a bit, or you know, decrease the amount of robots coming through or?
Yeah, so dynamic difficulty scaling. We experimented with it. Unfortunately, It was a really difficult one to get the right kind of information out of it.
I definitely think that's a place to be looking, especially to accommodate as many players as possible.
But yeah, unfortunately for us, it wasn't something that...
We never kind of got it to a place where it felt right.
So we kind of were like, we'll step back.
And the skip was added a bit later to accommodate for anybody who had real challenges with it.
Thank you.
Okay, last one. Cool.
I really enjoyed the experience.
But we, I'm using it actually as a reference point for something we're working on right now.
The thing I was most interested in were the portals, right, that the robots come out of.
I was kind of curious, can you speak to how you guys accomplished that?
Because, you know, trying to include the spatial mesh, and I had like the occlusion mesh.
It was, I got a solution, but it took some work.
So how do we get the portals on the wall?
It's basically, we're...
We're rendering the entire cavern space on the other side of your wall and just sticking it on there.
It's not like a traditional, not traditional, it's not like a proper portal system.
It's literally like we've put the geometry on there and then we've put occluders around it so that you can only see through from certain angles.
Basically one of the big challenges we had was...
Making sure that like these, the robots are walking with IK and stuff, right?
So having them, having the physics transfer nice and cleanly between the real world and the virtual world and having shots travel through that and everything else. We tried a few times through different portal systems and all of them at the end of the day were a little bit too expensive and Just created so many edge cases that we stuck with that format.
I think in the future it would be really nice to have a really sweet portal system.
So we'll probably build something like that at some point I'm sure.
But yeah, at the moment it's just like literally, there's the level, stick it on the outside of the wall.
Try not to walk through the wall.
Thank you.
Cheers. Thanks very much everyone.
