Hello everyone, my name is Wes Brandmont. I'm the lead technical art director at 343 Industries.
Welcome to my talk, Halo 4 content performance tips and techniques.
This afternoon I'm going to be talking about the work I did during the last year of production on Halo 4 to help get the game running at frame rate while maintaining the integrity of the visuals that the team had worked so hard on.
So a little bit about me. I double majored in computer graphics and illustration at Syracuse University. And I've been in the games industry for about 16 years. The first three as a lead artist and the last 13 in various tech art roles. I spent nine years at Electronic Arts, three years co-running a studio with three other guys and then the last four and a half years at Microsoft and the last two with 343.
So Halo 4 is my 20th ship title. Okay. So this talk is really geared towards folks who have little to no experience with content performance optimization techniques. So I'm going to kind of make that assumption as I go through the talk. We're going to start with discussion around performance planning and the tools that make this kind of work go easier.
Then we're going to get into the meat of the talk, which is common performance issues and ways to address those issues.
And then we'll wrap things up with performance reports and performance scheduling.
So before we get too far in, so what is performance?
Well, in the context of this talk, at a very high level, It's basically is our game running at frame rate.
And for Halo 4, our target frame rate was 30 frames per second.
And so basically, if we weren't running at 30 frames per second, we had bad performance.
And we had to kind of then, at that point, look a little bit deeper.
When I say deeper, what I'm talking about is how long is it taking the hardware to render a frame?
We had 33 milliseconds on Halo 4 in which to accomplish rendering of a frame in order to maintain our frame rate.
And so there's various stages at which this can slow down, and we'll talk about that in the next slide.
The reason this is important, which is probably obvious, is that if your performance stinks, then your interactivity goes down and your game's no fun.
And the reason performance analysis is really important is because what we want to do is maintain that frame rate while at the same time making sure that we kind of maintain the really awesome rich environment that our art teams have spent so much time on.
So why tech art?
I think tech art is uniquely positioned to kind of lead in this area.
We kind of have a background in both art and engineering, so we have what I think is a little bit more of a holistic view on things.
where, you know, artists might be more focused on just the visuals and the dev team might be more focused on just making sure the thing runs well. So when I'm looking at performance analysis, I find having this kind of high level picture in mind is really helpful. There's a lot more to this, but this is kind of the key stuff. So you've got two places where things can slow down. You've got your CPU and your GPU. And on Halo 4, We had two threads where you could potentially slow down the CPU or I would say the most common places we could slow down the CPU. And they were our SIM thread and our render thread.
And so our SIM thread is basically where we do AI updating, ray casts for collision, that sort of thing.
And our render thread is where we go through and sort of evaluate sort of what's visible, kind of collecting, data up to bundle up and hand off to the GPU, which we call feeding the GPU. And the GPU would be responsible for unpackaging the mesh and mesh data, shader resources, texture resources and handle rendering the various elements that we're passing to it. So at any point in this pipeline, things could slow down and your frame rate goes down as a result.
So before I get too far into kind of the nitty gritty...
I thought I'd share a little story with you that has some relevance towards this.
So I joined 343 in the fall of 2011 and up until that point the team had been in development for quite a while and they'd spent a lot of time and energy making some really awesome visuals, some really cool encounters, working on the narrative, but not a lot of time on performance. So the two projects that I've worked on prior to coming to 343, I spent quite a bit of time on performance optimization. So the engineering lead, David Berger, came to me and he said, hey, Wes, I'd love for you to kind of help lead the effort to get our game running at 30 frames per second.
and he said he was giving me the performance hammer. And I said, okay. Great. This is kind of work I've done in the past, so I was like, I definitely can help with that. And so a couple days later, I showed up at work and there was this big brown box on my desk. And I opened it up and there was literally this performance hammer in the box. And so...
His comment was basically, and I like that this was a very squishy hammer, because I think it's very relevant to kind of the performance balancing process.
But basically his comment to me was, I need you to work with the art team to kind of get things running well and if you can't accomplish this with the performance hammer, we'll come in with a sledgehammer.
With that information, I went and approached the art leads, let them know that we'd be partnering with them to try and maintain their awesome visuals and hit our frame rate goals.
And they were naturally skeptical.
And I could definitely relate to that, having been on other projects where.
Optimization often meant just kind of destroying the quality of stuff. Not because it was desired, but because that was what ended up being needed to get to performance goals. So, you know, I let them know, hey, my background is in art. I really care about the integrity of the work you guys have been doing.
And the reason I'm telling this story is I think it's really helpful to kind of build that trust going into the performance kind of optimization process.
I think having your team know that you've got their interests at heart and that you're going to be working with them to try and maintain all the love and effort that they've put into their work is a really important first step on this journey.
Okay, so...
When we started this process, one of the things that was really helpful was coming up with a per-frame budget.
And so, as I mentioned a few slides back, we had 33 milliseconds in which to render a frame.
And right off the top, we've got certain costs that we know we're always going to pay.
And I call those critical costs. We didn't really call them that during the project.
need to call them something for this slide. So critical costs.
And those are things like your HUD if you happen to be in a situation where you have a HUD.
You're going to pay for those all the time.
Post-process effects, if you've got certain things that you just know you're always going to do.
So we'd kind of take that off the top.
We'd also take a little overhead right off the bat, like a couple milliseconds, to make sure no matter what, we always had a little bit of buffer in case things kind of went haywire and we just needed some extra wiggle room so our frame rate wouldn't drop.
And then with what was left over, we sat down with all the art leads and we kind of mapped out, and this is a spreadsheet from one of our campaign missions, we basically mapped out for each area kind of what the classification was for that area.
So is it combat heavy, is it kind of a beautiful vista where we're not going to be doing a lot, so we can really put a lot more of our frame budget into rendering the environment.
is in an area where the lighting team really wants to go bananas and put a lot of really interesting lighting there, so we need more budget for doing that.
So we kind of go back and forth and negotiate these things and we come up with this per frame budget.
And so we had that for each mission in each area.
And so I'm going to mention this is more of like a best practice, as I mentioned.
Came out of the project about a year out from ship, so I didn't get a lot of opportunity on Halo 4 to do a lot of level review.
A lot of the levels were already kind of laid out.
But I think it's really important to mention this, because if you are early on in a project, getting involved, getting the graphics team involved, tech art involved early on, can kind of help head some things off that might be problematic, or at least you'll know where your kind of problem spots are gonna be, so you can kind of come up with mitigation plans ahead of time.
All right. So this is the most obvious performance tool and hopefully everybody has access to this but your FPS counter. Basically if you're running under your target frame rate, this is your early warning sign that you've got a problem. And just to kind of give you sort of a high level view of what this process looked like for us and probably looks like for most people is you find an area, you're not running at 30.
you go into that area in the game, you do some timing captures, which I'll talk about in a little bit, and you kind of diagnose what's going on and use various debug modes in the game to kind of help sleuth out what potentially could be the problem and ways to kind of address it. So one of the things that was really helpful, I mentioned this frame budget that we had.
We had a bunch of in-game counters that would kind of give us the same sort of information that we'd get from our timing captures.
But they just weren't as accurate because the fact that you were actually measuring this stuff introduced a certain amount of overhead.
But it was good for ballpark-y things and it allowed our art leads to have a way to basically look at their...
timings for their area and see if they were aligning well with the per frame budgets. And again, it was very ballparky, but this was really helpful in kind of a triaging situation where we're like, hey, we're not running at 30. Sometimes the the artist could kind of self-diagnose the problem and correct it, but if they couldn't, they'd escalate it to tech art.
we do an analysis. If we couldn't kind of come up with some ways that they could fix it in content and it was kind of deemed a engine side issue, then we would escalate it to our engineering team. I mentioned the debug views briefly, but basically there was a couple views that were really, really helpful in sort of diagnosing problems during performance analysis. Probably the biggest one that I found helpful was render freeze, which...
Basically, you freeze the camera, it kind of captures everything that is within the view frustum that the GPU is currently dealing with, and then it lets you pop the camera out and you can kind of look at it from another perspective.
So this is really helpful because in this case here, this is a shot from the first mission in Halo 4 where you're kind of going down the corridors of the Fort Unto Dawn after just coming out of kind of a deep freeze.
And those yellow lines are the view frustum.
And so you can see that there was a lot of stuff being rendered here that wasn't actually visible from the point of view of Master Chief.
And so this is a case where we were able to quickly identify that we had some culling to do.
The other kind of debug states were very helpful.
We had ways to choose to draw or not draw certain types of objects.
So static meshes versus dynamic meshes versus effects, just changing the wireframe mode, that sort of thing.
We also had this tool that would, well it was more of a kind of a option in when we ran our builds to log, information to our database. And so as we were progressing through the, or actually as everybody was kind of progressing through the game, we'd be periodically sampling FPS and then camera position and orientation and logging this to a database. And over time what this built out was this really nice heat map that we could then use a web, we had a web tool called Cortana web that could access this database and provide these heat maps which provided much more targeted kind of ways to identify where we need to go in and do real deep performance work.
Without this, we would have been wandering around levels and really kind of spending time in places we didn't need to be spending time.
So Halo 4 is a first party exclusive. So we were developing on Xbox 360 and the XDK comes with this great tool called Pix, which is the performance investigator for Xbox 360.
And this allows you to do CPU and GPU timing captures. And so I kind of mentioned our process is we find a place where we're running slow. It was very quick to get started.
create timing captures because you can just kind of attach picks and it would just kind of run while the game was running and you could pause it, it would pause the game, you could just kind of select a region and generate one of these timing captures which basically would give you a breakdown for the range of frames you've selected of kind of what the CPU was working on during that time period.
And the very top row in this image is what the GPU's doing.
And so a real quick indicator that you've got a problem was In this case, not a problem.
Is that if you have big white gaps, and if that top GPU line didn't look like a solid black bar, then your GPU is probably waiting around for something to finish up on the sim thread or render thread.
So it was a really quick way to kind of say, hey, I need to dig down deeper into the events that are happening on these threads and see what the timings are.
We'll talk a little bit more about that in a second.
But this was a first stop, because you very quickly rule out that it was the CPU.
And then the GPU timing captures, which we'll talk about on the next slide, take a little bit more time, because we have to kind of gather up all the information that is used to render a single frame.
And it definitely, it's more intensive for the dev kit.
So we'd kind of do this only once we'd kind of identified that we have a kind of a GPU-related problem in an area.
And what this does, though, is it grabs everything and kind of deconstructs the frame into this nice spreadsheet where you can kind of click through the spreadsheet and you've got timing for each element that's being drawn. And so it's very easy to kind of identify what's taking a long time. And then you can either ‑‑ there's some additional tools in the GPU timing where you can kind of analyze to see if you're kind of pixel shader or vertex shader bound or if you're stalled on texture fetches, that sort of thing.
And you can also then go into the actual content then and sort of kind of analyze it as well to kind of see what might be causing that to take a while. Okay. So now we get to the meat and potatoes of the talk. So these were some performance issues that came up over and over again during the development of Halo 4. And so I've kind of collated them all because they just kept happening over and over again. I can only assume they will happen for other people as well.
So large draw distances. In Halo 4 we had some really big missions, really expansive spaces. And we would often have performance issues in these areas. So generally this is due to one of a couple of things, poor LODing, related small triangles and also too many draw calls. So how do we deal with this stuff? There's kind of a bag of tricks. Some of them are kind of like that. All right here we go.
Some of them are a little bit more straightforward than others. So small triangles, obvious tune LOD distance. If we've got small triangles and we have LODs, we can swap to the next lowest LOD. In some cases we didn't have LODs on some assets and that's what I'm showing here.
We had this very complex model for the UNSC Infinity, and it had been modeled kind of for cinematic sequences, and we didn't actually know it was gonna end up making an appearance in the game pretty close to a combat area.
And so it was dropped in at the end of one of the missions, and...
And we ended up, this was a case of small triangles where we just had, we were processing not only just small triangles but too many triangles.
And so kind of removing a lot of the smaller details that you couldn't really appreciate at the distance it was at, we basically generally created a one-off LOD for this case.
Similarly at the end of the second to last mission, there's this kind of atrium area where this thing on an asteroid and it was modeled to kind of really look good when you're wandering around on foot. But later on in the mission you kind of traverse upward in an elevator.
And the art team had kind of just duplicated the mesh over to build this other asset.
And hadn't really taken time to kind of evaluate the size of the triangles.
And so we had a lot of tiny little triangles, which you can see I've circled all over the place saying, hey, you should probably delete these.
And they did.
And our performance got back to where it needed to be in that area.
Okay. Another technique. Draw calls. So when you're dealing with big distances and you have a lot of draw calls, this one may be, again, pretty obvious, is you want to call stuff. But I was surprised at how many times we were drawing things that we didn't need to be drawing and nobody really noticed. So this was from the last mission. We had this trench run. We were flying a broad sword down this trench and it was running really choppy. And the team was very concerned about having to, you know, impact the visuals to kind of get it into performance. Well, it turned out we were just rendering chunks of stuff just way, way out into the distance and it was stuff that you couldn't even see. Stuff that wouldn't even render in the frame. So this was a real simple case of just pulling in the distance callings that we were dropping things out sooner to reduce draw calls. It didn't impact the visuals at all and it got us back to where we needed to be for that area.
So sometimes when you've got these big, expansive spaces, though, you can't really call things.
You have to draw them.
And that's where ProxyGeo really kind of is a big help.
So in the first mission of Halo 4, you're on this severed half of forward onto Dawn.
And probably about a third of the way into the mission, you realize for the first time that there's these Covenant forces on the ship.
And you're looking out kind of over this observatory decking onto this missile bay, kind of open area.
beyond and it's actually a combat space later on in the mission. But at the point where you're viewing it, we had some really bad performance issues because not only are you rendering this big space, but we're doing it through a glass kind of surface. And so there's a lot of problems kind of compounding each other. And so in this case, we were able to get most of the way back into Perth by...
just creating a lower res version of this big outer area and then taking an in-game screenshot of the high res geometry and projection mapping it back onto the lower res geometry.
It looked the same, so it didn't drastically affect the visuals, but it helped us get back into performance for that area.
Okay. So sometimes you want to call things and you just, they're right in front of your face and there's nothing you can do. And we had, but that's not true, there is something you can do, which is occlusion cards. So this is a technique I first started using on Connected Ventures.
Basically, if you've modeled the heck out of an area and you've got, you know, a ton of geo, but you kind of need to, um...
You kind of need to get things back into scope.
This is kind of a way to approach that, one of many.
So occlusion cards, the basic idea is this.
Hopefully this runs.
So you've got the shader.
that just fades out as the camera approaches it.
So when it's opaque, you can call everything behind it.
And then you just kind of start drawing it just before it starts to fade out.
And I should also note that these don't have to be a plane.
It could be kind of a dome, or it could be any kind of arbitrary shape.
And it doesn't have to be kind of a.
a fog kind of plane here like this. You can put textures on it. You can put animated kind of shaders. I'm going to show you some examples of that. So it doesn't have to be a very obvious kind of just straight up fogging technique that is being used here. So some flavors of this that were used on Halo 4. This is a bloom occlusion card. Basically what we're doing here is...
We are using it to kind of fake a fake HDR exposure.
So we've turned up the color really bright and we let our post-process bloom, kind of blow it out.
But while we're coming up this tunnel, we're basically rendering nothing behind that thing.
And as we come up, just before it starts to fade is when we kind of bring in that huge, complicated vista that we reveal as you kind of crest over this rise.
Another example here, this is at the end of the second mission in Halo 4.
We had this very complicated forerunner building and a pretty heavy encounter going on in this area. So when you first enter this space we're having performance problems because not only were we rendering this really complicated exterior, there was a hallway at the base of this structure in, let me see if I can get this to work here, right in this area.
And so what we did was we created what I call an imposter.
occlusion card in this space where we took a screen shot similar to what we did with the proxy geo of the interior of that space before we called it. And then we just used that as a texture map on one of these occlusion cards and we do kind of a cross fade. And in the context of the game play you're kind of down in this lower level so you don't really tend to notice this. Where I'm standing in the level is probably where it is most prominent. You really need to be kind of...
keeping your eye on it to really notice it. But it got us back into Perf for this area.
And then another kind of variation on this is fog occlusion card. And this is actually it's not just a fog occlusion card, it's kind of like an animated fog kind of spilling over effect.
It's just a card like I've been saying, where it kind of fades out.
But what we did here was this big space off to the left, which has a ton of geometry in it, we were having some performance issues when we came down the hall here.
So we just culled all that and put this kind of fog, kind of animated spilling over, and it kind of masks the fact that we basically, if we took that fog away, we're just looking outside the world.
There's nothing rendering there.
So it kind of just masks the culling happening in that area.
Okay, let's go...
Okay, there we go.
So, the next performance issue, kind of related to these draw call stuff is poor culling.
So, this is, can sometimes be stuff that's actually in view in the camera view frustum, but a lot of times, poor culling can be due to things that are not even in the camera view frustum or...
seem like they're not in the view for us, but we're still paying for them.
Sometimes, well usually this is due to really big meshes. It can also be due to if we aren't rendering the right stuff into the Z-prepass so that we can kind of early out. Both of these can be contributing factors.
This next video is going to kind of show you the problem with big meshes.
So if you've got a really complicated mesh, it tends to be like a terrain mesh or like maybe like a big building or something.
Even with little polygons in view, we have to kind of have the whole thing being processed.
Where if we chop it up, we can immediately start culling things out as they move out of the camera frustum.
So this doesn't really affect visuals at all.
It's really more of a content fix, again.
That's what the focus of this talk is basically, how can we modify content to kind of get it back to where it needs to be.
And this is really kind of a low-hanging fruit.
An example of this is...
There was a mission on Halo 4, we're kind of in this desert environment, we're riding on this really big vehicle called the Mammoth, and we come to the end of it, the end of the Mammoth ride, and we jump off and we're in kind of this grotto.
that we called Sniper Alley, which you can see here, is this little area right here.
And we were having some performance issues, and it turned out it was exactly this big mesh problem.
So when we went into the render freeze, you could see that we had this entire giant terrain mesh.
This was actually a problem at a couple of different spots on this mission.
And like I've just said, chopping it up solved the problem.
Also had the added byproduct of giving us a little bit better management over our light maps.
Another thing that we could do in these areas, too, that helped with culling is we used a portaling system to do culling on the CPU.
And so tightening up those portals and making sure that they were really crafted as well as they could be helped a lot, too.
Because when we first built these spaces out, we'd keep this stuff kind of loose because the designers would still be adding and removing things.
But as we got closer to ship, getting those things really aligned with the content was important.
So another big area of performance issue, expensive shaders.
And probably all of you have experienced this.
So lots of samplers, lots of math instructions all contribute to shaders being expensive.
So the solution is shader optimization.
This image is a picture of some Forerunner metal.
We had a fairly complicated metal shader that we used for Forerunner surfaces.
And the last mission of Halo 4 had...
basically metal everywhere. And so we had to create a more optimized version for that mission.
And this one was made about 20% cheaper just by switching out the speculator model, which reduced the math instructions significantly. Kind of going along the shader optimization theme, we had this idea of production shaders versus ship shaders. So production shader is kind of like a generic shader that the artist can kind of experiment with, try different things out.
But when it came time to ship and we knew how a shader was going to be used in a specific context, we would dupe that shader off and just hack the hell out of it to get it like just mashed down.
And so, but maintain the look as much as possible.
So we would do that, we would kind of pack channels differently, we would reduce or remove shading terms if they were subtle or not used at all.
This image here is an example of the third mission of Halo.
The art team had spent quite a bit of time kind of crafting a look of these sort of volcanic rocks on that mission.
And they were very concerned about maintaining the look.
But we'd reached a point in the optimization process where these rocks were definitely, they were occupying a lot of screen space and they were quite expensive to render.
But we were just a little bit over.
So I asked the art lead, hey, would you mind...
If I took a crack at optimizing this rock shader and his response was sure, but it needs to look exactly the same.
And so I said, okay, fair enough.
I was able to get it about 15% faster.
And what I did was rather than do like an A-B comparison when I showed him the results, I was inspired by Sesame Street.
Have you guys ever heard like one of these things is not like the other?
Yeah, okay. So I built a scene with about five of these rocks and only one of them was the optimized one and I sat him down in front of it and I said if you can tell me which one is the optimized one I'll go back to the drawing board and he sat there for about a minute and pointed out the wrong rock. So the optimization stuck. And the reason I tell that story is because I think it's definitely a technique I will use in the future.
I think when you've got some maybe some built-in bias, I think making things a little more obfuscated when it comes to kind of these sort of subjective judgment calls, it makes sure that people are really being honest about what's important visually.
Another thing I wanted to mention is...
Our art team did a lot of kit bashing to kind of build assets.
So a lot of times we'd end up with just gobs of materials on what were otherwise very simple assets.
And those materials would often be sampling a ton of textures.
So doing some material optimization was also an important part of this shader optimization process.
So overdraw. Our effects team was actually very sensitive to this problem. This is where we're drawing too many transparent things on top of each other and it starts to bog things down. So despite some of our efforts in this area, you still have cases where...
effect might end up being placed in a certain context and it might be just the straw that breaks the camel's back. So we would, a solution in these areas would be to either kind of tune the emission rates to minimize the amount of overdraw that was occurring. Sometimes we'd go back, ask the effects team to go back to sort of do some additional work on the materials that are applied to these sprites to add complexity in those materials rather than achieve that complexity by overlapping a lot of sprites.
Another area kind of related, we had a lot of lens flares in Halo 4. A lot. And so we had one area in one of our missions where it was just really running terrible.
And it turned out there was just all these overlapping quads from all these lens flare elements.
And so the solution here was creating a more optimized lens flare for that specific use case.
And that's really a common theme in a lot of this kind of performance work is when you're trying to kind of.
find the sweet spot with the visuals is rather than trying to create a solution that is going to fix it for your entire game is just really just tune things in the places where they need to be tuned so that way your visuals don't get affected in areas where there is no problem. The other thing we did, our graphics team would occasionally render to a kind of a quarter res buffer so it wouldn't take as long to render our transparence. That helped as well.
So sky boxes were another area where we had lots of transparent pixels. When we first started doing the sky boxes were gorgeous. When they first started doing them, they were just putting them on these big concentric quad strips.
So we were paying, you know, they were just textures with alpha in the sky. So all those pixels in the sky, we were paying overdraw cost for nothing visually. So the solution there was to go in and kind of cut the geometry so that we aren't paying for basically fully transparent pixels. And then taking it a step further to go in and actually build a quad strip along the, right along the edge of the kind of mountain ranges and stuff. So we only pay transparent costs right along that edge line.
and then put an opaque shader on the lower portions where we don't need the transparency.
This same technique can be extended to water.
If you're doing kind of depth blending along a shoreline and you're kind of fading out to kind of deeper water, as soon as you get into that deeper opaque water, you can just cut the geometry there and put a fully opaque shader in that area.
So you're basically, you've got opaque pixels in the center of your water masses.
You're only paying for transparency along the shorelines.
use that on connected ventures. Not on halo. Okay. Another performance issue. Lighting costs. So halo 4 used a deferred renderer. So we had two types of lights. Screen space lights and we had dynamic lights. And there was good use cases for using either one. But screen space lights were definitely the more efficient of the two.
And so, but we also got immediate feedback with the dynamic lights.
So the lighters would often work with fully dynamic lights and only switch things to screen space when they were ready to kind of call it final.
So occasionally we would have lights that just slipped through the gap where they forgot to flip that switch and turn them to screen space. That was a common thing we just have to check for. Some other cases, though, even with screen space, we could have some performance hits. And this is a ‑‑ this image here is a good example of that. We had these little covenant light sticks that had these just huge falloff radiuses to the lights. And this is actually a frame from PIX. And, again, PIX is really helpful. It's got some ‑‑ it's got some cool visualization modes. And this one allows you to see the wire frame for the fall off of the light. And so when we saw these lights were expensive and usually screen space lights were quite cheap, it was a good way to kind of say, hey, we've got to reduce the radius on these guys. And that was a real quick fix.
kind of speaking to the kind of lights being left behind, we had, we had like, we were over this area and nobody could figure it out. Turned out it was, there was these tiny little spot, dynamic spotlights in the middle of nowhere that were costing three milliseconds, which is a huge part of your 30 mil, 33 millisecond budget and just deleting these solved the problem. So just kind of being aware of what your content is doing is a huge part of this.
So cinematics, we did a lot of work on cinematics to get them into performance. We had some very complicated characters.
Cortana was by far one of our most expensive things to render in the game. She clocked in around 5 to 6 milliseconds due to the various render targets we had to create to achieve that effect. So we had this sequence at the end of the game.
the game where Cortana is kind of, she comes up and we've got this pretty complicated effect behind her and she's doing some stuff and we're very concerned about this particular shot. And so because she's expensive, she's drawing over other transparent things in a really huge environment.
kind of all the problems I've just kind of called out all in one shot. And so some of the ways we dealt with this, one we kind of pulled the plinth back a little bit so that we can and tilted the camera down so that we could get more opaque pixels covering the screen. So you'll notice this this kind of platform you're standing on occupies about half the frame. That helped improve the render time. You also notice we put this barricade behind her in between her and that that kind of orange orb effect. And what that allowed us to do is, again, this is to address overdraw issues. We basically put some opaque pixels back there. And so where she's rendering, we're not paying all that overdraw cost in addition to the cost of just rendering her. So those are some techniques that helped ensure that we could get that shot, achieve that shot for narrative. Finally, I just want to mention, when she's creating in the title screen, that's I kind of touched on this at the beginning of the talk.
You definitely want to make sure you optimize your post effects.
On Halo 4 we had two types of fog.
We had a patchy fog and a screen space fog.
And a lot of times we had both of those turned on at the same time.
We didn't really need it.
So kind of being aware of what you're actually using and whether or not it's really contributing significantly to the final look of the frame.
And then...
having your, making sure your, all the things you're paying critical costs for, things that you're rendering all the time like the HUD are as efficient as they can be. And early on in this process our HUD actually wasn't very efficient and our UI team did a great job kind of getting that down as far as they could so that it wasn't eating too much of our budget up.
So I mentioned at the beginning of the talk, GPU starvation.
There are a lot of cases where your GPU is not your bottleneck, it's your CPU.
And so this can be due to a variety of issues.
Slow collision, poor calling, just too many AI simulating all kind of contribute to GPU starvation.
So ways to fix that. We've already talked about some of the culling techniques. Going in and optimizing collision meshes helps get your ray cast costs down and we did quite a bit of that on Halo 4. We had two types of collision. We had a play collision and a bullet collision and we would go in and optimize those as necessary to get those ray cast times down. We also had times like the one shown here.
where we were spawning in way too many dynamic objects and or AI and we would, the solution here was to go talk with the design team and they would have to kind of stagger the spawning of objects, which usually wasn't a problem because it was usually stuff that wasn't really in view anyway.
It was just, and they hadn't intentionally meant it to spawn in as early as it did.
It was just kind of something that happened.
And so at the end of this whole process, the end goal here is we want to create a bunch of actionable items for the team to go address.
So creating these performance reports at the end are...
probably the most important part of the entire process.
So we would create kind of call-outs per team, environment, lighting, effects, all the ones listed here, and we would give them multiple suggestions for ways to fix each of their areas where they're over budget.
Again, these are all referenced back to that per frame budget I talked about at the beginning of the whole talk.
So they would get kind of a call-out for each area, like, hey, you're maybe a millisecond over, here's some ways you could kind of...
get that millisecond back and we'd give them, you know, maybe half a dozen different options.
And to me that was very important because it let them own the final decision on what got optimized. And we definitely could have gone in and just said, hey, this is what we're doing, live with it. But you get a lot more buy-in from the team by involving them in the process and allowing them to help be the decision-makers for how their content gets optimized.
So performance analysis takes quite a bit of time. I often felt basically like master chief here in this image where we had our ship date coming in and there was lots of performance to do and not a lot of time. It usually took about a day or more per pass on a mission to do a run through and that was with our automated kind of heat map creation process so we could do kind of more targeted analysis. So...
Definitely for us it was important to make sure that we had time scheduled, not only for the initial analysis, but then those reports that I just mentioned would get turned into bugs in our bug tracking software, and then when they were resolved, it would be on us to go back and follow up with folks and make sure, or follow up on those areas that we called out and see if they'd actually addressed the issue, and then if not, we had to generate a follow-up report and more bugs.
The other thing we did towards the end was making sure we had scheduled play-throughs on release kind of builds.
When we're kind of in the midst of production, we run, our builds that we were running with had a lot of extra counters in them to give us more information on timing.
Those, similar to the case where you've got the in-game debug menu that kind of introduces some overhead, even with the timing captures, just having those counters in there also introduces a little bit of overhead.
So really we got our true numbers when we actually did our full release build.
And then we would have very minimal...
kind of instrumentation in there to kind of get a sense of where our frame rate was and we would make sure we were doing play throughs in both full screen and split screen because that was one of our modes and we wanted to make sure that that was a good experience on both those modes.
So before I wrap up here, I want to call out this is a talk that's happening tomorrow. If you have a lot of interest in this performance stuff, there's going to be a talk focused specifically on Xbox one on the performance tools and definitely suggest checking that out. And I just want to say thank you to the entire 343 team, to Bonnie Ross, Josh Holmes and Neil Harrison for allowing me to share these stories with you and to David Berger for entrusting me with the perf hammer.
That's it. Thanks, everybody. So I can take questions. Do we have time for questions? Yeah.
So if anybody has got questions. Yeah?
So with the occlusion cards, did you just let it render to your duck buffer when it was fully opaque or did you do some other way to call the others that were behind it?
actually I'm glad you mentioned that. So there's a couple ways you can do this. So the depth occlusion cards are part of the transparent pass. They don't render to the depth buffer as you pointed out. But one thing you can do is if you want to, you can put like a really big You can dupe the occlusion geometry and maybe move it back a little bit and put an opaque shader on there and that can write to your Z prepass and that can be another way to do your culling.
You just turn that off before you start fading.
So would that do dynamic occlusion queries then for the actual objects to stop the draw calls or did you actually have somebody hook up like hey, these objects will turn on?
So in our engine we had basically a distance flag you could set that just says pass this distance, just stop evaluating this object. And so we just set that and we had some tools that would just very easily let us set that on a bunch of them all at once. Yeah.
Hi. So in this you were talking all about your career missions.
So I was wondering how much, if any of this applied to the multiplayer maps?
That's a great question. It very much applies to it. We couldn't use as many of the tricks because multiplayer is kind of like you've got just everybody everywhere all the time. So we were a lot more strict about our kind of requirements for those maps, about kind of how complicated they could be. Because there was just too many situations where you just, you never knew if there was going to be a bazillion grenades going off or what the...
situation was. So we could be a little bit more crafted in the campaign and multiplayer we had to be a lot more strict.
So especially with the forge maps where you have a huge amount of content that players can put into the maps, was there any kind of optimization that you could do for those?
Not a lot. Other than put caps on the number of things you can place in the forge environment, that's really...
where the optimization is, is just creating a built-in budget for players to be able to adhere to so we don't create a scene that will be unplayable.
