Reminder to do all of your after talk survey stuff.
But let's get right into it.
So I'm Mike Acton.
I'm the engine director at Insomniac Games.
And today I'm going to talk about solving Nintendo's Coding Game Challenge.
So if you don't know, Coding Game is.
An online site where you do sort of a game, it's sort of a programming competition site.
So they provide specific challenges.
People go on there and solve them.
It's good for practice.
There's lots of sites like it, lots of hacker sites, similar kinds of things.
But the fact that Nintendo sponsored a challenge is the thing that caught my eye specifically.
I'm like, OK, well this probably has something to do with games.
It makes it interesting to me.
All of my steps, all the things I'm about to show you, including this particular document, are on GitHub.
There's the link.
So you can pull that and follow along if you like.
So, today's talk is about process, not solution.
This, I'm just walking through my personal process of solving this problem.
There are probably a million other ways of tackling this particular problem.
This was mine.
I may walk through the solution as part of talking about the process, but that is not the point.
So I'm gonna walk through basically all the test code, or at least a significant portion of the test code and versions that I created while I solved the problem.
So from test zero zero to test one F, and just sort of work my way through it and tell you what I was thinking as I was going and why I was writing each thing.
So, starting with test zero.
Test zero zero.
What's the question?
What am I trying to solve?
Can I get any insight into that?
So, going on to the site.
This was the question that was presented.
The SETI program has received a series of messages from Alpha Centauri.
The most frequent message seems to be, blah blah blah.
It is not known why any of these messages are encoded, but there's a good chance that the Alpha Centurions are trying to evaluate our cognitive abilities before establishing advanced contact.
Our best engineers are working to encode this messages, et cetera, et cetera.
So there's a lot of flower, right?
A lot of flower language around the problem.
And at the bottom is presented some pseudocode of the encoding program.
So I read this, right?
Try to get excited about the problem.
So the first thing I need to do is I need to take away all the flowery language.
I need to figure out what it is that this is actually describing.
So to summarize the problem.
We have some function which given A returns B.
In terms of the problem space here, we're given B and F.
And we have to return all the A which satisfy that.
A and B can be 64, 128, 256, or 512 bits.
So it's a pretty straightforward description, problem description.
So in our case, in my case, I called f encode, and so the inverse of that is decode.
So b equals encode a, and decode b returns some set of a, things that could have been encoded to create that b.
So taking the pseudocode and the C++ code that was provided, here's the encode function as basically as delivered as part of the problem description.
And looking at it, in my process I'm looking at it, so it says there in comments, magic Centurion operation.
I can't really decipher what's happening just by looking at this bit of code.
So my goal here is really just to understand what uncode does before I get deeper into trying to write a decode function.
That's the most important thing to me, first, is what does Encode do?
So first thing I do is I test Encode with random ints.
And if you saw Squirrel's talk, you know, you know, getting a good set of random values is important.
And so what I did, and what I generally do, is go to random.org, which has an amazing set of actually properly random values that you can just download.
at any given time and use essentially as a noise table.
So I wanted to be able to repeat all of my tests constantly over and over again, so I have the same random table that I'm constantly using.
So I just downloaded a set of that, created a random ints.h, and now I know for the rest of time here, all my tests are gonna be the same.
So, for test zero zero, I'm just sort of printing out what the encode function, this magic encode function does. I just want to have a look at it and see if there's anything I can see.
So you can see I'm just looping through my test count, which is my random ints.
I'm calling the encode function, I'm just printing it out. That's it. Printing out the results.
I just want to see what it looks like.
Looks like this.
So I spent a lot of time literally just staring at this, the whole output.
I'm looking for patterns, things that appear, anything that looks interesting.
And nothing really pops at me at this point.
So now I have to actually dig in deeper.
OK.
I have to actually do some analysis.
There's nothing super obvious.
So that's what test01 is.
Is there any obvious connection between encode, input, and output?
So I'm testing a bunch of obvious stuff, but the most obvious thing to look for is, is there a correlation between the bits of the output and the bits of the input?
So I'm testing here, specifically, what's the probability of a bit of B being on, given the same bit of A?
And that's just this simple function.
So in pseudocode, all test one does is sort of loop through all the random tests, and for each bit in each one of the results, it counts up, here are the bits, here are the counts for all the bits in A, here are the counts for all the bits in B, and just calculates the probability of B given A for every single bit.
And so I looked at the results.
So from 0 to 63, all the bits.
If I look at the middle bits here, so basically everything in the middle, super not interesting, right?
Basically, they're all hovering around 0.5, so they're all essentially random, given whatever A is, there's no correlation with B. But the first, there's sort of a chunk at the top and a chunk of the bottom that are much more interesting.
And I can see it's sort of scaling up.
So I'll start with, you know, the...
you know, given A, the probability of B being on is only 23%, so, or 24%.
So it's a sort of high correlation between those two bits.
And it's sort of, you know, decreasing over the first few bits.
And sort of at the end, too, there's this sort of bunching up of a much higher correlation of bits.
So I thought, okay, well, this is super interesting, right?
So maybe there's something I can do with this.
So this is where I went off on a super long tangent, which I won't really get into.
But this is sort of the state machine generator.
And this is totally a path that you can take to solve this problem, but it is absolutely the long way around this problem.
So you just start with what's needed to get the first bit of B to be set.
So everything that I need to know in order to set, definitely know that the first bit of B is set.
And then I move on to say, given that I know what the first bit of B is and what I need to know, in A, what I need to know to get the second bit of B, et cetera.
And I just sort of loop this in on itself.
You can basically build a state machine generator based on that, on those facts.
And again, like I said, this is possible.
It is totally solvable this way.
It is just a really, really long way around solving this problem.
So as I'm deep into this.
this approach. It occurs to me that I missed a super obvious test, and that's test02 here.
Instead of just looking at random outputs, I'm going to recheck with ordered outputs.
So now this is what I'm doing here, test02.
Testing encode with ordered values.
So for my input, A, I'm just setting a fixed upper 32 bits and the lower 32 bits is just an incrementing value.
So for however many tests I have, it just starts with zero, one, two, three, and I encode that and I wanna look at B.
So let's see what that looks like.
Well, dang.
That's a lot more interesting.
There's a lot more correlation going on here.
And if I'm looking at here, right, what's happening here, the top value of each of these pairs is the input, the bottom value of each of these pairs is the output.
They're saying there's a lot of similarity between these two numbers.
So when I'm doing it in an incremental way, it's a lot clearer that there's some correlation between the input and the output.
My first impression when I'm looking at it, maybe this is some kind of gray code, maybe there's something going on here, that's sort of my first impression in just looking at this.
So my next step is, OK, maybe I'll just swap the output and just display it in some more little-endian format to see if that changes anything for me visually.
That's all I do, is I just swap the 232 bits just to say, maybe for me it's a little more natural.
Maybe I see something different.
And so that's all this is, is just this more little-endian format.
I'm like, OK, well, as I'm looking through these numbers, I see something super interesting.
here as I'm pouring down through the numbers I see there's something super interesting about each of the powers of two like there's there's there's something happening here the unique to just the powers of two in terms of the A in terms of the input.
So my next step is let's just print out the powers of two. Let's just look at that.
Let's see what's happening with that.
So now, test 04.
So test 04, I look at just all the powers of 2.
Now, you can look at this, and even without knowing what's going on here, you can see that there's a visual pattern.
You can see this left shifting going on of the inputs and outputs.
So there's clearly something interesting happening in the powers of two.
And in fact, I look at each individual one of these, and I can see the same thing going on.
So I have a of a0 and a1.
So remember, sort of little Indians, the right side here is a0, and the left side is a1.
And so we start with a0, and it looks like what's happening is b is just sort of the a0 shifted left.
And the amount that's shifted left by is basically the trailing zero count of...
A1. So I have some questions now. Like, is it, what's happening if A1 is not a power of two?
So what do I do?
I pick any arbitrary number, I just happen to pick 0F in this case, I pick an arbitrary number and I just break it up into its constituent powers of two, and in test 05, what I do is I say print out encoding of 1, 2, 4, and 8, and then the final value, F, and show me what that looks like.
So I can see what's the correlation between the final value and all the powers of two that it's made up out of.
So this is what that print out looked like.
So here's a input.
Here's the powers of 1, 2, 4, 8, the powers of 2 that make up f and f at the bottom.
So I'm looking at this.
I stare at these values.
I look at all the variations of these values.
I'm looking at it, and I see something very interesting happening here.
And that's this.
I look at the final value, f, at the bottom.
And it's really just the xor down the columns of all the power of 2 values there.
So the first bit, the 0 bit at the right-hand side is just really.
one XOR zero, XOR zero, XOR zero.
The second column similarly, it's one XOR one, XOR zero, XOR zero, zero at the bottom.
And so I see that all the way across.
So I find that very interesting.
So now I have kind of a theory of how this encode works.
So given where A and B are 64 bits, and I can break up A into two 32-bit segments, it kind of looks like this.
So I loop through all the bits of A0.
If it's on, then B XORs with A1, shifted left by whatever the current bit that I'm on there.
So this should duplicate the work that we saw, that I saw there.
So now I have to test that.
But first I want to just help myself visualize.
So my next step is really just to re-space things.
This doesn't provide me any value other than visual value.
I sort of, I want to look at the problem a different way, which is a lot of what I do.
I just print it out in a different way just to look at it.
So with test7, the next thing I wanted to do was just validate across a wider sample set.
Does what I'm seeing make sense?
Because up to now, I've tested this very limited set, right?
A0, just really small subset of values, and in fact, the last test was just literally just F, right?
One single value.
And A1 has up to this point I've just had fixed.
So does the theory I currently have, in terms of what this loop is supposed to do, hold up across all the sample data?
And does it change if a0 is anything other than the small subset values?
So I create this alternate version, this encode 232, which is basically just the code version of the pseudocode we just saw.
See, nothing unique or special about this.
And I run through...
So Test07 runs through the same random inputs, runs the original encode, runs this alternate version, and just checks to see if the results are the same.
So this is pure sanity checking.
Does the thing work the way I expect it to work across all the sample data that I'm dealing with?
In fact, it does.
It works fine.
So I'm very confident now that this is essentially the function.
So I want to play with some variations of the encode function at this point.
And so all test 8 here is is just the realization that I can do this if this branch here and check and shift of the i, or I can just multiply by a1.
And so this is just me playing with variations.
I know these are two the same.
Like, I know these two things are identical.
But I rerun that test 8.
I want to rerun it anyway.
I create it.
I test it.
I rerun all my tests just for sanity's sake.
And luckily, all the tests pass.
I am still sane.
So, test 9.
So, I want to go back and revisualize everything again, with all the test inputs, so with all the random values.
I want to see what it looks like again.
So, test 9 is the same as test 7, but that encode 232 that I created just prints out all the steps as it's going.
And so, me injecting a bunch of printfs into the code that I write is pretty much how I do stuff.
And so this is a bit of the sample output from test 09, which looks like this, boom.
So printing out at every step what's happening.
So at the top is A1, at the right hand side is A0, so all the bits in A0, and at the bottom here, the result of B.
And as I said, each one of these columns sort of XORs down.
And So the results are as I expected, but visually it's super interesting.
Because now I look at this, and I say, well, looking at this way and looking at a bigger case like this, a very specific, you know, these test cases, this looks suspiciously like some kind of longhand multiplication, right?
But for each place, there's something different going on, right?
Instead of multiplication, it's really just anding.
Instead of addition, it's sort of an xor.
So, you know, we have this multiplication.
Instead of multiplication, right, we have and, so only one times one is one.
And for addition, we have this truth table.
So this is what's going on. So the question is what fits this model?
You know, if this isn't really integer multiplication, but it is some kind of long-hand multiplication, what fits this model?
In fact, there is something that perfectly fits this model.
Multiplication of a polynomial over GF2 fits this model perfectly.
If you don't happen to know that fact, I don't know how you get from what I saw to this.
This is a massive leap.
And the problem is that you can't just search for those tables.
Right? It's very difficult.
So my suggestion is, in the case where I happen to not know these kinds of things, where I hit this kind of block, and I know there must be something that's called this, Often what I'll do is I'll write a bit of code that prints out a bunch of numbers in order and then I can search the integer database online for something that matches those numbers and I can see what things that fit that model.
So that's generally my approach to those.
So GF2 basically just means a finite field of two elements.
So we can see here if I look up GF2 on Wikipedia, those tables look super, super familiar.
Those are identical tables that we just created.
So as programmers, when we talk about finite fields, as programmers we use finite fields all the time.
So if I were to say you have a uint8 a and we put ff in it, and I asked you what is a plus two, probably most of you could tell me what the answer to that question is.
And we know because it just, we know.
that it just wraps around a certain number of finite things.
We know that it's just sort of just mod of 8 bits here.
And in GF2, really all that means is all the math is mod 2.
So 1 bit.
It's super simple, super easy to understand.
Really nice overview of what's happening in finite fields is this particular paper, which I totally recommend reading if this is something that interests you.
What does it mean to represent a polynomial over GF2?
So the exponent is implicit in its place, right?
And the coefficient is stored.
And the coefficient here in GF2, because everything is mod 2, can only be 1 or 0.
So if we take a particular example, 1011...
The exponent is implicit, right?
So we're going from the right to the left, x to the zero, x to the one, x to the two, x to the three, sort of as you would expect moving from the right to the left.
And so that's one, zero, one, one, which maps to x to the third plus x plus one.
You can see how sort of it maps.
So next test, right?
I want, now I kind of have a model and I have a theory.
I have a theory that what Encode is actually doing is multiplying polynomials over GF2.
Everything so far in my model fits perfectly to this fact.
I don't care if this is the reality.
The model fits correctly, so that's as far as I'm concerned is the reality, right?
If the model fits, it's correct.
So I want to create a new function.
called pgf2mul and just rework things in these terms, knowing that I should get the same results.
So I create this gf2, 0, 0, dot c, and I start writing things in these terms at this point.
So I create a gf2mul, gf2add, which is just XOR, and a gf2 shift left logical, which kind of does as you'd expect and just shifts the whole value over.
So this is what multiply does, which is very reminiscent of the other version of the encode that we saw.
It sort of tests that, goes through all the bits, tests the bit.
If the bit is set, then it adds it in, which is the same as XOR, and then it shifts over the A so we can continue moving along.
So as you can imagine, it's that sort of kind of longhand multiply going on here in a recognizable form.
I rerun this function against all the same tests and all the tests passed.
So I'm getting exactly the same results, it's just formulated in a different way.
So test OB, it's another sanity test.
Now I want to make sure that after I've sort of doing all this work and reformulating it, do all the other expected bit widths work?
I've really just been focused on the 64-bit version right now.
But I want to make sure that all this other stuff works.
So I need to verify these cases where B can be 128 or 256 or 512 bits.
So test OB is the same as the previous test, this test OA that we just did.
but I've extended it to all the above, all these cases.
I'm using the exact same random number tables, they're the same random values, I'm just sort of casting them wider.
So instead of taking the first 32 bits of the table, I'm taking the second, the first two, and casting that as 64, the first four, and casting that as 128.
And so running all the tests passed.
So I'm pretty convinced at this point that this is in fact the model.
This is in fact what Encode does across all of the bit depths, I'm pretty good.
So with testoc, now I think I know, pretty sure, what encode means, what could decode mean?
So this is where I get to the point where I'm actually trying to solve the actual problem here.
So if encode is GF2 mul, what does decode do?
Well, what's the reverse of multiply?
And that's factor, right?
So now I'm going to take a look at the provided test cases.
So here's test case one that's provided.
And now with my insight into what's happening in the encode function, a lot of stuff really becomes a lot more obvious.
So I can look at the input and output, and I can sort of interpret it.
So I see that the input is some 64-bit polynomial in sort of little-endian format, where only this sort of bottom 16 bits have anything in them.
And I can say, what's factor?
Well, the first is that that same number, that same number.
as a polynomial times one is it, and that same number times one is the same value.
So that makes sense in terms of factoring.
And I can presume here that some polynomial represented by 83 times some polynomial represented by E5 multiplies 273af, and I can see the reverse immediately underneath it.
And so the thing is though, as I'm looking through these other test cases, and you can see the same pattern here with one times the same number and these two numbers that are flipped.
And these two numbers, you know, there's two pairs here that are the same.
As I'm looking through these test cases...
it really, really should have been obvious to me when I was looking at the test cases originally that this was sort of a multiply factor thing.
When I see this sort of pairs and I'm looking at something times one and it really should have been a lot more obvious but it totally wasn't.
I totally missed this looking at the original cases.
I had to go through this process for me personally of visualizing all that data and going through it and walking through it and recreating in code in order to then in hindsight see what's going on in those test cases.
So now with TestOC, moving on.
I want to just print all those tests, take all those test cases and print them out in polynomial format.
So this is just for me personally for visualization purposes.
So go through each of the test cases and print it out like you see here.
So instead of this value, instead of these values up top, it's just printing out the same values in polynomial format.
So I look at this particular case and we said, all right, well, 7 3af should be a3 times e5 in as polynomials, which is interpreted as x to the seventh plus x plus one times x to the seventh plus x to the sixth plus x to the fifth plus x to the second plus one.
I promise I'm gonna try not to read too many polynomials in the talk today.
So the first thing I do is say, OK, if this is true, if this makes sense, then I should be able to verify this in like three seconds in Mathematica.
So I just take the polynomial, the input polynomial here, and I cut and paste because I put it in a nice format that I can cut and paste into Mathematica, cut and paste it.
And I say, factor this.
And luckily enough, Mathematica can do modulus two factoring.
So I just say, factor this, modulus two, boom.
Those are the two values.
In fact, those are the same identical values as they show up there, which are represented by 83 and E5.
So I'm super confident now that we're going down the right track, that this makes sense.
The lesson here is if you have a calculator, use it.
At the very least, to verify what you're doing.
So I go through and I cut and paste and I check all the other test cases as well.
I just paste those in.
Do they make sense?
Am I getting the same values?
And yes, indeed, they're all identical.
They all map to what I expect them to map to.
So test OD.
Start figuring out what decode would need to do.
What's the process like?
What are the steps?
I want to just plug this into Mathematica.
I want to actually do the thing.
So what does it look like?
So at this point I can restate the problem, so I write it down.
So given a polynomial over GF2...
to the n, where n can be one of these bit depths, 64, 128, 256, or 512, display all the pairs of factors of degree n, less than n divided by two, that's sort of a specific constraint to the problem definition, is you're just outputting these pairs of factors.
So what if there's more than two factors?
If you're given a polynomial that has a bunch of different factors, well, I think the answer here is you just recombine them until you get a pair that fits the constraint.
So the steps.
Find all the irreducible factors of f, so the smallest things that I can make up f with.
Recombine those until I get pairs that fit.
Format and sort the results and output.
Seems fairly straightforward, except that I don't know how to factor polynomials over GF2.
So this is my next step.
How do I figure, what do I do?
How do I figure this out?
So I ask myself, what would Knuth do, right?
So, crack open the book.
I don't know about you, but I find auto-computer programming super handy for reference.
I find it super handy for when I already, basically when I already know the answer.
I'm just looking it up, or I'm just reminding myself I just want to know a finer point.
When I don't actually know the answer, it's super hard for me to understand what's going on in there.
And this particular set of solutions is no exception to that.
So, but to point you, give you reference, volume two, section 462, factorization of polynomials, which is perfectly what I'm looking for here.
And the finer point of that particular page is this, this half of the page is pretty much the steps that we need to do.
But again, in my first glance here, in my first pass of this section and this page and this part of this page, it's super terse because I didn't really understand what was going on.
I didn't, it was very hard for me to read because I didn't already know the answer.
But luckily, we're given a hint.
I was given a hint anyway here, which is the name of the thing that I need to Google in order to understand, which is Berlikamp's factoring algorithm.
All right, so after a bunch of Googling and reading and going, I found this one paper, right?
There's lots of papers on this particular thing, but I found personally this particular paper the most useful, the most straightforward description.
And I provide a link here if you're interested.
It's very short, it's like nine pages.
And it has a worked example, which I always find super useful, like if you actually work through an example.
So to go back to this now, okay, let's look at step one.
So I know, okay, I kind of got a better idea of what this means, what Berlecan's factoring algorithm means because I've read this other paper.
Now let's go back, I'm gonna work on step one.
Step one, B1, ensure that UX is square free.
All right.
What does that mean?
It means we have a polynomial, say, A, which is made of the factors B squared, C, D.
We're pulling out the squared factors.
In this case, B squared is the factor we're pulling out.
So we end up with two things.
A0 is B squared, and A1 is C, D. So those combined back together would be A. That's what we mean.
We're pulling out the stuff that is squared out of here.
So, square-free factorization.
ux has a square factor if the GCD of ux and the derivative of ux is not one.
So, just create steps out of that.
The first is, given some ux, which we're gonna call f, which I call f, get the derivative of f.
Get the GCD of f and the derivative of f, call that g.
So f is made of g times some h, which we don't know yet, but since we know g, we can just say f divided by g is that h.
So fairly straightforward process here, except, which I'll get to in a minute, let's start with an example with a square in it.
So I just create an example, any example, fairly complicated one, enough to sort of know that things are going right or wrong.
In the middle of that, circled at the bottom here, is a squared factor, just so I know what I'm dealing with.
So I'm gonna pull out that square factor manually, so just by hand here.
I know what I want in my A, I know what I want in my B, so I know what's left in my B.
So in testOD, I'm just gonna multiply all these little things here.
left that are left in B together and print out with the results.
So what should I expect from B?
So I already know how to multiply.
We've already done it a bunch of times.
But again, just to sort of sanity test and verify what I'm doing, I keep doing it anyway.
So I multiply all these things back together.
And this is what I get.
For B, I know this is what I want to be.
I verify this by, again, throwing it back into Mathematica and making sure that all the factors are correct.
So after a square-free factorization, I know that these are the two values that I should be getting, which is the A and B here.
The A is the squared value that's pulled out.
So I know what I'm looking for.
But I have a bunch of things that I need to figure out how to do.
So for instance, how would you take the derivative of a polynomial over GF2?
I don't know.
I didn't know at this point.
So let's start there.
So let's just review the regular process really quick.
So we have the derivative of x squared plus x plus 1 with respect to x.
The mechanical process for that is really simple, right?
We multiply each exponent with its coefficient and subtract 1 from each exponent.
We're left with.
2x plus one, fairly straightforward mechanical process.
But over GF2, it's the same mechanical steps, but all the math in GF2 is mod two.
So our two, our two in 2x plus one, the two there is two mod zero, which is zero.
So our derivative of...
x squared plus x plus 1 over GF2 with respect to x is in fact 1, because the 2x becomes 0.
To put a finer point on it, the process for taking the derivative in GF2 is all the coefficients are 0.
That already.
Everything is mod 0.
Everything is mod 2.
All the even exponents will be multiplied by either zero or one to get the coefficient.
The result is that the coefficient of each one of those will either be even or zero.
All even values are zero, so they're all going to be zero.
So we can just mask out all the even exponents, we don't need any of them.
All the odd exponents will be multiplied by zero or one to get a coefficient.
The resulting coefficient is either odd or zero, or all odd values mod two are one.
So we can reduce, we can just reduce all the odd exponents by one, which is the same as saying shift everything right one place.
So in terms of process, this is what it looks like. So we take this particular example. 101111.
We zero out the even exponents because we know those don't matter because anything, those even numbers all multiply by whatever are going to be even.
and all are going to be zero.
So we just zero, just mask those out.
We just shift everything else over one place, and we're left with, in this particular example, x to the fourth plus x to the second plus one, which is as I'd expect.
Which as far as I'm concerned at this point, is just witchcraft.
Like the fact that getting the derivative is so easy and so straightforward is amazing.
So in testOE, I'm just printing out example derivatives just to check, to see that what I'm doing is right, and what makes sense, and what's going on.
So I take this A value, and I print the derivative of it, and it all looks OK.
So the next step, testOF, what do I need to find the greatest common divisor of two polynomials?
Because my next step here is g is the GCD of f and the derivative of f.
So, how do I get the GCD of polynomial over GF2?
Well, in fact, like most things in this process, it's the same as the GCD of any two polynomials, only the coefficient math is in GF2, so everything is mod two.
So, reviewing how to get the GCD, it's basically GCD of A and B is the GCD of B and A mod B.
So we just go through this process.
We do a mod b, and we check to see if it's 0.
And if it's not 0, we just keep going through the loop.
But a mod b presents a problem, because it implies that I need to do polynomial division over GF2, because the mod is just the remainder of the division.
So how do I divide a polynomial over GF2?
Again, it's the same as dividing regular polynomials.
Only coefficient of math is all in GF2.
So if we're going to start with what's how does regular polynomial long division work, right?
We can see here is this particular example. I won't read all of it But starting with how many times is x plus 1 go into x to the third? We just need that first bit here We just say it goes in x squared and so we multiply those out and then we go down the process there But I can visualize that another way and I know lots of people visualize it this way And you just deal with the components and forget about the coefficients and forget about all the variables in this particular case.
Just dealing with the coefficients because it's much easier to read and reason about.
So you can see here.
1, minus 6, 11, and minus 6 are the coefficients of the same as x to the third minus 6x to the second plus 11x minus 6, right?
And 1, 1 there is x plus 1.
So in terms of doing this process, right, how many times does 1, 1 go in, how many times does it need to be multiplied in order to make 1?
It just needs to be multiplied by 1.
We subtract those out.
We get negative 7.
How many times does 1, 1 need to go to be multiplied by to make negative 7?
Is negative 7.
So we multiply those, subtract those out, and we get 18 minus 6.
How many times does that need to be multiplied by 1? 18.
And we subtract those, and we have a remainder.
The same process, right?
But.
In GF2, it's going to be a little bit different.
But if we're looking at the process of polynomial division, we know that we basically need two operations.
We need multiplication and subtraction.
Multiplication we already have.
We already know how to do that.
It's just and.
Subtraction, though, this is the first time I've had to deal with subtraction in this process.
But everything, again, is mod 2.
So 0 minus 0 is 0.
0 minus 1 is minus 1.
Mod 2 is 1.
1 minus 0 is 1, and 1 minus 1 is 0.
So this is our truth table for subtracting coefficients.
In fact, that truth table is exactly the same as the one for addition, which is just XOR.
So subtraction and addition in GF2 are exactly the same, which is super, super interesting and fascinating.
It also means that any code that I write in GF2 will not work in any other finite field definition, because I am guaranteed to screw that up and just use addition or subtraction everywhere.
So, test of.
Now I just want to print out a work example.
So I create this pgf2 div print.
It's a version of the divide algorithm that prints out all the individual steps as it's dividing two values.
So I'm dividing A by B here, and it's exactly in the same format that I showed before.
And part of the reason that format is valuable to me is it's easier to print F, honestly.
So how many times does the right-hand side need to go?
Does it need to be multiplied to the left-hand side just one?
It's always going to be one or zero.
And we just go down and get our result.
But the fact that I can visualize it and look through all the steps and look through any particular example is super helpful part of my process.
And it seems like a lot of these steps where I'm printing out a lot of extra things, I'm printing out a lot of extra steps, you know, is it worth that?
Is it worth me doing?
Inevitably, yes.
Inevitably, it's always worth me going through the extra effort of printing out a formatted version of what I'm working on.
because eventually I'm gonna hit some bug.
Eventually I'm gonna be stuck on something and I'm gonna wanna visualize all the steps and make sure that everything is right or wondering why this one case doesn't work.
It's almost always worth doing.
So in terms of division, this is pretty much what it's doing, which is as you'd expect, as we described.
So we're going through the count.
We're shifting left the quotient by one bit.
We're checking to see if that top bit is set because we're only gonna be multiplying by zero or one.
And if it's set, we're setting, we're adding, setting that one quotient bit at the bottom.
And we're shifting the divisor left to the appropriate amount so that we can subtract and we're subtracting.
And as you can see here at number six, in fact I call add instead of subtract.
So that whole guarantee where I would definitely get things wrong if we're doing anything in not GF2 is definitely true.
But add and subtract are the same in GF2.
All right, so now moving on, test 1.0.
So now I think I have enough parts here to actually get the GCD of two polynomials over GF2.
I have mod, I have all the things, right?
Can I do this?
In fact, so I build this function.
Pgf2 gcd, which just does pretty much this loop, right?
As you expect, looping through, I get the remainder, I check to see if the remainder is zero, if it's done, if it is, I'm done.
If the remainder is one, I'm also done.
If the greatest common divisor is one, the relative prime, so I can bail out here.
And then I just loop it around.
This is a while loop, so I just keep looping around with the, until I'm finished.
So this is, we have all the pieces, I can't test this.
Now I want to make sure that, in fact, it's all good, it's right.
So I get my example here, I print it out, print out the GCD, so everything's printed out.
And then I cut and paste, again, cut and paste my, my f here into Mathematica.
I say polynomial GCD, this value and this value modulus two.
And in fact, the result is the same.
So I can test a bunch of values here, be fairly confident that what I'm doing is correct.
Now I think, now I have, now I have division and multiplication, GCD and derivative.
I think I have all the parts to do square-free factorization.
This, the steps four and five here, just multiplication, division, so we're good there.
I already know how to do that.
So I jump right into creating GF2 SFF, square-free factorization.
And I just print out, test11 just prints out square-free factors.
So I just give it an input value, and it prints out square-free factors here in different formats, different cut-and-pasteable formats.
So starting with binary format and hex format and polynomial format.
And this last one here, SFF A0 and A1, so two versions in hex.
Is this what we expected?
If we go back to test D, so now I'm reaching back to one of the previous tests.
And it's nice for me to have all these tests in a row.
So I keep them all together.
It's not just the same.
It's just not like version-controlled versions of the same file.
I keep them all in a big pile so I can refer back to them like this.
So back in test D, I said, this is what I want to have after square-free factorization.
In fact, these two values are identical.
So I'm fairly confident that I'm getting the right answer here.
Test 12.
Now I want to build the matrix.
Q is ascribed in.
Step B2.
So step B2 here says, form the matrix Q as defined by 11 and 12.
This can be one of two ways, depending on whether or not P is very large as explained below.
Let me talk a little bit about the as explained below part of this.
I definitely felt dumb reading this.
And this is one of those examples where I'm reading it and I just, it's something just I didn't understand, something I just missed something, I just, something is just obscuring my understanding of this description.
And I just didn't get it, right?
I'm reading and reading, I'm just not getting it.
But again, that's where I reach back to that other paper that I mentioned, which sort of helped to clarify what was going on.
But in fact, I'll tell you the real answer here is, I really, really wasn't getting it to the degree where I went to a professor of mathematics at UCLA, and I said, can I just pay you money to tell me what's going on here?
And he said, yes.
And I'll tell you, often, at times, professor of mathematics at your local university will take money.
And he just sat down with me and we sat down for like four or five hours and just worked through all the holes in my understanding.
And totally worth the money, let me tell you.
And that's I think a legitimate way of approaching some problems where I don't know, like, I don't know what I'm missing, I don't know why, I don't understand this.
And just sort of helping me through.
But to summarize the end results here, I'll tell you how hard it was for me to get this.
And I'm sure this is super clear to tons and tons of people.
I'm sure there are millions of people who this was super clear to.
For me, this moment where I could look at this and understand what it was saying was huge and worth hundreds of dollars.
So the building that Q matrix looks like this, which is for I equals zero to the degree of P, and the degree of P is sort of the largest exponent P, where P's are polynomial.
Each row of Q is X to the even power, so I times two mod P, that particular polynomial P that we're building a Q off of.
So, This matrix is, I understand what's happening here, right?
I understand what I'm building, I understand it mechanically, but getting to this point was a huge, long process of understanding.
But in this particular paper, again, this reaches back to the other paper that I mentioned, there's that worked example.
which is super nice.
This is really, really tiny worked example because as often in papers, it's really hard to show a large worked example, but at least there's something.
So given this particular F, this particular polynomial at the top, here is the matrix Q in here.
And this is just print it, that same matrix here, printed out a different way, more tightly, but it's the same values above.
So that's the matrix Q where F is X to the fifth plus X to the fourth plus one.
So in test 12, all I want to do is verify my understanding.
Can I get the same results as that paper?
And I was really, really happy because one, I got the same results, and two, if that paper, if there was a bug in that paper and they printed out something wrong, I would have never, ever understood this because that was literally the only example that I had to work from.
But luckily.
The data in the paper is correct.
I could replicate it and understand what's happening here.
So the matrix is fairly simple.
x to the 0 mod a, right?
So which is just 1, even power.
So 1 mod a.
My a is x to the fifth plus x to the fourth plus 1.
So we just mod with that.
x to the second mod a.
So that's just, again, even power.
So all the even powers of x mod are a, and that's our result.
So test 13.
I want to create a small but simple example to factor and solve.
So I start with two simple irreducible factors.
And I multiply them together.
And all I do in test 13 is actually just multiply them together and print them out.
So it starts with these two irreducible factors, multiply them together.
I call my pgf2mul, which I've now used a bunch of times.
But again, I'm sanity checking.
Get that.
So for test 14, I want to start breaking down B3.
B3 says, triangularize matrix Q minus 1, and a bunch of other things.
But to summarize, what step B3 says?
It says, M is Q minus 1, and find the null basis vectors of M. So I'm going to start with that.
Step 1, Q minus 1.
I'm pretty sure I can do that.
So, in this case, test 14, I'm printing out Q, I, and M.
Q is that matrix I just built, printed out in this example.
I is identity.
I definitely know how to do identity matrix.
And M is Q minus I, so I print those out.
So I'm fairly comfortable with what I'm printing here, and I'm moving on.
Test 15.
All right, bigger problem.
How do I find the null basis vectors of matrix M?
In fact, super, super excellent walkthrough on this particular link, but I totally recommend you reading it if you're at all interested in this particular question, because for me, this really enlightened me, this particular answer to this particular question on math stacking stage.
It's a process much like matrix inverse.
So to summarize the process though, you're augmenting M with the identity matrix of the same size, you're transforming M to row reduced echelon form, and the null basis vectors are whatever's left on, whatever's on the right, when the left side of the augmented form is zero.
It's a fairly straightforward mechanical process.
So to start with.
Step A, in that mechanical process, augment M with identity of the same size.
So it looks like this.
W is just going through each row.
It's taking M, shifting it left by the degree of P, and then inserting the appropriate vector of the identity at that point.
So in test 15, I'm just printing that out.
I create a new print.
So I can print stuff in augmented form, which just means I just put a space in the middle so I can visualize it a little bit better.
So it's just this.
It's the same m on the left and this identity on the right, but it's just this one matrix w with also space in the middle for visualization purposes.
So, now I need a function, I need to get this into row reduced echelon form, which I don't happen to have a handy function for, but I can use, I know I can use Gauss-Jordan elimination.
Super useful description here.
There's also a calculator, there's lots of online calculators online for reference.
This particular one I found useful because it sort of dumped all the steps out as well.
So that as I'm debugging I have something to compare against, which is nice.
Again, going back to worked examples are really nice and really helpful for me in terms of understanding.
So I create this function, pgf2rref, and a function rrefhtml which prints out all the steps and the output so I can visualize it and make sure that what it's doing makes sense.
But to go over Gauss Jordan elimination, gf2, how does that work?
It works exactly the same as if you weren't in gf2 except for all the component math is mod 2.
So in terms of mechanical process, you mark the first row as the next result row, and then you go through a loop.
So you find the first row with the leftmost bit set, and then you swap that in your next result row, you call that your pivot row, and then you subtract that out from all the other rows.
So basically, that's the only one with that particular bit set.
And then you just go through that process, sort of working your way across the bits from left to the right.
And just remembering your add here is in GF2, so it's just XOR.
So output of test 16.
The thing about, so in this particular case, again, printing out in terms of printing everything out, printing everything out in HTML so that I can visualize what's happening here.
So I can, printing it out as it goes, marking the first row, highlighting, and again, it's printing this out in color so that I can see what's going on.
Highlighting the first, the pivot row.
It's highlighting the fact that they're swapping, so highlighting what it's subtracting from here, and then finding the next pivot row, et cetera.
And so going through all the process.
And you can see, I can see it sort of working its way down here.
And in fact, This was super fascinating to me, because I don't think I've, you know, looking at this and looking at 64-bit versions and 120-bit versions and 512-bit versions, I don't think I ever had seen some gigantic actual worked examples, step-by-step of Gauss-Jordan elimination, especially in GF2.
Like, I'd never seen it before.
And being able to visualize it and see it every single step of the way was amazing.
And so I played with this for quite a long time, to be honest.
Until you're done.
And you're left with this matrix M here at the end.
So the result, and remember it's sort of in augmented form, so I just put the space in the middle here.
And I take this, I also print it out, the same matrix in sort of an easy to paste into Mathematica form, which again just throws stuff into my printouts and make it easier to paste into Mathematica.
So, I verify this, I can do a row reduce of that matrix, modulus 2, and verify that the result is the same, and it is, so I'm good with that.
So the next step is to highlight what the null basis vectors are.
What was the point of doing all this?
So those are where the left side of the augmented form is zero.
So I just added, this is just an addition to the debug printing where I just highlighted those.
So here in red, the left side you can see is zero.
So the right side are the null basis vectors, which I then print out here in three different forms, in binary, in hex, and polynomial form.
So now I can sort of go through all the steps.
I can complete all the steps with B4 and apply it to a simple example.
So B4 here.
So calculating the GCD of u of x, which is our f, and that one of those null basis vectors minus s, where s is in the range of zero and p.
Now p, again, this is something that threw me reading this document.
P is the power of the field, the finite field that we're working with.
So p is two in this case.
So it's from where S is from zero to two.
So S is either zero or one.
So we're calculating V minus zero or V minus one.
So for each non-trivial vector V found in B3, and the non-trivial vector is anything that's not one.
One is the trivial version.
We can find non-trivial factors of our original value with GCD of F, so the original F, and V, which is one of those null basis vectors, and GCD of F and V minus one.
So multiplying those two things together will give us our F.
And that's pretty much what this says here.
It's the product of GCD U of X minus S and U of X, where S is in the range of 0 and P, where for our case, P is 2.
So this is just a simpler way of saying that same thing.
So highlighting our null basis vectors from test 17, again, I'm just highlighting the one non-trivial result.
The other one is 1, so we're just throwing that away.
So in test 18, all I'm doing, I can already do GCD.
I can already get my null basis vectors now.
I can do all the things.
So I should just be able to calculate and print, get the GCD of these two values, and verify that multiplying them together gives me my original value back, which it should.
And it does.
So I get that one BV, which I'm calling BV, that one basis vector.
I'm getting the GCD of A, which is my original input.
I didn't print it out there, my original input, and bv plus 0, and gdcd of a, my bv plus 1, which are those two polynomials there.
And now I can say, are these what I'm looking for?
Are these two factors what I'm looking for?
And if I go back to creating a simple example with two irreducible factors, those are, in fact, the same exact two irreducible factors.
So I can compare and say, yes, those are correct.
It looks good.
I solved a really simple example.
Yay.
So, test 19.
So test the process on a larger square-free example, which is this one I created before.
So I had this B, which was square-free, which I created before, which I'm now calling A.
So it's the same as the previous test, same as test 18, but with this particular value.
And so I can print it out, I print out everything, you can see much bigger, print out the highlights and null basis vectors there, I print out the non-trivial result.
the non-trivial results here.
So I'm just throwing out the one already.
I'm just in the function.
I don't have to worry about it.
I'm finding the factors based on those.
And so I'm doing the pair of GCDs here with each one of those basis vectors that I found here.
So each one plus 0 and plus 1, or plus 0 and minus 1.
It doesn't matter, because they're both the same.
So, each pair of these GCDs, you see, can be multiplied together to make the original value.
So, each one of those represents, each pair of those represents a list of factors, right, potential factors.
I can multiply any given pair of them back to the original one, but can I get anything else out of there?
So, I want to get factors that actually multiply together to get A. So, really, all I'm going to do is say, okay, I know.
each one of those pairs multiplies together, but can I get more out of this?
I'm just going to loop through all of them and just divide them out of A until I can get a list.
Maybe I get lucky and I can get some additional factors out of that, right?
So I just divide them all out and see whichever ones divide out evenly.
So from that, in test 1A, I can now print out a list of non-trivial factors of A.
These are all the things that I could find, so I'm comfortable printing that out at this point.
But now I realize that non-trivial factors are not the same as irreducible factors.
So I need to go from non-trivial factors to irreducible factors.
How do I do that?
Well, if I can find non-trivial factors, I can find irreducible factors, because I can just recurse, right?
I just get the non-trivial factors of each one of those until I can't find any more, and then I have an irreducible factor.
And so that's in fact what test 1B does.
For each one of the non-trivial factors, find the non-trivial factors of that until I can't find any more.
That's a pretty straightforward process.
So I'm left with, at the end of 1B, spitting out a list of irreducible factors of F or of A.
And so I look at this.
this list here and I compare it against B, which I created before, and is it what I expected?
And in fact, this list is identical to this list, this list I created here.
B is identical to the list above here of irreducible factors that I found.
So I'm fairly comfortable that I can find that list.
Yay.
Just one scene.
Put all these pieces together and test factor against a larger polynomial with squares in it in the first place.
So if we reach all the way back to creating an example with the square in it, which is the thing that we verified here that had a square in it.
Test 1C really just says call GF2 SFF first, and then for each one of those square factors, each one of the factors that get out of that, do the same process 1B, which is get all the irreducible factors of those, and then just combine everything into a final list.
So this is what I'm left with here.
So I'm left with this list of irreducible factors, which is the same as the one that we expected because we factored it in the first place.
So it all looks good.
But now I need an expanded list of irreducible factors.
So remember, one of those is squared because we pulled it out specifically because it was squared.
So it's this particular value that's squared.
But for my purposes, I want to be able to recombine everything.
So I want to expand this.
So really I'm just going through anything that's squared, anything that has a power, that has a polynomial squared, I'm just going to duplicate it as many times as it's called for.
So that's all that I'm doing in...
test 1Ds, I'm just printing out and duplicating all the expanded factors.
And so that's what this is.
F0, you can see, is the same as F1, hex 67.
And then the rest of them are as you'd as there are some that happen to be B, the section B of that original polynomial.
So going back to the original problem, step all the way back.
Given a polynomial over GF2 to the n, where n is one of those bit depths, display all the pairs of factors of degree less than n divided by 2.
Step one.
Find all the reducible factors of F.
Finally, I feel comfortable that I can do step one at this point.
But luckily, steps two, three, and four are much more straightforward.
So taking all those irreducible factors and just sort of recombining them into pairs that fit into the appropriate bit depth.
So that's all the test 1e does.
It sort of goes through those lists of irreducible factors and recombines them into pairs that fit.
And that's what it outputs here.
That's what it looks like.
So.
Then I get to test 1f.
Test 1f, now I go back to the original test cases and I say, all right, have I even solved the problem?
Am I even solving the correct problem here?
Have I done all the things correctly?
So let's run it against the original test cases to make sure.
So here's test case three.
We now know why there's a third, I now know why it says 32 instead of 64, even though input and output is 64, because it's a multiplication of two 32-bit numbers.
But I run now factoring on that input there, and I get my result here, which is the same as the output in the provided test case.
So I'm good, like I feel very good at this point, and seems to be solving the right problem.
Except.
Sometimes, in the original text, and only sometimes, the results include this sort of what seems like a totally unnecessary factor with one.
Like, it's the thing that made it so that it should have been obvious that it was a factoring problem in the first place, but it seems totally unnecessary.
Obviously, it's going to factor with one.
Why would you even bother to output that?
So when do you include that one?
When do I include that one in the results?
But I'll leave that particular part of the problem as an exercise to the reader.
And end here.
As I said, all this stuff is available on this GitHub page.
Every single one of the tests is there.
This document is there.
You can walk through it.
They all run.
There's a make file.
You can do that.
So you can dig your way through it.
And I'm happy to take any comments on that.
Even pull requests if you wanna keep going with test 2.0.
So that's it, thank you.
