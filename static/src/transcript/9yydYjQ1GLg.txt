All right, everyone.
Hello, and welcome to Designing AI for Competitive Games.
Thank you all for coming out.
We really appreciate it.
So first, I'd like to introduce the two of us.
My name is Derek Neal.
I'm currently the executive producer for Maximum Games.
But in a previous life, I was working for Iron Galaxy on Killer Instinct and the Shadow System, among other things.
With me is Bruce Hales.
He's a software engineer for Iron Galaxy and the architect of the system.
So for those of you that don't know, Killer Instinct is a fighting game, kind of in the veins of tradition set up by Street Fighter and things like that, published by Microsoft and Iron Galaxy has taken over development of the title ever since the season two launch.
So one of the things that we've noticed, I have a long history in fighting games, I worked for Capcom before this, I've been in the competitive fighting game scene, and one of the things that I've noticed just going through this is that...
The AI that's in games often doesn't do a lot to prepare users for online competition.
So I wanna tell you guys a story.
This is Bob.
Bob is a new user of one of these competitive games, in our example, a fighting game.
He goes into the game, he starts playing the single player mode and he loves it.
The AI is fun and interesting, it's challenging.
He learns strategies and tactics to beat it, gets better at the game.
And by the time he's done with that experience, he feels like he's really good at this game.
After all, he can trounce the AI, he gets through it, he's like, I'm ready, I'm gonna go online, I'm gonna play some real people now.
But when Bob goes online and he starts playing against those real people, he quickly finds that it's a totally different world out there.
The kind of game that the human players are playing is just dramatically different from the kind of game that the AI has been playing.
And the strategies and tactics that he's learned that are effective against the AI aren't effective against those human players.
As a result, he winds up getting destroyed, he feels frustrated, and he quits the game.
I'm sure you guys have seen this sort of thing happen before, it's happened to tons of my friends when I've tried to get them into fighting games.
And so, this got us wondering, is this a problem that the AI could help to resolve?
Are there strategies or tactics that we could use in order to make it better?
And so we kind of looked at what are some of the common problems, what are some of the common reasons why this happened.
And by and far, the biggest one is that the AI is fundamentally playing a different kind of game than players are.
Players are guessing and forming strategies and coordinating with each other.
But by and large, the AI has perfect information about the world and is just making decisions in a very, very different way.
So the kinds of strategies that it employs just don't reflect the same kinds of strategies that human players have.
So we've kind of distilled all of these observations down to a handful of topics that we'd like to cover today.
So first of all, the fact that AI fighters traditionally don't have the same limitations players do, things like reaction times and fidelity of input.
They also make decisions in a very different way than players make decisions.
And they don't tend to strategize or socialize the way that players do.
Another thing is that even in AI that's really good, really challenging, really fun, at the time that the game ships, over the course of the game's life cycle, players develop new strategies, they get better at the game, they come up with new tips and tricks, find bugs and exploits.
And as they do that, the way the game is played changes.
But traditional AI doesn't.
Traditional AI remains static, so even something that was a great AI at the time that the game launched might quickly become outmoded or obsolete as players learn more about the game.
So what was our solution to this?
Our solution to this was what we called the shadow system.
And what we're basically doing is crowdsourcing the AI development to our player base.
So we're looking at all the players, all of the things that we're doing, and we're learning behaviors from the players and letting them train the AI that's in the game.
Now the cool thing about these shadow fighters is that they're not superhuman.
They have all the same limitations and restrictions, they make the same mistakes that people do.
They're super easy to train, you can make a functional AI that will do whatever you want it to do in literally minutes.
They learn strategies, tactics, social behaviors even.
They'll disrespect each other, they'll, you know, be cautious or aggressive.
They have personalities that they learn from players.
And the other thing is that because they're learning from the player base all of these behaviors, they also change as players change.
When players learn new combos or develop new strategies, those strategies then get added to the AI's repertoire.
But rather than just talking about this ourselves, we wanted to show you guys the reaction of some of the players that first got a chance to play with the system and when they actually started playing against a Shadow that had been trained off of their own performance.
So I'm going to go ahead and play this video here.
So essentially what Shadows is, it's a system built into the game that I like to compare to Skynet.
It's essentially Terminator in real life.
Okay, I gotta be defensive with him.
That was easy for him.
Damn.
Destroyed me.
And the craziest part about it is as I went further and the computer got smarter, it did exactly what I was going to do at that exact moment.
oh dear nah unlucky guess oh that was sneaky oh shit damn it, no yeah nope get the fuck outta there Oh, oh man. Park. It's getting really fucking close. It is, Mark. This is a very... Oh no! Fuck!
Oh shit. Oh man. Damn. Dude, that's like one hit away. Come on in. Holy shit. Jesus.
Holy shit. Like I had to focus. Like I'm, I was literally, like I had the fight stick and I was like...
Like, I didn't blink.
I was gonna go next door to the Gunners booth and ask them to give me a pair because my eyes were hurting, because I wasn't blinking. I was staring and waiting because I had to- The fucked up part about all of it was I had to think about what I was going to think about before I was gonna think about it.
Like, that's- that's what it felt like. I had to think twice.
Damn you, stop being so defensive!
Oh my god!
Heh.
Oh my god, no.
He's just like me.
Heh heh heh.
I don't think there's a reason for anyone to feel like they are bad at this game.
I think Iron Galaxy and Microsoft are giving everyone the tools that they need to learn this game.
The Shadow Lab has helped me improve my character to some sense because I'm noticing mistakes I be doing that I don't be noticing when I be playing.
They fight me, you know, he's very aggressive.
And this whole Shadow thing works. I love the way it is.
Man, I'm fighting other people's Shadows from around the world.
It is going to change how we play Killer Instinct.
It's going to change how fighting games are developed.
It's going to change how fighting games grow as a community.
It is the coolest thing I've ever seen in my life.
All right, so obviously that guy was pretty excited about the system.
But after we released it, we did do some surveys and things to try and get some ideas of how people were using the system.
We wanted to share some of that data with you.
So first of all, as you can see from the pie chart, most of the people that responded to our survey were more hardcore users, but amongst that demographic, almost 80% of them reported using this mode.
And almost 50% of them said they used this mode regularly.
That compares to only 46% of them who say they actually play the game online.
So more people were actually self-reported using this mode than playing the game online.
The other thing is that the responses from the survey were pretty much all give us more.
We want to see more integration of this.
We want to see more ways to interact with it, more features that use it.
We were inundated by feature requests as opposed to complaints that the AI is terrible or whatever.
So, with that said, we'd actually like to show you guys real quick what it takes to train one of these by training a shadow live in front of you right here, right now, and showing you the process.
So, for that, I'm going to hand control over to Bruce.
As I pick up the controller, the shadow is going to be learning from me.
All right.
So, I'm going to go ahead and set us up so we're in game.
So what we're gonna do is we're gonna train a shadow for you in real time.
So throughout this process, we're gonna incrementally build up a shadow that's able to handle itself in a variety of different situations.
As we record this, I want you to keep in mind that Derek is playing the character in blue.
So we're gonna be looking at the character in blue to basically train the shadow, and then we're gonna see the actions play back on the character in red.
That's gonna show us what the shadow has picked up or learned.
So what I'm going to do is I'm going to go ahead and reload the match, and Derek is going to go ahead and give his shadow examples of being aggressive.
The first thing that Derek is going to do is give his shadow examples of how to be aggressive.
How to do basic attacks, how to do combos, how to approach the enemy and how to move around the screen.
So one thing that's important to keep in mind is that we need to give the shadow data from multiple ranges.
We need to show the shadow how we attack when we're up close, how we attack when we're far away.
and we need to show it examples of how to jump and then do attacks.
So now what we want to do is we want to give it examples of how to basically attack against an opponent that's being a bit more defensive.
So I'm gonna go ahead and take control and start blocking.
The input's dead.
We'll plug it in.
Resume real quick.
Okay, we'll just go ahead and commit this.
So now that we've got some offensive data, basically some examples of being aggressive, we want to go ahead and commit that and see if the shadow is able to pick up on what we were teaching it.
So we can see that the shadow is able to pick up on Derek's basic locomotion, it's able to pick up on some of his combos, it's jumping and attacking.
It's even picking up on some of his standing around when we were kind of, messing up the demo a bit.
So, that's cool, but what happens if we do something that the shadow hasn't seen before?
Like what happens if we jump in and attack it with a kick?
The shadow's never seen this situation, so it doesn't know what to do.
That's not really a problem.
All we have to do is kind of give it an example of what to do in that situation.
So I'm gonna go ahead and reload the match and give Derek an example, a chance to show his shadow what to do in that situation.
So he's just gonna do anti-airs when the shadow jumps in.
Of course, we have to wait for the shadow to cooperate with us because sometimes it's just going to want to attack us.
So now that we've got a couple examples of anti-airs in there, we wanna go ahead and save that out and see again if the shadow was able to pick up on what we were showing it.
So we can see that it's able to understand things like anti-airs and able to pick up on that behavior.
But what happens if we show it another situation that it hasn't seen?
For example, what if we try to do projectile attacks?
So what we're gonna do is we're gonna reload this and I'm gonna give Derek a chance to show his shadow how to throw projectiles.
So now that his shadow has a couple examples of throwing projectiles, we're gonna go ahead and reload it and...
give Derek a chance to...
So this is going to give Derek a chance to basically show his shadow how to react to projectiles, how to jump over projectiles, how to counter projectiles.
So now that we have some of that data, we're going to go ahead and commit that and see if the shadow is able to pick up on that as well.
So now what we have is we have a shadow that basically knows how to defend against projectiles, knows how to defend against anti-airs, and also knows how to attack, attack still.
So basically kind of in just a short amount of time, we've been able to create a shadow that kind of, we could kind of send out and players could fight against a bit.
So what's also cool about this is not just that we've created something that's functional, but we've created something that was also able to capture Derek's style of playing.
So we have something that's able to handle itself in a variety of situations, but also was able to capture Derek's style, which is really powerful.
because that would work for any other player, right?
Every player has a unique style, and this is going to organically pick up on that style without anybody having to come in and sort of ad hoc program that style into it.
So now we're gonna go ahead and dig a bit into how this works.
So.
I'm gonna give a quick overview of the system.
So, I think a really powerful way.
Oh yeah.
I think a really powerful way to think about this is to think about replay data, to think about replay systems that we already have.
So with replay systems, we kind of right now just use them to kind of share experiences with our friends.
So I did something really cool and then I want to send a replay to my friend so my friend can check it out.
But what if we took that replay data that we had and instead of just playing it back, playing back all the replay data, what if we looked at it and we tried to play it back in the right situation?
So for example, in that replay data we could have information recorded about how much health somebody had or what distance they were from the enemy at a certain point in time.
We could use that information to basically jump around in the replay and find the right piece of the replay data to play back at runtime to produce behavior at runtime.
So what we're seeing here is kind of a visualization of that process.
We have basically a bank of a bunch of different replay segments, and the idea is that the shadow is always looking for the best replay segment to play back in context at runtime.
So in this, we're just finding that replay segment, playing it back at runtime, and then the behavior is whatever we get when we play back that part of the replay at runtime.
So a big part of this that actually makes it work is that sequential actions are very important.
So even though we are jumping around in the replay, we're basically, we want to keep playing parts of the replay back that will look right.
So we don't want to just jump around arbitrarily or sort of just if the world state changes just a tiny bit.
Health changes a tiny bit, we don't just want to jump around.
We want to basically continue playing back the current part of the replay until something changes dramatically.
Something changes dramatically, then we'll consider jumping around to a different part of the replay.
This is kind of crazy, but a lot of stuff is captured just by playing back parts of the replay in context.
So lots of what we think about is very complicated or high-level behavior, planning that a player might be doing can be sort of captured indirectly by just playing back things in context at the right time.
So we can kind of see an example of that in this next slide.
This is an example of a player fighting his own shadow.
And it's not really an example of what I would say is like a high-level player.
It's just a player that kind of plays very stylistically.
He jumps around like he doesn't really know what he's doing.
And it's like he's not even trying to kill the enemy.
But what's really cool is you can kind of clearly see that those kind of unique locomotions, they're happening on both the shadow and the player at the same time.
And this is captured just by playing back those pieces of replay in context at the right point in time, and making sure to maintain the sequences.
You would expect maybe that we would see sort of jarring shifts in behavior or something like that, but it actually, in practice, if you do it right, it turns out to look seamless.
So, I want to talk about human limitations.
So, lots of times we tend to ignore human limitations when we're designing traditional AI.
In particular, in fighting games, one thing that we tend to ignore is reaction time.
So the graph up here is basically just a distribution of reaction time.
The data was collected from basically a very simple task where we would show basically a flashing green icon and users had to press a button as fast as possible when the icon flashed green.
So how, what was the response time that it took them to hit the button after it flashed green?
So, hundreds of thousands of users did this, and then we have their data aggregated here.
What this graph is saying is that the vast majority of people have a reaction time somewhere between 200 and 320 milliseconds.
So why this might be important for a fighting game, and in particular Killer Instinct, is because the vast majority of actions in Killer Instinct, the vast majority of things like attacking an opponent or hitting an opponent.
actually hit in less than that amount of time.
So what that means is that a big part of the game, almost half of the game, is not reactable.
And yet when people play the game, it seems like it makes sense.
People feel like they're doing something.
It feels compelling, they're playing it, and they feel like they're in control.
But if the stuff isn't reactable, how is that possible?
Well, it turns out that for non-reactable situations like the situation on the right, the player is basically playing a guessing game.
So you can see the enemy basically doing a pressure string, a string of attacks while you're blocking.
And you have to basically guess when the enemy is going to stop doing, if the enemy is going to stop doing the pressure string or if he's going to continue doing the pressure string.
And that guess lets you know when you should do tiger fury in the middle of the pressure string.
The thing is that you can't react to the enemy stopping the pressure string.
So you have to guess based on the history of fighting this opponent in the match, how aggressive is he, how long is he going to continue the pressure string.
This is kind of what people are talking about when they talk about mind games in a fighting game.
And this kind of mind game, this kind of thing that's happening at the margin of human reaction time doesn't just happen in fighting games.
It happens in other competitive games.
In Counter-Strike, there's lots of headshots that seem impossible, basically.
But then when you look at what's really going on, it's basically high-level players pre-aiming and pre-shooting because they know that their enemy is going to end up in a certain location at a certain point in time.
So, basically, keeping in mind, reaction time is very important in designing these kinds of AIs.
Otherwise, you'll miss out, basically, on all this interesting behavior that players have at those margins of reaction time.
So, Because of the way the shadow system works, because we're just capturing replay data and playing it back in context, we are capturing when players react and when players don't react based on the state of the world.
So that means that if a player doesn't react when, doesn't react in certain situations, doesn't respond to an attack in certain situations, we don't have any data for it, so we never get basically, you know, the instant hit headshot or something like that because we just have what the player did in context.
we get this human limitation just as a consequence of how the system works and records data.
So this is kind of an example from Counter-Strike of sort of what happens when you kind of ignore human limitations, just kind of the traditional example of like an aimbot or something.
So somebody just walks, gets headshot instantly, it's super frustrating.
The way that we traditionally deal with this, right, is we make it less frustrating by adjusting the aim accuracy or randomly dropping shots occasionally or something like that.
And that can work great for difficulty adjustment, but it doesn't capture human limitations in the same way that humans have those limitations.
So like we were saying with pre-aiming, it's possible in Counter-Strike for players to get an impossible shot, I mean a shot that's below reaction time.
But if we just do something like have a difficulty slider, it doesn't capture that aspect of human behavior.
So what we want to talk about now is decision making.
Basically, what is it like when you build an AI with a shadow system versus building an AI with basically traditional methods?
So with the traditional approach, we kind of decide on some stuff that we want to create.
We say, OK, let's make a aggressive AI.
Let's make a defensive AI.
And then we either use some ad hoc solution, or we use a behavior tree, or we use a state machine or something to try to explicitly encode those behaviors that we're interested in creating.
So this stuff works great, obviously.
It's what we always do.
We can get a lot of range and difficulty and everything.
One problem with it is that we're always limited by developer resources.
There's only so much we can do.
We have to decide what things we want to model, and then somebody has to sit down and do them.
And like we've talked about earlier in the introduction, obviously the game continues to evolve after being released.
And if we don't have some solution that's sort of automatic we're not going to be able to keep up with the game after we release it.
This is opposed, as opposed to the shadow system where instead of basically explicitly creating these behaviors, explicitly creating a offensive or a defensive AI, the designer or the developer takes a higher level approach and designs things called similarity functions, weights, and heuristics.
And we'll dig into what each of those are in a second.
So first of all, there's this idea of similarity.
When I was talking about the concept of picking the right part of the replay, I was talking about we need to find something from our bank of replays that is similar to the current situation.
So what similar means is kind of defined by the designer.
So you can imagine kind of a simple Euclidean idea of similarity, where you have two dimensions of health and distance.
And each of those dots in the graph is basically, you can imagine, a replay segment.
So for example, the one that has 100 health and 0.5 distance corresponds to a part of the replay where the enemy's world state was that.
So think of the dot on the far right as being the current as being the current runtime situation, basically.
So what we want to do is we want to find the dot, the replay segment that's closest to that runtime situation, which happens to be the one that is closest to that, that's immediately to the left of it.
Basically, it's up to the designer to say what that means.
In this case, it was just the Euclidean distance.
But it could be just absolute value, or it could be some crazy thing that a designer or developer comes up with.
You just need to come up with some idea of similarity.
So once you've created your similarity metrics for health distance or whatever you're interested in, whatever you're interested in using to compare two different situations, you need to combine all of those similarity metrics to basically get an aggregate score.
So you can imagine that you have things like health, distance, time, or meter, ammo.
Now that you have all these different similarity metrics, how do they matter relative to each other?
Is health more important than ammo?
Is timer more important than distance?
So another role of a designer or developer when using the system is to basically adjust all of these weights so that they have the right relative impact.
So this is something that kind of requires domain expertise.
It requires kind of an intuition for how the system works.
You might just have knowledge because of how well you know the game, that distance is more important than health, for example.
So it's worthwhile to think about how this kind of approach could be used in a different kind of game.
So if we think about something like Counter-Strike, instead of using the traditional difficulty sliders of, okay, maybe I'll fail to hit the enemy every once in a while, or maybe I'll fail to get a headshot every once in a while, what if we track things like visibility, like maybe there's occluding objects on the screen, or how far away the opponent is, or what the relative angle is to the opponent.
If we have all that information being tracked for each of the players and then what they did when the world state, what they did in those different world states, then we can capture things like some players being less sensitive to the angle of the opponent, some players not just having tunnel vision basically.
We can capture that part organically.
So this gives us something that's a bit different than the difficulty slider, right?
It gives us sort of the way that humans fail at this particular task.
Some humans have tunnel vision and they only focus on what's happening right in the center of focus.
And if we record this kind of data, that would allow us to capture that kind of human failing.
So the other piece of the puzzle is heuristics.
So basically, one thing that we want to be able to do with a system like this is allow the shadows to adapt during a match.
So one of the ways that we accomplish this is we basically try to identify trends in a match.
For example, how often is my enemy blocking low versus blocking high?
So you can imagine that we just look at that, create a number that represents the relative ratio of attacking low versus attacking high, and then in addition to other parts of the world state, like health and everything, we record that.
And then what that means is that when we go through the process of finding the best thing to do in the current situation, we can use this heuristic value as well as the other world state value to select it correctly.
So if that value is updating at runtime, we can see, okay, what did I do in a situation where my enemy was blocking low a lot?
And it also works, obviously, for the cases when a player doesn't do anything or isn't even sensitive to that kind of adaptation.
So, for example, if a player ignores the fact that his enemy is blocking low versus blocking high, it'll just record that he does whatever in both situations and it won't really change the outcome at all.
So the last thing that we want to talk about is sort of, we think of as human strategy.
In Killer Instinct, what this means is like high level behaviors like rush down or footsies and zoning and mix ups.
In other games like Counter-Strike, it might mean things like coordinating with your friends like around an objective or something like that.
Like if you're trying to defuse a bomb, you want some of your friends to basically defend you or something.
So the shadow system is able to organically capture a lot of, or in fighting games at least, it's been able to capture basically everything that we think of as a high-level behavior.
I like this video a lot because...
It shows us an example of basically a tournament level player fighting against his shadow.
So this is somebody that's at the top of this game.
He basically, every sort of part of the game that there is to know and exploit, he knows.
He has all these kind of crazy things in his arsenal.
And it's really exciting to see that his shadow basically is able to capture all of that and play it back.
Like, when I look at this, I can't tell the difference really between the shadow and the competitive player.
Even if you guys aren't that familiar with fighting games, it's kind of compelling to look at just the locomotions that are going on.
Just like, it looks kind of like a player is playing.
So I think this is a pretty exciting match, so what I want to do is just let the video play through and let you guys see what happens.
So in this case, the Shadow actually lost, but I mean, it was a pretty close fight, right?
Like, the reason why it was able to put up that close of a fight is that the Shadow really did pick up on basically like, everything that that tournament level player was capable of doing.
So I think it's pretty compelling evidence that basically, Shadows are able of learning these behaviors that we kind of think of as being exclusive to players.
These higher level behaviors like rush down and zoning and footsies in the context of a fighting game.
This is another video I like a lot.
Kind of shows how shadows can capture sort of social behaviors.
In this example, kind of taunt them.
So this is another video of a player fighting his own shadow and it's kind of funny because sometimes players can be assholes in fighting games and this guy is about to get kind of a dose of his own medicine.
So it's worthwhile to think about how this stuff might apply to Counter-Strike or a game besides a fighting game.
So this is just a video of a bot match in Counter-Strike.
And the thing that stands out to me with this is that it's almost like all of these AIs are playing a different game, basically.
They're not really aware of each other, they're not coordinating, they can get in front of each other sometimes.
So, is there something the shadow system could do to maybe help with this?
Obviously we can do a lot of stuff explicitly to make the coordination better, we can hand offer AIs to make the situation better, but how could the shadow system help this kind of a situation?
So kind of like the aiming example, we can think about things that we would track to basically help the shadow be able to identify situations that make sense for coordination.
So you can imagine a situation where in the past, you were kind of at a bomb site or something like that, guarding your friend.
Your friend was defusing the bomb or something and enemies were about to rush in.
If we look at things, like if we record things like the status of the objective, the fact that, you know.
your friend's at the bomb site, your friend's defusing the bomb.
If you record the fact that you're close to your friend that's defusing the bomb, and we record the fact that an enemy's in there, just like all the other stuff that we've seen, we can be able to identify at runtime when we're in a similar situation and pull out the correct part of the replay that basically will allow us to respond appropriately in that situation.
So in this way, just by basically looking at the right factors in the world state, we can kind of get this coordination, not for free, but kind of cheaply, because we don't necessarily have to explicitly design the coordination, we can just sort of capture it indirectly.
So, finally it's worth thinking about this whole metagame aspect.
When we, at the start of the game, despite how much time we spend creating and handcrafting AI and everything like that, a couple of months after release, everything is going to be a lot different than it was initially, because players figure out different strategies.
they figure out things in the game that basically we can never figure out because we have 200 testers, they have hundreds of thousands or millions of testers.
And what that means is that there is behaviors in AI, behaviors that would make sense for AI that we never thought of.
And we don't get a chance to come back to that usually.
It's just too late at that point.
We designed the AI for release, now a couple months after release, it's too late to fix anything or update anything.
So one thing that's nice about something like the shadow system is that it's live.
It continues to change and update as players play the game.
And as a result of that, it's able to sort of stay current and make sense as the minigame evolves.
So with that, I'm going to hand it back off to Derek, and he's going to kind of talk about some sort of future directions for systems like this.
Hello again everyone.
So as Bruce mentioned, I wanna go ahead and talk about some of the possible applications for this.
So as you guys saw, iteration times for a system like this are really short.
Once you have this kind of system in place, it's possible for a designer or content creator to just sit down and record an example of someone throwing a bunch of fireballs in order to create an AI opponent that will run around and throw a bunch of fireballs.
And this can be done in minutes.
This opens a lot of doors to do some pretty interesting things.
So here are some of the ideas we have for things we'd like to inspire you guys to go out and maybe create some things like this.
So first of all, it's really helpful for training, right?
You can pull down shadows of competent, experienced teams, highly rated shadows from good players, that sort of thing, and use them for a training gauntlet.
You can also kind of have a very gradual difficulty ramp going up through those where you have weaker shadows that's like playing against a weaker player.
and then the player goes through the gauntlet and starts playing against better and better players in order to prepare themselves for online competition.
content generation for tutorials very much the same way.
If you want to teach a player how to deal with projectiles, one of the best ways to do that is to make an opponent that throws a bunch of projectiles at him and let him learn how to defeat that opponent.
And you can do that just by having a designer play the game to create those AIs that rush down or throw projectiles or run away that are very aggressive or very defensive or have any number of behaviors that we can basically imagine.
It can also help with single player difficulty, right?
You can start people out in the campaign mode with fighting against opponents who not only play like humans, but are at an appropriate difficulty level for beginner players.
And then slowly, gradually ramp that up.
And you could even pull down from the cloud, from the crowdsourced AI, you could have actual players' data being pulled into your single player mode, forming the bosses and opponents and enemies that now the player is learning to fight against.
Another thing that's really cool with this is self-reflection, giving players the ability to play against themselves, identify what their own weaknesses might be.
Also, if you're online and there's no one else to play against, there's gaps in the matchmaking pool, you can pull down shadows and have players play against them while they're waiting on players to show up.
You could even have players drop in and drop out of matches like that.
So if I see that my friend is playing against my shadow, I could jump in and take over for it and beat him up.
And similarly, if my connection drops or I have to quit the game, my power goes out, whatever, my opponent's experience doesn't have to be interrupted because my shadow could take over for me and could seamlessly pick up and start resuming the fight.
Finally, some stuff that's interesting and kind of theoretical about this, nothing is stopping us from combining replay banks from different players.
So you can kind of create a Frankenstein monster that has the head of one player and the legs of another player by combining data from their matches.
So if you have a bunch of top players in the community and people want to see, you know, what if we had someone with the execution of Justin Wong and the aggressive tendencies of Alex Valle or whoever your famous players are in your communities, you could combine them.
combine those people together and let people play against those kind of mixes.
And then finally, there's potential to have AI-only tournaments.
And these can be running 24-7.
Players could bet on them, wager on them, or train up their own shadows in order to enter them into these tournaments for prizes.
So these are just some ideas that we had of things that could be done with this system.
And we're really excited to see what ideas you guys come up with to do with something like this.
So of course another thing that I'd like to mention is that it wasn't just Bruce and I that was working on this.
There was a great team at Iron Galaxy supporting and helping us develop this.
We want to give a shout out to all of those guys, many of whom are in the front row up here right now, and just say thank you so much for all of your help and support.
We couldn't have done it without you.
Uh.
Ha ha.
Ha ha.
Ha ha.
Ha ha.
Ha ha.
Ha ha.
Ha ha.
Ha ha.
Ha ha.
Ha ha.
So with that, we're happy to take questions if anyone has any.
Hi, how did you decide how many actions to keep track of for each, I guess, data sample?
Are you unifying them, or is it a certain amount of time or number of actions?
For each data sample?
For each data, so you know that the player saw some situation, and they did a couple of moves.
They did three, four moves, or they only did one move.
They just jumped.
And how do you decide how much of that to store and replay back for that particular scenario?
Yeah, so we didn't decide.
So basically, it seems kind of terrible, but you can have 90% of the data could be locomotions or something like that, for example.
We aren't doing anything where we basically look at.
The fact that you have a bunch of strings of locomotion, so we start to compress it by throwing out a bunch of them or anything like that.
One of the reasons that we don't do that is it starts making it so that we have to do more explicit modeling.
So in the case of locomotions, it seems like it might be simple.
But lots of times, if you're doing a locomotion, are you engaging in some sort of high level play or plan or something like that?
Are you staying carefully out of range, playing footsies with the enemy?
So because we didn't want to do that explicit modeling, it sort of just captures everything.
Another reason for this is kind of just the whole idea of just playing back whole parts of a replay.
Because things like the exact frame timing of things are so important for correct execution of combos and stuff like that, compressing together multiple sequences into the same sequences poses certain challenges.
Not that it's impossible or anything like that, but there were worries that we had that made it so that we didn't do it.
So just real quick, when do you stop then?
Because you don't play back the whole match.
Let's say you play back five moves, and when do you switch to some other situation?
Oh, OK.
I see what you're saying.
I see what you're saying.
So you can imagine that there is a certain weight given to the current situation.
So we're calculating a score, basically, of the current situation for the current plan compared to all the other things that you could be doing at the moment.
Obviously, there's lots of situations.
In our specific game, there's lots of situations where you just don't want to interrupt anything.
But where you're in a situation where you might want to interrupt kind of your current plan, it's just sort of a weight comparison against the score of the different possibilities that you might be interested in.
Testing.
Testing.
Yeah.
I think it was on.
Does that answer the question?
Yeah.
I think.
So, A, are you aware of salty bets?
Yes.
Okay.
And B, do you envision not having to ever go back to zero now that you have all of this data that is on this title, but basically you now have your encyclopedia for the next title, and what points do you think that you'd actually have to hard reset in order to clear the slate, and how much is that?
Coloring is is that positive or negative that you're going to have to worry about for future titles?
Yeah We kind of are worrying about this right now just because our we have a game that kind of has lots of game balance patches So the way that we are handling it is maybe not ideal, but basically, shadows kind of prefer data that they've done recently.
So if we throw out another patch, and some stuff is kind of gameplay breaking, so some setups and some combos don't work anymore.
It's almost like your shadow will sort of stop using them because you'll still be playing the game and showing your shadow examples of how to do things the right way.
So over time, sort of the old bad data will get pushed out, and the new fresh data will get pushed in.
There's weaknesses with that approach, obviously, but it's what we're working with right now.
Hey man, how do you handle asymmetry?
So for example, all the examples you had was a character training against itself.
So how do you train against different characters?
So that's a really good question.
So with the way the system is currently set up, All the data is recorded specifically per matchup.
So that means that the data that you have in a Jago versus Jago situation is specific to the Jago versus Jago situation.
And the data that you have in a Jago versus Orchid situation is specific for that situation.
So that doesn't mean that data doesn't translate at all.
It's just something that we've done to be able to better capture very match-up-specific behaviors that players do.
That being said, we have an onboarding experience where you fight basically against Dojo Master Jago.
And he only has data fighting against another Jago player.
players, when they're starting out a Shadow of any type, play against him.
And he more or less works.
He's still able to play competently and everything like that.
It's just that he doesn't have specific strategies against all the different matchups.
Hey, can you talk a little bit about the size of data that represents a Shadow?
Yeah, so probably from each match, you can get around.
up to, say, 800 different events or something like that.
And we probably, in aggregate, have somewhere between 20,000 to 40,000 events that we're considering per shadow when it's running live.
So in the grand scheme of things, maybe not that large.
Thank you.
So you talked a little bit about how it kind of learns and it scales up as you get better, and it kind of keeps you getting better.
But as a player, what if you are, for example, testing out a new shadow, and it already knows how to fight that shadow.
But let's say your friend is playing, and they're not very good.
Is it able to scale down as well?
Yeah, so if you do something like give the controller to your mom or something like that, or put the controller down and walk away.
you're going to hurt your shadow a bit, basically.
So it will even pick up things like standing around, or just jumping around, or just doing crazy things, basically.
Like, you can just go on live and encounter a shadow that just does nothing but run away from you and jump.
So.
There's a question there of, should we detect these bad shadows and throw them away?
But right now, we're not doing any of that, and we're not trying to say, oh, is this good data, or do we want to throw out this data?
Basically, the players control over the process.
At the end of a match, a player can say, OK, I want to keep this data, or I don't want to keep this data.
So it's sort of a player's decision if they want to save the game when their mom played it or something like that.
Okay, so basically you get the choice of whether or not you keep what you currently tested with and fought the shadow with, or you can choose something else later, so that way if you wanted to keep your mom's play session against the shadow, you could keep that simpler AI versus something maybe where you're more skilled.
Yeah, just to be clear about the process, right now it's only additive.
So you can't go back and then just pick these three replays in the past, even though that's technically possible.
The interface doesn't allow for that.
It's just after you record a match, you can say, do I want to append this to my shadow data, essentially.
OK, OK.
Thank you.
What's the performance hit doing all those, I guess, lookups or whatever the mechanism is versus a traditional behavior tree or something else?
It's probably going to be very dependent on how large that behavior tree and everything is, but in this particular case for our system, it's running in under a millisecond in Xbox One, even when there are, say, a fully trained shadow, like a mature shadow that has 20,000 to 40,000 or whatever different things that it's considering at a time.
Maybe not something that's possible when you have 40 shadows running, unless it's very highly optimized.
But I think it's definitely possible to, if it's something that you really, if you really want to use this with a bunch of characters, I think you can get it to run fast.
I think it's cheaper than doing like animation sampling, for example.
Thank you.
Cool.
So I'm going to get a little mathy.
So I was curious if the choice of the best move, whether it was the best move or was it probabilistic, so that you had a little bit of randomness.
What was your choice there?
Yeah.
So basically, you calculate all these scores for all the replay segments that you have.
And then you can imagine like you have a sorted list of scores, right?
So there's a question of if I have something where, say I have a situation where I have two scores that have the value zero.
Or I have a bunch of scores that are just sort of different by very, very small amounts.
Do I want to just sort of pick the one that maybe is kind of by accident the smallest score?
Or do I want to sort of randomly select between them?
So what we do basically is we, we basically find the smallest score, the best score, and then we sort of pick randomly from a neighborhood around that score.
So you could imagine that everything that's within 10% of that best score is kind of fair game.
And then, as an aside, the score itself, I think you said it wasn't like a Euclidean distance.
You just added up all the individual scores.
Is there a reason why you went with that instead of like a traditional Euclidean distance?
When I was saying Euclidean, I just meant for that.
just thinking about it as like Euclidean distance.
But there's no reason behind that.
The reason why we're doing this stuff this way is kind of just borrowing.
If you want to look up more about the people that sort of did this stuff for real, search for instance-based learning or case-based reasoning.
It's something people have been doing for 40 years, but just hasn't really, I guess, found its way that much into games.
Bye.
Yeah, if you dig into that, then you can actually see what the technical definition of similarity is and stuff like that, and whether or not it's a real metric and that kind of thing.
Yeah, in machine learning, you usually end up picking just the squared distance instead, because that's typically an L2 thing.
Yeah, yeah, yeah.
Cool, thanks.
Hi.
For games of sort of a different nature, say a card game, where your game state is less continuous and it's more discrete but with a lot more different actions, would you suggest using the shadow system to develop an AI?
Or is your data going to be too sparse because of the number of unique scenarios you get into?
And would you rather do, would you suggest something more like a simple min-maxing over optimal game states?
Yeah, I guess I don't really have, maybe Derek has a better intuition.
Yeah, so I definitely think this approach could be used to do a card game.
But because in most card games, the number of options that are available to the player is relatively small, it's not too hard to simulate forward like a large number of turns or something and could then compare those.
So because the space that you're dealing with is pretty small, I think it's probably unnecessary.
but you could definitely get something like this working in a card game if there were traits about personality that your card game might capture.
So where it would be most useful is if different players had different options that would show them as being aggressively bluffing or something like that, or being very conservative or very defensive.
Then a system like this could help capture those behaviors that might be hard to, you'd otherwise have to do some explicit modeling to try and create different types of AIs that play that way.
But if all you're interested in is in getting an opponent in a card game that plays kind of well, I think it's probably good enough to just do a search tree and find a good resulting board state and then go with that line of play.
Thanks.
Thank you for the talk, it's very informative.
It's kind of a two-part question.
The first one is you mentioned significant situations that get captured and then you capture the behavior at that point.
How do you define what a significant change is?
Are there numeric sliders for each metric, like angle of view or distance, or is it some other more specifically programmatic process?
So it's a fully manual process where you have to rely on the intuition of somebody that's really familiar with the game.
Derek is basically an ex-tournament player, and he was the design guy on this.
So he knew, oh, we should probably be tracking distance or something like that.
Yeah, so what we wound up doing was actually setting values for each of the different states that constituted a big divergence, right?
So for example, not everything that we track is a numerical metric.
So for example, we have the current player state.
Is he standing up or is he knocked down, right?
And so the weight that's associated with those is very high.
And then we bias, the way we continue playing back a sequence of actions is we add a bias to the next action that's in sequence.
And so when the deviation in those other metrics based on their weights is bigger than that bias, then it will naturally break and cause it to select a different action.
Okay, thank you.
And the other one, do you think there's like a market for gamers of all levels, amateur, intermediate, pro, super expert, to become kind of pseudo developers in that they'll play the game and the game AI when it's launched will just mimic the behavior of them?
So it's like you're playing as a real human.
Yeah, not only that, I think there's potential for players to use tools like this to create community tutorials, to create community training content or challenges, things like that, where they could deliberately train an AI that has certain behavior, and then that could go out as a challenge for other players to play.
So I think there is a lot of potential for the community to develop content using systems like this.
Yeah, so right now, obviously, it's kind of just a process where we're sort of doing it almost in the background for them, but it could be a more sort of driven process where we could prompt players to do specific activities at a certain point in time, and basically do things that would help us curate the shadows a lot better.
Thank you.
How do you handle strategies at different time scales?
So you might decide, for the next minute, I really need to focus on attacking this one guy.
But then during that minute, you're going to switch tactics depending on what they're doing.
Right, right, so most of that is captured by heuristics.
So for example, somebody that has a lot of insight into the game like Derek can say, okay, something that's important for my shadow to keep in mind throughout the course of a match is how often my opponent is blocking high versus low, or how often he's doing reversals on wake up.
So you come up with this heuristic and basically just a way of tracking fluctuating value throughout a match and recording it.
in addition to all the other world saves I've done.
OK, so you're never combining different replays.
So when you switch to a new replay, it doesn't remember what it was replaying before.
So it doesn't remember what it was replaying before, but it remembers the heuristic summaries of what's been going on in the match.
So that's how it keeps track of the higher-level strategy.
Yeah, which includes what it's been doing before.
So it knows how many fireballs it's thrown because it's keeping track of basically a fireball count as part of the world state.
And it knows that when the fireball count is high, you tend to do these kinds of actions.
Or when the fireball count is low, you tend to do these kinds of actions.
So if it's done a lot of actions in the past that are fireballs, and the player has a habit where he tends to throw a bunch and then rush in, it'll know that history of it's already thrown a lot of fireballs.
And so it will tend to pick actions that were done in that state, like running forward and rushing in.
OK, so you kind of have to know what likely things that people are going to want to keep track of so you can create that world state.
Yeah, yeah, yeah, you definitely need somebody that has a lot of intuition in the game.
With a large enough data set, it might be possible to identify some of those things programmatically.
Like you might be able to have some kind of algorithm that is able to identify those trends rather than having a designer specify them.
But for this specific implementation, I specified those heuristics basically.
All right, thank you.
Do you think of something inherent to fighting games that makes a system like this viable, like presently, but would make it not viable for something with a crazy possibility space like RTS, MOBA, et cetera?
I think that elements of it could be used sort of without great difficulty kind of in any kind of game.
I don't think, so Derek and I might, I think Derek and I actually disagree on this.
I think it would be very challenging, if not impossible, to just take this thing and kind of just get it working in an RTS without a ton of effort.
That being said, I do think you could do something like use this maybe just for the high-level strategy selection, or use it for maybe just sort of reactive movements in a MOBA or something like that.
At least if you were going to go ahead and trying to do it, like with a game that has to ship that's like a MOBA or something like that, I think that I, to be on the safe side, would try to sort of target small pieces of the game like that instead of trying to just use it for everything.
I don't know if you have anything to say about that.
Like Bruce said, I don't actually agree. I think that it's a comparable task personally to implementing it in a MOBA or an RTS or something like that.
But as Bruce said, use it at your own risk.
Thank you.
Hi.
So if I understood correctly, you're actually not doing any kind of utility function for this.
You're just taking replays, and you're not really caring too much about the outcome of those options when evaluating the choices available to shadow, right?
We're not doing any what?
utility function. Basically, just comparing the result and seeing, okay, so this combo chain dealt a lot more damage, therefore it's useful, or it led to a knockout, so it's going to leave me in a good spot, things like that.
Yeah, you're correct.
We're not doing anything like that.
I think it's definitely, once you have this data, you definitely could do things like that.
You definitely could say, OK, we want to make shadows that are like the player, but we're going to throw out a lot of the stupid things that players do just so it's a better version of the player or something like that.
And I can definitely see adding in sort of a.
things to, you know, oh, that combo does really low damage, so we're just gonna throw it out.
Or once you do this certain sequence of actions, it always leads to your shadow getting hit, so we throw out that sequence of actions.
I think that's definitely something that you could do if you have this data, it's just not something that we're doing at the moment.
Yeah, I'd also just like to point out that it's a very common technique in AI development to kind of forward simulate, look at the ending state, and then assign it a score and say, was this a good result or a bad result, right, and so do I want to do this?
One of the reasons we really don't want to do that is because we're not interested, at least in this case, in creating perfect play, right?
We don't want the best result.
We want the most human result, which is kind of by definition, whatever a human did in this circumstance, right?
So at least for our implementation here, I think it's better for us to just play back what the people did, rather than trying to figure out what would have been a better thing than what they did to do in this situation.
All right.
All right, thank you.
All right, thanks.
Thanks for coming, everyone.
