Hello. All right, everyone. My clock shows 3.30, so I'm not going to waste anyone's time, and I'll just go ahead and get started.
So I wanted to start out and thank everyone for coming.
I know that capturing reference is not the sexiest topic in game development, so I'm really appreciative of you guys for coming.
So as my slide indicates here, my topic today is about our reference gathering techniques for Forza Motorsport.
And in particular, I'm going to focus on some of our best practices around taking environment reference, so how we source a lot of the tracks in our game.
Okay, so just as a quick background, Turn 10 Studios, which is the studio I work at, is one of the first party Microsoft studios.
So, our mission, if you don't know, is to help create Xbox games that sell our consoles, to be frank.
And so, our particular studio was formed to create racing titles, and so that is...
my destiny in life.
And so, you can see here some of the titles that we've created so far.
And so, on the left you see Forza's one through four that were created for the original Xbox and Xbox 360.
And hopefully it's not a big surprise to you that our latest project was Forza Motorsport 5, which shipped as a launch title on the Xbox One last holiday.
So a little background about myself.
I left Disney Animation after over 10 years and I joined Turn 10 at the beginning of production on Forza Motorsport 4, so it was about four years ago.
And I operate as the technical art director there.
Okay, so for folks who aren't familiar that much with our title, I thought I would play a quick clip to introduce our game and give you a sense for the scale and the kind of content quality that we try and attain. ♪♪ ♪♪ ♪♪ ♪♪ All right, that was a condensed from our launch trailer.
So that was just a 30 second taste of what we have going on in the game.
And if you like it, buy more.
All right, so what am I going to talk about?
I wanted to kind of intro the topic.
The Forza Motorsport environments that we build mostly represent real world tracks.
And by real world, I mean they exist in the real world.
And so we're trying to model after some reality that's there.
We also have a handful of fictional circuits.
So those are circuits that exist in like a certain real life environment or motif.
And so for our latest project, Prague was our cover track.
And so we went to the city, there's no race track through the middle of the city, and so we kind of had to invent some circuit through it.
And so it was a little imaginary and piecing together this and that to try and build something that would make a compelling race course.
So all of us in this room, when we're creating 3D art content, hopefully you guys know that we have to create environments and worlds from thin air into 3D.
And so, like in our game, there's a lot of real world environments, and there's a lot of imaginary environments that you might have to build.
And so I hope some of these techniques you'll find applicable to the specific titles that you're working on.
So, no matter where we work in games or film, we have to build these worlds with textures and polygons.
Those are the tools at our disposal.
So anything that we can do to author those textures and polygons faster is going to result in cheaper budgets, more content, and just general...
fairy dust feelings, I guess, from everyone involved in the production of the game.
So, at Turn 10, when we sat down to imagine this new project that we were going to be embarking on, Forza 5, it was for the launch of a new console generation, and we knew that there was going to be some huge content demands, and that we were going to have to push it further than we'd ever pushed it before.
So, as we started investigating our processes, we kind of became convinced that the solid reference gathering techniques were the beginning or the foundation of creating content more quickly and accurately.
So, also just to be clear, reference gathering is the process of trying to document an environment or capture everything you can about a certain place so that your environment team can create those results in 3D, so that's gonna be the main topic of my talk today.
Alright, so quick agenda.
This is one of the few bulleted slides I have on here.
So what I'm gonna talk about today is, I'm first gonna describe the old school ways.
So how we used to gather reference.
And then I'm gonna quickly switch to some of our newer techniques.
So I'll introduce you to our hot new texture action.
I'll talk about some spherical video things that we played with and used in the production of the game.
I'm gonna talk about laser scanning.
And then finally, a few quick words on why we feel like this is important and hopefully you can get something out of it as well.
Okay, so when I first joined Turn 10, the team wanted to send me out on a reference gathering trip just so I could see what it was going to be like. So a few weeks after I started, I went on a trip to the Indianapolis Motor Speedway.
And so, there, we were starting from scratch the process of building a new track.
So, what is the absolute minimum that you need to capture reference for a 3D environment that you're trying to build?
It's photos.
And so photo reference is a pretty standard practice in reference gathering.
And so like many other studios, we will send a whole team of three or four artists out to the track.
And we will arm them with cameras and set them loose on the track.
And we have a spec that we follow.
So here's the specific things to take pictures of.
And we will go to that track.
So like many artists with cameras, we unfortunately get more than a few photos that end up looking like this.
But in reality, we actually end up with tens of thousands of photos on each trip.
So, we have all these photos that are scattered all over the place and it's really daunting, right?
We bring the photos back and then the artist sits down and opens this directory and it's like, here's five million pictures for me to sift through.
And how do I piece that back into an environment that I can actually build?
So what's missing from this is context.
You don't know where a particular photo is in relation to something else.
And to just take a folder like this and expect a team to build a 3D environment is asking way too much.
So, on our Indy trip, one of my particular responsibilities was to go around and take pictures of buildings.
So, it all made sense to me when I was there, because I was in the physical location.
So, I walked around, I'm like, hey, I see a building, let me take a picture of it.
And so, I'd go off and take pictures of buildings.
Then when I got back, to my dismay, I had rolls of pictures that looked like this.
So, this is a program building.
So, where is that on the track?
Nobody knows, so people would place it randomly.
So, what we found is that there's a big disconnect to being at a place and using our human brain skills to kind of process exactly where you are and to get that feel.
And there's that big disconnect to a whole directory full of images.
And so, the poor person that's on the other end of this, who wasn't there, it's tough for them to get some context about what this picture actually represents.
Here's another building that has awesome smoked turkey legs.
And so, where is this building in relation to anything else?
So, to add context to these photos, what you really need is videos as well.
So luckily that was part of our reference gathering spec.
So we also went around and shot videos.
And so we had some kind of method to the madness.
So part of our reference spec was to go around and mount a video camera or a DSLR that had video capabilities.
and kind of drive the whole circuit of the track and then take 45 degree increments.
So we would go around once with the camera facing forward, then 45 degrees right, left, 90 degrees, and so forth.
And so the poor artists back at home.
end up with something like this.
So at Indy, before I play this video, instead of giving us an awesome Indy car for us to cruise around and take videos of, they provided us with golf carts because they have a golf course that's part of the track.
And so we got these, each one of us got an awesome golf cart to race around.
Each one of these took 15 minutes to get around the whole circuit.
So, to capture all the angles that we wanted for our video specs requires eight drives around the track and it was fatiguing both to us as the driver and as the artist back at home who was trying to witness this.
So, this is some of the awesome action you get.
So, when you're an artist back at home and you're trying to build, like, this track, and you see, hey, there's a truck in the left. Oh, wait, now I passed it, so I don't know what it looks like.
Then you've got to go to the 45 degree or the 90 degree left one and kind of, like, get motion sickness and see this. And so, this was our video spec. This is what was happening as part of the thing.
So also, so photos and videos are kind of a given.
So to bolster some of our high-tech credness, we also lugged around some other digital tools.
So this is a digital level where we can go around the track and you place it down and it tells you how many degrees the track has of camber.
And so that's like the angle of the track for car optimal performance.
So this is me diligently marking in my journal the measurements coming around turn two of the Indy Speedway.
And what we would do is we would have to go to several different spots along that line because the camber changes actually as you go from the inner part to the outer part.
And then you'd march down another like 10, 20 feet or so, and then do another thing.
And then so I'm making little X's on my map and saying like 4.1 degrees.
And then someone at home would have to kind of process that.
So on foot, this took freaking forever.
So it sucks.
Alright, so the last part of our reference gathering spec was GPS.
So, this is our track production lead, Trevor, and he's walking around with his nerdy GPS backpack.
And so, he had to walk this entire two and a half miles of Indy Speedway.
on every edge that you can see.
So here he is on the inner portion of the track for F1, and he would walk down this line and take GPS measurements, and then he'd walk to the other side and take GPS measurements, and then if he had extra time, he would say, oh, there's a lamp post there, I should probably snap that.
And so at the end of that whole process, If you have a good satellite signal and you have a good pair of walking shoes, you end up with something like this.
So this is our 3D map of the Indy Speedway and you can see every single footstep that he took and kind of the measurements and the guides that we have to build this.
So, that is a summary of our old school ways.
When we come home from the reference trip, we would take these photos, the videos, GPS data, all that stuff, and we would just hand it over to our environment team.
And this poor team of like, you know, tens to hundreds of people have to like, really take this and puzzle it back together and figure out like, what exactly is what?
And so, they download internet images, and like poke around, and then like, come by and ask like, you know, this port-a-potty that you took a picture of, like, where is it?
I don't know, like watch my bouncy, crappy video.
So, it's actually amazing that we ended up shipping our game at all.
So, some of the questions that we found ourselves is, how can anyone tell what's happening with this reference that we're gathering?
Second question is, how do we even manage to build anything out of all this stuff that we come back with?
And the biggest question of all is, what if we miss something?
So, just to touch on that real quickly, when we started our process for Forza 5, we knew that no matter how complete you try to be with these old reference techniques, there's always something that you're going to miss.
So, if you have a picture of an alleyway, and there's something down there, and you're like, well, we're going to drive by it, but what's down that alley?
perhaps nobody took a picture right there. Or like there's a building, what's behind that building because we actually have to build it. I don't know, just make something up. So as we settled on Prague as our reference or as our kind of cover track for the game, we started planning our reference needs and creating a new plan for the trip.
So, since we are going to be traveling a particularly long distance, so here's us going from the Seattle area to Prague, we thought it would be really important to our studio management and executives that we plan a complete coverage spec, because the worst thing that you can do is say, oh, we forgot something, can you send us back to Prague, despite the deep pockets of a corporation like Microsoft.
Okay, so how did we arrive at a situation where we tried to consider our reference gathering techniques because as I mentioned before, it's not a sexy part of track production.
And when you say, well we have to build all these environments, it's not the immediate thing that you jump to.
So this is kind of a breakdown.
The TechArt team did some data mining after Forza 4 and we're like, well what sucks about building our environments?
And so I took some key figures off this.
But here you can kind of get a sense for this pie chart of where exactly we spend our time.
So, building this detailed environment actually takes a lot of man time.
And so, when we sat down to plot out what takes the longest, starting from the beginning of the very pre-production-ish kind of stage, we were surprised to find that the process of laying out the shape and creating all these rough objects actually took a really long time combined.
So what you see here is there's two areas in particular.
There's this course phase, which is our process for taking those GPS splines and kind of laying out a road surface so that we can see what the driving area feels like.
And then this rough phase at the bottom in.
in the right-hand corner here.
That's the process for taking blocks of white box objects, I guess, and saying, like, here's some trees, here's a building that lives here.
And so you can see those two added together actually take almost as much time, or about as much time, as our refine stage, which is where we're actually building out all the content and making sure it goes properly.
So we attributed a lot of this kind of get up and running kind of time.
to artists having to puzzle these reference pieces back together.
You know, like, we can't take all these reference images and everything back to the studio and then have them start building stuff and then like, you know, the first week we have some awesome drivable surface.
It takes a lot of time to process all the data and to organize it and everything.
So we were like, our general inability to quickly get up and running is really restricted by the kind of reference that we're coming back with, even for real life tracks.
So, we rolled up our sleeves at the beginning of Forza 5, and we knew that we were targeting this much more content, and we decided to design an updated way to gather reference, which was the fundamental source of our content production going forward.
So, what I'm gonna cover for the rest of the slide deck is how we've evolved our reference techniques, how we do things right now, and hopefully give you some insights that you can take away.
Okay, so, photo reference.
I just want to note, we still take photos as part of our reference gathering, but we do it a lot smarter, and I'm gonna jump into some details on that.
Second point is, inspired by Henry Labona, who used to work at EA and moved over to Microsoft for a bit, in particular, he gave a GDC 2011 talk called Art Direction Tools for Photoreal Games.
And in that talk he talked about some of the reference gathering and texture capture that goes into making video games.
And we discovered that the way we were taking photographic reference was honestly stupid.
And then the third point is that, you may have heard at GDC here, a lot of discussion about next-gen pipelines being based on a physically based model.
And so that includes material and lighting. A lot of next-gen pipelines are moving to that and a lot of the stuff at the tail end of that.
Xbox 360 and PlayStation 3 generation were kind of headed towards this direction anyways.
And physically based model means that you're modeling all your lighting and your material system using mathematical formulas instead of just squinting and eyeing it and saying that's about the right color.
So one of the critical pieces of that pipeline is if you don't feed in good stuff, then you're gonna get crap out as well.
Okay, so I'm gonna talk a little about our photo reference gathering techniques.
So what is notable about this particular photo up here, except for the awesome fact that Prague has a hippies festival that has its own website?
The awesome thing is this little guy right here.
So this piece of tech is a portable Macbeth chart.
So a Macbeth chart is something that has been used by professional photographers and cinematographers to calibrate color for years now.
So this chart is a swatch of 24 bits of color that have known RGB values.
And so our reference team will lug one of these around, each guy gets one, and we try and stick it into every picture that we take on our reference trips.
So how does this help us?
So, this color checker tool, it comes with this pretty awesome software that automatically detects the chart in the presence of the photos that you have, and it matches the colors that you have against the known RGB values. So, because they can calculate the deviation between the actual known colors and what it's actually showing up in your camera, it allows you to create a custom color profile.
for your camera and the shooting conditions at the time of your reference gathering.
So if you keep a fixed exposure, and ISO settings and everything, and then you just say like, from this time to this time, I was using this particular set of settings, you can create a camera profile that automatically color corrects for the environment that you're working in.
So how does that color calibration work?
So, with that profile, you can plug it into a tool like Adobe Bridge, and so when you pull in Adobe Bridge, we have outlined here, where you assign the camera profile.
So, when you assign this, it color corrects your image, and you can batch do a bunch of these at the same time.
And this ensures that the colors that we're feeding into our physically based system are actually correct and at a known good standard, which is really important, as I mentioned before.
So, the other thing we can do with this chart that we have is get some white balance accuracy.
So, on the left side of the chart that you see in the picture here, we have varying shades of white to black.
And so, you can just color sample the white part and the black part, which are different from the color calibration.
And you can set a good white balance and a black balance so that you ensure kind of like that your values are in a good range.
And so we try to do this for every photo that we're going to be using for a reference, and then we save it that way and commit it into our repository, so that anyone that's trying to take a swatch of this is already working at a known good kind of stance.
So here's a quick example of what this can do for us.
So we actually took a couple pictures at a racetrack with varied exposure, just so we can see as part of our testing as we're leading up to reference gathering.
So on the top, you see image number 7336.
We took it at a low exposure.
And then later on, we fumbled around with the exposure settings, and then we get the one on the bottom.
So this is before.
Then after the process, you end up with the pictures on the right.
And it's to a known good value.
So no matter what circumstances you were trying to take the picture in, because we are capturing raw images, we can adjust the exposure and the white balance and all that afterwards.
And then we end up with a known good target.
One final thing I wanted to mention is, because we have this increasing reliance on a physically-based material model, where almost all the lighting and material calculations are done with mathematical formulas that are meant to mimic the physical world, it's especially important that these images and the values are correct.
So, if you don't put in the right stuff, then you end up with colors gone wild.
And we've actually seen that on past projects, where if we adjust exposure or bloom on something, something will unrealistically blow out.
And we've always had to go in and kind of like mess around with the texture and be like, is it too white? Is it too high of value?
And so, this is an image of...
one of our environment artists took a bunch of known things that occur pretty frequently on racetracks, and he kind of dialed in the appropriate value numbers that each one should be in, in an approximate range.
And so this way, if you take this image, this is a 32-bit image, and you start adjusting exposure, the stuff that you expect to blow out when exposure is high is gonna get that.
And that's kind of key to feeding our material and lighting pipeline.
I just wanted to call out real quickly, I don't have a slide for this, but Nick Sagal, our rendering engineer, is giving a talk about the material and lighting pipeline for Forza 5 tomorrow at 2.30.
So you should attend that if you're interested to see how all this reference gets fed in a little bit later.
Okay, so that's reference images.
That's kind of where we've evolved our pipeline.
And the images are at least a lot better quality and to a known circumstance, even though we still don't know where the heck anything is.
So remember this crappy video from Indianapolis?
The still video is boring to watch, and the field of view really limits what you're able to see.
So we thought to ourselves, wouldn't it be sweet if we could just pause in a certain location and then look around so if we pass that truck, we can just look at it instead of having to stare at this and kind of decipher exactly where everything is.
So we played around with things like QuickTime VR and panoramic photos and all that stuff.
that you have a way of taking a 360 photo and you can just stand in one place and you take photos from all angles and then you can compress it down into something where you can, standing in one place, just look around in all directions.
So we're like, it'd be cool if there was some kind of amazing tech out there so that we could do that with videos as well.
And it turns out that there is.
And we just didn't know about it because we hadn't paid attention really to our reference gathering processes before.
So, after some extended research, our tech art team came across this, and this is a spherical panorama camera.
And in this specific case, this is a ladybug camera, and it's used by a lot of the Google Maps and Bing Maps as they capture some of the stuff that's feeding into our modern day mapping technology.
And so, we love this camera so much that I'm gonna put a halo on it while I talk about it.
So, we love this ladybug.
These kinds of devices aren't really that common or widely used, so it actually took us a while to track down something that would actually suit our purposes and be useful in production.
So, how well this worked was actually a big surprise to us and we were stunned at how really accessible this tech had become.
So, a couple things about this camera.
This camera comes with a bulletproof, awesome looking black suitcase that looks like one of those nuclear code things that you carry around.
And so, it's always a pleasure to walk around with when we're in Prague and other places.
We took this suitcase along on all our reference gathering trips for Forza Five.
So the camera itself is really slick.
This camera comes with an array of five cameras around the center core, and then there's one on top.
And there's various modules you'll see at the bottom that kind of do the streaming over wires to your capturing device, and also do some real-time stitching of the images together.
So whenever it was appropriate, we would take this camera out, we'd mount it on a car or walk around with it, and then we would record the 360-degree streams.
So, real quick, this is the 3D video process that you use in order to make it useful to your artists.
So on the left here, you can see we record the video, and we record a certain number of them.
Each one has to go through an encoding pass to get it into the format that you want, and then you have to have a player that kind of lets you watch it back.
And so, I'm gonna provide details on each step in the next few slides.
So here's us, there's me in the silhouette, driving around Prague with this awesome contraption going outside our window.
So this camera, you can see the wires heading into the car, it's actually hooked up to a laptop that is capturing all the streams.
And so the six cameras on this guy simultaneously record huge gigabyte-sized streams and it stitches them together in real time.
After we do the recording and we have a full laptop, we have some software that comes with the camera and it lets you encode it into whatever format that you want.
So here we are, here's a video that's kind of doing the 360 mapping and the distortion to kind of make it so that it can map onto a spherical viewing kind of thing.
So we encode the video into a panoramic 360 stream.
So this is what you get at the end.
And so this right here looks like it's a standard video.
And so as I start playing it, you'll see that we're driving down.
But the difference is I can use my mouse and just start turning around in any direction.
So I can see exactly where something is.
I can take it to any point, pause, zoom in on a certain location, and see exactly some detail that I might have missed.
And it's all a single stream.
I can jump to any certain point in the stream and look around.
So we forgot to take pictures of some tram wires when we were out there.
And we're like, hey, that's all over the place in Prague.
So we could jump to a certain location, scope around, and really get that missed reference without having to ask for a plane ticket back to Prague.
And so it's really cool because this also gives you the sense of immersion And the artists who weren't able to go on the reference trip can kind of play these back Everyone has access to it and then they can really get a sense for what is it like to drive down this particular part?
of the track What did things look like?
And what are some pieces that we would have otherwise made up in any other circumstance?
So this has been a tremendously useful tool for our artists who didn't get to go, to capture the feel of that environment and make it a lot more interactive.
So that was a cool thing that we discovered in the course of Forza 5.
All right, lasers.
Lasers make everything sweet.
So I'm gonna talk a little about our laser scanning processes that we were using on Forza 5.
So here's a quick diagram, that's an overview of how we make laser scanning useful in our pipeline.
So, first thing we do is take a bunch of scans, it goes through a process called registration, and then after you register it, that means it's stitching all the point clouds that you get back together in one global coordinate system, so that you know where everything is in relation to anything else.
You can slice it back up into pieces that are pieces that you might model.
You can also stitch it together into multiple bits and then make it so that you can move pieces around if you want to take a little artistic license.
And so this is really useful for blocking out fake environments, other things that you might do.
And so we kind of stumbled on laser scanning in an interesting state of events.
So one day we had a vendor come by to show us the state of the art in laser scanning for objects like a car.
And so these particular vendors accidentally set the vendor to scan everything except the car.
So they set it off and it was going and then at the end we were like, man, this is taking forever, this sucks.
And then they pulled up the data and they were looking at each other going like...
well, where's the car?
And then so, while they were puzzling over their incompetence, I was taking a look at the data, and I realized that they had picked up the entire parking garage where we were taking this reference and including the stairwell that was like hundreds of feet away.
I'm like, I can see the stairs and everything.
And so, we chased those guys away because they were not fitting the bill for what we needed, but it really planted a seed in our heads for when we started our reference gathering process on Prague.
So, when we sat down and we had a little breathing room after we shipped four, we were taking a look at the state of the art in surveying and laser scanning and LIDAR and all that technology around there.
And we were pleased to find that there was a number of financially accessible options to us and that there are techniques to scan like miles of area with sub-centimeter accuracy.
And that was really surprising to us, because we didn't subscribe to any surveying magazines or go to oil drilling conventions where they use this a lot.
And so it was cool to see how much that's evolved.
I'm going to talk in more detail about it, so you guys can hopefully be equally as impressed about what we can do.
It's really fun to say laser scanning, we should do laser scanning for our tracks.
But in practice, it's really difficult to go from that phrase to trying to make it accessible and usable by the artists back at our studio.
So, I'm going to go into detail about each of those.
Okay, so this is us chillin' in Prague, and we are in Old Town Square, and this is what the laser scanner looks like that we used.
So, nobody's around because we were scared of carrying a laser kind of device around Eastern European police, and so we would get up at two to four a.m.
and go out and take pictures of big landmarks like this with nobody around, and it really helped our reference gathering process.
So, you set this guy up, you set it on for a few scans, you choose some key locations, and at the end, you stitch it together and you get something like this.
And so, this is a screenshot of some pricey serving software that is out there for processing point clouds.
So this is pricey enough and they use opposite axes and their navigation is completely opposite of what our artists want to do.
And so for that reason, we couldn't buy this software and place it on all our artists' desks and we wanted to integrate it into their tool set.
So one of the biggest hurdles we had was to try and figure out how our artists could use this in actual practice to help their production process.
Luckily, around this time when we were poking around, we discovered that Autodesk was pursuing some opportunities in the area of point cloud capture and processing.
And so, we actually contracted with their custom consulting group and decided to work together on something.
And so what we ended up with was a special implementation that would allow us to have a plug-in that would load up the laser scan point clouds inside of 3D Studio Max, which is what we use in our pipeline, and let the artists actually take chunks of this and just load it up directly in their tool.
And you can vertex snap to it, so you can real quickly lay out a block of a building and just see exactly what it's looking like.
And so, thanks to the deep pockets of my studio, Autodesk has released this funded project into the wild with a free extension pack to 3ds Max 2014, and it's also built into Max 2015, which was announced yesterday here.
So this is equally as accessible to you guys now.
So we also worked with Autodesk to get some early versions of some software that they've now released into the wild as well called Reality Capture or ReCap.
And so using that software, you can take these point clouds that we load up in 3DS Max and kind of slice them and dice them however you want, create chunks out of it, delete some points, just block it out to however you want and then end up with discrete chunks that you can bring into 3D Studio Max.
So after we process this, like after the registration process in the laser scanning surveying software, after we slice it up using ReCap, we can bring it into 3D Studio Max.
And I'm going to play a quick video here to show you what it looks like to our artists.
So here's some chunks from that scan from the Prague Old Town Square.
I'm gonna play it.
So we can chop this up and now we can take some artistic liberties so that we can make the Old Town Square funner to cruise a supercar through.
So we try and make it a funner to drive Old Town Square.
So we're taking chunks of the buildings, moving it.
So you can see how this might apply to a fictional kind of area.
If you take scans of like cliffs or terrain or something, you can actually piece together a compelling environment and see it in pretty realistic 3D and it's all fast and interactive.
And so, real quickly here, we can block out what a potential design for this area might look like after we've taken our artistic liberties.
So, here's another view of the chunks pieced together in the end after we did a little rearrangement.
This is blocking out the entrance to the Old Town Square for our Prague circuit that actually ended up shipping in the game.
So once we arrange this inside 3D Studio Max, and again, this is all like full detail, like you can zoom in to the detail of the windows and get the exact ornate decoration that was on it, and should you choose to, you can model it as well.
So, after that it's a matter of turning the production crank.
We have a lot of environment artists at Turn 10.
They eventually build this set of meshes, and it ultimately looks like this in our game with the lighting AO debug mode turned on.
So, that's what we ended up actually getting into with our ship game.
All right, so now a quick few bullet points to wrap up this tour of our reference bits.
So, savings.
We found that going through this process, I actually had to write all this business justification and budgeting projections and all that to say like, hey, we wanna spend like tens of thousands of dollars on laser scanning and it's gonna improve our processes.
So I kind of had to prove that out before we spent the money.
We found that in the end, we've significantly decreased the time it takes to create those early rough phases of our environment production using some of these techniques here.
We ended up saving, I don't have the exact number here, so I'll just summarize it as, we saved hundreds of dollars of money during these phases, balancing this reference gathering with the time that it took artists to sit around and be like, well, I don't know, I'm just gonna make this random building here, and then having people look at it and comparing it to images and say like, well, it's not actually there, it's over here, and all the adjustments that that takes.
So it's been a huge dollar savings for us.
We also got faster initial iteration on the look and feel of our environments.
So you could see in the scans that we had, even inside 3D Studio Max, you could really get a feel for the environment, like way before we ever generate models and get anything really useful out of it.
So it actually resulted in less design changes after we really wanted to have things baked down.
And then ultimately this led to a lot less quality and plausibility bugs during when we were trying to shut down the track and For for our QA team and our test team to identify like things that are wrong Like we have a whole team of people that sit there and look at stuff after the fact and go like this sucks This is wrong. And like we got rid of a lot of that follow-up action Alright, so I wanted to have a quick slide on the lessons and application in case you choose to venture down something like this.
So investing in this was not easy or cheap.
We actually spent some significant spend on this and it was really tough to justify.
A lot of it came down to somewhat hand-waving because like you can't really say, well, you know...
what amount of time is an artist like sitting there twiddling their thumbs before it gets to a place where they can actually start producing content.
And it's not something the studio management really wants to hear.
And so it was tough to get over that initial hurdle of saying like, we want to actually invest in reference gathering because it's so unsexy and it's not like, well, you know, they're not building the track at that time, so why is that important?
So the cost actually ended up being pretty reasonable for what we get out of it, and our production savings here ultimately proved to be really worthwhile.
We had a big accessibility struggle for artists.
I'll touch on that a little bit more in my next slide.
But it was really tough for us to figure out like, well, here's a cool tech, and here's how we map it to something that is useful actually in production.
And then ultimately, we ended up with a large, much larger data footprint than we ever had for any reference gathering trips before.
So, where is this going?
What's the future?
We're in the early stages of all these really cool techniques for trying to really quickly pick up what reference actually looks like.
So, I have a slide here showing that the future is crap.
in no particular order except for it is an anagram for crap.
Here's where some of the future I see of reference gathering is coming from.
So, costs are gonna come down.
Like we see day to day in everything that we do, the technology that is seemingly inaccessible at the beginning becomes cheaper.
And so, we were actually surprised, we were like.
oh, what if we bought our own laser scanner so we could carry it around?
And it was actually a thing where we were like, well, we could go either way.
We could actually partner with a service or actually do something like that.
So I see costs continuing to drop, and so that's going to be really good for us trying to get a good start on our 3D environments.
Recognition of data features.
So, we end up with a lot of point clouds and we can process it to make normal maps and texture maps and things like that.
But ultimately what's gonna be really handy is if we could take that and we could press a button and it would divide up into all these pieces, like here's a building, here's a tree.
And so the recognition of that data, there's a lot of people in academia and research who are working on that kind of problem.
And so that would really help us as well if we didn't actually have to get down to trying to model things after.
like a template, a point cloud data, or something else that is just like slightly out of reach for the artist.
Accessibility is something I wanted to point out as well.
So some of this hardware and software is not really accessible.
I talked a little before about the serving software.
Like it was impossible to use, and like I still get confused now from my post-traumatic stress of using that software, because like I don't know which mouse button tumbles and which one goes up and down.
The hardware, a lot of it, like the ladybug camera, uses firewire.
And, like, you're hard-pressed to find a laptop that has that built in.
There's all these wires standing around.
And so, especially when you're in a foreign land, like walking around Prague, and you have a backpack with, like, all these wires sticking out and everything, like, you look like you're up to some sketchy business.
And so, I see it becoming a lot more, a lot more...
easy to use, ultimately. Portability is the next big thing. I look at the reference gathering that we did for Forza 5 and I'm like, well, how come GoPro doesn't build something sweet like this where I can just like mount it on a helmet and walk around and look a little less suspicious?
And so I think with all the iPhone apps and Windows Store apps and Android kinds of things that we have on our phone, a lot of this 360 capture, and you're beginning to see it in some of the released apps that are out there, the ability to stitch together a bunch of pictures, do some photogrammetry basics, to create point clouds from that, and just to capture something, I think that's going to become more and more prevalent.
And the last thing that I wanted to end on is Prometheus.
So I didn't want to get this huge lawsuit on me, because Microsoft is concerned about my slides getting sued.
And so I thought I would quickly paint up the scene I'm talking about from Prometheus.
So in Prometheus, there's a scene where these guys land on this alien planet, and they're like, well, who knows what's in these caves, right?
So they unbox this thing, and they have these laser flying drones that they take, and they toss up in the middle of the cave, and they fly down the cave, and in real time, they're getting this 3D model built.
And so I was watching that movie, and I'm like...
What? Where is that?
That's ultimate.
And if you think about it, we aren't that far from that kind of future.
Because we're at a place where Amazon is talking about flying drones to deliver some of the stuff, and you see that in all the quadcopters and all the stuff that you see floating around.
And then laser scanning, as I mentioned, is pretty accessible, and there's a lot of stuff coming.
So I see this Prometheus future.
as a way like we can quickly go to a place.
Even our Halo team visited Iceland and did all this other stuff to try and capture a completely sci-fi fake environment.
And they can go out and take reference like this and using some of the tools that I showed earlier, be able to snip it up into pieces, stitch it together and real quickly build up a 3D model.
So this is my commemorative GDC 2014 painting.
And hopefully you'll have seen from this talk that we aren't that distant from this kind of vision and hopefully we can all progress collectively and move forward in terms of our reference gathering so that that becomes not a piece that is like special to Turn 10 or a studio because it's not a piece that anyone really wants to own.
It's a piece that is fundamental in us building our 3D worlds.
That brings me to the end and I will be glad to take any questions.
Thanks.
There's a guy moseying up so...
Cool stuff.
Thanks.
I was wondering if you looked into automating low-poly...
generation from your point cloud data to get quick prototypes up and running and a second to that, projecting color data onto that so that you can take your data really quickly into the engine.
Yeah, that's definitely one of the pieces that we're interested in and pursuing.
So, there is some stuff that is out there.
Our gauge of the state of the industry is it's not completely there yet.
So, there's pieces, there's a lot of point cloud stitching kinds of things, and again, they're not really that accessible.
Like, you can poke around and, like, you'll see ten types of tools that are out there that...
create low res meshes or high res meshes from an area, but you have to take it through all these different tools. And then we've actually been looking at a tool recently that has power line extraction from a point cloud. So you can import a point cloud and then it'll be like, well, here's the power line and it kind of builds it together for you. And we're like, well, that's not...
very useful for us and we don't want to pay like 10,000 for that privilege.
But like, that's one of the things I was mentioning about accessibility.
I think there's gonna be more and more tools like Autodesk is going in interesting directions with their point cloud data and I really want to get to a point where we can be like, well, this is a tree, so make a low-res tree so I can just block it into the game.
We haven't seen anything that is exactly there, but if anyone has a product that's like that, like please come talk to me afterwards.
Hey, I might have just missed that, but what particular laser scanner did you guys use?
This one in particular is a laser scanner from a company called Leica, L-E-I-C-A.
There's a ton of alternatives out there, so I don't want to be a pitch man for them.
But it did have accuracy and kind of the time constraints that we were interested in.
Did the ladybug camera and the laser scanning completely replace your need for photos?
And if not, did you have any way to link those photos back to those videos and scans?
All right, yeah, good question.
No, it did not completely replace our need for photos.
So there's a specific need for photos, which is to gather texture reference.
So once we take some of this, we might want to have like, here's a proggish brick texture.
Here's some cobblestone that was on there.
And that's what was really important for us to capture and to be able to use as texture reference and cut it up how we want.
And so like the laser scanning and the ladybug camera was pretty low-res in what we showed.
Like it's actually HD, but by the time you split it out across all those cameras, like you end up getting something a little muddier than we prefer.
And so it doesn't completely replace it.
So yes, we still have the need for photos.
And then your second part of your question was how do you relate that back to the 3D source?
So, um, there's a lot of stuff, like, um, on my phone, when I take photos, it kind of comes with a GPS tag and I can actually look at my photos on a map and see kind of where I've been. Um, so, we were real excited about that technology and we're like, what if we took these and with like a GPS bit, uh, we could stitch it back together on our laser scan and like have this awesome, like, big data. Um...
it ends up not being very usable, that kind of vision.
So we've tried a bunch of hardware where you have a little card that slides into your camera and it takes GPS readings and stamps it on as metadata into your pictures.
So the thing that they don't really tell you about that is it takes a while to acquire that signal.
And so if you're standing in the middle of Australia trying to capture Bathurst, you could be sitting there for five to 10 minutes waiting to take a picture because you're waiting to acquire accuracy.
If you take your handy phone and do that, it gets rid of the accuracy.
So I did that for some of the photos that we were taking, and then some random photos will end up being in the middle of Indianapolis.
And you're like, well, it doesn't have the real accuracy that we need.
I think there's some of the new Canons and Nikons have some GPS built in.
And so, again, it's something that it wasn't there for us at the beginning of 425.
It continues to evolve, so we'll look into it.
But yes, the dream is to, hey, let's go on a reference trip.
It's easy to do, and you come back and you have exact photo reference, laser scan reference, video, and it's all, like, stitched together in one intuitive interface.
Yep.
Jeff.
Some notable tracks from the history of Forza, Maple Valley, my favorite, are gone now.
And the thing is that Maple Valley has no real world location it's based off of.
Is it missing now because your production pipeline has gone this route where you have to have a real world analog to get the source material, or is it missing for other reasons?
It is missing for other reasons.
There are quite a few tracks that we plan to resurrect and to build up to the quality level that it would take.
As you guys know, in game development, you can't always hit the desired targets of everything that you would want to possibly have in a game.
And so when we're at a place where we can say, well, here's a, our content looks like we're gonna be able to build 15 tracks.
These are the tracks for the design considerations and the thought was like, you know, one of the things behind porting something like that and bringing it up to the current spec would take too long for the time that we had.
And so I think you'll see, and we've already started the process of kind of resurrecting some of the other tracks and providing it as free content as time goes on.
So you'll see us slowly bring stuff back up to spec.
And for something like Maple Valley, it is based on a real world location, and we sent people there to kind of gather some of the reference.
And so we would want to send people and capture using the methods that we had and piece together something kind of on a more creative license formula more than we did on Prague, and so there'd be a lot more creativity and design laid out for it.
But we would use some of the similar techniques for sure.
Yes.
Hi.
When you take reference pictures in a city, for example, and it's sunny, then you get plenty of spots in your photos with shadows.
And then your pictures become more or less unusable because of that.
You can use it as an albedo texture.
So was it a problem for you?
And if so, how did you work around it?
Well, so Microsoft has a lot of money.
So we actually seed the clouds before we go on a reference trip.
And there's no sun when we go.
Yes.
Now, um, so for, for sunny, sunny days, um, is obviously a consideration.
Um, there's actually a lot, um, some software out there now that, um, does a pretty good job at removing lighting.
Um, and so, uh, I guess I won't go into specifics because I don't want to be a pitch man for any specific thing.
But there's software out there.
that we have used and that we continue to look at, which will let you take sunny photographs and identify an area of shadow and sun, and it will automatically, and it does a pretty reasonable job at subtracting the sunny component of it.
And so we did that for the most part.
But then that's only scalable to a little bit, and sometimes there's some undesired artifacts.
And so we will actually take it in and then use some of the Macbeth chart data to kind of dial it into an area that's more realistic.
And so that was one of the reasons it was really important for us to capture images with a Macbeth chart, because if it's sunny on the object that you're taking a picture of, it's sunny on the chart.
And you can kind of compensate for that, even though there's going to be some slight differences.
OK, thank you very much.
Last question, I guess.
Yeah, I was wondering if you could just briefly describe the pipeline for the laser scanner, basically, like the data get once you do the laser scan, you know, how you get that data basically into max. Okay, yeah.
Yeah, so I covered it a little in a previous slide, which I'll try and walk back to while I'm here.
But basically, the process for it is, we take all those scans, and then we, so this is the slide I had up on it.
So, we do the process of registration, which is you need to stitch it up into one single coordinate system, so you know, even though you take 50 scans because stuff was obstructed, you know exactly where the top of the cathedral is from this point that you were trying to take a look at.
And so you take all that and Serving Software lets you kind of stitch that together, and so it's all registered.
Then we can take each of those pieces, and we know it's correct in 3D space, and then we can start adjusting it.
And so we use the ReCap software from Autodesk to export out RCS files, and that's freely available for people to use.
And so you can break it out into RCS format.
And then, as I mentioned before, Autodesk has now released in 2014, max 2014 and 2015, this plugin that we paid them to make.
And it lets you load in those RCS files as a max object.
And so you can bring it in, and you have a ton of clouds.
And it does occlusion really well and decimation.
So you can crank it down to like 1% of the points, if speed is a concern, move stuff around.
And so we have a really kind of smoothed out pipeline from when we first initially started doing this.
So our artists can kind of take any bits that they want, load it into their Mac scene, and start building a model off it.
And there's a couple hops in there, but it's as good as it's going to get for now.
All right, well, if that's over, feel free to catch me anywhere after the show or after today's session.
And thanks for coming again.
