My name is Max Kreminski. I am a PhD student at the Expressive Intelligence Studio at UC Santa Cruz.
And today what I'm going to be talking about is procedural narrative design with parameterized storylets.
So if you have done anything in game narrative before, you have probably seen a diagram that looks something like this.
This is basically a branching narrative structure.
if you know what this says already.
This is from a specific blog post that sort of categorizes a whole bunch of different possible ways to do branching narrative in games.
And what you can see here is that there's sort of all these different possible paths the player can take through the story.
There's a whole bunch of like sort of different sort of routes you can take.
There's branching points where you diverge and then sort of join back together at sort of later decision points.
And there's a lot of good reasons that we see sort of these static overall sort of like predefined narrative structures in games.
We see a lot of sort of familiarity as one of the big advantages here.
So everyone sort of knows what this is, basically looking at it and sort of how to design something for it, even if it's only simple.
There's also sort of cost reasons and sort of simplicity of implementation reasons where like it's really easy to sort of go in and say, okay, I know how to structure the code for something like this.
And there's all sort of these preexisting tools like Twine, where you can sort of see that like, it's really easy to go in and write, sort of twine stories that are basically like taking this branching structure and reifying it and you can see how all the arrows are connecting all the nodes and it's sort of this overall graph of stories that's very easy to sort of look and see how it's structured.
But what I'm interested in is sort of taking this graph and sort of blowing it to pieces and sort of fragmenting this huge sort of branching story graph and taking it into a sort of stage where players are more able to sort of shape the narrative structure on a fundamental level as opposed to sort of charting paths through this predefined narrative structure that the authors have set out for them.
Especially I'm interested in this in the context of procedural narrative games, which are kind of all about this like ability to have the story vary significantly between playthroughs and in ways that are more fundamental than if you're just sort of stuck with this branching narrative structure.
And for this to happen, what I found is that you sort of need two things.
You need reorderable units of narrative content, and then you also need some mechanism for determining when it makes sense to use them. And when you put these two things together you get what I call storylets.
So storylets are sort of, the term was coined in Fallen London, which is the game you can see on the right here.
They sort of, as the designers of this game, decided to write their story content in sort of these tiny little modules, each of which has some preconditions on it that sort of dictate when you are or are not allowed to play through them.
And in this case, most of the preconditions are sort of involving stats that are attached to your character.
So if you have nightmares greater than four, you can play certain storylets, or if you're like over five or fifteen persuasive or something like that.
And then similarly you have Reigns, which is a more recent game.
And this is I think also a more well-known probably example where they sort of took the storylet metaphor for crafting stories and literally sort of took this deck of cards metaphor and smashed them into one another.
So stories are cards or storylets are cards and you're sort of swiping left or right on requests that people bring you in order to sort of accept or reject those requests because you're the king and that's what kings do.
So when you sort of look at the common elements of these two structures or these two games, you get sort of this common definition of storylets, which is basically that they're these self-contained, reorderable units of narrative content with sort of preconditions that dictate when you can show them to the player, and sort of maybe these effects that update the game state. So this approach works really great if your game state is pretty simple, right?
So in Reigns you've got just these four sort of integer qualities or resources that represent your favor with the different factions in the kingdom, like the military, the church, the people, and so on.
Or in StoryNexus, which is the engine that powers Fallen London, you've got this sort of bag of arbitrarily many integer qualities, which are the stats or the variables attached to your character.
But if you want to sort of use this approach with more complicated game states, you need some way to get beyond these sort of flat preconditions, these sort of like, we're just checking whether an integer variable is within a certain threshold or not, and you need to sort of basically get to a way of expressing preconditions that allows you to sort of query arbitrarily complex game states.
And so this gets to where Starfreighter comes in.
Starfreighter is a game that I was working on towards the start of undergrad, or actually towards the end of undergrad, and it's sort of into the start of grad school.
I've temporarily suspended development on it, but it looks like this, or the original prototype looked like this.
And the goal here, as you can see, was probably to make a Reigns-like sort of game where the framing is that you're sort of a space captain of a tiny little freighter traveling from system to system and sort of taking on odd jobs in order to eke out an existence in space.
What this gradually shifted towards being was a game about the relationships between a cast of quirky procedurally generated characters.
So if you've seen Cowboy Bebop or Firefly or the implied off-screen life of Han Solo and Chewbacca in Star Wars, all these things are what I was trying to get at in the narrative design of this game.
And for this to happen, for the procedural generation especially to come in, what I really needed was a way to write narrative content that wasn't tied to any one character in particular.
but they could be applied whenever an appropriate situation happened to come up in the game state.
So you can see that this is a much more complicated interface now.
You've got these individual characters who have their sort of Proc Gen names.
You've got this cargo in your cargo hold.
You've got all these procedurally generated sort of star systems you can travel between.
And what you really need now is to sort of like write content for generic situations like one crew member is irritating another, or sort of is mentoring another, or has fallen in love with another.
All these sorts of like situations that you can imagine being narratively interesting without the characters themselves being like sort of defined ahead of time.
And I already had the sort of simple reigns-like storylet system from the original game, but I had to sort of somehow hack it to support this kind of complicated game state, especially the sort of web of crew relationships and the parametrized narrative content that I wanted and had to write.
And so I ended up with something that looks kind of like this.
This is a parametrized storylet.
It's a pretty simple one, which is maybe speaking to how much Boilerplate I end up writing all the time, that I consider this simple.
But this is basically when two members of the crew are sort of like, when the crew overall is having a good time and two of them decide that basically they're getting along better now than they used to.
So you can see that there's, in addition to this sort of static precondition, which is basically like checking to be sure that the crew have not been unfriendly to one another recently, we're also having this query part here where we're sort of binding these two logic variables.
And what this means is basically we're looking for two characters in this case.
who are not the same as one another, which is critically important.
And we're sort of binding them to these two variables, crew one and crew two.
And then we can sort of use these crew that we've bound to these variables, like later on in the body of the storylet.
What we're doing is we're sort of querying against the game state, finding entities that match the preconditions we're looking for.
And then we're sort of saying, for every storylet whose query is currently met, then we can show the storylet to the player.
And we're sort of picking weighted randomly from among the possible pool of storylets that we've got.
So this leads very naturally to an authoring pattern where some storylets have these super specific preconditions, like you maybe have storylets that have 10 or 12 preconditions among them, and these are very rarely met because of how complicated they are.
But when they are met, it feels like it's sort of naturally written exactly for the current situation the player happens to find themselves in.
And this leads to these sort of magical moments where it's like, oh, this is so specific to my condition, it's like there's no way that the author could possibly have foreseen this particular condition that I've gotten into, but we totally did.
And so you get these specific bits of narrative for those situations.
And then more often what you're writing is a whole bunch of sort of these generic fallback storylets with really lightweight sort of small, simple preconditions that are easy to fall back on, that sort of match a wide range of situations and that maybe have some more procedural textual variation to sort of disguise the fact that you're repeating the same things over and over again.
And then you can see here that there's like this text template part where we're sort of like substituting in the names of the Crew into the sort of overall text that we show the player in the end Okay, so we get this definition of parametrized storylets that basically augments the initial definition of storylets with instead of preconditions We've got these roles where you can slot in a sort of appropriate entities like characters or cargo units or whatever Okay, I'm going to skim super briefly over disadvantages.
You lose precise control over the narrative structure.
This is kind of a thing that you know to be the point anyway.
You have to handle the implementation right now.
You can't just drop in a thing to Unity and say, give me parameterized storylets and it goes okay.
Same for authoring tools.
There's no Twine equivalent yet.
I'm working on that.
Debugging gets tricky, you have to write JSON a lot by hand, and so on and so forth.
But I think it's super powerful as an approach anyway.
It gives you the simple concrete alternative to static narrative structures.
It's really powerful, really flexible.
You can express lots of different ideas in terms of these queries that I've shown you.
And there's sort of design patterns in games that are using these techniques starting to emerge.
Like Cultist Simulator is a really great example that was recent, and I think you can start to see that there's more and more of this going forward.
That's it. Thank you. This is my contact information if you want to contact me after this.
I've also written a paper about this and Starfrighter, the current prototype, can be played on Itch.
Thank you.
APPLAUSE Hi, I'm Nicole He. I'm an artist and a programmer.
APPLAUSE Thank you.
I'm an artist and programmer from New York.
I freelance as a creative technologist at Google Creative Lab.
I teach at NYU's interactive telecommunications program.
And I'm also currently working on an entirely voice-controlled sci-fi game with the National Film Board of Canada.
So today I want to talk about some tools that I use for voice technology in art and games.
But actually...
Ahem.
I mostly want to talk about appropriating technology that's meant to be used for serious business purposes to make creative things.
Basically like you don't have to only use game making tools to make games.
So as I said, I do a lot of stuff with voice technology, which is mostly about just like allowing, making things that allow people to yell at computers and then like making the computers yell back at them.
So one example is a game I made called Enhance.computer, which is also the URL of the game.
It's a cyberpunk voice controlled game that's an homage to that science fiction trope where people are like yelling enhance and zoom in and then like magical technology things happen.
So this is the game that lets you do that.
But the thing is, when you're developing things with voice technology, the thing is, like, a lot of, you know, these voice assistant devices are basically the way that most people talk to computers.
And so most of the developer tools available are basically made entirely for these very rigidly controlled platforms owned by big companies.
And another thing is that a lot of this technology is actually advancing very quickly, so like speech recognition, intent detection, speech synthesis, sentiment analysis, all these things that basically make up voice technology.
There's a lot of advancement happening as voice assistants become more and more popular, but again, sort of the tools available to use those things, you know, naturally are used for things that make big companies a lot of money, and that usually comes out in the form of customer service chatbots.
So like all this innovation and research is basically currently being funneled into customer service chatbots.
And you can see this in the documentation of a lot of these tools.
So this is actually one of my favorite tools to use.
It's called Dialogflow.
It's an NLP tool for conversational AI that helps you figure out the intent of what a person is saying without having to, like, say, manually hard code every possible way a person could say it.
So this is used for enterprise and commercial purposes.
And you can see that just from the way that they talk about it on this website.
And the testimonies are from Domino's or KLM or companies like that.
But it's also a really powerful tool for games.
So I want to show you a couple examples of things that are basically not customer service chatbots that I made using this tool that was meant for that purpose.
So one example is a really simple voice game called Mystery Animal for Kids, which is on the Google Assistant, but it's also available on the web.
So it's like a reverse 20 questions style game where you have to ask the machine yes or no questions to like figure out what animal it is.
And this is possible because Dialogflow makes it so that people can say things in a sort of like open ended way and then we can still figure out what they're saying and respond appropriately.
So here, if you say, can I eat you for lunch? We figure out that they're asking if the animal's edible.
So a project that I worked on with the 3D artist Iran Helleli is where we used Dialogflow in an extremely hacky way that they definitely did not intend for.
It's called Garden Friends.
It's built with AR and Unity.
I'm going to show you a video.
Oh, hello.
I'm so glad you're here.
I've been waiting so long for someone to show up.
To be honest, it's pretty lonely around here.
Tell me, what is your name?
My name is Michael.
Nice to meet you, Michael. I really need your help.
I need to plant a beautiful garden so that other people will come visit me and I can make more friends.
But I don't have arms.
So please take this seed and plant it somewhere.
Well, it's a start, Michael.
But this tree could look better.
I heard plants like it when you talk to them.
Why don't you say something nice to this tree?
I think you're a very boring looking tree.
Michael, I said say something nice. That wasn't nice. Look what you did, Michael. Try saying something nicer.
Just kidding. You're a beautiful and extraordinary tree.
Well said, Michael. The tree seemed to like that. But we've got more to do.
Brown and teal.
Hey Lynn Brown, interesting combination.
Splendid. Well done, Michael.
I think we've planted a lovely garden with my creative direction in your arms.
People will definitely want to visit my garden now and become my friend.
Okay, so that's Garden Friends, and we did a bunch of experimental stuff there, like, you know, you can say your name, and then the character would say it back to you.
We use sentiment analysis, you know, when we ask you to say something nice to the tree, and if you say something that's not nice, the tree turns black.
We change the colors in the scene, depending on what you said.
And all of this stuff is made possible with Dialogflow, with the sort of intent detection and like keyword extraction and entity extraction features.
The problem is like the API is like built, is not built to be used that way.
So Dialogflow used to have this really nice, simple REST API, where you could just send an API key and send a query and get a response back.
but they've changed it so there's a lot more like authentication stuff that you have to do and it makes it difficult to use it in things like the, in, you know, the browser in Unity or somewhere else.
Um, so the solution is like, we, you have to do some hacky shit to get it to work.
Because Dialogflow, being a Google technology, is basically built to be used with the Google Assistant.
So if you want to use it again in a place outside of that, you have to do a bit of extra work.
So it's not necessarily that bad.
Like, if you want to use it in the browser, there's simple things you can do.
run a server with WebSockets, and Dialogflow actually does have a Node SDK, so you can do this thing instead of, like before, you might have been able to send a request from the client side and use it there on a website.
Now it's a little more complicated, but still possible.
And with Unity, actually, luckily, a few of my students, Alana Bonder, Alice Sun, and Lin Zhang at NYU, are building a plugin so that people can Again, use Dialogflow in a Unity project, and the URL is there.
And it's currently in progress, but I'm sure they would appreciate any pull requests.
So basically, to wrap up, sometimes the tools you want to use are not meant for fun things, but I think it's still worth doing those hacky things to make the cool stuff.
And again, you don't have to only use game making tools to make games.
So here's a guy having a great time playing Enhance.computer.
All right, thank you.
ERIC REIDMANN Hello, everybody.
My name is Eric Reidmann, and I'm going to talk to you about the level editor we made for our game Clone Drone in the Danger Zone and some cool things we learned along the way.
So, what is Clone Drone in the Danger Zone?
It is a third-person sword fighting game where any part of your body can be sliced off.
With your human mind downloaded into a robot gladiator, you must try to survive the sinister trials of the arena.
And in 2017, we made a level editor for this game.
It ships with the game, and you can use it to publish stuff to Steam Workshop.
And it turns out that people like doing that.
We currently have 15,000 levels in Steam Workshop, which is really cool.
They look a lot like this.
At least this is what people's first level tend to look like.
For a lot of our players, it's a cool way to kind of just experiment with putting a lot of really dangerous enemies into a level so you can kind of experience something that no sensible game designer would ever put in the game.
You can kind of tackle that with no upgrades kind of thing.
And of course, if you look at some of the top levels, you start to see more of a variety between like interesting gameplay challenges, more sort of thematically strong levels where you're trying to like create like a sculpted scene kind of thing.
So there's a lot of really, really cool stuff there.
And of course, we eat our own dog food.
We're using the level editor to make the official levels of the game as well.
So we're kind of really married to this tool as well.
And so far it's been really good.
So yeah, I'm gonna see if I can go over some cool features that maybe some of you will find some nuggets of useful information in.
All right, the first thing, we are able to expose values.
So here you can see a very similar looking thing to Unity or any other sort of game engine.
You highlight an object, you can see values associated with that object, you can modify them and they update.
How do we do that?
Well, we use attributes and reflection.
Some of you, I'm sure, have heard of this.
But if you haven't heard of this and you want to do something like this, you should Google that because it's amazing.
We basically just add a little include and level editor tag on any value.
And by magic, you can now tweak it in the game.
And of course, this also works for method calls.
This is an easy way to add a button to the inspector over there.
Here's an example of testing the height of a jump pad.
This saves so much time, not having to play test the entire level.
And of course, it works in exactly the same way.
You just slap an attribute on a method and boom, super easy to use.
All right, next features, triggers.
What are triggers?
Triggers are basically a way to detect that something is happening and in the level editor kind of trigger a response.
So in this simple example, we have a door and we have a zone where that kind of triggers when the player enters it.
Looks like this, as you would expect.
You run up to it, the door opens.
Oh, there's an enemy.
the enemy is also activated by the trigger.
And what's cool about this is that we can add all kinds of sort of things that trigger things.
So for example, you can also trigger stuff when everyone dies in an area, everyone leaves an area, animations can trigger stuff, and all kinds of wonderful things like that.
And then it kind of provides a standard interface for anything we add to the level editor can be triggered from a variety of triggers like that.
So it kind of forms a really cool system where you can string together stuff and chain them to create quite complex things.
So an example of that is that one of our players made a calculator somehow.
I'm actually not sure how he did it, but it basically uses triggers and then in response to shooting these triggers it moves some enemies around that again cause another trigger to update some sort of predefined value and he managed to make it so you can add these numbers together and get a result.
So it's a pretty powerful system when you have simple tools like that that you can kind of just weave together.
All right, next feature.
All right, next feature.
Hello, JDC humans.
Greetings.
We use text to speech for all the dialogue in this game.
It is superior to your human voices.
By far.
Yeah, this is one of the more successful features in the game.
We have about 33,000 spoken words in this little indie game which is a lot of words.
These guys talk a lot and people like it.
How do we do that? Well, it's actually very simple. We have a Google spreadsheet Here's you here. You can see the text. I just said and There's a simple one button import you click a button downloads the spreadsheet generates audio And kind of bundles it with the game And then it updates a manifest of all spoken dialogue So the game can kind of know what dialogue is in the game and you can just trigger it very easily from the game Yep All right, here is a maybe more controversial feature.
We added our own animation system to the game, or to the level editor, rather.
So this was a really hard decision.
It was kind of hard to justify doing this.
I spent about a month making this system.
Here's like a little cut scene from chapter four of story mode that we're working on right now.
And this was tricky because Unity already has an animation system.
Why would we do this?
And it kind of comes down to the fact that when you make a level editor, like a complex system that sits on top of the normal game engine.
it makes it hard to use the game engine's features as you would normally do them because you're kind of, you know, serializing stuff in a completely different way.
So, yeah, we agonized over this, but what it comes down to is that I love drama when making levels, you know?
I love it when suddenly a robot walks out from behind a pillar or something and it's like, what's up, human, let's fight!
You know, dramatic stuff like that.
Small dramatic things and big dramatic things.
And I think if you take nothing else away from this, it's kind of an obvious point, but when it's easy to add content, you get a lot of content added to the game and it's a joy to add that content.
So we have all kinds of animations now that we previously just couldn't do because it was too hard.
And I think that should be the goal of whenever you try to make a tool like this, it's kind of to make the user forget that they are using a tool, to be able to kind of stay in a creative mind space to think about what do you want to exist, not how are you going to make it work with these complex things.
And yes, that is, I guess, my overall point.
Thank you so much!
Hey everyone, how's it going?
I'm Em.
Woo!
And I'm here to talk to you today about using MIDI controllers to tune game feel.
So I spent a lot of the last year working on a new hardware platform where we were prototyping new low-level interactions.
We were basically trying to turn out a new prototype every couple days or every week to figure out what actually works, what are we trying to do here?
And we ran into a really classic prototyping problem.
where when a prototype is successful, that is really obvious, it's really easy to tell you should do more with this, but if a prototype is not fun, it's really tricky to call the line on, is this not working because it's a bad idea or did we just not spend enough time polishing it?
So one of the ways we tried to solve that was to minimize the amount of time it took us to sort of get a prototype really, really polished.
And one of the ways we tried to solve that was reaching for MIDI controllers.
So if this is a totally new concept for you, you were using some hardware like that, which I am also holding in my hand, where you can take all of these knobs and sliders and wire them up to all of your physics constants and all the other magic numbers in your game.
So while the game is running, you can tune them in real time and see how they feel.
So what did this actually do for us?
Tight feedback loops are amazing.
If you have ever done the sort of thing where you have to stop your game while it's running, change a number in code, and then restart the game, you know that absolutely kills your ability to be creative and come up with new ideas and try things.
Things are naturally a little better in Unity if you're using the inspector window at run time or at compile time.
But it's still not great.
I've seen a lot of people will, if they're using controller games, they may wire up the keyboard to do a similar thing.
But a media controller can be really great for this.
And where it really starts to get interesting is when you're tuning complex sets of variables that are related to each other.
So I worked a lot on a...
like cartoony kart racer, where we cared about things like max velocity and acceleration and turn speed, but we cared less about those individual values as much as what is the relationship between them, which is really, really hard to tune when you can only change one value at a time.
And I played around with things like...
Let's encode the proportion between all these variables as a number and tune that number.
But that gets very complicated very quickly and is way more complex than you want to deal with when you're trying to make a fun game.
Whereas if you have a MIDI controller and you can take those three or four variables and wire them up to sliders that you can each control with one finger, that is really easy to play around with what works.
Also, perhaps most importantly, you get to feel like this DJ code wizard.
This is, I really appreciate my design collaborator had this sort of sense of creating a mise en place before setting up to tune a given prototype, which seems silly, but I think is actually really vitally important, because once, like, game design is a creative activity, and if you can get into this playful sense of exploration and getting you to a place where you can explore the entire possibility space of your design, you're going to do much better work.
Also on a very concrete level, humans have a lot of very, very strong cognitive biases against weird numbers.
And if you're manually typing numbers into code or the inspector window, you're gonna go for numbers that look nice and clean.
Whereas if you have this nice expressive analog input, you might actually find the number that feels more right.
And I think it goes without saying, this is a very nice hack that I enjoy, but it still feels like a bit of a hack.
You might be familiar with Brett Vector's work.
This is from his talk, Inventing on Principle, where he talks about how do you tune a sort of Mario-style 2D platformer.
Like, in an ideal world, we wouldn't be dealing with running back and forth, changing physics and jump speed, and trying it over time to see what works.
We would have some higher-level conceptual abstraction that cuts cleanly through the design possibility space and shows us what our actual problem is.
But until then, like, $50 worth of hardware is a pretty good solution.
So concretely, what did I actually do?
So as I talked to people, it turns out there are a lot of people who are already using MIDI controllers.
They just don't really talk about it that often.
But pretty much everyone I talked to pointed to this William Shearer blog post from 2015 about how he uses a MIDI controller for Manifold Garden.
And he talked about the specific controller he uses, and the way he wires things up in Unity, and the sorts of things he use it for.
So in broad strokes, I took all of his work, took the work that I had been doing, and sort of wrapped it up in this nice Unity project, where the hope is there are already not that many barriers to entry to getting started here, other than not knowing what to do.
So maybe I can provide you a nice Unity library that if you have bought.
this Korg Nano Control 2 hardware that a lot of people use that is $40 to $60 online.
You can drop this into your Unity project.
And if you haven't changed the default MIDI values, it should just work.
That said, it is pretty buggy.
So we will see right now if it just works.
Unfortunately, most of the work I was actually using this for is both NDAed and fairly complex to set up.
So this is everyone's favorite Unity default Flappy Bird clone.
Let's see.
Oh, this is really awkward looking at the other screen.
So there is a custom specter window that is on the other screen.
Hey, so because we know that every good game has character customization options and Korg makes the Nano Control 2 in white and black, you can customize the editor.
But from there, let's say you want to wire up this knob up here to how high the bird jumps.
So we're just going to drag in our bird.
There we go.
And I was reaching in for this object.
I'm grabbing every amount of behavior off it.
So say we want the bird.
And then it's going to go through and use the C Sharp reflection APIs to find every property or stored field that looks like it could be a number we can tweak.
And then the sort of values, what the current value is, the range is basically these knobs have a bottom and a top.
So the bottom is going to be zero.
The top is going to be this number.
Let's make it pretty high.
Let's leave it with that for now and see if it works.
So we can close that out.
And if we run the game, you're not actually going to be able to see me move my hand, unfortunately.
But as I turn it all the way up, whoa.
I think we still have a little bit of tuning to go, but we'll leave it at that for now.
Yes, that's about it.
The other thing to call out is if you actually pull this open, there's another UI inside the inspector itself where you can add more bindings here.
There are a million different design decisions I could talk about that I don't have time for, but I do want to talk about one really important one, which is...
these dropdowns that I talked a little bit about.
So on a logistical level, it totally made sense for me to do this.
The amount of time that I spent implementing that paid back for itself immediately in terms of not worrying about entering a typo and typing something wrong.
But I think it's actually way more conceptually important than that, that if this is an empty text field, this is now a tool that you have to come to this saying, I know exactly what variable I want to tweak.
This is a tool that will let me accomplish that task.
Whereas now that it's a drop-down, this is now another space for exploration, where if you know this game doesn't feel right and I don't know how to solve it, maybe by browsing through the choices the tool is giving me, this will help give me some insight into what I can actually do. This is a tool not just to solve a specific problem, but to help give you a framework for which you can explore your problem space.
So augmenting human productivity is great.
We have lots of tools to do that, but I would push you as tool builders, because I assume a lot of you are here because you care about making your own tools, you should think about augmenting human creativity.
Or to put it another way, hammers are great.
There are lots of hammers that are very useful, but pianos are also super useful.
You should make more pianos.
Thanks.
I'm David Mershon with Universal Happy Maker, and today I'm going to talk about animating using Perlin Noise.
Just a little disclaimer, this is a talk about programming.
If you can't program at all, this would be a really good time to get a cup of coffee or mess around on your phone.
On the other hand, what I'm going to tell you are some things that we learned that made our lives easier and other programmers know them.
So if you're someone sitting in the audience that knows everything I'm going to say, I don't mean to insult your intelligence.
It's just maybe not everyone knows this stuff and maybe it'll make your lives easier like it did for us.
So first I'm just gonna show you what it is that I'm gonna demo today.
This is some Perlin animated characters from our game.
This guy is animated with more or less just one script with about 100 lines of code.
So if that sounds good to you, I'm gonna explain it.
If not, you're crazy.
So, why is it that we got into Perlin Noise for Animation?
There's lots of ways to animate things.
Basically, we're a small team.
We don't have anyone that can dedicate time to doing key frame animation, and we still wanted our game to look great because you have to impress people and make them wanna play your game and have it be a good experience in terms of visuals.
So, when we ran into this problem, I thought about my friend Nick Crockett, who told me years ago that if you want your game to look good, you put some Perlin on it, and I didn't really know what that meant, but I remembered that he said that, and so I looked into it.
And so what Perlin noise is is an algorithm that this guy Ken Perlin thought up in the 1980s to make procedural textures for the movie Tron, which won an Academy Award.
And this is what they look like on the left here.
That's a basic Perlin noise generated bitmap.
On the right is a sort of fractal extrapolation of that, that you might have seen if you use Photoshop or Studio Max or something like that, a very common texture.
And in the center.
is a 3D rendered landscape that's composed of content that's based on Perlin noise type algorithms.
So, but what our team used it for is animation and the easiest way to think about that is you go back to that picture on the left.
And you imagine just one line in that bitmap, and we're gonna traverse it from left to right, and basically convert each of those values, the luminance values from black to white, to a floating point value normal as zero to one, and use that to drive whatever motion we want as amplitude values over time.
So to show you why you'd use Perlin noise rather than something else, I'm going to compare several different functions for generating amplitude over time. We've got a seated random one first, then a sine wave, which you'd know what that is if you paid attention during math class, and then the Perlin noise, which is the subject of today's talk.
So I'm going to go to an example here in Unity.
This is just a graph I made that's going to blow those functions up.
You can see the random noise is indeed random.
But unfortunately, it's not very good for smooth movement, because the amplitude of the points from one moment in time to another has no continuity at all.
You still might find that useful for making raindrops or something like that, but not for moving objects around.
Next, we've got a sine wave, which is very smooth, which is very nice.
And you might use that for a cork bobbing on water, but it doesn't look very alive.
It's very mechanical.
Perlin noise combines some of the order of the sine wave and the chaos of the randomness.
It's smooth, so you can use it for moving things around, but it's also unpredictable.
You don't know when things are going to get really jaggy and when they're going to level off and kind of end up in a valley for a while or a plateau.
So, what does this look like when you actually move objects around in it?
That is what we're going to look at next.
So, this cube here is being moved around with a script that just uses Perlin noise.
I'll show it to you right here.
This is only about 20 lines of code, and all this is doing is taking those values of amplitude over time and using it to drive the x position on the transform of this object.
So you can see that it moves smoothly, but its movements unpredictable. You don't know when it's going to stop and start Now of course you can use this same code basically almost the exact same script with one line of difference to drive rotation Right now they're moving and rotating in sync because it's almost the same script and they're using the same time values but If you change the time scale on one of them, they now become disconnected and seem to have their own agency, or you can change the seed value, which is just what's being put into the other argument on the Perlin function.
It's built to take x and y coordinates.
So now they're moving at the same speed, but off basically a different line of that bitmap.
So this starts to become really powerful once you start organizing these into hierarchies like this one here.
And you can imagine that this is the arm of the teacher that is scolding you for not remembering your sine waves in math class.
This next example here.
is one of the actual scripts that we use in the game.
The previous ones were all demo scripts.
This one isn't much longer.
It's only about 100 lines of code.
And the main difference here is it modulates all three axes on position, rotation, and scale.
And this one is doing all of that and making something that maybe moves kind of like a balloon in the summer sky or that shiny black probe droid that was going to stick Princess Leia with needles if she didn't reveal the location of Alderaan if you've seen the film.
Now, you put those into a hierarchy, and you add some excellent character art from someone like our excellent character artist, Julia Y, and you get some characters that look like they move around, and they talk.
And this talking you're seeing is just a very simple thing.
We're just speeding up all of their animators at once.
And it's a really dumb trick.
It's like a kid shaking a sock puppet to make it look like it's talking.
But sometimes really dumb tricks are what you need.
So.
Here's some more of the characters in-game using this technology.
And we use it for just about everything else too.
We use it for environments, characters, UI animations.
We just make everything wobble around with Perlin noise.
and it looks nice and warm, and we didn't have to lay a single keyframe.
So, you can also change states with Perlin, use this time, amplitude over time values to swap safe frames in a sprite that's also useful, and this character's lips are flapping based on that as well.
So, thank you very much.
I hope what I said made your life easier.
Hi, I'm John Manning. I'm 50% of Secret Lab. I'm a programmer on Night in the Woods.
I've written a bunch of books. Go and buy them, please.
Also, I'm right now helping on Marvel Create Your Own from TapTap Comics.
And also, here's a cool tool you can use. It's called Yarnspinner.
and it was a simple solution to a fairly complicated problem that was faced during the development of Night in the Woods.
So the problem was Scott Benson was lead artist and also the dialogue writer for most of the game.
Alec Loker was lead programmer and Beth Hockenberry was research and story writer.
The problem was that Scott could not do all the writing and do all the art and also code at the same time.
There are some limits to how many different tasks an indie team can do.
Night in the Woods is a text-heavy adventure game.
The solution we came up with was a thing called Yarn.
Yarn is a language for writing dialogue.
The solution was to make this a very simple tool for ease of use for writers and ease of use for people integrating that tool into the software.
So this is inspired by Twine, and we've seen Twine being discussed a bunch today, and also, Twine kind of has sunk into the developer consciousness a bit as well, which is nice.
So the idea was, what if Twine, but in our game?
So the Yarn dialogue system is really two things.
It is the Yarn Editor, a piece of software that you use to write your dialogue, and also it is Yarn Spinner, which is the library that interprets that dialogue and runs it inside your game.
So Yarn is a simple app, a twine-like node representation of your dialogue.
Each node contains a number of lines of dialogue, it contains some logic, it contains basically a tiny script.
The Yarn code, as I mentioned, is a twine-like syntax.
So again, designed to be easy to write, easy to parse.
It's simple for writers who don't necessarily need to work with the underlying behavior of the scene.
And it's also simple for programmers who want to set up a scene's behavior without having to mess with the actual content of the lines as spoken by characters.
So, what does the language look like?
Well, it looks like this.
This is actually some of the source code from Night in the Woods in which we have some logic.
This is not a full node, so there's no end if there.
So, we have characters speaking, we have tags at the end of lines to indicate localization line codes.
We have logic happening, we have, you know, the game state being modified.
It was designed to make it easy for writers and easy to block out a scene and also have full control over what is happening inside the scene story-wise.
So all of the gameplay of Night in the Woods is almost entirely driven by Yarn's script.
So let's take a bit of a closer look at what Yarn language looks like.
These three lines of code here on the left are valid yarn syntax lines.
So each line of dialogue is represented as a line of text.
And what yarn spinner will do is it will read each line one at a time and deliver it to your game.
Your game then blocks on each line and handles it however it needs to.
So in the case of Night in the Woods, we pop a dialogue bubble, we display each character one at a time, we wait for player input.
but for example in a game in which you display multiple runs of lines it can also handle that just as easily.
Logic works in a very similar way.
So again, I've said Twine-like syntax probably more often than I should.
Any time that a variable gets accessed, Yarnspinner will actually just defer to your program.
It doesn't have its own built-in variable system.
You implement that yourself.
So it's very easy to integrate into your existing game state system.
The choice system is every time it encounters this pair of double square brackets it will add that to a list of options and when it reaches the end of a script it will display all the options it has seen so far and based on what the player has chosen it will go to a different node.
So it is designed to make it simple to add more options.
Additionally, there's non-visible, non-text based things that a Jansky would need to do.
So that's things like commands.
So all of the stage directions in the game are done with these kinds of commands.
In this case we have an instruction to dismiss the speech bubble and then make the player character perform a sitting down animation and then we delay for two seconds to create a bit of a beat.
So all of the non-dialogue stuff is handled in this way.
We also realized that because it's a very, very expressive text representation, there's a lot of opportunity for creating very short, lightweight choices.
So this is not necessarily things that affect the game story, like its main plot, but players do like being given options, even if that doesn't...
change anything apart from the fact that whether you say yes or no, like no variables are being modified here and yet the player is engaged. So this little arrow syntax makes it very straightforward to create lightweight options.
To integrate this into Unity, I'm not going to assume that everyone here uses Unity because not everyone does but basically the API looks like this.
You create a monobehaviour that implements some coroutines.
One for lines, one for options, one for commands, that kind of stuff.
You yield on those coroutines as a run and that's the entire thing.
So, you, for example, implement this abstract class called DialogUIBehaviour, and so you get called, hey, a dialogue began, or hey, a line has arrived.
Here are some options.
Let me know which one the player chose.
Here's a command, also, node complete or dialogue complete.
So to just show this in action, this is another chunk of code from Night in the Woods.
So we have two characters, Bea and Mae, talking to each other, then there's a choice.
And then if the player chooses the option, let's hang out, then we set some game state and then navigate to a different scene.
So here it is in game.
So what is happening here is Yarnspinner is delivering the individual lines to the game and that's causing the speech balloons to appear.
It's actually, basically once every eighth of a second, it's displaying another character to create that thing filling out.
And then, yeah, when the player chose that option, then we iris out and then go to the end of the scene.
Yarnspinner is free, it is available right now, it is open source, it is under the MIT license which means you can use it in your commercial projects.
By the way, this slide and the next slide contain things that you may want to take photos of, so I will just leave them on screen for a second.
It is all on GitHub so we welcome your contributions.
We also have a fairly active little Slack where people can come and chat about how to use Yarnspinner.
I am about to move to the next slide so I will give you a second.
That's me, that's my studio, that's Night in the Woods.
Night in the Woods was made by Infinite Fall and Finji.
We helped as well.
I'm also speaking tomorrow morning on some more advanced stuff on being able to mathematically prove that a line of dialogue is reachable.
So if you're interested in that, come see that.
Thanks very much.
That's it, that was the Tech Toolbox 2019.
Thanks so much for coming, let's hear it one more time for our six amazing speakers.
