Hey everybody, how you doing?
Thank you.
Welcome to my talk. My name is Jeff Van Dyke, and I hope you're ready for some exciting Foley fun.
In putting this talk together, I realized it's probably more of a post-mortem and a pipeline talk for that matter, and ultimately how the audio in Unpacking came to be.
I'm going to start on the story of our process, but then also get deeper into the technical workflow.
I think most experienced people here who are audio people will know the stuff I'm showing already.
It might be a bit redundant.
But I think maybe there might be a few things we did differently that...
or incorrectly for that matter, and we can both kind of learn from it going forward.
An interesting thing that I discovered is throughout this whole project is the reoccurring theme is underestimation on my part. I underestimated how big this project was going to be from the get-go, and I've also underestimated the response to it as well. So, welcome.
So who's Jeff and why are we listening to him?
And why am I talking about myself in the third person?
I don't know.
My name's Jeff Van Dyke.
I'm a composer, a sound designer, an audio director.
I got started in 1992 at Electronic Arts Canada in Vancouver.
I worked on games like Skitchin, the very first FIFA, the first Need for Speed, a lot of firsts there back in the 90s.
And then in 97 I moved to Australia and started working with the Creative Assembly in the UK.
It's a weird connection there, but it happened.
And working for Creative Assembly, I worked for them for about 10 years on different Total War games, starting with Shogun.
Rome, Total War, Medieval.
After all that time on Total War, the last thing I did with those guys was this game called Alien Isolation, which was probably the biggest AAA title that I worked on.
And at that point, I stopped working on AAA titles and switched to working with indies and haven't looked back since.
And I quite like working with indies, actually.
AAA is typically very.
corporate, and I find working with indies much more personal and getting to know people a lot closer.
Also a bit more multifaceted in what you have to do, not just audio, some of the biz dev stuff and what have you.
OK, so what's unpacking?
They say a picture is worth 1,000 words, so a trailer must be at least 1,500.
And this is quiet, this should have sound.
There we go.
Unpacking is a zen game about the familiar experience of pulling possessions out of boxes and fitting them into a new home. It's part puzzle, part decoration. You create a satisfying living space while learning clues about the life you're unpacking. There's over eight house moves, no sorry, over eight house moves, you gain a sense of intimacy with a character you never see and a story you're never told. It's pretty deep.
There we go.
Oh, thank you.
Thank you.
So how did Unpacking come about?
Unpacking was inspired by two members of our team falling in love and moving in together.
Literally, the game came to them while unpacking Tim's stuff into Ren's house.
They would normally be here with the rest of our team, but I think they're a little worse for wear after last night's awards ceremony, so we'll catch up with them later.
But the rest of our team is sitting here right in the front.
Snotten and Angus here from Witchbeam.
And yeah, so that's how the game came about.
Then what's this talk about then?
And I promise I won't do that joke anymore.
Soon after Unpacking's launch, there was a tweet that went viral in November 2021 that stated, oh, and this is from Francesco Del Pia.
He says, excuse me, what?
And posted this video.
possibly one of the most riveting pieces of cinema shown at GDC.
I have no idea what that is.
Thank you.
I don't know what that sound was.
Anyways, that video had over a million views, and then came the responses to that tweet.
Max from Audio Kinetic, who make Wwise, said, 14,000 Foley audio files, right?
Dear God.
And I'm like, yup, we had Reaper render the audio files into a deep folder structure that represented the containers and hierarchy in Wwise, then used a single template container to map all the sounds to the correct surface switches.
I felt giddy every time we did this process.
It was magical.
Why am I talking like that?
Anyway, so Polygon did an article on it.
They were impressed with the number of sounds.
And my friend John Passfield tweeted, there should be a GDC talk in just managing the spreadsheet required for this game.
And I'm like, hey.
So here we are.
All right, my first approach to the audio.
Had a brief discussion with Ren and Tim about audio styles.
We had a little bit of back and forth and kind of came up with a high level audio concept.
The pixel art, we felt, should have chip tunes.
That felt like a good match, except that we would add acoustic instruments like guitars and stuff like that, and ultimately.
made different instruments represent different characters in the game.
So the music kind of progresses as you play the game, and the instrumentation changes as the game progresses.
So the chip tune thing felt like a good idea.
But then I thought, well, should we also have chip sound effects, little beeps and boops?
And Ultimately, we didn't decide to do that.
But for the sake of this talk, I put a little example of what that would have been like in Francesco's video.
Now, I spent five minutes putting this demo together, this bit.
So it's a bit underwhelming.
And I possibly could have gone crazy with synthesis and made really interesting synthetic impact sounds.
But I just chose not to do that because I thought it would have been, well, actually, I just didn't feel like doing it, I'll be honest.
So it didn't go that way.
Then I thought of this idea, well, because the pixel art sort of has this impressionistic vibe to it in that there's a certain amount of missing detail out of the visual because it's pixel art.
And that's the charm of pixel artists is what they choose to show and what they choose not to.
And I wanted to.
I decided that I thought it'd be really cool if while that didn't have full detail, what if the audio had like tons of detail?
It's hyper-realistic.
And so I thought that was a good idea.
At this point, early on in the project, we didn't know how many items needed to be recorded.
And we also didn't really know the scope of the game.
So I just thought, all right, give me a list of things, and I'll start recording it.
So this is a photo from my kitchen, me recording the box opening and closing sound.
And for the audio people out there, that's a Rode NT2A microphone and a Tascam D40 recording unit, both of which we didn't end up using for the final game because that mic is a vocal mic and recorded too much ambience. And that recording unit has a bit of a noisy input, I found. So, and when you're recording really quiet stuff, you need really high quality inputs on your audio equipment.
Side note, after taking or doing this recording session, two days later I wrote the theme song to Unpacking, and it was one of those compositions that just sort of came out of nowhere, just went, and it was done in two hours.
And you know, if you're into writing music, you know, that doesn't happen very often.
I was really lucky in that that ended up being the theme song, which I thought was quite interesting.
So anyways, we did this recording and Tim and Ren made the prototype and we put it all together And so this is the prototype from 2018 of unpacking It's quite similar.
I don't know if you can hear it there, but there's a really nice ambience in the recordings of those sounds.
I just did a little cheat there that unpacks everything instantly, which is not in the final game, by the way.
But you'll notice here, all these things sound the same.
And I'm immediately broken out of the game, out of the immersion.
And so it was putting this together, we learned as we went, oh, we're going to need a lot of detail in this.
We need the sound of things stacking on each other.
We need, you know, small plates, large plates.
And yeah, so.
The other thing we realized is there's not a lot going on in the soundscape here, right?
So there's a lot of room for us to focus on all this fully and the detail in it, which was a big advantage for us because if you think about it like a...
first-person shooter game or something like that.
There's so much chaos going on, you never get to really appreciate that.
Typically in those games, there's a lot of detail in like the footsteps going across different surfaces and different speeds and movement types.
I wouldn't be surprised if this 14,000 number is a typical number in a AAA title with tons of stuff going on.
But in our game, because there's so much space, we all have this...
There's so much time for us to sit there and appreciate the quality of the sounds.
So at this point, I thought this was going to be an easy project.
I'll bang this out in a couple of months by myself.
I assume, you know, underestimation, right?
So the results of that prototype, these were my takeaways.
The natural kitchen ambience sounded awesome.
Shared item sounds didn't sound so good, so I'm going to need to record more.
I figured I'd record a few new variants and jobs done.
Awesome.
But then got some information from the designers, and they said, oh, actually, we're going to have multiple rooms, and items can move in between them.
And I'm like, so does anybody see what the problem with this is?
I had recorded all the sounds in the kitchen.
There's all this ambience on these sounds.
Imagine you take that same sound, play it when you move into the bedroom.
The bedrooms are typically really dead.
There's no reverb.
And now you're hearing this ambient sound in a dead bedroom.
So it would have sounded.
So that was a bit of an issue.
That means I'm going to have to rerecord all this stuff again.
So that's a bit of an issue.
And basically, the scope of the game had been clarified in terms of just the size of it.
And so this was going to be interesting.
What I did is I did some math.
There was going to be around 500 items in the game.
15 surfaces, 10 variants.
And by variants, I mean like just when I was recording stuff, I was picking things up and down 10 times.
So there'd be a lot of variation when you hear the same thing over and over.
This adds up to 75,000 audio files.
And I was like, what?
How am I going to deal with this?
I don't know how I'm going to deal with this.
Just like Doc here.
And so I left the building.
Yeah.
My second approach to the audio.
I know, I'll get my daughter Ella to help me.
And she was going to uni at the time, learning music production.
But she was on a break, and I said, hey, Ella, could you record some stuff for me?
So this is her in our spare bedroom, recording this stuff in our dead room now.
And I have a quick example here.
I really apologize for the quality of this video.
I actually think I was, I thought I was.
taking photos but I was accidentally taking video but you can see what's going on exciting stuff As you can see there though, the items we recorded were very literally the things that were in the game.
We weren't doing that classic Foley artist thing of using one thing to mimic another.
We did record as much as possible the actual thing that was in there.
Maybe where we improvised was what we were using for the surfaces, but that is like a benchtop and we had a shelf and we had, I think we used a cookie tray for the sound of putting stuff on the stove and stuff like that.
But then, so Ella was busy working on that stuff, but then she got busy graduating, and you know, how can I argue about that?
This sort of proud dad moment here.
So she graduated with honors, and she actually is just releasing her first video game soundtrack for a game called Fort's High Seas.
That gets launched tomorrow, actually.
So I couldn't be prouder, and she did a, she's just, it's really awesome.
Thank you.
Go, Ella.
That's really cool, thank you.
Yeah, I think she's going to do amazing things.
So now I'm in a situation where I started thinking, what am I going to do next?
So I'm just thinking, thinking while looking at a wooden seagull, and thinking while staring into your souls.
And I came to the conclusion that I think a lot of people in my situation would have, uh, came in the conclusion that I would have come to was, help, I need my wife.
Now, I'm choosing this picture for this slide because she came up with the idea of when you put the duck down on the ground, it quacks.
So I thought that was such a great idea.
So our third approach to the audio.
This is my wife Angela. She's awesome, talented, super smart, and beautiful too, in every way.
And I met her at EA in the 90s, and she has worked on a lot of different games herself, as a dialogue and foley producer.
very convenient.
And she worked on early EA Sports titles, Triple Play, NBA.
She sang some vocals on a bunch of songs of mine.
She co-wrote some of the songs, too, on Need for Speed and the Total War series.
And then...
She, on Submerged there, she helped me with the Foley implementation in Unreal and stuff, and she kind of is Unreal, so that's awesome.
So we discussed this and came up with some assumptions about our process.
These are very common. Manually naming files is time-consuming, mind-melting, and sucks.
Editing can be slow and tedious. We thought we would try and automate things as much as possible.
We weren't sure what we were going to need audio file-wise in terms of the end result, like if it needed to be loud, quiet, mono, stereo, sample rates.
So we wanted to keep everything non-destructive so we could keep changing our mind.
The only thing we kept destructive was the initial pass of noise reduction because noise sucks.
And we wanted to make the process easy to repeat with different audio settings so we could iterate quickly.
And so this is a little excerpt from Ange's blog of her doing the process.
Hey everyone, this is Angela Van Dyke and here I am in our sort of little makeshift Foley studio.
I am working on a beautiful game called Unpacking and it's being made by our fabulous team at Witchbeam.
And I've spent a lot of time in this Foley recording situation because in unpacking, you unpack lots and lots of things and you move them around from place to place.
And it sounds just like it would in real life.
And that's because I have recorded every item on every surface that you can put it down on in the game.
So I'm going to bring you along. I'm just going to press record.
And we're recording a little postcard now on tile.
So this is cardboard light on tile.
So and that's how I do it.
there is a little bit more involved. I'd have to, you know, do a bit of technical stuff and set levels and all of that and perform it. Usually it takes two hands to perform because you have to put it down and pick it up just so or it sounds terrible. There you go! For those of you who love all those little sounds of all the things in unpacking, that's how I do it.
Go, Aang.
So from there, we would go into editing.
And yes, I'm going to show you a video of me actually editing, because it's exciting.
So we would, here's a take with multiple items in one take.
And we would prefix each take with what it is.
And this made it fairly quick because we could set up a surface, get all the items and then just fly through them in one giant take on this surface.
Now what I'm doing is, Reaper has a function called Dynamic Split, which removes the silence in between transients of sounds.
So it turns one giant audio file into multiple audio files.
And now all I do is need to just delete the audio.
delete the audio that I don't need.
And this process was really quick for us.
It also edited things really tight and made it so, granted, we made a lot of audio files, but this editing process was really fast.
So what I'm doing now is I'm separating the pickups from the places, and I'm putting them onto separate tracks.
And now what this means is that I have separate tracks and can process them separately, have them in different volumes, add some EQ or whatever.
But also, it means that I can name them uniquely.
By only naming the tracks, I can use these to name the files, as well as the folders that we're going to render to.
So in this folder is called Benchtop, because that's the surface that it was placed on.
And now what I'm doing is I'm creating a region around these audio files, and I'm naming the region the name of the item.
In this case, it's Ceramic Light.
And Now I'm running this action, a Reaper action, called renameSelectedItemsWithPatterns, v2, by xRame, who was nice enough to make a tweak to this script for me to suit our needs.
And you feed this pattern.
In this case, it's region, parent track, track.
So region is the item.
Parent track is the surface and track is the action pickup or place.
And there it's just renamed everything super quickly, exactly the way we specified.
And yeah, this process worked really well for us. You can see things are named properly there.
So now, oh, now the other thing that happens is that the regions that you create get listed on the side here, and that region list becomes like bookmarks in your project.
So if you click on a region, the cursor goes to that, and it just made it really, really quick to manage.
So then we're gonna, now we're gonna render it.
And this shows you how big the actual, this is the master Foley project file for unpacking.
And as you can see, as I zoom out here, it just gets absolutely ridiculous.
to the point where it's like, what were we thinking?
So as you can see, there's the region list on the right side of everything.
On the left is the tracks.
The reason why we did it this way is because I can quickly jump from one sound to another and quickly compare quite easily one sound to another.
And now what I'm doing is I'm showing how we had to stagger the sounds across the surfaces from left to right because otherwise they would all play at once.
And that's what caused the project to just get spread over such a huge amount of time.
OK, so what I'm doing here now is I'm taking everything in the whole project and renaming it in one step.
And that just what I just showed you there, that just renamed, like I think it says 13,000 some odd files that is just renamed, which is just lovely.
And yeah, that was awesome that that happened.
So now.
Now what we're doing here is I'm going to render, show you the rendering process.
And we use this same information, but to build a folder structure, because you can do that in Reaper.
And I'm using those same parameters to, when it renders, it's going to put everything into a separate folder based on item, surface, action, and then the final place, the final, final name.
And the reason for this is that structure matches how we have things set up in Wwise.
Wwise is set up to expect that structure.
And I'm going to show you this process.
So the reason why we're putting it into all these separate folders is to match the Wwise container structure.
So now, the rendered files.
This is the result of that rendering we did.
And there's all the folders of all the different items.
And there's a whole whack of them.
And within each of these folders is all of the various surfaces for that item.
In this case, it's the box grader.
And then it's the benchtop surface.
And these are the pickups.
The other thing about these sounds is not only were they the sound of things being moved around, but they were also like a UI sound for the player.
And we exaggerated the pickup sounds.
I mean, it's a little bit unnatural to always grab and slide something, but we needed that feedback that you picked up something.
And you'll notice the edits are super tight.
There's no time wasted in these sounds.
But you've got to remember in unpacking, the pickup animation is one frame.
It goes from unpicked up to picked up.
And so having a sound that had a really nice, slow sound just felt laggy and slow, and it wasn't a good feeling.
So we kept everything really tight so it was responsive and tactile.
So going through this process, we were learning stuff as we went.
A lot of items sounded similar.
So we started recording generic materials to share amongst things, amongst items.
So that's like, rather than recording a toothbrush, we would record something we would call plastic light.
And so anything that was light and made out of plastic would use plastic light.
And we had glass, and we had ceramic, and et cetera.
The, this is always interesting, but when two materials hit each other, the softest material wins what were the predominant sound. So an example of this is you have a metal cup and a wooden cup and a hard table. You put the metal cup on, you'll hear the metallic sound.
put the wooden cup on the wooden thing, you'll hear a wooden sound.
If you take those two objects and put them on a bed, and put each one on a bed, they will sound identical.
So that means I don't need to record those two things on bed, I just need a generic thing called object light on bed.
So that worked on anything that was soft, and it was that revelation that was also another huge time saver, that and the sort of shared materials.
Items that had a lot of character we would deem as a hero item and actually record that on all the different surfaces because they were special, like a ukulele or something like that.
we recorded a library of sweeteners.
So, for example, we have this cup sound, but we also have this other cup that's got pencils in it, and they shake around when you move it.
So we just recorded the sweetener of pencils shaking around and played that while using the shared cup sound.
So we had this library of sweeteners that didn't need to be recorded on different surfaces because it's more about the sound of the...
objects interacting with each other.
And so the sweeteners actually gave us more mileage with all of our generic sounds.
And also we realized that shaking things is fun.
And so we made a dynamic shake system, which was akin to, you know, composers have percussion libraries and drums and stuff, and shakers with velocity switching.
That's so if you play a note quietly, it's a soft shake.
And you play it hard, it's like a hard shake.
Well, we set up that exact same system in Wwise.
And Tim, our coder, detected the movement of the mouse.
And the faster you did it, the louder it would get.
And it would detect left and right.
And so this is what that is like.
OK, so I'm going slower than I did in my practice.
So I'm going to speed through the next bit.
Importing into Wwise, this was our process.
We would set up the switches, in this case, the action switch, which was pick up or place.
Those are the two actions.
And we'd set up a surface switch of all the surfaces.
Then I had a template that was going to be used by all of the items.
This was pre-set up.
There's all of our surfaces.
And you can see that matches our folder structure that we did when we rendered.
And the switches get set in code when the event triggers.
So Unity's driving which one of these to choose based on that.
So it says, play shoe heavy, on surface equals shelf, action equals pick up.
And that's how simply that worked.
So this is the actual importing process of me going to where, what am I doing here?
Yeah, choosing the folders that I want to import.
Here's all the folders we rendered earlier.
This is the way it looks in Wwise.
You select all of these.
folders and set it to the template that I just showed you.
Wwise lights things up yellow that match.
You can see our folder structure now is matching the container structure, and so it's going to build all of these containers in this configuration.
The action containers will be filled with the WAV files.
Life is a progress bar, isn't it?
sign of the times.
Okay, and as you can see now Wwise has a whole whack of containers in it that are all set up with the correct surface set to the correct switch. And everything's named the same so it's really easy to understand what goes into what.
And you'll notice that not all sounds are set up on all surfaces.
because on those other surfaces, they can use these shared generic objects.
That's what those are there.
So those are on the softer surfaces, the bed, the carpet.
I think actually box and linoleum were the other ones that were considered soft as well, interestingly.
And that's all full of the WAVE files.
And now, the spreadsheet to track this thing was massive.
And I'll show you just a quick thing here.
This is it evolving over time.
Yeah, we didn't really know what was going to happen here.
We were making it up as we go.
We didn't have really a hard deadline initially.
So we took our time and it just evolved over time.
It was trial and error.
And it did get pretty crazy big in the end.
And lucky for me, it was actually Angela that managed most of this.
And she is much better at it than I am.
Although I get into like all the formulas and stuff like that.
But you can see how big this spreadsheet is.
It's just ridiculous.
And it's organized by the different rooms and the different items and all the different surfaces.
This data is ultimately what got sent to Unity to trigger these sounds.
I'm going to show a bit more detail here, I think, in my video.
I've just gone a bit ahead of it.
Yeah, so in the room column, that's obviously the room that this item is where it spawns.
The item name is the actual physical item from the game, and that drove everything.
Audio ID 1 is the sound event in Wwise that will get triggered on hard surfaces.
But we also wanted a generic one for the soft surfaces.
So we needed to basically assign each item two different IDs.
This is also where we set up the sweeteners.
And then the next thing I'm going to show is the surfaces.
Now these columns were built with...
This is the data that was sent to Unity.
And these columns were built by Formula, which just simply appended the audio ID with the surface.
Bed box, carpet liner, we're always ID 2 because that was the soft surfaces.
And the highlighted cells you see are overrides where we've decided, no, we don't want to use the thing we recorded, we want to use something different.
because of reasons.
Basically, sometimes the actual thing you recorded just doesn't sound right, and you have to make a creative decision and choose something from a different surface to replace it.
And this was a really cool little process here.
This is the, so what I'm doing here is I'm making a little change to show you how we would import this data into Unity.
So I'm just copying this and replacing this audio ID.
You can see the columns changing with that change.
Now I'm switching over to Unity and I'm, importing this data by downloading the CSV, and Tim made it so it would actually download the CSV directly from Google Sheets, which I thought was amazing.
Straight into Unity, I click Update, and that change that I've done is now live in the game, and it could be updated while the game was running.
which was awesome.
And the benefit of having something like Sheets in that situation with all that data is that obviously a spreadsheet gives you filtering, sorting, highlighting, formulas, and stuff.
And it saves a lot of time when you're managing that much data.
And then the final piece of the puzzle was that we would audit our data and make sure that it's all correct.
And so this is the audio audit tool that Tim made.
And what this is doing is just this particular tab is validating the data in our spreadsheet to make sure everything is set up correctly.
And it's telling us which, in this case, the mouseover is telling us which room a.
a item is in, and it was also confirming whether it was correct or overridden.
And the unused ones are ones that are not necessary for the game. If data was missing, it would show up in this list. Luckily, nothing is missing because the game is shipped and I couldn't do anything about it now. And this other tab, the Foley scan, validates the location of all the WAV files.
And it also shows me which audio IDs are mapped to which items.
And so there was just a lot of checks and balances that this gave us.
And in some ways, well, we had this tool, this audit tool, before we did the last recording.
So it actually helped us prepare our recording scripts that we used, because it would say, yeah, you need to record this, but you don't need to record this, which was.
really, really handy.
So now I'm going into the end summary.
Actually, how's my time?
We're good?
OK.
So we recorded a huge amount of sounds.
We found some shortcuts along the way with those soft surfaces and generics.
Reaper and Wwise workflows were flexible and they kept us sane.
Validation and Unity provided clarity in the chaos of all of this.
And working with my family was really fun.
And actually, I want to take this opportunity to share something with them, because they couldn't be here last night and today.
But it was really cool.
We won.
I'd like to just congratulate Angela and Ella for winning the GDCA Best Audio Award for Unpacking, which is really cool.
So good on them.
It's pretty cool.
Thing's really heavy.
Satisfying.
Yeah, it's interesting.
I've worked with Ang since we've been married and we've worked together and we're still married and still like each other.
It's incredible.
Actually, out of curiosity, does anybody here work with their family?
Like, is there any family businesses or got a few people?
It works well, it's all good.
Yeah, it can be challenging, but I think it's really nice.
I work with a few family devs, and yeah, it's really cool.
And also in summary, you folks are awesome for sitting here and listening to me geek out.
Much appreciated.
Thank you very much.
And I think this is the time where I would ask if anybody has any questions to ask about anything that needs clarification or anything.
Hey, Woody.
Hello.
Hi. Yeah, amazing job.
I have a question.
One of the first things that popped into my mind when I saw this project was, would this be a good use case for some kind of procedural audio, physical modeling, synthesis?
Which probably doesn't exist in the way that might work best for this.
But is that something you considered?
I did definitely consider that.
We weren't sure.
As an indie, we didn't have a huge budget.
And that would have been, I would have liked to have maybe tried the Wwise, there's an impact thing in there.
And I think I dabbled with it a little bit, but I think that could have worked.
But.
that just didn't seem to be...
I don't know, I felt like the budget was part of a bit of an issue.
The same reason why we didn't use the convolution reverb in Wwise in this, which since Unpacking has done pretty well, we've actually added the convolution reverb now because we can afford it.
But yeah, it was more of a budgetary thing that we didn't go down that path.
Yeah.
Cool. Thank you.
Yeah, I think in some ways this process matches the tone of the game.
Yeah, maybe.
It matches the organic nature of it or something.
Yeah.
I hear you.
Thank you.
Thanks.
Hello.
Hi.
Were there any, while working on this, did you have any issues with file size of the game as the end product?
No, file size. Yeah, that was really surprising.
You know, I think all that data crunches into like 100 megs or 200 megs, I think, on the platform.
And I think that's because Wwise is compressing it.
Also, you've got to remember, you saw those edits.
They are really short.
There's very little.
The longest things are obviously the music and stuff like that.
But yeah, we didn't have any file size issues or even file count issues.
I was kind of waiting for the whole thing to explode, but it seemed to keep it together.
So yeah, no issues with that.
All right, thanks.
Welcome.
Thank you much for the talk. I have a question about while recording so many different sounds and varieties to this probably some of them are metallic and Certain surfaces would produce a lot of like unpleasant frequencies and things like that Did you organize it in a group with DSS compressors and like EQs or you take care of this sound individually?
Just because there's so many of them. Yes groups might not be as good just because Yeah, you know what, I don't know if you noticed, I didn't really show it that clearly, but in the Wwise project of the master foley file, we had a bunch of automation at the top, and we had a bunch of plugins on the master bus, and we would just automate over certain items, we would turn on something with a plugin called, I think it's called Soothe.
I don't know if you've heard of this plugin called Soothe.
I highly recommend it if you work with anything that's transient.
It's really good at smoothing things out that are harsh.
And yeah, so we did do that.
We did some limiting.
We did some EQ, a lot of high-pass filters, because we're recording things that are so quiet.
We had that proximity effect where you're recording something.
It's this tiny little thing, but because you have the mic so close, you get this huge amount of bottom end coming from the sound.
which is unnatural, but if you high pass it, that works.
So yes, we did all that sort of stuff, but in very large sort of chunks of it, because rather than per item, there was very little per item, per sample processing going on.
It was always big brush strokes of stuff.
Just one quick question.
What's your essential mic setup you recommend for like?
Essential what, sorry?
Oh, microphone setup.
Oh, the microphone setup, yes.
The best, the mic that we used for everything was a Sennheiser MKH 8040.
It's a beautiful little mic.
I think it records up to 50 kilohertz.
So it's really a beautiful microphone, highly recommend it.
And that gave us all those beautiful sounds.
Okay, thank you so much.
Thank you.
Great talks, thanks. I was wondering, at the end of the project, a lot of things were very automated.
And how was your process about automation coming by?
Did you know since the beginning you were going to need tools and develop them?
Or did you try to fumble doing things manually and then discover that you would need tools?
And when did you choose to say, hey, actually, let's invest in tools?
You know, I think I learned about this stuff at a thing called Gcap.
It's a show like this, but it's in Australia.
And this person, Gwen...
Gwen Go, I think her last name is.
She did a little talk on her process with Wwise.
And hers was a little different than what I've done, but what I discovered watching her talk is that Wwise had these automated processes.
This is, the one I showed you is the one I chose, which is like...
taking folders and mapping it to containers.
Her process is you configure all this stuff with a spreadsheet, and you feed the spreadsheet into Wwise, and the spreadsheet tells Wwise where all the files are.
And they're both valid ways to do it.
And for whatever reason, I chose the way we did.
So yeah, I learned this partially from going to another talk, like you guys have done.
So yeah.
If I may just, my question was more like, because of that talk, did you know then since the start of the project that you would need to put these tools in place?
And I'm also thinking on the Unity tools that required programming and time investment.
Yeah, I see what you mean.
the, yeah, well, obviously I knew that this functionality existed.
I knew right from the get-go that we were going to need that.
The stuff that in Unity about those tools, that was, that came as we went and was developed as needed and as we got clarity.
You know, so, yeah, this is one of those things where, you know, despite, you know, I've been doing this a long time, I'm still learning, you know, after all these years how to do this.
And this is why I love this industry, actually.
Exactly that, because I'm always learning.
OK.
Thanks a lot.
Welcome.
Hi Jeff, really loved everything you did with the game, been following it since like 2019, so it was really cool to see it come out and see everyone loving all the amazing work you put into it.
Thank you.
Honestly my question is, imagining there were a sequel or something to it, anything that you want to try for a theoretical next time around that you didn't get to try this way around, or things that you think that you would absolutely do differently if given the opportunity?
Yeah, I would maybe, from a musical standpoint, maybe something a little less linear on the music side of things.
And I'm not exactly sure what that is, but something to ease on the repetitiveness, you know.
And then from a sound effect point of view, I do like the concept of the physical modeling of impacts.
I think that maybe there was some room to explore that area.
And I think ultimately, I think from the process of recording, when Andrew and I got to the end of this and went, you know, what would be awesome is if all of the surfaces were set up in a room.
And Foley studios are like this.
This is why they exist, the proper ones.
Ours was not a proper one.
But all of the surfaces are set up.
The mic is already set up on each one.
And you have all your items.
And you hit record.
And you could probably just sequentially go through all the items on that surface and on this and this and just blast your way through all of the items and efficiently record everything in a very relatively short amount of time.
kind of just doing more things in parallel, whereas, you know, she had to set up the surface, get all the items, do all the sounds, change the surface, change the miking, you know what I mean?
So yeah, that would be another way I think we could have improved on the process.
And if we did do a sequel, that's definitely what we would do.
Awesome.
Thank you so much for all the information.
Super cool.
Thanks.
Hello.
Hi.
You mentioned that when using the Tascam DR4, I'm curious if there was a field recorder or audio interface that you thought had a better preamp for the kind of quiet sounds that you were recording.
Sorry, say that last part again.
What field recorders or audio interfaces would you recommend for recording those quiet sounds?
Oh, I see what you mean. Yeah.
So what we ended up switching to instead of using that is I had a spare...
What was the interface called? Steinberg USB, was it USB? No, it was FireWire.
So it was kind of old. FireWire interface had really clean inputs and recorded up at 96 kilohertz.
And that was attached to a Mac laptop with Reaper running on it.
And look, maybe it's my particular TASCAM.
I don't know if they're all like that.
But my particular one, for whatever reason, was just really noisy on the input.
just added another step to the process of getting rid of that noise.
So I mean, for all I know, maybe it was a bad mic cable.
I did try a couple of different things.
But yeah, so in the end, our main recording process was using that Sennheiser 8040 mic into this Steinberg interface and straight into Reaper.
So that worked out quite well.
OK, thank you.
Thank you.
