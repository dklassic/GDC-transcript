All right, before we get started, we have to do something really important.
On the count of three, I want everybody to do jazz hands, okay?
One, two, three.
Thank you for that.
There will be more jazz hands at the end of the talk.
Let's get started.
Suppose I want engineers at my studio to be able to build tools.
Now maybe these are new engineers, new hires, or maybe they're veteran engineers who have been working in a different discipline altogether and haven't done a lot of tools work in the past.
Let's say I want them to be empowered to bring great tools to whatever teams that they are working on.
And I want them to create tools that fit into whatever tools ecosystem we already have at the studio.
So what advice would I give to such an engineer who's interested in doing tools development?
What do I wish that somebody had told me?
What can I impart to them?
Well, I might think back over all my experiences and all my trials and errors and trials by fire and I might say something like, don't build tools for engines.
Too many of us build tools that have the engine as their primary customer.
But the engine isn't our customer.
It doesn't suffer.
It doesn't call for help.
It doesn't have great ideas to make the tools better.
So as nice and pithy as that is, I think we can do better.
It's easy to say don't do this or don't do that, but what do you do instead?
We build tools for humans.
Yes, our customers are human.
And humans think about things differently than engines do.
Humans also make mistakes.
But that's not good enough, because an engineer might just build tools for themselves, right?
Something that reflects how they think about the game content that's being built.
Build tools for humans who aren't you?
This is good because while you as an engineer are probably a brilliant technical mind, you might be building tools for brilliant non-technical people.
But I like this though. This is starting to sound more like what all the UX books out there tell me to do, design with your users in mind, right?
It's getting better, but I'm not quite satisfied with this, because game development has this weird problem.
We have a lot of engineers.
And they could turn out human-centered tools, it's true, but then maybe you just end up with a pile of tools.
Does anybody here know what I mean when I say a pile of tools?
I see nodding heads.
Are they fun to work with?
I see shaking heads.
So it makes me wonder, are we building the right thing?
I don't want you to build tools.
I want you to build workflows.
Things that comprise all of those steps that content creators take, right?
And all the tools they involve and how the users flow through their work.
I want users to have a cohesive, coherent experience.
It's getting there, right?
This idea that you should build workflows for humans who aren't you is something that I think most engineers would agree with philosophically.
But even this is oversimplistic.
Making it practical is especially hard.
And making it practical is exactly what we wanted to do at VV because we're interested in enabling disciplines to work together and collaborate.
And we want new engineers in this space to be successful quickly.
So what I'm sharing today grew out of sort of this line of thinking.
We wanted to distill learnings from our past and our successes into knowledge that could guide future engineers, even non-tools engineers.
Because we did have past success.
Shortly after I started at VV, I worked with other tools engineers to create Alchemy Laboratory.
Alchemy is VV's proprietary engine tech and Laboratory is its tool set.
All of its tools are oriented around workflows which roughly map to disciplines and our users could mix and match different parts of the tool to craft whatever worked best for their workflow.
This, for instance, is the default world builder workflow where we built levels for Skylanders and Crash.
This is Visual Script Builder wherein we built visual scripts.
And there are other workflows in the tool set, too, for UI and VFX and cinematics and localization and all that.
Laboratory was a big investment in workflow development at VV.
And we came out of it with really good results.
I got to work with some crazy smart engineers who had a passion for building tools with users and produced great results.
In the year that we brought Lab online, workflows and efficiencies were seen as our studio's biggest strengths.
and our users rated them very highly compared to others that they had used in the industry.
We don't attribute our success in Laboratory to any one guiding principle, nothing that simple.
Laboratory was the culmination of years of tools engineering expertise, and a lot of it came from trial and error, and a lot of it came from investment in new things, and conversations with users and partners, and some of it was learned through disruption and false starts.
and inefficient deliveries.
So we wanted to codify some of what we felt had made VV successful at workflow development over the years.
We also wanted to provide direction for future efforts.
We wanted to sort of declare where we wanted our investments to go in a blue sky sort of way.
We wanted to make something that we could share with engineers that were new, veteran engineers, and now good people like you.
We created a set of wiki pages, and we called them our workflow development guidelines.
The original target audience was those engineers I've been talking about who wanted to participate in workflow development.
But I think that this advice is consumable by really anyone working in this space, tools designers, UX thinkers, and the like.
The guidelines themselves are technology and project agnostic, and they're organized into three categories, UI and UX design, engineering and implementation.
and something I call creative mindsets.
We want engineers to look at these guidelines and think, okay, this is something I can actually do.
This is concrete.
This is a trade-off I can make.
This is a decision I can think about or talk about with my team.
Now, standard GDC disclaimer, I'm sharing these because I feel that they will be valuable to your discussions back home.
I hope you agree, but they are not the only way.
This is not the one true path.
These are what we want, not necessarily what we have.
Remember, some of these are partly aspirational.
I think, though, that you'll get a lot of insight into what we have come to value based on our past experiences and where we think ground is still fertile.
They are not scientific.
What you're about to see is more of an applied retrospective.
It's a distillation of many past wins and not-wins, observations, conversations, lessons learned, and all that business.
It's not backed by any quantitative user research, though we would not discourage that, or we wouldn't turn it away.
But they are sound recommendations, despite the lack of hard data, and they have sparked some really good conversations.
And back home, not so much here, this is a living document.
I was making changes to these guidelines as recently as last night.
So, we expect these to change over time as our business changes, as our engineers change, and as our learnings change.
So, we'll start with user interface and user experience design.
A lot of you probably know that UI and UX design are really big fields outside of game development.
There's been an upward trend in UI and UX jobs over more than the last decade, and it's my opinion that the literature is sort of still catching up to some of the practical aspects, especially game development.
A lot of it, I find, is geared toward helping people buy stuff online, which is not really what we're trying to teach our engineers.
We wanted something that was more approachable.
These guidelines are more of a highlight reel.
These are lensed through experiences we've actually had that the literature probably wouldn't even know how to emphasize.
All right, the first section is boost workflows with keyboard support.
Because skilled users have very high expectations for making keyboards a part of their work to help them work faster.
Here are some things you, as an engineer, can do.
You can support precise input because users may know exacts.
They may know exactly how many missiles a turret should fire.
They may know exactly how long a cinematic shot length is.
Don't force users to type in an exact quantity.
Don't force users to express an exact quantity using anything slower than typing it on their keyboard.
They will appreciate the acceleration.
It is, however, good and clever to blend gross precision with precise in- I'm sorry, gross input with precision input, such as using controls like a drag slider there, where you can type on the num- or you click on the number to type something new in, or you can drag it like an up-down spinner.
You can accelerate data entry by anticipating input.
Users should avoid typing what the tool already knows or can infer.
Users may know exact names or identifiers, or they may only know fragments of them.
You can support both with predictive input.
Or you can anticipate those little micro-workflows.
So if you think of file open as a micro-workflow, that's something you can accelerate to with like a recent files list.
You can accelerate tasks with shortcut keys.
Shortcut keys save users time by reducing mouse movement or streamlining the flow from one activity to the next.
So for example, if a user intends to select two objects, group them, and then move the group, you have an opportunity to accelerate that by adding a shortcut key to the group operation, right?
Generally, you should favor assigning shortcut keys to actions that would otherwise require the user to shift their focus away from what they're currently looking at.
And you should also beware shortcut key pitfalls, because users are prone to typos, so don't put create next to delete.
Be careful of proximity.
Shortcut keys are a scarce resource, and unless your workflow has a very good custom binding Be judicious about assigning new ones because shortcut keys are forever.
Users internalize and habituate these very quickly.
And after they've had that opportunity, you risk changing them at your peril.
You can make keyboard support discoverable.
Tool tips are great for this.
Info tips, too, like the kinds that you see in just about any Microsoft product right now, right?
You can promote discoverability also by deferring to idiomatic shortcuts.
Control-S always means save.
F2 always means enter some kind of editing mode if you're in a text field.
Next section, build cohesive workflows, or features that play together, stay together.
Cohesive workflows feel organized and task-oriented and integrated with the user's other work, while incohesive workflows feel disjointed, scattered.
They may even seem incomplete.
Here are some things that you can do.
You can promote discoverability and findability.
Discoverability is the degree to which users can discover what features are available to them.
Findability is the degree to which they can find what they already expect to be there.
And to promote these things, you can keep things close together, clustered by task, like this doesn't do.
This is a screenshot from Laboratory Context Menu in the World Builder.
One of these things is not like the other.
Remember, I said this is what we want, not necessarily what we have.
Keeping things close together can mean minimizing certain distances, concrete and abstract.
Distance can be mouse movement, eye movement.
It can also be number of clicks, number of levels deep in a menu that a person has to go in order to find what they want.
Over time, users are going to build a strong mental map of your workflow.
And over time, they're going to learn where to find what they expect, or they're gonna know how to make a reasonable best guess.
They're also going to remember what they haven't tried yet, so that they can go back to it later.
You can avoid dumping grounds.
You see this most with any settings dialog.
and in some rushed UI designs where widgets are sort of thrown into a big pile because nobody knew where else to put them.
Dumping grounds indicate poor cohesion in your workflow.
Maybe you're not clustering things quite appropriately.
You are at risk of users having to do lots of parsing and scanning to find the things that change the behavior they're interested in, if they find it at all and don't give up.
And the bigger these get, the harder they are to internalize, and the more likely users are to ignore them.
So pay attention to how you group things in your user interface.
Pay attention to offering searchability and filterability and things where long lists are the rule of the day.
We see this good trend in a lot of settings dialogues you're probably familiar with, like ReSharper lets you search for settings, iOS, Chrome.
We're seeing it more and more and more.
You can understand the before and after.
Users may already have previous steps and next steps in the front of their mind as they're working.
They might have context switched into your workflow, and they're very likely to context switch out of it.
So consider, where is that attention coming from?
Where is it going next?
Are those contexts easy to switch between?
Is the user having to do any mental gymnastics or heavy load conversion in order to sort of ship their mental map from one context to another?
If so, is there anything that you can do to help?
Can your workflow or some software integration help ship meaningful data between contexts?
Can your proprietary tools send data to the DCC tool so that the user can avoid a big export-import workflow?
Probably worth it.
You can ask yourself what bigger task, what bigger creative goal maybe is the user trying to accomplish?
Because that may affect the inputs and the outputs that they either have or that they want that your workflow may have to produce.
Talking to them is really good for this.
In the engineering section, which is general guidance about sort of some of the implementation details that we find are really helpful, You can practice defensive engineering.
Consider the potential for abuse, because users are always looking for the paths of least resistance.
One tools developer at VV was always fond of saying, it is amazing what content creators will put up with.
And I'm sure a lot of you know what suffering in silence means.
Scott Meyer is a famous programmer.
He had some really good advice for people who were building interfaces in code.
He said, make interfaces easy to use correctly and hard to use incorrectly.
And I really like that.
I think it applies really well to workflow design as well.
Because if it's easier to do something, if it's easier to do something the wrong way and still get the same result, you should expect that your users will find and converge on that way.
They will tell their friends.
they may find shortcuts to circumvent certain validation processes in your tool.
We had a problem for a long time where users would modify game data in Notepad after a bad merge because the workflow for doing it in the tool was harder.
That's a problem we had to solve.
Whenever flows get bad like that, it increases the likelihood that users are going to look for shortcuts, and it's always happening.
You can avoid exposing everything.
This is similar to dumping grounds, but this is more about focus and reducing demands on users' attention.
There are more knobs and dials in a modern game engine than any individual user is going to know what to do with.
And what we've observed is that when users are confused, they'll just start probing the UI.
They don't know what anything means.
They'll just start clicking buttons to see if they can elicit a response from the game or from the tool.
Eventually, they're likely to get confused and into some confusing state, and they probably need help getting out.
So, it helps if you reduce your UI to only that subset of controls and knobs and dials that users need to do most of the job.
80% of your users probably only need a subset.
That one user who really does need access to the texel blending function on the fourth technique in the pipeline, they can go to a different part of the UI, maybe an advanced dialog or something like it.
Avoid relying on tribal knowledge because it is a fallacy that most users will know the right way to do something.
When faced with this situation, it really hurts their confidence.
They'll literally start asking questions like, what do I do next?
Is this going to work?
I don't recognize any of these terms.
I don't see any meaning here.
How do I make this do what I want?
Especially for engineers who are working with other engineers, tribal knowledge sometimes includes what you shouldn't do.
Consider any engineering trap in your code base.
that everybody at your studio knows how to avoid, knows that it's there, knows to step around it.
Now you partner with a different studio and there's no documentation and the other studio doesn't know that that pitfall is there.
VV has been on the giving and receiving end of that particular relationship.
It is no fun.
I had a really hard time finding a visual aid for this slide, but I did think this was fun.
This word cloud is all of the names we ever gave to tools in the Alchemy tool set prior to laboratory.
Can anybody tell me, current VV employees don't count, but I'm curious to know if anybody else here, can anybody tell me which one of these is the visual effects workflow or the world building workflow?
You can.
What?
Nope.
You can tolerate surprises.
Do what you can to tolerate the kinds of surprises that can cause people to lose work.
Laboratory has really good fault tolerance.
It has autosave and recovery.
It has process isolation to make recovering from crashes faster.
Fun fact, autosave and recovery was motivated in no small part by our studio's propensity for power outages.
They know what I'm talking about.
Consider content models.
This is a kind of put yourself in the user's shoes kind of guidance.
Understand what content concepts your users are expecting to work with.
Jacob Nielsen is a researcher with the Nielsen Norman Group and for years he's been doing usability research to try and make the internet easier to use.
And in one of his articles, there's a really good quote.
It says, the system should speak the user's language with words, phrases, and concepts that are familiar to the user.
rather than system-oriented terms.
And I think this applies to workflows really, really well.
They ought to speak the language of the content creator, right, not the language of the system, the engine for which their data is being produced.
I think we can introduce a concept here called content model that means the concepts and the relationships with which users express content ideas in your workflow.
Basically, it's a metaphor in which they work.
So for example, Level Builder's workflow exhibited a level, layer, group, object content model.
It's pretty straightforward.
And all the users could tell you what it was.
And it mapped very well to the way that they thought about the content they were building in the level.
Another example is our cinematic builder.
I believe that good tools and workflows should abstract away engineering complexity at every opportunity.
And they should fill gaps so that users have less mental mapping to do.
This UI expressed a visual effects queue as a resizable rectangle on a timeline.
You could drag the left side, you could drag the right side, and you could shift it in time.
But underneath, a visual effects queue is modeled actually as an array of spawn and kill keyframe objects that are inside an array, which is inside another array.
The two instances are in no way related to each other.
It's purely up to the tool to make sure that they make sense.
This was confusing.
A preceding workflow took a much more literal approach to presenting that engine data, those engine structures, and make the user think about them hard, which meant that users could put the start keyframe after the end keyframe.
It meant that the start and end keyframes were shown on separate tracks in the timeline.
And most of this was because our engine was reflecting over the data structures just automatically.
We simply didn't build a custom UI until then.
Good workflows that keep users close to their content will allow users to concentrate less on the runtime's demands and more on the content that they're building.
There are at least two really important representations in a workflow.
There's the runtime representation, and there's the user's content model.
So if you think of those as two opposing extremes.
If you, as an engineer, can minimize the distance between those two representations.
you will have saved yourselves a lot of complexity.
I call this category creative mindsets.
And my goal with this category is to capture benefits that are hard to quantify, but still have an observable impact on user satisfaction.
You can call it touchy-feely ROI.
I also want to reinforce some common sense that I think is easily forgotten or overlooked when you're in the trenches trying to build software.
But I also want to inspire, right?
I want the people who read these guidelines to come away thinking, I never thought about it that way.
There might be some good ideas here.
Invite your engineers to apply their unique expertise to the creative process.
We'll start with promoting user confidence.
When a user is confident, they will try cool new things without fear.
And when they're not confident, they may avoid workflows altogether.
And they may tell their coworkers to avoid workflows altogether.
And they won't tell you that you've done this.
We've observed and we have been told that users work confidently when the tools are doing what they ask.
They can change their minds quickly, and they aren't afraid of breaking other people.
They aren't afraid of introducing bad data downstream that somebody comes and yells about them about later.
Because when that somebody comes and yells at them about bad content they introduced, there's a better than zero chance that they will have no idea that they did anything wrong, unless your workflow is good at pointing out those cases.
So here are some things you can do to promote user confidence.
make sure that undo and redo work.
This may be one of the single most important things for promoting user confidence.
Because when you think about it, undoing redo is more than just about correcting mistakes.
It's about what if thinking.
It lets people try things and then immediately discard that idea, right?
Or multiple ideas, Control Z, Control Z, Control Z.
It improves iteration time by reducing rework.
It reduces the cost of making mistakes.
And its importance even impacted our architecture for Laboratory.
It offered Undo and Redo as a service at one of the lowest possible levels you could go so that all plugins got the benefit of it.
It was actually hard to build a plugin for Laboratory that didn't feature Undo and Redo.
You can support source control.
This may not sound like a promote user confidence tip, but hear me out.
You can save users a lot of confusion mucking around in Perforce.
Because if you put yourself in their shoes for a second, imagine how much of their content state they are having to reconcile with the depot state if they are unassisted.
That's actually a really large mental load.
And especially if your data contains complex dependencies, and users need to remember that if they add this visual effect file, they must also remember to add this texture, and the texture binder, and all these other things.
Otherwise, the build will break downstream and people will come yell at them.
If they don't have any assistance, that's more likely to happen.
That erodes confidence.
It introduces doubt.
This was another case where our architecture was really impacted by this point.
Like undo, laboratory offers per-force integration at one of the lowest possible levels you can go.
It's pretty much automatic and plugin authors don't even have to think about it.
You can do rigorous data validation.
Don't allow users to introduce bad data downstream.
So for instance, you can probably guard against them exporting assets that have four billion polygons.
You can probably help them avoid adding a bad reference, a reference to something that doesn't exist.
Users might not know, though, what correct or safe is.
So you should expect odd input in your workflow.
If something's wrong, find it, and tell the user what is wrong, and tell them how to fix it.
That's important.
You can preview changes.
If an operation makes big changes, help the user see what's going to happen before they commit to it for no additional cost.
Give them an opportunity to change their mind.
You can do this before or after a change has begun.
And this is one example of what I'm talking about.
A lot of you have probably used docking systems, right?
And this one is previewing the change that you're about to make before you go to the trouble of committing to it.
Another example is in our Visual Script Builder.
When you splice a node into an existing connection, the tool shows you what's going to happen to the connections, unless you change your mind, or unless you bail out.
Laboratories Curve Editor had a similar feature.
By hovering over a button, it will show you what clicking on that button would do, if you in fact clicked on it.
You can show the path to safety when errors occur, because is there anything worse than not knowing how to fix an error?
Make errors helpful.
When they occur, do your best to recover gracefully, that is, guide the user back to a familiar state from which they are confident they can continue.
And if corrective action of some kind is required, be clear about those next steps.
Do they need to reload?
Do they need to restart?
Do they just need to try again?
Do they need to enter a different value or reformat their value?
Consider engaging users to give you feedback on your error messages.
And I don't mean type in what was going wrong when the crash happened.
I mean, show them an error message as a sentence and say, if a tool showed you this error message, would you understand what it meant?
And then iterate on that.
Mine feature requests for hidden value.
This is the guideline that I think resonates most with the people I talk to, both engineers and creatives alike.
You should beware of treating user requests as specifications.
By doing this, you risk incohesive solutions when several different engineers who have all been told the same problem offer different solutions and create a Franken-app.
It can result in band-aid solutions that leave root causes unaddressed and then lead to subsequent band-aids because the root cause is unaddressed, which leads to subsequent band-aids, etc.
And it can inherit bad practices from other workflows.
Learn to recognize opportunities when you can help a user in ways that might not explicitly match the stated request, right?
Or maybe it's in a way that they don't know how to ask for because they lack the vocabulary.
Mind you, you could be having new creatives, you could have veteran creatives who have completely different vocabularies asking you for different problems.
One of them might be coming from a different tool set where everything was completely strange and alien.
So if you ever hear somebody come to you and say something like, I want it to work just like After Effects.
or I want it to work just like Excel, you've probably got a communication gap.
You should probably dig a little deeper because it's almost certain that you're not getting the whole picture.
That's a very loaded kind of statement.
We assess our tools candidates partly on their intuition for this.
One of my favorite interview questions is to say, a user comes up to you and asks that you change the transform gizmo to be yellow.
And I have some candidates who will, without missing a beat, they will tell me where in the view model.
They'll go find the color of the gizmo, and they're pretty good about guessing where that is.
And they change it to yellow, and they submit a code review, and they're done.
And then I say, OK, now imagine that a different user comes to you and says they want it thicker.
Well, some of them will say, OK, well, we just changed the thickness.
I say, now imagine a user comes to you and says they want it bigger.
And eventually the candidates have a sort of aha moment and they realize that continuing on this track is going to give you nothing but a big, yellow, thick transform gizmo.
Because it's not the actual problem. The problem is that the thing is hard to see.
It might be hard to see because of what content is currently loaded in the world.
It could be hard to see because they have a super high-res monitor and it's drawing one-pixel-thin lines.
What we want, not what we have.
Getting to the core of that real problem is useful because it's going to cause you to rethink the situation, rethink the problem in more meaningful terms.
So talk to user, talk to your users and discover that additional value.
So you can try questions like this if you're ever stuck and you feel like you're not quite getting to the bottom of it.
You know, back up a step and ask, why is the user concerned with this at all?
I wouldn't have thought that this would be a problem.
Maybe there's a gap in my understanding.
You can ask, could we look at this differently?
Could we maybe make a more general solution that helps more people with similar problems?
Is this an opportunity to bring more value?
Straddle that line of premature abstraction.
You know you want to.
What player experience are they targeting?
Right, there could be a knowledge gap.
It could be that you already have a tool in your pipeline that does exactly what they want to do, and they just don't know that it's there.
And you should ask yourself, are there any potential bad habits, unintended consequences?
So if a user comes to you and says, I want you to change the default value of this field from one to a thousand, and you do it, have you blown a lot of budgets all of a sudden without realizing it?
Be careful, because that happens.
And this section is called Keep Users Close to Their Content.
We want creative people to see, hear, and feel what the player will see, hear, and feel.
Success here means making exploring a creative space easy and fast and rewarding.
We want to increase the time spent seeing, hearing, and feeling, and we want to decrease the time spent learning how to operate an interface, right?
Learning how to navigate a pipeline.
This can be done by helping creative people notice little details, showing them things in context so that they can appreciate it from a more player perspective, or by enabling them to broadly explore a lot of ideas or deeply explore just a few of their best ideas.
I think tools can really innovate here.
A good case, I think, is user-generated content tools.
LittleBigPlanet, Dreams, which they were showing earlier today, and then this.
Fantastic, I loved it.
User-generated content experiences are really cool, because when you think about it, they have one job.
And that is to make people feel like they are producing good, creative, coherent work reasonably fast.
I think there's a lot of wisdom we can draw from that.
I think that maybe these workflows might actually be participating in the creative process itself.
This is getting into some of that more aspirational territory.
We're going to keep going.
You can support direct manipulation.
Direct manipulation means making natural feeling changes directly to content instead of some intermediate representation.
So for instance, dragging a manipulator in a viewport rather than picking Geo in the scene from a list or something like that.
We embraced this with Crash and brought some direct manipulation to a workflow that didn't have it before.
To choose and adjust bolt points that visual effects could fire from, it used to be that you had to select the bolt point in a list first and then type in the adjustment you wanted to make to the bolt and then send that information to the game.
The many-step process.
Instead, we put manipulators right into the viewport and saved our users a lot of time and made everything a lot more intuitive.
You can pick things from a list, but to be more direct, you could pick something in a viewport.
You could apply a material to a selected object, or you could drag the material onto an object.
You could type the start and end of a range in two separate text inputs, or you could use a new slider that lets you adjust them visually in both fine and gross adjustments.
I think transform widgets that have the constraints, like xy plane constraints, axis constraints, that's a great example of this, right?
Because you get to choose the constraint just by nothing more than choosing how you begin to interact with the thing.
You should augment content, not obscure it.
Because if you want to keep users close to your content, close to their content, don't come between them and the content that they're trying to create.
A simple example, a trend I like seeing more and more, is instead of shading a selected object with some solid color, outline it so that you don't disrupt the texture, so that you aren't obscuring what the content creator expects to see.
Debug spew.
Try not to display tables of real-time data on your game if you can help it.
It tends to be really hard to read anyway.
We did this for a very, very long time.
And we got to a point where we wanted to think about this differently because it was becoming unmanageable.
So we implemented IamGUI in Alchemy and allowed ourselves more real estate.
We shrank the game down to a part of the window and used the remaining space to display meaningful instrumentation.
But then we thought, you know, we could do one better.
Our tool set, written in WPF, is a lot richer, and it's a lot easier to interact with, and it affords us more capabilities out of the box.
So why don't we bring the game into the tool set?
So we made the game itself dockable.
Users could dock the game alongside the rest of their workflow and get all of that rich interaction that WPF has to offer.
Augmenting might also mean visualizing information that's already there.
So for instance, one of our engineers built this really cool visualization.
Every time you jump, a graph appears, and your jump is plotted on the graph.
Alongside more numeric and explicit information and graphs that show the acceleration and the velocity, this allowed our users to iterate on the all-important crash jump much more quickly than if they had not had it.
And it allowed them to keep their focus on the game a lot more than they used to.
You can promote mixing board thinking, where I use the word mixing board to mean controls that blend and constrain many inputs into one or just a few results.
Approaches like this relieve users of having to maintain complex mental models of data structures and the dependencies between them and the rules that apply to them.
It invites them to play more with the result and try combinations safely with parameters that you get to enforce rules on behind the scenes.
All right, so you see this with character creators all the time, right?
Skyrim offers lots of sliders and numbers and Black Desert takes a more direct interaction approach where you can tug on the cheeks and tug on the eyebrows to adjust the way that your character looks.
But these are all mixing boards, right?
They're taking inputs and they're weighting them and they're blending them with influences in order to produce some result that is safe.
And unless you go to Monster Factory on YouTube, you won't get yourself into trouble, right?
You're going to produce something that works within the context of the game.
Some workflows support modifier stacks like Max, right?
I think of these as sort of modular mixing boards.
The result of one mixing board feeds into the next mixing board.
And you may have seen animation workflows that have a palette of expressions for a character's face and you're able to dial in amounts of expression by clicking things in the palette.
You can dial in a lot or you can dial in a little, but you're mixing the result of a mixing board, a rig.
You can promote copy-transform-combine thinking.
Now this is probably the most abstract guideline in the set, but it is a very concise expression, I think, of a very powerful idea behind some of the best tools that I know of, and I found it very inspirational.
Still trying to articulate it in guideline form, so here we go.
I was exposed to this first in a video called Everything is a Remix by Kirby Ferguson, and in it he asserts that these three steps, copy, transform, combine, are foundational to any creative endeavor.
But it's obvious to me that they have a certain special importance to content creation workflows.
You can help users explore creative spaces and stumble on new ideas by building workflows that excel at these operations.
Copying is foundational to content creation, right?
It lets you skip boilerplate work.
It's a branch and a thought process.
And it lets users rapidly create sets and repetitions that can vary independently or together.
It lets programmers create ad hoc checkpoints in their work, like shelving a copy of your files in Perforce so that you can return to later.
So things you can do as an engineer are support copy and paste operations for values, for selected objects, for most of the stuff that users can actually interact with.
You can support prefabs, instancing, or get the needle closer to a place where you can support those because they're not trivial.
You can support robust cloning of your data models.
We spent a lot of time defining very strictly what copy meant when you took a chunk of data in Alchemy, which could have a complex dependency web, and chose to clone it.
Questions like, how far in the graph do you travel?
Which instances do you break?
Which instances do you make unique?
Which ones do you keep?
Which references do you have to correct and fix up?
It pays off though, because it makes copying faster, and it allows you to do more with the content that you have.
It's also useful to infer bookkeeping and other metadata.
So if you're shift cloning an object, don't prompt people for a new name every time you release the mouse button.
Chances are the tool can probably guess at one, the user can keep doing what they want to do, and they can go back and rename things later.
Transformation is the next step in creating variation.
That's the vehicle with which we explore creative ideas, right?
And it typically follows a copy.
Sometimes users have a clear end result in mind when they make a transformation.
They know exactly what they want to do.
But other times they don't.
Other times they're just playing around.
They might be experimenting.
They may not have a clear intent.
It's a let's try this idea.
Tools can help infer things to make that possible.
So things that you can do are support randomization, support mutations of sets.
If you can do something to one selected object, it is almost always true that you should be able to do that to a selection of multiple objects.
You can get users to success faster by guiding their transformations.
You might infer snapping.
Google SketchUp is really, really good at this.
you can help users change content between compatible representations.
One of my favorite apps is a wireframing tool called Balsamiq.
And Balsamiq has this neat feature where you put a widget on your canvas and you type in some text to make it show things like choice one or choice two.
And then you can choose to transform it into a different kind of widget, like a label.
And if I choose label, it will change it to a label and it will keep as much of the text that makes sense for a label.
saving me of having to drag out a new label, copy in the same thing, or do something else.
It's just one of those little things, right?
Combining concepts contributes to uniqueness and innovation.
Things you can do here are show things that can be combined and show the user when things can't be combined.
You can accelerate combination with implicit edits like VisualScript's node splicing feature.
We didn't always have that.
It used to be that if users wanted to splice a node into a connection, they had to delete the connection, move the node, and reestablish the connections the way that they wanted.
This was a way to save time on that combination.
Transformation can occur explicitly.
You can move a vertex on a piece of geometry, but combination lets transformation happen implicitly, right, like procedural deformation.
I can move a vertex on the spline and the deformation driven by that spline affects the box.
Tools can interpret combinations in clever and meaningful ways.
They can choose to use as much or as little of the metadata underneath these constructs as they want to, or as it makes sense.
You can even give the user certain choices about how a combination is formed.
I think modifier stacks, again, are a great manifestation of these principles because they yield this really powerful idea, right, that you can combine the results of transformations in a sort of workflow.
I remember when I saw the MaxModifier stack for the first time and how profound it was to me.
Because I started to think that when intermediate transformations become parametric like this, that's awesome because it means content becomes programmable.
It means that variation becomes injectable.
And it's ideas like that that led us to take a modifier stack-based approach to our new visual effects system.
Our users got to choose what they wanted to contribute to the final visual effect.
They could insert variation.
They could take out transformations that they didn't want, and they knew the way we had visualized it that it was just a top-down flow.
You start up here, and things are applied in layers almost, and you go down to the results.
Nothing I'm saying are really new insights about copy, transform, combine, but I think that for people who are in the trenches, it might sort of be hard to grok this, to internalize it.
And so I think that guidelines like these can reinforce these really important ideas.
For techno-creative people, I think the real magic here, the thing I wanna shout from the rooftops, is that tools can combine things in meaningful ways.
I wanna go from two plus two equals four to three plus two equals more tree, right?
I think engineers can contribute a lot here.
Because engineers already understand a lot of these concepts and they're using a different vocabulary.
You understand polymorphism, you understand operator overloading and implicit type conversion and all that groovy stuff.
We're really good at making the incompatible compatible.
And we're really good at sort of content algebras, right?
Defining rules that govern how things can be put together.
And to keep users close to their content, I think we should give them fewer reasons to be distracted by it.
By making creation like this more seamless, I think making combination effortless, we can help users stay in their flow and stumble upon some really cool stuff.
That part was really abstract, I get it.
I do wanna recap though.
By promoting user confidence, by mining requests for hidden value, and by keeping users close to their content, we're trying to help engineers put themselves in that creative mindset.
We're trying to help themselves put themselves in the user's shoes.
We want them to understand some things that are probably come a lot more naturally to their customers than it does to them.
But through reinforcement, I feel like this is a skill we can cultivate in engineers.
This is VV.
I'm the guy doing the jazz hands near the back.
And that's all I've got, guys.
Any questions?
Oh, and this is for you, Heather.
We have time for questions.
I think about 12 minutes.
So, hi, great talk.
I'm definitely an advocate for what you're selling here.
When you're dealing with a tool set that's been supporting your content for a long time, obviously maybe five or 10 years ago you made some decisions with the interface and then you've rethought it and you want to make changes that will be improvements based on these guidelines, how do you, what experiences have you had selling that to users who may have become designers and creatives who have become addicted to the bad old way?
It is a process for sure.
It may be one of those cases where you have to rip off the Band-Aid and be careful about how you do that.
I actually attended a talk on Monday.
I confess I forgot who gave this talk, but they were talking about just this issue.
There are ways to safely, or at least with due diligence, rip off the band-aid for the better.
Other times, though, whatever the case, you should be talking with your users.
You should let them know that this change is in the works or that it's being thought about and they'll probably give you very good input on it.
Ultimately, though, I think that the change is something you sort of have to force of will it.
With enough demonstrations and enough talking with your users, I think you can probably help them see the light.
Worst case, you can add a chicken switch.
You can add an option that lets them keep the past behavior.
But I always caution people against doing that, because it means there's more to support.
There's more for support staff to be confused by.
And I think that it doesn't solve that underlying problem.
Because chances are, if you are considering making a fundamental change to somebody's workflow or their interaction model, I hope there's a good reason for it.
And I hope that that reason is something like, what it's doing now is actually at risk of producing bad content, or what it's doing now is actually costing people time, if they're not that one person who understands it and likes it.
Hi, thanks for your talk, it was really practical.
Thank you.
I have a question regarding that one slide in which you showed iteration of the crash Bandicoot jump with a graph in scene.
It really reminded me of a talk, a very famous talk by Brett Victor, I don't know if you've seen it, it was called Inventing on Principle, in which there was...
precisely the idea of visualizing and playing with data, not in a side editor, but directly in the scene or 3D view.
And I was wondering if you somehow managed to generalize that idea or apply it to more than just one specific instance, where you had to code for this one jump, this one graph, or if you found approaches to maybe integrate the data and visualization more often into the workflow directly.
It's something I would love to explore more.
I'm a huge fan of Brett Victor's work, by the way.
What we did with Crash there was actually, I mean, you know when Crash came out, it was actually relatively recent.
This exploration into more sophisticated visualizations is something we've only just begun to start exploring with any rigor.
I think that visualization is incredibly powerful, and I think it's sort of an untapped resource in a lot of tool development, because if you can get your engine to expose the data you need to visualize, then actually visualizing it is not really that hard of a problem.
I think that, well, first of all, have I answered your question at all?
Yeah.
Okay, great.
I'll stop there and let another question go.
Thanks at all.
Some great advice there.
Thank you.
I wanted to pick up on something you said fairly early on about how some of your, you had some examples where people had to sort of break out into notepad to patch up some game data.
And although it's undesirable, it's always the case that there are some features that your tool doesn't have and things that people want to do that your tools aren't capable of doing.
And so I was wondering if you had any advice as to how you sort of allow for users to escape the constraints of the tool in a controlled way so that they're not hampered by what they can't do yet.
I don't think we have a silver bullet, but I do think we have a solution that's helped in most cases, if not all.
Our tool, it was very important to our tool designers at the beginning of Laboratory that we offer a robust way to edit raw data.
Basically that meant reading a file and showing it as a property grid, a big property grid.
But a property grid that took all the hints from the runtime type metadata, like how to display this as a color picker, as a slider, whatever, and also took any validation rules that were in place and enforced them.
So imagine, I think the closest equivalent I can come to is like view source in a web browser.
It was sort of like that.
It provided a minimum viable interface around the job of editing data at just peaking and poking values.
I think that there is more we could do there, but it's not, I think that that was a good enough solution.
except in some cases where data got munged in an upstream process.
Self-healing is something I think we could do better there.
Okay, great. Thanks.
Yeah.
How do you find the balance between the need for creating new features and the need for improving what you have already and make it more usable for users?
It tends to be based on a project by project basis.
It's often the case that we will look to the project that we're working on, and of course, things that are going to bring value to that project get ranked higher in that list.
At the same time, I feel very fortunate that VV is a studio that has that horizon on its mind all the time, and with enough rigor, with enough due diligence, it is possible for an engineer to make a pitch for a longer-term feature, one that might extend beyond the value of this project.
It always involves impact.
We want to know what impact will a change have.
How many users is it going to affect?
How much time is it going to save?
How much time is it going to take to build?
And then we try to prioritize based on that.
I try to blend.
I try to avoid the tyranny of prioritization, where you only work on what is item one in the giant tools backlog that lasts forever.
I try to do a blend of big things and little things.
I try to make sure that some of those priority threes always get attention.
I really believe that it's the little things that can make a big difference.
But I just got an email from my tools engineers who said, we cleared out all the priority one bugs in the sprints backlog.
I'm like, great job guys, that's awesome.
Now they can work on some of the others things.
We kind of play it sprint to sprint.
Hi, so kind of building off of the same question or the previous question, at what point when you're looking at workflows, you've already shipped it, but you realize that the workflow that you've designed is actually not exactly how it's actually being used by your users.
As you're getting feedback, how do you determine where that line is between whether or not you should actually make changes?
which would actually cause users to have to change their habits, and we potentially learned a workflow, and determine whether it should actually be an actionable improvement.
I think that if you can boil it down to a measurable positive impact, you've gone a long way in sort of making that case.
Depends on who you talk to.
Some people are more conservative about making changes to workflows that are already in circulation, already in the field.
Others are a little bit more aggressive and are a little more comfortable with ripping off the Band-Aid and just telling users, look, we understand this may be disruptive, but.
We use our professional expertise to tell you that this is going to be for the best, based on what we've learned, what we've talked to you guys about, and what we understand about the problem.
If you don't think that our understanding is complete, please come talk to us.
But other than that, we're going to change it next sprint, unless anybody tells us not to.
I don't think that the line is really very clear.
I think it's very much a case-by-case basis.
And it depends on where your focus is, where you want your team's focus to be.
If, like me, you are leading a group of tools engineers, I have found that they tend to prefer to focus on one area rather than make bunches of changes in lots of different places.
And so if our focus is in that area and we feel we can make a dent, that's something we'll explore.
If their focus isn't in that area, we may wait till another time, just so that they don't have to do as much context switching.
Does that answer your question?
Yeah.
Okay.
One minute, two minutes.
Can I just follow up in that case?
Yeah.
So let's say you do have to make a change, do you do anything special to actually heard or I guess navigate your users through the changes they have to make in their workflows?
And if you do, do you have any tips for that?
The best tip I've ever given anyone was bring them over to your desk.
He hasn't gone to lunch yet, let's go get him and bring him over and show him what it is we want to do.
I'm a big believer in proof of concepts.
Show me the change you want to make.
Mockups are great.
Working software is better.
Verbal descriptions are almost never good enough.
We have to be able to feel it.
We have to be able to use the mouse, use the keyboard, and make sure that this makes sense up here and not just on paper.
The users will give you that feedback and it's going to turn into a discussion, but that's okay.
They may need more convincing, they may need to understand more about the problem, and your engineers might too.
Fair enough, thank you.
Thanks.
Bye guys.
