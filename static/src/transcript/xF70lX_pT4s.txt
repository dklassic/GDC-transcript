I'm Claudio.
I work with interaction design and AI.
But today I'm going to talk to you about a VR game I worked on last year.
And we're going to talk about UX.
For this game, I cover the role of principal UX designer.
Just for clarity, it's not going to be about UI, UX, but it's more like the type of experience that's around how the user, how the player is going to use their hands around the environment and playing the game.
So it's a concept which is more akin to what some people saw like like calling spatial computing and things like this and So like I was going to talk about how to use some theories from cognitive science To actually make these interactions and those experiences more engaging and more compelling So the game is called In Death.
It's a VR game.
It's an Icelandic production.
It's been produced in Iceland by a studio called Solfar.
And with the help of RVX Special Effects Studio, we're all based in Iceland.
And it's been released across the major VR platforms, like Rift, Vive, and PlayStation VR.
It's a dungeon crawler, classical concept.
It's based in the afterlife.
So you are in this environment.
There's a lot of creatures that try to get rid of you.
And you've been equipped with a weapon, a shield, to make your way through it.
There's no specific goal.
You just have to survive.
And you have to go through the game until you reach the final boss.
And eventually, you win it.
And then you start the game again.
But this time, it's more difficult.
So.
you have to survive it, the concept is like pretty classical.
What makes it different, what makes it unique is the fact that it's immersive.
It's using VR, so you are immersed into this action.
What does that mean?
It means, for example, that you don't have a button for strafing and dodging projectiles.
You literally have to lean left or right with your body to avoid incoming threats.
Or you can use like part of the environment to hide yourself, get cover.
and like, you know, get some tactical advantage.
It also means that you don't move the camera smoothly.
Like we rely on teleportation, like many other like VR titles for comfort reasons.
What we did here though, like for this game was to try to fit the teleportation into the narrative of the game and like giving the player a special harrow that you can shoot with the bow that like it's gonna teleport you to a certain destination, which is the point where the harrow landed.
The game is designed to be very hard.
So there was a conscious choice of design, which is good because it allows a certain amount of replayability of the game if the player really gets into the challenge.
But most importantly, I think it's pushing the player to actually achieve mastery of the weapons.
Mastery of like marksmanship into using the bow and become really good at handling the weapon and becoming better and better since like the game is so hard, the only way to make it through is to become like really accurate with the shooting.
But also understanding architecture and understanding what could be a way to actually gain a tactical advantage by leveraging on the shape of buildings and how things are laid out in the environment.
Also by using teleportation in a smart way.
So this idea of mastery of the weapons requires an attentive design of the interaction of how the person, of how the player interacts with this object.
So as I said at the beginning, I worked on designing the hand interactions for this VR game, which in a game like this mostly means the way in which the player handles the weapons.
because this is a type of like hand manipulation that the person's going to go through very often, like on a second-to-second basis, especially in combat situations the action becomes really frantic and has to actually be able to control those weapons and handle those weapons accurately and have a sense of control.
So definitely like the functionalities of these weapons have to be there.
You have to have like the player, like we wanted to have the player experience a sense of becoming better and better at using those objects.
But was also important to me like a certain kind of fun.
So an engagement, like designing the interactions that were like engaging and they were like an intense experience of like combat like visual experiences.
Designing weapons for VR is different than designing weapons for games.
And it's important to understand why. It's important to understand where really lies the difference here.
So if you go on YouTube and you search for a video of a game or a VR game, you hardly see the differences between the two.
If you're looking at what's happening in the virtual world, they kind of almost look like the same.
But the big difference really lies when you actually look at the people.
What people do when they actually play these experiences, it's completely different.
In games, the posture is like quite static.
And usually I see it.
But what's important there is that you're holding a device with buttons, and what you actually move is just your thumbs, and that's the beginning of your interaction.
Something meaningful happens when you move your thumbs on the button, and whatever is meaningful, it's a feedback that gets bounced back to you through the screen.
So the person keeps looking at the screen continuously.
So the head is fixed.
In VR instead, There's like a way larger set of movement that a person do when it's inside these experiences.
People can be standing or moving around.
But most importantly, there is no screen.
The display is attached in your head, and you can literally move your head around.
That plays a big difference in the interactive experience.
And also like you like move your hands for performing certain interactions in environment around you. So there's a big, big difference in terms of experience here. So like, like, like what's what's like the real difference? What's really different about it too, if we think about it, is the motion space that we allow to the person.
So, like in games, which are interactive experiences, we have a very small motion space that's allowed to be played.
It's like you move the times over the buttons and things are happening.
Compared to other type of interactive experiences, for example, like face-to-face social interactions, not the kind of social interactions we do on Facebook, but face-to-face.
It's still an interactive experience. It's still like something interactive that we do with others which is meaningful But it requires the use of our entire body. I think you know body language for example you can rely on like entire spectrum of movements that your body allows to actually to actually like like make meanings with others What does VR lies in these pictures like something in the middle so they're like the movement space is like larger compared to the one of games but you know is this is this actually like lending itself to the same experiences like having having having like like the player being able to move more doesn't mean that we can actually think of those game in VR in the same way in which within games in the screen.
So the practices and the guidelines are really the same.
VR games tend to be more kinesthetic because of this.
And the fact that we have a larger box is not obviously a better or an increment in the experience.
It needs to be leveraged in the proper way.
So like back to weapons like if we now we have those type of like larger space of body movements which allowed to player and can manipulate things.
We like with their hands.
Like how are we going to design those weapons like off like obviously the guidelines that we use for games might not actually quite fit here because we have like you know the player moving hands and manipulating handling those weapons correctly.
So, like, how can we do that?
We need to think differently.
We need to think about affordances.
We need to think about how those objects are shaped and what kind of forms they have so that they can actually inform a person how to use them properly.
So affordances are important.
Like, good design is invisible, but bad design is pretty obvious.
When the affordance is not working for us, you can see it right away.
So affordances are important to actually name the functionalities of those objects, for us are the weapons that we focused on.
But how can we connect this to the fun?
And that's where it came to quantity science.
Like central to the design process, that I'll follow on, was the idea of embodied condition.
So it's typical to think that the mind affects the body.
With embodied cognition, we allow ourselves to think that body movements affects our thinking.
So for example, we can look at what happens with dancers.
Like dancers, they learn choreographies to actually perform and make a performance.
Learning a choreography takes a long time.
It's quite complex in terms of model coordinations and everything.
But they actually develop a trick.
They have a technique called marking.
that they used to learn choreographies much faster.
So marking, it's not doing the choreography, it's kind of like sketching the choreography, like performing movements that kind of mimics the choreography without really putting the full energy into it.
And that's like the way in which they learn choreographies like much faster.
By moving their body, they actually influence their learning.
We can actually see some research done by David Kirsch that's been looking at the way in which dancers are performing those markings and performing those movements for facilitating their learning.
And that's exactly what I found out, that by mimicking the choreography, they were able to actually learn it much faster than doing the choreography full out, full force, or even just thinking about the choreography.
Like what turned out that was helping them was like mimicking the movements, help them like to actually build a temporal model or a mental image of what the choreography would have been, like kind of like lay itself out in time and space and how to coordinate with others.
So the idea here that we had was to leverage the same concept and think about what is the choreography that the player is doing when he's actually moving her hands around his weapons?
What is the performance that the player is actually doing?
And the idea here is that the performance is a role model.
It's a hero character.
So the player is not only just operating those weapons, but it's also kind of like, as it does that, it moves in ways, if you design the weapons in a certain way, you make, the player moves in ways that, it's kind of like enacting a character, enacting a certain hero role model.
Which is like an idea akin to this marking that dancers do.
And role-playing, it's fun.
So central to our design process really was like, how can we make role-playing out of hand movements?
How can we design or think of the way in which the player moves his hands around those objects in such a way that that becomes an act of role-playing?
So overall, the picture was something like this.
Design affordances for those objects that makes move, like a person operate those weapons in the best way.
And the interaction with the weapons elicits the movements.
The movements is acting out.
It's similar to acting out the hero characters, but at the same time, it reinforces the idea of performing really well, or performing on top of certain, like out of the ordinary, through those weapons.
So, making the affordances for the objects, it was really important, we needed to make those affordances really well.
The first approach, the first temptation would be to actually copy the affordances from the real objects and translate them into the virtual world.
that doesn't work out of the box.
Like the reason why it doesn't work out of the box is because we all kind of understood this, like you know, the vision of VR, this idea of a vivid dreaming, like some kind of like manufactured reality where we impact the senses.
But like, the reality, like this reality we have now, the essence we have now, that allow also to do like a minor reality, a minor version of this vision.
So the question really becomes like, how do you project real objects into this minor reality that we have at our disposal?
But because objects and affordances are really meant for the human body, the deeper question becomes, how do you see the human body projected into this minor reality?
Because we need to understand that in order to make affordances for this.
And that's the way in which we look, that's the way in which the human body looks inside like a man of reality.
It's a VR monoculus with a head and two ears and not even eyes.
They're actually kind of binocular holes, which are quite different.
And we don't even have hands.
We have some kind of punching gloves in there.
And that's what makes a big difference in terms of affordances, because not having fingers and having palms, it uses a lot of our ability to explore our surroundings.
So the real question becomes, when you think about making anything that's like hand interactions in VR, how do you design an object for this creature?
Because if you think about objects that we in real life, those are designed for our body, but now we have an embodiment which is different.
How do you design an object for this creature?
How do you find out?
But the only way for us, or at least in our approach, the way that we actually move forward was surprise prototypes.
You just have to fast prototypes as fast as you can, like make as many prototypes as you can to actually get a sense of what responds, what works for this VR homunculus.
But also very important to use user testing as soon as possible, like prototypes alone, like that's only up to a point.
You need to see other persons like jumping on board with those prototypes and see how far they go with that.
It's important to prototype.
I experience it is important to prototype as soon as possible, but not too early.
Like, you know, bad ideas, it's like, better we adjust them.
So our approach was like to kind of like user test internally and then like open up to other user testers.
But like fast prototyping, it's been instrumental.
It's been important for us also to think of these weapons like props.
in the same way in which stage designers or people that work in theater think about props for actors, objects that are not really meant to work in certain ways but to suggest or elicit a certain way to act around them.
And what also we found out was tremendously valuable.
The prototypes became a communication tool inside the team.
It was the best way to talk about VR interactions for us.
Sometimes it's kind of complicated to talk about what will happen in VR.
And you might write down, you might have pictures of animations.
Sometimes nothing really works.
You just have to have actual prototypes within the actual VR space where you see how things are unfolding.
So let's look at the bow and let's look how the real bow translates into a bow for the B.R.
Moleculus.
How does the object change?
So a real bow, it's an elegant, minimal design, but it's also quite sophisticated.
There's a number of parts which are important for us to actually handle it properly.
There is a grip.
There is a harrow rest, which is where you place the harrow.
More importantly, there is a serving, that area that you see over there.
I don't know if you can see the pointer, but there's an area there where you can actually grab the string, pull it back.
That part, which is actually quite thin in reality, in visual reality it became thick and really, really long, as long as the string.
So it became kind of bulked up.
Instead of having like a grip, we have to replace that with an attach point, something that gets attached to your hand.
And something really important, because the VR Monocle doesn't have really eyes, they have like two binocular holes, we have to cut short and make the arrow appear as soon as you grab the knocking area.
Because that was helping the person to have a straight line of sight.
Because we wanted to actually have the person to actually achieve this idea of becoming better and becoming a master of shooting accurately.
So that really helped to keep this straight line of sight.
As much as it was helping, the other idea that we had to do was constraining certain worst orientations.
like, like, there are ways of twisting your, like, your hands that, like, have been disabled where you actually control the bow, so that, like, the arrow get placed into line of sight, which is constant. So you constantly get reminded of what's, like, your line of sight. You can actually get into flow of using this bow quite fast and quite quickly. The final result was something that lends itself to be used in combat situations, also, like, when there's kind of, like, a frantic moment.
And like, the player can actually shoot accurately, can get a sense of like becoming better, a bit more accurate.
But it comes to do like stuff that you wouldn't do with a real bow, for example, shooting horizontally.
That's something that like, it's connected, this idea of like enacting the use of an object so that you think like you are a hero.
And that was pretty much what we did for the bow.
It was important also to keep a consistent interaction, like design the object so that the player could keep a consistent rhythm of the interaction.
And that's pretty much what we did for the bow in short.
For the crossbow, it's a little bit more complicated because the crossbow is more recent as an object.
There are many different variants, so we went into archives of museums and some other connections I have in Italy to actually study different variants, different crossbows and understand the various mechanics and what was the advantage of others compared to others.
In general, the idea of the crossbow was to be able to load a bolt fast, so fast firing was the reason why they were invented.
In my research I also find something...
Quite interesting, I discovered that Leonardo da Vinci prototyped a crossbow, but just on paper.
It was never realized, but it was like an automatic, like kind of like something you could load quickly.
So there's this artisan in Italy who actually made it, this following the blueprint of Leonardo da Vinci.
And it's a crossbow that is cut in half, so you can open it and it loads automatically.
So the idea was really rapid firing.
What we did for the crossbow was to think about how to fuse all these characteristics of different crossbows from different eras and try to fuse it into one object that we thought could be representative and different from the bow.
in the way to use it.
So we went through a number of prototypes, like modular prototypes that we build quite quickly out of gray boxing and like modular parts that you can interact with.
We started by having like an handle on top and then looking at people and how they were responding and how much they were getting into the flow.
And then we moved the handles to the side.
just to see what's the difference, if it was better for aiming or not.
And then we even went as far as putting some kind of lever type of interaction here and kept looking at how people were moving and what we're doing.
And the final version is this one over here, where you can grab the string and pull it backwards and it loads immediately.
So if you become really good at doing this movement, you can actually shoot and reload it very fast.
And then you can also grab it with two hands and do some more precision shooting.
So that's what concerned looking at those objects in the virtual world.
But it's interesting to look, as I said in the beginning, to look at how people responded in terms of movement.
And this is actually the marking of the people mimicking like a certain character through the use of that object.
So design the object so that people can move in certain ways when they were actually using it.
And it's also important here to actually think about fatigue profiles.
Like, since you design an object that gets used, that kind of like, you know, make people move in certain ways, you need to think about what kind of muscles get involved in there, and try to actually make fatigue profiles which are orthogonal between these two different objects.
You can also see how the movements are not necessarily the same movements that we would do with the real objects.
They're like sketched.
But nevertheless, they are enough to actually build a mental model of what's happening inside the virtual world and what's happening when they are enacting into those objects.
Another thing that we did that was very important was to parameterize the affordances.
That was key for us because we didn't have much time to do user testing or formal user testing, so we had to go fast, try to iterate as fast as possible.
So what we did was to organize the affordances into a number of parameters that we could actually tweak and change right after every user testing.
So user testing was an occasion to observe people, but also to mold those values around what we found out was more or less comfortable, more or less easy to actually get working for the players when they were trying this.
Also, once again, those parameters helped a lot as a communication tool, because it helped us to have a meeting where we were focused on certain ideas and certain concepts, so they really worked as a form of information architecture, provide us a vocabulary to talk about what we saw during these user experiences, during user testing.
Something that was also very important that sometimes get overlooked was active feedback.
They put a lot of effort into trying to actually get it right.
Why it's important? Because active feedback is a way to highlight a rhythmic pattern of the interaction.
Also, VR tends to be very loaded on the vision.
It tends to be visually very loaded.
So to actually provide feedbacks in a subtle way through vibrations is actually a good thing.
It reduces the current load on the person.
But for example, let's look at the bow, at the act of shooting the bow, and how the active feedback comes into play to actually define or reinforces the idea of a tempo of the interaction.
Reinforcing the idea of a certain rhythm, and getting into a rhythmic pattern as using this object.
That's achieved by providing an active feedback in key moment of the interaction.
like when the player touches the string, first you get a first impulse, then you get a longer one when you grab the strings, then you get a progressive one when the string gets pushed backward, and then you get a shake.
So all of those active feedback are there to actually mark a tempo in time, that in turn gets the person into a repetitive flow of movements and getting into the repetition of those movements like in a form of a static of interaction.
Something we didn't realize early on when we started working on the two weapons, especially because the crossbow, as an idea, came further down into the game, was that the two, like these two weapons, like in games when you add a new weapon, it's like adding more to what you already have.
But here it was really about adding an extra object.
And also demanding the person to actually re-learn a new set of movements.
Because the handling of the two objects is different.
The bow is something that, let's say you hold with your left hand and you operate it with your right hand.
The crossbow is the other way around.
You hold it with your right hand and you operate it with your left hand.
So, like, when you tend to use one object, you build up the muscle memory of that object, and when you switch to another weapon, the muscle memory doesn't work anymore, you have to relearn it.
And that's, you know, it's a bit different, like, from games, where, like, ultimately all the weapons really, like, you know, it boils down to pressing buttons, like, at least like a sensory motor level.
But here it's different.
So having new weapons required new conditioning and effort.
Something has to be considered that we did not consider first, but then we kind of like crashed onto it and we had to work around it.
But the good news was that we found a way to interpret these differences.
And instead of looking at them as two different weapons, we started looking at them as two different classes, two different ways of playing the game.
So they were like two different gameplay styles.
And when we actually started looking in that way, everything became like, in a way, like more productive in a sense that we could see how we could imagine two different communities of players forming out there, one that prefers the bow, another one prefers the crossbow, and start kind of like competing each other out in performances around the idea of like designing, like designing objects like in a different way.
So here's where we had to go through a very intense user testing session that was done remotely.
Because at that point, the game was already in early access, so we got a few very dedicated players on board.
They really wanted to test the new additions, one of which was the new weapon.
And at the beginning, they hated it, because they were super good at playing the bow.
And then suddenly, they have to relearn the things from scratch, and they didn't like it.
But there wasn't really a way to be able to operate the crossbow the same way in which you operate the bow.
It's like they're two different objects.
You can't really manipulate them in the same way.
So by doing something I've never done before, like some...
like remote user testing through Slack, we were able to actually like work really well.
They were like incredibly passionate about the game, so they start like commenting and talking to each other how it works and what not, and that was like very good for me to keep a track of all those conversations.
And also what was really important was asking them to send me video recording of their play sessions because it was really hard to understand, or it was really hard to read through what they were actually experiencing.
It was important to see what was happening really in the game.
So that was something I didn't expect to work out.
It could have worked out, but it worked out pretty well.
So just to conclude...
forget any rules about like practical, practical like trigs or practical like rule of thumbs here.
Technology is changing.
As the technology is changing, the VR monoculus will look more and more like a person.
So the affordances will be different.
Like what's really a takeaway is not about how to do things in the details, but to keep looking at people and keep looking at how people move.
So not only focus on what's happening on the screen and what's happening in the virtual world, but look what people do, because that's where part of the fun is coming.
Part of the fun is coming from making an experience which is kinesthetic and fun in a kinesthetic way.
So in a sense, like practice dancing, in a sense, like reconnect to your body, like rediscover what's fun to do with your body, in a sense, because that allows you to connect to this idea of making beautiful experiences through body movement.
And that concludes my talk, and I'm open for questions.
Thanks.
Yeah.
I have a lot of trouble using haptics in VR, and especially when doing the up and down modulation that you showed in a graph.
Can you share your technique with making that happen?
Technique.
Yes, so the graph I showed is a very crude representation, because haptic is like frequencies and amplifications.
But what I did was basically having a similar approach to motion design.
So I made a way to actually modulate the haptics through a couple of parameters.
And then I tweaked them until I was getting a response that I thought was actually good.
And then I also created different categories.
There's something that I call the haptic click, that mimics a click, or it's kind of like a soft, rhythmic feedback.
And then another one which is thicker and longer.
I don't really know a better way to describe it. It's a bit like describing sounds.
like taking it longer. And then like I remember something that worked really well. It was like the shake on the bow. Like it's an up to feed, but it just like shakes like this.
Like it kind of like gives you the idea of like.
like energy that gets released into the object.
But the main concept really that I wanted to show was really try to place it into key moments of the interaction.
Like try to imagine the interaction almost like a dramaturgy.
And try to imagine what could be the point where you want to make an emphasis in the tempo.
And that's at least what I found out was the most effective way to do it.
And then of course the user testing.
Sometimes I overdid it, I put too much of it and it was getting confusing.
So as a little term, like in music, it's better to just be conservative and not add too much on it.
Thank you very much.
How closely did the design of the UX elements that you were just demonstrating tie in with the UI elements?
For instance, the little bar that you can see on the bow, on the other hand.
Did you guys experiment with using UI elements that were, I guess, more attached to the camera?
Or was it an immediate thought that we're just going to have diegetic UI design and have that as part of the props themselves?
Yeah.
Thanks.
That's how to recap on this.
This, it's been like, we didn't want to have UIs on the camera at the beginning, even though I was one of those pushing for it, like, to have some of this information on, you know, attached to the camera.
So the health specifically ended up to be, like, in the bow, because we kind of wanted to have it visible as you were shooting.
Other type of UIs maybe, that I never thought to go over here, was how you actually select the arrows.
Because...
I didn't mention that you can have like power up arrows and all these kind of things.
And like you can carry those arrows with you in some form of inventory.
And that was kind of like a more challenging UX UI type of thing.
Because at some point we tried to work it out in a way that was user friendly.
Let's put it in that way.
Try to have it like with smooth animations and everything.
But then it really broke against the fast-pacedness of the game.
When it was getting really fast-paced, and when it was getting really just intense, that was just in the way.
So we stripped it down to something much more basic that literally appears and disappears.
But what we did was to play with time.
And actually, we did time dilation.
because the action can be so frantic, and you might feel actually so overwhelmed with everything that happens around you, which is kind of threatening.
We basically slow down time every time you open any of those UI for selecting arrows.
It was thought out to be a way to help the people to actually select the arrows properly, but then it became a trick the players exploited to actually do better.
you know, the game. So, you know, it turned out in those ways.
So there wasn't like, just to recap, like we didn't really did like a very intense thinking about like where to place, like the UIs, we knew that we wanted to minimize it as much as possible and really just make it about like the action.
And in fact, we, like the only kind of like UI augmentation we did were the one that you see there, like the health plus, like the selection of the arrows.
Thank you.
Thanks.
I have a follow up question about the Haptecs.
So did you design them as audio waveforms that are parameterized so that they change procedurally?
Or did you do something else for that?
No, I wanted to design them as sound waves.
There was no time for that.
So I designed them as animation curves.
that they were just like bound between zero and one.
So they were like normalized, but then you could add parameters to them to kind of change them in terms of like length, amplitude.
So those are the kind of parameters that I was changing.
So probably there was like a better way to make it like more refined in terms of active feedback.
I'm pretty sure like if you talk to someone which is very expert of active feedback, can tell you like a much better way to do it.
For me, from the point of view of the interaction design and the general UX, it was important to nail that concept of rhythm.
Like, when do we want to have them?
At what point of the interaction do we want to have them?
And it's like, what types of active feedback do we want to have?
How long it is, how intense it is?
As I said before, to classify them into things.
But I was really keen to actually try the sound waves and see what would come out of it.
I don't even know if the controllers that we have at the moment are actually responding very deeply to this kind of sine wave optics.
So I was actually wondering about that too because I've been struggling with the same kinds of things in optics right now.
And Oculus controllers versus the Vive controllers have very different haptic profiles.
Did you do custom curves for both of those?
And do you actually have amplitude up and down kinds of stuff in your animation curves?
Because if you just drive a single animation curve, it doesn't really feel like anything, at least in the experiments I've done.
Yeah, we did.
Mostly, they are the same.
like optic curves, let's call them that way.
Mostly they are the same, but in a few occasions I remember we have to actually make them different for platforms.
So, because like the vibe is very different.
The Oculus was much better from this point of view.
It like give you a much better response.
Also like in terms of kind of like identifying a different type of optic, you know, in terms of like, you know, how long was the optic click or the intensity of it, that really was better.
But yeah, all in all, we actually kind of like moved kind of carefully around it because we didn't want to overdo it, but also like we didn't know how far we could go with the platforms we are in.
So we took it like little by little, adding like, you know, little by little every now and then and see like if it was improving.
Thank you so much.
Thanks.
Hi.
Thank you so much for your talk, by the way.
Yeah.
So I found it really interesting.
You know, you mentioned the remote user research.
I found it really interesting how you were able to get your users to collaborate within their group.
Can you talk to how you were able to set that up and how you found the users, how you facilitated the channel?
Yeah.
About the collaboration, I have to say we were lucky.
They were just talking, they were out of passion, they were just talking about themselves.
We set it up as internal beta testers, officially they were internal beta testers.
But then I recruited them into the user testing of the crossbow.
The way we did it was simply by releasing the prototype of the crossbow into the game.
And tell them, like, okay, that's a new thing.
Like, just go, like, go wide with it.
We did not anticipate anything, really.
I wanted to get, like, the most kind of, like, pure, in a sense, environment possible.
And, um...
And then what we did was like, we didn't really think that through because I wasn't even thinking that was a good idea to do it remotely.
But what we did was just to have a channel on Slack and they were like talking.
They were like in the channel and they were like talking out each other in the channel.
And that allowed me to listen a lot.
They were like talking so much and they were like typing so much.
How many people were there?
Many people?
We got like, I think it was like four or five beta testers on board.
And they were like, you know, by the time they got into the beta testing, they already had like hundreds of hours on their shoulders.
So they were really, really, like, they really built a lot of muscle memory for the boat.
So the beginning was like, we did something crazy.
Like we switched a teleportation device from one end to another one and they couldn't play the game anymore.
So that was like the thing that we did.
But then I have to say, very, very important was to actually get the video playback.
from them like the video recording to send them on Slack and just like to send them on Slack and then like kind of like organize as a forum like free to comment on it and that was giving me a lot of information in the back lines. Awesome, thank you. Thanks.
