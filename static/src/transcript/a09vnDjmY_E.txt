Thanks for being here this morning so early.
Just before starting, a few reminders.
Please silence your cell phones.
At the end, please fill the forms and give me as much feedback as you want, and I will apologize for the French accent.
My name is Charles Lefebvre.
I am a technical architect at Ubisoft Montreal.
And I've been working in games for a couple of years.
I've been doing a few games, some that you know, some that you don't know.
And I've been working on Assassin's Creed Origins.
That's why I'm here today.
And of course, that's me, but this is going to be the work of a big team that I'm going to present.
So, enough about me.
Who is a programmer?
Who is a designer?
Who has never played Assassin's Creed Origins?
Okay, so if you haven't played, it's not for me.
It's mostly a game about patting cats, riding unicorns, and surfing on pyramids.
But some players have seen something else, according to the forum on Reddit.
They have seen that the NPCs seem to have now a schedule and that they are always alive.
Is it true? Yes.
And I'm going to tell you why this is happening, thanks to our Meta.AI.
So what did we add before?
Are my videos on the plane?
No.
Okay, I will have to do that really, really manually, so I really apologize for that.
Try not to be late.
So what did we add in Assassin's Creed Syndicate?
Basically, oh sorry, I'm gonna see anything on my screen, so I might turn, but I apologize for that.
We had only gameplay in the, can I get the mic here?
No, I'm turning all the time.
The gameplay was only happening around the players.
There was no gameplay when you were far from the player.
We had some fake crowd that you could see when you were far, but there was no gameplay happening.
You can see also some icons, but they are not moving.
They are persistent icons, and they are just telling you where you should go.
So why did we change?
First, we have introduced an RPG element in our ingredients in our game.
Ascend Squid Origin is not an RPG game, but we have some ingredients.
And for example, you can loot some targets.
You can loot some animals.
And you don't want to be able to kill a target, loot it, go away, come back, and be able to reloot it again.
We have the eagle.
It's something new to the brand.
And with this eagle, you can do a couple of things on a video that will not play.
So with the eagle, you can go in the air, focus on some NPCs and see what they are doing.
So those NPCs are really close to you.
But you can also focus on NPCs that are really, really far from you, like 400 meters away.
So you can focus on them, see what they are doing, you can see that they are moving.
And you can move with the eagle, you can go as far as you want from the player with the eagle.
And when you arrive close to them, they hear they are doing something, they are spawned, and they are in the right state.
We have the long range navigation.
We have what we call Fiery Kiss, that are bounty hunters that are attracted sometimes by the player, and they need to be able to navigate even when the navmesh is not loaded.
And obviously the navmesh will be only loaded around the player.
And we switch from a mission system to a quest system.
That means that we have multiple quests tracked and active at the same time.
And before, we had only one mission active.
And sometimes when the target was too far from the player, we were failing the quest, the mission, and you had to restart it.
Now with this quest, since you can have multiple active at the same time, it's not something that we can do anymore.
Also, Egypt is a huge world.
This is Egypt.
This is London in Sonic 8.
So it's 10 times bigger.
So we need to have something that will create emergent and system in gameplay, because obviously we cannot fill this world with scripted or even small ingredients.
We need to have big ingredients that are moving and creating gameplay.
So what is a Meta-AI?
It's a combination of three things.
It's a virtually tracking system that can track objects virtually in the world.
It can be static objects and dynamic objects.
It's a spawning system in charge of spawning the visual representation of those objects.
And it is a behavior system that will push goals and objectives on those objects.
It's not a game director.
Every object is independent.
So we have static objects.
It can be a ballista, it can be a brassier, or it can be a cage.
They are always loaded.
It's in-place data, either placed by mission or other designers, but they will be always loaded.
It can have a representation or not.
So here, we have a station.
So it's one kind of static object that doesn't have a visual.
It has a type, but it also has some labels, and it can be identified through those labels.
It can have child positions that can be occupied and reserved by dynamic objects.
Most of the time you will have a quad station at the position of the child position and when the entity is spawned it will be acquired and play a nice animation like the one you can see here.
It can be disabled but never deleted.
And we have a lot of static objects.
This is a 2D map.
This is a player's wide piece that you can't probably see.
This is one kilometer, and this is five kilometers.
So you can see that we have a lot of static objects.
We have, in Egypt, 50,000 static objects for a weight of 15 megabytes.
This is five kilometers of the game.
So it's still big.
This is the type of static objects that we have.
Most of them are location and animal locations, but we have also a lot of spawners.
So the spawners are the objects that will create the dynamic object, they will spawn them.
Every static, every spawner will automatically generate some spawning position to ensure they are not all spawning on the same spot, and they will create some dynamic objects.
So what is a dynamic object?
It can be a boat, it can be a human, it can be an animal.
You can be parented to another one, like here you have a human on a boat, so the human will be parented to the boat.
And all the characters are underlined by the Meta-AI in the game except one.
You can be virtual, you can be in bulk state, I will come back on that later, it's when you have a very cheap visual representation.
And you can be real.
Another video.
You can have an AI state.
That's what you are seeing when you are focusing on them with the eagle.
And this is represented by your current behavior.
And like the static objects, you can be identified by your type or by your labels.
For the static objects, the labels were static, they will never change, but for the dynamic objects, some labels can be pushed by your behavior according to what you are doing.
And once again, you can be identified by that, you can search for dynamic or static objects with a specific label.
It's not going to look very great because this text is still going to be here.
But if I'm zooming out, you can see that we have a lot of dynamic objects around the player.
And they are moving, they are doing stuff.
OK, we have up to 12,000 dynamic objects loaded for a budget of 40 megabytes.
And if I'm displaying the same 2D map, you can see that we have a lot around the player.
But as soon as you are going far away from the players, there are less, because we can delete some of them, like the crowds, the animals.
We don't really need to keep them all the time.
But some are important to keep, like the mission NPCs and the girl that you killed in a camp.
And you can not delete them, but you can make them hibernate.
That's the one that you can see in green.
And in this case, that means that they won't be updated anymore, but we will keep them.
So they will keep the inventory, their target, everything.
Once again, this is what we have for dynamic objects.
Most of them are humans and animals, but we have some various dynamic objects, like water vehicles.
We want the subject to move, so for that we need to have something that will handle the long-range navigation.
And this is the AI network.
So this is a top view of the AI network in telemetry.
So what is the AI network?
It's a graph with nodes.
Those nodes are going to be always on the live mesh.
They can be either generated or end placed.
Two connected nodes will have a maximum distance on 25 meters and always on the NAD mesh.
Static objects and child positions will be nodes, but we have nodes that are not static objects or child positions.
Between those nodes, we have some links, and those links can have some properties, like can it be used by a human, by an animal, or by a boat?
And we have some lanes.
Each dynamic object that can navigate will have a navigation profile.
And according to this navigation profile, you will be able or not to navigate on a lane, and on a link, and to choose a lane.
Isolated networks are supported.
It's super easy for us to check if, for specific navigation profiles, two nodes are connected.
So we can support isolated network.
And they are divided in sectors for hierarchical pathfinding.
So doing, even if it's a huge.
a huge map, it's not super expensive to do a request.
I'm going to try to show the video.
So if I'm zooming out, you can see that we have a lot of nodes and links.
We have alpha million nodes and alpha million links for a budget of 100 megabytes.
Oh, that's a video.
We are also using, we can also see the AI network.
Sorry, I've lost my mouse.
We're also using the AI network in the game when we are auto-following a road.
And in this case, the player will follow this AI network, and we are even going to display it.
So it's not only used by the meta-AI.
So there are three states for the dynamic objects.
The first one is a virtual state, and I'm going to show you a nice screenshot of an object in virtual.
So obviously you cannot see anything, but if I'm turning on the debug display, you can see that we have a position, we can have an inventory, we can have a level, we can have a target, and you can have a path to this target along the eye network.
That's the minimum that you need to keep when you're in virtual.
and you're not going to be updated every frame, obviously.
When you're in virtual, you're going to be updated every 15 seconds by default.
If you're close to the player, you're going to be updated every five seconds.
The second state is a bulk state.
So you can see here, value subject in bulk.
So that's a very cheap representation of an entity.
It's only one draw call, there are no shadow.
The spawning distance for those bugs will depend on the size of the object.
For a child, it would be 250 meters.
And for a boat, it would be two kilometers.
And they can be animated.
So you can see that they're animated.
It's a simple animation, but when they are far, it's not obvious.
So you can see that we have a very limited number of Bulk's models.
They all look the same, every woman, every man, because they are really far from the player.
It's different from what we had on Sonic 8 where we have a big variety of Bulk's, and when they were getting close, we were trying to spawn an entity that was looking like the Bulk.
So we have around 1,000 bugs when we are in cities, like in Alexandria, for example.
And they are updated every two frames when visible, and once again when they are not visible.
You don't really need to tick them each frame because the animation is not going to move a lot.
So we are going to update them one in every two frames.
Video, don't crash.
We are even seeing the bugs when we are meditating.
In this case, on the bottom of the screen, you can see that the boats are moving really, really fast.
And it's not something that we can do with a real entity with physics components, but here it's a bug, so we just update it with a big DT, big delta time, 20 times the regular DT, and they're going to move super fast and create these visual effects.
Finally, we have the real state.
It's when you have an entity with components, so it can be animation, physics, AI components, a lot of components.
When you're in a, no, obviously it's a video.
When you have an entity, then you can fight with a player, some things that you cannot do in bulk or will.
You can take damages, you can take arrows, you can, you have some particle effects, you can play some sounds.
but this is going to be super expensive.
So you can pick up some objects, but it's super expensive.
Each component can be updated multiple times before and after the physics, for example, so it's really, really expensive.
So we have a maximum budget of 200 objects in real estate.
The player, I've said that there is only one object, one character that is not part of the meta eye and it's not the player.
The player is an object.
We have a player object.
Obviously, it will never be in bulk or virtual, but other objects will be able to target the player and to navigate to the player and to fight with the player.
The only one that is not part of the Meta AI is actually the Eagle.
And one big reason for that is we don't really want the other NPCs to shoot and kill the Eagle.
So it's not part of the Meta AI.
But the Meta AI is not player-centric.
It doesn't have any privilege.
And I have a video to prove you that.
So as you can see on this video, it's really not player-centric.
And other NPCs don't care at all about the player.
And it can be appeased by that sometimes.
So in Meta-AI, there is AI, so we need to have something.
And this will be handled by virtual behaviors.
So virtual behaviors will give a world to the object.
It can be to select a target, to navigate to this target, and to interact with this target.
It's a simple gameplay loop.
We have a couple of behaviors, but most of the time, it will be a go-to, a patchwork, can be slightly more complicated, like an ambush.
And for each dynamic object, we have one main behavior and one reaction behavior.
The only reaction behavior that we have is actually the flee, but we can persist the flee in virtual and keep on fleeing in the virtual space.
And it's only going to run on the root object.
So if you have someone on a horse, only the horse will have a virtual behavior active.
That was an issue for us because that means that if you need a horse to navigate somewhere, as soon as you are on the horse, you need to ensure that the behavior is pushed on the horse and that the horse is going to select the same target.
And as soon as the entity is spawned in real state, it's going to drive the AI of the spawn entity.
Our AI is working through a state chart and the virtual behavior will push some embedded state charts into this state chart.
So how this is working, small example, here we have a behavior go to for a range of 150 meters and the label will be location sleep for low class.
So we have an NPC with this virtual behavior.
Well, this bed is too far.
This one is not connected, it's on a separate AI network.
This one maybe has the wrong label, and this one is already occupied, so we are going to use the closest bed.
Can be the closest to the NPC, or the closest to his spawner, if we want to keep him in a range around his spawner, and to avoid him from going far away from the spawner.
Now we need something to push those virtual behaviors on the dynamic objects, and this will be needs.
So what is a need?
Well, you can have a set of needs, like going to the toilet, sleeping, eating, or healing.
And maybe this NPC went to the toilet 10 minutes ago, and now he doesn't need to go.
There is no bed nearby, so he cannot sleep.
And his health is perfectly fine, so he doesn't want to go and see a doctor.
So he's going to eat.
Those needs are organized in schedule, and you can have different schedules according to the time of day.
And here we can see the active needs.
The guy on the left is working, and the guard is socializing.
So another nice video.
So here you can see a guard for the moment.
Try to move the text.
I'm sorry for the text.
For the moment, he's eating, but at some point, he's going to decide that he needs to go to the toilet.
So it's going to navigate to the toilet.
There's a timer for the toilet need, but the timer is not going to start as long as you don't reach the toilets, because obviously you don't want the guy to start navigating and to do a U-turn after 20 seconds just because his need is over.
Just going to, it's a long pass, so I'm going to move.
It's moving.
That's really far.
Yeah, it's.
It's a private area of the fort.
Am I here?
Yeah, I think it's here.
OK.
So now he's arriving to the toilets.
And if you can see, the timer is going to go down.
Let's give him some privacy and we'll move.
At some point, he's going to switch somewhere.
I don't remember where, but to the night schedule.
He goes, the night will arrive.
Now it's a different schedule.
He doesn't need to eat anymore.
Obviously, everything is data-driven, by the way.
So it's 90 seconds.
It's very long, obviously.
But it's just because we want you to see that.
Yeah.
Too many beers yesterday.
And at some point he will fulfill his need and he will do something else like socializing.
And it's really nice for us because what we can do is with those needs and according to the number of resources that you're placing, maybe here during the night you will have only four guards that will be active.
But during the day, you will have seven guards because during the night, maybe some guards are sleeping.
So according to the time of day, everything will change and we'll have different behaviors happening in this camp.
And this will create emergent gameplay, obviously, because animals will have needs as well.
And one of their needs can be to eat and they can eat humans.
So on the top, you can see a hippo arriving in the camp and start fighting with the guards.
And they will fight.
And at some point another one will arrive.
So nothing is scripted here.
It's all imagined gameplay and these situations will happen.
The only thing that we needed to tune actually was to disable fighting for animals in virtual space as there were dead bodies everywhere in the world and we wanted to avoid that.
We have groups in the world.
We have two types of groups in virtual space.
It's a video.
So the first one is the art group, like the bodyguard here.
When you have an art group, the group is created at spawn time.
And the followers will target the leader and always follow the leader.
And if you kill the leader, then the group will be deleted.
And you have the soft group.
In this case, the groups are created at runtime.
If you have multiple objects from the same factions that are navigating to the same target, they will automatically create a group and navigate together.
One leader will be elected.
But if you kill this leader, another one will be elected.
And as soon as a group is created, they will try to always select the same target.
So to summarize the Meta-AI, what it is, it's 50,000 static objects, 12,000 dynamic objects that are moving on the AI network in virtual real or bulk, and with needs that will push virtual behaviors.
So that's a lot of data, and I'm going now to talk about performances and troubleshooting for that.
The first thing that we need to do, I'm not going to play this video, it's during the white room, we are pre-rolling all the objects.
That means that we are going to update them a couple of times, like 10 times with a big DT between 75 and 150 seconds.
And the goal is to spread them and to ensure that when you're starting the game, everything is not at the same place and the world seems alive as soon as you're starting.
Then we need to update.
So this is one frame of the game.
At the beginning of the frame, we are going to update all the groups, all the avoidance, and to manage the spawning.
Then, and this is single-threaded, it's around one millisecond.
In the middle of the frame, we are going to update all the spawn units, that's when you have a bulk or a real entity.
We are going to update only the root entity, the root, sorry, object that will update its hierarchy.
And it's multi-threaded, and it's seven to 10 milliseconds.
And at the end of the frame, we're going to update the meta object.
But it's going to be time-sliced because we just want them to be ticked every 15 seconds.
So we just have a budget of 1 to 3 milliseconds single thread, and we will adapt this budget to ensure that they are updated every 15 seconds.
And if you need a pass along the I-network, then we are going to create a pass request.
And this is going to be an asynchronous task.
It's actually going to use a CPU idle time from the processor.
Then we need to debug that because that's a lot of data.
So how do we debug that?
We have some automated smoke test that we can run.
So we can, ah, no, no, no, no, no.
So we can, NVid is our editor and we can load a test map in our editor and ensure that there is no regression.
So here we have some guys navigating, some guys fighting.
So we can load that and ensure that nothing has been broken by a change.
We are using a lot of telemetry, and we are sending a lot of data when someone is playing a game.
So as soon as someone is playing the game, we are tracking everything that he's doing, and we can replay all this data in telemetry.
So we can check all the time where was the player, and how many dynamic objects were created, how many static objects, things like that.
So it's really useful to detect regressions.
Every night we were doing a performance walkthrough.
That means that we were teleporting the player every 15 meters, loading everything, and doing a performance capture.
But we were not only capturing the CPU.
capturing everything.
And after that, we can open the result in our browser, in a map.
So here, that's a performance map.
I can see the areas where we are not running at 30 FPS, and I can open a performance file.
But since we are recording everything with telemetry, I can also check the number of dynamic objects.
and get a heat map of all those dynamic objects and I can focus so I can see if an area is too populated or if there are not enough NPCs in this area or too many animals, we can track that.
And obviously also to detect leaks.
Finally, we have nightly reports.
We have nightly reports.
Every night we were doing a lot of tests, like checking if two static objects are still connected and if it's important for a mission.
And every morning we could receive the report saying how many errors were created.
And I'm not going to talk a lot about that because there was a talk yesterday from Nicola Ruti about that.
And if you haven't seen it, I would suggest you to watch it on the Vault.
Now, performances, we switched from less than 100 to 200 NPCs, and we needed to do that because our spawning radius is bigger than before.
So we needed to optimize those NPCs, and especially the ones that are between 60 and 80 meters, because that's a change in our spawning radius.
So we have introduced two new techs for that.
The first one is a component LOD for load and demand.
We already had LOD for our visual components, but not for every component.
And a lot of components were doing something like saying, oh, if I'm too far from the player, maybe you don't need to tick me.
But you know that the best optimization is to not call a function.
So what we did is introduce a component LOD for all the components.
And you can be in low.
medium or high and visible or invisible.
So that's six LODs.
And you can decide if you're going to switch from one component to another according to your distance or if you have a budget like 10 high visible and you can even mix both.
And when according to your LOD you can decide to disable completely a component or to reduce the update frequency or even to be notified and for example in our AI component we are turning off the head look at when you are in low even visible because it's not something that you can see when you are far from the player.
The second take is a bulk animation.
So we've seen that the bugs are animated, but the animation is not as good as the one from the real entity.
But what we can do is to update the bug and to copy the animation from the bug on the real entity when they are far from the player.
Hopefully this is going to...
That's two videos, that's more complicated.
Okay.
So this one here is a real animation.
You can see that the fingers are animated, that the feet are not sliding.
So it's a good looking animation.
And here you have the bulk animation.
So with the bulk animation, the fingers are not animated.
The feet are slightly sliding, but if you are at 80 meters or 60 meters away from the player, you couldn't make a difference between those two animations.
I apologize, nobody.
One of the.
If you are playing one on top of each other, you could see the difference.
Okay, so that's the Meta-AI.
It's something quite powerful, but we still need to improve some things.
First, we have two navigation services.
One for the spawn space and along the nav mesh, and one in bulk or virtual along the world path.
And what can happen is, You have an NPC that is quite far away from the AI network.
And the reason for that could be that he was in a fight and he went far away from the AI network.
Now, we are going to unload this cell.
It's going to switch from real to bulk.
And now he cannot navigate anymore on the nav mesh, so he will try to reach the AI network and do a straight line to the closest node.
and if the player is coming back, well, he will respawn inside this pyramid.
And this is actually happening in the game, and that's not something good.
It was not happening a lot.
We have a few solutions for that, but it was still sometimes happening.
Also for a long time during the project we were not enforcing the density in the world and you could have a market with a lot of valid spots that could attract a lot of people but if everybody's coming it's very likely that we will have more than 200 dynamic objects nearby and that we cannot spawn all of them.
So what we did is...
to create a grid and they are all registered in a grid of 40 by 40 meters and in each cell you can have a maximum of 16 dynamic objects and this will include the ones that are inside this cell and the ones that are targeting an object inside this cell. And when the cell is full they will try to select a target that is in another cell to try to spread everything.
It's going to be only for non-monetary NPCs, so not for the mission NPCs or for the merchants in the cities.
But if you have an interior, like here I'm going in an interior, you have a lot of dynamic objects inside these interiors.
And they're going to use a density, because in virtual, we don't really know that it's an interior.
And...
When you're outside, they will not be spawned, they will still use an entity, so we are kind of wasting them.
Finally, we don't manage emotions, and it's possible for NPC to be part of a cinematic, but it doesn't know that.
And he has taken it.
This is one of the saddest cinematic of the game.
It's a funeral of a little girl.
And well, you will see what happened in the wet square.
Anything for Ramos.
He will pay for this.
And all those who serve him.
So it's something that we cannot really control.
Finally, Quest and Meta-AI.
So Quest are using the Meta-AI.
First, they will acquire objects from the Meta-AI.
It can be a specific target, like Cleopatra.
Or it can be just a guard, level 15, or I don't know what.
Just a specific guard if they just need someone to play a view or something like that, to play a bark.
We have introduced new scripting operators and new virtual conditions, so they can push schedules on those dynamic objects, and they can check their position.
We have some very specific behaviors for quests, like the stand still and the scripted go-to.
But the good thing is now, mission, stand still is used, sorry, for cinematics, and scripted go-to, it's when we are navigating somewhere, but we want to have a dialogue happening at the same time, or something like that.
But the good thing is now mission designers are going to.
push goals on the NPCs instead of micro-managing their behaviors.
So this guy will be able to react and adapt to what's going on.
So here I have a quest.
Here we have a rebel.
The rebel in this mission has to go to the ruined fort and he can use a horse.
Sophia is here to follow the rebel and she must wait for the player.
And Bayek is here, in this quest he has to escort Sophia.
And during this quest he's an opponent to bandits. We have bandits in the world and here you are an opponent of the bandits.
Let's play that.
Attack on a nearby encampment.
There are more soldiers than we thought.
You're going to cross the path of a bandit.
How many wounded?
Enough. That's why being close to their mind is so important.
And the fight is going to start. So it's not something scripted, it's not part of the quest, it's just systemic. So everybody's fighting.
Okay, he's dead.
So now everybody is going to resume his goal, they know what they have to do.
So he's going to go back on his horse, Sofia is going to go back because she needs to follow him.
They're going to recompute a new path on the iNetwork, and they will resume what they have to do.
So it's really good for us.
That means that we can start a quest anywhere in the world.
We don't have to put the mission giver at a very specific location.
He can move around.
It's really, really powerful for us to do that.
And there was, during the high summits, there was a talk from Jean-Marie Santini about the quest.
If you want to look at that, it will be also on the vault.
So.
So.
Was that something good?
Yes, I think it has created a lot of opportunities.
Obviously, we had to change a lot of the code.
It was a big change.
And some people seem to have lost control about what they were doing, because before it was way simpler for an animator to create a station and to ensure that there was always somebody in the station.
Now the NPC has to decide that he wants to go to the station.
But we have unified a lot of the code.
Everything is now done.
In the dynamic object, in these behaviors, it's not done from something outside the NPC.
So it was a lot of work, but at the end, I think it was good.
And thank you for following that.
And if you have questions, I'm happy to answer.
Thank you.
I have a question.
When you're in Assassin's Creed Origins and you have the eagle flying, Bayek can be riding on his horse to some destination.
If the eagle gets far enough away, does Bayek also become bulk or virtual?
No, he's never becoming bulk.
He's going always to stay spawned and even the horse is going to stay spawned.
But you cannot move at this point.
At some point he will stop moving and only the eagle will be moving.
Okay, thank you.
you for that excellent talk. Couple questions. Can you speak at all to how the virtual node network was actually, because you said it could be automatically placed. Can you say anything about how that was done?
Yes, but that would be a full talk.
Basically, if you have a road, it can be automatically generated on the road.
You can also just create two nodes and create a link and at build time we will ensure that we are creating a path on the nav mesh and play some nodes.
We can do a lot of things.
We have some templates that we can drag and drop.
There's plenty of ways to do that.
Is, sorry one more question, do the bulks have any collision at all?
They can do avoidance, they don't have collisions, but they can do avoidance.
We don't do that between humans, but when we have carts or boats, we need them to avoid each other.
So there is no physics, but they have collision, they have avoidance.
Could the player like shoot an arrow at one of them?
No, that's why we have a bigger spawning radius actually, because we have the Predator bow, and you can shoot at 80 meters with the Predator bow.
So we need to ensure that everybody spawn, as you could shoot through a bulk, and that would not be good.
Okay, thank you.
He literally just asked my question, so.
So I had two questions.
First of all, you're using NavMesh and also network, like the AI network.
Is it a performance reason that you have both?
Like, while you move to it?
It's a memory reason.
There's no way we can load that.
I think our budget for the NavMesh is something like 20 megabytes, and it's only for a couple of cells.
If we are loading Egypt, it would be almost all the memory of the game.
Okay, and my other question was, you were talking about the behavior and the needs and the camp that had guards and some were sleeping and some were still guarding.
What was deciding which one was sleeping, to make sure not everybody goes to sleep?
It's the resources. We wouldn't place 10 beds in a camp with seven guards, so the level designers will ensure that there is not too many resources.
And they came to prevent that from happening.
Thank you.
I have one question.
This might just be some confusion on my part.
With the grid system that limits how many dynamic objects can be spawned within a given area, in combat, if If it's possible for like guards or whoever to kind of rush into one square on that grid, could that be overloaded or how does that work?
I don't think that we would, that our fight system would attract so many people because the fight is already quite expensive, so we wouldn't want to have a fight with so many people, so I don't think that the fight will attract so many people, that many people.
Hey, yeah, thanks.
Great talk, by the way, despite the video things.
I was wondering, so you said that your budget for real NPCs is 200.
What's your budget for combat NPCs?
I think it should be around 40.
I think we have a maximum of 40.
All right, thank you.
Okay, thank you very much.
