Thanks you guys, thanks.
I'm Sky Lewin, music director and composer at Bungie. It's my pleasure to introduce to my left Michael Sechrist, our senior technical audio designer who's also doing some composing and to my right, good friend, uh 15 year Bungie veteran, now an independent composer, C Paul Johnson. He's gonna kick off our talk with a look back at what the ambient music system was in Destiny, what we changed and enhanced for Destiny 2 and why.
Alright, thanks Sky.
Okay, so why are we here?
Well, we had to modify our tools and our music implementation and our scoring process for Destiny 2 in response to scope and scale and gameplay changes.
And we thought you might find our approach to solving the particular problems that we ran into interesting and helpful in your own music solutions.
Why is this talk called Linear Music in an Open World?
Because during the development of Destiny 2, as we started to understand more and more about how much freedom the player would have and how the needs of the gameplay evolve from Destiny, both in, Destiny 1, both in the explorable gameplay space and in the number of unique highly scripted linear activities that we were building, we realized we needed to find a more efficient way to score.
our game that didn't compromise the musical experience we still wanted to retain. So...
Okay, so before we look at what we changed, let's start by looking back at how our ambient music worked in the original Destiny game. Destiny, and Destiny 2 for that matter, consisted of several different explorable destinations. Here you can see a few of the destinations.
in Destiny. Each destination was given its own collection of linear pieces that act as the locations ambient music and defines the feel for each environment. So it's a typical open world solution. These pieces of music acted as a randomized playlist of music with stretches of silence after each piece.
Each piece consisted of an ambient layer that was played and then an action layer that would come and go based on engagement with enemies.
In Destiny, when we wanted to custom score a mission or a specific encounter, we were required to custom implement and script all the music for that mission as a one-off event.
Okay. So what did we change for Destiny 2? In Destiny 2 we have a multitude of activities in the destinations that feel very linear but could be kicked off by players in the world or not.
And that left us with a whole bunch of linear gameplay that needed to be able to come out of the open, of the destination content.
Those were also pretty easy for designers to set up, and it left us with a whole bunch, way more linear content than we could reasonably support custom scoring everything.
So we needed to support unscripted environmental gameplay, more curated content, and we needed to do both those things with high production values.
At the same time, we didn't want to lose our tailored linear music experience, given the fact that a lot of the gameplay was still linear.
we were discovering that the original method we had in Destiny of scripting out the ambient music and bringing it back in wouldn't scale.
So our approach to Destiny 2.
How did we propose to move forward?
Well, we had ambient music playing based on which environment already, and we had ways to turn it on and off when we wanted to score something.
So we wondered how much mileage we could get out of giving that ambient music more things it could do.
Once we did that, could we score whole story missions with this new system?
Could we set things up so designers could easily experiment with timing and intensities and pacing without us getting involved?
Could we build that designer tool in a way that would let us go back and fix what they did in a way that, without having to touch the game scripts, which is really important for us in the late stages of development.
Creatively, wanted to have the ambient music when the player was wandering around, activated by AI like before, custom music tailored to our linear flagship content, and this middle layer of music that felt linear to score the rest of the gameplay.
And we were asking ourselves, could we make that into one cohesive system?
I don't know.
Could we make it all easy to use?
Those were our goals, and now Sky and Michael are going to talk about where we landed.
Cool. So this part of our music system we're really literally just focusing in on is what we play in the destinations when you're exploring in the game. So our flagship content really retains the same aesthetic as it always has and we're still scoring that the same way. So this part of the talk is really focused on one piece of our puzzle, if you will.
So for Destiny 2, we retained the same randomization, the same ambient playlist functionality that was established in Destiny, with the same vertical ambient and action layers that C. Paul already mentioned, but we actually expanded it by composing additional linear horizontal sections of music for each of these ambient pieces that play in a destination.
And these intensities, such as action or high action, actually expand what that music can do so that they can cover more gameplay activities that traditionally would have needed custom score. And we call each of these a music system. And what a music system is, is a single expanded piece of music or a collection that contains all of the necessary different intensities to play, um, at the same key or related keys and tempos. And, uh, that's we build these different intensities out with transitions so that they can transition nicely from each piece to any other piece.
And in this system, it actually has to be able to go from anywhere to anywhere or end at any time.
And this by itself is not necessarily unique.
What makes this unique is the way we combine it with other aspects.
So each system is effectively a cue in the destination's music, the music that defines the feel of the destination, as C. Paul mentioned earlier.
And so the suite of systems that goes into that destination includes several of these, these music systems.
So our music system contains a bunch of music systems, if that's not confusing enough.
That's how we call it.
Um, but again, like I said, none of these by themselves are unique, but when we combine them together that gives us this solid linear score in the destination game experience, which is exactly what we were trying to do with this.
Basically taking that linear feel of our flagship content, that blueprint, and imposing it upon the feel of the activities in the destinations in our game.
And basically, one of the big benefits of this is that because this suite of music systems contains music at a variety of different keys and tempos, we are able to keep ourselves from being limited to one or two keys and related tempos, and that gives us a lot of mileage with this music.
So how did this change our scoring process? Of course the big thing here is that none of this will work without good content So we still try and focus on writing the music the same as we always have that part really hasn't changed We're just developing new ways to put it into the game and to play it back when we're playing the game. So in Destiny, we would spot an activity with the designer, we'd start composing or in some cases use that information to alter what we were already composing if something was already in flight. Um, and then we would go in and temp the activities as they were being built with temp music. So for those of you who are familiar with that, you know what that means. If, if you don't, it's just temporary music that's not gonna stay. It's some placeholder to show what the functionality is gonna be like.
Um, excuse me. And then a designer or Michael would script in the music into the activity. We would orchestrate and record and produce the music, mix it, get it all ready. And then...
finalize it, put that real music into the game in place of the temp music and polish, review, make tweaks as necessary. And that was basically our process. And that same process we carry forward for flagship content, that more or less doesn't change with a few tweaks, but there's some benefits to this new process that actually streamline that and that's what I wanted to show you here. Is that in Destiny 2, we actually start off with letting the designer script the activity.
And they're actually building the activity score as they build an activity, whether it's a mission or a strike or a raid or something that might play in a destination.
And so we're actually kind of skipping the temp step because they're able to temp while they script and hear that music immediately as they're building the activity. And then our spotting session really becomes more of a review and tweak and change or update than, you know, that initial step that kicks the whole process off for these activities.
And then of course we record, orchestrate, or orchestrate record in that order. Um, mix, get the music ready, put it in the game, review and the rest of the process is more or less the same.
So once our music systems are ready to go into the game, there are three main steps we need to take to get it implemented.
First, we build the music systems in Wwise, and then second, we assign the music to the various destinations.
And then last, the designers can then use that music to score their content.
As Sky mentioned earlier, each of our music systems is composed of several different sections of music for the various intensities that we have.
The way that looks in Wwise is each music system becomes a switch with all the various sections composed for the system as the different values or if you're familiar with Wwise, a playlist within that switch.
Once all of our music systems are built as switches in Wwise, they're ready to be assigned to the various destinations.
The way we do that is by grouping them into something we call ambient music sets.
These are custom files we've created to act as collections of music which we then assign to destinations or parts of destinations to provide their music.
Each of our destinations in our game have at least one ambient music set, while some may have more.
It all depends on what the environment calls for.
For example, our destination Titan has two ambient music sets, one for the exterior space and another for the interior.
Once we've assigned an ambient music set to a location in the game, we've achieved the same ambient playlist behavior we had in Destiny, and that's done by randomly cycling through the various music systems in the set and playing their ambient sections.
But thanks to all the additional sections we've composed into each music system, that music can now be used by designers to score their content.
And the way they do that is by using another one of our custom files called a music score.
Now these files are comprised of a series of sections that are added by the designer to determine the flow of the music through their content.
Each section has a name, which is what the designer calls in script to trigger that section to play, and an intensity value, which is literally a drop-down selection of all the different switch values we use to build the music in Wwise.
So action, high action, tension, all of the different intensities that we have.
Now let's pretend I'm a designer and I'm...
Building an adventure for Destiny 2, which is essentially a side mission.
My music score might look something like this.
Here I've created three sections of music, starting with light action, going to action, and then ending with end, which will play the appropriate ending for whatever music is currently playing.
That's all determined in the transitions we've built in Wwise.
Now that I have my score, I just need to do a little bit of scripting in my adventure script to make it all function, and that could look a little like this.
This is totally real right here.
The first thing I do is I define my sections at the top using their names.
Then I simply call or activate those wherever it is I want them to play.
And that's the whole process for implementing our music systems.
Before I hand it back to Sky, let's go over a quick graphical representation of this entire process so you guys can have a little bit better understanding.
Here's another one of our destinations, I-O.
The first thing we do is we build I-O's music systems in Wwise as switches.
We then assign those switches to an ambient music set, which is then assigned to I-O.
At this point, if a player lands on I-O, the engine will randomly pick one of the music systems in the set and start playing its ambient section.
Here you can see it's choosing the second system in the set.
Now let's say the player comes across the adventure we just created.
Here you can see our adventure's music score and the script.
The player kicks off that adventure, that first music call for light action will be made by referencing the first section's name.
At that point, the first section's intensity is sent to the engine, and the piece of music that was playing its ambient section transitions to the new intensity, in this case, light action.
And one of the great and most powerful things about this system is if we decide that that call for light action is not what we want, it's super easy for us to go in there, open up the music score, click on that.
It's literally just a drop down selection of the different intensities that we can make the change to.
We don't have to touch wise and most importantly we don't have to touch the script.
So therefore we can make these changes as late in the game as we need to.
So let's take a look at what this actually sounds like in the game.
I'm going to play you a couple of examples here.
But before I do, let me give you a couple heads up as to what we're going to see.
So first of all, as we mentioned, you can actually hear this transition occur from either the silence between pieces of music in a destination or from a piece that's playing.
And so one of the videos, the first one we're going to show, is going to actually demonstrate a transition from music that's already playing.
The second one is going to start from the silence in between the pieces.
So we're going to look at that in the examples.
We're also going to, I want to point out that this, because the system is actually randomly cycling through different pieces of music in a destination's playlist, we're actually randomly picking a cue and the activities then can be scored by different pieces of music.
But we can actually choose to limit that to a specific piece if we want.
So, if we say this activity needs this piece of music every time.
then we just make a bucket with that piece in it and it has its score. But we can also let it randomize and pick and the great thing about it is you can scale what it can pick from. So it can be the whole destinations playlist or a sub-playlist from that destination or just a single piece. Um, another thing to point out here is that the, uh, the videos we're gonna watch are drastically shortened just for digestibility. So you're gonna see the burn-ins on the screen that say time cut. That's where we cut a lot of time out.
Um, and in between those, you're going to see script calls on the screen.
You're not going to hear the music transition right on the script call.
You're going to hear it afterwards because obviously the transitions have to be musical.
And if you're familiar with wise, that may in some cases be next beat, next bar, whatever the next grid setting is, or maybe a custom queue, but, um.
the transitions will follow as the music dictates. And so on the first one we're gonna watch, it's just gonna be music only, I'll kinda talk through a couple of them and we can watch that.
And the second one, we'll take a look at it in context. Um, let's take a look.
Okay.
So there's the script call for action.
When you hear the transition starting.
And now we're actually in action.
There's a time cut transition to light action.
And now we're actually in light action.
Thanks for watching, make sure to like and subscribe!
So in the next video, we're going to see the exact same activity, but a different play through, a different piece of music.
This one's going to actually have the full game mix, sound design, everything in there.
But I'll point out that the music mix is a little hot, just so you can hear it a little more clearly in context.
Hey Zavala, guess who pinged our beacon near that Fallen Pike Gang?
Fallen?
These vehicles aren't as maneuverable as a Sparrow, but they pack a punch.
Keep punching. You have a golden opportunity to put the Red Legion down for the count.
Remind me never to get into a boxing match with a Titan.
That Fallen Pike Gang is still a threat.
Took the words right out of my mouth.
Let's not make this a habit, huh?
We'll see.
Be careful out there.
Those pikes were rebuilt with scavenged technology.
I'm pretty pissed.
Whatever they throw at us.
They deployed a walker to your position.
back to the scratch. And a victory like this will ensure a respite for us as well. Excellent work.
Cool. So some of the challenges that we had in actually making this work and building it out is that it does require a large amount of music. Now there's a sweet spot at which the amount of music that doing this requires is actually less than doing it the way we did in Destiny, which is basically custom scoring every single activity in the game. And the reason that it was beneficial for us is because we were over that sweet spot. So if, if your team is, um, gonna attempt something like this, you may wanna find where that is for your project, because it, it could be that doing this actually requires more content than you need to put in.
So depending on the needs of the game, that's something to be aware of.
Another big one that we found is that designers need some education on this.
You can't just put the tool there always getting the result that you expect because sometimes a designer is going to maybe do transitions a little too closely together or there's often a misunderstanding of, oh, I called it, it didn't transition right away, I want to hear it right there and then.
And so making the...
making the understanding of how this thing works really clear was important.
And there's also just the basic need of making sure that the script itself actually supports what the mission is going to be doing.
And so that's what the spotting session is incredibly important for, is making sure that what the designer's script is calling and the music flow following the mission is actually scoring the mission the way it needs to.
And then of course, there's the need for handcrafted moments and the ability to handcraft is still incredibly necessary.
So we occasionally need to combine using the system with custom scoring.
And on the advantages side, there's quite a lot of great things that we discovered with this.
And the big one for us was that we were able to use this to score action in the familiar dramatic and linear fashion that we set out to do it.
It did what we wanted it to do.
As I pointed out earlier, the designers can easily temp their own activities and being able to immediately hear the activity and the changes in their music in their activities as they're building them is really huge and it cuts down on iteration time for them and it takes us out of that step in the process almost entirely because they can now use music from an older, uh, destination or another destination to temp an activity as they're building it. It may not be the right piece of music, but temp music rarely is, so that it really worked in our favor there. Um, another big one is that because the randomization aspect of this happens to be something we can control, we can use the...
randomization to enhance the replayability of some of these missions when we want to.
And a really big one is that the implementation work is a lot less redundant.
So let's say we had a piece of music that we wanted to use in three different activities and maybe part of it was going to be used here and another part there and this part overlapped.
If we did this by hand the way we used to do it, we would have to...
and basically implement each piece three times.
But with the system, we just implement it once, and the script points to which part we're going to play.
And so it's a lot less work to set it up.
I mean, it's still a lot of work, but it's a lot less than doing it the other way.
Yeah, of course it's still work.
But it's a much more efficient means of making that music available to the game.
Another big one is that the more activities that are added in a destination, the more value we actually gain from using this system approach, since the randomization can stretch and cover more activities.
And the scalability ratio of music to activities is a huge asset for us.
But the biggest one, I think, hands down, is that late changes to music...
have less risk associated with them because the content is already hooked up and functional and literally all we're doing is we're changing the music intensity values in a drop-down menu like Michael mentioned.
We can do this completely on our own as late as the last check-in in a mix and the script does not need to change so there's no risk to the project.
And on that note, um, we are going to be moving to, uh, one of the wrap up areas. If you guys have any questions, I just want to remind you, please fill out your surveys and I have to say that GDC's been awesome. This is my first time here. The game audio community is awesome. You guys are all great. Please keep it up. Thank you.
