Hey, so like Dave mentioned, this is not actually a talk about utility AI from the content creation standpoint.
This is a talk about utility AI from the content creator's standpoint.
And where this all came from was about a year ago after GDC, I had this inkling of wanting to make a tool that could turn utility AI into something that was intuitive and accessible for the average AI developer.
This was partially selfishly motivated.
I had a lot of designers at ArenaNet that were working with utility AI projects that Dave and I had done there and other things like that, and there were a lot of gaps in the education there.
There's a lot of other AI developers, especially in places like the AI Summit at GDC, where I had conversations with people about how they had difficulty with educating designers or even programmers about how utility AI is supposed to work.
So there's a specific challenge that keeps coming up in the Guild Wars 2 franchise, which is probably easiest to summarize as, why the hell does my AI do that thing?
He's supposed to do this thing.
So the fact that we keep facing this question over and over signals to me that our tools need to be better.
We need to be better about creating tools for rapid iteration and prototyping, but we also need to be better about creating tools for debugging.
So Curvature is a standalone tool, and that might sound like a strange decision since we already have a game engine with a bunch of utility AI technology built into it.
But my thinking here is pretty straightforward.
Coupling to a particular game engine is a constraint.
It carries a lot of baggage.
There's things that I have to do if I'm going to work on a utility AI experiment, like set up the rendering and make sure that all my shaders are right so that I can actually see my AI agents running around.
And maybe if I want to have some physics involved, I have to get all that debugged.
There's an awful lot of extra stuff that just has to happen for a AI experiment to come to life.
Another problem that I run into a lot personally is that a lot of engines out there are not great at real time editing.
And what I mean is they have to do data pipeline builds.
And this means that every time I need to change something, I have to run a process that bakes my data out, does some processing of some kind, and then generates something that can actually run in the game.
This is murder on iteration time.
So instant feedback is actually the secret to building a system that's easy to understand.
As a result, Curvature is 100% self-contained.
My hope is that it's really easy to set up and play with.
And there's no baggage from any other engines or technologies involved.
It's literally one EXE file written in C Sharp.
You can drop it on your desktop, run it, and go.
The last point that I really want to hammer on this is that this is a fully real-time editing experience.
Everything you play with in this tool is reflected immediately back to you.
So utility AI is an architectural category of approaches to making behavioral decisions with an AI system.
The basic principle of utility theory is, in a nutshell, we're gonna score all the possible things that I might wanna do as an AI agent, and then I'm just gonna pick the best one for some value of best.
This is specifically built on the Infinite Access Utility System that Dave Mark introduced here at the AI Summit several years ago.
I don't have time to go into a full treatment of how the architecture works, but the basic pieces are pretty easy.
The first thing that we want to do is get a whole bunch of input data about the world.
So we've had talks earlier in the last couple days about knowledge representation and understanding the context of what our agents are doing in the world around them.
This is exactly the kind of thing that I'm talking about now.
Taking data from the simulation and processing it.
In our case, we do this through what we call response curves, which are basically just small little compact formulas.
And those formulas help us decide that for each possible behavior, What is the score? Should I continue talking right now? Should I take a drink of water?
Should I blow my nose? Whatever. I have a lot of options of things I could do right now.
What's the winner? So the recipe for this whole system is really simple. It's input data plus response curve equals score. And then you just pick the best scoring option.
Before I get into the bulk of this, there's a couple of quick things that I just wanted to point out.
Curvature is a spare time project.
It's not sponsored by ArenaNet.
It's not a public thing.
It's actually open source, just me on my own time.
There's room for improvement, but I think that's actually very exciting because that leads me to a challenge that I would like to issue to everyone here.
Specifically, I would like you to leave this session thinking about how you can improve AI tooling because I firmly believe that all of us can and all of us should.
So, step one of this whole process is knowledge representation.
I'm going to quickly define some requirements that I impose on this system.
It's going to be a lot simpler than most games would work with, but it's just enough to get the basics of a simulation running so that we can play with it.
So the first thing I wanted to do is identify properties of agents.
So an agent is basically just a character, an NPC or whatever running around in the world.
They have properties. Some of those are user defined.
and some of them are calculated from the simulation.
But regardless of where this information comes from, everything needs to have a name.
This is a personal line in the sand of my own, where I want to be able to refer, by name, a human-readable string to every single piece of my AI data.
The next part of this that's important is validation.
I wanna be able to have...
an expression of what numbers make sense for this particular type of data.
So we can do numeric ranges, and we can also in Curvature do user-defined tags.
If you were here for Rez Graham's talk earlier, this should sound awfully familiar.
So let's look at the UI real quick.
This is what the UI for knowledge representation in Curvature looks like.
The idea here is that we have a series of records, and each record is a piece of data about the world, and it has a number of attributes.
The first one that I want to point out is name.
So we have these names over in these boxes here that describe what this data is, what is its semantic significance.
The next thing we want to look at is where does this data come from?
In this case we have two choices.
It can be a property of an agent or it can be something derived using a prefab equation.
I'll describe prefabs a little bit in a second.
Another piece of information that's very useful is the validation.
Does this number have to be in a configurable range or is it a predefined value like a tag or enumeration?
So you can see here there's just a couple of different pieces of UI that'll dynamically spawn into the window as you choose whether or not this is a configurable range or a predefined value.
You'll get UI that automatically helps you flesh out the validation for that data point.
Then down here we have this little use distance prefab drop down which is a nice little transition to why we do prefabs at all.
So the idea is there are a lot of things that we can compute about the environment.
We can compute distances, we can compute line of sight, we can do all kinds of great stuff.
And we don't want to have to represent that as static data that a designer enters.
This is stuff that a simulation should be able to provide to us for free or small computational cost and then the AI can reason about that information.
So we could use this mechanism to hook up a bunch of things.
We could do pathfinding, we could do raycasting.
If you were here just before lunch, Dave gave an excellent talk on influence maps, which would have a lot of potential in a system like this.
Right now in curvature specifically, I've been deliberately minimalistic because A, it's less work for me and I'm lazy, but B, it's actually easier for the user of the tool to not have to keep all of these possible inputs in mind.
The main challenge that I've run into with explaining AI systems to anyone is that when you get into a certain level of complexity, there is just so much going on that it's virtually impossible to keep it all in your head.
So we have a whole lot of data about the world.
The next thing that we want to ask is what kinds of things can we do to influence that data?
How can we feed back into the simulation and do things?
So again, I'll start with some quick requirements that I imposed on this project.
I wanted to have a set of actions that the AI could choose from.
And these would be things like move to a place, or start doing this new set of behaviors, or so on and so forth.
I wanted to basically have a behavior be an actual effect in the simulation.
So anytime an agent chooses to do something, I should be able to measure that response in the world.
So again, I could move my agent to a place, I could change a property of an agent, and all kinds of different little things that help make a simulation actually move forward through time.
There's another little element of this that's very interesting as you get into more sophisticated simulations, which is targeting.
the number of choices that we have to score grows in sometimes complex and difficult ways with the number of targets that I have to consider times the number of decisions that might interact with each of those targets.
So basically, we want to limit the number of times that we do redundant calculations on parallel targets, especially because some things just don't make sense to have a target.
Right, like if I want to yawn, I don't do that to somebody.
That is a thing that happens to me personally, and that is contained within my agent.
So again, let's go to some UI here.
I wanna look real quickly at the core of what are four behaviors that I've defined for this particular demo.
You can see here we've got a couple of pursuit and a couple of evade, and there's variants for the blue team and the red team.
So each one of these has a specific drop down that tells the curvature system what happens when an AI chooses to do this behavior.
What does it mean in the simulation as an active event for this behavior to be executed?
And then of course there's also this little ability down here to change the targeting mode which lets you control what context makes sense for me to do this action in.
So like I said before, if I'm yawning, I can say no that can't target others and uncheck that box.
So this is where the AI starts to happen.
The real question that we have is why?
You remember if I said at the beginning, the problem that we kept running into was why does my AI do this and not that?
So why would the AI do this and not that?
The answer to that question is considerations.
And again, going through the requirements definition, it's really just all about the why.
Why would I prefer to do one thing versus something else?
The goal here is to account for real-world relevant data as much as possible.
But we also need to contextualize that data, because it's not the same for me to say, I want to buy a plane ticket, how far is too far to fly?
And I want to walk to lunch, how far is too far to walk?
Those are both distance questions, but they have very different contexts.
So ultimately, all of the different input factors that we're gaining from the simulation, scraping out from this knowledge-based system, they all have different contributions to the score of a particular behavior, and considerations are how we reflect that.
So this is a little bit wallet texty, but I'll kind of point out some of the most important aspects of it.
A consideration has an input.
This little highlight here kind of shows that we have currently selected to work with the distance to target input.
There's also validation, which we can do from this view.
And then there's this interesting little mess down here for a response curve.
I've seen enough demos of utility AI to know that as soon as these little two-axis plots with the blue curve come out, a lot of people start feeling a little freaked out.
And that's fine, because there is an escape hatch in curvature, which is right here, the presets button.
So this is the fun part.
I am a firm believer in the power of natural language.
This is sometimes at odds with my desire to make video games, because they don't often overlap very much.
But I think sometimes it's true that being able to express something in a few concise words is much more impactful than spending a bunch of time trying to play with all these possible sliders and UI elements and, you know, rolling numbers and all this to try and lock in an exact shape that you want.
So this is the Curve Preset Generator dialog.
These two drop-downs here are basically highlighting the two controls that we have.
This system is starting with a list of over a dozen different preset curves.
With no inputs, it will let you choose from amongst all of them.
But as we refine our request for a curve, it's going to use the natural language description of what I put in these boxes to filter down the list of suggestions and only show me the curves that match the exact description that I provide.
So here's how that works.
The top input is as input values grow towards 1, or as input values get bigger, basically, the consideration score should...
Now we have some options here. We can become more appealing, we can become less appealing, we can stay the same because we don't care, or maybe we can fluctuate a bit because we're being random.
So let's look at what happens if I plug in steadily less appealing scores as inputs grow to the right.
And you can see that graph there.
And I've chosen a constant or linear rate of change in the second input.
And the net result is that we get exactly what we asked for.
We have this graph that does a perfect linear decrease from yes to no across the input range.
But we don't have to stop there.
What if we decided that we wanted to have a curve that started decreasing quickly and then slowly decreased out towards the top end of the input range?
This is something that Dave and I would refer to as a 4-poly or a quadric curve.
So we can see here I plug that input into the preset generator and that's what I get.
So There are other possibilities in those drop downs.
What if I decide that I just am not content with that and what I really wanted was something that is slow at either end and fast in the middle?
And you should already have a mental image of what this looks like, but the curve is really easy to visualize.
This starts slow, accelerates in the middle, and then slows down again.
This is an inverse logistic curve.
And then just for the hell of it, I figured I'd do a consideration whose score fluctuates dynamically and there's a sine wave. I didn't bother animating the arrow because that was a pain. But you can kind of get the idea of where this is going.
So I wanted to pause here to kind of cover a couple of thoughts.
The natural language feature has gotten a lot of great feedback.
A lot of people really enjoy being able to work with it, being able to specify things in what feels like a much more intuitive manner.
It's super easy to implement.
It's literally just a tag on each preset that says, these are the different properties this function has.
It increases quickly at the beginning, slowly at the end, or whatever the curve might be.
And then the drop downs are just a filtering mechanism.
So it's super easy.
There's not actually any natural language AI.
I'm sorry if I disappointed anyone.
There's no real genuine difficult work going on here.
But this is low hanging fruit for everyone who doesn't want to have to think about the equation form of all those response curves.
So this is a very different type of intuition that people can develop about how utility AI works without having to think about it in more math, more formal terms.
Now I think we can go further than this.
You'll notice that in the screenshots there was this notion of as the input grows towards one.
I'm not totally happy with that.
I would like the UI to say something more relevant.
Like as the input, which actually is distance, grows towards the upper end of the range, which is 75 meters, then I should get something that says as distance to target grows towards 75 meters, the score should, and then the designer fills in the blank.
So that's kind of an idea of where I'm going with all this.
I wanted to jump back to the consideration view real quick because there's another escape hatch that's worth calling out real quickly.
And that is this wizard button up here in the top right.
The consideration wizard is genuinely a wall of text, but the idea here is that if you've got a moment and you're not entirely sure what you're trying to accomplish, you should be able to sit down and read through these instructions and get a perfect idea of what you're trying to do and why.
So each of these panes, each of these tabs in the wizard goes through a different part of building a consideration. Uh the first one is input selection and this one here you can see is chosen distance to target. Um I then can do the parameterization which tells me what are my relevant ranges. I care about everything between zero and 75 meters. And then of course there's the actual response curve system which has the preset escape hatch again so that you can go look at the natural language version if that's what you prefer.
There's a fun little twist on the end of this one, which is that naming things is actually, as I said before, very important to me.
And one of the ways that I've emphasized that is by providing this link, which goes to the Curvature Wiki and actually explains in a very brief and digestible way, how to do good consideration names.
So this one, for example, is Prioritize Closer Targets.
This kind of gives you a real quick and three words idea of what the consideration is doing, what it's trying to accomplish for the AI.
So, this is probably my favorite phrase right now, is building intuition through play.
I really like this idea of experimenting and messing around and just getting your hands dirty and by that process alone, coming to comprehend how a system functions and how to control it.
So this is an example of a behavior with some considerations on it.
There's a...
set of inputs right up here that we can look at that correspond directly to the inputs that are in those considerations. So you remember things like distance or is this target on a particular team. I can also see the response curves here which show that for the current values of the inputs, these are the scores that the considerations will have.
Now as I play with these specific input drop downs, we should be able to see these response curves moving in response to what I'm doing. So I will change the distance and you can watch that blue dot on the bottom right box slide back and forth. That is a very visceral kind of instant feedback mechanism for someone who doesn't want to think in terms of equations, but does want to think in terms of geometric shapes.
So you can play with these and then if you want the numbers you can go over here on the left and look at the actual breakdown of the scores of what the considerations produced as they calculated their response curve values and what the score of the behavior was at the end of that process.
So this is useful if you're looking at considerations within a single behavior.
It doesn't do you much good if what you really care about is how different behaviors compete with each other.
So there is another tab in Curvature which actually targets that specific use case.
You can see in the center column there are the four behaviors that I introduced at the beginning, to pursue and to evade.
Right now I have the variance for the red team selected.
So I'm dealing with behaviors that only an agent on the red team would actually try to execute.
and the same input controls are here as well as we had in the consideration system with a twist.
If I have two decisions that are both based on distance, I only get one control in the UI that controls distance.
It will intelligently collapse all of the different inputs that are the same basic input data so that you don't have the problem of feeding considerations for this decision with a distance of 30 and considerations for this decision with a distance of 50 and now you get broken behavior as a result.
So the last piece of this is there's a little chart, and this is a lot more impressive with larger, more complex demos, but this is enough to get the point across.
You can see here there's these two behaviors that are being scored against each other, and the winner of them is highlighted down at the bottom.
So in the situation that I've configured with these sliders and everything up on the top, the particular decision that my AI will choose to pursue is actually to go chase down an enemy of the red team, or probably a blue guy.
And we can see that the score for that is .71.
So this is all different ways of gaining intuition of a running system.
But it's not quite enough.
I wanted to put in a last twist on the experimental intuition through play concept and do a complete sandbox simulation.
So, again, starting with the requirements for what I wanted this to be, I wanted to visualize what the AI would do.
So if I actually took and built all the data for an AI system and plugged it into this tool, I want to watch them actually behave.
The other thing that I really found really important, and I alluded to this earlier, is just debugging. I want a way to go back and look at this stuff and understand where it went off the rails and why.
So this real quickly is the scenario mode of curvature.
You can see up in the top left, there's some red guys kind of hanging around a little base, and there's some blue guys down in the bottom right doing the same thing.
I'm gonna go ahead and play this forward, and what you'll see is a whole bunch of these agents swarming towards each other, and then collapsing as they run into each other in the middle of the field.
And what's happening is they're doing exactly the two behaviors that they were given earlier in the behaviors section, which is to pursue their enemies and evade their allies.
That is the only thing these guys are going to do.
You'll notice as they move towards each other, they have this tendency to swing out.
And that is them trying not to run into each other as they go.
And then the fun part happens, and they realize that I've run into my enemy.
I don't have a reason to pursue him anymore.
I have no reason to exist.
And so they stall.
And this is actually an event that you can get in the curvature debug logs.
I stalled because I ran out of stuff to do.
So the debug logs themselves are a little more on the programmer-friendly side than the designer-friendly side at the moment, but this is something that is ripe for exploration, I think.
Down the left side is a tree.
The tree contains a list of every tick that has occurred in the simulation.
Underneath each tick, there's a list of every agent that did a thinking operation in that tick.
For every agent in that layer, there's a list of all the behaviors that they considered trying to do.
Then for each behavior that they thought about doing, there's a list of targets, so relevant things that they could do that behavior with in the world.
The winning option happens to be marked.
In this case, there's a small blue rectangle on one of the items in the tree on the left side.
This is just kind of a visual indicator of, this is the thing that in that tick, this particular agent actually wound up doing.
So the key here is actually the text on the right.
And that has all the details that we could possibly want.
I'm not going to go through it line by line, but basically from the top down, there's more generic to more specific information.
You can look at things like the position of the agent in the world.
You can look at what their decision was that they actually wound up doing.
You can look at the comparison between that decision and other competing decisions or even competing targets for the same decision.
And then you can finally, at the lowest level of granularity, you can see there's numbers there that represent the actual input values, the actual normalized input values, and the response curve scores for every single consideration that we processed in that tick.
So, just to kind of bring this around to a little bit more open thinking, the debug experience is kind of a work in progress.
There's a lot of stuff that could be done with it.
There's a lot of exciting potential there, in my opinion.
One of the things that would personally make me very happy is to be able to rewind the simulation to a specific point.
I would love to be able to scrub forward and backward on a timeline and say, this is where things went wrong.
I'm going to stop there, change the data, manipulate the AI design in some way, and then run the game forward, the simulation forward, from that exact moment in time, and see if it fixes the problem that I noticed.
Another thing that would be really cool is if.
you could modify the properties of an agent while you were running through the simulation.
So, I want to, I'm in the moment, I'm watching these guys have a giant fight, I want that guy to have 10 more hit points, I want to be able to click on him and go 10 more hit points, and everything just works.
That kind of thing would be very exciting, not just for me, but for a lot of the designers that I know work with these systems.
The current limitation of curvature is you can manipulate the properties of agents, but you have to pause the simulation to do it.
So...
You can inspect objects in the world, those little triangular or circular agents that were flying around in the simulation mode earlier.
You can click on them individually and get a breakdown of what they've been doing and why they're thinking about what they're thinking about.
uh it's opportunity for improvement here because there's a lot of information that could be there and it's very difficult to predict in uh uh kind of ahead of the time what information you might want that display to populate with. So I might know all kinds of things about this agent and what he's been up to but the designer only cares about one tiny slice of that and this is a UX challenge to figure out how do I pipe that slice of things that the designer needs to know through that particular interface of inspection.
So I got a couple of basic ideas that I really want to leave you with.
If you get nothing else, this is the good stuff.
We talk a lot about tools for producing stuff.
We do a lot of work to make tools so that we can ship games.
This is a great thing.
I think tools are very important.
I think tools are a critical piece of how we get our jobs done.
But we don't spend a lot of time talking about tools that just provide learning and exposure to a concept.
We don't spend a lot of time on educational tools that exist solely to help people build intuition through play.
One of the things that I think is very critical when we're talking about that type of tool is there has to be multiple ways to understand what's going on.
And that's why there are so many different modes and angles for approaching data in curvature.
Because what I want is for anyone to be able to find a route to that information that they're comfortable traveling on.
I want everyone to be able to sit down with that tool and feel that they understand utility AI because they can own the process of understanding what's going on under the hood.
And that means we have to give alternatives.
So iterating on the tool is just as important as iteration while you're using the tool.
A lot of tools talk, spend time talking about the user's iteration time and how you need to make sure that they can save and reload and do all this stuff really quickly.
That's all very important.
But actually evolving the tool past version 1.
is also extremely important.
And so that's something that I would like to reinforce here, is that when we build these systems, we shouldn't just let them sit once we're sort of happy with them.
We need to tend to them and grow them and evolve them with ourselves.
Sandboxes are a lot of fun.
This is just kind of a bonus point.
I love the idea of doing one outside of an engine because it means that it's very lightweight, it's very flexible, and it gives you the ability to experiment very quickly.
Most of all, I want everyone here, again, think about how you can improve AI tools and what you can do along these lines to make the experience of learning and using your AI systems even better.
Curvature is open source.
You can find it on GitHub at this URL.
I'll leave this up.
And this is also my email address.
And that's what I got.
Thank you very much.
