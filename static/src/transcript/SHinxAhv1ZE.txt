So, understanding constraints.
So, I started my talk last year with a story about Legos, and people seemed to like that, so I'm going to start this year with another story.
So, a long time ago, when I was a teenager, I fell in love with skateboarding.
And I loved it so much that I built a skateboard ramp in the backyard of my home.
in Ohio, and it looked a lot like this ramp.
And this is called a halfpipe.
So there's a flat bottom joined by two quarter circles.
So back then, I used to get this magazine, a skateboarding magazine called Thrasher.
And in that magazine, there was an article that said that you could build a skateboard ramp with a different shape than the regular halfpipe.
that uses this cycloid shape, and that would be faster.
And that's kind of like the optimal shape for a skateboard ramp.
So a cycloid is defined this way.
So if you have a rolling circle and you trace out a point on that circle as it rolls, that curve that it traces out, that's a cycloid.
So back then I had no idea how this could be possible.
How do they know that it's this cycloid shape?
I didn't understand the mathematics.
Later on when I was in grad school, I was studying an advanced topic called the calculus of variations.
And in my book I found this problem called the brachistochrone problem.
Try saying that.
Anyhow, so in this problem.
They described an optimization problem.
So normally when you think of what the fastest way to get from point A to point B, you would say a straight line.
But if you're going from some point A to some lower point B, just under the influence of gravity, then a straight line is not the fastest path.
Actually, you need the path to dip down.
And With the calculus of variations, you can actually derive that the cycloid is the fastest curve for a skateboard ramp.
So, I thought this was amazing.
You know, I finally understood what I'd read about so many years earlier in Thrasher Magazine.
And, so, at this point I realized, you know, that mathematics can actually be very useful.
But I also realized that just understanding the mathematics was kind of its own reward.
And I feel that way about game physics.
Understanding constraints is very useful for what we do, but it's also kind of satisfying when you understand these things in greater detail.
All right, so let's get started.
So as a physics programmer, it is our job to understand constraints.
Constraints are as fundamental to game physics as shaders are to graphics programming.
So with shaders, you can use standard recipes for lighting, shadows, or you can make up your own shaders and create something unique.
Just like shaders with constraints, you can use standard constraints like Revolute, Prismatic, and you can implement those.
Or you can kind of come up with your own constraints and create something unique.
So constraints are an area where a physics programmer can show their knowledge and their creativity.
So we can model and program our constraints to a high degree of accuracy.
They can be accurate enough to simulate a robot or a satellite.
But the problem in games is that if we want to solve these constraints precisely, we need cubic time and we need quadratic memory.
But for games, we can't do that.
It's too much time, too much memory.
So we make do with linear time and linear space solvers.
So we're always wrestling with this low-accuracy solver.
So the better that we understand these solvers, I think the better chance you'll have of creating robust game simulations.
So.
Understanding constraints can be very useful.
You know, if you just start with constraints and you use the standard techniques, you can create constraints to do ragdolls and destruction.
But if you understand constraints more deeply, you can do things like motorized ragdolls or soft constraints.
And you can go even further.
You can develop things like block solvers, position solvers, and character solvers.
And I'm going to be talking about some of these things today.
All right, so I've been talking about constraints at the GDC since 2005.
You can find a lot of this reference material on my website, box2d.org.
Nevertheless, I'm going to go through a bit of review here.
So, in my opinion, everything starts with the position constraint.
So imagine this skateboarder never leaves the ramp.
It's just moving back and forth on this half pipe.
So.
The skateboard is constrained to that surface, but can move freely on that surface.
So this is a position constraint.
So let's look at how we would actually express the position constraint for that ramp.
Well, for simplicity, we're just going to treat the skateboard as a particle.
And the position constraint that we need to develop is a...
It's a scalar...
function of the position of that particle, P.
And that constraint function, C, it must be equal to 0 when the constraint is satisfied.
Otherwise, it must be non-zero.
So the bottom of the ramp is flat.
So I've just defined C to be the sine distance of that particle from that plane.
So if the particle is above the plane.
then C is positive.
If the particle's below the plane, then C is negative.
So that has the properties that we want.
I need a different position constraint for the circular part of the ramp.
So, in this case, the particle is restricted to be on a circle centered at P0, and the circle has radius R.
So here, C is just the distance of the particle from the center of the circle minus the radius.
And that has that same property, that if you're on one side, it's negative.
If you're on the other side, it's positive.
And if you're right on the circle, then it's zero.
So actually, you can think of this constraint function, C, as defining an implicit surface.
So in this case, C implicitly defines the circle.
Alright, so now let's look at a constraint that's very ubiquitous in game physics.
It's the contact constraint.
So, I have a box B on this fixed plane A.
And I'm going to set up the contact constraint for the lower left corner of the box.
So I'm just going to do one contact point.
In reality, you might have multiple contact points.
Yeah, you'd have another contact point in this case for sure.
The contact constraint says that the contact points on the touching bodies don't move relative to each other along the contact normal.
So for right now, I'm just going to treat this as a bilateral constraint.
In other words, I'm not going to let the box leave the surface.
Later on, I will talk about how to handle inequality constraints.
So we have the position constraint for that contact.
And I should note that...
So in the picture there, I have P as one point.
Now I have a point on the box, and I have a point on the plane, and those are overlapping, so that's why you don't see P-A and P-B, because they're both the same point in this picture.
So to get the velocity constraint, I need to take the time derivative of the position constraint.
And we're going to need that velocity constraint for the solver, so that's why I'm doing this.
So, to do...
to get the velocity constraint, yeah, I just do the time derivative.
And there's dot notation.
That means differentiation with respect to time.
So that dot above C means dC dt.
And to compute the derivative, I have to use the chain rule of differentiation.
So I get two terms there.
All right, so I can make some simplifications now.
So...
First of all, the ground is fixed, so P.A is zero.
So the velocity of the contact point on the ground, it's not moving.
So that works in this case.
And also, in general, I can get rid of that second term completely because, by definition, when I'm evaluating the velocity constraint, P.A and P.B are overlapped.
That term just drops out.
So then I'm left with something a bit simpler on the bottom.
All right, so the solver is going to need to deal with velocity at the center of mass, not velocity at the contact point.
So I need to use this standard formula that relates velocity on a point on the rigid body to the velocity of the center of mass plus...
A term involving the angular velocity and this radius vector r.
So, I can express p.b that way and then substitute that into the velocity constraint.
Alright, so I have the velocity constraint now.
Our solver is also going to need to know about how the impulses are set up, because the solver is going to work with impulses.
So, the idea is to apply impulses to steer the velocity of the box so that the velocity constraint is satisfied.
Well, for the contact constraint, I have to apply an impulse at the contact point along the direction of the normal.
Now when I do this, at the center of mass, there's going to be a linear impulse.
And there's also going to be kind of like a torque, an angular impulse, created because the impulse is not applied directly below the center of mass, it's applied off to the side, so there's going to be some induced rotation there.
So I need to also express what the angular effect from that impulse is.
And so...
I have this symbol here, lambda. Lambda represents the sine magnitude of the impulse.
So, actually, I know where the impulse is applied. I know the direction of the impulse.
All I need to figure out is, okay, what is the value of lambda to satisfy the velocity constraint?
All right. So, now if I actually want to solve for lambda...
I need to bring in Newton's Law.
So here I have Newton's Law in impulse form.
So the first one is the linear equation of motion.
It says that the change in linear velocity of the center mass is related to the impulse, the linear impulse.
And then the second one is the angular equation, and that That expresses the change in angular velocity in terms of the angular impulse.
And that also involves the inertia tensor I.
All right, and then now I can bring in my velocity constraint.
So I just rearrange things here a little bit.
I have the velocity at the final state, state 2.
So I want the velocity constraint to be satisfied at state 2.
It's too late to do anything about state 1, that's kind of the input.
What we're going to move to, we're going to apply an impulse and then move to state 2.
And at state 2, I want the velocity constraint to be equal to 0.
Alright, so now I actually have enough equations to solve for lambda.
And here's how you do that.
So, Newton's law, I isolate v2 and omega2, so the linear velocity and angular velocity, and express those in terms of that unknown impulse lambda.
Okay, so now I can substitute the expression for v2 and omega2 into the velocity constraint.
And so that's what I have there on the lower line.
All right, so...
We can just rearrange those terms and come up with a formula for lambda.
So first I have this collection of terms which I'm calling the effective mass.
And then that's multiplied by the initial velocity constraint.
So if there was no air initially in the velocities, then I wouldn't need to apply any impulse.
If there is some error in the initial velocity, then I'm going to have some non-zero impulse that I need to apply.
And so that first term there, called the effective mass, I think of that as kind of the mass of the box projected onto that constraint axis.
And it is kind of the inertial resistance seen by the impulse.
And it has units of mass, so that kind of works.
Alright, so that was a single constraint that I solved.
In game physics, we're going to have lots of constraints, and we have to solve all these constraints together.
So this problem is much more difficult, because when you solve one constraint, that can...
uh... introduced air and other constraints cuz you're like tweaking the velocities of all these rigid bodies and and uh... they're all interrelated so to to actually solve this accurately you have to build uh... a matrix equation and and and solve that matrix equation if you had a hundred constraints you'd have to build and factor a hundred by hundred uh... matrix and this will be uh... you know likely too slow for most games So, therefore, physics programmers often make do with linear time solvers that are local solvers.
So what we do is we go through and solve one constraint at a time, and then iterate and do that over and over, hoping that the whole thing will converge.
So sequential impulses is a kind of local solver that I'm going to be talking about.
So I'm going to show you an example of how sequential impulses work.
So suppose you had a stack of circles and they're all at rest.
Okay, and then at the beginning of the time step, apply gravity and then adjust the velocities so they're all moving down at the same speed.
Now to counteract gravity, I need to apply impulses at the contact points to support the weight of the circles.
And actually, if you think about it, each contact point needs to support the weight of all the circles above it.
And so that's represented by these dashed lines.
And then, after one iteration, you can see the impulses start growing there.
And those are those arrows pointing up.
And they're kind of reaching towards that exact solution.
So there were still some errors, so we iterate again, and the impulses get a little bit closer to the exact solution.
And I should mention that when we're solving those contact points, it's kind of in arbitrary order.
You could solve a top-bottom, bottom-up, random, whatever you want.
It doesn't really matter, except in terms of performance for, like, cache-friendliness.
And then, you know, if we iterate some more, we'll get even closer to the exact solution.
So at some point, we just got to cut off the iterations because we have to get on with our game.
So there's going to be some error in those impulses, and the result of that is the objects are still kind of moving into each other.
So then when you go update the positions, you're going to see some overlap.
I'll talk later about how to deal with that overlap.
Alright, so that's kind of end of review.
Now I want to talk about one of the main topics is understanding convergence.
So you can kind of see this iterative solver is kind of converging.
And we need to look at that in more detail to really understand what's going on.
So when I think of convergence for an iterative method, what I think is like, OK, I had this previous error.
And I'm going to multiply it.
When I do my solution, I'm going to multiply that by some fraction, alpha.
And hopefully that fraction is less than 1.
So then my error will then decrease each iteration.
If alpha were to be greater than 1, you'd have divergence.
Convergence may be fast in some cases where you have a small alpha, or it could be slow in other cases where you have a large alpha, and that's what these curves represent.
We don't have control over alpha directly, it's just kind of like representative of situations you might see.
And let's look for some of these bad cases, you know, these large alpha cases.
the difficult situations we run into.
So I'm going to explore convergence by looking at circle stacks.
Circle stacks are nice because they limit the problem to one dimension.
So we kind of understand things better.
So in the case of a single circle, when I solve that constraint, I actually get the exact solution.
So there's really nothing interesting there.
There's no competing constraints.
OK, so if I go to more circles, things get more interesting.
So I actually created a MATLAB script that runs the sequential impulses algorithm.
You can get that script and some other scripts I'm going to have in the presentation when you go download this later from box2d.org.
And you can run these scripts in a free software called Octave.
So, anyhow, in this case of two circles, the graph here shows these dashed lines which are the exact answer, and then the curves are the contact impulses as I iterate.
So the x-axis is the iteration, and then the y-axis is the total impulse applied.
So you can see, after about five iterations, I get 95% accuracy.
So that's not bad.
All right, so mass ratios are often quite a difficult problem for physics programmers.
So I'm going to start looking at different mass ratios.
So how about if I have a half kilogram circle on top of a one kilogram circle?
Well, in this case, convergence actually got better.
I only needed three iterations.
Let's flip that around.
So now I have a one kilogram circle on top of a half kilogram circle.
So now the convergence is much worse.
I need around 10 iterations to get 95% convergence.
Now let's take that to an extreme point of mass ratio of 10 to 1.
Now I need around 50 iterations.
So things are getting quite bad.
with this mass ratio increasing.
So you might wonder, well, how bad is it if I just increase the mass ratio indefinitely?
How does the number of iterations I need, how does that change?
So what I did is I kind of ran a simulation of simulations.
So I set a mass ratio and then...
Counted how many iterations I needed for 95% convergence.
And then I did that for several mass ratios.
And then I plotted it all out.
And it actually turned out to be a straight line.
So a curve fit said that the number of iterations needed was three times the mass ratio plus two.
So what that means is, one, the minimum number of iterations you're ever going to need is two.
Also, as iterations increase, as you double the number of, I'm sorry, as the mass ratio increases, as you double the mass ratio, then you need double the number of iterations.
So why is convergence slow?
So let's do a little thought experiment.
So I have this heavy circle on top of this light circle.
And what does the solver see there?
Why is it slow to converge to that problem?
Well, let's just start out a time step.
So we apply gravity.
And now both these circles are moving down with the same velocity.
And let's say we're going to solve the bottom contact point first.
So we solve that bottom contact point for the small circle.
It doesn't know about this big circle on top.
So when I solve the contact for the small circle, it's just going to apply enough impulse to bring that small circle to rest.
Okay, so now that small circle is at rest, and now I still have this big circle moving down, and I'm going to solve that upper contact point.
So, when I solve that upper contact point, we have this big circle moving down, there's this tiny circle at rest.
And when I solve for the contact there, it basically just brushes that small circle out of the way, and the top circle only slows down a little bit, because that upper contact doesn't know about the ground below.
So now this top circle is slowed down just a little bit, the bottom circle is moving down.
I go solve the bottom contact again, the small circle comes to rest.
And then the same situation, when I go to solve the top circle...
or top contact again, I'm just taking a tiny bit of the velocity away from that top circle.
So you can see I'm just kind of, I need to bring that top circle to rest by only removing a small amount of its velocity each iteration.
So that's why the convergence gets slow when that mass ratio gets high.
Okay, so we saw that the mass ratios cause a lot of problems for convergence.
When we had just one circle, we only needed basically one iteration.
For two circles, I needed five iterations.
In the case of four circles, I ran a simulation, and I needed about 20 iterations to get a convergence.
So a nice exercise now you might try, you can download the script and try if you want, is to...
See, well, as I grow the stack size, how many iterations do I need?
So you can maybe generate a graph of that, iterations versus stack size.
Alright, so...
we have all these convergence problems with our local solver, with sequential impulses.
Is there something that we can do to kind of help it out?
Well, in games, things don't move a whole lot from frame to frame.
And we have lots of frames.
So maybe we can make use of that coherence to kind of break up the solution over several time steps.
And so that's the idea of warm starting.
Kind of just taking a few iterations each time step and then passing the result on to the next time step.
So here's how that works in pseudocode.
So let's say I have my solver, and it's computing these incremental impulses, and then adding those impulses up into accumulated impulse.
So I compute an incremental impulse each iteration that I pass through for that contact.
And then I'm just storing all those incremental impulses up.
And then I just... but I apply that incremental impulse.
Okay.
So now I have that, at the end of the time step, I have stored this accumulated impulse.
And then I bring that around to the next time step, and the next time step at the beginning might apply gravity, and then I just apply that stored accumulated impulse.
And then I go start my iterations.
So, imagine I had already converged.
I already have the exact...
impulse to support whatever objects are there.
If I... and nothing moves and nothing changes.
If I apply that accumulated impulse at the beginning of the time step, then that completely counteracts gravity and the system is completely stable at that point.
And then when I go iterate, those delta impulses actually end up being zero.
So that's how it works.
There is some downside to warm starting.
If you have a heavy load and it's suddenly removed, then that next time step after you remove that heavy load, you may not have enough iterations to kind of back off on that large impulse you have in your contacts.
And what you'll see in that case is you may see a bounce.
And I'm going to show a demo of some of this stuff.
All right, so this is Box2D.
I created a couple of demos.
Zoom in here a little bit.
OK, I'm going to make some changes.
I'm going to turn off Warm Starting, turn off Continuous, turn off Sleep.
I'm going to turn off Position Correction.
Let's start this over.
So without Warm Starting.
And I'm doing eight iterations here.
That's just not enough for the solver to compute the right impulse to support that large circle on top.
So, like I said, you're going to have some big errors in your impulses, and so your velocities are not right, so objects move into an overlap state.
Let's turn on warm starting.
All right.
There's some bouncing there, but I do get proper support eventually.
The reason for the bouncing, we were just talking about this yesterday, and I kind of figured it out.
So when the objects are moving down, you need kind of a large impulse to bring them to rest, and it's larger.
then the impulse you need just to kind of hold them there after they've come to rest.
So that's kind of the situation where there's this large load, then it gets removed, but then you don't have enough iterations to back off, and so the impulse is still large, and then so that causes a bounce.
And let's look at a better example of that effect.
So here I got two little circles and I'm going to go down to just two iterations on the velocity constraints.
All right.
So now I've got this heavy circle on top of these two little circles.
Warm start is on, so it's converging, but there's some bounce.
All right, now I'm going to delete that top circle and watch the two little circles.
See, there was a bounce there.
And that's because there was that stored impulse there that just couldn't be reduced quickly enough.
And so it was too large and then that caused lift-off.
All right, let's get back.
All right, so next topic is understanding inequality constraints.
So, constraints like contact constraints require special handling.
In this case, the constraint can push, but it can't pull.
So, in the context of sequential impulses, it's not hard to deal with this.
It's not hard at all. We just need to use some clamping.
However, we have to be careful about how we clamp.
So you could just say, well, I'll compute that delta impulse, and I'm just going to clamp it so that it's always pushing.
It's always greater than 0.
This is actually wrong.
So what you want to do is clamp that accumulated impulse.
So you can think of that accumulated impulse as the total amount of impulse you applied at that constraint over the time step.
So you want that thing to be positive.
This will allow the incremental impulses to be negative.
And here's how you do that.
So first, store the old accumulated impulse.
Go ahead and compute the incremental impulse, delta.
Then add that into the accumulated impulse.
And then clamp the accumulated impulse.
And then the next step is the tricky bit.
So I'm going to adjust that incremental impulse to be the actual change in the accumulated impulse.
And then I go apply that updated incremental impulse.
So there's a few more steps here.
But essentially, all I'm doing is clamping to achieve the inequality constraint.
So why do that?
It's because of overshoot.
OK, so there's.
Clearly, in the case of warm starting, you're going to need to do this, because as objects start to lift off, the impulse needs to decrease.
We need some way of decreasing the accumulated impulse.
How about in the case where we don't use warm starting?
Do we still need this?
Well, let's try to figure that out.
All right, so I want to start looking for overshoot.
So in the case of a box on a plane, we'll have two contact points.
And I wrote a script that solves this.
And here's the graph of the solution.
Now, these two contact points, they should both be supporting half the weight.
So there's no rotation.
You want them balanced.
So they should both be going up to that dashed red line.
And they do, they go up in two iterations, and there's actually no overshoot.
So you don't, in this case, actually don't need any clamping.
So, that's not the case we need.
How about instead of the box being on this big plane, it's actually on top of some pole?
Now, you can imagine this in the extreme case, where the pole gets narrower and narrower.
Then we basically have two contact points, which are almost on top of each other.
If I have one contact point below the center of mass, and I go solve that, it's going to want to support the entire weight of that box.
But, let's say I move that off to the side, it's still going to be very close to the entire weight of that box.
Now I bring in another contact point, and when I go to solve it, it's like, well, the box is not moving down anymore.
Now there's just a small rotation, so I'm just going to apply a small impulse there.
So let's see how this plays out in a simulation.
Alright, so with the pole at 75% of the width of the box, already I got some overshoot.
So this shows that we need to clamp the accumulated impulse.
Otherwise, you would never be able to back off of that overshoot and get to that exact solution.
And in this case, convergence is still good, just two iterations.
How about a 50% width?
Now I've got even more overshoot.
I really need to be able to apply negative incremental impulses to back off on that overshoot there.
And now I need five iterations or so.
No, just a couple more.
All right.
Now at a 25% width.
I need around 12 iterations, and there's a lot more overshoot.
So this is actually kind of interesting, because I was looking for a case where I had some overshoot.
But I also found a case where convergence starts to suck.
So this is a case where there's no mass ratio problem here.
I only have one moving object.
Yet I need more and more iterations as the geometry gets more extreme.
And this type of stuff happens all the time in games.
So, yeah, another case where having a local solver causes trouble.
So, we can kind of address this problem with...
a block solver.
So the idea is, well, I really love that exact solution that the global solver gets, but I just can't do that on all my constraints.
But maybe I can apply that kind of matrix methodology for just a couple constraints at a time.
So what you can actually do is solve for those two contact points simultaneously.
So yeah, in 2D.
You know, if you have two convex polygons colliding, you either get zero points, one point, or two points.
So the most I'll ever have to deal with is two contact points between two colliding polygons.
So in the case of two contact points, I'm going to try to solve those two impulses simultaneously.
And if you think about it, there's actually four cases.
There's a case where both contacts have a positive impulse, or one contact is zero and the other is positive, or vice versa, or they're both zero, and that means the objects are moving away.
And so what I actually do is solve all four cases, looking for the case that's valid.
So first I solve a two-by-two matrix, because I have to solve both constraints simultaneously.
And if those...
Both those impulses come out positive, then I'm done.
Otherwise, I set one constraint to zero, basically forget about it, and then solve for the other one.
If that's negative, then I switch and try the other contact.
And if that's negative, then the objects must be leaving, and they're both zero.
So I'm not gonna go into any more detail about this, but you can actually find this in Box2D.
And I will show a demo of how it works.
I'm going to turn off the position solvers, sleep, continuous.
Okay, so I have it set up so that I can turn on and off the block solver.
So now I just turned it off and we only solve one contact point at a time for this stack of boxes.
So there you can see the asymmetry.
and introduced by just solving one point at a time.
If I could turn on the block solver, there it almost behaves like a stack of spheres.
It's because I'm solving those contact points simultaneously, so they're perfectly in sync and completely symmetric there.
So that kind of solves that problem with the convergence.
Like on the pole, if you had a narrow pole, you wouldn't have any convergence problem there.
Alright, let's move on.
Alright, so next topic is...
Well, we started with position constraints.
And then we took the derivative and we got the velocity constraint.
Well, what if I want to work with forces and I want to work with accelerations?
Because that's how Newton's laws are written, right?
That's maybe more intuitive.
And you can actually do that.
You can take one more derivative of the velocity constraint and you can get the acceleration constraint.
And then you can work with accelerations and forces.
But there's a problem.
So, first of all, With a rigid body, when you have collision, the collision happens instantaneously.
So that means that actually you would need infinite forces, because you need to be able to change the velocities of those objects instantaneously.
And when you're dealing with acceleration and forces, you need an infinite force to do that.
So we don't do that.
You could say, well, OK, I'll apply impulses during collisions, but then I'll use acceleration of forces when things are in steady contact.
Well, that also doesn't work.
Here's an example of where you can run into trouble.
So let's say you have this rod that's sliding across the ground.
There's going to be some friction force pushing back on that rod.
And that kind of tweaks the rod and gets it to dig in.
That increases the normal force.
But the normal force and the friction are related.
The stronger the normal force, the stronger the friction.
So then the friction gets larger.
And then the normal force gets larger.
And this becomes this positive feedback cycle.
And they both become infinite.
Yeah, so for this reason, game physics programmers abandoned working with acceleration constraints a long time ago.
If we go over to what we know, velocity constraints, it's no problem.
That rod is digging in.
We can apply a friction impulse to bring that contact point to zero velocity instantly, and then the rod will tip over.
So it's no problem with velocity constraints.
So the impulses remain finite.
So are velocity constraints the best thing?
Well, they work really well with friction, because friction is purely just a velocity constraint.
It doesn't care about position.
So that seems to be a sweet spot for rigid body simulation, but that doesn't mean that.
There might be other choices and other things we have to look at.
So, first of all, the velocity solver is not perfect.
First of all, nonlinearities due to rotation means you're not going to get an exact result.
You have a fixed number of iterations, so you can get into overlap situations very easily if you're only solving velocities.
So, the sequential impulses algorithm doesn't...
It doesn't do anything to help you with that.
You have to add some additional stuff to deal with overlap.
So one common method for dealing with overlap is by velocity steering.
Basically, we take the velocity constraint that we have.
And then we add in the position error into that to try to steer the objects in a path that removes that overlap.
So here you can see I started with the regular contact constraint, and then I added some stuff below.
So there's this beta factor, which is kind of like a tuning factor.
And the S in this case is the signed distance.
So in the case of overlap, it would be negative.
And then I've got to divide by the time step.
That makes sure that I have units of velocity.
So length over time.
And then, yeah, beta is a non-dimensional thing.
If you set beta to 1, you're basically saying, I want to remove all the overlap in one time step.
We don't usually do that because you often, due to other inaccuracies, you'll get some overshoot.
So, usually use a beta factor less than one.
So what this does is when we feed this adjusted velocity constraint to the solver, it's gonna do then, the impulse will be a little bit stronger, and then your velocities are gonna get adjusted.
All right, so there's a problem with that.
First of all, you're adding kinetic energy to deal with position overlap.
And this can actually lead to instabilities in some cases.
Also, it may make your constraints look less solid.
So I like this idea of velocity steering, but I don't like it feeding into the velocities that I have.
So what you can do is you can completely decouple the position correction problem.
And instead of dealing with the real velocities, use pseudo-velocities and also pseudo-impulses.
So but we can use the same machinery that we had set up for solving velocity constraints to solve position constraints.
So here's how it works.
So I set up Newton's Law using the pseudo-velocity, pseudo-impulses.
Then I have like a pseudo velocity constraint, and I use the same solution technique.
But those pseudo velocities only exist for that one iteration.
So they start out zero.
So there's no concept of momentum.
Also, those impulses, I don't need any warm starting because.
If the position constraint is satisfied, then those pseudo-impulses should be zero, because there's no external loading.
So, actually, when you converge on the position overlap, those pseudo-impulses go to zero.
You also need to remove things like friction, other things that are only velocity-dependent.
You also see that in the bottom equation, the pseudo-velocity constraint, I've removed time, because time doesn't really mean anything when you don't have momentum and you're just trying to resolve some overlap.
And actually, you can see that then these pseudo-velocities are just like delta positions.
They don't have time involved either.
And this method.
It's basically an iterative method for solving a non-linear equation.
Because the position constraint is basically a non-linear equation.
So to resolve positions, now I have this separate solver that happens after the velocity solver.
So now there's this extra iteration load.
It's not too bad because I found in practice I don't need as many iterations for the velocity solver.
I mean for the position solvers I need for the velocity solver.
So, where the velocity solver I might use 8 iterations, for the position solver I use 2 or 3 iterations.
Alright, so...
We saw that velocity constraints were better than acceleration constraints.
Does that mean position constraints are better than velocity constraints?
Well, in cloth solvers, like a Verlet solver, we actually deal with position constraints directly.
So, typically you're dealing with these distance constraints between two particles, and you just, you know, that's a nonlinear constraint, but you can solve it exactly by either moving the points apart or together.
And so we're not actually solving any velocity constraints there, we're just adjusting positions.
But we still want some concept of momentum, and the way that works in a cloth solver is you basically record the position at the beginning of the time step, then you go solve all the distance constraints, you get the new position, and then you just...
Compute the velocity from that change in position and divide by the time step.
So that way the constraints kind of affect the momentum there.
Another example of a position solver is a character solver.
Character solvers are used to move avatars around in the game world.
The main job is to prevent the character from moving through walls.
But the motion may not, you may not want that to be governed by rigid body rules.
You may want, like, gameplay code governing the motion.
So, it's just purely a collision solution method.
So...
What you often see for these character solvers in games is they will actually use a velocity solver, whether they know it or not.
So you have some, say this character solver is just using a collision circle, and it's sweeping across the world and it hits some plane.
And it says, well, okay, the way I'm going to handle that is I'm just going to clip the velocity against that plane, and now, okay, now my velocity is going up that plane.
But I don't know why you would do it this way, because you're still going to have to deal with some position problems.
You may get some overlap. Things may be spawned inside of each other.
So you still have to deal with the position problem.
Also, we don't want any friction sliding along the wall.
So that would be good if I'm doing velocity type of solver to have friction.
Normally we don't want friction.
So we can actually just use a position solver to solve that same problem.
And that will allow us to deal with overlap as well.
So here's how the position solver would work.
So you start at point P1, and then you move to the target point.
Along that path, you may do a shape cast, and you say, oh, there's a plane there.
I need to deal with that plane.
So move to that target point, and then just project onto the plane.
And that's pretty much it. It is quite simple.
And you can generalize this to deal with multiple planes.
And it actually looks a lot like the position solver.
You can kind of express this as an optimization problem.
I want to minimize the distance between the final position of the character and the target position, subject to a bunch of plane constraints.
And, yeah, here's how the solver is structured in pseudocode.
So we move to the target position, then for some number of iterations, we iterate over all the planes.
If I find that the character is behind any plane, I project it onto the surface.
Any local solver, there's going to be some downside.
So the downside for this kind of local solver is acute angles.
Now you could say, well, I can solve for two planes at once, and so I can deal with those acute angles.
But in reality, in complex games, you may get really complex collision, and you have lots and lots of planes to deal with.
And then you're back to solving some big matrix problem.
It turns out that using the iterative solver works out well in practice, mainly because it is super cheap.
So I never see that thing be nearly as expensive as doing all the collision detection.
So with acute angles, what happens is you move to the target point and then you start projecting onto the planes and then you just see this ping-ponging as you're trying to solve each plane.
So it takes a bit more iterations, and the more acute the angle, the more iterations you need.
All right, so...
basically, in terms of understanding constraints today, what I've covered is convergence, inequality, and acceleration position constraints.
There's other topics for understanding constraints, but I think this is a good start at understanding these aspects, and it will give you a lot of tools to deal with...
making your games more robust.
So thank you.
Here's some references.
You'll be able to download these slides and the scripts.
And you can reach me on Twitter or at pox2d.org.
I'll leave the references up and I'd be happy to answer any questions.
Please step up to Mike if you want to ask a question.
Hi, I don't have a question. I just want to thank you for Box2D.
You're welcome.
Thank you.
Okay, now it's working. Okay.
I just wanted to ask you that you're now working at Blizzard.
Are you now working mainly with 3D physics there?
And what kind of differences do you have added challenges regarding, for example, the constraints in 3D?
3D, the biggest problem is rotations.
Rotations become much more complex in 3D.
But a lot of the same convergence problems exist there.
So you can understand quite a bit about dealing with constraints just by looking at 2D, even in 1D.
That's a big reason why I work on Box2D, actually, is so I can understand these kind of fundamental problems at a simpler level.
Hi.
Well, as far as I understand you, you do not recommend to use acceleration constraints.
Correct.
You recommend to use velocity constraints for objects in gravity or in some kind of force field.
Yes?
And you recommend to use position constraints for characters.
Yes, yes.
Thank you.
You're welcome.
All right, well thank you very much.
Coming up at 11.15 we're gonna have Erwin Koomans talking about Featherstone.
