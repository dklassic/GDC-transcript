All right, so Bill and I are both engaged in a fairly large project to try to develop new approaches for reusable, sort of a cross scenario and a cross character social behavior.
So the first thing is, what do we mean by social behavior?
And what we mean by social behavior...
is the kind of behavior that we found in Facade, where the characters are engaged in activity which is primarily about modifying the social state. They're not necessarily worrying about, you know, in this case, weapon combos or combat behavior or navigation.
but really about doing things that express rich social state change.
Like, you know, I don't like you, but I'm hiding I don't like you, and I'm trying to ally with this person over here.
This is the kind of behavior that we really want to make radically reusable across characters.
So the vision we have is reusable social behavior.
Reusable means it's applicable to multiple characters in multiple game worlds, that it's easily overwritable for custom content.
So the idea would be that you've got a big library of social behaviors.
You can sort of drop them quickly on characters and sort of get to this 80% point.
in say a particular social situation you're creating and in that 20 percent there's a nice kind of layered system for going in and doing overrides and inserts.
It should be highly mixable. Combinatorial behavior blends and behavior contracting where one behavior kind of will tell another behavior to do something for it in its service, but somewhat generative to avoid combinatorial authoring.
If we have combinatorial blends, but you have to author how everything combines with everything, well, then you're just back to this giant authoring problem.
We want it to be real time, where behaviors play out continuously and are continuously reactive to player input.
And we want it to be symmetric.
that every role in a particular social behavior can be performed by an NPC or a player, that they can all perform and respond to the same actions.
So if we score a facade in this case, well, real-time it was doing okay.
There's continuous performance and it's fairly interruptible.
You know, there's never really, you know, kind of in-engine cutscene-like activity where they're sort of blabbing on for a long time or performing some action and you can't interrupt them.
pretty continuously interruptible and they're performing all the time. They never just stop and go into, you know, kind of a Perlin noise loop to establish their liveness while they wait for the next thing. They're moderately mixable. So, for example, you know, the characters can make drinks while arguing about any topic. There's an eight ball gag that can sort of mix in anywhere on top of things. There's a lot of complicated staging that's going on that can mix in on top of any argument behavior.
So, fair amount of mixing. I'd like them to be even more mixable.
Complete fail on reusable and symmetric.
The majority of the behaviors are very specific to Trip and Grace in this scenario.
So even if you wanted to make another story about Trip and Grace, there would be a bunch more behavior authoring you'd have to do.
And if you were trying to make a sort of AI-based interactive story about completely different characters, well, you're going to have to almost start from scratch.
So not reusable and not symmetric.
Trip and Grace can do a lot of things with each other, like be snarky and understand they're being snarky and respond to the snark that the player can't do.
The player can't sort of say something in a snarky way and know that they'll get the snark.
And there's a lot of cases like that where the characters are engaging in sort of richer social interaction with each other than the player can with them. So in Prom Week, which we talked about a couple of years ago here, our goal was to say, well, can we push reusability at the dialogue level?
We wanted to have a larger cast of characters where we could generally write social exchanges between characters and have those social exchanges automatically re-target onto specific characters in specific social contexts.
So social behaviors in prom week were more reusable.
We could dynamically retarget dialogue within a scenario, but had very little physical behavior.
Effectively, kind of dialogue exchanges were sort of illustrated by tagged animations that went with them.
So I guess you could call that sort of physical behavior reuse, but it's sort of like, you know, zero with order physical behavior.
It doesn't provide overrides and inserts for cross-scenario authoring, but was definitely far more reusable than Fassad's social behavior.
And it was symmetric.
Anything the characters could do, the player can do.
In this case, since it's sort of a god-like game, the player is sort of, in a sense, determining which of the affordances characters are computed they want to do next, they take.
But you could imagine versions of using the underlying social engine where the players have a menu of exactly the same kind of affordances that the characters have.
This is very much the approach also that Richard Evans took with Praxis, the engine behind Versu, was this kind of symmetry at this kind of discrete choice point level.
But, like in Versu, we achieve that by simplifying affordances.
The affordances are discrete choices that can sort of be computed and put into a menu.
It's not real time at all.
strict turn-based interaction, not interruptible during a social exchange, and it's not mixable. There's only one social exchange occurring at a time.
So the current project we're engaged in is to try to say, hey, can we get the best of both worlds here?
Can we get the reuse and symmetry of Prom Week and the real-timeness and mixability of Facade in sort of one architecture and approach?
We're doing this in the context of a DARPA-funded project in nonspecific cultural training.
And what this nonspecific means is what happens if you as the player are sort of dumped into situations where you don't speak the language, you don't understand the sort of cultural values and cultural norms, something's kind of escalating, and what do you do to try to de-escalate the situation to quickly suss out what's going on and keep it from turning into something horrible?
That's what's meant by non-specific cultural training.
This is happening in the context of a sort of whole body interaction system.
So if I just sort of play a snippet of this, here's one of our scenarios called the lost interpreter where the player has lost their interpreter and is trying to interact with people who doesn't share a language with other than a few words.
and just trying to find out, hey, have you seen my interpreter from this photo?
And so, you know, there's a lot of, you know, real-time gesture recognition going on, sort of pose and stance recognition, facial expression recognition, and so on.
And so those are the signals that are kind of coming into the AI, as opposed to, say, you know, the text that was being used in facade, you know, text and mouse movement and clicking that was in facade.
So this gives some sense of what the whole body interaction looks like.
So you can imagine the full architecture for this is pretty complicated in that there's sort of a lot of machine learning based gesture stuff we're doing.
There's the sort of social pragmatics piece that has to kind of turn that, take that and turn it into kind of higher level social moves that have occurred.
There's a drama manager that's trying to sort of manage for pedagogy and kind of dynamically update the simulator to kind of make specific pedagogical points.
And then within the social simulator itself is this new NPC architecture and approach that we've been building.
For the purposes of this talk, we're focusing specifically on the kind of social behavior NPC system within the social simulator and not the rest of the architecture.
And this is being done by, you know, a fairly large distributed team.
split across four organizations.
And the UC Santa Cruz team along with BBN are responsible specifically for the autonomous characters.
So what lessons are we borrowing from Prom Week?
What are we bringing from Prom Week?
that we're then going to adapt and enlarge on.
The first is the idea of declarative modeling for the characters.
You know, we do a lot of declarative modeling for other aspects of NPC interaction, right?
I mean, we keep track of positions, we keep track of like how much ammo, you know, there's a lot of sort of declarative state about the state of the world that we do, you know, say put on a blackboard for our characters to respond to.
But we don't do it so much for social interaction.
And Fassad did.
So a lot of the character state between characters, between Trip and Grace, was implicit in the behaviors.
It wasn't explicitly being modeled as values that are being changed by moves the AI is making.
This was one of the first things that PromWeek did, is to say, hey, let's make all of that explicit.
traits, social statuses, the current social state existing between all pairwise combinations of characters, make that declarative and explicit.
And now the system can start reasoning about it and explicitly taking social action to change it.
The other big thing we did there in prom week that we're adapting is this kind of utilities meet symbolic reasoning, this kind of soft rule-based reasoning approach.
So we all know from hearing talks from, say, Dave and Kevin over the years, the benefits of, and we may recognize this diagram, the benefits of utility-based methods.
That they keep you out of corners in the state space, you're constantly able to compute a value.
that the brittleness, basically, that symbolic techniques tend to have, go away.
But symbolic techniques are able to express much more complicated situations, like if X feels high romance towards Y, and Z does something mean to X, and then Y does something mean to Z, then there's going to be this tendency for X to want to date Y.
because Y basically came in as a knight in shining armor and saved X from being picked on by Z.
This kind of temporal, rule-based reasoning is really hard to capture as sort of algebraic combinations of sigmoids and exponentials and so on is very easy to capture in a symbolic system.
But then we lose, then we're in brittle land, right?
And we lose this kind of common currency and no edges, no brittle corners property that utilities have.
So what we do is on the right hand side of rules, instead of sort of computing like do this action, for example, if something's true, we just say add three to your tendency to want to date.
Add two to your tendency to do something mean and so forth.
So implicitly, you're actually computing multiple, really complicated utility surfaces.
that are implicitly being computed by a bunch of rule-based reasoning.
And so we're trying to get sort of the common currency and no corners aspect of utilities with the rich expressiveness of symbols.
So those are the sort of two big lessons from PromWeek that we're then saying, well, how do we do this with real-time reactive...
3D characters. So the first thing we need to do is take the notion of dialogue exchange and generalize it.
So in Prom Week, you can imagine that you have templated dialogue exchanges like this, and I won't go into this sort of natural language system, but you can imagine that you wrote maybe a thousand of these, and they're not specific to any character. They're just floating in space, right? And you can imagine that all the AI of Prom Week is basically just trying to say, in this specific situation in the game, which of these many dialogue exchanges that are sort of just floating in space do I want to zoom, zap, zap down onto these particular characters at this specific time so that it's social state and personality appropriate.
Like that's the, that's the sort of re-targeting that's going on.
Well, we need to turn this now into behaviors, right?
That what was before kind of a NLG-based template now becomes a fairly complex behavior tree that's controlling sort of what initiators, responders, and onlookers are kind of all doing reactively and in real time during the carrying out of that social exchange.
So the specific idiom we've developed to capture this is this notion of social games, which we talked about social games and facade, but in facade they were sort of like a design idea, but weren't reified in the architecture.
Now we're reifying them in the architecture.
So two examples of social games that we've implemented are alliance and authority.
Alliance is the general idea of NPCs and the player, and sort of any number of them, having kind of a bidirectional alliance values between them, how much I feel like you're currently could be one of my allies.
And then this binary allies thing, which can be accomplished through social exchange.
If I feel high alliance towards you and you feel high alliance towards me, we're going to have a tendency to want to take social action that actually establishes the binary or Boolean social fact of currently being allies, and then allies may break up and so forth.
So all of that states modeled.
The authority game is really about authority that NPCs and characters generally, players and NPCs, have over each other and also authority over objects, who owns objects, who can do what with what objects.
So a social game sort of like bottles up the social state associated with a particular general domain of social interaction.
Then also associated with social games are these kind of utility-based volition rules that we talked about with prom weeks.
but then use that state plus sort of inferred intermediate state to assign utilities to performing particular actions.
So here, the bottom rule in alliance says that if you have a certain volition to do an allies make move between x and y, and gifting is appropriate between x and y, and that would be computed by some other rules, and there's an object in the world that's tagged as a gift, then you have a certain utility that you're going to sort of transitively move over from your volition to allies make to object transfer to perform the specific move object transfer.
And object transfer is now going to be sort of one of these.
behavior tree things that handles all of this sort of detailed moment to moment interruptible activity around transferring objects. Similarly in the authority game, manipulate object is something that's computed at the bottom rule and you can see sort of intermediate rules that compute utilities on doing what we call authority up moves. Okay, so once you've sort of snapped one of these social games into your scenario, you now have a bunch of utilities being computed for performing actions.
You have the social state necessary to reason over those, and you get a bunch of social interaction units that come in, which are like the atomic actions now.
So here's the social interaction unit for object transfer, which is actually a sequential one, sequential and hierarchical.
It says, perform these three lower-level social interactions in sequence.
An optional request of object.
an offer object, and an accept object.
Within each of those, you have parallel behaviors for the initiator, for the responder, and the audience.
You have to have accept and reject behaviors, because just because someone decides they want to initiate a social interaction doesn't mean that the responder wants to do it.
So that's computed by volition rules.
But then how do you actually perform accept and reject?
You have to have the ability for the player to perform any role and the NPC to perform any role.
And so that means that you have a lot of behaviors that are also kind of listening in a context-specific way to these signals coming from the whole body interface and interpreting them according to the context.
You have to have appropriate monitoring behaviors for player action, reactive staging behaviors, emotion side effects.
And recursively, an SIU may make sub-decisions about performance using behavior scope depletion rules.
And this is one of the key kind of architectural modifications we've made is to take this volition approach, which was in prom week only used at the top level to make a high level decision about what social action to do next.
And we want to say, hey, that would be really cool and powerful to have that kind of decision making capability all the way down.
right, all the way down to like low-level animation control performance behaviors if needed. So to describe a teeny bit about what we're doing there, I won't belabor the ABLE language.
There was a talk at GDC 2004 about it.
It is a reactive planner that has a library of behaviors, a working memory that's like a blackboard system, a sort of sensor and action abstraction for interacting with the world, and then this active behavior tree that the main thing that's different between this and many behavior tree architectures is it's not a static behavior tree.
You don't sort of author a behavior tree, you just author bags of behaviors.
And the behavior tree is dynamically computed as the character's executing and is changing moment to moment.
And this was a class of architectures that sort of came from the late 80s called reactive planners.
And in fact, Damian was working with Bruce Blumberg at the Media Lab in a similar kind of architecture, which is where he got the idea for the kind of behavior tree implementation he did in Halo.
And so there is a historical connection between reactive planners and behavior trees.
But the big difference is there is no static behavior tree.
It's a dynamically computed data structure, basically, that changes moment to moment.
All right, so in the ABLE execution, there are sort of three places where ABLE has choices it has to make.
The conflict set, which is the leaves of the tree.
These are all the things I could do next.
And this is where you get parallel intermixing going on.
And ABLE comes with its own sort of default algorithm that's based on priorities and anti-thrashing heuristic and the notion of step conflicts to resolve that.
There's behavior choice for a particular sub-goal, preconditioned behavior specificity, and there's conditional steps.
The new version of ABLE uses rule-based utilities at any of these choice points.
So the idea is that this whole sort of, you know, SIF, social simulation engine-like reasoning, can now be recursively inserted.
anywhere in ABLE that it would make one of these other choices.
So you've got the default way you would do it, and then you can write rules and do this sort of rule-based utility way.
And so that's how we're getting this kind of recursive decision-making all the way down.
Working with Michael has been a privilege and a trip.
He gets to pretend he has money and I get to pretend I'm interesting.
And I also have to talk very quickly here to keep us on any kind of schedule.
So this slide is just summarizing how we deal with the question of character individuation in this kind of framework.
Characters are differentiated from each other by the list of things on the left.
This is old hat and apple pie those things man those differences manifest in the way They do things how they perform what they look like how they move their pacing and and at a higher level by the choices They make about what they will do We produce those differences then with the declarative representation of the character that we've been talking about so far, and rule sets that map those differences in representation into different behavior choices.
And then we have the ability to override things specifically so that if somebody, instead of getting louder and faster when they get angry, gets slower and more threatening, we can mix that in if that's the right thing for a particular character.
Finally, we can put in custom behaviors.
We can do it the old-fashioned way if that's what's necessary to make things go.
And the big question is, how do we manage all this combined content without having to deal with the N-squared authoring combination that's going on?
Well, we do a performance management, which I'll describe in a minute, to sequence the low-level behaviors.
We interpret physical behavior on the character's part, and this is to get that symmetry that Michael was talking about, so that it gets translated into the same social signals that the NPCs are passing amongst each other.
We use something called wrap-ons, which are ways to wrap attitude into a behavior or cross-cutting behaviors into another behavior that's goal-directed.
And finally, then, we do support author-defined overrides to deal with particular problems when they come up.
Performance management is a simple process.
Well, it's a rather straightforward process of prioritizing different activities amongst the many competing things that an NPC might do, and even that the various body parts of an NPC might do at any particular time, and then going with the highest priority for a particular set of body parts so that you can talk while you're eating and your hands can remain eating because they're not going to do the gesticulating that they do ordinarily while you are talking.
So that takes care of a lot of interaction at a low level.
When we're dealing with this problem of symmetry with the player, because remember the player is standing in front of all these sensors actually doing things, we get a signal from the sensing system that's a physical behavior, like the player extended their arm or they shouted.
We interpret that with a set of rules that are seeded by expectations from the social simulator.
So if an NPC has just offered something to the player, the expectation that the player will either accept it or decline it will get passed over to the interpretation rule.
So if the player extends their hand in that situation, they must be trying to accept the object.
If they shouted instead, that wouldn't be interpretable in the context.
It would fall into a set of initiation rules that would try to say, well, maybe the player's trying to do something new that's not going on right now, and we need to start a new activity to accommodate what the player's doing.
Finally, we're doing these things called wrap-ons, which are simply cross-cutting behaviors that express attitudes of what's going on, or which, yeah, right.
or which deal with common behaviors like thanking people or dealing with confusion.
This is to achieve this dream of a substrate of real social interaction that's going on.
And basically what are we trying to do with all this stuff?
Well, we would like to create a social engine.
We saw an example of one of those things in Reza's talk yesterday morning about Sims Medieval so that all the characters have this kind of baseline repertoire of social behaviors that they can draw on.
This enables new games with a purpose, potentially, like we're using it to train social skills or to accomplish the social process of teaching.
Finally, if the player is socially engaged with the game, they'll become socially uncomfortable, socially rewarded by smiles.
And all of these things can be used to enrich the kind of behavior that they've been having.
Where we're going next, we've got all these games that have separate representations of state.
We have to figure out how to share across them.
We're dealing with blending animations to go with our blended behavior and hitting a bunch of problems that you guys are probably familiar with.
We'd like to go farther with these cross-cutting behaviors, and we would like to apply more of the social state information to the interpretation of the user's behavior to deal with highly ambiguous or complex situations.
And thank you very much.
