Hello everybody and thank you for coming to Bioware Embedded QA, your support class.
My name is Barbara Klimek.
I'm a team lead at Bioware and I've been with Bioware for about six years.
Fun fact, it's my birthday today and I can't imagine a better way to ring in 30 than talking to you guys about what we do.
When I started in QA, I had no idea that what BioWare did.
I didn't know what embedded QA was.
I didn't really know much about QA.
But what we do, it's special.
What a lot of studios do by using embedded QA, it's the future.
And that's what I'm here to talk to you guys about, about how we do things.
And if you are interested in doing embedded QA or you already are doing embedded QA, some things that we've learned that maybe you guys can apply.
This talk does run pretty long, but both Garrett Geer and I have a roundtable at 3.30 today in room 121 in North Hall.
A couple of pieces of housekeeping.
Please set your cell phones to silent.
And the team does send out a survey at the end of this presentation.
So please fill it out.
Let them know what you thought of the presentation, what you thought of me, and what you thought about having QA talks at GDC in general.
Thank you.
So embedded QA.
To understand embedded QA, I need you to understand what I mean when I use the phrase black box testing.
So in black box testing, which was the more traditional way of doing QA, QA was given a copy of the game to test in isolation.
In that model, the relationship was limited between quality assurance and development, and they were seen as an external team, not part of the team itself.
Black box testers would be isolated from developers, working either in a large room or in a separate studio entirely.
Black box testers didn't interact with developers directly.
and all test requests from developers would come in to a test lead and then be parsed out into an anonymous testing pool, basically.
The testers didn't have access to the developer tools or source code.
You know, there is value in black box testing even today, but it is very limiting when it is the only QA model that is used on a project.
So embedded QA is essentially a peer-to-peer relationship between quality assurance and developers.
It stems from a culture of communication and shared knowledge.
Embedded QA are individuals who have access to and knowledge of the design tools and game code.
This allows us to build custom tools, scripts, and levels to assist both us and developers in testing.
It allows us to understand systems thoroughly from the backend, and not just from the final product that we are delivered.
It also grants us opportunities to extract data from the game code directly to drive verification testing.
QA work directly with developers, ideally in the same office, if the space allows.
They are part of the Scrum team.
They attend meetings with them, have full access to their backlog, and communicate with the developers.
they support on a regular, if not daily basis.
This is a full working relationship where the expectations of what should be filed, how and when is agreed upon by both development and QA.
This is basically what it looks like.
This is a very simplistic view.
In reality, we have multiple team leads and a larger team overall.
An embedded QA team consists of a blend of permanent, highly specialized quality analysts, and regular, if temporary, testers.
Often, the testers are specialized as well, and are encouraged to form working relationships with the developers they directly support.
Both are encouraged to document and share their knowledge with the rest of the QA team.
So the analysts will write test scripts for their ownership, and they are autonomous units.
They task themselves and the testers that support them.
Their work is driven by developer work, as well as their own scheduled regression testing.
Tying everything together, we have people like me, team leads.
Team leads provide high-level deliverables and performance manage the team.
They also handle requests for coverage on things that span multiple disciplines, such as a demo.
They drive convergence initiatives across multiple QA disciplines and projects, and work to remove any roadblocks that the team may encounter.
So no model is ever going to be perfect, and the embedded model does offer many advantages.
But with those do come some additional things you need to keep in mind.
So, discipline specialists.
Our games have a lot of content and systems that can interact with each other in many different ways.
The best way we found to provide coverage for those was to split our QA analysts into various sub-disciplines.
So you'd have your art analyst, your narrative analyst, gameplay, and level design.
We do our best to mirror the way the development scrums are structured.
Each area usually has at least one specialist and a couple testers dedicated to it.
Our analysts become knowledge experts that build upon their knowledge of an area across multiple projects.
They get more proficient in that area with everyone.
This is an investment that pays off over time because they bring that expertise forward to the next project they're working on, which allows them to identify risks and potential concerns early, which can result in savings when developing features.
So the catch is, if you want to build someone to take on this additional responsibility, you need their pay to reflect that.
These are no longer entry-level positions, as QA is normally perceived to be.
But specialization isn't limited to just our QA analysts.
Becoming knowledge experts empowers individuals, and we find that testers that are given an ownership, well, they take more pride in their work.
If you have something you own and are personally held accountable for, you're more invested, you're gonna get attached, and you're gonna perform better, even if you are a temporary tester.
The return on this for us is that we have people who work harder, who pay more attention to the details of their ownership, and are more proactive when it comes to communicating about potential issues in their area.
So the cost of this is time.
It takes time for both analysts and testers to become knowledge experts.
An analyst needs to set up the framework for onboarding new testers into their discipline.
And realistically, it takes about a month for a tester to really become a knowledge expert in their area.
Now, the upside of this is, of course, that our analysts and testers form closer relationships with the developers, which result in better bugs, as well as testing that is relative and reactive.
The specialists feel comfortable asking questions of the developers, meaning there's very little downtime looking for answers.
Specialists, because they know their disciplines so well, will also be the first to know if an issue is the result of a feature currently being worked on or an actual bug.
They will also notice minor changes or subtle bugs because they're so intimately familiar with that specific piece of content that they own.
Understanding a system, they will also be better at identifying if an issue is the result of a larger problem and thus systemic or if it is a one-off issue.
This often prevents us from filing multiple bugs that are caused by a single issue, which would otherwise pollute an already busy bug database.
Specialists also identify telemetry and testability requirements early, so that they are considered part of the development of a feature and not a costly afterthought.
Another advantage of this model is that QA have full access to the game and the code, as well as the editor that is used to build it.
So with great power comes great responsibility, and we do take that power very seriously.
QA are not adding content, they are not changing content that's gonna ship the game.
Instead, they are building scripts or test levels that allow us to test content or systems in isolation.
Both of these save our development a lot of man hours over the course of a project, as we find some of our test levels are used by developers to test their content as it comes in.
We can verify content against the backend data directly from the editor itself.
Let's say you need to check the LOD levels of an art asset.
Well, we have a script that will just extract that information, put that into something where we can parse, like Excel.
So we can just do a check like that, which takes minutes instead of hours manually opening each asset or testing that asset in a test level.
Using extraction methods like these, we can ensure that our test scripts are also more accurate than they ever would if we had to rely on manual updating.
So what is the cost of this?
Well, you need your analysts and your testers to be somewhat technical.
They don't need to have a computer science degree, but they need to be comfortable working with a game editor.
Even then, you need to take the time to teach them how to use your specific editor.
Everyone within QA at BioWare is trained how to use the editor within their first few weeks, if not the first week.
Subjective feedback.
Subjective feedback is difficult because it is fundamentally opinion-based and thus carries with it some form of bias.
Traditionally, QA found that their subjective feedback was dismissed, with more merit being put on the results of external focus tests rather than internal QA.
The thing is, internal QA are an opportunity for continuous focus testing that the developer can trigger on demand and in-house.
It can be used to complement regularly scheduled focus tests or used to dig deeper into existing focus test results.
As a company, you are already paying for these QA, so why not use them to their fullest potential?
For QA, though, The key here is being able to provide subjective feedback that is actionable.
Saying this combat is too hard doesn't help anyone.
Without knowing what the root cause is, a developer is likely to dismiss this as a one-off, and they are absolutely right to do so.
Developers are working on a compressed schedule, and they don't have time to investigate one-offs.
However, by having QA analysts analyze the cause, they can provide better actionable feedback.
This combat is too hard because the enemies in this fight tend to do x, y, or z.
Or this combat is too hard if you did this quest first, and thus you're underleveled.
This gives the developers a direction to focus on when they're addressing the issue.
Being embedded with a team also means that they have a better understanding of when and what kind of subjective feedback is appropriate at different phases of a project.
saying that a combat is too hard is useless if a balance pass hasn't been done on the creatures yet.
And the cost of this is, again, time. The analysts need to sit down with the developers to establish what the feedback loop is going to look like for both functional and subjective feedback. What makes actionable feedback for gameplay is not going to be the same for level design, nor are they going to stick to the same schedules.
Finding and fixing a bug early is more cost effective.
Full stop.
If it is a systemic issue, finding and fixing it early prevents child bugs that pollute the database.
If it is a content issue.
Having knowledge experts within QA who understand the content and systems result in a much higher chance of those issues being found earlier.
This is why we have QA onboard a project as early as pre-production, reviewing design documents, reviewing first passes of writing, QA providing feedback from the earliest steps.
Providing subjective feedback about what isn't working early allows for course correction before the feature is completed.
This results in savings of developer hours that are better spent developing new features or achieving stretch goals on existing ones.
Our games tend to be narrative heavy and narrative is one of the hardest things to provide feedback on as it is highly subjective.
Our senior narrative analyst has been working with the narrative team for years to establish a project agnostic framework between the writing team and QA in regards to how, when, and what we test when it comes to narrative content.
This was a project that he got buy-in from the narrative team directly, and they reviewed and offered feedback on it, finally signing off on the latest iteration.
This gave it the stamp of approval across the studio to be used as a standard approach for narrative testing.
So what you see on screen is a small sample of this framework.
It is a blueprint for how QA should be testing narrative content, right from the earliest planning documents to the final finished implementation.
This is important because it allows the narrative team to feel confident in the coverage they will be getting.
Writing can rely that the format they will receive feedback in is appropriate for that specific phase of a project.
Beyond that, as part of our narrative QA framework, Erone created a guide for how to deconstruct feedback so that it is useful for the writers.
And this is especially critical when providing subjective feedback.
Having QA who are familiar with your content and toolset unlock opportunities for the discovery of efficiencies.
For example, Dragon Age Inquisition shipped with almost 600 unique codex entries.
These were entries that the players could unlock as they played through the game.
Testing that these could be obtained legally was incredibly difficult.
There was no reliable documentation that had been created and these were going through changes all the way up until we shipped.
So on DAI, I manually looked through the editor, which is not something you could do as a black box tester, found the location of every entry and jotted down where was it located and what was required to actually unlock it.
This took hours.
And while for that moment, two months before we ship, it was accurate, over the following weeks as content changed and moved around, it was no longer accurate.
And so maintaining it was incredibly expensive.
So during DLC, I got to work with one of our technical QA analysts.
Brian has a talent for identifying opportunities not just to automate testing, but to automate the acquisition of information.
When I approached him about my codex woes, he came back to me with a script that parsed the data directly from the editor, giving me a list of every codex name, the exact location where the codex was placed, and what was required to unlock it.
The first time he looked into how to create this script, it took him about four hours.
After that, any script he had to write that was similar in terms of looking for a specific type of data and then dumping it into Excel, took him half an hour maybe.
And then to rerun this specific script takes five minutes tops.
So I could always have up-to-date information at the press of a button.
Well, this was huge.
I could pass this on to a tester and they could verify all of these were accessible in game because they knew exactly where to go and what to do.
But this is only possible if you have people who not only are they technical, but they understand the project enough to know how to apply their knowledge to save you time.
Even the analysts who do not know how to write scripts are positioned to identify opportunities for scripting because they have an in-depth level of expertise when it comes to their own specific discipline.
All right, so let's say that you've decided to try adopting an embedded QA model.
It's critical that given embedded QA relies on a partnership between development and QA, their buy-in is essential for making it work.
There is no universal formula I can prescribe that's going to work for every studio, but I will instead provide some guidelines, and it is up to you to adapt them to your team and your project.
First off, identify the need.
If you are just starting off, start small.
What are the one or two things that are key or large features within a game?
Let's say your game has lots of characters that are constantly being iterated on, but those characters play in a handful of levels that are static.
You'll probably want to focus on a gameplay analyst over a levels analyst first.
Reach out to your production and team leads.
Maybe there's a discipline that specifically feels they could benefit from dedicated QA.
What services or feedback would these teams like to receive that they may not feel they're currently getting?
Are some developers or teams just more QA friendly than others and view QA bugs more objectively?
Great.
Start with them.
Find your champions in the development team and work with them.
Second, well, now that you know what you're trying to address, it is time to stand up the framework for what exactly these embedded QA will be doing.
Will they be building test levels and scripts?
Will they attend sprint planning?
How often will they sync up with their developers?
What will their communication channels look like?
What reports will they provide to their developers?
What tools and training will the embedded QA need in order to do their job well, and who's going to provide it?
Ultimately, what value will your specific developers gain by collaborating with QA directly?
Run this framework past the discipline lead and production members, get their thoughts on it, iterate on that feedback, and then present it back to them.
Third, as I mentioned before, this is not going to be an entry-level position, as QA often is.
You want people with experience, either technical or show a solid ability to analyze games.
Look, don't hire people who are just looking to get their foot in the door as a stepping stone to another department.
If your HR is selling QA as a foot in the door, tell them to stop.
This is not how we're doing things anymore.
Be selfish.
Look for people who actually want to work in QA and pursue a career in it.
QA is not a parking lot for developers to be.
Lots of our QA have moved on to other departments.
But every single one of them were exceptional QA long before they moved on to work in other departments.
They had a passion for QA just as much as they did for writing, for cinematic design, for art.
Those people you definitely want on your team, but not the people who sit down in the interview and just say, you know what, I wanna be an audio engineer and this is my foot in the door.
Sorry, go look for an audio apprenticeship.
Avoid people who are going to tell anyone how to do their job.
If these people can't provide feedback without telling that developer how to fix that issue, they're going to burn bridges, and they're going to burn them fast, and nothing is going to hurt your department more.
Invest in the people that you hire.
Give them training, continuous training.
Training doesn't stop after your first week.
And give them support.
Set up a training plan for ramping testers and analysts alike that is standardized and thorough.
This provides a baseline that you can rely on for your entire team.
Iterate on that training.
Keep developing it over time based on the feedback and changes that occur within the industry and your projects.
You want people who are independent and self-motivated.
People who ask questions and offer suggestions for improvements.
These people will help your department grow and not just sit there and run the test scripts that they were assigned.
You want people who will look at a test script and say, you know what?
I think that humping every wall is just inefficient.
We can script that.
Those are the people you want.
It's no secret.
We work in a digital environment.
And you want people who have some form of technical knowledge.
Maybe they have a computer science degree.
But maybe they just know how to reskin mods for Skyrim.
That's fine.
Those people are technical enough for us.
We can teach you everything else.
What you don't want is people who struggle to find out the specs of their computer.
And what you really don't want is people who don't know how to Google how to do that.
All of this criteria, and it is a lot, applies for what we look for when we hire our testers as well as our analysts.
Testers are never just a bum in a seat for us.
These are people we seek out, we interview a lot of people, and we choose them because they bring something special, even if they're only with us temporarily.
Create long-term growth opportunities for your permanent staff.
This is key for QA growing into a valid career choice.
If people see that this can be a long-term solution for them, they are more likely to stay with you and remain invested.
And last but not least, go slow.
Learn from the challenges you face and iterate upon this.
Not everything will go smoothly.
That's fine.
Reach out to other QA teams in your company.
In other companies, attend roundtables and summits for QA.
Share knowledge, challenges, and suggestions.
We can be a community to help each other grow.
But wait, what about the traditional model?
Am I suggesting that we abandon it entirely?
No, we still need black box testers and we still use them.
We find they add the most value at the end of a project when everything is open for bugs.
They provide valuable fresh eyes feedback.
And they're not as susceptible to bug blindness, either due to repetition or due to knowing the intended design.
They are ideal for regression passes on content that is no longer going through iterations or changing.
Game testing becomes a numbers game near the end of development.
During finaling, you want to test as much as possible before you ship.
And this is where the number of black box testers that you can get really pays off.
Black box testers are closer to an entry level position.
And thus, when it becomes about covering as much content as possible, they are going to be a more cost effective solution.
The analysts and specialized testers assist the black box testers, helping direct their testing and answer questions about the systems or the content.
So in conclusion, QA needs to continue to grow and identify opportunities to be more than just the final link in the chain.
This is how we become a respected long-term career choice.
Developers need to start speaking up and asking when they want more than just basic support.
We have much to gain by striving to work as a unified team.
Developers, we are your support class, and we are here to provide buffs as needed.
Thank you.
Does anyone have any questions?
We've got two mics over here.
Hi, I'm a producer on a team that's trying to help out QA and we're in the process of potentially sort of transitioning to embedded QA, we're maybe 25% there.
And one of the roadblocks that we've specifically hit is that our QA derives a lot of value from being able to sit together and use each other as a resource.
And that's been one of the main roadblocks in being able to split them out into feature teams.
Do you have any advice or insight on that?
We have the exact same problem.
Our teams are huge.
So we found that using Slack or any sort of group chat helped a lot.
A lot of it is also just culture building.
So we do a lot of team building events with the QA to get them.
They're still working together during those team building events, but during the rest of time, they're sitting with their developers.
It's going to take time.
Some people are really introverted, and you have to work with them more to get into that relationship.
But yeah, the biggest thing that helped us, because we work with external embedded QA as well, have some kind of unified communication network.
And for us, we've been using Slack and we love it, and it's helped us a lot.
Does that answer your question?
Yeah, thank you.
Awesome.
Hi, I'm Andrew Barron. I'm with Bohemia Interactive Simulations.
Over the last year, we've done basically what you were describing, at least in our features group.
We moved QA into the Scrum teams.
So we do teams of six, Scrum teams.
We have two QA in each team.
I would say that for us it was a massive success, but there was definitely obstacles to doing that, a lot of internal resistance to moving them out of the sort of black box role and into that role.
I was wondering what you found as the biggest obstacles in your rollout and how you overcame them.
So full confession, we have done embedded QA for probably 15 years organically.
So internally, it's just the way things are at BioWare.
When we work with external teams to try and get them embedded, a lot of it is just the testers are hesitant to come up to developers and work with developers.
That was our biggest roadblock, was that they felt inferior in a way.
They would apologize that they had to go up to the developer, like apologize 10 or 11 times, which even for a Canadian is excessive.
We had to work with those individuals and try and say, you know what, you are a peer, and build up that mentality.
So that was our biggest challenge, is break that wall and create that feeling like, no, we are all equals, and there is no hierarchy, basically.
I'd be really interested to know more specifics about what were some of the challenges that you faced, but we are running low on time, so I wanna catch up with you later, because I'm curious.
Cool, thank you.
Anyone else?
Ha, wonderful.
You've been mentioning at the beginning that you were providing all the source code and all the tools and the training for your QAs, but preventing them from doing any changes.
I've been kind of doing the exact opposite.
I mean, I provide them everything they want, but if they find a minor bug, they're in collaboration with the developers and say, hey, I can fix this.
No need to raise a bug, just fix it.
So I don't know, I don't know what, I have six people too, so it's probably easier to manage, but I'm wondering what your...
We have had people do that in the past, and I mean, that's the general rule of thumb.
The challenge with that is you're actually, okay, if I have my QA fix a bug, they're actually creating twice as much work.
One, the time they're taking to fix that bug, they are not testing.
Two, someone else now needs to verify their work.
This is a discussion we've had going back and forth with the various teams.
And I'll be honest with you, if it works for your team, awesome, go for it.
We've done it in the past.
But it's targeted and deliberate.
I would not recommend if you're just starting it to do it.
Because I mean, there's also that level of accountability.
That's a lot of pressure to put on a QA department.
And to be blunt.
I've seen other companies use their QA as, in this case it was artists, they were basically using them as junior artists but paying them QA wages, which is unfair and honestly not the best use of resources.
I don't think that's what you're doing, but I've seen another company do that and it was, you know, it ended up collapsing on them in the end.
It's just not great.
So again, do it, but do it deliberately.
Anyone else?
Well, you guys have been a wonderful audience.
Thank you very much.
