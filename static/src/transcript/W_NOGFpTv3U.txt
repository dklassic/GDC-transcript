Hi, my name is Niklas Kray.
I work at a company called R Machinery.
And in this talk, I'm going to talk about tools development and more specifically what we've done to speed up tools development and make it faster and make our tools better than before.
I have a long history of writing game engines.
Most well known is probably the BitSquid and Stingray game engine, which is actually the same engine.
rebranded when Autodesk bought it.
In the last few years I've been working on a new game engine called The Machinery and been trying to fix all the mistakes of the past game engines that I made.
So in this talk, I'm going to be talking a little bit about the history we've had with BitSquid and Stingray, our troubles with tools, why it's been so hard for us, and what we can possibly do about it, and how we attempted to fix it when writing the machinery.
So first, let's start with a brief history of our failures as when it comes to tools.
In the first version of BitSquid, our first idea about tools was that we shouldn't write any tools at all.
Rather, we should just expose sort of public file formats like JSON files.
And our users could just write their own tools.
As long as they outputted this file format, they would work together with our runtime and everything would be fine.
Turns out this wasn't really that great idea.
Users actually do not want to write all the tools themselves.
You would think we would have figured that out before.
starting this game engine, but we didn't really. So we quickly had to scramble and address this in some way. So our first approach was just, well, let's hack together something quickly in WinForms.
This actually is a pretty speedy way to build tools. You can just put in whatever check boxes and buttons and dialogue boxes that you need.
But to be honest, it looks kind of ugly, like it's not the nicest look.
And it also turned out pretty messy.
We didn't start with a clear plan of how things should work in the tools and how different tools should interact.
how things like copy paste and undo and redo and drag and drop and stuff like that was supposed to work.
So over time, it got kind of hard to maintain and it got kind of messy.
But to be honest, it worked pretty well and it's a fast and nice way to build tools.
But we thought we needed to do something better.
So for sort of the next iteration of tools for the Bitsquid Engine, we decided to go with...
WPF instead. The reason we made that decision was like that was sort of the recommended UI toolkit from Windows at that point. I think it still is, but I'm not 100% sure. And using WPF, our tools suddenly looked a lot better, a lot prettier.
But a result of switching to WPF and moving away from this sort of hacky approach we had before was that the tools actually took a lot longer to write.
who's also a higher barrier of entry.
WinForms is pretty simple to hack together tools, pretty straightforward, but to use WPF effectively, you need to know C-sharp, you need to know the programming patterns of C-sharp, and query style programming and stuff like that.
You need to know WPF, you need to know XAML, and there's a lot of little subtleties that you need to know.
And as a result of the tools, so our initial plan was we should rewrite everything.
We should just take all our WinForms tool, convert them to WPF and things would be fine.
But this conversion actually took a lot longer than we expected.
I think just our unit editor took like six months or something to rewrite.
And as a result, we never actually completed this rewrite.
So some of the tools you see here, so this is sort of our launcher that launched all our different tools.
And some of these tools were rewritten to WPF and some were not.
And we sort of had this mix of tools built on top of different frameworks, which is not great.
And the cause for that was just that it took so long to rewrite everything in WPF.
Then we got acquired by Autodesk.
And one of the requirements or wishes that Autodesk had was for our editor to be platform independent.
So that meant we couldn't use WPF.
I mean, we could try to do something with Mono, but it didn't look very nice and promising to go down that route.
So we decided to go with web-based tools.
It seemed reasonable.
Everything would be platform independent, sort of by default.
It would be built on web technology.
We also had the idea that we could, by using web technology, we could sort of reuse web expertise.
There's a lot of people out there who knows how to write UIs using HTML and CSS, and it could be nice to use all of that.
And our tools would run in the browser too, which is kind of nice.
But there were multiple drawbacks with this approach.
Our tech stack, which already was kind of complicated because we had an engine using C++.
Then we had a scripting language for that engine, which was Lua.
And then we had C-sharp to run our tools, which targeted WinForms and WPF.
So that was already kind of complicated.
To this, we now added Chromium.
to run the web tools.
Qt actually was used for the Windows system and some parts like that.
We had JavaScript, of course, because we need to program Chromium somehow.
We also had some JavaScript toolkits.
I think we had a bunch of them. Angular was one, but I think we had React there at some point, and some other JavaScript toolkit too. We had WebSockets to handle the communication between the engine and the tool. So this is a really deep, heavy tech stack. And as a result of that, tools took even longer to rewrite, because now there's all of these components that we need to take care of.
And it ended up being that we never completed this rewrite either.
So not only did we not rewrite all WinForms tools to WPF, we didn't rewrite all WPF tools or all WinForms tools to the web platform either.
So at the end of sort of the Stingray area, we had this mix where some tools were in WinForms, some tools were still in WPF and some tools were in the web interface, so even more complicated at that point.
So, to be honest, Bitsquid and Stingray never had good tools.
The tools were always suffering.
And as we started out with the machinery, that was one of the problems that we really wanted to fix.
Because I think that every time you start writing a new engine, you kind of want to like atone for the mistakes that you made in your last engine and find a way of addressing them and fixing them.
And that's sort of the drive too for making a new engine.
So we identified this as sort of a core problem.
So what were the big problems?
Well, one problem, of course, is we kept changing the frameworks, the underlying UI framework, and that caused us lots of delays and lots of extra work.
But there's also, so that caused, made us lose a lot of time writing tools.
But there was another problem that tools just in general took too long to write.
I remember on a number of occasions where I would add a feature to the engine.
and it would take me maybe four hours or a work day to add that feature to the engine.
And then to add tooling for that feature could be like a week or two weeks just to do the work.
It also needs to be scheduled into the...
sort of pipeline for the tools programmers, which means there could be a month or something before the UI was actually there.
And I always felt like there was like this weird disconnect here.
How was it that it was so much easier to add stuff to the runtime than to add stuff to the tools?
And it always felt like the tools were slowing us down and like holding us back from writing an awesome engine.
So we need to fix that somehow.
A third problem that we also had with the Bitsquid and Stingray tools, especially as we got into the web technology, was bad performance.
So, I mean, writing a game engine, it's all about performance.
It's all about how many characters, how much animation and physics and so on.
Rendering, can you push?
And it's kind of sad if your editor doesn't reflect that.
So if you have a really long startup for your editor, or if it doesn't just feel snappy when you click on things, it's not nice.
So we wanted to make sure that the performance of the tools match the performance of the engine.
So how do we fix this?
What are the actual problems that we need to address?
So one of them, changing frameworks.
So why does this happen to begin with?
Sometimes I would say we're changing frameworks because we made an initial bad decision and using platform-specific technology like WinForms or WPF could be considered a bad decision.
Maybe it would have been better to go with Qt instead.
Using web technology, maybe that was a bad decision too.
But it's kind of hard to avoid all bad decisions.
You're probably likely at some point to make one or two bad decisions that will result in you having to change frameworks.
Also, even if you don't make any bad decisions yourself, you sometimes get in a situation where technology that you've used and sort of depended on gets outdated or abandoned.
So there's a number of.
different technologies that they get obsolete and they get put into like the legacy scrap pile.
So one of them that we used actually in Stingray was the native client, the Google native client, and that got abandoned or deprecated and then we need to find another way of handling that.
Now, in theory, if a piece of technology gets sort of abandoned, you could keep running on it because you have the latest version of it and you probably can still use it.
But in practice, that's kind of troublesome because it means that since it's not being maintained anymore by the people who actually made the technology, it means that you now have the full responsibility of maintaining this framework.
And that can be a big burden.
I mean.
Say you have an engine with like 300,000 or 500,000 lines of code, you have to maintain that.
But, but suddenly you now also have to maintain like an old version of Chromium because you want to keep native client.
And that's got like a million or a million and a half lines of codes.
And do you really want to keep fixing bugs in that?
And, and also missing out on, on any new features that come into like the main branch of Chromium.
So sometimes this just forces you to change technology through no fault of your own.
And the only way of avoiding that is to be less reliant on these frameworks and be really careful about what frameworks you rely on and your ability of switching them out if necessary.
Another question, why did it take us so long to write tools compared to writing engine code?
Well, we identified a number of factors.
One is just like that every, every little thing you add to your engine needs a UI.
So you add a new parameter somewhere, then it needs, someone needs to design a little UI for that, that piece.
It needs to be coded, it needs to be tested and so on.
So every little, every, it's just a lot of work to do every little thing.
There's also a lot of features that you sort of expect in a modern UI, things like undo, redo, unlimited undo, redo, you want copy and paste to work, you want to drag and drop to work, it needs to work with serialization and saving and loading and migrating of data and stuff like that.
And all of these little things, each little thing takes time to add.
And it also adds to the size of your code.
So every time you add a new UI box and then you add undo and copy paste for that, you add more code to your project.
And generally the more code you have to lug around, the less agile you become and the more slower.
everything becomes because you have to manage all that code and if you want to make some kind of refactoring you have more code to refactor, more code to debug and profile and so on.
Another problem specifically with the way the Stingray technology was built was that we have this deep tech stack.
And when you have a deep tech stack like that, it's hard to understand where bugs are happening.
If you run into a bug, you don't really know, well, is this a bug in Angular?
Is it in the JavaScript code?
Is it in the WebSocket?
Is it in Chromium or C-sharp or Lua or the C++?
There's just so many different places to look.
So the problem here is really one of complexity.
The more complexity you add to a project, the more work you have to do for everything.
Like finding bugs becomes more work, finding performance issues becomes more work, refactoring becomes more work, adding features becomes more work.
So complexity is really your big enemy.
That's really what you want to minimize.
And having all these layers and all these components that are not really ours and that we don't control really adds to the complexity.
Another problem with this complexity too was that...
Since there were so many different components here, only the tool people really had a good understanding of the tool stack. That means that if a rendering engineer, for instance, added a new feature to the renderer, they couldn't just go in and add that feature to the UI, because the UI was too complex for them to to do things like that quickly.
So the development got very siloed and you got the tools team and the runtime team and they were completely separate, which when you do stuff like that, it often leads to friction between the teams.
And it also means that stuff that's important for one team, like a feature that's important to the rendering team might not be as important to the tools team.
So it ends up being queued on some queue somewhere and...
You don't know actually when it's going to be implemented and stuff like that.
And I just think things run a lot more efficient when everybody is sort of able to touch all the code.
So the rendering engineer can actually go in here and add it to the UI.
And then maybe some UI programmer needs to come in later and sort of pretty things up a little bit, but at least the feature is there and can be accessed.
So people don't constantly keep getting blocked by other people.
Third issue, the performance problems. Why did that happen?
I think a big part of that is that standard web practices didn't always work.
So the way when you have web programmers in, they have their usual way of doing things.
And that doesn't always work when you're building a game editor.
Because game development has way more stuff than your typical HTML application.
Like I said, when it comes to making game engines or games, we always try to push performance as far as it will go.
And that means you're always sort of running at the brink of what your computer is able to handle.
And if you do things like...
And this doesn't mean that you necessarily...
It's not possible to do this in the web browser.
Web browser can do amazing things.
And if you write things the right way for the web browser, it might work.
But if you write it sort of the regular, the usual way of doing it, it might not work.
So what would often happen is that some of our UI programmers would create a tool and it would look pretty and it would run nice with like a hundred objects in it.
But then as soon as you put a thousand or ten thousand objects in it, it would break down and run on its knees.
And fixing that was not just an issue of like finding little performance, like profiling it and finding little performance hotspots. It often required a complete rewrite of the system.
Controls had to be virtualized, data had to be stored in a completely different ways.
Maybe we had to bypass some JavaScript framework because that framework didn't have a performance mindset. So the rewrite was often, the cost of the rewrite was similar to writing the system from scratch.
Also, the deep tech stack, again, complicates everything.
It also complicates finding these performance issues.
And the browser, when it comes to performance issues and the browser, it's more or less a black box.
You don't know, oh, I've wrote my JavaScript code this way and it's send the JIT into this.
bad path so now everything runs 10 times slower than before and these things can be really hard to know. They can also change from version to version of the web browser so if you update Chromium because you need access to some new features then suddenly you might have completely new performance problems and you need to investigate everything again which makes this really tricky to keep a good control of the performance. So how do we fix all these things, all these problems?
Well, the thing with too much stuff to write, our idea there was we can automate a lot of this stuff.
So stuff like undo, copy, paste, and stuff like that.
If we define a standardized data model, which is the way we represent the data in our application, we can define a lot of these operations on that data model.
And that means that the UI doesn't really have to be bothered with it that much.
It doesn't have to do anything specific to do undo, redo.
It can just talk to the data representation and say, well, undo this action and then the data model can do it.
So that cuts down drastically the amount of work that needs to go into the UI.
Step two, what we did, we really didn't like this deep tech stack and all the complexity and the problems with changing frameworks that came with that.
So we decided to minimize the tech stack completely, use as few frameworks as possible, and also own as much of the tech stack as possible.
So it's actually running on our code, not everybody else's codes.
That means we know the code, we can debug it, we can profile it, and we can understand everything that goes on with it.
make things explicit so instead of these black boxes where you don't know what's happening you can actually see what's going on in there.
Finally, again to handle this sort of busy work instead of writing UIs for every little thing, we try to, as far as possible, sort of auto-generate and auto-populate the UIs from data.
And so for example, a graph view or a tree view or a property view, we try to reuse them from between different systems and just have them be generated from the data.
So that way, as a programmer, you don't actually have to write the UI.
It's sort of created for you.
If you can use one of these.
standardized views and components. So I'll explain all these parts as we go on through this presentation. But that cuts away a lot of the busy work of just creating UIs for everything and also cuts down the size of the code which is really nice too.
So start first with this data model, our way of representing data and how we can use that to do things like undo and stuff like that.
So our data model, we call it the truth.
kind of cheekily because it's, we consider it, it's the truth about the state of the project. It's where you go to find out anything about what the editor is doing. So all the data, all the data that's handled by the editor is represented in a uniform way, and then we can define operations on it. So the way the truth is set up, it's based on objects.
of certain types. Each object has a type, each type has a number of properties, and each of those properties has a type. So, for example, a person object might have a name property that is a string, an age property that's an integer, and then a flag that specifies where it's registered or something like that.
So this is kind of a JSON-like model with the way these properties work, except we have sort of a schema for these different objects.
We also have well-defined ways of representing references between objects, so an object can refer to another object, and also sub-objects.
So the difference here is that sub-objects are objects that are owned by these objects.
whereas references are external objects that this object just points to.
And that changes how things work when you copy and paste, for instance.
For example, when you copy and paste, you copy all the sub-objects, but you don't copy the references.
So it's nice to have that explicit in the data model too.
So our data model supports multi-threading automatically, and we do this actually in a lock-free way.
And I'll explain a little bit about the detail of this because it's important to other things that we do in our data model too.
So the way we implement lock-free multithreaded access is by dividing the step of changing the data into two distinct steps.
So first you call write on the object that you want to change and by doing that you will actually obtain a copy of the object that you can modify.
and all those changes are local to this copy of the object so it doesn't affect any readers of the data they still see the old object and once you're done with all your changes you call commit on the object and it will atomically switch out the old object for the new one by just doing an atomic pointer switch and then all the readers after that all the readers will see the new objects.
So this way the readers can read the data without locking.
And eventually we clean up all the old copies with a garbage collection procedure.
So undo in our system is actually based on this too, which is why I presented this sort of complicated multi-threading approach first.
So undo works in a similar way.
The only thing we do different for undo is that when we perform like an undoable write, we save the old object and the new object.
So both these versions in our current undo scope.
And we can save these for multiple objects because one undoable action might affect multiple objects.
And when the user wants to undo something, we simply reinstate the old data that we saved in this undo scope.
We also have a system for prototyping or prefabs that's built into our data model.
The way this works is that any object in the truth can specify another object to act as its prototype.
What this means is that the instance of the prototype will inherit all properties of the prototype, but if it wants to, it can override some of them locally.
So we could create another instance of a person object here that just overrides the age, for instance.
So this concept is similar to the way like prefabs work in Unity, for instance, where you can use a prefab and you can override.
properties on it but the important thing here is it's actually built in into our data model so it works with everything it's not just with entities but any kind of data in the engine can be given this like prototype treatment which is nice so other things we can do sort of because we have this well-defined data model is we can do really advanced things such as real-time collaboration So multiple people on the network can be working in the same project.
And the way this works is that when someone does a commit, so they change something in the data, we just compute a Delta between the old and the new version of the object.
And then we transmit this Delta over the wire to our other collaborators in the session.
And then they will get those changes and they will enact those changes on their data model.
the data model will be replicated.
This is an example of this.
We have two people working together here over the network, a host and a client, and you can see that any action that's performed by either the host or the client here in this level is automatically reflected over to the other person.
Again, since this is built into the data model, it works with everything.
And it also works with if you extend.
our engine with your own data types and your own your own kind of your own data representation and your own UIs which you can do with plugins all of this will work automatically for for your stuff too So sort of analyze this approach of using a data model in this way.
What are the advantages and disadvantages that we see?
Well, the big advantage of course, is we get all this functionality for free.
We get undo, we get copy paste, we get serialization.
It just works automatically, not just with our data, but with other people's data in plugins too.
And as we saw here, it's not just these simpler operations like undo and copy-paste, it also works for really advanced features such as prototyping or real-time collaboration.
So what are the drawbacks? One drawback is that this way of representing the data, the sort of key value format with objects and properties, doesn't work well for all kinds of data. So an example of data that's not that...
well represented in this model would be long pieces of text.
I mean, you could do it, you could have an object with a string property and that string property is just like 200 pages of text.
But it's not really a nice way of representing that data because the way our undo system works means like if you change one character of that, that big document, you have to make a complete copy of all those 200 pages of text to do the undo operation.
So it gets pretty inefficient for that kind of data.
But luckily that's not really the kind of data that we deal with a lot in Game Engine.
But yeah, it's a drawback of the system.
Another drawback I would say is that it's a pretty complex system because it needs to handle all these different things, prototyping, multithreading, and it also sits at the center of everything.
Because the whole point of having...
a single system that works with all the data is that everything will use it, so everything will work the same way. So there's really no way for other systems to opt out of using the truth.
So if you wanted to write, for example, a text editor in the machinery, it would have to use the truth to be able to interop nicely with all these other systems. And so you would have to figure out, you could probably massage it some way to...
find a way to use the truth to still represent your text object so that it would kind of work.
But yeah, you can't really opt out of using this system. And it's also the complexity of the system makes it kind of scary to modify the truth and add new features to it because everything depends on it. The serialized data that's stored on disk depends on it. So you might, if you mess up, you might destroy people's saved projects.
So it's kind of a scary system to change.
You can't get out of it, even if you would like to, and it sits in the center of everything.
I would say those are the drawbacks. That's sort of the price that you have to pay to get all this nice stuff for free.
So next I'll talk a little about our tech stack.
As I said, we really want to avoid being dependent on frameworks.
So we built most of our tech stack ourselves.
We also want to keep the tech stack itself as simple as possible.
If you remember from the Stingray tech stack, we had a lot of different languages involved, C++ and C Sharp, Lua and JavaScript.
And we also had like scripts written in Ruby and Python.
So big ball of things.
So for the machinery, we decided to change that completely and write everything in C.
Even our little helper scripts are written in C2.
The external libraries we use is very limited.
We basically just use Vulkan.
When it comes to the UI, we use Vulkan for rendering, and then we have the platform SDK that we need to access to get access to input events, like such as keyboard and mouse events.
And then we have our own API abstractions on top of that, a 2D layer for doing 2D drawing, and an input layer, which is our abstraction over the OS input layer.
So it's common for all operating systems.
And then we have our UA system on top of that, which is an immediate mode UI.
And then we build our applications and editors on top of that.
So our 2D drawing library.
It has regular 2D drawing operations such as strokeRect and fillRect, etc.
Whatever you need for drawing the UI.
But the way it's implemented is kind of interesting.
We actually, all these drawing operations actually write data directly into a single vertex buffer and a single index buffer that will contain all the things that we want to draw in the UI, like rects and text and so on.
And at the end, we just render these buffers with a single draw call.
And if you want to learn more about that, I've got a link to our blog that kind of explains how we actually do this.
But the end result is our drawing is really, really performant since it's just one draw call to draw the entire UI.
Clipping is done by the pixel shader.
So when we want to do clipping, we write our clip rects to the vertex buffer two, and then the pixel shader will refer to these clipping rects and clip the data against it as it's written.
So we do no clipping on the CPU.
It's all happening in the shaders, which makes that really efficient too.
So overlays, this is kind of a neat trick, which is why I wanted to mention that.
So when we're drawing something in an immediate mode UI, it will sort of appear in the order that it's drawn, but sometimes we have a desire to make stuff appear on top of stuff that will be drawn later.
For example, if we have a pop-up menu or a context menu, we want that stuff to sort of float on top of the stuff that we draw after it.
And the way we handle that, it's not really by doing some complicated layering procedure, stuff like that.
We just keep two separate index buffers.
So we have one index buffer that contains all sort of our main layer draw call.
And then we have a separate index buffer, which we call the overlay index buffer, where all the pop-ups drawing happens.
And then at the end, when we want to, so we just keep a single vertex buffer or a single primitive buffer.
We call it vertex buffer, primitive buffer, where all the vertices go into, but we keep two separate index buffers.
And then at the end, when we're ready to draw anything, we just concatenate these two index buffers.
So we just put all the overlay stuff at the end after all the...
the regular stuff has been drawn. And since the index buffer sort of contains all the actual stuff that's being drawn, by concatenating the index buffer at the end, the effect will be that all the overlay stuff appears on top of all the regular stuff. So it's kind of an interesting way that we use the fact that we're drawing everything straight to buffers to do this overlay effect.
One thing to note here is that our Since we're drawing everything including our overlays with a single draw call our overlays can't actually protrude Outside your main window as they can in Windows for example so pop-up menu will always be clipped To the to the main window if you wanted to if you wanted to show it outside Your sort of main rendering when you have to spawn a new a new window to hold your pop-up so that's kind of a different technique, but This is an interesting way of doing it the way you can do it with just a single draw call, even the overlays.
So our UI, as I said before, it's an immediate mode UI.
So that means we're not explicitly creating or destroying UI objects.
That's kind of what we mean by immediate mode.
Instead, we have a single call to draw a control and handle the interaction.
So, for a button, for instance, we have a draw call, we call it with a rectangle and a text, and it will draw a button with that text in that rectangle, and if the button was clicked in this frame, it will return true, and otherwise it will return false.
So, with a checkbox, we call the checkbox...
call a function to draw a checkbox, we pass in a flag.
If the checkbox was toggled this frame, that flag will be toggled by the function.
The important thing to know here about immediate mode UIs is that these buttons and checkboxes that we are drawing here, they're not saved anywhere.
After we've called this function, there's no memory that there ever was a button or a checkbox in this place.
So these controls that we're drawing, they don't really have any existence, no permanent existence like the next frame, we might draw a completely different set of controls.
So the way we keep track of what's happening with the controls is that each control is given a unique ID.
That way, we can keep track of which control the mouse is currently hovering over or which control the user is interacting with.
when these controls don't really exist permanently.
So pros and cons of this approach using immediate mode.
I would say the big advantage is that you get a completely straightforward code flow.
So if you want to know if you have like a bug somewhere, like a control is showing the wrong state, or a control is being too slow, you can just step through the code and see everything that's happening from the call to button to every part of the button being drawn and the function returning.
You can see the performance of it, you can see any bugs in it, and you just go in there and do it.
Whereas if you have a retained mode UI, which is like the alternative to immediate mode, You have some part of the code over here that is setting things up, creating controls, destroying controls.
And then you have some part over here, which is probably deep inside the framework, where the interaction of the controller or the drawing of the controller actually happens.
And these parts are kind of separate, but what you do over here affects what happens over here.
So if you have performance problems, you kind of need to figure out, or a bug, you need to figure out how these different parts work together, which is way more complicated.
Another advantage of immediate mode is that there's no need to synchronize state.
So, so with retain mode, you have to have like events getting sent from controls, and then you have to process those events to change your, your data.
Whereas here we're just drawing the data.
When we draw the control, we pass in, when we draw the checks box, we pass in the current state.
Um, so we send the data directly from the application.
There's no need of processing events or anything like that.
which I think is a big advantage.
A disadvantage that people often bring up is that you have to redraw every frame and that that can be expensive, just redrawing the UI every frame.
I think that's less of a concern for a 3D application, like a game editor, because you typically have a viewport in there.
That viewport typically wants to render every frame anyway, at least if you have some kind of animation or anything going on there.
So you're not really wasting any resources, but by also rendering the UI every frame.
There are also ways to get around rendering every frame if you need to.
For example, you can render only when you have actual input actions that would change the UI.
So if the user moved the mouse or if the user pressed the keyboard, you re-render the UI and otherwise you don't do it.
I actually find that with immediate mode UIs it's kind of easier to get good performance because you can easily match, you don't have to deal with anything that's not visible on the screen.
For example, if you have a long list of items, like a thousand items in a list.
It's very easy to like just figure out like which items are actually visible right now on the screen like in the rec that I'm drawing this list in right now what items can be seen.
And then you just process those items, you don't have to care about anything else.
Whereas when you're doing retain mode, like if you're doing retain mode in the default setup, if you have a list of 10,000 items, you have to somewhere create these 10,000 items.
and that might be really expensive and the processing of those 10 000 items might be really expensive so to speed up performance, you might have to resort to some trick like, I have to use virtualized items where I don't actually create the items until they're really shown on screen or something like that.
And you have to resort to tricks like that in order to get the performance back. Whereas with immediate mode, it's very easy to do this kind of clipping and just do...
just do the processing for the thing that's actually shown on screen.
So I find it a lot easier to get good performance out of an immediate mode UI.
And then a lot easier to actually find where your performance is going to.
But it is a new mindset and it can...
it can take time to get used to and the big thing with a new mindset is that there aren't actually any objects to talk to because that's what you're used to from a retain mode. You have a button somewhere and you can sort of message this button and get it to do something but in the media mode that doesn't exist. So one example of that is For example, if the user selects copy in the main menu, if you have a retain mode UI, you would find out which is the current focused window or text field or whatever, and you would send that copy event to that object.
Now you can't do that in retain mode, cause there's, or in immediate mode, cause there is no object to send it to.
So how do you do things like that?
You have to like sort of wrap your mind around it.
This shows here the state synchronization, which is really nice.
We have a number of different views here that are all showing the name of this object.
And to sort of synchronize the name between these different views, we don't have to do anything, because all these views are drawing it straight from the data.
So whenever it's changed in one view, it automatically gets updated into all these other views and they will automatically show this change without the need for processing any events or having any observer, observable patterns or anything like that, which I think is a great advantage of using this model.
As an example of gotchas you run into and how you need to change your thinking when you're dealing with immediate mode, a problem that pops up sometimes is if you have overlapping objects.
So suppose that we have a graph editor that's based on nodes and you can drag these nodes around.
And suppose that you have two nodes, two overlapping nodes like this, and you want to process mouse clicks.
If this was in retain mode, we would probably just loop over all these graph objects that would exist in the UI and check for mouse interactions.
But we can't do that because the objects don't really exist.
Instead, we sort of, we have to process these events as we are drawing each object.
And the problem here is that when we're drawing node one here, which happens before node two, because we're drawing everything on order, so things we draw later appear on top.
So when we're drawing node one here in our immediate mode, we don't know.
that we're going to draw node two later.
So node one can't just do a test like, well, if the mouse is inside my rectangle and the button is pressed, I should process this event.
Because we might draw node two later on top of node one, in which case node two should actually process this mouse event.
So how can we fix this?
When you're like stuck in this retain mode object thinking, this might seem super, super tricky.
But we can actually fix this by introducing a frame delay.
So, the way we do it in the machinery...
is that we keep track of which object the mouse is hovering over.
So, and we do it, we assign it at the end of the frame.
So, we check when we're drawing this node here, we check if the mouse is in the rect of the node.
And if it is, we says, well, the hover for next frame should be our ID.
Remember, our unique ID is how we identify this control in the UI.
And then we check, well, if the hovered object is our object.
and the button is down, then we should process the event.
So let's see how this works when we have two nodes here like this.
So in this case, the first node would go here.
It would see, oh, the rectangle is in...
the mouse is in myRect, and it would set nextHover, the hover that we should use for the next frame, to myID.
Then we get to this check, is the hover my ID?
And the button is down.
The hover is not the ID of this control yet, because we only set the next hover variable, not the hover variable.
Then it gets to node two.
The node two text is the mouse in my rect, and it is, which means node two updates next hover to now point to node two.
So it overwrites what node one did, and now next hover is node two.
Then we get to the end of the frame, which means we assign nextHover over to hover.
So hover is now assigned to node two, which means the next frame, when we go through this code again, node two will see, well, hover is actually my ID and the button is down, so I should process the event.
So we had to do a frame delay here where the mouse click is not detected the first event or the hover is not detected the first frame, it only happens in the second frame.
And this is basically the only way we can do this because since node one doesn't know what might be drawn after it, we have to go through an entire frame in order to discover all the things that can potentially be drawn.
after it. So it's a different way of thinking.
And lots of times it's a different way of thinking if you're used to retain mode. And I've seen a lot of people claim like, well, immediate mode UI seems great, but they can't do this.
This can be a lot of things sometimes. It's like drag and drop sometimes It's like other stuff, and and I find that that's not true at all there's Always a way to do it in immediate mode But you have you might have to do a trick like that that like this like introducing a frame delay Like saving some data somewhere you have to retain some data like we're retaining the hover hover variable here But you don't have to retain the whole state of controls and stuff that you just have to figure out What kind of data you have to retain and do then do this sort of frame delay trick And then you can solve all these problems. It's my my experience I haven't run into anything that I wanted to do that that can't be done in in immediate mode So if someone says that to you, immediate mode can't do that.
I encourage you to challenge that.
There are lots of stuff that's really nice in immediate mode that's sort of problematic in retained mode.
One thing is layouting.
I really don't like layout managers that you have in lots of UI frameworks.
I find them really painful to work with.
Usually trying to get CSS to put controls in the right place is a pain in the ass.
Whereas if we're working in immediate mode, we don't really need a layout manager to do any kind of layouting We're just working directly with the rectangles here So we can just split them ourselves and do whatever fancy algorithm we want to split it Like if we want two equally sized columns we don't have to like come up with some Way of tricking our layout manager into doing that We just split split the rect in half and we have two equally sized column So as an example of this here, we want to do a layout like this.
We just split off a rectangle at the top to hold our header here.
We split off another rect off that top rect for the search field.
We split off a rect at the bottom to hold the footer.
And then we use sort of a dynamic splitter to do this split between the two areas here.
So this is super straightforward in my mind, super straightforward, super easy to understand, super easy to debug compared to trying to get like a layout manager to do this kind of behavior.
Doing custom controls, super easy too and in immediate mode UI.
To do a custom control, all you have to do is to implement the drawing of the custom control using all these draw commands, stroke rect, fill rect and so on and then implement sort of the input interactions like handle, mouse clicks.
keyboard clicks and so on. And in fact there's no distinction really between built-in and custom controls. Our built-in controls are written in exactly the same way as a custom control would be.
And just to show you an example, this is how this drag number control would be implemented.
I won't go through this in detail because it's a bunch of code, but just to show that it doesn't need a lot of code to implement something like this, you can do it pretty easily.
So in summary, having the full control of the tech stack like this, it's really nice.
It reduces the complexity a lot.
We don't have to worry about framework changes.
We can step through and debug anything.
There's the same language and APIs used everywhere in the engine.
So there's no artificial barriers separating tools programmers from engine programmers.
Everyone can go in and do anything pretty much, which I like a lot.
The cons of doing things this way, building your own framework, you have to start from scratch.
Like we started with nothing and then we implemented drawing primitives.
So that's really starting from scratch. I would say that's about six man months of work or something before you're up and running with like a UI that you can actually use.
But we found that that initial cost is soon recuperated, just in how much time saving we have from not having to deal with wrestling with the framework, like wrestling with an external framework and trying to force it to do what you needed to do.
You could start with an existing immediate mode UI, like Dare in GUI, for example.
That would be a way of getting started way quicker.
So that might be a good choice for you, depending on what your situation looks like.
Another con that you might not think about is that doing things your own, like implementing everything, your own framework, actually requires a lot of design decisions.
When you use an existing framework, everything is sort of decided for you.
You have a checkbox and it works the way it should work.
Whereas when you write everything yourself, you kind of have to sit down and think, well, how do I want a checkbox to work?
How does it make sense for a menu to work and so on?
You have to make all these design decisions, which depending on whether that's something you're attracted to doing or not attracted to doing, that might not be the right decision for you.
But you should be aware of that.
There's a fair amount of thinking and work that goes into that.
And also, as I said, it kind of requires to rewire your brain a lot to think about UI this way, to do immediate mode.
So the final thing we're doing here, generating UIs.
As I said before, the idea here is we want to reduce the work.
We don't want to create UIs for everything.
We want to drive that automatically somehow.
A typical example of that is the properties panels.
And I think this is something that a lot of editors would do.
they would drive their property panel, they wouldn't implement it for each object, it would drive it from data.
That's what we do.
We use a property panel as our default object editor.
The way it works is that we loop over all the properties of an object and we draw an appropriate control for each of these properties.
For a Boolean, it might be a checkbox, for a string, it might be a text box, and so on.
And now using the default control might not work for everything.
For example, things like color, you might want to have a custom control for that.
So how do we do that?
And we get all these properties from the truth, by the way, since we have a standard data model for that.
So to handle custom properties, we use a system that we called Aspects.
And basically it's just a callback, a function callback identified by an ID.
So each system can define an aspect like this.
So the property, the property tab has defined a callback that's identified by an aspect called AspectCustomProperties.
So we can if we want an object in the truth to be drawn in a special way in the property panel all it has to do is to implement this aspect and Then when we go through all the objects here we check them or does this object have a special aspect for interacting with the property panel and if it does that aspect will be called and if it doesn't it will get the default panel So this is an example of that for a vector three.
Again, I won't go through the code.
It's just showing that it's pretty easy to do this.
And the nice thing about this is that every control, everything gets a UI by default because we map the standard controls to the UI, but then you can go in and customize it with a special control if you really need to.
But we take this approach of using generated UIs even further.
It's not just for properties.
We use it for previews, for instance.
So this is controlled by an aspect again.
So any object that want to be able to be previewed, just adds a preview aspect to the object type in the truth.
And then that preview aspect takes care of drawing the object in this preview window, spawning entities, drawing UI, playing sounds and so on, whatever is needed to preview that kind of object.
We use the same thing for trees.
So by default here, we would render, by default to render a tree view of an object, we would just render all sub-objects as children.
But if an object wants to customize that, it can implement the tree view aspect and do its own custom tree drawing.
So here's an example of a full UI using all of this.
So this is our animation state machine editor.
As you can see, there's a lot of pieces of UI here, but all of these pieces are actually standardized.
So we have a tree view here.
That's our standardized tree view control.
We didn't implement anything special for the state machine.
We have a GraphView, that's our standard GraphView control, and the state machine is just implementing an aspect of it to define how its objects get represented in this GraphView.
Same with the properties, so standard properties control, and we have a preview control here, which is our standard preview window as I mentioned earlier.
This way, we can put together a really complex UI by just reusing all these different parts, which is really nice.
So, conclusion here.
I would say that creating UIs in this way, in this system, feels a lot faster.
We no longer feel blocked by UI tasks.
And in fact, we could build our entire engine with the UI, with the editor and everything, by two people in two years, which I think is really good.
Our data model, it's awesome to get all this stuff for free, but it's also a little bit scary how it's a central piece of technology that's kind of complex and it's getting more complex with every piece of functionality that gets added to it.
I think using aspects the way we are is a really great way of customizing object behavior.
I definitely recommend that.
Implementing things yourself is a lot of work.
Functional design, as I said, but I think the payoff is great.
Not being dependent on frameworks, being able to debug and profile everything, and being in control.
I would say that we are missing some features that you would find in a full-fledged toolkit.
We don't have support for right-to-left text, for instance, for localization.
But I don't worry so much that we don't have a ton of features, as long as these features would be easy to add when we need them.
So at the point where we start needing this, I'm pretty sure we could implement it easily, that's the whole point of keeping things simple and being agile.
And I think there's a danger of having lots of features, but having a complex system that is so complex that you don't actually have time to use these features.
As an example, in Stingray, we used web technology and stuff to be platform independent, but we never had time to support any other platform than Windows.
And we had right-to-left text that we needed, but we never had time to really start on localization of the editor at all.
So I think you have to be really careful about how you're spending your time.
And it's...
more important to be simple and to be agile than to have features that you're not using yet.
And all in all, we're really super happy with the way things are going and the speed with which we've been able to develop UIs and it feels fun to make tools and UIs for the engine, which it didn't really do before and I'm really pleased and happy with that.
So this would be the time where I would ask for questions.
I can't really do that now since we're in lockdown mode.
But if you have any questions, tweet me at my Twitter handle there.
We have a podcast, an R Machinery podcast that I recommend you can listen to if you want to find out more stuff that we're doing.
We also have a blog available on our website, rmachinery.com.
and feel happy to read that and contact us if you're interested in looking at the onion or using it.
