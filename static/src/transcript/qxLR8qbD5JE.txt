So here we go.
Hello everyone, my name is Marco Renzo.
Welcome to our presentation, the Animation Pipeline of Mario Bros. Rabbit Kingdom Battle.
I'm the Animation Director at Ubisoft Milan and I'm here today with Tommaso Sanguini, our Animation Technical Director at Ubisoft Milan.
And it's amazing to have you all here today.
We are super, super excited to be able to show you some of the tools we've been working on in the past few years.
and talk a bit about the reason why they've been necessary in the first place.
But before we start, let me show you a quick trailer for those of you who do not know the game.
Who do you think you are? You should kneel!
I'm the star! You are nothing but a parody!
I'll find you a good role in a tragedy!
In a million years ago, the only words you know By heart will touch your princess's heart And you will be torn apart You think you win this tournament I swear you do, I swear You so half-heart, half-heart You think you win this tournament So, what kind of game is exactly Mario Plus Rabbids Kingdom Battle?
Well, it's a Nintendo Switch exclusive, a turn-based tactical adventure starring Ubisoft Rabbids and of course Mario and his friends.
The project has been developed in the last four years by Ubisoft Milan and Ubisoft Paris in collaboration with Nintendo.
And the gameplay is composed by two main parts.
There's an exploration where the player is free to move around, solve puzzles, find coins.
and collect items such as new weapons, artworks, and music tracks.
And a tactical combat phase.
And here the player can plan the strategy to win the battles.
You can use different characters, choose different moving and attack abilities.
Different kind of weapons and fight various kind of enemies.
and unlock and upgrade skills that will help you progress through the game and beat increasingly hard fights.
So here's a quick overview of what we'll discuss today.
The talk will be split in two parts.
In the first one, I'll show you how this project came to life and what kind of goals and constraints we had to consider when planning our pipeline.
This would be key to understand how these factors translated into our tools.
In the second part, in fact, starting from these requirements, Tomaso will discuss the technical implementation of some of them, showing the functionalities that made this project possible.
So where did we start?
We started from here, a paper prototype, and then a digital one made with Unity 3D and a pipeline based on MotionBuilder.
And I still remember how surreal at the moment I was told we were going to work with Mario was. A game of Mario and the Rabbids. It just sounded insane.
But as crazy as it sounded, we sure didn't want to mess it up.
I mean, you don't get every day the chance to animate Mario, let alone to present a prototype staring him to Nintendo itself.
That's why we wanted to be as respectful as possible with both brands.
Nintendo and Ubisoft IPs.
So we started meticulously previous games, looking for references and going through them frame by frame and try to learn as much as we could as fast as we could.
Because the plan was to show something playable in just a few weeks.
So we managed to pack a prototype and present it to Miyamoto-san.
And his reaction was great.
He did not expect something playable and he was actually surprised by the amount of detail we put into it.
But he also added something during that meeting, something that would completely change our approach to the game.
He literally told us, make a Mario game that has never been done before.
meaning to be innovative, proposing something new, fresh, somewhat unique and unusual.
And receiving this feedback, we realized that he was encouraging us to fully express ourselves, to get out of our comfort zone and try the unexpected.
And we deeply thought about his advices and defined what became the core pillars of our game, based on our passions as game makers, of course, but also as gamers.
So first one, which shows an unexplored genre for both the Mario and the Rabbid IPs?
And as you can imagine, this decision brought challenges.
First of all, it's a genre usually considered as complex and for a very specific public of dedicated players.
And secondly, it involves many new mechanics and interactions between characters.
Now, from an animation point of view, this is a huge, huge deal.
Suddenly, not only we had to bring to life probably the most iconic character of the whole industry, but also make him perform actions he had never performed before and make him look believable and acceptable by the fans.
Now, add the rabbits to the equation and...
It was challenging.
Once we decided the genre, we focused on the mood we wanted for the bottles.
And have you ever played with water guns in a house summer afternoon or maybe with the snowballs during the winter?
That's the kind of mood we wanted to convey. We wanted to be colorful, we wanted to be playful, joyful.
And the video here shows the very first proof of concept of our core system.
It should give you an idea of the tone we set for the whole combat system of the game.
And then cartels.
Our goal was to communicate their personalities and let them feel well grounded into the world.
And as I said earlier, having Nintendo characters performing new actions was a challenge by itself, but at least their personality is well defined, with tons of references to study and analyze.
The rabbits, however, historically have always had a generic personality, and the challenge we set for ourselves was to make each one of them feel unique.
We did not want them to simply cosplay as their Nintendo counterparts.
We want them to have a unique personality, thought process, and acting choices, which is basically a dream for an animator.
Okay, so we identified our core pillars, tactical genre, hide-and-seek mood, unique characters.
It was time to implement them into the game and focus on the mechanics.
On our side, on the animation side, to be able to achieve these goals, we had to first and foremost answer a simple yet complex question.
How do we mix and balance characters so different?
I mean, just look at that.
And let's be honest here, I guess the reaction most people have when they hear for the first time about a game mixing the Mario universe and the Rabbids is at the very least surprise, maybe confusion.
So it was obvious that it was of the utmost importance for us to find a way to mix these two worlds in a way that felt new and fresh, but also believable.
And the way we approached this problem was letting the two brands mutually influence each other.
For example, from Mario, like I said earlier, the Rabbids gain a strong personality and a unique personality.
Every Rabbid hero is a parody or an exaggerated version of the Nintendo counterpart.
But we didn't stop there, of course.
In fact, the usual clarity of a Nintendo character's posing has been applied also to the Rabbids.
strong line of actions, clear silhouette, great readability, the concept of posing as a mean to communicate gameplay rules are all state-of-the-art elements in Mario games.
And these elements have been key for us because they made the actions read clearly from the gameplay camera, which in our case is quite far away, and communicating mechanics without overloading the player with information from the UI.
Here's some examples with the rabbits.
And their shapes are challenging.
Huge head, very short legs.
And to push their poses, we focus on the line of action of the two main masses, head and torso, and use the ears to strengthen the line, like in the poses here of a rabbit Luigi and a rabbit Yoshi, for example, or to create a rhythm with S curves going through their bodies, like in the case of rabbit Peter and rabbit Mario.
The timing and spacing have been affected by this mix as well.
In most cases, they've been inspired by Mario.
For example, cycles, damage animations, locomotion speed have all been set and tuned using Mario as a reference since he's always present in the party.
As a result, Rabbids are now more organic and way less snappy compared to the past because, generally speaking, their animations last longer.
Here's an example, two walks, and if you look at Rabbit Peach, you can notice how her walk is much slower compared to the typical generic walk of the past.
And one of the reasons we made it this way, that it just felt more natural when coupled with Mario.
Here's another example with the damage animation.
And it's interesting to notice how the animations last exactly the same number of frames, but the ziggy on the right, which is one of our enemy archetypes, it's much more exaggerated in terms of deformations and spacing.
Moreover, we realize that the characters should not look in pain, and therefore in our game they are not suffering and they do not die.
Heroes are just knocked out and enemies are set free from a malicious influence.
On the other hand, the rabbits.
They have introduced their humor and their craziness to Mario's world.
This was key for us because it created the contrast and it helped to push the personality of the characters.
We wanted to develop a new take on the Mushroom Kingdom, keeping its familiar tone, yet feeling fresh at the same time.
We tried to push the humor, both on gameplay and in cinematics.
Here's a couple of examples from gameplay.
And we looked for every opportunity to add some humor, like damages, bosses, just love Rubby Kong, it's awesome.
Simple runs.
Or losing animations, and as you can see here on the left, Rubby Peach really hates losing.
And here are some more examples from our cinematics.
And as you can see here we had fun playing around a bit with the personalities and relationships between the characters. So, Peach, Rabbit, Peach.
Mario and Rabbid Mario.
Rabbids and Luigi.
Robbie Peach, Mario and Peach.
And here's a sequence which I believe perfectly gathers all these elements.
You think yours is a real moustache?
Who's done me a thousand wrongs ever since Donkey Kong?
Slithering down every pipe, despite his plum-shaped body type.
He's gone a-running, fia, why screaming, mama mia?
Who leaves me grey and grim?
Oh, what does Pete see in him?
And I truly believe these are examples of interactions that have been possible for us to make solely because, thanks to the rabbits and their innate ability to break the rules and get any carter out of their comfort zone.
Obviously, we had to mix the cartoony style of both IPs, but we wanted to push forward, exploring new directions.
In order to do this, we exaggerated the deformations, especially through squash and stretch, to achieve a more organic feeling.
Rigs have been built to support these kind of animations and deformations.
So here are a couple of examples with Robby Kong.
And as you can see, the animator has really a lot of freedom in the way they can adjust and change the shapes of the character.
Sometimes too much, probably.
And you can also see how specific each one of them is due to huge differences in terms of the design and size between all the characters, heroes and enemies.
An example of deformations is the use of smear frames and the Rabbits usually feature full-body extreme deformations, while for the Nintendo characters they are limited only to the extremities and used very sparingly. So here's a for example Rabbit Peach or White Rabbit and here you can see how the whole mouse is changing, it's deforming.
while for Luigi, it's limited only to his feet.
And hopefully you won't notice it in real time.
So we had our goals set on a specific style.
It was time to focus on the actual implementation of some of the core mechanics.
And we first started from the locomotion.
We actually have two types of locomotion in combat and during exploration phase, and each one of them has its own set of specific animations.
They're both code-driven in order to achieve a classic arcade feeling, and plus it allowed the designers to tune it as much as they wanted without having a strong dependency on our work.
And the same is true for special movement abilities like the dash or the team jump.
And here you can see an example of Luigi changing these actions, dashing enemies and jumping on top of a rabbit Luigi.
And going back to cover.
Speaking of which, our cover system is actually animation driven.
This allowed the animators to push as much as possible interactions between the characters and the environment.
And this is especially true during the combat phase as the characters interact a lot with covers.
Here for example, Rabbid Luigi leaning off of an off cover.
We have a total of several cover positions between low and high ones, and as you can see in the video, each position displays a different idol.
Also having unique characters means that each one of them needs a different way of taking cover.
And the transitions, which have been for us equally important.
We spent a lot of time and attention to make sure that each one of them stayed true to their character.
They are not simply a bridge between state A and state B, but they are key to convey their personality.
If you look at the video, the way Rabbit Yoshi and Rabbit Mario switch side of the cover tells a lot about their character.
And here's another example of one of our enemies playing different animations depending on the starting and ending position.
So, left to right, front to back, also.
back right to left front and so on.
And another area that's worth mentioning is the targeting mechanic.
And from a gameplay point of view, its goal is to easily communicate to the player if the target will be hit or not.
If the character is hiding, it means no chance of success.
And also you can see here the line of action of Robin Mario being pushed.
And the characters of course have their own personalities, so they react accordingly.
So here's an example with one of our enemies and their reaction is also based on the position of the attacker.
So if Mario is in front of him, he will have a reaction, but if he's on his side, he will react differently.
And of course, again, different heroes, different reactions to Rabbid Yoshi will probably react differently compared to Rabbid Mario.
We love Italian acting cliches.
But we're Italians, so we can.
So another tiny detail that might be hard to notice, but when we are attacking and another character is on the way, the one in the middle will duck.
To give you the idea, he's actually trying to get himself out of the way.
So Mario is trying to dodge the bullet here.
And props, of course, have been used to better define the characters.
So what's interesting is the fact that it happened quite a few times that we added props that were not included in the original design of the character to support specific animations that were crucial to push his or her personality.
For example, the moustache, the toothpick, the mandolin and the pizza of Rabbid Mario have been introduced very, very late in the development cycle to bring his personality on par with the other heroes.
And again, of course, to convey humor and parody.
So everything you've seen so far hopefully has shed some light on some of the artistic challenges we had to overcome.
But I guess that no project comes without its own amount of technical challenges.
And this one was no different.
In fact, first of all, we had to switch to a new game engine.
And Snowdrop is the latest Ubisoft proprietary game engine.
It has been chosen for its flexibility, scalability, and of course, rendering quality.
But it was built with a division in mind, which is a totally different game compared to our project.
We also had to develop for a new console, and probably you know what it means, right?
We also had to handle two important IPs, which meant that not only the artists had to learn how to work with the characters, learning their psychology and mechanics to the point of knowing them by heart, but we also had to learn how to handle the feedback received, which would come at any time during the process.
And we also started with a fairly small animation team.
In fact, we started with just four animators, one pipeline TD and one character rigger.
So to sum up, we developed on a new engine, a new console.
We had to prepare to react to a feedback we have never received before with a small team that was working on a Nintendo IP for the very first time.
So, how?
How did we avoid all the mistakes we were leading into?
Actually, we didn't.
What we did was planning for mistakes.
We quickly realized that there were just too many variables and avoiding mistakes would have been simply impossible.
Therefore, we focused on planning the inevitable mistakes, giving our animators ways to explore, experiment, prototype new ideas, and above anything else, learning while doing so.
We set the time for them to prototype and experiment or simply play with the characters.
And these gave birth to some of the coolest ideas that we ended up implementing in the game.
So here you can see some example of this process and if you look at the admission in the bottom row, for example, they've been used in some way or the other in the game.
And our tools and pipeline have been developed to simplify and increase the speed of iteration process.
to give the artists this kind of space in order to let them express themselves and iterate on their animations, even at an advanced state of the production.
And Tommaso will now show you some of these tools which have been key to the success of the project.
Hello everyone, it's such great to be here.
It's now time to go a little bit more technical.
As you can imagine, after all the consideration that Marco has made so far, we were heading for a huge amount of key frame animation data.
And as our technical department, we wanted to make sure that the iteration on this amount of data wasn't frustrating for the artist.
So we tried to keep being focused on these two main concepts for the development of the pipeline.
Freedom to explore, in order to let the animators easily manipulate such amount of data.
And fast iteration.
In our case especially, in order to react quickly to the feedbacks that could arrive from both IPs any time at any stage of the production.
The first step was to find a logical way to rationalize and organize such an amount of animation data.
If we could arrange multiple clips in the same file, it is easier for the animators to iterate and compare on related animation clips.
There are different ways of achieving this.
If you are on a motion builder, you could take advantage of the take system.
But our pipeline is on Maya, and we don't have a native take system.
We tried to arrange clips on the timeline one after the other. We tried to use the tracks editor but in the end we decided to go for animation layers as at first glance it looked like to be the answer to our question. However for the animators working with the animation layer wasn't really intuitive. If you have to move one clip or the other You have to turn on the corresponding animation layer, turn off the others, adjust the timeline, and so on.
So collecting all the feedbacks we received from the animators, we came up with our take system in Maya.
It is basically animation layers wrapped with additional functionalities.
Something very simple, but very effective.
From a very simple interface, the animators can handle the different takes present in the current scene, and for each one of them, you can still have additive animation layers.
Let's see the tool in action.
The animator can select the controls he wants to animate.
From the takes pane, he can create a new take and assign a nice name for it.
and adjust the timeline. As you can see when the timeline changes the new frame range is recorded inside the take pane. And then the animator can keep working as usual. After a while what you get of course is a single animation on a take. And anytime the animator can right click and create a new take.
or uh just uh adjust the time uh the time range. Rename the take of course. And uh even assign a nice color. As you will see in the next slide we took advantage of the color coding a lot in our pipeline. Since we have a lot of animation using color coding is very effective to have a quick uh feedback on the related animations.
After a while what you get is a single Maya file with different clips. And you can see how it is reactive for the animator to just click on a specific take and activate the corresponding clip. The frame range is adjusted. The timeline is color coded to reflect the current active take.
and uh we we took advantage of uh meta data and attributes so something very simple uh like uh a reordering takes is very quick compared to reordering reordering animation layers. We stressed the take system and the animation layers to the max and it resulted to be so reliable and so effective and so intuitive for the animators that that we started to build upon of this uh simple tool.
So we integrated the text system with uh our exporter on the left and our process library on the right. But uh we didn't stop there of course.
even if our scene files are under version control we may wanted to save in the same Maya file different versions of the same uh animation clip. So we created a tech version system in a way that the animator can uh realize such uh functionality.
Let's see it in action. The animator can right click on a specific take.
and create a new version for that take. It can be an empty version or a duplicate of the current version. And you can animate the one version or the other.
As you can see here the animator can uh right click and activate a specific version for the take. As the different version belong to the same take in export it will result as a single clip. And this is very nice to it is very effective to keep uh very nice and uh uh clean uh uh files in exports.
But let's suppose that uh you have a specific version that you like so much and you want to have like a separate uh separate take and uh create a version upon on that. Anytime the animator can right click on a take and extract the current version. And uh this will become a a separate take. This is uh very simple and quick since uh I said before we use uh metadata and not networks to um create such a meta structure on the takes.
and of course you have the opposite function. You can set a specific take to be a subversion of another take.
and time markers. For each take we also added the possibility to set specific time markers. Uh this allow the animators to visually uh mark specific areas of the timeline. As you can see here the animator can uh select a specific area of the time range of the timeline and mark this area. In this case as an interface.
then it keeps working by selecting another area and marking this on hydro as uh um idle phase. And just like uh said before you can assign uh uh specific color coding for that area.
It may sound like something very simple but um the good thing here is that the animator can frame any time the specific area of the timeline. This is very effective for uh for instance for framing the idle phase and making sure that uh the looping uh animation is working properly. And uh also the animator has the possibility to export the uh markers uh separately or as a whole.
I don't know if you, how many of you have played the game?
How many of you have played the game?
Yeah, cool, very cool.
And yeah, we have this kind of gameplay cinematics where we have balloons that you have to confirm.
And this tool has been crucial for us to make sure that during the idle animations, during the balloon being visible, the idle was working properly.
As you can see all the tools are very relative to our domain, but our focus was always to design for the animators.
As you saw earlier, the transitions play a key role in our game.
And we made this very simple tool for automating the creation of the takes for these transitions.
From this interface, the animator can freeze different poses.
and uh the tool takes care of generating the possible transitions between these poses and uh nice color coding is automatically assigned. Then we have some other little extra features like uh the ability to mark specific takes to the to be ignored. Uh let's suppose you use uh takes for uh um just storing poses or whatever you want.
and you don't want this to be exported. And then we have the ability to mirror specific takes. See here rapid widget going from left to right and uh the tool creates the opposite uh uh clip. Having rapid widget going from right to left.
The same way we can create a reverse of the current take. We have Rabbit Luigi going from cover left to back and we can reverse the animation and having a take going from back to cover left. It's now time to see how we uh took advantage of the take system.
Here you can see a typical file structure of one of our heroes. As you can see it's uh it's very nice and uh clean. All that light blue files are our Maya scenes. And on the right you can see uh an example with uh Rabbid Mario. Starting from a 92 Maya scenes the animators generated 592 takes and in export uh there was just 530 exports.
Could you imagine iterating on 530 Maya files separately?
Probably it's a nightmare.
And here you can see one of the heaviest scenes, just to give you a quick feedback in terms of performance.
On the left you can see the standard Maya animation layers.
On the right, our take system.
Every time the animator clicks on a specific take, The corresponding animation layer is activated, the time range is adjusted, the markers are made visible, and so on.
Again, handling such amount of animation layers manually, it would have been a nightmare for the animator.
Let's talk about poses now.
We have seen with Marco how important are poses for us in order to convey the personality of the character and to give feedbacks in terms of the gameplay status of the character.
In our case, having poses under version control and shared wasn't enough.
We had to find a way to be as reactive as possible to the feedbacks.
here you can see a typical feedback that our animators received during the production. And they had a very short time to address such kind of feedbacks. For these reasons we needed to track where and how the poses had been used and eventually update them automatically. So we created a post system. The post system is made of a classic post library.
poses tab showing the poses used in the current take and uh the timeline where you can uh see where the pose has been used. Let's see it in action. Every time the animator apply a pose from the library the pose is marked on the timeline and on the poses tab. So the pose since we might have poses for the body, poses for the face or any other different limbs or props, the pose system source not only which pose has been applied and where but also how the pose has been applied in terms of controls for instance.
So we could have different poses applied on the same frame.
Yeah you can see here after a while all the poses applied.
and from the poses tab you can click on a specific pose that it will act pretty much like a bookmark to go straight to that frame where the pose has been applied. And also you can check the synchronization status of the pose. Let's have a look at how we update a pose to react to a feedback. When a feedback arrives the animator can right click on that specific pose choose edit and tweak the pose as required by the feedback. Once everyone is happy with the new pose the pose can be submitted of course to our versioning system and shared to the others. If we open the previous scene and go to the poses tab we can see that the pose results to be out of date.
the animator can just right click on that specific pose and choose re apply and the pose will be updated. Like the take system also the poses rely on a shared library so we can easily script the update of the different poses or check the status on the different scenes all in batch. And also we my uh we also have the ability to uh fade the poses with the current animation in a way that we can have a nice blending transitions. Let's talk a bit about uh data management. As you can imagine the take system and the post system is at the animators work. But on the technical side they introduced a lot of additional data to be managed. In fact now for a single uh Maya sim file we have rigs that may be updated anytime.
we have different takes stored inside this scene.
And for each one of them, we have different poses.
We have explicit dependencies like the rigs, but the poses and takes are implicit.
So how we could make sure that everything is nice and in sync?
We created an overseer tool that basically is the answer to this question.
Here you can see basically the same dependency graph you have seen before. On the left the animator can load different scene files and quickly check what is the synchronization status of the pose of the scene file. On the right you can get information about the takes contained inside the scene file and poses synchronization status and text log of what is the synchronization status.
Let's see how it works in action.
we can load um specific folder with all the it's all subfolders and contained uh sim files.
The tool loads in background the dependency um the dependencies of the sim file and checks for the synchronization status. From here you can get the version status, the takes synchronization, the poses and uh the file owner. If you click on a specific my sim you can see I said before the takes contained there.
and check if everything is in sync.
Moreover the overseal handles the batch update process of the poses and the exports in the engine. When we load the different sim files you can see that only specific sim files are checked. This corresponds to the Maya file that needs to be updated. It may sound like something very simple but if you think about scaling such amount of data with all the takes.
exporting everything every time is just a lot time consuming and risky. As you can see here the batch exporter select not only the specific scene files but also the takes that needs to be updated. We have a lighter version of uh the overseer for the cinematics. On the left we have the different cinematics and on the right we have the different shots that belong to the cinematics. Like before just watching at the icons you can get a visual feedback on what is out of date. And you can see a play blast of the specific shot or the whole sequence.
Every time the animator updates a specific shot the whole sequence preview is automatically regenerated on server side. Let's go a bit deeper on how we realize that the dependency tracking. To track the Maya scene content we use the uh, uh, uh, uh, uh, uh, uh, uh, uh, uh, uh, uh, uh, uh, aside the card technique basically we have a descriptor describing what's inside a specific Maya file in terms of takes, markers, poses and rigs. If for some reason the scene is modified outside of our pipeline a ghost process takes care of regenerating this descriptor by scaffolding the scene file.
to checking the synchronization status of the takes we use a technique. Every time the animator updates a curve Maya call back triggers a method on the current take in a way that the animator can just watch the takes and if the current take has been updated it will be marked with a star.
synchronization status of the poses we use both the dirty B technique as before and the time stamp technique. In fact poses are just files so we could easily check the last time the pose has been updated with the last time the pose has been applied on the specific take. For the export things are a little bit simpler since the exports are just my FBX file animation data that we feed to our engine. So we could just check the um latest update of the FBX with the latest time the current take the corresponding take has been updated. Now the future.
We already have in mind some very cool ideas to extend the functional use of our tool.
But of course for us the priority is still to improve the overall performance and usability of the tools.
Maya introduced a cool time editor in the latest version.
It is very useful to do non-linear editing of different clips.
And we aim to integrate our tech system with this time editor.
And at last, we are working for having a tighter Maya engine workflow in a way that we can short the time from Maya to the engine and transfer metadata from Maya to the engine.
So this concludes our talk.
I just want to thank you all for being here in behalf of the Ubisoft Milan and Ubisoft Paris studios.
This project was really made by heart by every person in the studio.
And of course, we had a lot of fun working with that.
So thank you.
And these are our contacts.
Feel free to contact us for questions or just get in contact.
And I guess we have time for Q&A.
Thank you.
Is it loading?
Yeah, um...
Does this work?
I can also just shout.
Oh, there we go.
Hi.
Hi, I'm Alex.
I work at Ride.
First of all, thanks for the game.
It was awesome.
I really enjoyed it.
And I think the opera scene is probably one of the funniest moments I had in games ever.
It's amazing.
Can you guys talk a little bit about how you hook up animations within the game?
Is there an HSM running?
Or is it literally just one sequential animation after the other?
How are you guys blending between animations during runtime?
uh... right it depends but usually we we have our animation system which are in property tool of Zodrop and uh... they're usually connected to states so they're played sequentially But it supports also the use of layers, if you want.
So it depends on the feature.
OK.
Thank you.
You're welcome.
I was just curious about how you give your feedback back to your animators, because you had a little sketch over the, like, what's your system?
Do you have an in-house tool or anything?
Uh, not really.
Uh, usually, um, the feedback is based mostly on, uh, recording in engine.
And, uh, we, we do use a draw overs if needed, but we have several steps of a validation, actually we have a very first one, a very, very, very soon, um, to get a roll approval by the brands and other people involved to do that.
If the idea is right.
and then uh... the more uh... we move forward uh... it moves into polishing details so for those uh... usually it's uh...
we actually have a tool that generates uh...
play blast uh... of the animation from several camera angles to speed up this process and it's what we usually do for example to get approvals from the rabbits brand or from nintendo it's just ease the process And then it's just we have dailies to get the feedback from the whole team.
And basically that's it.
Thanks.
I was wondering if are you able to get real-time playback with all that info in the Maya scenes?
Are your rigs pretty light that you're able to do that?
Well, we started three years and a half ago.
We started with Maya 2014.
uh... at the moment we are uh... migrating to the latest versions and uh... of course we will uh... uh... improve our rigs to make to take advantage of all the new features like the uh... gpu caching uh... anything else the parallel evaluation of course and uh... there was a nice talk on yesterday about uh... forward facing rigs and uh... it was very inspiring for us it totally blew my mind on yesterday so I For sure I'll start from, uh, with that ideas.
Yeah, it's one of the area we'll, uh, focus on the most, uh, moving forward to add, uh, real-time feedback, uh, in, in our scene. Uh, I, I think, uh, there's the latest version of, uh, Maya, there's a beta right now that, uh, they're working on it to, to, to, to remove the, the need to do, to, to make PlayBlast at all. So, that, that's super cool. It's, it's, it's, uh, A good frame rate, but for gameplay animations, it's real time.
But for the cinematics, we're still not there.
And that's what we're aiming for.
Also, gameplay was able to get real time on this project?
I'm sorry?
So the gameplay sequences, the takes, were able to get real-time playback?
Yeah, for those, yes.
It was mostly, the issues were mostly on some sequences that were heavy, very heavy with many characters and environment and so on.
Yeah, I can tell you that what we did for having these more efficient animation layers Part of the handling of the animation layers in Maya has been rewrote in a way that could be more efficient.
I can give you maybe a deeper insight.
If you think about the corresponding animation curves belonging to the same animation layers, the Maya standard way of enabling of disabling this layer is to turn on and off the lock of this curves. What we do really is just deferral sorry doing deferred evaluation of the lock and unlock curves in a way that Maya doesn't have to wait to change the lock status of all the curves. It just basically delays this after the Maya goes in idle. I don't know if that's clear in my English.
We have an additional layer as Italians.
We have to convert.
And also another nice tip for everyone.
For the cinematics, we used a lot the GPU cache for the environment, and that dramatically improved the frame rate of the cinematics.
Good talk.
I appreciate that.
Can you talk more about how you decided where to split the scene?
It looked like you had multiple Maya files per character and how you decided to split this Maya scene has these takes and this other Maya scene has these takes and go more into how you, where you decided to split it up.
It's mainly based on features and we usually try to gather the animation clips that you'll probably have to iterate on the most.
For example, the locomotion ones, we tend to keep them together because there's a lot of iteration on those.
You know, you adjust one, maybe you have to fix the other one.
And for example, for the text, all the variations, like all the clips that are logically connected in some way, we try to keep them in the same file.
If they are just split, separated, then we probably keep them on different files.
Or if in.
We have usually two animators working on a card at any given time.
So if they're working on two features, like damages and acting, for example, we try to keep those separated so they can work on it at the same time without having an impact on each other.
Thank you.
Hi, thanks for the talk.
Sorry.
Did the animators have to fight sort of the animation compression that might happen when they move the, because I noticed you were able to get some very specific smear frames with some of the animations.
Was that ever an issue and did the animators have to learn to work around it or was it the other way around?
uh... we had some uh... generally speaking no uh... it's we got uh... most of the time one on one uh...
match between Maya and the engine but there are some cases where uh...
there are I don't know some props uh... down the hierarchy down the chain and we have a prop that has to stay someplace or there's the idle in the character selection menu where uh... the there's a In places where there are specific contacts and really, really detailed animations, you can probably notice slightly some glitches there.
But it's very, very hard to notice.
Good enough, right?
Yeah.
Hopefully.
We could tell you where, but we will not.
So my favorite part of the game was walking through the game world and seeing the Rabbids on the side like slapping each other and doing all those different animations.
So I was wondering from a creative standpoint how you went about figuring out what those would be and sort of divvying out the task.
We actually have one amazing animator that works on those.
She has a lot of experience with the rabbits.
She's worked with, I think, on all the games ever created.
So she's a master at that.
And the way we usually work is she brainstorms ideas, and she creates these sequences.
And then we try to fit them in the world where it makes sense.
Or sometimes it's the other way around.
We just look at the environment and see if there's anything that sparks a cool idea.
And we just try.
And then we try to understand where it's probably best to put them in a way that it doesn't annoy the player but they can be noticed.
They are there to give life to the world and the rabbits must be doing something while they are there.
Thanks, I was amazed by the amount of unique animation in the game.
Um, thanks for that talk. Um, your implementations on, um, letting animators quickly iterate over several hundreds and hundreds of files blew my mind. Um, and how well your tool was connected to source control, that was amazing. Um, My question was, you have so much of animation content that's being pumped out.
On the runtime side, does the tool help the runtime in loading these animation assets separately?
Or does the tool employ any strategies in deciding, okay, this batch of animation content gets loaded first, and then this other batch gets loaded conditionally?
Does the tool allow...
um, any content author to specify that this batch of content needs to be loaded all the time and this batch of content can be loaded at some other time.
Um, can you reformulate the question maybe? I just, I just lost the last part. I don't know if you were, uh, telling us if you can, uh, separate the takes in different scene fights or, uh, something like that. Um, I actually was talking more about, um, conditional loading of these animation assets on the runtime side.
Did the tool have any strategies to suggest that certain animation content should be loaded all the time and certain content only on the engine side, right?
My question was, did the tool make any improvements on the metadata layer?
Okay, so the way the engine works right now is the clips are loaded for any character that is in gameplay.
But, for example, for cinematics, to avoid the load of...
usually to avoid loading usual useless animations.
What we usually do is we have specific characters made for that.
So for those, basically don't load anything.
So do not overload the game.
Okay, and I also really appreciated the dependency graph that you showed that helped, you know, visualize where things are going and what's dependent on what else.
So as part of that, was there any visualization tool that you used?
uh... that showed how animations were being shared across multiple uh... characters for example and were there any challenges that you faced in sharing animation content among several characters that have different skeletons and different rigs for example?
Yeah, sharing was an issue.
In fact, most of the missions are specific.
But it happened that we shared the stuff between the rabbits, for example, as a starting point, at least.
And I don't think we don't have that kind of way of visualizing how the dependencies are used.
We have a database that we can query using standard queries to check the dependencies.
But it's something separate from Maya.
Basically, it works on the data that is baked inside the engine to check the dependencies.
And the fact of sharing, it was a challenge for us, mostly because the difference in terms of proportions of the characters, but also in terms of creative intentions.
Even the rabbits, as you saw, they have to convey different personalities.
so it was also a creative choice to don't share everything.
Maybe we just start from the same file, but after they go for their own way.
And of course it has a cost in terms of iteration, so that's why we built all these structure to make iteration easier.
Cool, thank you.
Thank you.
I'm trying to apply those old Looney Tunes techniques of squash and stretch and silhouette to the game I'm working on.
So I studied this game like a textbook, because I really can't think of a better example.
And watching that Rabid Kong deform in all those crazy ways was pretty exciting.
So do you have any secrets you're willing to share about how to get that sort of crazy deformation without breaking the mesh and breaking the rig?
You mean on the technical side or on the artistic side, or both?
Or both.
OK, I'll try to reply on the technical side.
It is challenging.
We used some parts of the rig are automated, some parts are handcrafted.
And that was the secret to make that kind of freedom we had on the rigs.
But it was challenging because you have everything basically on joint-based.
And at some point of the production we introduced a kind of blend shape based on vertex shader.
We created a tool for automating all this stuff.
And that gave us a little bit more freedom in terms of deformations.
But the challenge for us was to let everything work real time with just joints.
And, yeah, that's it.
And, yeah, the advice is, of course, smear frames and deformation have to be felt but not really seen.
So...
The focus should be in keeping the volumes and try to avoid getting the character out of his design.
But what we usually do, we go broad, we exaggerate it, and then if it's not simple, if it just doesn't work, we scale it back.
It's better than go up little by little.
Thank you.
You're welcome.
All right, I think, okay.
And if anyone has any questions, we will be able to show some of these tools at the Ubisoft Lounge this afternoon.
We'll be there to answer any questions.
So if you want to drop by and say hello, we'll be there.
Thank you all.
Thank you.
