Hello everyone.
Welcome.
My name is Cole Hicks.
I'm a composer and sound designer.
And I'm Chris Hunt.
I'm the creator of Kenshi.
And this is Unscoring the World of Kenshi.
We're going to be talking about the oral direction and what we decided to do.
To explain a little bit about Kenshi, we actually have a video for you to watch first.
you So that is a short video that explains Kenshi a little bit.
But Chris, if you would like to explain a little bit more.
Well, Kenshi is basically a sandbox RPG.
So at its core, it's all about freedom for the player.
There's no story or grand quest.
You're not the chosen one.
You're not special in any way.
So the whole game takes a nihilistic approach.
There's no Rat Street to practice on.
Player characters don't get any advantage over NPCs.
So I wanted to drill this into the player that you are not a hero, but kind of subliminally.
So the music we decided is about the world, not the player.
So it only cares about the trees and the mountains.
You're not a hero and the game won't treat you like one.
So reflecting this in the music is...
the best way decided to hammer this home.
Exactly.
So in this picture here, you'll see me and a fantastic cellist named Janess.
We recorded down in LA.
But what that means for me is I needed to create a system that represented the world and was indifferent.
So I wanted to have an interactive music system that only reacted to input from the world.
So based off of the time of day it was and what biome you're in, the only agency the player actually has is a music frequency slider and the options that they can control.
So they can control how often they hear music.
And that calls the engine and they'll play back.
different combinations. I'll explain our exact system and how that works, but it varies in timbre, texture, and the mood based on what biome you're in and what time of day.
So, because the map is so huge, we divided it up into four main types of biome, four classifications of music style.
Five of you include the ones without any music at all.
These were the ones that were intentionally designed to be lonely places.
The others reflect the main, the type of the biome, apart from the Ashlands, which was a special case for the extra far away from civilization, dangerous, lots of death and treasure kind of areas.
Exactly, so.
This is Jun Kuramoto.
She's a Japanese koto player, also featured in this score.
And specifically, we hear the koto in the plains biome.
But there are many different biomes.
And there are some that just don't have music at all.
Something you'll hear a lot throughout the talk is silence is utilized quite frequently.
It's part of our style.
And I think it helped.
define our oral scape and give the players enough room to listen to what's going on in the world, enough breathing room.
But the instrumentation, the colors and the mood all change on the biome and what time a day.
So for example, the swamp, they have similar motivic material and you'll hear melodies approached in similar ways across all of the biomes.
However, It'll be slide guitar, banjo, and jaw harp playing those, whereas you go to the planes, and maybe it would be something different, like the koto.
In addition to that.
it's not only the instruments that change, but how we play them.
So during the daytime in the plains, we would have a cello, and it would be playing a little bit closer to the neck, and it'd be playing solpanto cello at night, so something a bit more haunting, hollow, and dark that makes sense for that biome in the time of day.
And this here is a general chart of our interactive music system that only reacts to world input.
I'd like to start at the bottom here so we can talk about that.
First and foremost, when you're in the game, The player, the only thing they get to do is they set how frequently they want it.
It could trigger every minute, it could trigger every 30 minutes, I think we have it up to every hour because there are people that have thousands of hours in this game and maybe you don't want to hear it that often.
But . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
We have the engine that calls to wise every minute or two or five or whatever the player defines and I broke it down into multiple layers that all have random components in there.
So the drone layer, for example.
has our tonal center, our mood information, and is comprised of elements that exist in the other two layers as well.
For example, the cello for the planes, what I ended up doing is took a sample of that, stretched it out, ended up adding some effects, brought it into iZotope's Iris, mapped it across the keyboard, and turned that into a pad that I could then play, and that ends up being part of the drone or ambient layer.
Then on top of that, we have the potential for another layer to exist, and this contains primarily harmonic information, so chord progressions, things like that, any kind of rhythms that are interesting or unique.
And while the drone layer may be anywhere between 30 seconds to a couple minutes long, the frame layer tends to be a bit shorter, anywhere between 15 seconds to a minute.
And then on top of that, we have the possibility of having what I call the canopy layer.
And that is our melodic information, the stuff that has the heart, the soul, and the emotion of what potentially is going on in the world.
It's not representing exactly what's...
going on with the players.
And one of my favorite stories is, I was reading on the forums, and we have a pretty strong community for the game.
And they created their base, and it was raided by a group of bandits.
And they were able to dispatch them relatively easily, but one of them was limping away.
In traditional combat music, if you were approaching it from a standard RPG, it might be a little bit more heroic, adventurous.
It's like, congratulations, you're a badass, good job.
But our music is a bit more ambient, and it felt lonely and dark and sad.
And what ended up happening is something that Bob Ross would call a happy accident.
The player then associated this killing of the last bandit and thought to themselves, oh man, this guy was just trying to survive too, and I don't feel so good about this exactly.
So then maybe you end up being a bit more pacifist throughout the game.
Whether or not that's actually possible, I don't know.
It's a pretty dark and gritty world.
But regardless, that was one of my favorite stories, and this kind of system allowed for those happy accidents to happen.
If I approached it in a traditional sense, we wouldn't have had something like that, and it couldn't exist.
And we have an example here that I'd like to play for you guys of our music.
So that's just the frame layer.
Now we change biome and night.
Frame and canopy on top of each other.
Night again, but for Swamplands.
Again, Fragment Canopy.
Date time for the Tar Sands.
Interestingly enough, there's a possibility that it triggers silence across all three layers, which is nice.
And I have to re-trigger it again, so we get...
And that contained all three layers, our drone, our frame, and our canopy, all combined together.
Escape from that.
Going back.
So one other important point was the anti-Hollywood sound.
This was for the same reasons as everything else, it was to avoid glorifying the player.
Combat at the end of the day is just a bunch of guys wailing on each other with bits of metal, so...
I wanted more of a dull thwack sound rather than cinematic chings.
Exactly, so what I ended up having to do from that information is figure out a way of approaching the sound design and the VO and the music and having it all really mixed together.
Something I just thought of today as I was putting the talk together over the past couple months or so is it kind of reminds me a bit of pointillism.
where we're not necessarily focusing on the very tiny details, but all these little dots add up, and as you move back, you can start to see a bit more clear picture.
And that's kind of how I like to think of the audio for Kenshi, is it's all these tiny little bits and pieces that all fit together relatively well and are mixed somewhat evenly and treated evenly.
So, for example, we don't have the ginormous thwacks and impacts that you would expect in traditional sound design from big, heavy action games.
No whooshes, and it's not super realistic.
We still wanted to make sure that it was engaging, but it wasn't necessarily over the top either.
And another thing that I mentioned prior is silence is good.
We used silence a lot.
It's okay if you don't hear a lot of sounds throughout a decent portion of the game because a lot of these players, it's not just a quick pick up and play for 20 minutes.
It's usually I'm going to sit down and play a session for three or four hours and many players have hundreds of hours, a couple even thousands of hours into the game already.
So silence helps them.
kind of deal with all of the game that they've been playing.
And one of my favorite compliments that I think I've ever received specifically from this game in the forums is there's lots of players that said this is the first game or one of the first games where they didn't automatically turn the sound off and listen to their own music.
And I think that's in part because we didn't inundate them with sound and music.
It was more ambient in our approach and just giving them information that they needed.
So one other little challenge we had was the orbital camera.
It can zoom and rotate pretty far.
So instead of having the listener on the player, like in a first-person game, we had to keep an appropriate ambience to keep in line with the camera movements.
So mostly we based this on the camera altitude from the terrain.
And what that means for me is I needed to create an ambient environment system in Wwise that took into consideration our mobile camera.
And when you're completely zoomed in, for example, let's pick the jungle biome.
If we're in there and you're listening to it, you should be able to hear a general loop that contains information on some twigs maybe breaking over there, maybe some insects, birds.
a general loop that exists in that world, relatively dry, and that's part of our system.
I use blend containers, then, to, as you pull back and zoom out, that loop I brought into Pro Tools, added a lot of reverb, made it a bit more wet that was appropriate for the bio mode it existed in, and then add a low-pass filter, slightly pitched it down, and made the stereo field, as this chart shows, a bit more narrow.
So what ends up happening there is as you pull out, the stereo field for the primary ambient loop gets a bit more narrow.
The wind sounds and other weather sounds come up, but they still stay far-panned left and right.
So it feels a bit more serene, and you're getting wind sounds there.
When you zoom back down into the world, it fills out entirely so you can hear or feel as if you have just dove right into the biome, and the wind comes down a bit.
Beyond that, though, we have an interesting randomized creature vocalization system.
Rather than picking a tree that randomly exists in the world and saying, all right, we're going to attach an emitter to that that says there's going to be a type of bird that would sing there all the time, and maybe it would change off of day or night.
Instead, what I decided to do was go with user-defined positioning for the sounds.
So if you have a 3D sound, whether it be...
a sound, a container of any kind, you can define how it's being played back.
And I decided that we had a random container that's biome and time of day specific, so you have a whole bunch of different creatures that could only exist in the jungle at night.
And it will constantly play that as a loop with the volume randomized, the pitch randomized, and low-pass slightly randomized.
In that container, I have baked in reverb to a lot of the different sound files.
And on top of that, the user-defined, what that means is we have our listener there.
And then I've picked random locations around the listener for these sounds to spawn.
Some of them have movement as well.
That's what the little blue squigglies are.
So what you end up getting when you are completely zoomed in is this more fully fleshed out ambience that isn't necessarily tied to anything specific.
We do have emitters in the world that exist too that you can visually see and interact with.
But this is just to fill out the entire system.
And I have a video for you guys to watch right now.
Thank you.
And the building integrity is we pick a value from 0 to 100, 0 being it's about to fall apart, to 100, it's doing pretty well.
And then that has even more randomized sounds that exist in that world.
So we have wood creaking.
If you're in a metal building, it sounds different.
Stone's different.
Maybe there's some rats scurrying around.
There's flies, too.
That's all part of it.
So.
Audio dialogue was something we avoided altogether.
Due to the sheer size of the game and the amount of text dialogue we had, there was no way to keep up with it.
And I really wanted to avoid arrow to the knee syndrome.
Constant speech repetition in characters is one of the first things to break believability for me.
And we had a small budget and a big game, so I thought it was better to leave it out than to do it badly.
And something important for me and Chris was to then have...
each vocal timbre be easily identifiable.
So the hive people sound different than the skeleton or the robot race you see over there, sound different than the human, sound different than the shek.
And the role of VO and kinshi is more akin to sound effects, where it's enhancing and justifying certain player actions.
So during combat, you may have reaction hits or anticipations.
certain actions justify vocalizations as well.
And there are some idle sounds too.
So if you're in the bar or the tavern, there will be some sounds playing there.
But we don't have a lot of dialogue or monologue for the reason that Chris mentioned, plus localization issues too.
And I have a video to kind of demonstrate the skeleton race, the robot over there, what that sounds like.
And then I'll go through my process for that.
So that last one was them getting hit, the robot or skeleton race.
And that was interesting because I had to think of it a little bit backwards.
where the second step you can see is to reverse the phrase that I recorded.
So if I wanted ow to happen, and usually we'd say ow, and it descends, then I would have to think wah, and it ascending in pitch.
Of course, as you reverse, it's going to sound a little funky.
It's not going to be perfect.
But it ended up working for a race like the skeletons here.
But I recorded phrases, reversed them, then EQed it a bit, taking a bit off the top and the bottom, and adding around 2 to 3k.
compressed it, and something that was really important to Chris is to have it sound like these guys have this old, beat up, dusty speaker that they speak from.
So, MicDSP makes a plug-in called Futzbox, and we picked the antique speaker, tweaked it a little bit, added a little bit of distortion, EQ'd it slightly, and that ended up giving us the sound of our robot race, of the skeletons.
Now I have a video as well that kind of sums this all up together and you'll be able to hear samples throughout the game.
One thing I do want to point out is the combat.
I specifically took out the VO and the footsteps and some of the other sounds that exist in there so that you can focus purely on the whoosh and the impact and keeping in mind our idea of the anti-Hollywood sound.
Bye.
Bye.
Bye.
Bye.
Bye.
So that's a little sample video.
One thing I did want to point out about that is the last three samples were completely taken at different times, but they were all in the same biome.
So that's why it sounded like the music fit relatively well in between each example, as they had the same tonal center, the same tempo, and a lot of the same instrumentation, considering it was daytime there.
So that is our talk.
Some final thoughts just to sum it all up.
For me personally, it was important to create a aural scape that represents the indifference of the world of Kenshi.
So that means making a music system that's self-generated from all the different variables and layers that I've given it.
It's a bit more ambient, and it only reacts to world input.
Then sound, it's important that that plays a role where it just fits into the picture and it's not super Hollywood or bombastic in style.
And lastly, silence was very important to our style.
Yeah, I'm happy with the result and I think when you put it all together, the anti-Hollywood sound, the silence, it makes, gives you a nice depressing, lonely feeling and I like it.
Which it works well for Genji.
But that's our talk.
Thank you very much for attending.
Fill out your surveys and ask us anything.
Please come up, say hi as well.
Thank you.
And if you do have questions, please feel free to stand up to the mic.
They told me to ask you.
Hey, John.
Hello, sir.
Question.
In crafting the score, how many real instruments versus samples versus, could you give us a breakdown of your orchestration, basically?
Sure, sure.
Absolutely.
So I prefer to use as many live musicians as I possibly can, even if I am going to.
put it in a music system that randomly decides when it plays back.
So I would say a decent amount of our score, and Chris was on board for this the whole time which is wonderful, and we ended up working with a lot of live instruments.
The foundation or bass layer, the drone, that was like a mix of Omnisphere and me tinkering around in Iris and other things to create those sounds.
But a lot of the frame layer and the canopy, those were all just live recorded and then I would mix and master and add some reverb to it.
So I'd say a good 80% of the score is all live.
Alright, well thank you guys very much for attending and please come up, say hi, and if you have any questions later, let us know.
Thank you.
