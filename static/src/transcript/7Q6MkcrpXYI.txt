Good evening. It's 5.30, so we should get started. Thank you for coming to the last session of the day. I really do appreciate it. A couple of reminders first. Set your phone to vibrate. You'll be receiving your evaluation over email, so please remember to fill that out. And if you have questions, they'll probably be pushing us out because this is the very end of the day, so there's a wrap-up room or wrap-up corral that's right across there so I can answer any particular questions that you have. My name is Mia Consolvo and I'm going to be talking about a practical guide to doing ethical player testing. Why should you listen to me? I've been studying game players for about the past 17 years now. I've been studying And I've used a variety of methods to do that.
I'm mostly interested in who plays, why they play, and how player culture adapts and evolves over time.
And so I've been getting at that mostly from a qualitative perspective, so a lot of observation, both participant and non-participant observation.
I do a lot of interviews and focus groups.
And I've done a bit of survey research, but I don't get so much into experiments and big data analytics.
Over time, I've investigated a number of different things and with respect to players.
So my first book was about cheating in games and how and why people cheated, how they defined it, what they did or didn't do according to their own definitions.
I've looked at a casual MMO that was online for a short period of time called Faunosphere.
Most of the players were older women and so there was an interesting dynamic going on there.
And my most recent book is Atari to Zelda, which is about Japanese video games and what happens as they travel to the West, including how Western players take them up and make sense of them.
So I teach at Concordia University, which is in Montreal, and I run the M Lab, where we play games, we study games, we study players, and we try and innovate in better methods for studying play.
So what I want to do during this time is give you, and I wasn't going to include the first point, but the track administrator said, we really want a history of how this evolves.
I was like, okay.
So you're going to get a very short, short history of why, for example, universities require researchers to go through like ethics training and get ethics approval for their projects.
Usually, of course, it's because somebody messed it up for you.
I'm going to talk about some important concepts to keep in mind for testing, some questions to ask yourself when prepping for testing.
I have a short section on VR because it's just becoming more and more of an important thing to think about and hopefully we'll have about 10 minutes for Q&A at the end.
I should point out that this is not a talk about improving your game design through player testing.
There are many other people, or you're probably more of an expert there.
There was a great talk yesterday about evil data in its relation to play testing and how to get better data or, you know, like sift through to get really, you know, ask the questions that you really want to ask.
Instead, what this talk is about is ensuring that your play testers are getting the best possible experience.
That they don't leave feeling vaguely bad or mistreated.
You know, that they didn't, there was something that happened that they definitely didn't sign up for.
And so, you know, they're happy, they're engaged, and so they are giving you the best possible data to work with.
And also, if you're hoping to work with them again, that they are willing to come back and test again and not just, you know, run screaming and telling everybody, you know, what a horrible experience it was.
So a caveat, it would be easy if this were a list, just a simple list of do's and don'ts.
Instead, most researchers will say that thinking about ethics with your research is like a series of questions that you have to ask yourself.
And sometimes there may be a definitive answer, but many times it's really not that there's one right or wrong answer, but it's that you've considered it and what are the consequences of going one way or another.
These are some guidelines for you to consider, some hard-won knowledge that other people have found.
So a brief, very brief history of human subjects research.
I'm just gonna talk about two studies, and you may have heard of them already.
Or I will if this will advance.
Okay.
And these are from social science.
Medical research has its own outliers in terms of very bad practices.
But in social science in 1961, Stanley Milgram did a famous experiment where he was interested in how obedient people would be to figures of authority.
And so he recruited folks and said, you know, I'm going to, you pick a piece of paper and you can be either the tester or the testee.
And conveniently everybody was the tester.
They didn't know it.
The testee was just somebody who was in on the study, but the testers were told, um, You're gonna be watching them and they're gonna be trying to, it's this test to improve their memory.
They're gonna hear words, they have to repeat them in sequence.
And we're trying to see if shocks, if pain will increase their ability to engage in memory recaller.
You know, increasingly motivate them.
And over time there were more and more words and the shocks got stronger and stronger.
And Milgram actually thought that most people would drop out, like they would refuse to do this, like that they would refuse to engage in the shocks.
Now, of course, these people did not know that the shocks were not real.
The people who were being shocked were actors.
But disturbingly, they found that many, many people were perfectly fine going along and shocking people more and more.
I mean, these people were like screaming.
One guy was like banging on the wall, you know, in apparent distress.
And so they said, you know, wow, like, this is really showing us some interesting things about how obedient people are to authority.
This is important as we go along, but also another important element is that the people were being deceived, but they didn't know, you know, of course, that, you know, these other people were not really being shocked, which may cause you some psychological distress that carries over.
But also, the people who were doing the shocks were not really told that they could withdraw from the study.
There were four prompts, like if they were being reluctant, the person who was watching them said, you must continue, and then it's really vital that you continue.
And there were four going up to like, it's absolutely imperative that you continue this study.
So even if these testers felt uncomfortable, it was a situation they mostly felt like they could not escape from.
The second experiment is the Stanford Prison Experiment, which happened ten years later.
Philip Zimbardo ran it, and he was curious about the psychological effects of becoming a prisoner or a prison guard.
He didn't know if it was the situation or, you know, individual psychological traits within people.
that would lead to problems in prisons.
And so he recruited a group of college students and they were randomly assigned to be a prisoner or a prison guard.
And it was set up to be a two week experiment.
They set up a mock prison in the basement of a university lab on campus.
The prisoners, interestingly, they were not told exactly how this would start, but they were arrested at their homes one day, driven to prison, they were processed, given a jumpsuit, and they were given a number and told, you know, like, you're not going to be referred to by your name, now you're this number for the duration.
And if you're familiar with it, you know that things quickly went downhill.
The prison guards wore reflective glasses so you couldn't see their eyes.
They were told it was perfectly fine to psychologically harass the prisoners.
They quickly and readily fell into this role.
The prisoners also fell into their roles, where some of them, the ones who tried to fight back, were harassed and further abused.
Many of them just fell into silence and depression.
Some of them actually had breakdowns and had to leave early.
Another important element, the subjects were told that they could not leave voluntarily.
And Zimbardo himself was not a neutral observer.
He couldn't really step back and see.
He was playing the role of the prisoner's superintendent.
It was actually his girlfriend at the time who was a graduate student who stepped in and said, Hey.
This is kind of problematic.
I think you should really look at what's going on here.
And they shut down the experiment after six days.
Also, another important element that led to further review by universities is the fact that they never actually talked to the people involved, like the subjects, until almost a year later to see like, hey, how are you feeling, are you okay?
Is anything going on that might have caused you distress ongoing after this?
So those are the types of things that led to universities saying to researchers, hey, you know, we're going to have some protocols and guidelines if you're doing any federally funded research. And actually, if you're a researcher in the U.S. or Canada, even if you're not doing funded research, because your university accepts funds, you have to, you know, get ethics approval.
Obviously, you may not have to do this, but many of the standards still apply for, you know, like what are the principles and best practices for engaging in research.
And one of the big major ones that I'm going to start talking about is consent, you know, what it is that people are agreeing to.
And so in the Canadian guidelines, they talk about consent has to be free, informed, and ongoing.
And by free, they mean voluntary.
So I'm going to go through each of those three categories of consent.
So voluntary obviously means no undue influence or coercion.
The easiest example of this is, you know, if you force somebody to play your game, you know, I force somebody to participate in a research experiment with me, you know, maybe I threaten them, you're gonna fail my class if you don't.
Maybe you say you're gonna be fired if you don't do this.
Obviously that is, you know, they cannot give their consent.
You know, A little in a more of a gray area is undue influence.
And so one of the things to consider is, is there a power relationship going on between the investigator, you know, you who's setting up the test and potential participants.
Now it doesn't mean that you should never, like it's never okay if you find somebody who you're in a power relationship with, just that you should be thinking about, you know, is there some way that I might be, you know, unconsciously.
coercing them or convincing them to do something.
Are they really free to say, no, I don't wanna do it?
If you're not sure if it's a power relationship, think about, do they trust me?
And am I really pulling on that trust to kind of get them to agree?
Participants should know, obviously with informed consent, what's expected of them during the test.
Now this does not mean that you have to tell them every single thing about what's going to happen, every element of information involved in your game, but that they should have some general idea of what they're signing up for.
So, you know, what's the game? What are you asking them to do?
You know, are you asking them to test like the first few levels?
Are you asking them to go through the entire game? Is it characters that you know, you're asking them to like react to like you're Is there a character that they prefer?
Is the storyline believable, you know, whatever.
Now it may be the case that, you know, there's something that you don't want to specifically tell them.
You know, how long is it gonna take you to get through this level?
Because once you tell people something, then they're unconsciously thinking of that.
But you can frame it in a more general way, right?
So at least they have some idea.
They should also know, like, how long they're going to be there, roughly.
You know, is this a 30 minute test?
Is it a two hour test?
What's gonna, you know, How much time do they really need to budget?
How will they be observed and recorded?
I'll get into this in more detail, but just, you know, like, what are the elements involved in what you're doing in terms of watching them?
And also that it's okay to change their minds.
So at this stage, you know, after you've explained what's going on, maybe they're gonna say like, oh, it's a survival horror game.
I really don't like those.
This is not for me.
Okay, you know, it's fine for you to back out.
They should also be told what some of the risks are, and if there are any potential benefits involved.
I'll get into this in more detail.
Also, that they're under no obligation to participate, and again, that they're free to withdraw at any time.
And so it's really in terms of you're being open and honest about saying, hey, if you're really not into this, maybe this is not for you.
And I should also know, you know, like what's going to happen, like if you're recording their data, are you going to identify them in any way? Like if there's a video camera, you know, are you recording their face, their facial expressions, and is this something that you're going to keep, or are you going to like maybe gray out or blur out their face or something?
There should be obviously some contact information so they can ask you later if they have any questions or concerns.
You should talk about how you're gonna actually use the data.
And so, like, is this something that it's just you who's looking at personally?
Is it a member, you know, is it, like, your team?
Is it everybody from the studio?
Are you going to use it, oh, in a GDC presentation?
You know, and you may not know immediately, like, how far you will take it, but, you know, you should think about that and say, like, it may be used in these particular spaces.
Maybe you're going to have blog posts or something about, you know, like, testing and what's going on.
You should have information about any payments or incentives.
And also, you should give them a reasonable amount of time to go through this so that they don't feel rushed.
And they can also ask questions.
And these things can all be things that you can either print out so they can read quietly, or you can explain it to them verbally.
Either way is fine.
Consent also has to be ongoing.
What this means is just that it's not enough to get somebody to say like, are you okay with this?
I've explained everything.
They're like, yup, and then it's over.
Then you're in prisoner territory.
It's like they said yes once, and then no matter how horrible it was, it was like, oh, well, you signed up for it, too bad.
People should feel like they have the opportunity to leave at any time.
And if, you know, for whatever reason, maybe they don't like the experience, maybe they're feeling sick.
You know, if they're not having a good time, they're not giving you good data.
And so you need to think about like how, what are the different ways that you could like remind people.
during the play session, you know, it's okay.
Like, we're gonna take a break now.
If you need to go now, that's cool, whatever.
If you have multiple aspects of the test, are there things that maybe, if people are uncomfortable with one aspect, you know, that you could omit that for them, but have them do others?
Or maybe you need people to complete the whole experience and just be up front with people and say, like, if you're not comfortable with everything, then this isn't for you.
So again, they should be told that they can stop, not just leave, but stop at any time.
And the environment should support this.
So it's one thing to say this, and you know, you may not have control over where you're doing the testing.
You know, maybe it's in a room down a corridor with no windows, and you know, you're sitting in front of the door.
And I mean, that's like a very, you know, tough thing to do.
Like people are already, as those experiments show, kind of obedient to authority.
Like my students, you know, if I sit at the front of the room and the door is near me, it's very difficult for them to like get up in the middle of class and walk out, right?
Like that's not a cool thing to do.
They don't want to draw attention.
And that's another way that the environment can unwittingly shape people's expectations.
So if it's possible for you to think about this and alter the environment so that people feel comfortable, that's one thing you can do.
If it's not, then it may be a case of just reminding people more frequently.
And there should be multiple ways to withdraw.
So maybe they can tell you, or maybe, like I said, it's a break, and they just kind of disappear.
So you can use incentives.
You may already use incentives.
Probably for most testing, and I've found this with testing, playing the game is often incentive enough for most people.
I ran a study where people were playing games that had already been released, the Walking Dead series from Telltale and also Dragon Age Inquisition.
We asked them to come in for three to six sessions of 90 minutes each, and we didn't have any dropouts, and we didn't offer any compensation.
They just kept showing up because they enjoyed playing the game.
The one thing to think about in terms of ethics is, you know, if you're offering very large incentives, because then it becomes about people just signing up for the money or whatever the swag is that you're offering them.
So deception, you know, I mentioned you should be up front in telling people what it is that you're asking them to do, but, you know, is it ever okay to deceive people?
Is it ever ethical to deceive people?
Yes, it can be.
You know, if, as I said, there are things that you're trying to measure and if you told people exactly what it was, you know, that's obviously gonna, it might change how they react.
But the big thing just to think about is what's the risk involved in the deception?
And does the benefit of the deception outweigh any potential risks?
Okay, so this is where you're in the balancing act of, you know, are you just doing this because you didn't really think it through, or, you know, is there like something really important that you need to get from players, and if you told them ahead of time, you know, it would not work.
Also, another thing to keep in mind is, you know, you've been working with this game, you're close to it, you know it so intently.
People coming in may have no idea, really, like, what it is about.
And so for them, many surprises are going to be magnified.
Probably the majority of the time, the testing that you do under university rules would qualify as minimal risk.
The university speak for defining minimal risk is probability and magnitude of possible harms implied by participation in the study is no greater than those encountered by participants in those aspects of their everyday life that relate to the research.
It's amazing how convoluted universities can make.
You know, simple statements.
So if this is something that people would probably do in their everyday life, then it's minimal risk, right?
So if your game is rated, you are targeting it like E for everyone or T for teen, it's probably something that they would do in their everyday life, and so you would be qualified as minimal risk.
There are a few times when you go beyond minimal risk.
Minimal risk doesn't mean that you have to ignore all of this, but just that, you know, the stakes are a little lower.
If you're beyond it, then you do have to think a little bit more carefully, you know, and you might want to consider some of the resources I suggest at the end.
Beyond minimal risk can happen when suddenly you're involving vulnerable populations, which is how we talk about them.
So children, those people with diminished capacity, so people with, like, cognitive impairments, you know, where consent Maybe something that you have to really think about how they can understand that.
And also indigenous peoples.
So indigenous peoples in Canada have this very bad history of being exploited and abused.
They were tested on by different people just as like a convenient population to see what would happen.
And so now they get extra protection as a result.
I just wanna talk a little bit more about children though, cause that's probably the population you would deal with.
So obviously with kids, it's not just the child, but their parent or their guardian who would need to consent.
But also think about the age range you're including and why.
Because kids aren't necessarily an amorphous group.
A 7, a 10, and a 13-year-old are all going to be really different in terms of what they understand, how they think about the world, how they can communicate back to you, what elements of the game they might think are interesting or exciting or scary.
And so, you know, think carefully about how to, you know, which age ranges you want to include.
And... .
I would say this is a common recommendation for researching with children.
I would say it would apply to anybody.
As the prior experiments have shown, adults are sometimes uncomfortable with saying, no, I feel uncomfortable doing this.
Kids are even more so.
So are there ways that with nonverbals you can...
Figure out like they're not having a good time.
You know, are they closed off?
You know, they started laughing, now they're not.
They're looking down, their body language is closed up.
You know, that can be a way that a kid is signaling they're not comfortable anymore.
I'm not going to talk any more about children, but if you do research or play testing with kids, I would say check out this talk from The Vault.
In 2014, Gareth Griffiths talked about testing Skylanders with kids of different ages, and he's got some really good information about how to do that.
So you've identified who you want to test with and what you want to collect.
Now you want to think about how you're going to store this.
How are you collecting your data?
You know, are you audio, video recording?
Are you going beyond that?
Are you just taking notes?
But how are you storing it?
Is this gonna be secure in any way?
Does every member of the team have access to it?
Which can be fine, but you just need to know how far you want it to get out.
How are you identifying participants?
You know, are you using their names or are you taking off their names and then assigning a pseudonym?
Again, what are you doing with the data?
And also what happens to the data when the study is over, when your play tests are done, when the game is released?
If you're like me and you're a Packwright, you tend to just hang on to everything.
You're like, oh, I don't know when I could possibly need this again, but I might.
But it might be better just to erase it and get rid of it so that you don't worry about it getting out anywhere.
And related to that, how are you gonna identify these people?
There are different levels of control that you can have.
So you could keep people anonymous.
This usually works with online surveys where you don't even know who these people are.
But maybe people come through who never physically identify themselves to you, and you've got this data that you just, is literally unlabeled.
More commonly, you know who these people are, and then you have the choice of saying, you know, we're going to keep this information confidential, like your personal name and, you know, address, or we're going to identify you.
A lot of times people offer them the choice, like, do you want to be identified or not?
Chances are you're not using this outside of your studio, so it's not going to make a difference.
But if you did want to use it, you know, in public-facing materials, this is something like to ask people, are you okay with this?
So VR.
There's a study that came out last year talking about research ethics in VR testing that said, you know, VR poses risks that are novel, that go beyond the risks of traditional psychological experiments in isolated environments, and go beyond risks of existing media technology for the general public.
Even though VR feels pretty new, there have been waves of interest in VR and some researchers have been studying VR for quite a while.
And so there are a few studies that we can draw on to kind of get a sense of how people might react with VR systems.
In 2002, there was a study of the virtual pit.
So they had subjects put on a head-mounted display and stand on a ledge.
They were asked to lean over and drop a bean bag into a pit.
Now in reality, they were standing on a wooden platform that was an inch and a half off the ground and they were told this, like they knew it as they were getting on it.
But still, even though they cognitively knew this was going on, their bodies felt that it was a real situation, that they were really They were actually standing over a pit, and so their heart rate increased, their sweating increased, some of them felt very uncomfortable.
So even as they knew in their brains, this is just a test, this is not real, their bodies reacted like it was real.
Remember the Milgram experiment with the shocks that I told you about.
Somebody redid this experiment in VR in 2006, but what they did was they asked people to administer shocks to a virtual human.
So they had some people who saw the virtual human, some that were just, it was a text communication, but the testers knew that this was a fake person, right?
And so, but they were told, well, we're seeing how, This is how the application of pain applies to learning with virtual humans.
I don't know how that would apply, but this is what they were told.
And interestingly, again, even though they knew that it was fake, they reacted bodily as if this person was real.
So two people, you know, they had to read words, and then the virtual human had to repeat them back, and if they got them wrong, they shocked them.
Two participants emphasized correct answers, you know, like, These are the, you know, they're like reading them out, kind of like hint, hint.
And, you know, asked, when asked about it later, they were, said they were trying to help her.
Eight repeated the question after receiving no response.
So the virtual human's quiet, and they're like, hey, come on, come on, let's go, let's go, even though they knew she was fake.
They showed increasing frustration with wrong answers.
The researchers concluded people behaved in a way that only made sense if they were responding to the virtual character as if she were real.
They said humans respond realistically at a subjective level, so they were like justifying it verbally afterwards.
Physiologically, you know, they could tell their heart rate increased.
They were increasingly uncomfortable.
By the way, they also kept going up with the shocks even though they said that they really felt bad.
They felt bad in doing this to a virtual person.
And behaviorally as well, like their physical body, they could tell that they were uncomfortable doing this.
So they said this could be evidence that, again, we are obedient to authority figures.
Also, it may be a matter of participants being willing to put up with their own discomfort for the sake of honoring their agreement to be a participant in the experiment.
And I just want to underline here, for the sake of honoring their agreement to be a participant in the experiment.
So we already know, you know, like people want to help you, you know, there's other research that they'll, you know, make themselves uncomfortable with VR.
Even again, they felt, you know, fair amounts of distress, and they put aside their own distress because they really wanted to help people.
The question is, you know, are you really getting good data if people are uncomfortable with the experience, if they're not having a good time?
On the positive side of things, Nikki and Jeremy Bailenson have studied what they call the Proteus Effect, putting people in VR and for example, giving them an avatar that's taller than themselves or better looking and asking them to negotiate.
And they find that they're more confident and able to better negotiate.
And that actually this ability carries through after the VR is over.
They don't know how long it lasts after the VR, but it did last after they continued, after they ended the testing.
So what this means is with VR, there's a bit of a tautology.
Like the central, the one thing we say is do no harm to people.
But even though we know a little bit of what's out there, you know, and researchers will say there should be no foreseeable harms with the research that you're doing, we don't know what necessarily the foreseeable harms are with VR.
People are reacting differently than they do with standard research.
And so with VR, it's more about, again, carefully considering, like having a statement to tell people, you know, immersive VR can have lasting behavioral influences.
Some of these risks may presently be unknown.
It's just being honest with people, like we really don't know what might happen.
Like, that's the truth.
Also telling people that they may have powerful emotional responses to game content, whether or not they believe it's real.
It may be one thing to say, oh, I'm used to scary games, but it's another when you are in the scary game and we know that people's bodies react powerfully even when their brain is telling them it's fake, it's fake, it's fake.
Torture in the virtual environment is still torture if you're perceiving it as such.
Also with VR, there's the chance that you're getting a lot more data.
Suddenly it's not just a video recording, but maybe it's eye movements, bodily movements, you know, you're tracking their kinetics over space and time, and so, you know, you need to think about what, it's fine to collect that data, but how are you storing it and how long are you keeping it?
And what might you reasonably erase at the end so that, you know, people keep their privacy.
And also just beyond testing, thinking about doing game development in VR, we don't know the psychological impacts of long-term immersion in VR.
I mean, the games that you see now are fairly short experiences.
Obviously, testing is a pretty short experience.
But you know, like...
It's still an open question in terms of what long-term exposure might be, and also like what is the potential for abusive avatars, you know, that look like their users, not just when a person is in the virtual space with their avatar, but if they have ownership of an avatar, you know, is there the possibility that somebody might be able to take it or copy it and exploit it?
So that's the background.
So now you want to create a protocol for playtesting.
And I'm just going to go through here with a game or two that I've created with some questions based on all of this to kind of guide, like thinking about my thought processes as we went through, and also some additional ones, like for imaginary features that we would add.
So in 2010, I was part of the Gambit Game Lab at MIT.
We had a group making Exa, Isla the Wisekind, which was just a puzzle game that was on Facebook.
And this is what it looked like.
And just so you know, when I put up this screenshot, I realized that at the bottom were, remember the old Facebook games where you had the faces of all of your friends that you were playing with?
And I had all the faces of all the friends I was playing with, and I was like, oh, I didn't ask them if their faces could be up there.
So I have cropped that, that's why the aspect looks a little off.
So yeah, didn't want their faces necessarily associated with it.
So what was I testing for?
So with this game, you know, we did a couple play tests over the course of the summer that we were making the game.
And at first, you know, it was do players understand what to do in the first level?
Because as you saw, it's a puzzle game.
You twist tiles so that your little avatar can make their way through.
You can make puzzles for other players and share them.
And it's timed however long, you know, it takes.
And so you can beat people's times and share other puzzles.
So do they understand what to do?
Do the instructions make sense?
And how long are players taking to get to the end of the level?
Because at first, the first few levels we created for people so that they would kind of learn how to do it.
So with recruitment, we could ask, so who's the player base?
How can I recruit people from that group without exploiting any trust or power relationships?
We were lucky that Gambit had a reputation for doing play tests regularly over the summer.
So we had a good pool of people who were happy to sign up and attend just for the pleasure of playing the games.
In terms of incentives and rewards, there was the playing of the games, and then each team with a game usually had cookies.
Sometimes we would compete with each other for better cookies or chocolate or that kind of thing.
And so we didn't have a relationship we were necessarily exploiting.
And where was I asking them to playtest?
So these were labs with several doors.
It was easy to get in and out of them.
People moved freely.
There was no way to really kind of trap people in a particular space.
How will I handle obtaining consent?
So with Gambit at the time, there was a blanket consent that people would fill out when they came in to test the games.
If I'm doing other testing of other games, then I can have a sheet of paper with all of the information on it to hand out as people start.
That's usually the way that I like to do it rather than verbally explain it because then people can just kind of take their time and think through it.
And how do I ensure testers feel comfortable enough to leave if they really want to quit?
You know, we did have people observing, people playing EXA, but they tried not to be really intrusive.
They were sort of standing back.
But we would tell people a couple times, you know, like, you can leave whenever you want.
There's also in this game, like, once you solve a puzzle, they're fairly quick.
It's not like you're, the game itself makes it difficult to just sort of get up and leave.
Deception, is there anything in the game I want to be a surprise to testers?
There was nothing here that really stood out.
Is there a way to let testers know there's some material that they might be really bothered by?
In this game, no. There's another game that I'm working on on my own, where, as the geek of all geeks, I'm making a game about being a department chair at a university.
And, you know, there are multiple problems that you encounter, and, you know, one of those problems could be dealing with sexual harassment.
You know, and I want players—I don't necessarily want to tell them in advance, like, every single problem that the player character will go through, but I might, you know, say in the consent form, like, As an administrator, you deal with multiple problems.
These could include sexual harassment, student complaints, shrinking budgets, whatever.
You know, let me know if you have any questions about this.
So if somebody came up to me and said, hey, what do you mean by this?
I could tell them, like, here's what the scenario is.
Are you OK with that?
Because really you don't know when people are coming and what their backgrounds are, right?
Like you don't know in their history what kinds of bad experiences they've had or maybe that, you know, their friends and family have had that they've been a party to.
Maybe they just had an incredibly bad day.
You know, why make them feel worse by, you know, springing something on them. But in that way, by sort of generally alluding to a situation, I'm not informing everybody, you know, of what's coming, but the person who might have a problem with it, you know, then can talk with me and I can give them more information. So that's where the, you know, is the surprise really worth it or not.
Now if I were doing a VR version of this, and this is just gathered from playtesters, playtesting groups who are working with VR now, but having a kill switch so that everything quickly turns off so that people, if they're uncomfortable and upset, can get out of the situation, especially with VR because there are so many parts involved.
It's not just as simple as taking your hand off the mouse, right?
Having a protective bubble around people's avatars.
Whether it's because they're playing with other people or even potentially with NPCs.
So remember the virtual human, people felt bad about hurting the virtual human.
So it may be the case that they feel bad about being attacked by an NPC.
And again, protected populations, which I can deal with in the Q&A if you're interested.
So it might be useful if you're doing VR research to find information for people, like if you're dealing with certain issues or certain problems that you know, like sexual harassment or racism or whatever, like to have information available for your testers to know like if you're bothered by this, here are some people that you can talk to.
So other questions I would ask as I was doing my play test.
So how am I recording?
With both games, I wasn't actually recording any gameplay.
I was simply standing behind people, watching them, taking notes.
And then I would also ask people to fill out a brief questionnaire at the very end, asking them about specific elements of the game.
Because of this, there was no identifiable information like linked back to people.
What we would usually do is say like, tester, one who sat in this chair, female.
You know, and maybe ask people for like an age range so that we could, you know, kind of get the data and sort of understand maybe how it broke down.
So I did not share that with anyone. Uh, so I didn't need to worry about that.
Uh, again, we kept the data, we created a Google spreadsheet with it and then at the end of the project got rid of it and yeah, it's gone.
Now if we were doing a multi-play test, you know, there are questions to ask.
So do players, you know, like in terms of what am I testing for suddenly, if you've got players not just by themselves but maybe competing or collaborating with other players, do players understand how they can interact with other players?
Do instructions, do the instructions I'm giving them make sense?
Maybe you're testing out harassment tools and so you're thinking about are they using them, you know, and what kinds of toxicity am I seeing?
Just a note here, based on some research that I found about harassment, a lot of times when you ask people about harassment, and you're saying, have you been harassed, they will say no.
That doesn't mean that they weren't harassed.
Sometimes, especially with teens, they don't see what I would see as harassment as harassment, they would term it drama.
So if I say, have you been harassed, they're going to say no, but it doesn't mean that there weren't problematic behaviors.
So it could be the case that you just ask generally, are there interactions that bothered you?
You know, were there negative things that happened?
You can also ask, you know, as a way to kind of offload, did you notice negative comments about others in the game, which is usually an easier way to get at it, right?
Because people are usually much more willing to say, oh, I noticed this directed at so and so, rather than like I was harassed.
They don't want to be that person.
So putting it all together, if you want to do a consent form, this is just some language that would distill it down.
And there's slide after slide.
I'm just going to read them through quickly.
So I understand I've been asked to participate in playtesting of X Isle of the Wise Kind by Mia Consolvo.
And these are the kinds of consent forms that I would have to give to the university to show.
I have been informed that the purpose of the playtesting is to determine whatever it is that I'm testing for at the time.
I understand I am being asked to play a game that isn't finished for about 30 minutes.
I understand that the computer is video recording my gameplay.
I am being observed by someone while I play who is taking written notes.
Obviously at the time we weren't doing that, but that's something else that you would add.
I understand that I am free to withdraw my consent and discontinue my participation at any time without negative consequences.
Going to risk, there might be certain risks.
These risks include feeling frustration or anger while playing or hearing other players saying negative things during gameplay, which might upset me.
This would depend on, you know, Which way you're going with the data, but I understand that my participation in the study is.
And you can also offer people here the choice, so they could circle the one that they want it to be.
You know, confidential, the researcher will know but will not disclose, or non-confidential, my identity will be revealed in study results.
So sometimes you can say, pick the one that you're comfortable with.
And then, I've carefully studied the above and understand this agreement, I freely consent and voluntarily agree to participate in this study.
Some additional resources for U.S.-based developers, the guidelines, the Belmont report, and some other training modules are at these URLs.
And then for Canadian-based developers, there's another website.
And for European-based developers, there's a third website.
European researchers usually have slightly different guidelines to think about.
There are stronger protections for privacy with people working in a European context.
There's also slightly different guidelines in terms of, they may not, universities may not always make such a heavy hand in terms of like, Asking about these matters, they may just rely more on researchers who are doing their own work.
But depending on which context you're in, it can be useful to see kind of what the standards are.
And then again, if you're interested in VR-based testing, this is what I was drawing a lot of the material from this study from last year.
Real virtuality, a code of ethical conduct, recommendations for good scientific practice and the consumers of VR technology.
It's an open source site, so you can read the whole article.
And it's also got lots of good links to other research, other player-based research using VR that goes back 10, 15 years or more.
And that's it. We have plenty of time for questions so we have a mic here if you would like to come up and ask. Thank you.
Hi there. My name is James. So I have a question regarding recruiting for, recruiting the testers and when does it go from targeting a type of tester to almost like discrimination. Do you have to worry about, for example, like sometimes I just want beginner players, right, so you can target that. But then let's say I want disabled players. Is that more, or sometimes let's say female players.
When do you start getting into discrimination?
Well what is the goal of your targeting, I guess?
Why are you targeting particular...
Maybe for disabled players is to test certain accessibility features, let's say.
Right.
Okay, in that case, like when we were at Gamba we had a game that was made for visually impaired people.
And so that was what they did.
They were looking specifically for blind people.
So it's looking for your primary demographic at that point.
So it's acceptable to do that.
The question would just be not who you're including, but if you're excluding people from your study, why are you excluding them?
And it may be perfectly acceptable to say, I'm just interested in this one segment right now, but to understand why you're doing that.
So like newbies, maybe that's really important to say, I really need to understand how people who are new to games or this particular genre understand it.
Because experienced players, they're going to go through it too fast.
That's not the goal of your research.
So yeah, that's perfectly fine.
All right, thank you.
So in the context of games that are taking high amount of risk to physically or more so psychologically affect a player's mental capability, is there additional legal obligations that you should look into, like following up with a therapist afterwards, things like that, in the context if there is a psychological breakdown during the testing?
That's a good question.
Especially if you're dealing with the protected populations.
So, like, yes. Like I mentioned, you know, kids are one. Also, like, I've had a couple of conversations with people at the conference here about pregnant women with VR because of problems with, like, motion sickness. Like, that can be problematic so that the large studios will regularly ask women, like, are you pregnant or you think you're pregnant because you shouldn't, you know, we don't want to test with you if you're pregnant while playing because there could be an implication.
Without knowing the details, it's hard to say for sure. One thing that's possible is to consult with somebody if you have like a university nearby, like with a psychology department or there's always an ethics board at the university to say like, hey, is this something that we should think about? And if you give them the details, they'd be more able to say with certainty.
No other questions?
Okay. Thank you all for coming.
Have a good night.
