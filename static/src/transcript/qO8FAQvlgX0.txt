Because I don't have... Oh.
Is it ready to go?
All right. Hi.
Uh, thanks for sticking by to the end.
So my name is Manny Koh.
I work for Activision in the Essential Technology Group.
So today, um, this topic I'm gonna talk about is how to generate random number in a parallel program, like multi-threaded program or on the GPU.
So I'm gonna start with a very, uh, quick...
overview of some of the more standard serial or random number generator methods, just to give it some context and so that we can, before we can go to the really the heart of what I want to talk about, which is to generate parallel random numbers.
Maybe it didn't sound like it's a topic that's even worth talking about, because you say, what's the problem?
Just start a bunch of threads and...
give each of them a separate seat and just call it a day.
We can try that, but maybe your application will be okay with it, but there will be some application that might not be okay.
And I will show you, I won't be able to show you the application, but I will show you some picture when a bad random, parallel random number generator is used, some of the interesting picture that you're going to get.
Some of the, and the parallel random number generator will introduce funny terms like leapfrogging and splitting.
But it's just a, yeah.
The concept is actually very simple, but one of the main takeaway, I hope, is to introduce a very simple type of, uh...
random number generation that's based on a cryptographic hash that's very simple to implement, that literally can be implemented in five lines of code and has good properties, and is very, very parallel-friendly.
So, um...
what we would like a random number generator to have is that if you want the world, is that we should be really...
like have no correlation, no discernible pattern.
The number two desirable is actually very hard to achieve.
It's that we would like the program result to be the same, no matter how many threads or core you actually are running.
Because, well, first is to just to make your, you have to run some simulation, like a terrain or poly noise.
You don't want your different customer to get different kind of results.
It would be weird, right?
But also for your own sanity.
if your artist and you have a different number of cores, you get different results.
It's not so good.
So even just achieving that is not that easy already.
And of course, we want it to be fast, easy to write, and doesn't take any storage, and whatever.
But we would like all of them.
And we couldn't give up on any one of them.
But hopefully, I'll show some range of options.
Typically, people in doing scientific computing, They evaluate random numbers a lot more than we do.
But we don't need to work as hard as they do, but it's good to know how they measure goodness so that when you're making your own, at least run some of the tests to make sure it's not completely messed up.
So I'm not going to talk a lot about it, but just to tell you, introduce that these are the usual tests.
And even Knuth Volume 2 is still kind of old, but it's still a very good reference to talk about the semi-numerical algorithms.
It's sort of where I got started on this problem.
And so one of the ways to evaluate is to look at the power spectrum, but since not all of us have done...
Fourier theory and all that stuff.
So I just want to briefly mention that you can just use MATLAB or some off-the-shelf thing, computer power spectrum, or your random number.
And it should look like the right two slides, if you look at the mean and variance of your random number.
Basically, what you're looking for is that you don't want any particular orientation.
or any particular frequency to be more dominant than others.
So you want a very flat mean and relatively, you know, small standard deviation across different frequency bands.
Not easy to achieve, actually, but...
The most commonly used random number generator is used in linear congruent method.
It's just a fancy term.
If you look at the actual code or math, it's actually very simple.
It's just a magic constant, A, times your seed, and then you add another magic constant, and then you do modular.
Now, most runtime libraries cheat, and some of them don't include C, or they pick bad ones.
And the one most common cheat, it happens on the M, because M, modular M, is a divide.
And you know, you know device is expensive.
So a lot of time, we're seeing people use a modulo, like a mask, by using masking, which is power two, which kind of works, except we'll show that that actually can be really, really bad.
So just make sure you remember, try to avoid using M to be power two.
We all would try.
Hopefully, I'll offer some alternative.
And if you really must use a linear congruo, then one of the old papers called Park and Miller gave you some recipe of...
I forgot to include C, but...
if you just Google Park and Miller, you will see what a couple of good choices are.
And the one interesting thing for me personally is that that M looks kind of...
I don't know if anyone recognizes what that M is, but it happens to be 2 to the power 31 minus 1.
And that is a prime.
You don't expect a number like that to be a prime, and yet it is.
And you want it to be a prime for your modulo for the reason that you get the maximum period out of your random number.
Because that means that your A and C and your C are not going to be divisible easily by your modulo number.
But that's all for now.
Usually, your C runtime use some variant of this.
But usually use, I would call it, a slightly worse version of this.
Just don't use it. Always use your own. That would be my advice.
Um, that's another common class of, uh, random number generator is called— Oh, sorry.
Um, linear congruent is that it's simple. I mean, it's very easy to write.
And you only have a single word of state.
You need to just store the—the current, uh, uh, the last, uh, random number.
But the problem is that the period of the random number is relatively short.
Even if you use all the perfect magic numbers, at most your period is equal to M. And if you use the cheap M, the lower bits will be highly correlated.
So this is the most extreme version.
Of course, you don't do that.
But you can see how bad it is.
It's 1717.
But this is a sidebar.
But for a Mersenneau prime, which is 2 to the power of 31, which is a prime that is one off from a power of 2, that's actually a more efficient way to compute modulo by a Mersenneau prime.
It's that two lines of code.
It's probably not well known, but it can come in handy.
but I'm not going to dwell on that too much.
So the second major class of random number is called a lacted Fibonacci.
It's related to some Fibonacci sequence, but exactly how it, I don't even know.
But I'm sure it is.
But what you need to do is, the key is to concentrate on the P and the Q.
You're basically looking back at either you're multiplying or combining using modular or two previous random numbers that you have emitted yourself.
So basically, you store, you know, you have a circular buffer, and you store away, uh, you store the previous, uh, the larger of the P and Q, and then you reach back by having like a two sliding cursor, and you, uh, do, but the math is very simple.
That's the beauty of that, of like the Fibonacci generator.
Uh, it's, uh, it's, it's like a single operation, and...
The beauty of that is that you can actually use power to module and still retain reasonably okay quality.
So if you use the multiply operator to combine the star up here, it's not a set multiply.
It can be, sorry, I should use a different symbol.
It can be minus, it can be a multiply, and it can be an XOR.
So I, I, there's some error in the slide, so I apologize for that.
But the most interesting ones are usually relies on either addition or multiplication.
So those are the, the ALFG is additive lactate Fibonacci.
So that's the, that's the equation.
So it uses the, a add to combine the, the previ, the P, lactate P and Q.
And modulo by power two.
but multiply will give you better quality.
So the period of an electric Fibonacci generator is much, much bigger than a linear congrual.
It's just roughly, linear congrual was roughly 2 to the power m.
So think of that, this is like a 2 to the power of p, which can be like 18, for example, to another 2 to the power, you know, let's say it's 12.
So it's a very big, the period is just a lot longer.
So it's power tool mod, relatively efficient, much longer period, and you can work directly in floats.
Leaning congrual, usually you have to work in integer and then convert it to float.
And that's not very modern pipeline friendly, because they kind of store the floating point pipe, and so on and so forth.
And it's higher quality.
And later on, we would see that the edited version of the letter Fibonacci can actually skip ahead.
So this is sort of like, right now, we don't know why we need to skip ahead, but for now, just keep that in mind.
So the bad thing of letter Fibonacci generator is that we have to store state.
And then it's also purely sequential.
So, meaning that until you generate the previous P or Q number, you cannot generate the next number.
And the multiplicative version of that, you cannot jump ahead.
For people in scientific computing, or even in high quality rendering, like offline rendering, the gold standard is called the Mersenne or Triste.
If you look at the spectrum, it's very nice.
This is what you want to see.
It's like white noise. No pattern.
But if you look at the code that implements it, you won't like it.
It has a huge table and also has to store a lot of state.
But it's very high quality.
So if you want...
So what I do in my ray tracer is that I always have this around so that...
and I have a virtual, like, I random, I could just switch to MT.
If I have some weird bug, I would just say, oh, I'm gonna try MT.
And if that bug goes away, I will look at my random number generator.
But, so it is sort of like the gold standard, but, you know, well, if you look at the code, it's lots of flops and it's hard, but not impossible to leapfrog.
It requires some fancy matrix factorization, which I don't even want to get into.
Very limited parallelism.
So it's very high quality, but even in offline rendering, people try to not use MT when they can get away with it.
So this is the basic overview of serial code.
So again, why do we want to generate random numbers in parallel?
Well, modern computers, as you know, we hit the limit on what a single computer can do, as well as on the GPU.
So for a parallel random number generator, we want to maintain the original serial random number generators' quality using those set of tests, for example.
And the number two is that we want the same simulation result regardless of the number of cores.
And we would like to have minimum state or no state, if possible.
And we want the different streams to have minimum correlation with each other.
So one of the pretty old techniques from scientific computing to construct a parallel random number generator out of a serial one is to use two linear congruent generators and with just a different A, the multiplier, they use the multiplier in the seeds.
And, uh...
What this picture is showing is that you use your first generator L to generate a bunch of initial states for, and think of that each of them will run into its own thread or process, and then the R generator would take that, take over, and then the good thing of this approach is that you don't need to know how many generators you need, for example.
you might have to make some runtime decision that you make some computation before you decide whether you need to...
need another set of general numbers.
And if that's the case, you can always spawn more...
you can spawn a new instance of the R.
Oops. Oops.
Sorry.
I touched the...
You can always spawn another instance of R using another iteration of L.
So there are specializations of the random tree.
One is called leapfrogging.
So leapfrogging is the interest, important to concentrate on this picture.
Like each of this is, imagine it's running its own thread.
But if you look at it in the time in adjacent horizontally, the three threads, if you put them together, these three numbers would have been generated by what would have been the original single threaded code.
So you get nice reproducible results out of that.
And with leapfrogging, you need to know the number of cores.
So that's a limitation.
So that means you have to fix your number of cores ahead of time.
So let's say you want to support a maximum of eight cores.
If you have four cores, you start A through S.
Then this algorithm would work.
And this is just to show the actual initialization conditions for the...
So if you look at the first line, it really just is a linear congruent generator.
A times the previous...
Here I say L, but before it was X.
K, which is the previous one, and then I actually dropped the C here just to simplify things.
And then the key is look at the R.
R is the disk part.
It's A to the power N, which is the number of separate sequence or core you need.
So if you use this particular combination, the, the, the, the, the, each R's individual subsequence when contained together would have been the same as the original serial code.
So it's sort of elegant.
But the problem is that you need to know how many cores or degree of parallelism up front.
Which, you know, sometimes we have, we couldn't, we might have to live with that, but.
So this is just to reiterate what the, what, yeah, visually, what you're getting, yeah.
The final sequence is the same as the serial code.
And each sequence does not overlap.
So, this is the good of the serial code.
But you get the same sequence, but the choice of your random number generator is limited.
So let's say we mentioned that the multiplicative linear vector Fibonacci has very high quality and long period, but there's no way to express it in the leapfrog form.
The bad thing is that the A to the power P, or A to the power N, sorry, I changed notation, doesn't have the same original qualities of the, as if you generate it all using A.
All the subsequence concatenate together would produce original simulation, but what's your, but equally important is that each threads, random number, should have good qualities.
And so if you're skipping ahead, the quality of a fixed sample of the original sequence, you're losing the original.
Think of it that you're doing another modulo using a small power tool, because unless you are the old PS3 in which you have seven or six cores, but almost everywhere else you get power tool.
because someone took away one core or Xbox 3, Xbox, yeah, right.
But the Power 2 is going to stare you in the face unless you artificially take away one or add one virtual one.
But so it's not without its problems, but the biggest one for me is this last one.
linear congruent generated period is already not very long, 2 to the power of 31 at the best, and you shorten it by a factor of n. So very quickly, with modern computer, with GPU, you're going to chew through your random number in no time at all.
Just think about that. That's not very much random numbers.
And if I'm running with one teraflops on my GPU, I can just chill through it very quickly.
So another thing is just called sequence splitting.
This doesn't solve the period problem, but the quality of each subsequence is actually better, because you are getting the same sequence for each thread.
The problem is that the Same thing, your period will get shorter.
And this one, we need to know this other thing.
We need to know the number of values to know where to split.
So if you know up front, you only need three numbers per thread, you can skip ahead three.
Or if you know you need 512, you can skip ahead 512.
But we don't always know that.
So it's a technique that can.
And to actually program it, if you use linear and congrual, it's relatively easy.
You just kind of flip the, you just move the, it's just basically reversing the row, using the A to the power N on the L, which is on the right.
So it's very easy to code.
So both leapfrogging and sequence splitting, it only guarantee that they don't overlap, but it doesn't talk about, the quality is actually.
usually you compromise on the quality.
And both of them are not invariant to the degree of parallelism.
And I don't know about you guys, but for me, if the serial code and the parallel code don't produce the same result, and different run of the parallel code don't produce the same result, it's usually a very bad day.
So, lactate Fibonacci, live-frogging is actually possible, except not So that's why I introduced the electric Fibonacci is that, because it has much longer period, the M can be power two, and as long as you use the addition operator.
But still, The problem is that we have to store a lot of states for vector Fibonacci, right?
Basically, you have to store the larger of the P and the Q.
And it's not very GPU friendly when you have to store that much state.
So, but for running the simulation on the CPU side, it is an option.
So, I'm mostly going to focus the rest of the talk on using a completely different way to attack the problem.
It's that we look at the—we try to look at random number generation as a cryptographic hashing problem.
Um, one of the most commonly used one is MD5, but it's very expensive to compute.
Okay.
And so I'm going to introduce a really, really simple one.
It's called TEA.
And TEA is short for Tiny Encryption Algorithm.
It's literally tiny, five lines of code.
So the core idea of this is that you feed some kind of linear, bland RAM to each thread.
So just some kind of linear, so it could be a thread ID or whatever.
and it could be just your some other vertex.
You can encode it in your vertex data, and you take each of those, you take the linear ramp and you run it through your cryptographic hash.
And so that means all, there's no dependency on each other and there's no dependency on previous state.
The only dependency is input and then you will produce an output.
So it's completely deterministic.
And the quality of that is not too bad.
It's actually almost like MT, medicine neutral.
It's pretty decent.
So the TEA uses a network that is almost the standard building block in almost all modern cryptographic algorithms.
It's called a Feistel Coder.
The key, the interesting structure of that is that it's very elegant, actually.
It's... Oops.
Uh... Oh. Sorry. Just keep on...
Oh.
Um...
It's... The input is split into two halves.
L... into L0, the left and right halves.
And then the key, there's a key, 128-bit key that is split into four chunks, like 32-bit chunks.
And then you feed the left and the right and the key into this magic thing called the F, which is the Feistel shifter or the encoder.
And then you feed the output back together with the, the input again and you mix it again.
So you're basically just mixing bits.
But the way it's mixing it is they're mixing in a very careful way.
And also, it uses the two halves of the input to affect each other to speed up how fast what is called the avalanche effect has been achieved.
The avalanche effect is that a single bit change.
would propagate and affect all the rest of the bit of the word.
And that allows you to hide where your bit change has occurred.
And that's really what the cryptographic hashes try to do.
So, now I'm...
But I'm not trying to...
But this is not trying to do cryptography, but the same characteristic of the fact that you can achieve avalanche quickly allows us to produce a cheap random number generation.
Thanks.
So, this is the program.
So, uh, the, the, the, this is the 128-bit key.
Just use it. No.
And then, uh, and then there's a delta.
You just keep adding it each every round.
This is the Feistel shifter, which is corresponding to the...
the L and the, and the, uh, the L and the R.
So, and then, uh, the key is to control number of rounds.
Uh, for-for the theory, you say that your minimum needs eight rounds, or in six rounds, it would be able to mix all the input.
And you-with eight rounds, you get okay.
But 16 rounds, you get very good results.
So that's just a takeaway.
You can experiment with it yourself.
Don't-but don't try anything less than four.
The-the comment is that delta has happened to be the golden ratio, but, you know, uh, it's just- just a bit of, uh, trivia.
And this is some of the applications that you can use.
Continuous terrain to drive so that you have an infinite world, or you can use it to drive some kind of texture synthesis, or Perlin noise.
But also, any kind.
But actually, screen space sampling, area light source, all can use this algorithm.
One good package to use, at least as a reference, is to look at this, try to download this package.
And if you're going to do your own, at least run, compare your result with this, Mance.
It's very good.
And this is a reference.
And the takeaway, I hope, is that look beyond linear congruent generator.
additive lactate Fibonacci is worth a look except for the state, but I would say try to use TEA and it might be might be useful. Yeah, thanks.
No questions? Oh, please.
like the CUDA engine right now for libraries?
Do you want that?
Uh, the CUDA one.
Actually, I don't know how the CUDA library works.
So CUDA just provides a file of communication of common algorithms.
Like, I believe there is the same cluster of algorithms if you do use CUDA.
Yeah.
And there's four approaches.
There's CUDA-GPU-RAM-NMR, which has properties that probably don't talk about here, but it does a file of a CPU and pushes data back to the GPU.
That is always... you're computing on the GPU...
wait, computing on the CPU and push on the GPU?
-... ... ... ... ... ... ... ... ... ... ... ...
Each of that is a, first of all, if you have any adaptive algorithm, the GPU will have to now inform the CPU code how much random number I need, and then if you have even more fancy algorithm that, like even the example that motivated the CUDA talk about why you need dynamic kernel invocation.
If you have any kind of adaptive simulation in which some locally you want to do very fine, high quality and fine meshing for your let's say fluid and other part you want coarse, that means some of the grid will need only a few numbers, some of the grid will need like a lot and that would be very hard to for a CPU, GPU to share that load.
So I would say that would be a secondary...
That will only be good if you have existing hyper-scientific computing application that you have to produce exactly the same bits as...
Otherwise, you couldn't pass your government certification test.
Then you probably have to use that approach.
Otherwise, I wouldn't... I probably wouldn't use it that way.
Yeah, sure.
Thanks.
