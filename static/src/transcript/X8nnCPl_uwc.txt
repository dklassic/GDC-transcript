Thank you for coming.
Today, I'd like to talk about the system we developed to support game balancing using AI.
I'm Kazuko.
I'm working at Square Enix Japan.
I worked as a programmer on the development of some console games before.
Currently, I'm an AI engineer, and my work is about quality assurance, especially in the area of game balance using AI.
I'll cover all of this presentation today.
But before it, please let me introduce a member of our team, Shigeru Awaji.
He is in charge of data visualization and data analysis in this project.
Our project would never have succeeded without him.
Shigeru, can you introduce yourself?
Hello, I'm Shigeru Awaji, an online backend engineer In my previous career, I designed and created general Windows desktop applications and databases, and I made a career change to the game industry.
By using that knowledge, especially in the last three years, I have done data analysis work with over 20 projects.
Using AI and simulation results, we created a tool to visualize the characters' behaviors.
There will be time for Q&A at the end of this presentation.
So Shigeru and I will try to answer them as best as we can.
OK, let's start.
This is the outline of the presentation.
First, I briefly introduce the game targeted for the research.
Next, I explain how we use AI to balance the game with the different successes and failures we had.
This is a main topic in this presentation, so I will give a detailed explanation of the AI algorithm and the results.
After that, I'll show how to configure the system.
Finally, I talk about the future plan of our research.
Our research was about finding a method to balance the gain, grains, nodes, repage.
It's an action battle game for smartphones.
And the main game loop is the following one.
At first, prepare the party before the battle.
Choose the characters and their equipment.
Then the battles.
It's automated, so the player cannot do anything.
And the post-battle.
The player receives rewards based on the result, which allows him to become stronger.
Then repeat.
Party consists of four main chapters.
Each chapter is supported by two heroes, and only the heroes will participate in the battles.
There are a few hundreds of heroes.
Each hero can have some equipment, such as weapons and accessories.
For example, there are about 100 kinds of weapons, and each weapon can utilize up to five enhanced items out of 65 available choices.
The hero's behavior in battle depends on its hero AI equipment.
Each hero AI contains a predetermined rule set of actions which can be customized by the player.
It evaluates conditions from the top until any condition is matched and execute its associated action.
Though the system is simple, there are a few dozens of conditions and actions.
And their actual behaviors change depending on heroes' properties.
As a result, it's difficult to find the best hero AIs for each hero.
But it's a high potential feature, as it allows the character to beat stronger characters.
Until now, I explained how to configure a hero.
Eventually, Apati is built by eight heroes like this figure.
So I think you start to understand why balancing grains nodes is a nightmare.
But just in case, let's see a number of possible combinations for Apati to give us a better idea.
We have eight main characters.
80 heroes, 60 weapons, 3 costumes, etc.
And the number of possible combinations is 10 for 182.
A real lie to me.
You see?
Furthermore, the game is actually updated every one or two weeks with new characters, weapons, and so on.
And we need to find the balance breakers before each update.
Impossible, right?
In the situation that the amount of data continues to increase over time, it's very difficult to adjust game balance by hand.
Our idea for the problem is, let's try to make the strongest party.
If there are elements that break the balance of the game, the strongest party must have these elements.
It's a really simple idea.
This methodology of search is called optimization-based falsification.
It uses global optimization methods to guide the test toward a possibly small region in the input space that leads to incorrect system behavior.
In our case, a game balance breaker.
I'll explain an algorithm to find the best combination of characters and equipment.
First, I'll show the result a little.
The left party is created by our team, and the right party is the opponent.
The upper bars show each health point.
A party that has more health points is the winner.
Okaji Party, hajimeru yo!
She is the strongest hero in our party.
She is equipped with a weapon that heals her every time she kills an enemy.
And due to her hero AI settings, she uses it frequently in her ultimate skill.
It repositions her far from the enemy, so it's hard to get damaged.
Every time she uses her ultimate skill, she consumes two points.
In the video, as soon as there are two points available, the hero detects it and directly uses its ultimate.
We never told our method the effect of the ultimate skills or the meaning of the hero AI conditions and actions.
Nevertheless, the method was able to optimize the play of this hero by only observing the battle results.
To create parties, we use genetic algorithm, which will be referred to as GA in this presentation.
GA is a method for combinational optimization based on biological evolution.
GA simulates evolution of individuals in an environment.
The evolution proceeds by crossover of individuals between each other.
In this process, the better individuals will have a higher probability of being chosen as parents.
Individuals born from good parents tend to be good too.
In the result, after some generations, all individuals get better in general.
This is a general explanation for GA.
So let's confirm the correspondence with Grimm's modes.
The environment is a problem we want to solve.
So it is a battle in our case.
An individual is a candidate to solve the problem.
It's a party.
Each individual has a fitness value, which is a score that represents the degree of adaptation against the environment.
As the environment is the battle, the fitness is the battle result.
There are many other terms in GA, but these are enough for today.
As a side note, we chose GA not because it's the best algorithm to find the balance breakers.
There are three reasons.
First, a GA is a simple algorithm.
It's easy to understand and implement.
Second, GA has a long history.
We can find many understandable explanations on different media.
This helps us to save our time to study and implement GA.
Third, we can get the suboptimal solution in limited time.
In game development, the structure often changes suddenly, right?
So GA outputs an optimal solution at the time.
In conclusion, we use GA because it's suitable for product development.
Now, let's see the process of GA.
After the initialization, we evaluate the parties, we select the best parties, we crossbreed them, and mutate a few of them.
This process is done for each generation.
And after specified conditions have been reached, or a specified time has elapsed, the algorithm stops.
From here, I'll explain them step by step.
Step one, initialization.
The initialization is a simple part.
GA choose characters and equipment randomly and create parties using them.
These randomly created individuals will be the individuals of our first generation.
Step two, evaluation of the parties.
In this step, the algorithm will evaluate each party on how good they are against the environment, which is, in this case, the bottles.
So the fitness of each party will be computed based on the result of their battles.
In Grimm's notes, there are different types of battles.
We focused on two types of them, PvE and PvP.
In PvE, the players fight against predetermined parties from the game.
On the other hand, in PvP, the prerogatives are fine-tuned by other players.
In both cases, the battles are automated.
I summarize the differences between PvE and PvP.
These differences look very small, but they affect the evaluation methods.
Players fight in PVE to get many materials.
No amount of materials could satisfy the players.
There is no constraint of number of challenges, and no defeat penalty.
Consequently, it's very important to win quickly.
So, we use these axes for evaluation.
In case of victory, we are going to use the battle time.
In case of defeat, the time is not a good expression of how good was the party.
We use instead the damage dealt by the party.
As you can see, these evaluation policies are very specialized for the game.
Next, for PvP.
The players aim to get more arena points.
I won't explain what exactly arena points are, but the important point is that they can be won or lost depending on the result of the battle.
And because the number of battles is limited, the player will want to make the most out of them.
These facts indicate that the important point for PVP is high and stable winning percentage.
But the player cannot choose the opponent.
To measure the winning percentage, we let the generated party to fight against some of the top players from the online leaderboard.
We use the average of the result as evaluation values.
These top players have different fighting styles.
As a result, we can assess the ability of the generated party to win any PVP match.
So this is the final version of evolution policy in PVP.
For both victory and defeat, we use the difference of remaining life points.
In the case of close matches, there's little difference in score between victory or defeat.
Therefore, we add a fixed amount of bonus points to see a bigger difference between victory and defeat.
This policy is also very specialized for the game.
The evaluation equation is very important and sensitive for not only GA, but also other learning methods.
It takes a little time to design a good evaluation equation.
We need to think about what is the essence of the game.
we decide not to generalize, but to specialize the equation to our game to get more accurate evaluation value.
In case of PVE, the victory and defeat evaluation functions are based on two different units, the time, in case of victory, and the damage dealt, in case of defeat.
GA needs to compare evaluation values, but it's difficult to compare the values if their units are different.
Therefore, we mapped this value to one axis.
For PVP, we handle the evaluation value in the same way.
Now, let's advance to step three in GA.
Select the best parties.
After evaluation process, GA choose parties to be inherited to the next generation.
As evaluation value are on one dimension now, we can know easily which parties are better.
We decided that we keep top 80% parties for the next generation and dispose the others.
This policy keeps the diversity in parties and avoids falling to a local optimum.
Step four, cross-breed the selected parties.
We represent a party composition as tree structure.
It selects one point to cut in each tree randomly and swap the crepe subtree.
like this figure.
This is the Wiener method, one-point crossover.
Step five, mutate a part of the parties.
We expect the crossover improves the parties entirely, but it's a probabilistic method.
Sometimes good elements can disappear.
Also, in the parties randomly generated in the first generation, there might be no overpowered elements.
Our mutation method compensates these disadvantages.
The mutation occurs with a 5% probability.
In the mutation.
After selecting a point to cut randomly, it replaces the subtree with a new randomly generated subtree.
As this is also a random operation, in most of the case, mutated parts get worse.
However, rarely very good elements appear, and they are inherited to subsequent generation.
I guess you feel a bit afraid of the mutation work.
That depends on luck.
That's why I was afraid of the same thing, too.
As an experiment, we ran GA repeatedly in the same settings except random seed.
There was a hero that always appeared in the final generations.
But sometimes that hero was not in the initial generations.
This experiment proved that this mutation works well and is an important process for the coverage of the elements.
Until now, I explained the evaluation of the parties, the selection of the best parties, their crossover, and their mutations.
By repeating it many times, GA improves the parties gradually.
This is a more simplified figure of the overview.
Our system repeats the battle, evaluation, and improvement steps.
As evaluation and improvement are located outside of the game, We need a communication pipeline with the game.
We use an API to communicate with the game because we delegate the development of the game to an external company.
Therefore, using the API is a suitable method for us.
But if all members are in the same development team, it might be OK to communicate directly in the course.
Before and after the improvement step, there is a conversion process.
This looks redundant work, but it allows the improvement steps to be independent from the game and so that it can be applied to any games.
In short, the battle part is almost the same as actual game.
Improvement process by GHMB-SHIELD.
If we customize the communication pipeline, the evaluation, the gene conversion process, we can apply this method to other genes.
Actually, the evaluation and the conversion are small functions, so most of the required customization work is in the communication pipeline.
This is one of the results we got for PVE.
A point shows a party.
Blue means victory, and green means defeat.
The evolution proceeds from left to right, and the vertical axis shows the battle time.
At the beginning of the evolution, all parties lost their battles.
After the first winning party appeared, the number of winning parties increases generation after generation, and the battle time decreases.
PvE battles tend to be easy to win, so this party evolved without any trouble.
This is a result for PvP.
Please note that the vertical axis changed from battle time to fitness value.
So the higher the fitness value, the better the party.
The fitness score improved continuously too.
On the other hand, there is some sudden growth sometimes.
It's more difficult to win PvP battles than PvE battles.
So this sudden growth happened when the generated parties solved one of the reasons they were losing the battles before.
This is the best party in this evolution.
However, because the fitness value is computed based on the result of 15 battles, there is a certain measure of error.
To confirm the party's strength, we made it fight in 300 battles.
The upper number is the winning rate against parties that were used for the evolution.
The lower number is winning rate against the other parties.
Both of them shows high win percentage, and they're almost the same.
This result indicates the best party can win against the various parties as planned.
This is a video of a battle where the best party created by G.E.L. fight against the opponent.
The game version is different from the video I showed just a while ago.
So the party composition was changed because new characters and pieces of equipment have been added.
Please watch the strongest party.
I guess some of you have never played this game before, so you may not understand what is happening on the screen.
But it's the same for me.
Although we can understand just a little, we cannot follow all of the actions by the 8 heroes action.
And to share this presentation, I explain the detail of the GA algorithm.
GA showed as a strong parties.
However, it's too complex to understand.
Video of battles are also very hard to understand.
We need a better way to visualize this information.
From now, I'll introduce our visualization method to find the valuable information from enormous amount of data.
Every time that analysis progresses, every time the game is updated, what you want to check and what you want to know will change.
Therefore, the visualization is required to be startable at low cost, easy to be customized.
We are using open source Apache Debian.
Various languages and data sources are available for this tool.
We can add and change the display such as table and graph any time we want.
Apache Spark that runs in the background has scalability that can adapt its memory and CPU usage to the available CPU and memory with clusters.
We recommend it as it's convenient to can be used immediately for free.
In this table, we can see the result of 15 matches executed by one party.
Each match results are compressed and displayed in a row.
Specifically, it shows the settings of AI, the type of weapon equipped, and the special activity that occurred in the battle.
The column shows the fitness, so the table also serves as a ranking of grade.
Each row follows this structure.
The first part displays a summary of the battle result.
It is then followed by more detailed information about each chapter, but I omit it partially in this figure.
Let's see the methods to make information easier to see.
They are dimensionality reduction and abstraction.
First, dimensionality reduction.
Finding the best party is very useful for designers.
Sometimes you want to check how strong is a party with a setting composition, or you want to find similar parties to the best ones.
Until now, the only way to find similar parties was to take a look at the party composition tables and find similar parties from here.
This table is one of them.
This table only shows the list of weapons used per party.
Each row corresponds to a party, and each column to the number of times a specific type of weapon is equipped in the party.
And as you can see, it is already very difficult to find similar parties.
We needed a better way to visualize this kind of information.
In this case, we used the dimension reduction method called principal component analysis for plotting multidimensional data.
With this method, we reduced the dimensionality of our previous table into only two dimensions without losing the feature that data had.
By performing this conversion, it is now possible to plot 20-dimensional data into a two-dimensional xy-coordinate system, which is easier to understand intuitively.
In this case, the graph shows the similarities between the parties.
For instance, if we want to find parties similar to one to the parties at the top.
The green parties located at the top are all very similar to each other.
Each number correspond to party ID.
On the other hand, if we want to find a party that is largely different from a green party, the parties located at the opposite, in this case, at the bottom left, will be great candidates.
It takes a little time to use this method because it requires some data preparation.
But important point is that this method can help you solve this kind of problem effectively.
Next, this is an example using abstraction.
The content of the frame.
is status, such as the number of ultimate points, attack power, etc.
For example, if a hero has 74,000 health points, is it high? Is it low?
This exact number has no meaning. What is important is to know how high or low it is relative to the other.
Here, we explain relative evaluation using standard deviation.
Standard deviation is a measure that is used to quantify the amount of variation of a set of data values.
The average is also a well-known measure to show how relative is a value to the other values.
But it would be affected too much by a few outliers to express the data properly alone.
Standard deviation helps ranking in accordance with distribution of the data.
In this slide, C and D are volumes, and HP 74000s belong to the rank D, which is a little lower than the average value.
Standard deviation replaces the two detailed numbers with expression that can be understood at a glance.
What I'll show you next is a change of granularity.
The part highlighted in the figure is the settings of the Hero AI, which are compressed into single letters.
What was the Hero AI?
As explained earlier in this presentation, Hero AI is a rule set that decides heroes' behavior in the automated battle.
There are many kinds of settings.
We focused only on the actions and ignored the conditions to represent the equipped hero settings at the simplest level.
In Action AI, we also compress the meanings so that the pattern stays very simple.
For example, there are some pieces of the hero AI that trigger ultimate skill.
Ultimate Steel, immediately, Millennium, close range, long range, and on the same line.
We grouped all of them into the category U.
It is the same for all other pieces of the Share AI.
If features can be understood at a glance, comparison becomes easier.
For example, we can know easily that the first hero in these four parties has similar hero AI by comparing only six letters.
Letter U means ultimate skill, and F means full combat attack.
So we can understand that this hero is very aggressive.
Of course, a part of the information is lost when we abstracted HeroAI, but tendencies are enough for us in most of the cases.
If the short latest makes us want to know more about this party, we can open the page of its detailed information.
There is no information about the conditions of hearing eye, but we can see a little information by the order of the letters.
Actions at left side have higher priority and importance because the conditions associated with the more left side actions will be evaluated first.
We can know a certain amount of information about roles played in the battles by considering not only the complex text data, but also the order.
This is another example with a change of granularity of information.
These maps show the battle results that is used for the calculation of the fitness in the GA evolution.
In the evaluation I showed today, a fitness value is calculated with the result of 15 battles.
Each party had five different opponents and fought each of them three times.
The symbols at the bottom are the average result of the multiple games for each opponent.
In the example, the winning percentage against enemy 4 is 66%.
So a double circle is shown here.
The battles in the game have a lot of randomness.
Some battle results often change easily.
Therefore, the exact numbers in the winning percentages do not have big importance.
If the two had a feature that shows color easily, we wouldn't have used color to show the winning percentage like a heat map, because it's somehow cool.
Actually, we can understand the rough winning percentage by the symbols, and it's enough for us.
Like this example, it saves a bit of our limited time by removing insignificant information.
The third method is summarization, which extracts the important information from the large amount of data.
In the example here, you can see the content of the battle which had been done during the G evolution.
Heroes from the party can be tagged automatically according to the roles played in the battle.
For instance, in the middle frame, there is a tag of ace, which is given to the hero that dealt relatively high damage in that party.
A and H is an abbreviation of attacker and healer, which will be tagged to the hero who both attack and heal.
The frame on the right said this hero did not join the battle.
Thanks to the tag, we can know that we do not have to check this hero carefully.
We use the visualization tool at first to know which battle we should focus on.
Then we watch the video, if required.
Now that we know what we should focus on, let's see the video again.
This hero, named Sheherazade, was tagged ace, which means top damage dealer.
Her data also indicates that she's aggressive, and she buffs attacks and heals.
Her normal attack is not very strong.
She used her ultimate skill here.
Her ultimate heals her ally first, and after that, a long-range attack occurs.
And she used it again, the ultimate.
The damage is much higher than the damage by the normal attack.
And she used it again.
As a summary, she keeps her party alive while dealing high damage to the opponent.
Actually, outside the previously introduced hero, we found a few other strong heroes.
Let me introduce one of them.
This hero, despite being strong, is not very popular among the player base.
Her ultimate skill costs very little compared to the previous characters.
Our tool indicates that she's one of the key heroes of some specific parties.
Let's check her in details.
Her ultimate skill is Slow and remains for a long time.
As a result, thanks to its wide collision box, it hits many enemies a lot of times.
The damage is not so high, but her ultimate pushes back all the opponents on its path and prevents them from doing anything.
Consequently, despite the opponent having very strong heroes, they are unable to fight back.
In the end, the video are not what were recorded.
We have a function to replay the battle.
It needs to specify a random seed and running with fixed frame rate.
The proceeding of the battle is always the same if we specify the same random seed and the same party composition by JSON file.
This function makes it possible to watch the battles in the evolution later without recording.
If GA and Visualization 2 are used alone, it will not be useful, even if it finds bounce breakers.
No game designer believes that it is indeed a failure or a problem if the only thing they see is numbers and text.
they need a visual proof.
In other words, our visualization tool only detects potential balance breakers, and the replay function proves them.
Let's check this process with the previously introduced space character named Scheherazade.
It's shared balance breaker.
Actually, this character was a popular character with high evaluation from veteran players.
As the player did, our GA and the visualization too also found that she's a balance breaker.
However, it's very difficult to get this hero in the game.
After multiple conversation with the designers, it was concluded that her strength was as designed and the balance as a whole is working as expected.
When we want to find other balance breakers, we can do it with a simple operation.
We rerun GA with specific settings that prevent the use of Scheherazade character in any party.
GA will search the strongest party with this condition.
This section explains the overall system configuration and the processing flow from simulation execution to seeing the result.
First, build a game and deploying it to the Outplay environment.
And second, the designer executes GA with the tool.
Third, they check the result with a web visualization tool.
They do not have to care about the content in the autoplay environment.
Inside of the autoplay environment, we can find all the things I explained earlier.
After the building, computers for the game have the binary files.
There is a master server to manage the auto battles.
The server stores battle tasks to be run.
The slave computers fetch and run the tasks and return the result after the battles.
The visualization tool uses the data stored in the server to show the result to the designer.
That's all for the system configuration.
As much as possible, we made each element of the system independent to each other, so that we can easily replace one of them later if we need to.
What about performance for the system?
GA needs to simulate many battles to find strong parties.
How much time does it take?
We tried different approaches.
We created the first simulator to solve the problem.
It is what calculates the result of the battle numerically by simulating the proceeding of the battle.
The running time was only one second for one battle.
However, we were unable to prove that the simulator was accurate at 100% because the simulator was a new implementation of the game loop.
So it may not be exactly the same game loop as it is in the original game.
Especially when the game was updated.
We need to update manually the simulator game loop.
So it was another heavy burden.
And there was a possibility that we even forget to update the simulator when we update the game.
We decided to stop using the simulator.
Second idea is to connect the GA directly to the in-game logic and actually play the battle in the game.
This idea can guarantee that battle progress will be the same as in the game.
Also, as I showed, the designer can see the battle using the replay function.
On the other hand, it takes much time and many computing resources.
We concluded that accuracy was the most important aspect for us, and currently we use this solution.
As a conclusion, the requirement of the L-player as follows.
Using in-game logic, it is a necessary condition to guarantee the accuracy.
The following ones are options, but we strongly recommend satisfying them.
Supporting acceleration.
The update cycle of games became much shorter than it used to be.
The shorter the playtime, the better.
executing the program in the cloud.
I said our system is made computer resources.
It will have a problem of budget.
But if the program runs in the cloud, we can easily start using many resources and dispose of them soon after.
It reduces the cost to the minimum.
And we don't have to sweat from the fans blowing heat at us.
And of course, these all need to be updated automatically or by very little work.
Finally, I'd like to talk about what we want to realize in this feature.
We believe that ideally, the balance of the game should be spiced up time to time, so the strongest hero is always changing.
To do so, we created a cycle in the correlation of party strength.
However, currently we have no tool to check if the changes we do to the balance of the game are in line with the cycle of party strength we are aiming for.
We can already let the AI-made parties fight each other, but we will need new data analysis and data visualization tools to confirm the cyclic balance.
Also, it would be good to propose party compositions to players using the result of the data analysis.
Of course, there are still many possibilities in the current system.
We will continue to improve it, especially we focus on data visualization.
The current tool is specialized to visualize only the generated party.
The next major goal is to visualize the regions that G construct the parties.
We are considering using clustering method called k-means.
The clustering makes it possible to see the past progress of the trial and error by the GA, so we can know what the GA valued.
The sensitive point is how should we abstract the party composition for the clustering.
On the other hand, being abstract means that it makes it difficult to observe the individual strengths of a party visible.
As a measure for it, we are studying the use of the visualization method called box plot.
Box plots express abstractly while leaving important potentials, such as maximum value, medium value, and outlier value of growth as a whole.
We would like to continue to report to you about this research.
Let's wrap up the presentation with takeaways.
If you want to balance a game with nightmare amount of data, finding the strongest elements of your game will help you.
Today I introduced genetic algorithm, but it's only one of the methods to find strong airlines.
No matter the method you use, We recommend data visualization and analysis to understand the strength of the strongest element.
An out-of-play environment is also very important.
If you implement it for your game, you should use the same logic as actual game to guarantee the accuracy.
In addition, the outplay function must be updated automatically according to the actual game update.
The most important point is preparing them early in the development.
Are you busy with the game development?
Even if you are too busy now, it's most effective for the budget and the development of your game.
This is a transparency presentation.
I'm sorry, but we're still used to sharing English, so we'd like to ask you to speak slowly and simply.
It's serious.
Thank you very much, it was great.
How long did it take to fully design and implement this system?
Thank you.
I couldn't understand.
Well...
Um...
The first prototype finished.
After studying a half of year, and we continue to improve the whole system.
So now it's...
The final version finished by one year?
One year.
About one year.
About one year.
He agreed.
Okay.
Yes.
Have you considered any options for automatically highlighting the statistical outliers in battle during the replay?
Sorry, can you change to a more simple one?
I'm sorry.
So, during the replay, it's very difficult to see what's actually happening.
Have you tried finding automatic methods of highlighting those statistical outliers?
I've visualized all the outliers, except for the video.
I think video is best.
Video is best.
So we make visualization for such a video.
And planner want to look video.
So, I want to make more visualization, but planner want only video.
So, so now, no idea to system.
Sorry.
Well, video isn't a very good visualization for design.
Sorry.
Other than it, statistics?
Statistics method.
Any other methods?
Did you think?
Is it a question?
It's okay?
Thank you.
Okay, sorry, it's time for...
Thank you for your kind attention.
