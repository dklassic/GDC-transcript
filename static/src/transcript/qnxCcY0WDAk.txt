The room's a lot bigger than I thought I'd be getting, so I don't know if I should feel excited or nervous about that, but in any case, thank you for being here to hear me speak about our skin texturing workflow that we've been developing, specifically in terms of how normal details are handled.
And I'll be speaking about it from the angle of how we developed it by drawing from environment texturing principles.
So before jumping into it, I'll just give a quick overview of what I'll be covering today.
So I'll start off with a brief introduction, followed by a look at our previous skin texturing workflow, the steps involved in that, and some of the issues that that raised.
Then I'll explain how the heck an environment artist got involved with a skin texturing workflow for characters.
After that, in developing this new workflow, it was really important that we understood what skin really looked like, especially in terms of common patterns and characteristics.
So at this point, I would go over the steps that we did to try to understand human skin better and the conclusions that resulted from that investigation.
Afterwards, building from these observations, we designed this new skin texturing workflow, so I'll describe how that works and show some screenshots of our test results.
And then finally, I'll close off by sharing the ways that we're trying to push this workflow even further and then maybe answer some of your questions.
So, to start off, let me introduce myself.
My name is Adele Bueno, and I'm the chief environment artist at Square Enix headquarters in Tokyo.
I've worked on environments in past games, such as Bloodborne, The Last of Us, Uncharted 3, and most recently Final Fantasy XV.
And currently I'm part of a group called the Advanced Technology Division.
And we're a central technology group, or a multidisciplinary central technology group.
And at Square Enix, there's a bunch of different games that are being developed for several platforms using all different kinds of technology.
So at ATD, we're responsible for developing tools and pipelines and workflows for all these different games.
And our department is pretty engineer-heavy, but we do have two artists, one of whom is me, and the other being Eduardo Mozena, who is the chief character artist, and was actually the one who kick-started this whole investigation when he decided to look at the previous skin-texturing workflow that was in place at the time.
So this is where we started.
This is Agni.
She was created for a tech demo that was released about four years ago.
And the method that was done to texture this character was basically that same workflow that was in place.
So for normal details, that was basically handled by two maps.
The map that did basically all of the heavy lifting was a sculpted custom one-to-one normal map.
And this handled all the facial details from micro detail or tertiary detail, which is like tiny pores and micro wrinkles, all the way up to primary and secondary details or macro details.
So that includes folds, pockets of fat, large scars, basically the large forms that you'll see on the face.
And because of the amount and range of detail that this map needed to cover, the resolutions for this one-to-one needed to be pretty big, so at least 2K, even 4K for cinematics, and in some special situations, even bigger than that.
We also used the Tiling Micro Detail Map.
This one was shared across all characters.
This was a lot smaller, and it was basically just a generic noise.
And the purpose of this map was to add some texture, so to speak, to the skin.
Basically, it's to break up that spec a bit.
Now, there are a couple issues with this workflow, and there are two main ones that we identified.
The first one, obviously, was the texture size.
So, a minimum 2K map, just for a single character, just for a small part of a single character model, we thought was a bit much.
But because this map had to handle really fine, tiny, poor details, that resolution was necessary.
But even still, even using 2K or even 4K resolution, we still weren't really happy with the results.
Now the second issue was with the micro detail map.
So since we were using just a generic noise, it wasn't actually useful in terms of adding meaningful detail to the face model.
But also the pore types on faces differ so much on different parts of the face that we also couldn't get away with just choosing one actual pore type and then applying that uniformly throughout the face.
However, we did notice one thing, and that was with the unique map, the custom map, that was unique for each character.
So if you ignored the micro details and just focused on the larger forms, the primary and secondary details, they could all actually be represented by much lower texture resolutions.
So we could go all the way down to 1K, even 512 maps, which is significantly lower than what we were using.
But of course, what about the tertiary details?
And it was this need to represent this range of details on the same map, the need to display small details and wider forms at the same time, that was the root of all of our problems.
But when broken down in this way, when phrased in this particular way, it actually started to seem like a familiar challenge.
And that's because it was.
Basically, this is the same kind of challenge that environment texture artists face on a regular basis.
So I'm assuming there's gonna be some non-environment artists in the room, so just to kind of give a quick overview of what it's like to texture environments.
Environments tend to have much lower memory budgets relative to the amount of assets that we have to create, which can range in size from small pebbles and grains of sand all the way to big mountains, right?
And so to deal with that, the majority of the textures that we use are tiling textures.
And to create even more variations, we'll blend these different tiling textures together.
And this allows us to maintain fidelity at close distances, while still keeping texture sizes fairly low.
So we thought, why not give this a try for skin?
Now the idea of texturing characters using tiling textures is not really a new concept.
So we were already kind of doing it before with that micro detail map.
And for cloth, for instance, it's being this technique of using tiling textures is being used for cloth weaves to add detail to fabric.
So maybe we were onto something, approaching skin as if it were an environment.
It was worth a try at least.
So when approaching environment art creation, the first step is to try and identify the basic common elements that you can repeat throughout.
So for skin, obviously this meant starting with pores.
But we didn't want to just jump in without first gaining an understanding of the patterns that make up skin.
So what we wanted to do first was to try to find the common pore patterns that are found across most, if not all, faces in terms of shape and placement.
And that meant looking at a lot of reference.
So what we did was we gathered photos, and then I went around and scanned several faces in the office.
And honestly, as an environment artist, it was kind of fun for me.
Because for environments, the references that I tend to look at are rocks and dirt and bricks.
lots of bricks. So it was kind of cool to, even though I spent quite an amount of time looking at faces over and over again, it was a bit of a welcome change from what I usually did. So I looked at faces such as these. These are all my coworkers, by the way. And actually, I have to kind of set them aside for just a small snippet. So that dapper fellow to the leftmost of the slide is our lead graphics engineer.
And the truth is everybody who volunteered to be scanned was super awesome.
I really appreciated it.
It's not easy to put on the stocking and sit still.
It's really awkward to have me scan them.
But Jason went the extra mile because he usually has eyebrows.
And I asked him to shave, and I wasn't expecting him to go all out.
So it's worth a mention, he is the most loyal game developer that I've ever worked with.
So yeah, he deserves a bit of extra recognition.
So yeah, so getting back to it, oops, I think I went a bit ahead.
So getting back to it, what we did with these references was try to identify as many micro details as possible and then afterwards simplify them into basic, commonly occurring shapes.
And these were our conclusions.
So first, in terms of shape, we found that skin detail could be generalized into the very technical terms of dot and line patterns, as you can see here.
And just to kind of add to that, we've found that we can combine these simple patterns to create even more complicated patterns.
So for instance, this kind of cross-hatching effect, although it looks quite different from the previous shapes that I identified before, can actually be created just by combining lines in different orientations.
And the one, I actually forgot to indicate this here, but this one on the right actually also has a dot pattern layered on top of that too.
The one exception was the nose.
So we initially tried to generalize this just by applying a dot pattern too and modifying that a bit.
But we found that nose pores are quite a unique shape on their own.
And so that ended up becoming its own category.
The second conclusion was regarding placement.
So we found that certain kinds of patterns tend to be found in the same areas of the face across many different people.
For instance, with the dot pores found more concentrated on the apples of the cheeks, lines found between the cheek and the mouth, whatever this fold is called, and various combinations of both throughout the face.
So I actually went through each set of facial photos and categorized and color coded as many variations as I could.
And this is a simplified version of the pore placement map that resulted from our observations of people's skin, with the different colored areas representing the different types of patterns that could be generalized across many faces.
The third characteristic was directionality.
So we noticed that at neutral expression, certain areas of the face were stretched by default.
And so initially we identified many more basic pore patterns until we realized that some of them were actually the previous dot and line patterns I mentioned before, just stretched.
So for instance, This example right here looks quite different from that basic non-directional dot pattern that I identified before.
And indeed, if you were to sculpt it, you would sculpt it quite differently than, let's say, you would sculpt the pores on the apples of the cheeks.
But what this is, is still basically that same dot, that dot pore pattern, but just stretched along these directional lines.
So we found that in general, pores on human skin tend to follow the same directional pattern across many different faces.
So there are some variations to this as well, like for instance with age, a lot of these directional lines tend to be stronger to get that, again, technical term, droopiness in the face.
But in general, you won't get a lot of variation from, or deviation from this directionality map.
So armed with these observations, we set about to design an improved skin texturing workflow with the following goals in mind.
So the first one was to reduce texture memory.
I mean, this was the reason that we set out to redesign our previous workflow in the first place.
And we aim to achieve that by either reducing texture resolution per map, sharing textures across multiple models, or if we were lucky a combination of both.
Second, we wanted to try to reduce texture authoring time.
To be honest, this wasn't actually a main priority, but we wanted to make sure that whatever changes we made to the workflow didn't translate to more work for the artist.
Even with these goals in mind, however, we still wanted to make sure that the quality of the micro-details was actually better than what we were able to achieve before with our previous workflow.
So we decided to evaluate this by two main factors.
One, how good the details look up close compared to our previous workflow.
and two, that we were able to accurately reflect the variation in detail that skin actually has.
You know, we spent so much time looking at faces and investigating characteristics of the face, so we really wanted to make sure to represent that as much as possible.
So with that in mind, this is how we broke down the details for our new workflow.
For the primary and secondary details, and that includes, again, large wrinkles, pockets of fat, scars, basically large forms that you can easily see on the face, that was all still sculpted.
That was sculpted on a custom one-to-one map.
The main difference was that we did not include the micro details, so no pores, and nothing smaller than 0.5 centimeters.
And so because of that, we could get all these details down to a 512, sometimes 1K if necessary, especially for hero characters.
And because we didn't have to include all these micro details in the sculpt, we found that sculpting time was reduced in general across the artists who tested it by about 40%.
And in the case of scans, we could just basically use the smooth scan data and bake that directly onto the low poly and use that as is.
So this is an example of what a sculpt in this new workflow looks like.
So you can see all the major forms are represented.
There's some tiny, fine details, but that just kind of came out out of sculpting habit from our artists.
And when baked onto a 512, all of the details that mattered, those were all preserved.
For the tertiary details, this is where the workflow really differed from what we were doing before.
So for these micro details, we represented these with four basic shapes indicating the different, four basic, four textures indicating the four different shapes.
So we have our dot pores, lines in different directions, and the nose in the alpha channel.
And in each one, there is a cavity map that we stuck in the alpha channel of each texture.
And we use these as a mask to add detail to the albedo and roughness passes.
So one thing that artists could do was just by vertex painting they could control how the different details blended and Place exactly place the details exactly where they wanted to so just by painting in different shades of gray And overlaying certain details they could make characters look older younger more wrinkle just by making certain details stronger or weaker And this is an example of what these different vertex channels look like.
So as you can see, each detail is mapped to RGBA of vertex color channels.
And these could be painted in Maya.
Maya has a vert painting tool there.
Or depending on the engine that you're using, I know Unreal 4 has a vertex painting tool in Engine.
So you could actually import your models and paint it right there.
And to speed up vertex painting, we would start out by importing colors from a standard pore placement map.
And we realized that we could do this because, as mentioned earlier, the same patterns tend to be found in the same areas of the face.
So for NPCs, that was basically it.
Like we would load it from the standard map.
and the resulting vertex color was used as is.
But even for hero characters, it ended up being useful as a good jumping off point for artists to do the rest of the work that they wanted to do.
And that way they wouldn't have to start from scratch every time.
So this on the left is what that standard map looks like.
And this was never actually loaded in game.
And in Maya or in some of our in-house engines, also in Unreal, you could import the vertex colors from a targ or something like that.
And for NPCs, that would be basically it.
But yeah, this would work.
And this mapped pretty well with the earlier poor placement map that I showed you earlier.
So directionality was another important characteristic that we identified in our observations.
And to apply that in this new workflow, we decided to use a smear map to control directionality.
So what that is is basically 2D vector offsets and works similar to a flow map.
And you would author that similarly to how you would author a flow map as well.
And these would have a direct influence on the UVs to mimic that look of stretching that I was talking about earlier.
And this map can be shared or custom.
So depending on the character.
For NPCs, we used a few standard smear maps.
And I say a few because we had a couple, for instance, one for older characters and one for younger characters.
But since in certain areas and for certain individuals, directionality and stretching can vary significantly between different models.
We also wanted artists to have the option to create their own custom smear map for each character. So this, depending on if it was a hero character or an NPC, it could either be shared or a custom map.
So I have a video for you guys, but I won't load it directly from here.
At Square Enix, different teams use different engines, and we have this set up in in-house engines, but for this talk, we chose to do all of our examples in Unreal, Unreal 4, for a couple of reasons.
So one, everyone has access to Unreal.
You guys are probably familiar with it or can be familiar with it.
And the whole point of sharing this workflow at this point is that you guys can all do it and try it yourselves.
But also we have a few teams that are using Unreal to develop their games, so it made sense.
Yeah, so that's been a lot of words, but it'll probably be easier to demonstrate in a video.
Okay.
All right, so in this one, I'm just applying the different details with RGBA channels and vertex painting that.
And we have the ability to adjust the intensity and scale globally for each detail through sliders.
And in this example, we actually have the dot pores layered twice.
So this was actually kind of interesting to see how our artists used it.
So some people used it just to kind of add some general bumpiness to the skin.
So they scaled it really big, and you'd have this kind of just general unevenness.
And other people used it to scale it really small and had like really, really fine micro pores on there.
So as I was saying before, depending on how you paint these details, you can paint in different shades of grey and the artist has full flexibility on where and how intense certain details are.
Editing each detail is also a lot easier.
So compared to the old workflow of separating these details in ZBrush layers, editing them was quite difficult.
But here you can kind of experiment with scale.
You can erase at will, but preserve.
For instance, you can, I'm just gonna pause it for a second.
You can choose to edit only lines, only wrinkles, but leave the pores intact.
And this last bit, if you just pay attention to where the arrows are pointing to, you'll see the effect of the curvature of these wrinkles by toggling the smear map on and off.
So I hope it's big enough on there.
You can just see the curvature changing a bit.
Okay.
All right.
So this is how I break down how the textures are, so how the details are summarized in the different textures.
So as I mentioned before, the primary and secondary details are still sculpted, but on a much smaller map.
And again, like the previous workflow, this is still custom to each character.
And the tertiary details this time are handled by either four 128 by 128 detail maps or they're atlased together into a slightly larger 256 by 256 texture atlas.
And these are shared across all human characters.
Then for the smear map, that's on average about 256 by 256, and this handled the directionality or the static stretching of the skin.
And this was shared or not shared depending on the importance of the character and also the, I guess, the choice of the artist.
And since I'm assuming we're all visual people, or at least maybe it's easier to understand this by, you know, through visual means, these are the relative texture sizes comparing the old workflow and the new workflow.
So the textures that are outlined in yellow, those, again, are custom to each character.
The ones in green are shared.
and still comparing the lowest resolution scenario of our old workflow with the highest resolution scenario of our new workflow, there's still a considerable improvement in terms of texture memory.
And this is what that looks like applied to an actual model.
So this is, again, using the old workflow compared to the new.
And in terms of close-ups, so this is a 4K normal map that's applied on here, compared to the largest normal map that's applied to this is a 512.
And I mean, you'd never go, you'd probably never go this close ever to a character's skin, but now you can if you want to, so I don't know, you could come up with some creative shots using this technique.
So we created some different lighting scenarios just to test how the pores react, if they were acting the way that we expected them to under different lighting scenarios.
So I'm just going to scroll through them so you can see.
We got kind of creative with this.
We don't really get to do fun lighting, so...
This one's my favorite one.
It's kind of a Sin City sort of thing.
It's quite different from Final Fantasy, so it was kind of interesting for us.
Yeah, so we're always looking to improve what we're working on, and there's some things that we are planning for our next steps, like to try to improve this workflow even further.
One of them is to try and use procedural substances in lieu of bitmaps.
So at the moment, the textures that we're using are sourced from scans mixed with a bit of hand sculpting.
But with substances, we think that we can reduce texture memory even further and also add some more customizability at the pattern level.
Another thing that we're doing is looking at pore distortion for facial animation.
So making sure that in addition to static stretching, the animated stretching also matched with facial animation.
So that's my colleague Chida Kazuhisa, he's working on that.
And it's a separate system, but we're making sure that our different workflows complement each other.
Another thing that's really important that we want to try to push even further is increasing ways for customization.
So one way is to add two layers of RGBA instead of just one.
So currently we have four basic patterns for each channel RGBA, but with two we're thinking, with that extra set of details we could either have...
entirely new different set of details or have the same ones but have the ability to have different scales and different intensities at different parts of the face. And lastly one of the things we're looking into is allowing for optional masks to allow for decal application. So for instance in the case of war paint.
Yeah, okay.
And I don't know if there's a moral to GDC talks, but if there is, the moral to this story is that interdepartmental collaboration is good.
So nowadays, skill sets are so.
specific and so defined and so specialized that we don't really get to talk to each other much.
So, for instance, in terms of character artists and environment artists, we have completely different workflows.
We use the same software but in completely different ways.
And we don't really get this chance to work together in production.
And that's a real shame because, for instance, in this case, the solution to one of the problems that one of our departments was having was already put in practice for a while.
And the point is, inspiration can come from unlikely places and no harm can ever come from just talking to each other more.
So, yay!
Before finishing, I'd just like to give some special thanks to a bunch of people who helped.
significantly in developing this workflow.
So first to Eduardo Mozena, who is the chief character artist and did all the art for this presentation and also co-developed this workflow with me.
Also to Jason Lacroix and Chida Kazuhisa, who in addition to being fabulous models, their faces are in the slides, they're also really helpful in providing feedback and advice.
Ishii Haruya as well tested this workflow extensively and gave a lot of useful feedback.
And the other names on here, Graham Murray, Hendrik Skubach, and Paul Chandler are just some of the other models that I have in my slides and were kind enough to let me use their images.
So yeah, I think we have time for questions, right?
So if you've got any questions...
Hi, great work. I had a quick question about the smear map. Did you have any problem with singularities due to the directionality of it?
Sorry, pardon me?
With the smear map you said it was some 2d vectors on there. Do you have any problem with singularities occurring due to just Not in our experience. I mean like to be fair. We we only had a few artists test this This workflow and they would author smear maps like let's say in Mari some of one of them like kind of hacked the vertex paint functionality in Maya to try to create a smear map that way, I don't recommend it.
But no problems that way had ever really come up.
So yeah, I hope that answers your question.
Thanks.
Any other questions?
Hi, nice.
Great talk.
I kind of missed on, when you were painting on the face, which application were you using?
It's in-house, or it's a ZBrush, or?
Oh, that's actually in Unreal 4, using the vertex paint tool in Unreal.
So, I mean, I'm not saying that you need to use that.
Oh, sorry, I guess the question was, like, what was the tool that I was using in that video?
It depends on your own workflow.
It depends on your in-house engine.
Like, not all engines have that in-engine vertex paint capability.
So in that case, you could use Maya, because Maya has that ability.
But I thought it would just be easier to demonstrate in Unreal, in this case.
Hi. I think this is really cool.
And I have a question about the production on this.
If this is in use on older men or men's skin, I think that would be perfect.
But how do you treat this on some teenager or young girl's face?
Would you still like to use the same way?
Because, you know, the young ladies maybe show the beauty of their skin.
And how do you balance it?
So the question was, I guess he understands how this workflow applies to men, but how would it work for prettier people, I guess.
And the truth is, you can use it for women, smoother skin and younger skin as well.
Because even young skin also has pores.
They're just a lot finer and less pronounced.
So in this example, we use an older character with more pronounced details, just so you could see it better.
but it would still be the same workflow, just applied a lot more lightly, either the way that you painted or through the global parameters, just kind of scaling that all down.
Okay, thank you.
Hi, this goes a little bit beyond the scope of the panel discussion, but I was wondering if you could provide any additional insights onto achieving more accurate subsurface scattering maps.
I traditionally see them, they're more hand-painted and kind of artistic decisions, but I'd love to know if you've explored anything with facial tissue depths or achieving greater accuracy with actual real-life subsurface scattering on skin.
So the question was about subsurface scattering, which again for this presentation, we kind of focused more on just texturing and normal details.
If you want, you can email me that question.
I could try to forward it to somebody who might be looking at that right now.
Oh, certainly.
I sincerely appreciate that.
Okay, thanks.
Thank you so much.
Anybody else?
Yeah, we're good?
Okay, all right, thanks.
Oh, one more question?
Could you use a RGB mask instead of using a vertex color for your placement of?
Yes, actually.
So the question was if we can use an RGBA mask instead of vertex color.
You absolutely could.
The point with using vertex color was to reduce texture memory.
So that's one of the things that we're trying to do now, like how to layer to RGBA instead of just adding more and more maps.
Because the point is to try to reduce this.
Yeah, reduce text from memory as much as possible.
But you totally could.
OK.
Thank you.
