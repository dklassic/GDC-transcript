So I last spoke here in 2014.
My PhD was in AI for Games, and many of you may remember me as the shouty guy talking about how we could do things a slightly different way.
And I disappeared into corporate America at the end of 2014, and I actually moved here, which was strange, and joined Zynga, and I've worked my way through the ranks and become director of central and strategic analytics, as Steve mentioned.
And that's a big lofty title that doesn't really mean much.
But what it sort of means is that I provide kind of technical oversight over a majority of our kind of AI and machine learning and data science across Zynga, as well as leading a team of practitioners that are a centralized resource.
So you might have heard of Zynga.
Back in the old days, we were very well-known for Farmville.
That was kind of 2009.
That's the thing that kind of kicked everything off for us.
And since then, we've diversified our portfolio.
We're now running games like Zynga Poker.
That's now celebrated its 10-year anniversary.
And then we acquired studios like Natural Motion, and we now have CSR2, Dawn of Titans, games like that in the mid-course space running out the UK.
Words With Friends obviously remains our staple title.
Everybody's played Words With Friends on the planet, I believe.
And more recently, we've been doing some acquisitions, picking up studios like Gram Games in Istanbul with Merge Dragons and the Small Giant Crew in Helsinki for Empires and Puzzles.
So that's the kind of games that we make and where we are.
But let me give you some numbers on that.
After over 10 years, we've got actually 50-plus games live today across our entire portfolio.
And that's across mobile.
We're mobile first these days.
But we've still got our presence on Facebook, on Facebook's instant messenger platform, and iMessage as well.
We have across our whole portfolio, we have about 85 million players per month, and that's driving in 2018, 907 million dollars in revenue.
So I've pulled those numbers from our most recent financial report, so I don't think anybody can dispute them, and certainly corporate didn't when they reviewed these slides, so it's probably right.
So let's talk a little bit more about what central and strategic actually means.
So like I say, it's a small group of data scientists and data analysts who sit centrally, not embedded with our stakeholders.
We have a game analytics crew who is all embedded, really supporting in a service kind of role the actual day-to-day of our game.
So these are the people who are giving the insights to the product managers, actually kind of delivering a lot of insight and knowledge into what's going on inside that game.
We don't do that.
We sit centrally, and as a central team, we provide support to the people that don't have coverage.
And that means like, corp dev, for example.
Like, when we go on one of these acquisition sprees, well, there's no point having a team dedicated to that because it's kind of infrequent work.
So it falls on my team.
And then on the strategic side, we're kind of focused on things that cross division or cross company, things that are going to touch multiple teams across the entire kind of global operations of Zynga.
And one of the core things that we're kind of centered on, mostly because of my personal biases and kind of that's how I'm steering the team, is a focus on kind of novel uses of AI and machine learning techniques.
So what do we mean when we say AI?
This is gonna get defined repeatedly and repeatedly, but in the context of kind of big corporate business, in general, we would like our AI systems to be one or more, ideally more, of three things.
Assistive to humans, better than humans, or faster than humans.
And if you can tick at least one of those boxes, it's probably a good candidate for some cool AI shit.
And the idea is that we can drive operational efficiency.
We want to move humans up the value chain.
There's not really a whole lot of value to humans doing mundane tasks that an algorithm could do.
What we want to do is put the humans in the driving seat, kind of driving the algorithm, and actually kind of providing more impact than doing grudge, drudge kind of work.
So who here knows anything about mobile advertising?
Cool, then you're going to enjoy the next slide.
Because I got dropped onto a project around mobile advertising.
And it was the first thing that I kind of took on as part of this new responsibility.
And I said, cool.
At that time, I knew that our games were supported by ads.
And there was some magic that made ads appear in games.
And that was all I knew.
So let me give you a crash course in mobile advertising, because you will need it later.
So imagine you have a game, and you want to show some advertising in that game.
We use what's called mediation.
And the reason that we do that is that we're going to try to find a good price to sell this piece of advertising at.
And we use what's called a waterfall strategy.
There are other strategies out there like unified auction.
But our waterfall strategy means that we contact a mediator, and we say, OK, well, can you talk to AdNetwork1, and can you try to sell this piece of advertising for $20?
And they will contact their advertisers, and kind of all of this is happening in real time.
So the price here is in cost per thousand, so CPM.
So it sounds like a big number for one piece of advertising, but divide it by a thousand.
And maybe they say yes, in which case we're done and we can move on and it's all good.
Maybe they say no, in which case we go, OK, cool.
What if we went to AdNetwork2 and got $20 there?
And maybe they say yes, and maybe they say no.
So then we might go to AdNetwork3 and $15, and now we're getting not desperate yet, but we're going to get desperate as we go further down here.
AdNetwork1, maybe we drop the price and we say, OK, well, you couldn't do $20, but can you do $13?
So each one of every time we reach out to the ad network, they're running an auction on their side.
And the dollar value that we're giving here is the reserve price.
So imagine that they are running an eBay auction with a reserve price at that point.
That's kind of giving you a sense of what's happening here and why it's this cascading waterfall.
So, at the end of it, we maybe dropped down to $5 at network 2.
So 18 months ago, we asked the question, okay, cool, how do these configurations get generated?
And the answer we got back was that there are people who sit down and figure out what they think the price point should be, and which order the ad network should appear in, and what goes where.
And they do that all manually.
And we said, well, fuck that.
So 18 months ago, we said, OK, we can optimize this process.
So let's actually start a project around optimizing this.
And we created this thing called Zoe, the Zynga Ads Optimization Engine.
It turns out that if you work at a big company that has a Z at the front of the name, most of your acronyms end up starting with Z. The other one is VIL, something VIL, contract VIL, manager VIL, just an insight into corporate America there.
This is a really interesting problem, though, because at the end of the day, we actually partner with 40 different ad networks. In fact, it might even be closer to 50. Each network can appear multiple times at multiple different price points.
This is one of the gnarliest optimization problems and the most fun optimization problems I've ever had to sit down with.
Um, because you've effectively got this kind of indefinitely long list of knobs that you can kind of put on the thing.
You've got a box full of different knobs and different settings and like you can just play around with it. It's fantastic.
Um...
In an ideal world, you would start out at the highest price point that you think you can get to, and you would go, okay, down the list, dollar, dollar, dollar, dollar, dollar, 99 cents, 99, and you would just brute force it, right?
That's kind of the optimal strategy to maximize revenue.
The problem with that, and I kind of mentioned it earlier, is that people are waiting for their ad.
This is all happening in real time.
So the more times that we actually go out, and the more we get it wrong, the worse the user experience is, because they're sat and they're waiting, and you've just got a blank screen there.
And that's not good.
And it turns out that if people are given a blank screen when you're supposed to give them an ad, they will eventually just piss off and never open your game again.
And that's not what we're going for, for our user experience.
So, let me introduce you to how Zoe works from a block kind of point of view.
So imagine that you have data to ingest because you're tracking everything and you have a whole bunch of sales information about what's actually being done.
That reporting is generally on a 24 hour aggregate basis.
So we get performance for the last 24 hours.
We ingest it.
It's data, so we have to clean it because it's trashy in places.
And then we do a whole bunch of aggregation type stuff.
I'm going to gloss over the next box.
We do clever stuff.
And then there's a post-processing phase.
And then what happens next is it gets shipped out to the ad networks.
Now, that sounds easy, right?
Turns out that the state of ad tech is woefully behind the times on the publisher side.
I joined this project, and I thought, OK, cool.
We just fire off some API calls, right?
No.
Turns out that most of the ad networks have got to a point now where they have web portals.
So you open up a web browser and you log into their portal and you set things up and you've got to set it up in two different places because you've got to set it up on the mediator side and on the network side.
That's not great, particularly when you're doing that at like 30 plus networks and you're reliant on these vendors not changing their website because you're trying to do it using like Selenium or something like that.
So that's suboptimal.
It turns out that there's a whole bunch of ad networks that are even further behind the times.
And you actually email a human being, and they will make the change in their system for you.
That's actually easier for us, because we can generate an email automatically.
We can't figure out how to, well, we could figure out how to log into these websites, but we decided not to.
So we introduced some drudge work for some humans, and we actually spit out a text file and say, okay, cool, go put this into a website, please.
And they do that.
And then we go and we go and do some sales for the day, and we show some ads, and it's all good.
And then we get reporting for the last 24 hours, and close the loop there.
All right, so that's how Zoe works at a very kind of 30,000 foot view.
I kind of arm-waved the clever stuff and I'm not going to get away with that in this room, so let's talk about what clever stuff means.
The reason that I like that block level diagram is that it really highlights the extent to which this is a modular approach.
It means that we can sub different strategies in, and we've actually developed three or four different solvers to try and approach this problem.
We've been doing a whole bunch of experimentation with algorithms, with update cadences.
Our initial kind of view was that the frequency of update actually made a difference.
We kind of, we took a parallel to the stock market and said, okay, well if we can get to a place where we're doing effectively high frequency trading, that feels like a win.
Turns out it doesn't work like that.
We also played around with ordering.
So in that example that I gave you, everything was in strictly decreasing CPM order.
We played around with trying to do it in fill rate order, trying to do it in a whole bunch of other strategies.
And it turns out we've been just too clever.
So the algorithms that we tried.
was predicting the price point based on market trends.
So we called that system the gradient surf.
And as the kind of stock prices, so the parallel that I draw is stock price.
So imagine that each line in the waterfall is a single stock ticker, and it's kind of trading at different prices over different times.
If you can predict where it's going to go, the theory was that you can set your price point appropriately and off to the races.
that didn't seem to work well.
And here is a piece of advice for you.
If you've got something that's fairly experimental, don't put it on your biggest game.
So I got a lot of angry emails from Words With Friends.
And we turned that one off, because it wasn't doing well, and we tested it somewhere else, and actually it turns out it's actually not great.
We tried linear programming with binpacking.
In fact, I think it's binary programming rather than linear programming.
But the idea is that you can kind of put out the, all the...
waterfall lines and the potential prices, and do a whole bunch of linear programming around that for which one should be turned on and off.
And that gets you in a world where you can bin pack around how many requests you're going to get in the next day.
And it turns out that because requests is softly connected to DAU, it's not directly correlated.
But if you've got a good sense of how many people are going to play your game on a Thursday, you've got a good sense of how many ads you're going to need to serve on a Thursday.
And at that point, that puts you in a world where you can say, okay, well, if I'm trying to fill a backpack that's this big, how do I do that?
And then we tried some simulation-based approaches and a whole bunch of stuff around kind of doing things that are a little bit more kind of roller-oriented.
And one of the reasons that I'm not going to get deep into which one of these is great, the first one definitely is not great, is that I don't think we've solved this to optimality yet.
And I don't wanna say, hey, do it this way.
Also, legal don't want me to say, hey, do it this way in case we're onto something.
But the point is that this is a really good opportunity to use some cool machine learning to actually optimize something that's around your business that's not actually inside of the game, but actually drives outcomes.
So let's talk about those outcomes.
First thing that I have to kind of caveat is that this is so hard to figure out what's going on.
Every one of these line items in the waterfall, like I say, it acts independently.
They kind of are treated as their own commodity within this stock market.
And it turns out that there's no real strong way to A-B test that.
Because as soon as you try and A-B test it, A and B start doing different things, and that...
is really awful.
So, we've spent a lot of time kind of just staring at charts, trying to understand what the hell is going on, trying to find apples to apples comparisons in terms of historical performance.
So what we know is that we know that we can mess it up.
That algorithm I mentioned earlier really proved that we were actually connected to revenue, which is intuitively it has to be true, but it's good to get the validation when you just torpedo everything.
you have to find a silver lining somewhere.
But what we found is that you can't actually really tell a difference between the operation of the humans and the algorithm.
Like, we're getting comparable results.
You can't kind of look at them and go, well, this is obviously the one that's underperforming.
And what we think is that we think we're driving upside.
And the reason that we say that is that when we do find something that looks historically like it's an apples to apples comparison, and we drop Zoe on one of the apples, it starts to diverge.
And that's really kind of a good indicator.
It's not conclusive, but it's a pretty good leading indicator that we're onto something.
And like I say, this frequency thing.
Intuitively, you should be able to make the changes faster, react to the market faster, and get there.
Turns out, we think we're causing so much turbulence in the market every time we change around our waterfall that it actually is worse than just kind of holding back.
So we've not rolled this out to the entire portfolio yet, but we're starting to really strategize about what that's going to look like and how we can do that.
So some of the things that we're looking at are kind of like predicting upside.
So if we can say that there's an opportunity on words today, then we can actually direct the ad operations people to kind of focus their attention there, take the guidance from Zoe.
Whereas if we see tomorrow that it's somewhere else, we can actually be reactive to that.
So cool, you all now are smarter about mobile advertising a little bit, I hope, and benefited from about 18 months of me staring at stuff going, what?
So let's talk about something else.
It's kind of a related problem, but user acquisition.
People show up in mobile games because of reasons.
And some of those reasons are that we've paid for advertising on various channels.
How would you go about optimizing your budget allocation?
At a meta level, the way that you do it is that you focus on this idea of return on ad spend.
Basically, this is a kind of measure of how quickly you are going to get the money that you spend on the ad back.
And that varies on different channels, and that's kind of because the different channels have obviously different audiences, different types of people around.
So maybe you might decide that you're going to spend a whole bunch of money in Facebook and very little money on Google AdWords today.
The trick to all of this is maximizing the aggregate return on ad spend.
If you can do that, if you can do a whole bunch of optimization at a meta level, then you can get to a world where you can actually start to do that.
But then we can go a step further and a step deeper and say, OK, well, what about targeted acquisition?
What about specifically for this person?
How much would you bid for this player?
Two things going on there.
One is the real-time nature of that, because you have to be real quick.
You have to have a system that runs in sort of millisecond order of speed.
But you also need to know.
how much you value somebody who looks like that.
You know, and in order to get to that, you need to have a good sense of whether, you know, as somebody who meets these kind of criteria that the advertiser is kind of presenting to us, have they enjoyed the game?
Have they paid for the game?
Have they like churned out immediately?
In which case, maybe we're not gonna spend that much on them.
So this is why analytics and AI is completely intertwined, particularly at companies that have established data groups.
This is always going to be true, I think.
But the insights that we drive based on the data that we're gathering.
So at the base level, you are gathering that telemetry.
You're figuring out what's going on in the game.
Then at the next level, you're driving the insights, and you're driving that kind of understanding of how people are interacting with the game, what's going on.
So this is kind of the very service-oriented view that I mentioned earlier in the game analytics group.
But then you can take those insights and start building decision systems around them.
And those decision systems can actually be driving some really cool shit for your business.
So.
One of the things that often comes up when we start talking about data science and kind of this kind of idea is the propensity modeling.
So propensity modeling is basically this idea of given historical data and what happened next, I'm gonna drive a model to kind of tell me, okay, based on this, I understand what the kind of causative factors in this were, and then we can start rolling it forwards and predicting the future.
So you have to, so let's give a concrete example of that.
So like likely to lapse, likely to not come back to the game.
Well, I'm gonna look at a snapshot of time in the past, and I'm gonna label all that data based on whether people came back or not.
And then I'm gonna feed it into some sort of analysis or modeling system, could be a random forest, it could be a regression system.
But the trick is training a classifier on that labeled data set, and then run it against the recent data.
And that's going to allow you to understand who's coming back, who's not coming back.
Then you can take that kind of idea forwards and start doing some interesting things with that.
You can start surfacing offers to people who are not having a great time.
Give them the opportunity to kind of, you know, get more out of the game at a cheaper price point.
Now this, frankly, is very low-hanging fruit.
It's a very obvious way, it's a very product management centric way of approaching the problem.
But it's effective.
You know, you are kind of customizing the game experience and kind of giving people an incentive to hang around a little bit.
One of the dirty secrets about that, though, is that if people were likely to lapse already, it's because they kind of weren't enjoying the game.
And giving them a sale...
okay, maybe you get them to hang around a little bit, maybe they, but it's still the same game, right?
What if you could go a step further?
So take those kind of understandings of our propensity scoring, and use them to build out some pretty deep, holistic models, and start to actually manage the experience of the player, to match likes and dislikes.
My fundamental theory is that people who enjoy a game are motivated to support the developer.
And if you're not enjoying the game, it doesn't really matter. You know, sales are great, everything's great, but fundamentally, that person isn't a good match to that game. So incentivize people to and optimize for fun experiences.
We can do that by modulating our live operations.
We can actually tweak things in real time and say, okay, well, you want this kind of experience, therefore, maybe we're gonna alter the difficulty because we know that in an evening, when you're going home, you've just been sat at work all day and you actually just wanna grind through a few levels and not actually have a challenge.
Whereas in the morning, we know that you as a player want more difficulty.
You want to actually experience something that challenges you because you're getting psyched up for your day.
If you can take everything from the data science side and match it with this kind of idea of matching people's, matching people's desires, ultimately, personalizing the game to be what they're looking for, it's not actually that much harder than showing them the sale.
You need the same indicators, right?
You need to know what's going on with them.
So, we've said a whole bunch of stuff.
I'm starting to run out of time.
So I will throw you a final disclaimer.
Zynga's scale makes some of this easier to justify.
1% lift on our ad revenue means millions of dollars.
That makes it a real no-brainer to chase some of this stuff.
But if you start thinking about things in this way, you're going to find the opportunities for your business.
And your mileage is going to vary.
This is why I'm really loathe to tell you exactly how our ad stuff works, because I think yours is probably different.
And it's probably not going to work exactly the same way, because it's so related to the relationship between the networks and the vendor and blah, blah, blah.
The point being, your mileage will vary.
But start thinking about this stuff, because AI is a lot more than what we've historically talked about in this room, and I'm going to be yelling and swearing about that at 5.30, so please come along to the Cheering Tantrums session.
But I want to encourage everybody in this room to think strategically about how AI can support your businesses.
Those opportunities really do exist everywhere.
I've talked about advertising, I've talked about user acquisition, I've talked about personalization, but what does AI for community management look like?
Well, think about it.
There are people in this room who have opinions about that.
What does it look like for even like...
Stationary cupboards.
How many pads of paper have you got through today, versus, or in the last six months, and versus how many are you gonna order?
Like, there's probably a model in there that will optimize stuff and actually help you kind of use your budgets.
That's a really daft example.
Don't do that one.
We've really only scratched the surface of what we can do.
So I want to challenge everybody in this room to go forth, open your eyes, and actually use your skills, your AI skills, everywhere you possibly can.
And if you would like to do so at Zynga, analytics.zynga.com.
You can reach out to me, Eldick, at zynga.com.
You can find me on Twitter, I'm at Luke D.
Please reach out, tell me just how wrong I am about all this stuff.
But this is a fundamental philosophy for me.
You know, at the end of the day, the obsession with NPCs is cool, it's kind of nice, it generates really interesting things, but it doesn't generate business results.
And that's kind of what I want to see us do more, because we can.
That's it.
Any questions from anyone?
Everybody's piecing out really fast, so I'd.
Hello.
Thank you for your talk.
I have one question about this personalizing player's experience, right?
Sounds really great.
So I was wondering, does it?
Like if you make the game more fun for the player, it means like maybe you're giving him or her more rewards or something like that.
And it doesn't mean that it will basically decrease chances that the player will buy something.
I mean, do you have anything on that?
OK, so the question is, I guess it came through the mic, so it's probably OK, but I'll repeat it anyway because I was told to.
The question is, if you personalize the experience, do you end up in a situation where you end up giving people more things, and as a result, kind of cannibalize your sales?
The answer is, maybe.
It's definitely something to keep an eye out for, right?
But at the same time, if you're doing your personalization in a smart way, probably not.
You know.
I don't want to say yes or no to that question.
It's definitely a factor.
It's definitely something to be aware of.
But I think there's ways you can mitigate it.
And part of that is like, you're providing a fun experience for people.
And okay, people, it's changing the value proposition maybe.
In which case, maybe change your monetization strategy.
Maybe that person to you is more valuable watching ads.
And they're going to stay in the game longer because you've given them something to keep them around.
So they've got more opportunity to be incentivized a different way.
Okay.
Thank you.
Does your scale give you the ability to drive back into the marketplace and say, give us a better interface and we'll give you preferential treatment so that we can actually do this more the way we want to, or are you not allowed to comment on that exact thing?
You know what?
I am... so the question, to repeat the question, is does Zynga get to push back on vendors?
I would say we have good relationships with a lot of vendors.
In fact, you know, we're in a position where I wouldn't frame it as pushing back.
We are able to contribute to people's roadmaps.
But also, without legal in the room, I don't really want to give a definitive answer.
So we have good relationships with various vendors and different.
Our scale does give us some opportunities.
But we're not, you know, if you're talking about us talking to Google as a business, like Google's significantly larger than we are.
So it depends.
In other words, you may see improvement in the future.
Yeah, can I ask one?
OK, no, we're out of time.
So let's give Luke a final round of applause.
