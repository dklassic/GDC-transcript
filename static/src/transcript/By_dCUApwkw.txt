Hi.
So, uh, uh, the Sound of Horror, Resident Evil 7, thanks for coming to our talk.
We are Capcom audio team from Resident Evil 7, and we flew from Japan.
It's really nice to play San Francisco, actually.
Thank you.
It's really nice, and we are super happy to give a talk here, and, uh, yeah, hope we will be fine.
OK.
OK, so the next slide here.
I'm just going to give a short interaction from each of us.
So we have, my name is Akiyuki Morimoto.
I'm a composer.
And we have, my name is Kenji Kojima.
I'm a sound programmer.
And I'm Ken Osami, I'm a sound designer.
And good news, we have audio director here sitting here.
He's Wataru Hatsunoko.
So yeah, he's the guy actually.
So, so, so, okay, thanks, Wataru.
OK, so let us just give a short overview on today's topic here.
At first part, we will just talk a little bit of Resident Evil 7, a little talk on the game features, and some summary maybe we'll cover a little bit of.
And the second part will be a sound design and pipeline.
And here we will break down to a sound effect, system workflow, music, and working with the level designer pretty much.
And each of us will give a little talk on each topics.
Okay, and we will have some video clips here to illustrate our audio works.
And you know, it's a Resident Evil 7, it's an M-rated game, so it contains intense violence, and strong language actually is there.
So please be aware for that, and we just want to warn you first.
And also there are some spoilers for those who have not played the game, so please be aware for that too.
Okay, so let's go.
So, Resident Evil 7. I just want to start with this short question. How many of you have played Resident Evil 7 here?
Wow, great, great.
Thank you so much.
It's really good to see.
OK, so the Resident Evil 7, we have new features.
It's quite a shift from the previous sequel.
But if we were to point out some of the key phrases or new features in Resident Evil 7, there would be a photo real visuals with first person view, really big change from the TPS, the previous sequel, or a fixed camera from the really old, great Resident Evil sequel.
And we may say this every time when new Resident Evil comes, but it's back to its horror roots.
But I think we really tried our best to make horror games.
But yeah, again, so it's back to its horror roots.
And OK, so I'm just going to give a little bit of people here who worked in audio production for Resident Evil 7.
So it's kind of really small here, but we have about 15 people involved in total audio team.
And I think that's kind of huge.
But of course, that's the maximum number.
So at the early production, pre-production, we have less people, like audio director, maybe some of the leads.
And we add more people when it gets busier.
And three years of production, including prototyping, grey box testing, and vertical slice.
And we also actually developed a new engine here.
It's called RE Engine, in-house game engine designed for Resident Evil 7.
Resident Evil 7 RE Engine.
So it's very cool.
Yeah, nice name, actually.
Very, very, very straightforward.
I like it.
And we used Vicepool as a middleware.
And Kenji will explain this complicated system part.
And I'm a sound designer, so I don't know much about it.
But Kenji's going to tell that.
All right, so here we have a smiley guys here.
It's in our foley stage, so that's a lot of people there.
And we're smiling.
I guess it's because of the shipment of the game, right?
Yeah, I mean, we are really happy that the game is shipped.
And finally, we finished the video game development, and that's really cool.
And also, I think I need to, but I think I'll do it later.
OK, so the sound summary, I'm just going to tell a little bit of our core pillow of sound.
And it's really simple here.
It's just sound of horror, because the game is a really scary game.
So we really focused on how to scare people by sound and how to make a more immersive experience throughout the sound.
And so the sound of horror is the core pillar.
And we have some, when it breaks down, we try to house the creepier mood in the game by sound.
And the blend of realistic, it's for the real visual.
So we really needed to nail the real sound by follies and vice versa.
But it's dramatic.
I mean, it's the game.
So we have some cinematic scene as well.
So there is a blend of real drama.
And the pacing, silence is of course important in the horror games as well.
If the scary sound, you know, like continuously, you know, if you have like lots of scary sound, then people get used to it.
So the pacing and the silence is also are some things we really explore with.
In Traumatic Immersive, we have a VR version in the game.
So the immersive is also our key phrase here and the dynamic interactive is the game.
So yeah, it's interactive.
Okay, and yeah, moving on to another part here in the sound summary still.
I'm going to talk a little on some sound summary.
So we actually re-sketched our system and workflow.
We really thought about efficiency, agility, accessibility, resource management were kind of keyword here.
And because of our tight schedule here, we choose more automated methods.
And that's, yeah, we have like numbers of automated system here, but these two are kind of being here, the measure system here, the auto trigger for movement, footsteps, props, some of the movement on the props, and the utilize of other resources such as effect collisions or meshes to change ambience, reverberations, occlusions.
and stuff like that.
And within this automated system, it's kind of really weird to say, but sound implementation are taken care of or done at some extent when upper stream assets, such as animations are ready.
For example, when animations are ready, there is no sound usually, but within this new system with new component behaviors, so we have some sound playing to some extent, and that's taken care of automatically, so I really make.
things easier.
And also Kenji prepared some tools that let some designers to polish and do more, do manually to brush up assets later on.
So we have both static ways and dynamic ways.
And I think from next slide I'm going to hand to Kenji and he's going to share some details on RE Engine and our basic sound features.
Okay, let me talk about our new engine and the sound system in this part.
First, I will give a quick overview of RE Engine.
RE Engine is the latest state-of-the-art in-house game engine.
It was specially designed for development of Resident Evil 7.
We can produce photorealistic results and display objects of various textures and to write into the smallest details.
Next will be about the sound system.
We had two aims to start with.
I designed the sound system, not only basic features for game audio, but also to meet these goals.
The first aim was the works of sound roughly ends automatically when upstream assets are ready.
And the second one was to provide more spaces and choices for sound designers to polish assets later.
In this way, we could get high quality and immersive sounds with relatively less effort.
I will show two examples at later part when I talk about systems and workflow.
The sound system was powered by Wwise for basic features.
Wwise is an excellent audio-video player, as you know.
On past experience, sound designers and composers in our studio make complete use of their tools to improve the quality of game audio more and more.
I respect their challenge as an artist, and I think it should be so.
But sometimes that tends to take lots of time and efforts for game programmers because they get more requests from some section.
As I wanted to make this game with not only rich experience, but also exciting gameplay, I wanted sound designers and composers to concentrate on leverage quality, and the game programmers to utilize more time for making game mechanics better.
I was keep thinking about this issue, and this idea popped up.
Game programmers are no need to consider or know very well about using Ys, but let some designers and composers utilize the full potential of Ys functions.
So here was my approach.
First, I sealed Ys under the engine.
Next step was to open public about floating point parameters and was step by step stage in the game.
Finally, I changed that to the engine.
Even in a complex use case, all of the process for Wwise was executed at the engine.
Game programmers are never called Wwise API.
At minimum, they only needed to trigger and to open public parameters.
The engine took care for the rest part.
That is how we could get rich sound system.
The sound system in RE Engine equipped many functions for basic development of action shooter game.
For example, animation sequence, FSM actions, clip timeline, generator for environmental sound, monitoring tools, and so on.
Okay, thanks Kenji.
So from next part, we'll break down to little categories of sound effect, music, and the system, and we will again talk a little.
So from this part, I'm gonna explain a little bit of sound effects here and how we built our sound design in Resident Evil 7.
So first of all, I want to share some videos here to illustrate our work here.
That was silly, I'm sorry.
We should have actually cut that word, I'm sorry.
I'll go, i'll go.
So that's clip number one here.
And the, just gonna explain, oh, I have to close this.
Right, thank you, Kenji.
So, okay, the follies.
Well, obviously, it's the Hodorio Realistic, and we have lots of props that's really real.
So the sound also needs to be real.
So we really focused on our Foley recordings here.
And the aim was to create real sound with the exact resonance and the deep details in each sound.
And we tried to place really many sounds that we hear in our daily lives, such as noise of electricity, draft wind, drawers, or really simple furniture, sound, something like that.
And perhaps.
You know, we don't pay much attention in this sound because it's supernatural.
We are surrounded by this kind of sound.
But we know somehow we know subconsciously how they sound and the variety of sound that surrounds us.
So the first step was to create this real, real, real, hyper real atmosphere in the Resident Evil 7 in this way.
And these real sound roles were to create much immersive spaces.
And if things are ready, unlikely once you hear the sound you're not familiar with, it creates much uneasy and disturbing moods in the game when it accumulates especially.
And that can actually drive players into a horror state.
So we really have this real sound versus this horror dramatic sound.
So a little more talk on the Follies.
For the Follies stage, we choose to record sound in larger places so that we had more flexibility and could get various resonance on each sound.
So two main places.
We went to Toho Studio, which is in Tokyo, Japan.
It's a really famous studio.
And fortunately, actually, we do have a Follies stage at Capcom, and we really used that studio, too.
And for the microphone setting, we set three or even more microphones.
For each recordings, all the microphones were set in different positions to capture different characters on each sound.
So if it's close, you get more direct sound. On the other hand, if you have mid-range sound, it captures more spaces and ambience.
So in this case, we really recorded a lot of sound here.
And we actually, the cool part of this is we actually collaborated with Masaya Kitada, who actually worked in the garage, Japanese horror film.
I think it's the 90s, I'm not sure, but it's a really scary movie there, and he was the foley artist there, and he even actually worked in Howl's Moving Castle animation, so he's really a famous foley artist in Japan.
And so the amounts were quite a lot here.
We have a prox.
We have 700 props there.
And we have some MVNs recording in the foley stage.
And character movement, like footstep, crossing closes, and weapons were also recorded basically in the foley stage.
And the in-game demo, yeah, so the amounts were really a lot.
And we took our PC, actually, to the Capcom stage.
so that we could actually implement really quick.
And, I, and Foley recording for like cinematic scene or in game demo, we recorded like simultaneously by watching, we have a TV screen in the Foley stage, so, you know, just like how they do in a film industry.
Okay, so here's some footage of the Foley recordings.
It's a really short one.
So that's a Capcom stage, and that's me with long hair.
And that's Masayaki Tadai.
It's in Toho.
That's Wataru, right?
Playing with pineapple.
I was mentioning the world.
Here's my best part.
So that was one of the fun part of Holy Recordings here.
And yeah, you see pretty much the scary stuff, Masaya took care of.
And we did simple stuff.
Just kidding.
OK, so continuing on the slide here.
For the equipment gears, pretty really famous microphones were used here.
And we tried some of them, but these microphones really worked well.
Well, the plugins Magnetic 2 was really great, and RX4 was really great, especially.
We really used lots of RX here.
Well, obviously we had a Foley recording, and they have really great denoise and the de-reverb function.
And these were really useful for the props recorded outside the stage, such as door sound.
So.
Okay, that's it for the Foley sound, so I'm gonna talk a little bit on the ambience here.
For the ambience, we have, basically, we have three layers of ambience, and these are, base ambience is just, you know, base, like, really low frequency room tone, and we have 3D positional ambience that's like a water drop from water tap or a wind sound from window, or, you know, something is placed in a 3D world.
And the spooky sound, we named it spooky sound, are more likely a strange sound, like wood clack or rap sound you hear.
You may hear in a haunted house or in Japanese old house, you actually hear this kind of sound.
And it's kind of scary.
And I have some samples for each of those.
So here's the 3D sound, basically.
Geno-wing sound.
And here is some sound from the props.
It's all mixed.
I can't do it.
So the refrigerators, water.
And here's some spooky sound.
And we have a bass tone for the kitchen.
And here's the ensemble of all of those.
Okay, so among of those, the spooky sounds were really, really effective here.
Most of them are actually random sound, but when players are in the area where it's filled with all sorts of natural sound, the more immersed player get, they tend to lose actually their sense to identify the sound they are hearing, whether it comes from enemy or from by themselves, such as footsteps or kicking just bottles or chair, or just simple ambience or prop sound.
So it was really important for us to put many kinds of sound, not to only match these photoreal visuals, but to create the sound illusions to player.
And it's FPS, so it's kind of really hard to identify which sound actually comes.
We know the direction, but it's really hard to localize the precise place.
So we really tweak with those techniques.
So I haven't actually prepared the extra slide for this, but apart from these ambience and props, we also implemented lots of horror sound, which typically were placed and triggered by a level designer.
And the role of these sounds vary from creating an anticipation or to simply shock the player.
And these sounds are something you may not want to hear in the real life, but the sound in the game could give you a clue of what's going to happen next.
So it's anticipation, basically.
And here is some cool slide here.
It's not written here.
Again, we have lots of sound in the game.
But the most effective way to create an anticipation or anxiety was to bring the sound level lower or make complete silence in it.
So it makes actually people questioning what's going to happen next.
So that's actually our.
We really tweaked with the silence a lot, especially with music.
Okay, so moving on to reverb and occlusions here.
We had some simple systems here, but a really cool way to do automatically detect the parameters.
And so the reverb and occlusion changes interactively and automatically depending on the space where sound plays.
It's a sound place.
And when sound playbacks, the system allows sound to detect the space name, which is game object, and then an appropriate reverb set for that sound automatically.
And these functions are also one of our automated systems, as I have mentioned before, for utilizing meshes and collisions in the game.
So occlusions change depending on what object lies between players and sound source.
The ratio change by material of the structure would hear more clear and if you have metal it's more muffled, like that.
Really basic physics here.
And these basic actually reverb parameters were adjusted by mixing engineer at Capcom, Kazuya Takimoto, so I think the reverb is really good too in this game.
Okay, so here's the example of the occlusion.
So please pay attention to a mother emerge voice.
Gets muffled and gets clear.
I am sick and tired of your bullshit, girl.
I am sick and tired of your bullshit, girl.
I need to hide.
I need to hide.
Why are you putting this muffin up?
What have I done to deserve this except open my hole and feed you?
So yeah, that was, I hope that explained.
But really, really simple principle we did in Resident Evil 7 here.
I'm just going to show a little off.
It's kind of handwriting drawing.
So the basic principle of occlusions here in the Resident Evil 7 at least.
So we have on the left side, we have a room here.
And when the sound plays back, sound asks where am I?
Those questions.
And the system tells you you're in the room A.
with the larger and the wooden covered room and the player here clear because there is nothing to distract or there is no obstacle between the sound and player.
On the other hand, you have a similar situation but different setup, so the sound plays but there is a metal ball between so you're muffled.
So it's really, really simple techniques were adopted here.
But it's really done automatically.
Thus, the cost goes down to 1 3rd comparing to RE6, right?
Okay, and because we don't add collisions manually as often as we have done before, obviously there are some places that some designer like me needed to add collisions manually, but that's the numbers were significantly decreased and once, I mean, that took care of optimization as well.
So that's a sound effect part and I'm gonna hand to Kenji and he's gonna tell about the system.
Okay, now let me talk about some of the system and workflow on our game.
We will give you two concrete example in this part.
First one is automated sound trigger.
This is for sound effect, mostly corresponds with animation assets.
There are numbers of cases, automated sound trigger in this game.
Footsteps, rustling of crosses, his sounds are some of the examples.
I will highlight the movement sound such as cross rustle and gimmick movements.
When we have both approaches, dynamic and static.
Sometimes dynamical way can be much better and vice versa.
The system for movement sound uses velocities.
There are three ways to use velocities.
Velocity of any joint, angular velocity by any three joints, and twist angular velocity by any two joints.
Some designers get automated sound triggers by setting thresholds on each weight.
Let me show some examples of automated sound trigger.
So you hear the squeaky lantern sound, and that's also automatically generated.
So there are two cases that how to use automated sound triggers, a one-time calculation and a pre-calculation.
The former is usage of dynamic, and the later is static way.
In each cases, the source of calculation are done in same assets.
First, sound designers check velocity using velocity monitor on each game object while playing with lists of animations or playing game and set thresholds of each triggers on asset.
Next, they set the property of assets on behaviors.
Finally, they also can bake it in animation sequence.
In this way, some designers can brush up and adjust the sequence more precisely.
Runtime calculation affects entire character moving, including blended animation.
The benefit is, there is no lack or surplus triggers, even if it has a complex blend animation.
There is one other advantage in dealing with updating animations.
If animation will be changed, animation sequence need to change or check accordingly.
But because of this system, the triggers are calculated interactively, so no need to keep changing.
It is even possible to polish out easily with the function of pre-calculation.
Triggers which are baked in animation sequence can be added, deleted, and they are adjustable.
I'm sure that some designers do it in their familiar tool.
And finally, the scope of baking can be changed.
We can use the animation sequence plug for to stop runtime calculation temporarily.
Thus, because of automated system, the works of sound roughly ends automatically when animator's process finished.
And sound designers are able to polish them later, as needed.
Next keyword is cohesion.
In Resident Evil 6, we used collisions by meshes and primitive shapes.
We used meshes which had been added by environmental artists for only changing sounds by materials.
For example, footsteps, hit sounds, and so on.
Additional to that, we had used primitive shapes for changing reverb ambience by each room, and also for obstruction and occlusion.
These collisions had been added manually by sound designers.
It's very hard work for sound designers because it was often requested again, and it could have caused spikes when placed a lot.
Things that we had meticulously worked on and spent lots of energy on would constantly go to waste.
It was like carefully building a house brick by brick, and then what someone bruises over it, and build another house instead.
So in Resident Evil 7, we change roles.
We use meshes for all of collision usage.
So we request environmental artists to cut meshes by rooms.
And we use primitive shapes for overriding the effect of meshes.
It's only for limited areas, basically to reduce the reworks of environmental artists.
Okay, let me show some examples of changing ambience and reverb.
Actually, in many cases, sound designers no need to put primitive shapes.
It was such an innovation.
Sound designers are very happy.
Right, Ken?
Yeah, of course, because we needed to add manually and when the spaces and area changes, we actually needed to redo it, so it really helped a lot.
Great.
But is everything okay without any problem?
No, the CPU cost for this way is very heavy.
We get to take care of it.
So I thought about a way to solve the problem.
There are two approaches, thinning out update and updating asynchronously.
The former is simple.
I think I'd update with consideration for sound designers who don't feel gap.
The later one consists some steps.
For starter, triggers of sound in behavior is only in set Q basically.
In this timing, they don't take place of obstruction and occlusion.
Exceptionally, generator of environmental sound are calculated as a sound position in this phase.
In another phase, animation sequence update for true trigger or not, but don't check place and so on.
It's only queuing basically.
The sound module also update asynchronously.
It's broke off the game loop, only with buffer synchronization and setting update task.
Actual updating process will be done in coherence of another processes.
Updating asynchronously is not easy way.
It's a hassle, but it can be solved.
We made it possible and get non-blocking sound system.
We usually having trouble with spikes of collisions for sound, but there was no trouble in this game.
Of course, I needed to take care of those spikes, but mostly it occurred because of another reason, which can be solved a lot easier.
So, within this workflow, environmental artists can brush up until last moment.
And in this area, some designers worked not on roughly ends automatically, but also have some spaces for further modifications and improvements likewise.
And again, spikes by sounds have decreased.
It contributed a lot to make an immersive atmosphere in the game.
I have a favorite proverb, kill two birds with one stone.
In Resident Evil 7, we managed things sometime in this way.
We get two or more benefits with only one solution.
Needless to say, everyone is happier.
Okay, next part is everyone's favorite, music.
So, okay.
Can you cue key?
Okay, here goes music part.
OK, I'm Akiyuki Morimoto.
I will explain how we develop the music.
OK, this clip explains how the in-game music transits and how it interacts with sound effects, such as ambience.
Let's watch.
hear her i can feel her clawing her way back inside of me So, you know, strong balance.
I told you, I told you.
Okay, on the left side, blue area, horror, immersive, realistic world, are the concept for the game.
On the right side, we built music idea that connect well with this game concept.
And we came up with three keywords, which are tones, recording sound, and analog sound.
That eventually leads up to a technique called music concrete.
When we started developing the game, we thought what was the role of the music in this title.
Music, especially underscore type music, are commonly not a part of a 3D world in the game.
But in this title, we wanted to create music that can be perfect match with the game scene and textures, as if it could be heard as a source music, which most of them were not.
We named it.
this type of music, music atomos.
To build music atomos, we concentrated on the tones rather than typical harmony.
For example, microtones, spectral music, and sound textures.
We composed the music using original tones as a reference to technical music concrete.
Music Concrete was developed in France in 1940s.
This music is generally developed from resonance and textures of sound, not always from harmony or basic element of music.
When we created the tones, we prepared some key words that represent the taste of the game.
High temperature and humidity represent the idea or atmosphere of the stage in the game.
The game takes place in Louisiana.
Noise texture and analog sound, they are from the key items in the game.
The character explores mostly in the old mansion, so ruined, dead, silent, derived from there.
Decay comes from a new creature called Molded.
The creature is covered with mold, so it is called Molded.
Yeah, the guy actually, yeah.
It's mold.
Black map.
This shows the basic flow of music development in RE7.
For composing music, we made a careful preparation.
At first, we recorded elements for making tones.
And then we create original sound library with editing these tones.
And finally, we composed the music using the original sound library.
OK.
To create original sound library, several recording sessions with total of 10,000 tracks were recorded.
These are just like a sound palette.
It is like a drawing in campus, but in music.
OK.
I'm going to briefly introduce about each recording session.
I will give you some unique hearing examples.
First one is quarter tone cluster.
And here goes super low cluster.
Okay.
And we recorded three people's voices in total.
The concept is creepy human noise, like Japanese horror film Grudge.
Do you know Kayako?
Uh...
We have lots of Kayako.
Uh...
This sound is death scream.
And next is throat sound.
Next, we recorded many kinds of real organic sound.
So many unique sounds recorded by the Hachenda Creative.
This example comes from the bee noise.
Buzzing.
Yeah.
OK.
We built different tones for each character, rather than building a music theme or a music piece for each character.
We used Mind Map to start up to find out the best matching sound for that specific character.
This mind map is for Jack, who is a quite cool guy from the Baker family.
Yeah, welcome to the family.
Okay.
Okay, so far I talked most about the recording sound.
From here, I will focus more in creating and how we edit tones.
We built the original music software, named it REM, which stands for Resident Evil Music Module.
It runs in contact instruments with basic functions, such as simple editing, process effect, and so on.
This system allowed the composers to build tones.
with more flexibility, especially because of Raymer control with a good usability and very friendly operation and function.
I have prepared a clip to show how RAM looks like.
This is RAM.
There are main, mix, and master windows, and different parameters in each option.
Now changing attack speed.
Then, let's change the value of the revolve.
Next is changing delay.
And the final part I'm going to share is still a spread to change, narrow sound.
To wider spread sound.
So, believe me, it's different.
Maybe this, I don't know, we have a big room here so that our sound actually spreads.
So we created our original tones utilizing this system.
Oh.
Okay.
These are some other plugins which really worked well in music development of RE7.
We often use sound toys plugins.
For example, Crystallizer, Echo Boy, Pan Man, Decapitator.
And Nomad Factory Magnetic 2, it's a tape simulator.
One last thing we would like to mention is that we used lots of analog sound from a tape.
It helped to boost more mid and warm tones.
that I think definitely helped to build and create a peaceful moment. ♪♪♪ ♪♪♪ ♪♪♪ ♪♪♪ ♪♪♪ This music can be heard at a safe room where you don't get attacked from creatures or enemies.
Okay, that's all for music part, and I will hand back to Ken.
So our last part, we are going to show a little bit of a little talk on how we worked with a level designer here.
So here's cool level designer, and they're really cool.
And we have Koshi Nakanishi, he's the director there.
And he actually gave a talk on four o'clock or something.
Is Koshi here?
He told me he will be here.
Koshi-san.
Ah, hi, Koushi.
Hi, Koushi.
Hi.
Ganbarimasu.
OK, so yeah, we have Koushi.
So we have a good guy here.
OK, so we really especially worked really, really close with level designer in this project.
I just want to mention that we do work close with level designer planner in Capcom, in other project too.
But typically this title, since it's the horror game, the role of sounds were kind of large.
So.
We really concentrated on working with Level Designer here.
And we actually prepared some systems that allowed Level Designer to tweak and readjust the horror sound by themselves.
These tools actually vary from just play one shot sound or move that sound object or even setting the state of the game to change music or volume of ambience.
So we had some tools for the Level Designer as well.
And here's a basic, really, really primitive workflow that I want to show here.
So basically, level designer, of course, mainly designed the game.
And with the audio team, we had a really good relationship with them, so we shared our ideas, tips.
especially to make sound like source placement, to connect well with level designing and stage.
And because of nature of the sound, I think we are really good at, good on like tempo, timing, because sound is linear.
And we deal with the dialogues too, so in this part we are really good at, so we really talked a lot with them.
So we also, actually it was kind of cool, we also suggested to make complete silence to enhance the horror sound coming up next.
So that's pacing again.
So at the first, we have pre-production, gray box testing, those periods.
We prepared some placeholders, like temporary asset, and let level designer use really freely.
I mean, they could do anything with those sound.
And within these assets, everyone is really clear in the team that we could see what's going to happen next and what.
they want to do and what we want to do.
So it was really good to share, I mean, working this type of way.
And for the second part is the iteration.
We have a lot of.
iteration, of course, in Resident Evil 7, too, so we really had to go over work and stuff like that.
And this is the timing when we see if everything really makes sense and for that particular places within placeholder and stuff.
We still don't really make a real asset yet.
The placeholder is pretty much being used here, but maybe some...
change has been done usually and really really lots of like gigantic huge amounts of Communication and discussions are needed at this point, and it's really cool kind of we are I mean house team so Actually the re7 team was just below our floor So we could just go and talk to them and hear it's here is wrong and here It's cool, and you know stuff like that, so we really had a healthy conversation with you within really nice in-house environment And the final phase is, of course, is to prepare the actual asset for the audio teams.
And many refines and many readjustments has been done up to here.
And we share, hopefully, our goals from very beginning to meeting all members of the team.
So we are kind of clear.
And it made us easier to work in a relatively larger team like this.
So yeah, that was just a basic workflow here.
And actually that wraps up our talk here.
So just want to thank you once again for being here.
And it's really great for us to give a talk in GDC.
And, uh, Arigato gozaimashita.
Arigato gozaimashita.
Arigato gozaimashita.
Thank you very much.
Hopefully we will have some time for Q&A, but we have put our email address over there, too.
So if you have any questions, or maybe deeper questions, maybe you guys can ask on the spot, we'll be here at GDC tomorrow, too.
So if you have simple questions, that would be much better for us.
But I may need to translate.
So that's OK.
So if you have any questions, please do so.
Oh.
That's good.
Or maybe a little sad.
Director Nakanishi.
Oh, director.
Ask us later.
Japanese?
Japanese, no. It's America here.
Sorry.
No, no, no. Please, yeah.
Of course, yeah.
The best scene we like?
Okay.
Ah, so the choice between Mia or Zoe.
So there is a scene in chapter 3, or I mean, yeah, in middle part.
So you have to choose either Mia to save me.
I'm sorry, I'm spoiling for some, but you have to choose little, I mean, you have to choose Mia or Zoe.
That's the other girl there.
So that's, yeah, that's right.
Yeah, that's, that's nice part.
Yeah.
What's your Kenji?
Kenji.
Kenji.
Kenji.
Kenji.
Kenji.
Kenji.
Kenji.
Kenji.
Yeah, my favorite is Jack Chase's Ethan.
That's nice.
And the other four.
OK, yeah.
That's right.
That's a really nice one, too.
And my favorite is the garage.
I mean, you're driving the car, and you're actually killing Jack by hitting the car.
So that's cool, too.
Oh, sorry.
So is there any other questions?
I'm sorry.
I'm sorry.
Sorry for being.
Are we out of questions?
Or are we out?
Oh, I think I answered my question, so please.
I mean, I answered my answer, I'm sorry.
Oh, no, no, no, it's fine.
Jet lag, jet lag.
No, it's okay.
So, my name's Lenny Moore, I'm a composer.
So, thank you guys for coming all the way from Japan.
Thank you very much for inviting us.
It's such a pleasure to see you share what's going on with your team there and your great work.
So, it's just a comment.
Oh, thank you so much.
Oh, so nice of you.
Arigato gozaimasu.
Arigato gozaimasu.
So I was wondering, I love the game and the sound design is amazing, what do you think was the thing that you guys didn't feel happy about or that you thought you didn't do well and you would like to do better for 8 or whatever your next project is?
Okay, I think Kenji will answer that part.
Propagation deflection more definitively.
Yeah, more precise location, like more system side of the early reflection and...
Yeah.
Is that it?
Yeah.
Okay.
In the system side we want to do that.
And also I asked Kenji to build more...
I mean, his tool is really amazing, it's really friendly use.
a little more friendlier.
But you know, I'm a sound designer, so I don't code, so please help us.
I hope I answered my question.
Yeah, that's great.
Thank you so much, appreciate it.
Maybe there is a key.
I'm sorry.
Oh, you can ask.
Go ahead.
Oh, yeah.
Thank you for your presentation.
I thought it was very interesting that there were two particular sounds in the game that came from earlier Resident Evil games.
Oh, I see.
The first one was the key panel.
Oh, you noticed that.
OK.
Yeah, you noticed that.
Resident Evil 3 and one of the ending themes rearranged.
That's right, you noticed that too.
Ending team rearranging for that.
We actually used it intentionally.
Yeah, we tried, yeah we tried.
Actually it was Wataru's idea to put the old UI sound on the keypad we were actually doing.
You still have that library?
Really deep.
You go like a dungeon and you just grab this masterpiece of Faber-Sachs.
I hope I answered your question.
Oh, I'm really bad at it.
Thank you guys so much for being here. That was amazing.
Did you guys develop for VR at the same time?
So it was all just along the same timeline?
Yes, actually, VR was developed almost at the same time.
uh... uh... it's not well-sounding and to answer the yeah okay and so did you guys think any different approaches to that and if i can if you can answer it what you guys use course of course the audio for the uh... actually the prospect on the audio didn't actually necessarily, I mean we didn't focus on the VR side much because every sound is in 3D positions that actually took care of the VR part but for the most of the VR players they are going to use headphones so we have virtual surround features in the headphone and what else and actually we have some musics are actually binaural.
by no running things.
So in some approaches, we did.
But most of the part, actually, our audio workflow took care of the VR version as well.
We really tried to nail.
I mean, we tried to put lots of sound in a 3D world.
And that actually helped a lot.
We attention this program in early phase.
So we prepared for.
That's right.
Yeah, we actually.
thought, or we guessed, actually, the problem is going to come later on.
Because we weren't sure if we were going to build a VR version or not.
Actually, at the really early phase, we don't know about that.
So we actually thought the solution for that.
Thanks. Also, I'll do a little plug for you guys, but Resident Evil 7 is Amazon's deal of the day.
So, pick it up if you haven't. I just bought it.
Thank you.
Thank you.
Thank you.
Excuse me, but this is Japanese.
Ah, of course.
I was going to ask about VR, but I was asked first, so I'll change the question.
When we make games in a small studio, the sound direction is done by the director or the planner.
It's really hard. But when I watch Resident Evil, the sound is perfect at the right time, the music is perfect, and it's amazing. I'm really impressed, but who decides when to make this sound?
How do you do it?
OK, I need to translate that.
Yeah, please.
OK.
So yeah, his question was, he's Swery, and he runs a studio in Osaka.
And yeah, Swery, yeah.
Yeah.
Yeah.
Yeah.
So yeah, we have a big guest here.
We have a Nakanishi-san, and every director is here.
Well, anyway, so his question was that he runs a relatively smaller studio, comparing to Capcom.
And he thinks our audio was really nicely done because of the audio director.
I mean, we have audio director, and we have this working pipeline here.
But unlikely, like his studio, they don't have audio director, so is it sometimes hard to figure out where to put all the sounds and the quality lines and stuff?
I think you will get the exact answer with Wataru.
So maybe we can talk with him.
But I believe, I think it's because we have a really good relationship with a director and audio director, and of course other lead.
We have an art director and all the leads and they have really good...
And level designer, of course.
So we have really, you know, we have these systems to talk, like, see, like, I mean, we see every guy's face every day and we go lunch with them and these kind of really healthy relationship, you know, eventually.
Right.
Okay.
Yeah.
Hope I answered my answer.
Oh my.
Yeah.
Yeah.
We need more drinking.
Oh yeah, that's right.
That's right.
Let's go, let's go.
Let's go drinking.
Thank you very much.
Thank you.
Thank you, Serif-san.
It's really good to hear.
Okay, that's all for today.
So thanks.
Oh, we're actually passing.
Oh, so I really appreciate, thanks for being here.
And we're super, super happy that we could give a talk and hope we did fine.
So yeah, please ask us any question if you have any thoughts, questions, suggestions, or I mean, emails up there.
And we have a business card here too.
So please do so.
Okay, thank you once again.
Arigato gozaimashita.
Arigato.
