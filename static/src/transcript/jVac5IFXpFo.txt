Welcome to the audio bootcamp. I'm really excited to be here talking today about signal processing for sound design.
My name is Peter Zenda. I'm a supervising sound designer at Formosa Interactive.
I've been working in audio for about 20 years.
I divide my time between games and movies, although in the last five or so years I've really been concentrating on games.
You can see some of the projects I've worked on recently.
Even though the title of today's talk sounds very technical, what we have today is a creative focus.
I really want to talk about how to use technology to achieve your creative goals.
When you're working on sound design, it is not a technical discipline, it's a creative discipline.
Our jobs as sound designers...
are to support a scene, they are to tell a story, they're to build a world, make an item like a weapon feel real and visceral.
We are creating performances, if we're working on a creature or something like that.
And so we use technology to do our work, but the work itself is actually creative.
So we don't want to get too mired down in that.
Right now is an incredible time to be a sound designer.
There are more tools out than we've ever had before.
Our computers are more powerful than they've ever been.
We're able to process more at one time.
We're able to do it more quickly.
There are many tools out there that are very low cost and sound great.
And so it's really like I'm excited to be a sound designer right now at this time in history.
It's a lot of fun.
One of the great things about using plugins and signal processing is it has a transformative power.
We're no longer shackled to what's in our library, what we recorded, what we might happen to have around.
We're able to use that material as raw source and process it and turn it into something that is perfect for that specific project that we're working on.
It's a lot of fun to be able to take something and use your own creativity through these tools and turn it into what you intend it to be.
Why do we use signal processing?
One great use for it is to respond to the team or the client's needs, depending on if you are an in-house person or a vendor like I am.
Sound design and game design is an iterative process. You're going to be making things, putting it into the game, seeing how it all works together, discussing it, getting feedback, and having a command of digital signal processing can allow you to respond to those needs.
You might get a comment to make something brighter or crunchier or deeper or bigger.
There's a lot of adjectives that are going to get thrown at you.
And if you can take those adjectives and translate them into something you can do with EQ, dynamics, things like that, you don't have to start over from scratch and make a whole new sound.
You can also use signal processing to rescue sounds that are contaminated with noise.
I do a lot of recording and I encourage all of you to get out and record as much as possible.
I don't always do it in a perfect environment.
Not everything I record is suitable to go out and be on a library or a CD library, anything like that.
It might be contaminated with traffic or machinery.
There's all kinds of sounds that are out there in the world and they're interesting, but they're not in that perfect, perfect place.
And if you use something like noise reduction plugins or a multiband expansion, you can actually kind of rescue those sounds and use them in your design.
You can also take sounds that might be the right thing, but it's kind of an old recording, and you can shine them up again and use those sounds in your sound design.
You can also use signal processing to simulate distance.
I would caution you that that a lot of times is best used, saved for later in your process.
If you're making game assets for a game.
that could be used in a variety of different environments, right?
Like your gunshot or impact could be in a giant hall, or it could be in a tight hallway.
So the game engine is going to do a lot of that for you.
However, you might be working on a cinematic, and you need to create a train crash that's happening in the distance.
you can use reverb and EQ and delay to achieve that effect.
Or you might be making a game asset that's supposed to be off in the distance.
Using the right combinations of things can make that feel real and keep your player immersed in the game world.
Another great use of signal processing is to adjust how the various elements play against each other.
The sounds you make are going to have a lot of competition out there in your sonic landscape.
There's going to be music, combat maybe, machine guns, explosions, screaming, and there might be an event that's happening at this level of the game that is really important to get across to the player.
one of the ways that you can make sure that event pops out and gets their attention is look for where in your frequency range you've got a little hole, some room to work in and boost that frequency.
There's a lot of other ways to achieve that also through ducking and mixing things like that.
And then kind of the holy grail or one of the most exciting things about it is creating unique sounds signature sounds that nobody's ever heard before that they are only going to associate with your game I know if I really like a sound or like a game I could hear that audio ten years later totally out of context and I could be like oh yeah I remember that, I remember that level and uh... that's one of the most fun things we can do uh... being sound designers is really create a memorable experience for people So you can see the building blocks for sound design.
We have a number of different types of processors, and these are the fundamentals.
These are your building blocks.
You can use EQ, adjusting the frequency content of your sound, dynamics, adjusting the amplitude and how wide that range is.
Pitch and time shifting become very important for creating a performance.
If you're making a creature sound, the right pitch bend may make it really feel like that creature is dying and whether you're happy that creature died or not.
We can use reverb and delay.
Again, a lot of that is best saved for later in the process, but you never know.
And then there's been a real renaissance of saturation plugins that have come out recently in the past few years That affect both the frequency content and the dynamics of your sound the interesting thing about these is You know you it used to be you had to use tape or you had to have a tube processor to get that sound And there's some pretty convincing ways to do that now And in a way, I don't really care if they're necessarily faithful to the original.
I just want to know if they're useful for me.
So that can be very useful for making things sound bigger or for taking the edges off things.
The interesting thing about tape compression was that it didn't affect all the frequencies equally.
So if you have something like Foley that has two sharper transients, running it through a tape simulator can be very useful.
We also have noise reduction.
I can't stress enough how amazing the tools are that are available to us now to clean things up using software like iZotope RX or even multi-band expansion as a noise reduction.
We can use modulation plugins, which are getting things moving and changing over time.
I think that's a great way to keep people's interest.
You know, anytime something is developing over time, it's a lot more interesting to listen to.
And then we have a broad category of manglers, what I'll call manglers, or things that are more extreme, like morphing and granular synthesis, and we'll talk about some of those today.
And then you can put these together into plug-in chains, which are using more than one plug-in to create a cohesive effect.
This is where you're going to use all those fundamentals, all the other pieces and elements to create something new.
And I'm going to go over some examples of plug-in chains as a way to do sound design in these next examples.
So I'm going to call this example metal magic.
This first sound is dry ice on metal, which a lot of you being sound people probably know about but for anyone who doesn't, if you apply dry ice to metal it will shriek and scream.
And I find the best kind of metal props to use for this are something that's thin enough to resonate.
So a lot of times if we're working on magic, having a tonal element to that can be very useful.
That's going to be our raw material.
I'm going to start this chain with a plugin from Tom Irby of Soundhack fame called Spiral Stretch.
This is a time expansion plugin.
What's interesting about it is it allows you to have multiple voices of that sound going at one time.
There's a certain amount of randomization to it.
and what can happen with these tonal sounds that are changing over time and then you have multiple voices of those happening, you can get them kind of harmonizing with each other in a musical way.
So the initial sample was pretty recognizable as metal.
Now we're getting it out of the realm of our everyday world, something that sounds like we haven't heard it before.
Now, some of you may have used Absynth as a synthesizer.
It's also worth noting that you can process sounds through it.
This is going to be using the Cloud Filter in there, which is a combination of granular synthesis, pitch shifting, and filtering.
So now we've taken that sound and really kind of made it sing.
It's got more tonality to it, more harmonics.
And it's getting outside of the realm of something we've heard before, which we can associate more closely with magic.
And as the final step, I'm going to give it a little extra shimmer with the crystallizer.
You can see this is a very dry setting, not much of this new signal there, but I'm adding pitching delays that are going upwards in pitch with a fair amount of feedback.
And you could take that sound and use it as a power-up for a spell that's going to be cast.
You can doppler it and use it as an attack spell.
You could attach it to some kind of mythical creature.
And so the more you can make these kind of magical sounds and rely on signal processing, you'll kind of expand your palette there.
Another sound you're going to have to do a lot of in game design is weapons.
My feeling about weapons is that microphones capture the sound, but they may not capture the experience.
For example, if you go to a shooting range and you fire a 9mm, you're looking at about a 160dB SPL peak.
You're going to be wearing hearing protection, hopefully, and I'll tell you, nobody wants to wear hearing protection while they play your game.
If you see a movie and you played that perfect recording back at the maximum volume, you'd be looking at about 105 dB.
That's about the loudest sound you can play back in a properly calibrated theater.
Louder if you're close to the screen, of course.
In the living room, you're looking at about 70 to 100 dB, depending.
People tend not to play your game at a level where their windows are rattling.
The other thing is, you know, our sounds are not just conveying the sense of sound.
If you fire a gun, it's going to kick against your hand or it's going to kick against your shoulder. It's a very visceral experience and that's what people remember. That's what the game designer on your team is going to remember. That's what the players are going to remember.
So we need to use sound also to convey that feeling of touch.
DSP can help you capture that 160 dB experience at a lower level.
So we're going to start with a recording of a machine gun.
And I know we need to be considerate of our neighbors, so this is maybe not going to be as loud as we would like.
So that's a very nice, realistic recording.
Sounds pretty good.
But even if we put music against this, a lot of that detail is going to get lost.
So the next step in the chain is going to be some tape saturation.
A lot of the gunshots you're used to hearing in movies, certainly going back a few years, were recorded on Nagras because they had that awesome tape compression characteristic.
They had those incredible Nagra mic pre's and they just gave it something special. This is going to compress the high end a little bit more and it's going to let you push the mids and the lows.
I hope this is going to come across here.
Again, this is a little subtle, but that effect is going to be magnified further down our chain.
You'll find that you can make subtle changes at the beginning that are then going to get magnified by things that are later.
Next, I'm going to do some limiting on it.
I'm using both the Waves Ultra Maximizer and the Multi Maximizer.
I like the Ultra Maximizer because it lets you choose from a number of different profiles.
This one I'm using the Extreme Analog and you can tell the threshold is only at minus 2, so I'm not really boosting that sound a whole lot.
And the Multi Maximizer will maximize it across all the frequencies, so you get something that's more full range overall and louder in all the frequencies.
Again, this is not too extreme, you don't want to hurt yourself with these.
Next, I'm going to apply some EQ.
Why do we as sound designers have so many EQs?
They all do the same thing, right?
But not exactly.
Like, people are always looking for that holy grail EQ.
People love the Pultec EQ, and you'll see a lot of both hardware and software emulations of that classic EQ.
You'll see it on Foley stages.
You'll see it in music recording studios.
This is my current favorite.
It's made by Nomad Factory.
They call it the PulseTec EQ.
I basically use this if I want one of two things.
If I want more sizzle or less sizzle on something, the high-end shelving EQ is great.
Or if I want to add more beef to something.
It's not a clinical EQ at all.
Now, after we're done kind of boosting all this stuff up, one of the things about designing weapons for games is a lot of times a gunshot will have a tail on it, reflections off of all the surfaces it was recorded around, but we want to have that gunshot.
and get out of the way. After we're done firing the gun, that gun isn't really relevant anymore.
What's more relevant is the shots that are coming in toward us, people screaming, explosions, maybe us reloading the gun. So we can use a transient control plug-in to dial down the tail on that and let our beefier gunshots come out.
You can see the tail on that is, certainly in this environment, almost entirely gone.
The Native Instruments Transient Master is an incredibly powerful tool with three knobs, one of them being gain.
I'd encourage all of you to experiment with that.
And then if we keep this chain exactly the same and pitch this, we can come out with a totally different gun.
Sounds like a completely different caliber.
The same kind of processing will work for impacts also.
Here is a realistic stab recorded on the Foley stage.
Pretty cool, has a lot of nice detail to it, a lot of nice gush, some blade in there, but again if you are playing a game where there's a lot of foley and running around and explosions and gunshots and music going on, you may only hear the top couple of dB of that sound, everything else may be lost.
So you'll want to bring out that detail with those same kind of plugins.
Now it's almost like, you know, we can hear the cartilage ripping in there.
So this is the violent section of today's talk.
So next I want to talk about how to take a very mundane sound that we're all so used to hearing that we don't even hear it anymore and turn it into something totally different.
We're going to take a refrigerator and turn it into a force field.
This is like the nastiest picture of a refrigerator I could find.
Looks like, you know, I'm afraid to open it.
I don't know what I'm going to find in there.
So here's the original sound.
You can hear it has like a little bit of a low end throb to it.
Some interesting frequencies.
Next I'm going to use another of Tom Irby's plug-ins called Pitch Sift.
And I'm not even going to be pitch shifting with it.
It has a partial gate control on it that's pretty interesting.
It allows you to let the more dominant frequencies come through and it's going to filter out any of the low level detail.
Some of that low level detail is what makes it sound real to us.
It's like what our ears are used to hearing and if you take that away already it's going to sound like something we haven't heard before.
If you listen, this sound has a very strong whine or fundamental frequency to it.
You can see what that partial gate is doing here.
On the left is the original sound and on the right is the processed sound.
Now I'm going to take that fundamental frequency, that whine, and I'm going to use...
filter freak to notch that out. I'm going to put a band reject filter right at that frequency, but I don't just want to get rid of it. I'm going to actually use that low-end throb that's making the volume go up and down, and I'm going to put an envelope follower on the frequency and modulate that, so that part of the time the band reject filter is going to be getting rid of it, part of the time it's going to let it go through. We do a lot of additive EQ, but you can do some really cool stuff subtractively as well.
Next I'm going to apply a pretty simple delay effect.
These are very short delays which can give you a robotic sound.
Now let's take it another step further.
We're kind of getting more into the sci-fi realm now.
It's starting to feel pretty good.
We're going to use a little bit more absinthe on it.
This is running through their Super Comb processor.
You can hear as the comb filter is filtering out various frequencies and that's kind of modulating around that you're getting some singing frequencies, some frequencies that were fighting with each other aren't anymore and they're allowing a little more low-end to come through.
And that might be a really great effect for a level where we are exploring, where we're not in combat, where we can have some suspense and have a quiet moment.
But maybe it's not that kind of a scene.
Maybe we need to have something with a little more edge and be able to compete with a few more sounds going on at the same time.
I'm going to start with the FabFilter Saturn.
It's a pretty useful plug-in that allows you to do saturation and distortion in a multiband kind of way.
What I also really like about it is you can have modulators.
And what we're going to do here is modulate the crossover frequencies of the band that I'm putting the saturation and distortion on.
That's going to allow that band of distortion to sort of move around based on the LFO.
And after that I'm going to run it through the BlueCat MB7, which I'll show you after this.
Already that saturation and distortion is giving it a more aggressive or edgier sound.
What I like about the MB7 is it allows you to use VST plugins in a multiband way.
So it splits the sound into four frequencies and allows you to put two VST plugins on each frequency.
And the other cool thing is I'm a Pro Tools user, it allows me to use VST plugins inside of Pro Tools.
What I'm doing here is applying some compression on the very low frequency.
I'm keeping that low-end rumble from eating up my headroom.
and I'm doing a little bit of chorus on the low mids and leaving everything else alone.
So just to play that example again.
You can hear the chorus thing going on there in the low mids.
Next I want to talk about focused low-end enhancement.
It's awesome to have these big hits or stingers in your sounds that have a ton of low-end, really give you a lot of impact.
We don't want that impact to rumble out and potentially interfere with something that's going to be happening after it.
We want it to stay very punchy.
So I had an opportunity a few years back to do some train coupling recordings.
Worked with an awesome guy who was with the railroad and was able to do it in a very safe way.
Here's that raw recording.
Now, I know I'm going to be enhancing the low end in this, so I'm actually going to filter out the low end after that impact.
I'm going to use a multiband expander. I really like Ozone 5.
And I'm going to let the low end go through on the impact, and then I'm going to let it die out over that interesting metal detail.
So you can hear, I hope, how clean the end of that is.
Next I'm going to add some beef. I'm going to run it through the Waves Multi-Maximizer and I'm going to use one of those saturation plugins I talked about.
This is the Voxengo Vari-Saturator. It's a dual-band saturator.
Can really be great for adding beef to your sounds.
And I think we're getting some rumble from the next stage over, so that's an interesting timing for that.
I think that means we get to play our songs louder, right?
Yeah.
There are two low-end enhancement plugins I like from Waves.
There's Renaissance Bass and Low Air.
Renaissance Bass actually adds higher harmonics to things that give you more of a sense of low-end through smaller speakers.
And Low Air adds a lot of those really, really low subsonic frequencies.
I find it's really useful to use them in series, to actually run through Renaissance Bass first and then into Low Air.
And you get these.
you know, harmonizing low-end tones that are pretty cool and they're great for this.
They're also really awesome on creature vocals.
I'm just going to play that one more time since the rumbling stopped.
So you can see there is actually a lot of rumble all the way through to the end of this one.
And I'm going to do that same process again. I'm going to use multiband expansion to let it hit and then get out of the way We work on a lot of things that are very fast paced We need to like hit and then maybe a few frames or you know seconds later We're going to have another hit right after that So this can be a useful way to make sure that you're not kind of falling all over yourself with impacts running into each other Next, I'm going to talk about granular synthesis.
It's somewhat esoteric, but none of us here should be intimidated to play around with it.
What granular synthesis does, it divides your sound up into grains.
Those grains can be a second of your sound, it can be just a few samples of your sound.
There's a lot of granular...
plugins out there. They allow you to control how big those grains are, where the start and end points are, how much pitch variation there is, if you want pitch randomization, how many of these grains are playing at one time, how much feedback there is in that, like if you're pitching downward is it going to keep pitching downward more and more.
and also some of them will allow you to quantize those pitches.
So granular synthesis can get really atonal really quickly and the quantizing granular synth can let our western ears attune to something that's more on a musical scale.
It can be really useful for creating steady sounds, backgrounds, or anything that needs to loop.
I think we're out of the era.
One of the first games I worked on, we had to create background loops that were one second long and did not sound repetitive.
So granular synthesis would have been a great thing to have at that time.
It's also great for engines, for turbines, machines.
We'll see some other examples.
And obviously you can create really bizarre sounds using granular synthesis.
So here's an example where I'm going to take a sound that you could not pull a loop out of to save your life and I'm going to make loops out of it. I worked with Scott Gershon and his neighbor is a pilot and invited us to come over and record the jet that he pilots. So we went over to that hangar and we recorded some sounds that were something like this.
So that pitch is changing all the time.
There's really, there's no way traditionally to loop that.
I'm gonna use a plugin from GRM Tools called their Freeze.
And what that allows us to do is load a certain amount of that sound into RAM and then choose how much of that we're going to play back.
We can be very tight with it so it's just a few samples.
This is set up to have 16 loops of that grain playing back at one time and there's a certain amount of randomization between them so by kind of piling those layers up together we can create something that doesn't sound like it's repeating.
and I was able to pull out a number of loops at different RPMs.
It's awesome if we're creating something and we get to go out and do custom recordings for the game and we're going to get steady RPMs at various intervals, but you don't always have that to work with.
And here's a way you can sort of pull out those kind of assets.
So again, that doesn't work perfectly for everything.
Might not be great for a car, but for something like a jet turbine, it actually works quite well.
Now we're gonna kill two birds with one stone and talk about whooshes and granular synthesis at the same time.
You know, you're gonna be called on to create a lot of whooshes in your career, a lot of things moving through the screen or attacks that are gonna move out or away.
And you'll.
You know, it's been happening for years, people use animal growls as a source for that.
You're probably not going to play this in a way where you can actually hear it, it's just going to support another more organic sound.
So we're going to start with a tiger growl.
And by using the freeze plugin, I'm actually going to kind of perform with it.
I'm going to move the grains around and I can create a whole bunch of steady source that I'm then going to be able to run through a Doppler.
So, this still has the characteristic of the growl, it has some of that vocal quality, but it's steady enough that we're going to be able to make whooshes with it.
So here's my Doppler chain.
You're going to see a lot of different plugins there.
The linchpin, of course, is the GRM Tools Doppler.
The salty grain is giving me a little bit more variation.
You can see in the lower right, I'm using a plugin called DMG Pitch Funk that just has a long, slow LFO moving the pitch up and down.
I'm doing dynamics processing to sort of bring it out after it goes through the Doppler plug-in because it can be very peaky I'm doing some saturation with the FAD filter Saturn I'm using some the plug-in mix octaplexer. It can be really useful to have Something that's an octave down. So it's harmonically related to your material but supports it with more low-end If I'm doing Dopplers, I really like to have an envelope following filter after them Some of that is built into the Doppler plug-in itself But I actually find it's useful to have another one that I have control over It's nice that it makes it feel like it's further away when it's on the further away part of the Doppler But also that filter opening and closing can have a vocal quality That can just make your material that much more expressive I am using some chorus on this.
Again, not appropriate for every project, but for something that allows you to be a little bit sci-fi that can give it more motion.
Doing a couple different kinds of low-end enhancements.
And the other nice thing is if you're using Nomad's Magma plugin, it has an entire modulation page in it.
So I have eight different LFOs assigned to different parameters, such as how fast the Doppler is moving, how much the pitch is changing, I'm varying how much low-end boosting I'm doing.
and anything you can do to get it moving, like just get things changing over time, you can run that for five minutes and come up with a whole variety of material very quickly.
So here's what that material sounds like going through the chain.
Here's a few different examples of the whooshes you could get from that.
So those would be great on a spaceship or maybe things flying past the screen if you're going through a wormhole through space and time.
That kind of stuff, granular synthesis and Doppler can create a whole range of interesting things for you.
Another plugin you can use to create some interesting new raw material to work with is Morphing.
This is where you're going to combine frequency and amplitude information between two sounds.
Just as a tip, I find it's really useful to have independent pitch control over those two sources.
Wherever you have common frequency content, that's what's going to go through the morph.
If you don't have much in common between those two sources, not that much is going to come out.
So being able to either have those on a sampler or have a pitch shifter, I'm using loopers for this, and I'm able to control the pitch of each of those independently.
And what I like about that is it lets me record for a minute and pull out all these little gems that are going to pop out of there.
So this is using my voice morphed against itself.
I'm not going to play the original source because that would just be embarrassing.
But so you know this is just two human voices at different pitches interacting with each other.
you So, you know, you can create a whole range of things.
You can use two voices against each other, animals and human voice, animals and other kinds of animals.
You can combine it with metal sounds, things that are tonal tend to sound pretty good when you're using the morphing plugin.
Here's another example where we can take an evil laugh and morph it against some more metal.
Hee hee hee hee hee hee hee hee hee hee hee hee hee hee hee!
And this is just a metal rock recorded at the Foley stage.
Through the Morph plug-in.
A lot of times we're going to be asked to work on an object that needs to function like a character, whether it's a ship that's going to creak as it's sinking, or a door that's going to open, or a robot.
Being able to take something that has a human element and apply it to those more organic sounds can give you a very expressive result.
As I said, it's important to get things moving adding modulation to your chain can really Catch people's ears anytime you can have change over time. That's very useful. It's great for creating power up and power down sounds the other thing you'll find that I do and a lot of sound designers do is load up whether it's synths or Sound elements going through a whole bunch of different chains that you're just improvising and playing around with different parameters and sounds You might record five minutes of stuff, and 98% of it is totally unusable.
But maybe 2%, maybe you're finding a sweetener for something that's a second long or three seconds long.
Don't be afraid to do processing that's really extreme and then pull out little gems from that.
You can add modulation in your DAW. I find it's really helpful to have a control surface to do that you can also modulate parameters in a host such as Nomad Magma or Vigil from plug. I've been using that a lot lately. It's pretty interesting. I'll show you a screenshot of that later Also, there are plugins that are just made to modulate like the Doppler plugin So we can use modulation to create comedy.
Not everything you're going to work on is going to be a super aggressive, dark world.
Sometimes you might be working on a kid's game or something that just needs to have some comedy to it.
These are some pretty flat-sounding raw metal hits.
Again, recorded on the Foley stage.
We're going to add some pitch modulation.
I actually have two LFOs going here at different speeds.
That's going to give it more warble.
And you don't have to just grab from those old, overused comedy cartoon libraries.
You can create your own stuff pretty quickly and easily.
So that could be a character bouncing around on screen or one of a number of things.
Technically, part of what made that funny was the sustain part of it pitching up and down so I've used some tape compression and transient modulation to bring out the sustain there.
A quick note, always save a rendered copy for later.
That plugin you're using now might not work five years later when you're doing the sequel.
And also, it's always good to save an unprocessed copy of what you're doing.
I'll put a muted region nearby in my session in case you need to unwind that.
Always leave yourself a trail of breadcrumbs.
You can save your chains in a number of different ways.
Pro Tools will actually let you save track presets.
That's an undocumented feature.
You can Google it.
but it allows you to save folders of track presets.
This is, you know, I have a bunch of different reverb boxes.
This will call up the 480 and Altiverb.
You can save chains in something like Nomad Magma.
This actually allows you to load up a bunch of different plugins into it, both VST plugins and its own.
And you can save that as a preset.
You can use a program like PlugVigil that lets you have all these plugins as building blocks and draw signal chains between them.
And you can also use the VST rack in SoundMiner as a way to save things.
And that's what that may look like.
I would be irresponsible not to tell you in this talk, don't over process.
If you have the right sound, use it.
The correct organic element, if it works, just doesn't need to be messed with.
Some of the best things you're going to find are coming from the natural world.
And then what you really need to do is automatize, right?
This is your learning process.
You need to master the fundamentals until they become automatic.
You don't want to break your creative flow thinking about how am I going to achieve this?
They just become automatic parts of your workflow.
You reach for that right EQ or the right plugin.
Your goal is not to be thinking about technology, it's to be thinking about the scene, the level, the weapon, the character, all that kind of stuff.
You want to get the sound in your head, or the director's head, or the game designer's head coming out of the speakers.
Whenever you have downtime, that's your time for experimentation.
You're going to find things that surprise you.
Get outside your comfort zone, download demos, combine things together.
You're going to find all these happy accidents that you're.
you know, when you're not on a deadline.
And then the key there is to turn your experiments into something you can use intentionally.
That's where the art of it comes in.
Finding the happy accidents, filing it away for later, saving that preset, so when you're in a situation where that is the perfect thing for your scene, you can call it up and use it.
That's where your art comes from as a sound designer.
So that's the end of my talk today, and I'll open it up for any questions.
Oh sure, come up to the mic if you have a question so we can have it on the tape, the recording.
Do you have any examples of how the, how your signal flow can change based upon where you put the plug-ins in the supply chain?
Oh yeah, that can actually have a huge influence.
Like I was saying with that tape saturation plug-in, you know, putting it at the beginning is going to keep us from having a lot of high end later on down the line.
The nice thing about Pro Tools or some of the other hosts you might use is you can actually reorder those.
And it can have a huge effect.
Another thing is you can, for example if you're morphing, put multiband limiters on both of your sources so you're boosting up all the frequencies and you have more things that are gonna interact with each other, more frequencies, and you'll actually get more out of that plugin than if you just let them go through and then did that after the fact.
Maybe you already said this and I missed it, but do you have any recommendations for morphing plugins?
The examples you heard here, we're using the ProSonicMorph, that's audio units only.
I also really like the Native Instruments Vocator, that is not supported anymore, sadly, it's a really great plugin.
There's a lot of vocoders out there, Trax also makes one, SoundHack is like the mother of all morphing and mutating programs.
Hey, so like in that talk you had so many examples of plug-ins and I guess like one of my issues when I'm sort of approaching getting acquainted with new tech and stuff like that is that it's like when I'm overwhelmed with like 30 things and then trying to like go in there and figure out like, okay, what are the parameters that like really make this thing work or like I guess how do you get to a point, are there any resources available for just like okay if you have tons and tons and tons of things that you want to research.
How do you get to the point where you kind of like know what the sort of specialties of each thing are?
I think part of that is, you know, as you buy things or demo things, you're going to find what you like about them.
A lot of plugins I use, like maybe there's like three things that I just go to all the time.
Like my Eventide DSP-4000, I use that for chorusing reverbs.
Like it's just really good at that, and I tend to go to other things.
for other stuff, like experimenting and playing and finding what works is the best way, just putting the time in.
Do you get a lot of recommendations from other people or just tricks of the trade?
I'm very lucky that I work with a whole company of other sound designers, so we're talking to each other all the time.
You hear something coming from somebody's door, like, hey, what are you doing? How did you do that?
The goal, even today, isn't to take notes on these chains or these plugins.
It's to take that information and inspire yourself to do your own thing.
Cool, thanks.
What kind of recommendations would you have for portable audio recorders and or microphones for when you're doing what you call field recordings and things like that?
I have a sound device in 744, which I really like. We have about one minute left.
I really love my Sennheiser 416.
If you were buying a first microphone, that would be one that I would pick as a great foley and voice recording mic.
It's awesome on things like big cats or other animals you might go out and record.
There's a lot of handheld stuff out there.
If you go to Gear Sluts or a lot of the forums, you'll find a ton of information there.
Cool, thank you. Sure.
Hi. You mentioned in the beginning boosting up holes in the frequencies.
Do you have any tips relating to working with voiceover artists?
Yeah.
To do kind of the opposite, to leave a hole in there for the voiceover?
Yes.
You know, a lot of times if you're doing that, it's going to be in a mid-range frequency.
That's where most of the human voice is.
A great plug-in for that is if you have the ability to do it like a multiband compressor with a side chain capability that will actually duck the frequencies that are coming into the side chain, like the dialogue.
That can be good in mixing, although it's harder to do in real time in a game engine.
And I would say probably EQs that have a broader sweep to it.
Alright, thanks.
Sure.
How hard is it to...
I think the cane is coming for me.
So I'll take one more question.
OK.
How hard is it to know the sweet spot for processing, when you don't need any more?
Because when you were doing the refrigerator demonstration, there were a couple of times where I was like, that sounds really good.
And then you did something else.
I'm like, oh, it still sounds really good.
So how do you know when to stop?
You know, it all just becomes raw source that is kind of putty in your hands as you're processing it.
That's part of, I would say, developing your own personal taste level is going to be what makes a supervisor or an audio director want to work with you, is just listening to what works.
And listen to movies and games for what's already in them.
You'll find that simple sounds are what ends up in a mix.
Thank you.
We need to take a break. Now, lunchtime surgery, Peter is going to be in the room, so if anyone has any more questions for Peter, then you will get an opportunity.
