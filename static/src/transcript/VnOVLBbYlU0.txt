Well, hello, everybody.
My name is Marius Quiero, and today I will be talking about ranking systems.
Let me give you a little bit about my background first.
I'm originally from Spain, in case you're wondering where this accent comes from.
I'm very competitive.
You may have heard of the importance is to participate.
No, the importance is to win.
Don't forget.
If you're like me, you probably understand why ranking systems are so important.
I, back in the day, I practiced a lot of competitive sports, in particular rowing, you know, this racing with boats.
I was pretty good at it.
I also played some online games, like StarCraft.
I was pretty terrible at it.
Multitasking is not my thing, seems like.
Then moved to the US, started working on the major leagues gaming, where I got experience on eSports.
Later worked on games for about five years.
and in the lab and now they sleep here in San Francisco and I work for twitch interactive you know the cool video platform but I didn't really get to dig deep into ranking systems until I was working in one of my side projects which is jump craft this is like a tiny experiment think of it as a Mario maker but with simple pixel graphics which are super cool In this game, players make their own maps, which are pixelated and just draw around.
But then, the system will estimate what is the actual difficulty of the map.
The system knows if the map is hard or easy.
How does it?
Well, it has a ranking where it will match players versus map.
The player gets to play a random map.
If the player is able to get to the end, the player wins.
If the player dies before getting to the end, then it has three lives, but if he loses all the lives, then the player loses and the map wins.
For the ranking system, they are both the same thing.
I did it using a true skill implementation in Ruby, which is what I was coding, and for the system, there is only one rank, but I saw different ranks for both players and maps.
So, if a map, if many players keep dying in the same map, the map slowly goes up the ladder of difficulty.
This talk is going to be about 30 minutes, and I'm going to talk about Elo, system, true skill, building on top of Elo's ideas, and at the end, practical considerations to build your own.
I'm afraid I'm not going to give the super awesome answer to all your problems with Elo as a player or as a designer.
If any, I'll probably raise even more questions in your head.
Hopefully, one of those questions leads to an answer that solves your specific problem.
Let's start with the first example, the Elo rating system.
And I'll start by introducing the man who started it all.
He deserves no less than this amazing confetti animation, Arpa Zelo.
Animation is awesome.
Well, Arpa Zelo, born Hungarian, came to the United States and was a physics professor and master chess player.
While playing chess, he identified problems with a previous ranking system called Harness, which was a little bit subjective in some sense and depended on which tournaments you play and how.
So he proposed a new system with more sound statistical basis called the Elo rating system.
I will put my name as well on it.
I will call it the Mario system.
Well, that system was adopted by the World Chess Federation quickly in the 70s, and he ended up publishing the rating of chess players past and present in the 78, which you all can read if you want.
Oh, fun fact.
Up until the mid-80s, Elo himself was running all the calculations for all the players manually.
It wasn't that hard, because back then there were, like, no more than 2,000 players.
But still, thanks, Elo.
Later, computers took over, as they will with all of us at some point.
Ha ha.
So Elo.
System is all based on the normal distribution Assuming that chess players performance are at random distributed variable. Oh In the eyes of Elo, you are all slimes Yes, you're all slime people everybody yeah Which, just like a slime, your skill is not here, not there, it's somewhere in between.
And the system is not really sure where it is, but it has some idea.
It's more or less here in the center.
Now if you are more to the right, you are a better slime.
You are more to the left, you are a worse slime.
Sorry blue slime.
The formula, and now think that the formula in Elo is for one versus one players because that's the only thing it supports.
And nowadays, there are many different ways of approaching this problem, but this is the simplest possible way, so let's start from here.
After a given match, when two players play, there will be a transfer of points from the player that lost into the player that wins.
This rating difference is the score, which is a number, is zero if you lose, one for the win.
minus the expected. And the expected is from 0 to 1, the probability that the system is expecting to happen before. So it's what is expected plus what happened minus what was expected to happen before. And then multiply by the k factor, which is just a random number. It's not a random number, sorry.
It's just a number. It's a constant that you have to assign to the system.
This is just because without the k factor, you will always be transferring points between 0 and 1. So we'd like transfer points from...
red, green, 17, whatever you want, so you make a bigger or slower k-factor.
It's also used for adjusting the speed of transfer.
So inside the same ladder, you can make that lower players have a higher k-factor, and then towards the upper parts of the ranking, a smaller k-factor.
But think about it as the updated speed.
Much of the trick here is in figuring the expected, and that is what the system is doing, is predicting what will happen, then adjusting based on what actually happened.
The original ELO system assumes this formula.
What is that formula came from?
Well, it came from the union of these lines, where the two lines touch together.
There's an area there that you can integrate.
And you can know what is the actual probability that player E is actually better than player B.
Elo suggested like a shape for, like the same shape for the slime for everybody, assuming some standard deviation, assuming that the chess players were, the performance were under a normal distribution, but you could use any other distribution, you will get a different formula.
At the end of the day, you get that the expected probability of player A of winning is based on the difference only between player A and B.
As an example.
Well, this is the kind of numbers you will get with this formula.
Let's assume player E is 0 points better than player B, he will have a 50% chance of winning, which is obvious.
If he has 100 points, and this all comes from that 400 number in there, you can use a different scale, but originally, as you know in chess, it goes from...
1500 to 2000, you can use a different scale.
But with this scale, 100 points will give you 64% chance of winning, 200 give you 76, and so on.
This is what the system predicts.
Let's see an example with Bob and Alice.
Bob is a new player, he has 1500 points.
Alice is way more experienced and has 1900.
The system believes that the expected probability of Bob winning is 9%, and the least is the other part, 91%.
Well, what happens using a k-factor of 32, and you would use either 10, 30, depending on the case, this is the amount of points that you will be transferring.
If Bob wins, he will get 29 points, because that was a big surprise for the system.
If Bob loses, he will only lose three points.
And this means that the system is self-adjusting.
In theory, you can match anybody of different difficulties, and the amount of points will be transferred based on the actual difference of a score.
In practice, we'll see later, it's not that easy.
Usually you wanna match players that are actually closer to each other to avoid those outliers.
A few comments on Elo, and we'll wrap up here, is a very well understood system.
means that's an advantage, whatever you use it, other people will know to expect what happens with it.
It only works for one versus one.
It also means team versus team, but you can only track the team points, not every individual player, unless you do yourself some kind of distribution inside it.
It's simple, but its simplicity is also great strength.
It's still widely used nowadays.
Also, if players understand how it works, and they can run their numbers in the calculator like Elo used to do himself, it also feels fair.
The k-factor is sort of like an incognito there.
You have to find out what is the good one for you.
There are many, many different ways.
That will be its own talk.
And nowadays, there are many different implementations.
Almost nobody uses exactly as originally stated.
Because, obviously, we have more data.
Even for chess, we have more data right now.
But what is the actual standard deviation than what Elo assumed at the beginning?
Also, new players can take on time to convert to the correct skill rating.
This means that they need to play many, many games in order to get to something that reflects their actual skill.
Let's move on into the next ranking system that I'm describing today, which is TrueSkill.
I'm talking about TrueSkill specifically because it builds on top of the ideas of Elo.
TrueSkill ranking system was developed by Microsoft Research, designed originally for allowing to have a more general system for Xbox Live games.
I think the first one that went live implementing this was Halo 2 Online.
In proof of open ideas.
Well, I think Microsoft Research also did a terrible job.
Terrible job.
So they deserve amazing confetti animation.
Yeah.
This is awesome.
My next talk, I'm going to use this animation for every single slide.
It'll make it so much better.
So the main difference, there are many differences with TrueSkill, I'll discuss a little later when compared with Yellow.
But the main difference is that there are two variables now.
One is a new, abbreviated skill.
And that is pretty much what you'll have, like, count on the median, on the average of the standard deviation, on the average of the Gauss bell, or the Slime curve, Slime curve is much easier.
And Sigma, which is the degree of uncertainty.
So now you can model not only what is your belief on the player's skill, but also how much you believe it.
Like, do you believe it's here with many uncertainty or not?
So in the eyes of true skill, you're also Slimes.
An easy way to explain this is that the new players' lines will be short and fat, like the blue one.
And more advanced players will look more like a tall and thin lines, where the system is a lot more certain their skill actually belongs somewhere in that area.
Now, if you have two variables, what do you show to the players?
Can you tell players, like, well, this is your ranking, this is your new, and this is your sigma.
Well, you've got to come out with a single number.
TrueSkill suggests a very conservative rating of nu minus three times the sigma, which gets 98% coverage of the whole area of the curve.
That is very conservative, meaning that the system actually believes that the actual skill of the player is 98% likely to be more than what you saw, which also means when you do updates, it's likely to go up, not likely to go down.
This is just to improve the perception.
Using sigmas and noos also allows the blue slime down there will show himself a rating of 0.
So this is just a very good way to start players on the ranking when they see themselves with ranking 0, instead of in Elo where they start with 1500, which it feels like, where is the number coming from? At least for them.
Let's see an example with the simplest cases.
Simplest case, I mean, because in TrueSkill, you can model multiplayer games.
8 versus 8, 16 versus 16, even teams of 3 versus 3 versus 3 versus 3.
You don't need to do any tricks.
You just feed that data into TrueSkill.
TrueSkill figures out every individual skill update based on what happened in those teams.
The simplest case is 1 versus 1, which is very similar.
If it was with two players that have exactly the same standard deviation, that would be equivalent to Elo, very much.
But it can come with different levels of the sigma.
Natalia, for example, here will see herself as first game will have that nu and sigma.
Eric, on the other hand, has been playing for a while and has a much smaller sigma, which means less uncertainty.
What happens if Natalia wins?
Big surprise for the system, which allows to give her a very big update.
So, he goes straight from rating zero to 15, or how it would be used in Xbox Live is the code level.
Know that I'm using the same as Xbox Live from one or from zero to 50, which is what they use.
51, you can get sometimes.
I'm gonna go back and forth with this animation so you can see the data a little better.
So, you see Natalia.
gets a big update in her new, but Eric only gets a tiny update down.
That is because he has a lot more certainty.
Natalia also gets a big decrease in the sigma, and Eric also gets pretty much no difference.
In reality, he's getting a millesimal tiny down, but it's rounded to 125.
So once the sigma is small, it doesn't change that much, but at first it changes fast.
This allows the system to quickly converge to the true scale, to get very, very fast to what you're actually.
what is your actual skill as a player.
Again, for the simplest case, those are the formulas you can find online.
They are all public.
They're kind of complicated, obviously.
They are really not that complicated.
I'm not going to go over because we have limited time here.
If you want to see them, Microsoft Research published them.
They are also, which you can find from a link from the Wikipedia.
A few comments about TrueSkill.
It is more flexible, at least when compared with Elo.
You can model many different types of competing games.
What do I mean with this?
It allows you to model not only one versus one, but also multi-players.
It has a parameter for the chances of drawing, which in some cases you can draw.
More like in other cases, like Goat and Racing, you will not draw, you will always get at some point.
It also models the luck versus the skill, which is very important.
Some games, like trading card games, have more luck involved.
Chess has less luck.
With Elo, usually, you will have to come up with your own Gauss-Bell formation for getting more close to the actual probability of winning or losing.
It does quickly convert, at least way faster than Elo.
As example, as I was mentioning before, eight or 16 players playing against each other, randomized.
The system will need about three to five games to get a very good prediction of their skill.
If you're talking about teams like League of Legends, for example, five versus five, that needs a lot more games.
Even if you randomize the team formations, we'll need about 50 games in order to get a good...
a good prediction. This is because ELO, sorry, true skill, same as ELO, it only counts wins and losses. It doesn't track individual performance of players inside teams. But it works.
Calculations are very complex, as you saw before, foosh, foosh, but today is not a problem with computers. You don't need ELO to run the numbers game by game. Although, if they are complex, that also means players sometimes don't understand what's going on. And when things don't go the way they expect, they'll be like, it's unfair, it's broken, it has a bug.
This, using the Sigma, makes it easy to model new players, whether in yellow is usually a problem.
And the downside is that it's proprietary.
You may have to pay Microsoft, although there are great alternatives out there.
There are some free implementations, or at least I think they're free, to be used, which don't model exactly the same as TruSkill, but they're close enough.
There's also the Glico system, which it has a lot of the benefits of using TruSkill, but it's also modeled after one-versus-one players.
It's also simpler, but it also converges to the TruSkill of the player very fast.
Now, after seeing some of the theory, let's move on into the considerations if you want to build your own.
Just doing math is not enough for having a good ranking system out there.
So what makes for a good ranking system?
Well, it needs to be credible.
I think this is the most important thing.
If players, it's all about player perception at the end.
If they don't perceive that this thing is doing the right thing, it doesn't work.
It needs to be easy to implement.
This is also obvious, but that implies that if your system is too complicated, it'll be problematic both for players to track what's going on and also to implement, which also means easy to do bugs, to find bugs, to exploit the system.
Depending on the case, there are many other things.
Different games have different requirements.
Ranking systems are used everywhere.
So let's review a few practical issues here.
I'm gonna go over one of those one by one.
There are more, but those are the ones that I can fit in this time.
Start from complexity.
Foosh again, foosh.
Yeah, I clearly love Jackie Chan.
He's great.
Well, the more precise and flexible your system is, the more complex it is.
If it's too complex, it's hard to understand.
And also, complex systems are easier to cheat.
Never forget that simplicity goes a long way.
After all, it is still widely used worldwide nowadays.
Subjectivity.
Well, the more subjective elements into your system, the more complexity you can digest.
That's probably the best ways to do that.
The extreme example would be a gymnastics tournament where there is a judge that says 7.7, 9.1, 9.9.
They just say a number, and that's it.
That just digests all the complexity.
Super simple.
You just need one person to say that.
Well, it still is important that the players or the sports people that are competing believes that the rating is credible.
If they trust the judge, then it's fine, actually.
Also, it's important to tell that systems like Elo, more mathematical, they also have a lot of subjectivity involved, but it's more subtle.
For example, Elo, you have to guess what is the best k-factor for your guess.
Also, Elo assumes what is the standard deviation inside the players.
But those things are more subtle.
Inflection and deflection of scores.
Well, scores may keep going up over time.
Why is this?
This is because the prediction of the system gives you, even if it gives you a very good estimation, may have a 1% error.
That 1% error can add over time.
If you're thinking about something like chess, what has been played over hundreds of years, that can add up over time.
Well, in most cases, games don't last for 100 years, unfortunately.
So it's usually not an issue for you.
You shouldn't have to worry about this too much.
But if it happens, there are things you can do.
In chess nowadays, sometimes they give bonus points after tournaments, which help feed points into the system to make them grow.
They can actually make, for example, new players start with less score, so there's less points into the system.
You can try to control that somehow.
Well, hello there, new players.
When you have a new player into your game, your system, what is his skill?
You don't know.
They may be an expert already, somebody that was playing and created a new account.
Most of the time, they will be new players also.
The trick usually is to guess what is the average of all of the new players that are starting.
Also, what is the data you give your players?
Well, true scaling and Glico, since they have explicitly modeled the uncertainty of the players with the sigma, they just make a big sigma.
They make those lines fat and short.
But Elo doesn't have that.
But Elo can work out with having a bigger k factor on the lower ranks.
This is also why placement matches are very useful.
Around 10 games is usually enough to have a decent estimation of the starting point of those players, even if it's just for matching them better against others on those initial games.
You don't want your game to have the initial few games to be a bad experience.
Time decay, what happens between game, you're waiting there like the frog.
Well, returning players may be out of chase.
In Elo, this is a problem, because Elo doesn't model time decay at all.
You may spend a few months without playing, you go back, and your actual skill is below what the system believes it is.
Your first games will be a bad experience because you need to lose a bunch of times until you get back to your original place.
In TrueSkill and Glico, since they model uncertainty, again, that is easy to solve.
True skill, at least the algorithm that's described by Microsoft Research, suggests that after every single game, you just increase the uncertainty a little more.
That usually helps.
Glico models precisely increase the sigma based on how long passed since the previous game.
With biggest uncertainty, the system updates way faster back to your original skill.
So you will also lose the first games, but maybe two games instead of six games in order to get back to your skill.
I had fun once, and it was awful.
That's what the Grumpy Cat says probably when I play on the ranking.
Well, ranking can be brutally honest.
It tells you how bad you are.
You don't want to know that.
Most players, realistically, they just want to feel progression.
They just want to feel they improve over time.
Well, for games, I believe this is the most important slide of it all.
Sure, you have mathematics behind, but at the end, it's a game.
The ranking system.
doesn't have to be, so their score doesn't have necessarily to be what they see.
In fact, many games use...
a system like TrueSkill for matchmaking the players, but they show them a different score.
The score is accumulative.
There are many accumulative systems.
I'm not covering them in here, but they may be a great solution for some cases.
Accumulative means that they just get points as they win.
This means also that players can play, play, play, play to kind of grind those points.
But in some cases, this is fine.
For example, in actual chess tournaments, how many chess tournaments you can play during a year is not that easy to actually do this.
In other words, that could work better for some cases.
There are side missions like Hurston Dust with some loot to get so you feel you won something even if you lose the game.
Locality is important, play against your friends so it's not as scary.
You can also do divisions like in Starcraft Ladder where you play against the same hundred people for the season.
Hierarchy is important so it's more fun to be a gold player than saying I'm a player with 773 points so you can talk with other people.
Never forget the fun factor is important.
Gaming the system like the most interesting man in the world.
Well, matchmaking should be random in general, at least if you wanna, this is the easiest way to avoid people gaming your system.
When I was young, I could play against my little brother, StarCraft, and I would win every single time.
Mining one point at a time, mining one point at a time.
But the system didn't allow me to explicitly target him.
That is mostly why those assignments are random.
Well, it happens that usually in tournaments, since the pool of players is small, that is not targeting players, but that gives the players a good idea of who they are playing against.
And that sometimes can be problematic.
For example, in Magic the Gathering...
They used to use Elo before, but the actual distribution of Elo gives a hard, like between the best player and the worst player, Elo says, oh, there's like a 99% of chance for the best player to win.
Maybe in reality, magic is more like 70% only because there is still more random factor, which means they don't wanna play against.
When they are on the top, they don't wanna play to don't lose their ranking.
And this could be a problem.
That led them to change a more cumulative system called place worker points, which works better for them.
Margin of victory, this is an easy one.
This is just why do these systems count for victories only, and they don't count for how many points you make inside.
Well, this will be very useful, especially for team games, so you can track who is contributing to the team victory more.
But it's always problematic.
Every time you put a metric that players can maximize without thinking about their team, that can lead to unhealthy matches as well.
So it's usually best to keep it simple, unless you have a very good reason not to.
Now, if you do, keep the margin of victory.
That gives you more information.
Your system can be even more accurate.
I guess this goes back again to complexity versus simplicity.
In many games, there's really no place like home.
For example, in basketball, it's well known and studied that there is an actual home advantage.
Like, the referee may be biased.
Having the crowd cheering for you is empowering.
There are things that make, and definitely there are basketball skill rating systems that take this into account, and with a very decent chance of winning.
This is just another variable that you could use in your rating system.
It's an easy one to use.
This one doesn't increase complexity much.
And in games could be, you know, the favorite maps, or something that you find out where you believe these players have a higher chance to win already.
And here, the Dreaded 50% win ratio.
Well, by definition, matchmaking systems like Elo and TruSkill, they're trying.
What they do is to predict, try to track the skill of players.
Therefore, you can create high-quality matches.
And high-quality matches means some games where both players have roughly the same chance of winning, because that makes it more interesting.
Remember that in a ranking, a ranking itself is a zero-sum game.
If you give more wins to a player, you're moving more wins from the other player.
So the best you can have is 50% ratio.
Realistically.
Many players actually, they like to win more often.
I wouldn't put my hand in the fire, but I would say this is even so more true for millennials.
They need to win all the time.
We all know that.
How do you defeat this?
Well, you cannot defeat this with a ranking system.
You can offer side activities like the StarCraft Arcade, non-competitive quick games.
You just need to give them some place where they can have fun and win more often.
Maybe have fake AIs, synthesize win streaks when they are happy, and then have them many losses to counter for that.
That's definitely something you have to take into account.
Going beyond games and beyond.
Well, rankings are everywhere.
You know, Amazon, Google search, everything that is putting different items together is using ranking system.
Well, most of the time, this is not a matchmaking system like Elo.
There are many other algorithms there to find out.
Suckenberg's famous example of doing face mask site before doing Facebook to run Harvard students only based on which one of them are more cool.
That was using Elo behind.
And any item that can be compared can be ranked.
For example, player versus map.
That's all for now.
Keep calm.
I love cats or kitty raptors.
Thank you so much.
You have any question at all, please try to use the mic.
I'm not sure if this works.
OK, there we go.
What do you think about systems like you have Blizzard's Overwatch system where it'll hide the different rankings, or show you one rank, but you rank maybe something else?
When do you think it's appropriate to hide some of that information from the player?
I think it depends...
Oh, it wasn't...
Okay, I'm going to repeat the question.
When is it more appropriate to hide the actual rank and just give them something that they can... different, right?
So, this is a design question more than an actual mathematical programming question, but...
I believe it's better in more casual games.
You usually don't care that much about that because you just want the casual players to win more often or not to win more often but to feel the progression.
It's all about feeling the progression.
Where the more hardcore games, as far as they understand what's going on, and maybe you need to make sure that you're showing before the game your actual sort of...
Even if it's not just the chances, like, oh, you're playing much against this other player, which is gold, and you're silver.
That is probably good, so they know what to expect.
It's always usually about setting the expectations.
Now, for casual games, don't expect a lot of your players will not understand how the system works.
Even so, if you have a very good system, like TrueSkill, and they play three games, their rating goes from zero.
to 25 and then it stays there forever.
And maybe it even goes down sometimes.
That's not fun.
So in those cases, when you can identify that, it's good to do so.
You may still use a ranking system behind the scenes just to make sure that they have fun matches, that they are not ranked against somebody that's much better or much worse than them.
And this is great that you can get there in three games.
So you know as soon as possible.
Thank you.
No worries.
So online games always have a problem with cheaters and exploiters, people who buy boosted accounts, et cetera.
And obviously, when you catch the cheaters, you reset their Elo and ban them or whatever you want to do.
But I haven't seen many games or game companies try to tackle the issue of having players with inflated Elo from either cheating or botting inflating other players' points by losing after they have cheated up to a certain rank.
So you might have players that played against the cheater 10 plus times in a single day, and now their ranking is too high.
And you punish the cheater, but you don't actually tackle the problem of this kind of point inflation that has been introduced by cheating or exploiting.
Okay, so the question is, how do these ranking systems fight cheaters when there are many different ways they can do to exploit, like losing purposely and things like that?
What?
increase the unpredictability in your equation when a player has fought against a cheater?
That is one way of doing it.
So this ranking system we saw here, both Elo and TruSkill and Glico, they do not try to solve this problem.
What they do is they give you tools so you can work with that.
Identifying the cheaters goes outside of this algorithm at all.
The system never really knows if the player suddenly was training on the side, or now it's so good, or why is he losing.
He is demotivated.
What you can do with TrueSkill is, as you mentioned, play with uncertainty.
You need to have some detectors.
And identity sometimes is a problem.
If you don't have a good system for it, if they can just break an account and make a new one, that will lead to problems into the ranking.
But unfortunately, through these algorithms, there's really nothing you can do.
The only thing you can do really is detect when this is too odd.
He's been winning, and now it just looks weird.
You can try to increase the sigma, change it, penalize, do some things like that.
But I warn you, the more things you can try to add into it, the more complex the system will become.
after all. And generally speaking, the more complex, the easier it is to cheat as well. They will constantly find. So that unfortunately is a constant fight.
You're welcome.
Hi, thanks so much. So you mentioned that one of the disadvantages with systems like these is that the top players don't really want to play. And you mentioned a couple of different ways to deal with that, like progression. Are there any others that you're aware of?
Other ways that you know of to encourage the top players to still want to keep playing?
Okay, so the question is going back to the players not wanting to play ranked.
Well, in the case of DSi with Magic the Gathering and other competitive games, they introduced a totally different system, the place worker in this case, which was better for them because...
At the end of the day, you need to think Elo was designed for chess, the way chess is being played.
The more different it is from that, the less probably it will match your game.
For them, making cumulative makes more sense, both for fun in terms of progression, and also because it's not that easy to play, to repeat many, many games of Magic.
And also there's a correlation between the amount of games you play, the more you improve your deck.
If you're not doing that, you don't want to radically change, something they could do maybe is to create a new expected formula into their ELO by changing the assumptions.
They were assuming that Gauss Bell, like originally created for chess and for magic, may be a different one.
I'm guessing it will be like a shorter one.
The uncertainty will always stay higher.
They maybe by changing that will give them, the better players, a more accurate estimate so they will be more willing to play.
But it's very common lately to not pick your, when you're going to play the World Championship, not pick just the top players from your Elo ranking or your TrueSkill ranking, but do it in some other way, more based on achievements and things that you need to do.
And that usually works well.
I believe in terms of sports and e-sports as well.
The Elo is not going to help you that much at the end of the day.
So it's probably one of the places where you should look elsewhere for solutions.
Look at how Hurston is doing it, which is also doing it quite different for choosing the tournaments.
Thanks.
I don't know if I have time for this question, but just real quick, because you made a game with kind of a non-traditional use of Elo, you had the maps and the players ranked kind of the same way.
Was there anything kind of interesting that fell out from that?
Did anything weird come up that you didn't expect?
On the prototype?
Like having to rank the maps.
Did that?
Yes.
There's definitely.
When you try different things, you always will find things.
That is why it's important to understand, oh, I'm going to repeat the question.
Did I find more interesting things when matching players versus maps?
So yeah.
That is why you need to understand how the model works, so you can adapt it to your case.
In this case, it was surprising, first, that you have two populations, for the same reason they are both the same, maps and players.
But you have two populations where they never play each other.
Maps never play against maps. Players never play against players.
They play each other. And it still works.
Because they influence each other through indirect...
Indirectly they influence each other.
So that was surprising. It actually worked quite well.
Especially when using TrueSkill.
Less surprising is, well, when a player makes a new map, what is the initial score?
Going back to the cold start problem.
In this case, instead of using the default initial, I just applied the same score of the player.
I was assuming if you're in, obviously, you have to beat your map, much like in many other user generated maps.
You have to show that your map is beatable.
And therefore, that would show.
Later, I realized that most of the time is not the same skill of the player, but actually better.
Because players this good, when they are playing other maps, they die on three lives.
But when they're doing their own map, they can play over and over and over again.
Now, what is the number?
It doesn't really matter much.
And again, if you think about progression, making fun, it's probably OK to make the map a little worse so the first few games will more likely be won.
There are other implications like that.
But yeah, and you also need quite a few maps.
You need also to make tutorials where in the first few, you need some placement matches in which you will show your own maps.
So you don't want to send players into that pool right away, and things like that.
Thank you.
Thanks.
So I had a question, so chess...
Last one, okay.
Sure. So chess is a game that you have balance changes with, but we do that with live games, where we might introduce new troops, they have new stats, or even changing the stats with troops.
How do you incorporate that with the ELO system or TrueSkill system?
Do you mean...
Players might find out the new troop is just OP and they're just using that, and then we nerf them.
Sorry, I don't understand the question.
You mean handicap, maybe?
Or not?
No, you're talking about something else.
Yeah, I guess just adding new troops that existing players use and just kind of min-max and find the best ways of using them first.
I'm not sure.
Maybe we can talk right after.
Yes.
All right, so that was all.
More questions?
I'll be around here, and you can find me.
Thank you.
