Yeah, we're gonna talk about AR today.
The talk says the state of AR and the future.
And I have a confession to make.
I don't actually believe in predicting the future.
I think it's kinda hard to do.
But I am a big fan of a quote by Alan Kay, which is the best way to predict the future is to invent it.
or to build it.
And so, I think what we're gonna do today is, we're gonna talk a little bit about our learnings at Niantic, having launched some AR products and run them over the past couple of years.
And then, I'm gonna share some about our thoughts about stuff that's under development right now.
So, stage one's looking back, stage two's about what tech is getting built and the importance of that tech.
And then stage three of the talk is going to be about what we think the implications of that technology are for the kinds of products that we can build, whether they're games, game developers in the room?
Fair number.
Good.
So we're talking about games.
We're talking about non-game applications as well.
So looking backwards, let's start with just a little bit about Niantic.
I know some people know us as the company that made Pokemon Go or the company that spun out of Google, which is cool, that's what we are, but we're our own thing too, and the thing that we're kind of proud about is not in a chess-beady way, but proud of is why we're doing what we're doing.
And so I want to give you some insight into why we're building these products.
These things never really work when they're supposed to work.
I can push this button.
So why do we do this stuff?
So the journey actually started quite a ways back for us.
There's kind of a through line that connects.
So, for me, it started when I was a kid, actually.
I grew up in a small town, there wasn't a lot to do there.
But at one point, somebody came and they dropped off grocery bags full of old National Geographic magazines.
And for me, I fell in love with the maps that you could pull out.
Like, I can still see the one at the Nile Delta and all of the kingdoms, just amazing stuff.
So I spent hours with those maps.
A few years later, I saved up my money for mowing lawns and bought a computer.
And so that's kind of my whole story right there.
Like a bunch of National Geographic maps and a computer and basic and no money to buy any software.
So then things happen.
But that led me through a series of events to meet some really cool people, including a guy named Phil Kesslin.
Phil is the CTO of Niantic.
Back then, Phil was an engineer that I met out of Silicon Graphics.
And we and some colleagues, Shikai, Owazama, Avi Barzev, Mark Aubin, Michael Jones, Brian McClendon.
We founded a company, the company was called Keyhole.
It's a small company, we didn't have a ton of resources, but we had kind of an audacious vision, an especially audacious vision for a company that size.
We wanted to take 3D technology, new digital satellite imaging technology, and broadband, and make a map of the world.
unlike any map that had been made before.
A map of unprecedented level of detail built on imagery for the entire planet.
So we got started with that.
We actually were acquired by Google along the way.
And with help from a bunch of other talented people inside of Google, Brett Taylor, Jim Norris.
Andrew Kirmsey, to name a few, but actually a very large team.
We were able ultimately to realize that vision, to build a map, and really to put the whole world on your desktop initially.
And then later we brought it to the palm of your hand when we brought it to iOS, brought it to the iPhone, and brought it to Android.
So after we built the map, at that point, there were thousands of mashup sites, people doing all kinds of crazy things with maps.
And so we started thinking about, well, what can you do with a substrate that we've created, this geographic substrate of the world?
And we also got interested in the kinds of devices that people were tinkering with that look like they might come after the cell phone.
They might be that next.
thing that would come.
There were early versions of wearables, watch-type devices, people were playing around with HMDs, different kinds of AR glasses.
And so the thinking was, okay, maps, location, information, the real world, these things probably combine in some interesting way.
I got interested in part because I became a parent, I had kids.
And you know, when you become a parent, it's like, it's your chance to do everything over again.
It's great, it's like you reset.
And so I was thinking about all the places I wanted to go and explore with my kids.
So we started Niantic with kind of those themes in mind, like let's see what happens with maps and location, wearable technology, to build stuff that brings those worlds together, the digital world and the physical world.
So we built some products.
By the time we spun out of Google, Pokemon Go was in development.
And we had a pretty clear notion at that point in time.
of kind of what our value would be.
The things that we wanted to, I mean with software, you guys know how it is, like you can build anything.
You know, sometimes the hardest thing is to decide what you actually want to build.
So we said, well let's put some parameters around our efforts here to guide us in a particular direction.
And the ones that we came up with based on our experiments and based on the early games that we pushed out to users and beta tests and so on, were these.
It started with this idea of exploration.
So sort of the key thing that we settled on was, you know, In every neighborhood, there's probably a story that's interesting.
There's a mystery that can be built there, everywhere in the world.
So it was this idea of exploration.
The second thing we settled on was, you know, being computer people and spending a lot of time at our desks.
you know, we realize that hey, everybody needs a little nudge sometimes to go outside and get their 10,000 steps in or get their daily workout in.
Maybe some of you have had a chance to check out our garden over outside the Metreon.
Good, if you get tired of sitting inside, we've created a nice space for you out there.
And we heard back from some of the early users of our games from Ingress that people who didn't consider themselves athletes really appreciated that gamified kind of nudge to to exercise. So we we adopted that as one of the three principles.
And then the third one was social.
So the other thing that you know and this really came from feedback not from originally from our own insight, but from what people told us when they were using our products, was that they loved the opportunity to meet new people and have a thing to do together with their friends or family or parents with their kids outside, like an activity that people could do together.
Just lots of love, lots of fan mail, lots of positive reinforcement around that.
So we adopted that as the third principle.
So this is sort of guiding us.
We track our progress, I mean just to give you a sense of scale of how this is going.
We measure various things.
In terms of the exploration piece, we measure the total number of places that have been observed as special, unique places in neighborhoods where people live that people have photographed and named and described and added into this global game board.
So that now numbers in the many millions.
We've opened up that submission process in Pokemon Go, so it's.
growing rapidly worldwide.
So this idea of stitching together a global game board, a place that we can play out of all the interesting nooks and crannies in the world, is going pretty well.
On the exercise front, this one is just, you know, it blows us away.
We check this number, it's like bigger every time we check it.
It's currently three billion total kilometers walked.
And it's interesting.
I know here at GDC, maybe four years ago, five years ago, there was a speaker talking about some of the early efforts to do outdoor games.
And the conclusion of the talk was, hey, people aren't gonna go outside and play.
Give up.
Gamers wanna stay seated in their couch.
And I don't know if it was just timing or the evolution of the technology or that right combination of gameplay and design and tech, but that's not true.
Like people like to go outside and they really enjoy that part of the experience.
In terms of social we measured in 2 ways, we measure it in terms of like the formal connections that people form in the game.
We added the friend feature in Pokemon Go last year so you can identify your friends, you can exchange gifts with those friends, you get bonuses for playing together in raids.
So now there are over 190 million friend connections, so lots of activity there.
And we also measured in terms of the events that we hold.
Has anybody been to a GoFest event or a Pokemon Go community day?
Okay, decent number.
So if you haven't been to one, these events look a little bit like music festival, if you've been to like Outside Lands or Lollapalooza or something like that.
maybe combined with like a healthy dose of comic on with a little bit of 5 K if you can like combine all those ideas. Um, so people coming, uh, really fully, you know, into the game, living out their fantasy of being a Pokemon trainer or.
part of that world, and families will come together, groups travel from across the country, carpooling together, people travel from continent to continent.
So really neat, these have been very successful for us.
Last year we had three million people in total come to these events, and single day attendance.
At a single event, we've had events with over 100,000 people.
So this idea that games can be part of that festival-like outdoor world is very much true.
So just in terms of catching up and looking back retrospectively, a lot of people know us as a company that helped to pioneer this idea of consumer AR.
The first game we launched was Ingress back in 2012.
Going very well. It's played in a bunch of countries. I think 175 countries around the world.
We've held hundreds of the events of the kind I was describing.
We were doing it with Ingress before Pokémon Go.
We launched a new version of it last year, Ingress Prime.
And this was our learning place.
This is where a lot of the feedback that's informed our later work came from.
Pokémon Go continues to set records in terms of...
users, revenue, it's now over a billion installs in total, over two billion dollars in total revenue, and a really awesome, amazing global community.
And we're continuing to obviously invest.
heavily in that product.
We recently rolled out our AR photo feature in Pokemon Go.
I don't know if anybody's tried that.
It was the third version of AR in the game.
So the very first version of Pokemon Go had a really crude implementation of AR.
We did AR+, about a year and a half later.
And then this is our third iteration of figuring out how is the best way to actually utilize AR in a helpful and fun way within a game.
So, check it out if you're kind of looking to understand our thinking about this at the moment.
Next up for us is Harry Potter, Wizards Unite.
Hopefully there are some Harry Potter fans out there.
So, this will come later this year.
I will play a short trailer for you.
Immobility!
I don't know about you, but when I hear that music, I'm ready to play the game.
I love the world of Harry Potter.
My kids grew up with it, reading the books.
I read them aloud to all, I have three kids, to all three of them at this point.
So we're excited about this product.
We just gave a first look to the press a few weeks ago, released some of the first screenshots and video of gameplay.
So we're looking to this as a platform to evolve our work around real world and around augmented reality.
A lot of people talk about AR and AR games, by the way, and we really prefer the term real world because we think it's that fusion of the digital and the real world that's the interesting part of it.
And AR, sometimes people think AR and it's that technology of seeing something through a viewfinder, which is certainly part of what I think of as the full breadth of augmented reality, but that's not all of it.
It's really about how you integrate that with the physical world.
Okay, so behind these games is a platform.
And this is the set of tech that drives the games.
It's evolved with each of these products.
We actually have several projects under development that have not yet been announced that are built on the same technology stack.
At present, we have as many people working on the platform technology as on Pokemon Go itself.
So there's a robust effort to mature this and productize it.
This tech is the part of the system that does the heavy lifting so that we can all play in a single game instance.
So if any of you played World of Warcraft like I did back in the day, of course we had to pick what server to join when we wanted to join a massively multiplayer game.
The innovation here is that this system holds state for all users in a single...
instance, if you will, of the game.
It's, of course, striped across tens of thousands of servers, but you don't have to think about that as a player.
This system also supports all the social features that I've talked about, all the mapping, all the location, information that's integrated into that, really all the support that you need to develop and publish a game like this.
And of course, advanced AR.
And we're gonna spend maybe the rest of the talk talking about the advanced AR part.
That gives you a common layer between ARKit and ARCore, and also provides a way for us to extend that functionality with cloud-based AR capability.
And that's where a lot of our R&D is going.
We do have a developer contest that's open right now, the Niantic Beyond Reality Contest.
There are a million dollars in prizes for that contest.
It's open for submissions until the end of the month.
There'll be a sort of game jam session through the summer where we'll be working with the finalists.
And we've set aside.
actually several tens of millions of dollars to fund, hopefully some projects that emerge out of that, beyond the prize money, and also other projects that we'll identify next year.
So something to check out if you're interested in building products like this.
Why do we want to see more games like this?
One of the reasons that we do our events like this, so I talked about our Niantic-hosted events.
Within that are a subset of things that we do with civic organizations.
So we think about technology.
There's a lot of bad press about tech right now.
I think that tech can actually have a very positive impact on the world, and this is one example of that.
We partnered with the Knight Foundation.
They do a lot of work in cities that are distressed, that are trying to rebuild, that have serious economic and social problems.
And one of the ways they do that is they host festivals to get people into the city and just walking the streets, meeting their neighbors, rediscovering what's there.
So, Soclavia in Los Angeles is an example of that.
The Philly Free Streets Initiative is another.
There's a UK org that we work with which is independent of the Knight Foundation.
called Big Heritage and they're devoted to teaching history to kids by having these big festival style events, families come together and then they learn about the history of the town in this really fun interactive way. So in all these cases we're overlaying gameplay.
onto an existing kind of civic festival, dramatically increasing their attendance and drawing in an audience that wouldn't otherwise probably attend.
So we want to see more events like this, and that means opening up our platform so that many people can build, hopefully really fun experiences on top of it.
Okay, so what have we learned?
You know, this is the part where we share some of our stubbed toes, some of the mistakes that we've made.
You know, the first one is really a message of encouragement about the potential to build games that are broadly inclusive and broadly appealing.
Whenever I first started investigating the idea of us doing a game, I was doing my research and people talked about casual games and mid-core games.
And casual games had a certain look and feel, they attracted a certain audience, they had strengths and weaknesses.
Mid-core games were for real gamers and they had a completely separate dynamic to them.
And then there are hardcore games or like the real serious console games.
We didn't want to put ourselves into a single category.
We wanted to build something that was broadly appealing, but we had ambitions around retention.
We wanted it to be financially successful.
And so this was a risky shot for us.
And what I'm reporting back to you is that it is possible to build this kind of game, and I don't think it fits an existing category, I wanna call them accessible games.
You know, games that are gonna appeal to males, females, people from all walks of life, multiple demographics and age groups.
With Go today, based on third party research, polls that have been done, we see more than 40% of the players are women.
We see underrepresented minorities in excess of 30%, which is great.
That begins to approach what the world looks like in terms of those distributions.
So gamers, not a subset of the world, gamers are just, they look like everybody else.
And we've seen very good long-term retention, good spend in terms of the revenue.
So it's possible to build broad games that keep people for a long period of time playing very intensively.
So mid-core, casual, there's something in between, I think.
So AR, I want to tackle this head on, because I know you guys, many people are probably curious about AR, many people are thinking about starting AR projects, and we've had some learnings here, right?
AR in and of itself is not a magic bullet for a hit game.
There are some real drawbacks to it.
The ergonomics are one of them.
We know that...
Oops.
We know that people really don't like to hold up their phones for long periods of time.
We think the right session length for holding up your phone is not more than two to three minutes, for example.
So if you think about AR, you wanna think about it as a type of play that happens within a broader game where a lot of the gameplay is not happening in AR mode.
Social stigma.
So when you hold up your phone and you wave it around, it looks like you might be taking a picture of everybody who's standing around you.
This is a big drawback to AR in certain situations and is something that really needs to be designed around.
The other thing is just efficiency.
And by that, I mean two things.
Device efficiency, so there's a power drain that one has to take into account.
And there's also just gameplay, game loop efficiency.
If people are power leveling through a game.
they're not maybe happy to take that extra time it takes to instantiate an AR session and play in that way.
So, short sessions and really thoughtful design.
We think the right approach here is to design things for AR that really can't be done outside of AR.
So to try to think of game mechanics where you're in AR mode and it's obvious why you're there, you're having an experience that you can really only realize through AR.
The other thing that I want to sort of flag here is you hear a lot of hype in the industry about augmented reality. You hear it from large tech companies other than us, like the really, really big tech companies. You hear us talking about AR. It's important to understand that sometimes when we talk about it, and certainly when some of the other companies talk about it, Really talking about the potential for AR in devices that are going to come after the phone.
So there are inherent limitations to AR in phones.
I, for one, don't believe that AR is going to take over the phone and everybody's just going to walk around in AR mode all the time.
That's definitely not going to happen.
But I do believe there's huge potential.
I believe that potential is going to come in future devices.
Having said that, there's huge incentive for all of us to try to learn about AR, to learn what works and doesn't work, to evolve the technology on mobile devices today.
So a lot of the interest you see from other tech companies that I won't name by name and us is trying to figure out this technology and advance it and evolve it while this other kind of hardware is being developed.
So, what's the killer feature for a real world AR game?
You know, some people ask that of us a lot, and I don't think it's the AR.
I think AR is nice embellishment on top.
It's the icing on the cake.
The things that we think are really the killer features for games of this type are the ones that we adopted as our core principles.
That's why we adopted them.
But it is exploration, exercise, and real world social interactions.
In terms of the, you know, I said earlier we had 3 million people come to events that we host.
Pokemon Go players organize their own event once a month, it's called Community Day.
We support it with a little live ops programming behind the scenes.
But there were over 100 million players that participated in Community Day last year.
So intense interest in people getting together in real life.
And we think there are reasons behind the exercise and the real world social that are pretty obvious.
Both of those things make people feel better, ultimately.
So there's a feedback loop there that's driving that.
Okay, so that's the past, all right?
Now it's time to look towards the future.
So what is the interesting technology that we're working on and other people are working on with AR?
We're gonna get into the meat of that.
So the way I like to characterize it is connecting the atoms and the bits.
So if AR sort of V1 is open your phone, see a hologram, Maybe it is sort of situated more or less accurately in space, it's glued to the ground.
It doesn't really know where it is.
It's not really part of the world.
It's sort of a parlor trick.
It's an illusion that's fun, but there are limits to how far you can take that.
So ARv2 is about really connecting those bits, the thing that we make in the computer with the atoms of the world.
And having those objects be grounded in specific locations being aware of those locations, being shareable, and being persistent.
So when we think about what's next, there are three kind of key areas of technology development that we think are essential to realize that vision that I just described.
The first is mapping, and I'm gonna talk about each of these in more detail.
The second is understanding or interpreting that flow of pixels that's coming into the device.
And the third is sharing, the ability for all of us to have a common, shared experience with AR.
None of these are really possible with today's technology.
So each of these three areas are new things that need to be invented.
So let me talk about mapping first.
I think this is, this is the one that's near and dear to my heart.
It is a continuation in some ways of the work that we did.
on Google Earth and Google Maps.
But it's really different in some ways as well, because we made Google Earth and Google Maps for all of you.
We made it for people.
It's designed to be a fun, friendly, accessible UI for human beings so that we can never be lost again.
We can navigate wherever we want in the world.
The AR maps that we're building are built for machines.
So it's a very different kind of map in some ways.
Now, I want to say, when you say we're building maps for machines, it sounds like Terminator or something like that.
It's in the service of helping us be better human beings.
And that's a really important thing for Niantic.
I think you've seen some of our thinking around that.
It's to allow us to better connect with the world and to have shared social experiences with one another.
But fundamentally we're building these maps for computers, and those computers are cell phones today, those computers may be glasses in the future, and by the way, they may be robots beyond that, because robots that want to move around in the world need that very same kind of precise localization.
So what the map does by accumulating data is to allow the computer to know x, y, latitude and longitude, exactly where it is in the world, down to an order of centimeters.
That's what we need for AR, preferably like single digit centimeters.
And we wanna know the 6DOF orientation.
So we wanna know exactly what that device is pointing at so that we can interpret and add to that scene.
So you sort of go into the next deeper level of what does that look like.
You know, it looks something like this.
So you start with lots of images.
in different ways those images might come into a system, but from that you're gonna derive a very, very detailed three-dimensional understanding of space.
And you have a bunch of points that almost looks like a solid physical object, but that is a collection of data that lets us understand a specific location.
Now you can glean from looking at this image, this is a small statue, lots of photos, lots of points.
That's a lot of data.
I mean, you think about the entire world.
Like, think about all the places that human beings can walk in the entire world.
If we want AR to work out of the box without having to remap, re-localize, do a lot of work every time we wanna use it, and I think this is really, really important.
this map's gotta be created, okay?
And point number two is that at this scale, the world is not static.
Like, stuff changes all the time.
It's incredibly dynamic.
So this is the kind of map that...
It's probably a map that never gets finished, really.
This is like a lawn that you mow, where as soon as you get done on one side, you start over on the other side.
It has to be continually rebuilt and refreshed and extended.
So in our view, we think this kind of thing can really only be built in a cooperative way by people that are using a system.
So a collaborative, ongoing effort to constantly map and remap the world.
In terms of a more concrete example of a system working that uses this technique, I'll show you an example of a system from our research team.
And this will show you that evolution from photos to points to putting holograms into the world.
So this is the Ferry Building in downtown SF.
Maybe you'll have a chance to visit if you're from out of town.
Really cool place.
So lots of photos are needed.
From that, we get what you might think of as a point cloud.
The points that you pick are really important.
Once we have that, we're able to put things into the environment.
And importantly, because it's in the cloud, you can come back the next day and see things in exactly the same location as you saw them on the first day.
With this technique, we can put holograms in place over very large areas, indoors and outdoors.
And finally, everybody who's having the AR experience is seeing the same thing.
So it's really as if the hologram's part of the world and not this sort of manifestation that you've created.
Okay, so that's mapping.
The second piece is understanding.
So, point cloud, there's a bunch of points.
If we want our games, our characters, the story that we're telling, to interact with the world in a meaningful way, we have to imbue the system with a little bit of intelligence to know what's happening, what objects are in the scene, what are all of those pixels, what are all of those points.
So that falls into an area that some people call segmentation.
We're talking about various techniques and there are multiple techniques I'm going to show you too involving deep learning, neural networks, to essentially decipher what we're looking at.
And that opens up all kinds of possibilities.
So we would think about a vocabulary for AR.
In this case, if I wanna put a vase on the table, and I wanna put Pikachu in the chair where he belongs, which is the point cloud, you can't really do that.
You don't know what it is.
You know the shapes, you can put something on top of something or hide it behind something, but you can't really do things that are semantically interesting.
So what neural networks enable us to do are, they enable us to segment a scene like this.
and this is a real screenshot by the way, this is a made up artistic creation, it lets us identify what's in that scene with a pretty high degree of probability.
So we know at a high confidence level that that's a monitor, we know that's a chair, we know that's a table, and so on.
So we can actually then respond to that and we can put Pikachu in the chair and a Voss on the table.
Even more importantly, we can put Comby with our flowers in the garden and we can put Psyduck with his duck friends in the pond.
So that's one type of ML that can be applied to AR that I think for us, for game developers, people want to tell stories, is really important.
This is another type.
So I talked about mapping the world and how hard that would be with all the stuff that changes.
Some things actually change second by second.
So the idea of mapping them in advance is a non sequitur.
People walking down the street, cars driving down the street, you don't create a map of that.
So that's something that you actually have to understand in real time if you want to augment the world in a way that's realistic.
So this is another piece of work that we're doing.
And this is deep learning.
solution that basically can provide the depth of all the pixels in a scene in real time.
So rather than mapping in advance everything that's happening here, we're deciphering depth in frankly a dark, kind of a dark and mysterious way in terms of how these neural networks work.
But we can understand the depth of people as they walk around in cars.
So, that nicely complements the map piece.
So you can build a map of all the permanent structures, the stuff that doesn't change, and then for the really dynamic stuff, with people moving around and cars moving around, you can add this capability.
And it really is quite amazing to me, as somebody that's worked around computers for 25 years, that this kind of thing is even possible.
But it is. The rate of change here is phenomenal.
That allows us to sort of fix AR in a way that it's really broken today.
So if you've used our products or others, you will know that if you drop your Pikachu for photo mode into the scene and somebody walks in in front of Pikachu or other things happen, that illusion of reality gets broken pretty quickly whenever the character is not properly occluded behind things that it should be occluded by.
So we want to see Pikachu ideally here be hidden behind objects and people when it should be.
That will help us believe that this hologram is actually part of the world of atoms, the one that we live in.
So when we apply the system that I was just describing to the same situation, we see that as people walk in front of Pikachu and as Pikachu moves around these planters, that he's properly hidden.
and that's what we want.
We want to create believability.
We want to make these atoms and bits indistinguishable from one another.
That's the ultimate goal.
Okay, so that's, we talked about mapping and we talked about understanding.
The third kind of key piece of technology that I want to describe and show you some of our work around is around sharing.
Games are played between people games are inherently shared experiences.
Those of you who are building console and PC games. I'm sure have dealt with latency in a multiplayer situation.
It's really hard to share lots of data between users, especially when you have a fast pace game and things are changing all the time and you need to keep everybody updated.
and locked.
And we know that with online games, sometimes we can cheat because we don't really know what that person is doing.
And so if you lag behind a few frames because there was a hiccup in the network for a brief period of time, you can sort of fudge it and then make up for it.
With AR that becomes a lot more difficult.
because you actually see the atoms, the people moving around, and you see other things that are real visually instantaneously.
And so the additive stuff, the holograms that you're adding into that environment, need to track with the atoms really closely, or it's immediately obvious that you're out of sync and things are broken.
So why do we care about it?
We care about it because we want to make experiences like this better.
We want to have a truly shared, immersive, holographic AR experience.
So we've been working to figure this stuff out.
And we built this, which I'll let one of our amazingly talented designers introduce, David Holland.
And this is code named Neon.
So what you're seeing here is high speed, low latency, shared AR.
So you have shared resources on the ground.
So think of those as Pac-Man pellets.
Those are energy globules that you need to absorb in order to attack the other players.
You'll see people walking around.
So each person is being tracked.
in real time in this environment.
And this is all footage taken directly from device.
There's no CG applied here.
And you're seeing projectiles fired between the users.
So it's all being tracked in AR, all being shared to all the users at the same time.
It's really hard to do that right now.
There are just some laws of physics that get in the way.
You need around 10 milliseconds or so for that to be imperceptible.
OK, and if you were building something today that has to round trip to a server over the internet, you're talking about 100 or hundreds of milliseconds typically.
Obviously, a lot of folks are trying to get those latencies down for many applications, including cloud gaming.
But it is a big problem that has to be designed around.
We've found some ways to do some clever things so that we can do that in many situations today, including in some 4G LTE environments.
But it's not easy.
This is another example, so it doesn't have to be about shooting.
Let's see, Lena.
I'm Lena from Niantic, and this is Tonehenge.
She's gonna introduce us to this.
So this is a puzzle-adventure-y kind of shared AR experience that we also built.
just to kind of explore a different dimension of gameplay.
I was a huge Myst fan, so I particularly love this one.
So we'll see in a moment, a hologram that everybody is sharing.
We actually cloaked the other players just to sort of add to the ambiance.
That's really hard to do, and there's some interesting work to be done to really clothe and cloak people in a more intricate way.
But this allows a complicated puzzle to be manipulated by all the users at the same time.
You have to talk to one another and synchronize your actions in order to unlock this thing.
and solve a puzzle.
So the whole idea is to give people reasons to talk to one another, right?
I mean, that's really the heart of social gaming.
You're creating a context where, giving people an excuse to be social.
You're making it easy for people to be social with one another.
So that's Tonehenge. I'm really hoping we get to turn that into a full-fledged game.
So on 4G networks, you can make this stuff work, but it's hard.
5G, for those of you guys that read the tech press or are into networking technology, you know that there's a huge amount of hype about 5G.
It's probably one of the most hyped technologies that's been around in the last several years.
A lot of people would say it's overhyped.
There are some real advantages for AR.
So I'm personally grateful that we have 5G networks coming.
It's going to make AR.
much easier for us.
Number one, latencies are lower.
So you can actually get latencies between 5G and edge computing, which is part of the overall paradigm that's rolling out.
You can get 10, 20-second latencies on a regular basis.
The other area it helps us is that 5G supports a far greater density of users in a given area.
So if you want to do mass outdoor AR gaming where you have lots of people playing in the same space, 5G is super helpful.
It actually supports by spec three orders of magnitude more people per essentially cell tower.
Real world performance may vary, but nevertheless it's a much better architecture for shared AR.
So we are forming partnerships with a lot of the companies that are building the networking infrastructure to make this possible.
To help them do it in a way that's going to be good for AR and to also really be on the cutting edge as this technology lands in consumers' hands.
So folks like Deutsche Telekom, SK Telecom, and Samsung are all instrumental in the backend systems that are going to enable 5G for consumers.
Okay, so we talked about history, and we talked about the tech that's being built.
So now we get to the fun part.
Okay, so since technology exists, what are the implications for the kinds of experiences that we can build, for the kinds of games and non-game experiences that we can build?
So I wanted to say something thoughtful about this and not just show a bunch of demos.
Broke it out into a couple of categories.
I really think about it in terms of two fundamental kinds of interactions that we can do.
We can add information and services to all of the atoms in the world.
So all the physical stuff can kind of work like the web.
Like you can connect to information and you can make it do stuff through web services.
And then the other major area is to, is to add things to the world, okay?
And I'm gonna talk about each of these separately.
So in terms of information and interactivity, as I said, it's about information and services.
And in terms of adding things, I wanna talk about those as augmentations, just generally.
And here, in the first case, we're talking about connecting atoms to bits.
In the second case, we're talking about making bits that can really fool us.
that can realistically masquerade as atoms.
So we want the bits to feel and act as much like real atoms as possible.
When we think about the first problem and what we might be able to do with it, this is really the AR vision that we've been sold by sci-fi, by movies.
This is about walking around with glasses and being able to know more about the world.
So you might walk to the Ferry Building in SF and you might learn about the history of that building and who designed it and why it looks the way it does right now.
You might walk up to a piece of artwork and understand, okay, who is the woman depicted in the statue?
You might walk by a restaurant and understand what Yelp has to say about that particular restaurant.
Maybe you're running late for a dental appointment, you run into a building, it's got 20 floors, you know your dentist is somewhere in some office, you can know exactly where they are and how to get there.
So incredibly powerful.
That's just learning.
Then there's a whole other layer that we can do here, which is to enable interactions.
So we can not only consume information, all these things can become interactable.
So we can perform actions.
If we walk up to the bus stop and we see the bus rolling in and we don't have money on our card, you can transact.
You don't have to go to a physical terminal.
I go to the airport, you can check in.
When you arrive at your hotel.
hotel, you can check into the hotel.
Think of all the places in the world today where, I mean we've tried to kind of do it by installing kiosks and things like that.
All of that can be just a surface that becomes an interactive surface for services.
Now people have thought about what this might look like, and one of the best known of those is a guy named Keiichi Matsuda.
If you guys have seen his work, by the way, the Hyper Reality film series, I know many of you have. I'm going to play about a minute of this just to remind us of it.
It's interesting.
Let's just take this in. This is a possible future that we might live in.
I already feel stressed and nervous just watching this video.
So the system knows where we are.
We're going to find out in a second that we know when to get off the bus.
That looks helpful.
You know, there are times when I might like to see a path by guiding me through the world.
What's really crazy is this part, where she goes, she's going outside.
Now the world is plastered with ads and distractions.
So...
It doesn't have to be like this.
I had a chance to meet, actually I was at a talk, it was kind of like this, I was talking about hyperreality and I was talking about Keiichi Matsuda and how smart he was, and this guy on the side of the room held up his hand and said, I'm Keiichi.
So I had a chance to meet him.
And I learned about his work.
So he's not showing us that because he wants the world to look that way.
He actually follows something that's called, there's a school of design called critical design.
And the whole idea there is that you make things, you design things to question certain things in the world.
And so really he was very deliberately challenging.
what the world might look like if sort of current trajectories continue into the future and we build AR not in a very thoughtful or considered way.
And it's a world where you're tracked everywhere you go, where giant companies know everything about you, your identity is constantly at stake, and the world itself is noisy and busy and literally plastered with distractions.
So that's out there and some people would say, hey, AR is a bad thing because we've seen this vision of how bad it can be.
The point I want to make to you all is that it doesn't have to be that way.
And it's up to us to make it the way we want it to be.
And there's some incredibly powerful things that you can do.
So I don't think we should be scared by KHE's vision.
I think we should be informed by it.
And actually I know he's continued to work in the field of AR after that and he's helping do some of the work to really define how AR should work.
But I imagine a future where with the kind of map that we described and with the kind of understanding that we described that we can have experiences like this where we can learn about the world in a deeper way.
and we can access things.
Like, I think, like riding public transit, I try to ride the subway or the trains or the buses in every city I go to and I travel a fair amount around the world.
And it's like the most complicated adventure game that you've ever played.
Trying to figure out how to buy a ticket and navigate through the terminal.
That could all be so much easier with AR, and that would be a social good.
If more people rode public transportation because they could understand it, it'd help them get places in a more reliable and easier to access way, that'd be fantastic.
And it's one of the things that I think AR can do for us.
So just to address some of the, you know, if the more technically minded people out there might wanna challenge a few assumptions here, you might say, hey, you know, you can do some of that stuff with an app today.
Like, there are a bunch of apps in the App Store.
And that's true, but it puts a huge amount of work on you as a user.
You're kind of the in-between.
You're the glue between the world and the digital world, the atoms and the bits.
So you have to go find the app, install it, all the apps work differently.
I, for one, know that I'm in venues all the time that say, hey, use our app.
and I don't download their app, because I already have a lot of apps on my phone, and it takes a while, and it's complicated.
So I don't think that really is the solution.
The other sort of counterpoint would be, well, maybe you don't need this kind of complicated AR cloud that you were describing to do this.
Maybe there are other ways to do it, like you could have QR codes on things, or you could have Bluetooth beacons that tell you where you are and what's going on.
I don't think we really want to put a QR code on every object in the entire world.
I think that would be kind of hard to do and would add a little bit of pollution to the world.
I think that would be a bad thing.
It's not really a very practical idea.
Bluetooth beacons are even more expensive and more difficult to deploy.
Many companies have tried to deploy large networks of Bluetooth beacons and it's expensive and hard.
I don't think that's really the answer either.
Even like raw computer vision, raw computer vision in some cases can tell you, hey this is a Starbucks or this is a bus station, but it has a very difficult time knowing that this is this specific bus station, this is this specific park bench, a specific anything.
Because it's trained to recognize patterns and specific things are hard to pick out from all the things that look alike, frankly.
So the AR cloud is essential even if you have good computer vision.
So, let's move on to the second class of things and I have some examples I want to show you here too.
So we're talking about augmentations, we're talking about putting things in the world that look like us or they look like creatures, they look like guides.
So these are things that might entertain us.
they might do useful things for us or they might even help social interactions between people.
When we think about games, you think about Pokemon, you think about adventure games, you think about putting fictional characters into the world, it's kind of an obvious thing that we wanna do with the technology.
But, if you tried to do it right now, you might run up against barriers that you weren't expecting.
Like, you know, one thing that I can imagine is, Okay, imagine that we want to have this great, noir experience in San Francisco.
We want to be Humphrey Bogart.
We want to go through the city on an adventure.
We might want to meet a hologram.
So imagine that there's a hologram standing down on the waterfront of San Francisco.
If that hologram doesn't know where it is, if it's just something that you popped up in your phone, but it's the same experience that could happen anywhere, there are limits to how sophisticated that interaction can be.
But if that hologram knows it's standing on a specific street corner in San Francisco and it can direct you a half mile away to Coit Tower on a quest to find a clue that will lead you on the path to the Maltese Falcon, that would be incredible.
But to do that, we have to have holograms, we have to have augmentations that have contextual awareness.
We need the AR map for that, and able for these things to know exactly where they are in the world.
We, the other thing that it gives us, and we talked about it earlier, I have to rebuild the whole slide again, is that it allows us all to share that experience.
So it's not, you know, if only you can see something, there's a word for that, it's called a hallucination.
Sometimes that's a bad thing.
But if we can all see it, it's an amazing shared experience, which we all talk about.
So the sharing part, the everybody seeing the same thing part, is really, really important.
We've been dreaming about this at Niantic.
Our designers and artists have the things that we want to build.
We imagine our festivals with real life gems and Pokéstops that everybody can see and understand together.
Even going back to the early days of Ingress, we were thinking about this.
More recently, we've been thinking about non-game applications and what these kinds of holograms can do.
The technology is not there yet, but I think you saw from the preceding section that we are getting closer.
This is an example of one of those baby steps forward.
So, this is a project that we did with our colleagues and partners, SoftBank in Japan.
It's done on HoloLens 1, not HoloLens 2.
And we actually captured this footage at the top of Roppongi Hills.
I don't know if anybody's been to Tokyo, but probably some of you have, and you know the big skyscraper.
So when you see this, imagine you're on the top floor of the skyscraper.
We're gonna look out the window in a second, you'll understand why.
So as we look around the room, we're seeing, and everybody who comes through the experience, we ran a bunch of people through this, everybody saw the same things in the same location, so they were shared experiences, as I was talking about.
We had specific Pokemon inhabiting certain parts of this pretty open room.
And then when you walked out to the window and looked out across the city, you could actually see all the Pokemon gems where they're supposed to be.
We can see our legendary birds flying through the air. I think Moltres is in the background.
So it was really exciting for us because it was one of those glimpses of the future.
You know, you can only do this in a limited way.
You can prototype under certain conditions.
But it is a glimpse of what's going to be possible in the not-too-distant future.
Okay, so I want to wrap this up.
I think we're getting close to time.
So we've talked about AR and we've talked about...
the history and the things that we've learned.
We've talked about the technology that we're building.
And last, we talked about some of the product potential.
And I think for you product designers and game creators out there, your mind is, you probably have 1,000 ideas of stuff that you would like to build.
So whenever people ask that question, well where is AR in the sort of hype cycle or whatever?
Is it up, is it down?
I don't really care about that.
The question that's interesting is, is it something that is meaningful with a capital M?
Like is it something that's gonna affect our lives in a significant way, in many people's lives in a significant way?
And I absolutely believe that it is.
You know, what is happening on handsets today is a warmup.
That's the pregame.
What's going to happen with glasses in the future is the real deal.
But I think it's one of those platform shifts.
you see it once every 10 or 20 years.
You know, and I've lived through a couple.
We saw PCs, we saw the cloud, we saw mobile.
I think AR is one of those shifts.
So it's something that I think is worth our time to understand.
It's worth our time and money to invest early in.
And I think it's gonna be hugely important.
Rose colored glasses, I wanna touch on that.
That was part of the title of the talk.
People have knocked AR because they've said, Oh, I didn't switch my slide to the beautiful closing slide here.
Perfect, rose-colored glasses.
So some people have said, hey, I always like rose-colored glasses.
You're taking it away from the world.
People aren't seeing the world as it really is.
So it's a bad thing.
I want to push back on that a little bit.
A good pair of sunglasses, if it's bright outside, they actually don't get in your way of seeing the world.
They help you see the world more clearly.
They eliminate the glare.
You can focus.
You can see things you couldn't otherwise see.
And that's how I think of AR.
We're adding things to the world, but the things that we can add can deepen our appreciation for the world and our understanding of the world.
I think there are two primary things that AR can do for us.
One is it can allow us to see the world in a fresh way by causing us to pause and seeing history.
everything that's interesting about the world brought forward to us.
I really think there's an opportunity to deepen our connection with the places that we live.
The second thing that I think is incredibly important about that is that it allows us to do it in a shared way and to have experiences together, to have these adventures in real life with our friends, with our family, and with our kids.
And by deepening our connection with community...
in the physical sense, and deepening our connection with community in the meeting our neighbors and doing stuff together with our friends sense, I think is a really important step forward for technology.
And frankly, I think it's something that we need.
I think it's something that the world needs.
You've seen how it can go wrong.
So thank you, Keiichi, for showing us how horribly wrong AR could go.
But I believe that the positives here outweigh that.
And I want to put it to everybody here.
There's a Gandhi quote, which is, be the change you want to see in the world.
In our professional lives, I think the quote is, it is really up to us to build the future that we want to live in.
It's up to us to build the future that we want to live in, that we want to exist.
And more importantly, it's up to us to build a future that we want our kids to live in.
So if you guys are inspired by the opportunity here and are interested in AR, reach out to us.
We have a contest.
We're looking for allies.
But there's a lot of work to do and I think it's important work.
Thank you.
