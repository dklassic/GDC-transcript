Well, thanks for the introduction.
And hello, everyone.
Welcome to our talk.
Today, the topic of our talk is how game designers analyze data, how to develop an online pivot table too.
So let's get started.
Before the talk, here is a quick introduction of myself and my partner.
I am ZiJie, a project manager from NetBeast, and I'm also a game designer in Naraka Bladepoint team.
And my partner, Yong Yuan, is a tool developer in Thunderfire UX.
He has developed a virus of tools from web tools to client tools.
And he has a coding experience for over 10 years.
And the tool he has developed has chipped in several games in our studio, such as Revelation Online and Naraka, etc.
So today we're here to share how to help game designers quickly get started with decision making through data and cultivate data-driven culture by developing a reproducible online pivot table analysis tool with a low development cost.
We will organize our talk into four parts.
The first would be what problems we are facing with.
And the second part would be the design pattern and how to quickly achieve this tool.
The third part would be a simple demo shows how the tool is chipped in our game and how it works.
And the fourth part would be the takeaway and suggestions we can bring to all of you.
OK, here comes the first part.
What problems we are facing with?
In our studio, data-driven decision-making has been a routine among designers.
Data is the most objective factor that loyally reflects the exact operation pattern of a player.
Then designers and the user researchers can dig the real demands hidden behind the behavior.
In order to cultivate data thinking among designers and make decisions quickly through data, designers often need to raise demands to our data engineers to obtain data, and then use Excel or other tools after obtaining the data for analysis.
However, data engineers in our studio often have other important tasks to handle.
They are often assigned in-depth research and the development of some important topics in games, such as financial system monitoring and social system monitoring.
Also, they are responsible for in-game recommendation system and abnormal monitoring.
Here's a diagram shows how data demand worked before our tool chipped in our workflow.
Normally, there are three ways to handle a data demand in our studio.
First is developing a real-time check monitor.
However, it costs much developing resources.
Second, we have a business intelligence platform.
Designers can raise a data demand and use the data dashboard for stable demand.
And third is directly raise demands to a specific engineer for service.
A data product manager might be helpful to clarify designers' demands into keys and rules of the database to the engineer.
The process will cost several colleagues for every demand, and the communication cost is also high.
Let's take this diagram as an example.
For a data demand, a real-time check method is instant, but it's resource costly.
The second one is BI platform.
Let's assume it may cost three hours for an engineer to develop for a single demand.
And the third one is manually fetch.
It may cost three hours and many colleagues to coordinate to finish the fetch operation.
Additionally, all of these three methods have communication costs.
We have data product managers to handle the communication process with designers, the communication process may also cost all the relevant people for, let's just say, for an hour.
So every method have either resource cost issue or time cost issue.
But our tool, as a customizable tool, can handle different demands in one tool.
And a single designer can handle this.
Facing with a situation above, our tool is targeted to finish the whole data demand process in 30 minutes, and only with a designer, his own.
This diagram shows the traditional way we handle a data demand.
It takes at least three person to handle a single demand.
Four processes are involved in it.
And this diagram shows the target of our tool.
Designers directly get the data through our tool, skip the communication process, and the repeated operation of writing SQL code.
Engineers can spend more time on the more valuable work.
Before our tool is developed, there were four processes in the total to finish the data demand.
But after we shipped it in our tool, there are only two processes in total.
Again, let me emphasize that developing every tool is for upgrading the efficiency of our colleagues, lower both time cost and labor cost.
And the pivot table tool is not excluded.
And then we go to the second part, what solutions we suggest.
For an engineer, querying data is just writing several lines of SQL code to look up some data in the databases.
But for a designer, to expect every designer have a technical background is not practical.
Let them learn SQL code is not a wise choice.
The key problem is how to bridge the designers with the data.
Before the tool is developed, our data product manager and engineer who communicate with designer and the marketing department had really a hard time to know what some designers really want.
Like one of our data product manager mentioned, this demand is a total tragedy and a long word document with ambiguous descriptions.
Finally, I found that they even did not tell me which locks to search.
I do not know which designer gave this demands but it is obvious that the process cost, cost much time for designers to clarify with data product manager and engineer about the exact demands they want.
Gradually, our data engineers work out a regulation to let designers to follow.
Designers are required to provide an Excel file, including important messages and rules they want to add to the SQL code. Like in this picture, they are told to provide time information like every Friday, Saturday, Sunday from March 11th.
And the logs they want to check is the GM trials, dungeon reward log, and the inner logic of some data, like the average daily activity.
It costs less time in communication, but still need engineers to handle the SQL search operation.
Still, more than one people are involved in this process.
Following this, we want a more direct way to let designers to handle data demand on their own, something like advanced search engine.
It should have powerful functions and customizable keys.
But advanced search is a tool which is hard for designers to learn.
Too many keys to add and it is easy to miss important information.
We should not give designers too much things with all directions.
We need fewer entrances but lead to a correct SQL code with enough messages.
So after this, a more practical method is to translate the SQL code into natural language that everyone can understand. Designers can set the keys, like filling some forms, to finish a paragraph of text. And a SQL language can be generated to automatically query the results in the databases.
So combining with the data structure contained in our game, we decided to use a 5W model to design a question and answer system.
The designers can use 5W to organize their data demands in several questions.
So 5W2H is originally a concept in management field to disassemble an event into several elements.
We modified it from original ones to meet our situation.
So r5w is who, which refers to the primary key of this data query, and whom, which refers to the detailed description of the primary key.
And what refers to the purpose of the data query, when refers to the range of the data query, and where refers to the server range selected for this query.
We use 5W to cover all keys designers can query.
They just need to choose exact keys among several dropdown menu.
And 5W can disassemble demands like disassembling other events.
And it only provides five entrances for designers to fill.
It won't be too messy for them to handle.
And let us see how exactly this method works.
This sentence shows the designer want to query all roles in November 16 at all servers.
All channels, the information include the role's name, date, they've created the role, and the servers, and the occupations, and the battle power.
The 5W questions will show one by one for designers to answer.
It is also a good way to ask a designer to think again about their data demands by going back through the sentence again.
By this means, we try to let the designer know what are the elements to form the data demands.
And this is how the result of our tool is given.
We provide the data through a pivot table.
Designers can modify the pivot table with the exact key they want to show.
And data visualization is another important demand of our tool.
Designers need an intuitive view of our data.
A pivot table is a good way to represent data with more than two keys.
So that is why we decided to aggregate the pivot table into our tool.
So enough part for the design pattern and now it comes to the engineering part.
Let's leave the stage for my partner Yong Yuan.
He will introduce how to achieve such kind of tool with low cost method.
However, I move on in time.
How to achieve a pivot table to present day is another issue we are facing during the development.
Let's see the test stack of our tool first.
As a typical web tool, the front-end uses mainstream technology structures, TypeScript and React.
The component library uses an open-source library and design.
The API shell is Python Django, which we can implement lightly and easily.
And the database is MySQL.
So, how to choose a private table based on our stack?
We investigated some of the popular technology solutions.
Commercial software like Flexmaster, DHTML, and CharmPilot is not suitable for us, since it costs a lot of money.
Open source components, such as Private Table JS, are not suitable for us.
And because the UI is not pretty useful enough, and it's not easy to extend.
So we decided to use a table compartment of Andy Design to extend the implementation.
After we decided to implement this Andy Design table, there are still some issues.
The back end means two problems.
performance of fetching data, and position of the circle.
The front-end main needs to fulfill performance, fix serial number, header and data processing, frozen column, row, and serial width.
I'm here to share three main problems I have in front of you.
The first one is how to implement the serial numbers on the top and the left of the table.
Many of Shor's private table components don't have a serial number for the private table, but Excel has a serial number.
So our designer also wants a serial number.
So again, with the same tools and relations, we also make our tool intuitive.
It's very simple to use and learn to implement this.
We only need to set the first column as a number of strings and the number of sides can be increased according to the data length to achieve the number of strings.
For the order of the top, we can set the letters to the value of the header.
If there are more than 26 columns, we will use AABB.
The second is table header setting and data procession.
Our tables are generally used to view set-dimensional data of rows, columns, and values.
Material tables can only view two-dimensional data, so we need to make the anti-design table components view multi-dimensional data.
It was the fusion that the header of the anti-design table components.
can be nested.
Put the value of the column in header and throw the nesting object header.
And let the low and the right data spread normally so that the most basic low column and the right data of the power table will be quickly displayed in our table.
Many people may think that the header can only put things like but we have to break the conventional thing so that you can achieve some expected results.
Here is how I extremely studied children of the commons.
The learned data and results of the final power table are shown in the figure below.
The third problem is the free stored rows and columns of the table.
When there is a lot of data in the table, the current rows and columns can be frozen after certain data, which is needed to display the data.
That's also the reason why I didn't choose other open-source parallel table components.
because they don't permit this function and it's very troublesome to implement.
The end-to-end table components supports raising counts by default.
We only need to monitor the query behavior and use the assess card to raise it to face this load.
The front picture is the effect after we add the frozen length and there's no need to worry about the data we want to check.
after two months of scoring.
After brief introduction of the design pattern and the engineering pattern of our tool, let's see the exact situation when our tool achieved in our games.
Let's take Revolution Online as an example.
Revolution Online is a memory mobile game.
It has a large number of players.
supported by RStudio.
Due to the large scale of players, massive data has been generated.
R designers are accustomed to data-driven decision-making and it has become a feature of the development group.
The R Showbiz is a large part of our daily data demands.
Here's how the designers use R2.
R2 has been chipped into the game database.
Designers now directly use R2 for data amounts.
Up to now, we have chipped in short games and make future contributions in more games by helping designers to open and analyze data easily.
Part 4, How to Improve a Private Table in Your Studio Today, we show how to help game designers quickly get started with decision-making through data and card rates, get German cards by developing a reproducible online private table analysis to reach a low development cost.
We also showed why it's valuable to our studio and how it changes the workflow.
And if you want to implement a tool like our pivot table, I can give you two suggestions here.
First, try to cultivate the data-driven skills among your designers.
Own your strong view of improving user experience through data and make decisions.
Through this, can the tool make better contributions?
Second, the purpose of developing tools is to improve efficiency, reduce repetitive man-labels, and reduce cost.
The developing purpose of our tools is the same.
We must be good at using open-source software for rapid development.
The technologies used by our tools are here referring.
If you are interested in them, you can also look to implement a similar tool in your shorter period of time.
And here is the three main takeaways that you may be interested in.
First, a direct tool is a bridge between designer and data.
Second, Finder can help designers to regulate their data demands and cultivate data-driven thinking.
So I provide a scalable and low-cost tool that developers can refer, especially for innovator developers.
Thank you for your attendance.
