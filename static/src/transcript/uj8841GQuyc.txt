You All right, my name's Mike Bridgman.
I'm here to talk about how not to build a VR arcade game.
And the title of my talk is partly inspired by Thomas Edison famously saying he invented 99 ways how not to make a light bulb before he invented the best way to make a light bulb.
So I'm gonna talk today a lot about the lessons we learned through a lot of trial and error.
So let's get started.
Who is MajorMega?
That is a company I co-founded in 2013 with Sean Hennessey.
This is our first official company photo.
My mother questioned my professionalism when she saw this, but I had to explain that if somebody doesn't wanna work with us after seeing this photo, well then I sure as hell don't wanna work with them.
So, it's kind of a qualifier.
It works really well.
Our current mission is to create the arcade machines of the future.
And so the arcade machine of the future has a tall task because with Oculus Quest and Home there are some incredibly immersive experiences you can have at home.
So you've got to do something much more grand than you could ever experience at home along with other people.
So the HyperDeck is our flagship product.
It's got a full motion floor, very intense wind, heat, turret controllers, and then our current offering, or our latest offering, is the SpongeBob SquarePants VR dynamic duo game.
So, let's go back in time.
I think this was around 2016 or 2017 on a project with Nat Geo about landing on Mars.
And from this era, we're gonna learn that G-forces can be simulated, motion can be amplified, and fast iteration is key.
I don't think I have a slide for this, so I'm just gonna say right now, as much as I'd like to pretend I could tell you all the steps to eliminate motion sickness and make the perfect experience.
it really just comes down to trying something, tweaking, trying it again, tweaking.
It's a lot of just trial and error.
We're working on some tools that help with that, but I'll talk about that next year maybe.
So this project was a six degrees of freedom cable coaster.
And by six degrees of freedom, that basically means it can move in all directions.
So those cables lift you off the ground, they can go up, down, left, right, forward, back, toss you all around.
And this was set up for a week in Manhattan.
And it was a really fun experience because we really put a lot of our heart and soul into it and then we got to spend a week just watching people enjoy it.
I don't have really great video of the more intense parts, but you can see here these guys are entering the atmosphere, they're just kind of getting jostled around.
Then there's some more intense parts that get good reactions.
So, let's talk about this G-Force simulation.
During this project, if you put somebody in VR on this thing and just let it be a one-to-one experience, meaning the person is just letting the HMD do the work and getting tossed around with the ride, a lot of people are getting motion sickness.
And what we discovered is it's because they weren't feeling the proper G-Forces for what they were seeing visually.
So like if you're sitting in one of these chairs in a virtual roller coaster, chances are you'll get sick because your inner ear is not getting the signals it thinks it needs to feel like you're actually on that roller coaster.
So if you have two riders here, just sitting there with a one-to-one VR experience, gravity's pulling straight down.
But if we tilt you back, suddenly you're sliding back in your seat, right?
You're getting pushed against the back of your seat.
But if we take the VR image and we rotate your camera in the game engine to counteract that rotation, suddenly you have this middle ground where the person in VR is not getting the visual stimulus of being rotated, but they're actually feeling gravity pull from a different direction than straight above.
While this is not a perfect g-force effect, it is something like a real g-force effect and it works really well.
It works well enough to prevent people from throwing up, which is the most important thing in the out-of-home entertainment experience.
So then the inverse of that is true, right?
So you can amplify motion.
So if we tilt you back, and then virtually, we tilt your camera even more, we can create a sensation of you moving even more than you actually are.
So the real benefit to this is that we can keep you in a safe motion profile, but you actually think you're experiencing something much more dangerous.
Oh, and I should say, a rough number we use is 400% or four times the amount the person's actually moving.
Again, it's just trial and error, but I just think that number's important because it's really amazing what the brain makes up when they see something visually and feel enough of it to go the extra mile and be like, nope, this is really happening to me.
So this was a huge multi-million dollar project.
It was never something that could be put in an arcade, obviously.
And this is kind of what sparked our journey to create the Arcade of the Future.
So we wanted to step back and start from scratch and figure out what is the simplest thing we can do to create motion in VR without people getting sick.
So we started out by doing motion without motion in real life.
So the lessons learned from this era are that if you're not gonna move the person in real life, well virtually, you can't accelerate or turn.
The more wind, the better.
And you can do vertical motion, but it requires vibration.
And true randomness really, really enhances the level of immersion, and I'll get to more of that in a bit.
So we built this thing that we called the HyperRoom, and it's a Home Depot-inspired prototype.
You can see the steel bars there and some box fans.
I'm gonna show you a quick clip of this experience.
So you can see the person's rising up out of the truck.
Wind kicks in when they clear up to open air.
And then we just had a really simple mechanic of basically using a gravity gun to grab car parts and shoot them back at the cars.
So, because this person is never accelerating or decelerating, he came up out of the truck, was already going 55, it was a great experience and nobody really got sick.
And so, for that vertical vibration, I'm assuming a lot of you are working in 5.1 or 7.1 surround sound in your games, and a really, really easy way to add accurate and realistic vibration is through a low frequency transducer.
And the Kleenex brand name of that is the Butt Kicker.
Maybe you've heard of it.
They're popular in home theaters.
They shake your sofa.
But basically a low frequency transducer is a speaker without a speaker cone.
So all you have to do, and in my company that all you have to do phrase is a trigger.
That means it's not actually as simple as you're saying.
But all you have to do is hook the subchannel up to this transducer.
And then when you send an explosion or gunfire or an elevator sound or whatever you're doing, your floor will vibrate exactly how it sounds.
So it's a really easy way to recycle the assets you're already using.
And then I want to talk about random.
You know, when we first did this experience, we wanted to add road bumps.
So you start out with just a very basic bum bum, bum bum, bum bum, just like you're driving down the highway.
But when the pattern is perfect, your brain kind of starts ignoring it, right?
It gets used to it, and you don't even realize it's there.
So then we started making, just using basically math.random, the simplest way we could do it, and mixing it up a little.
But it still didn't feel very organic.
And we found that using a Perlin noise function, maybe some of you have used it, it's a 2D visualization on the right here.
It's a really great way to get organic noise.
It's very popular in terrain generation and things like that.
So we found that using Perlin noise for environmental effects and haptic feelings, It's a really great way to add that next level of immersion.
So, let's take it a step further and add motion in real life with motion in VR.
So lessons learned from here are wind direction is not always important, mostly it's not important.
Motion and heat do require visual indicators to be truly effective.
And the fishbowl effect is real.
Players are self-conscious when you essentially blindfold them in public with a VR headset.
And haptics require a 240 frames a second or greater resolution to be effective.
So, for our platform, we went with three degrees of freedom, which basically means you can roll left and right, you can pitch forward and back, and you can heave straight up and down.
And we tried all kinds of stuff with airbags and springs and some other weird stuff, but electric linear actuators are the sweet spot of price, low maintenance, they're very affordable, and you can see here, they're a pretty compact package.
So then we built a safety deck around the motion platform, and we ended up creating what I call the VR Speakeasy.
This was set up in the storage closet of a sandwich shop.
I swear to God, you had to suck in your chest to get past the garbage bins to get into the door.
And every Friday night, we would invite people out.
bring a bunch of beer and just put people through this VR experience. They had no idea what to expect and uh we just studied whenever they felt sick or didn't want to play and we just kept iterating, iterating, iterating until nobody got motion sick whatsoever. Um so you can see here we we we took this thing to an open source conference um and this is before we had fully realized it but you can see that um this is um this is something from December 2016 on the wind is placed directly above him.
But what we came to realize is that if you're blasting someone with a lot of air and then you turn that air off and then you put a helicopter above them...
you can put that air back on.
It really doesn't matter what direction it's coming from.
They are convinced that that helicopter is what's generating that air and it's coming down on top of them.
So we actually removed ceiling fans from all our designs because for our application where the player is standing in the same spot, it was almost 100% reliant on the visual indicators of where that source of air was coming from.
We use infrared heaters for instant effect.
Infrared is really neat because it heats the water in your skin with microwaves, which sounds really scary, but it's not.
And so that's really nice for interactive applications where you're passing by lava or you have an explosion next to you, you can really feel that heat instantaneously.
This is a screenshot from one of our first titles called Hair.
There's two things going on here. The villain is shooting lasers at your vessel and at first we didn't have any kind of ambient light but we turned on the heat to represent those lasers cooking above you.
And people thought it was cool, some people didn't even notice the heat.
But as soon as we put ambient red light glowing all around you, it was just crazy.
Heat became the star of the show.
And it was always the first thing people said when they got off the ride, they said, and that heat was just insane.
And it was just, all we changed was a visual indicator that they should be feeling hot.
And then the other thing to notice here is that you'll see these spring coils on all four sides.
And we found that there's a lot of subtle movement happening.
And when you don't have a frame of reference, like a building going by you, or trees, or anything within proximity to really highlight the fact that you're moving, those springs give peripheral vision, give indicators that the floor is actually moving and doing stuff, and really helps highlight the fact that you are moving.
You have to promise my wife I didn't use this photo.
I told her I wouldn't, but I had my fingers crossed behind my back.
This is just a great example of the fact that she would never ever play this VR game when people were around.
But as soon as people left the room, she would strike a pose, she played the game, and she loved it.
But it was only when it was just her and I.
So this is a really tough nut to crack because at an arcade, you're just surrounded by random people, it's very hard to escape that.
So our solution was to basically enclose the player in a somewhat private space, so you're kind of going into the experience and closed off from the outside world.
And this ended up being very effective.
And then the last thing is this is a video of our motion test.
We've got 800 pounds of sandbags testing our motion floor.
And the really interesting thing here is that we started by just updating the position of the actuators in our game update loop, which For like a console, 60 frames a second.
For VR, it's hopefully 90 frames a second.
But I could feel the motor stepping, right?
I could feel the resolution of that motion.
And so we started increasing it and increasing it and increasing it.
It wasn't until around 240 frames a second that it did feel buttery smooth, where I could not feel the motion stepping.
And what's really interesting about this notion is that I was researching online how to manage threads in Unity that are updating a lot faster than the main core loop.
And I came across a guy who had solved it.
I looked up his username and I dug deeper and here he was making a VR controller with haptics built into it so you could feel like when you had a sword battle it would feel like the controller was bending or you toss a whip you could feel like it was recoiling.
and he came to the same exact conclusion that you needed a little over 200 frames a second for that to feel smooth.
So, all of our experiences so far have been on rails.
And it's really easy to not get players motion sickness when they're not controlling the motion.
But when you give them control, it becomes a lot more difficult to ensure they're not doing anything that's gonna cause either the rider or the passenger to get sick.
So, the lessons learned here.
are that you need to get out of the building, which I'll explain in a minute.
The safest path to no motion sickness is no yaw, and that just basically means you can't twist on your y-axis.
If you do want yaw, you're gonna need guardrails, assuming it's not an open-world exploration game.
You're gonna need some kind of guardrails to keep them on the path.
And finally, do not rely on real physics.
So, we had this prototype product called the Hyperdrive, and the front player there would lean left and right to steer the vehicle, we just measured your head, or your HMDs offset from center to lean it like a motorcycle, and then the back player had a turret gun much like the Hyperdeck.
And the get out of the building lesson is something I learned early on in software development that I did not listen to here, but...
When you're behind a computer all day working away, you're feeling productive, you're making a lot of choices and making a lot of assumptions that you know what your users want and you're building the perfect solution for them.
And so get out of the building means you need to get off your computer, you need to get out and talk to your customers, right?
You've got to interface with them and get their feedback.
And so with this product...
We spent a lot of time talking about where we're going to put the TV.
And the TV serves as a way for the spectators to see what's happening with the players in VR.
And so we thought we had this genius idea that it would be on the front here.
And there's transparent sides on each side of the TV.
So you could kind of see through the players playing, but then kind of have a portal right into what they're playing.
So we took it to the trade show.
I kid you not, every single freaking person came up and said, hey, why'd you put the TV on the back?
And we were like, what are you talking about?
That's the front.
And they're like, oh no, no, I'm pushing that up against the wall.
And so we didn't realize, we didn't show our design to an operator and said, you know, how would you prefer to configure this in your space?
And so that was a really, really hard lesson learned.
Then COVID happened.
We won't talk about any of that, but...
So, know y'all.
An easy way to think about this is like Spy Hunter, right?
It's a straight road, and you're letting the person turn, but they're just basically sliding left and right to change lanes.
It's gonna be a really fun game concept or game mechanic, but it's also pretty limiting.
If you wanna add y'all, you've gotta create guardrails that keep them on the course, because not everybody has their driver's license yet that's gonna play your game.
So as you'll see here, this is before we had implemented some safety measures, and this is what happens when a bad driver can slam, slam, slam, slam.
And I think you can imagine that the rear player especially is probably ready to barf.
So this is just a great example of an early test and us getting out of the building or bringing people to our building to test out these mechanics.
I don't have a diagram for this, but the easiest way to explain the solution that we arrived at for this is that if you hit the guardrail at a very soft impact or a small vector, we'll just bounce you back off, right?
It's a pretty low impact.
But if you come in at a really hard angle, we will let you go through the guardrail, fade to black, and then reset you to the middle of the track.
This way there's no harsh impact, you're penalized for doing it, and nobody gets sick.
But the angle of that vector and the speed of that vector is up to you to iterate on and see what works best for your application.
And then finally, don't rely on real physics.
So you can see here, this guy's about to take a series of jumps.
And on the last jump, he corrects himself.
I realize it's pretty small.
But he's veering off the road and he slams back on just in time.
And a fun way to look at that is going back to Super Mario, the original Mario Brothers game.
Mario jumps really fast and he falls really slow.
But while he's falling, you can actually move him left and right.
and that's obviously not realistic at all, but it's important to give players that level of control so they can self-correct.
So originally with this game, once you ramped, we were just relying on physics to let you fly through the air, and people were ultimately getting very sick because you can't project where you're gonna go once you hit a ramp.
And so all these things came together.
We launched SpongeBob SquarePants Dynamic Duo last fall in Orlando at the IAAPA Expo.
And this is just a fun series of events.
Oh, yeah!
Oh!
Oh!
Oh!
Oh!
Oh!
Oh!
Oh!
Oh!
Oh!
Oh!
Oh!
Oh!
Oh!
Oh!
Oh!
Oh!
Oh!
Oh!
Oh!
Oh!
Oh!
Oh my god!
Oh my god!
Oh!
Oh!
Oh!
Oh!
Oh!
Oh!
Oh!
Oh!
Oh!
Oh!
Oh!
Oh!
So it wasn't obvious in that video, but the player in the back is actually delivering Krabby Patties.
It's inspired by the Paperboy game.
where you're shooting at windows, other cars, launching them into driveways.
I'm a little early, of course.
The dry runs were a lot longer, but I hope you learned something today.
I guess I can open it up to some questions if anybody has them.
First off, this is a really fantastic talk.
I feel like I learned so much.
Really specific, good.
So who was doing most of the motion sickness testing?
Well, I'm a great litmus test because I get sick super easy.
But really, it was always internal and then we just invited beta testers out.
Awesome.
Hi, great talk, thank you for taking the time and energy to tell us about this and put this together.
So I'm curious from an accessibility standpoint, I've worked in museum places and things like ADA guidelines and things like those are usually pretty concrete and set, so I'm curious about how you approach this from an accessibility perspective and what those play tests might have looked like.
That's a great question.
So the HyperDeck was built with accessibility in mind in that the HyperDeck comes with a portable ramp that you can bring out and lay down.
And there's enough room to put a wheelchair on.
And if you lock the wheels, it is playable.
The SpongeBob game is not as accessible.
But in our industry, ultimately, a lot of the accessibility falls on the operator.
So we will do our best to create a ride that's accessible to all.
But the nature of motion especially, sometimes it's impossible.
Great question, thank you.
Yeah, thanks.
Yeah, I work in VR, so that's an important topic, but something that shouldn't be, you know, you shouldn't be afraid of it, asking this question.
So I appreciate you taking the time to even dive into it.
I'm sure you thought about it, but that's all.
Well, I'll say this, something I didn't talk about, but when we first launched the HyperDeck, I thought for sure everybody's first question was gonna be, how much does this thing cost?
Yeah.
But it wasn't.
The first question everybody asked was, is how big is this thing?
because they don't care how much it costs if it doesn't fit into their facility.
And the HyperDeck is a really big product.
And so wheelchair ramps take up a lot of space.
So ultimately that flexibility is left to the operator to figure out how it best works in their facility.
So we've actually had some places build a permanent ramp that goes out and then twists around the side of the HyperDeck.
Because that's just the way it needed to work for their facility.
That's awesome.
Thank you.
Anything else?
All right.
Well, thank you very much.
We got one.
We got one.
You mentioned 240 frames a second for the haptic feedback.
Was that just the feedback, was that the rate for ramping values, or is that sort of the speed of the phrases?
You know, so you were talking about a tick, so you have to have something that's continuous at 240 FPS, but what was the fastest speed that you rendered sort of haptic phrases at?
I'm not sure I totally understand the question, but I can say that with our actuators, we're sending absolute positions So much like an mp3 file compresses a perfect sine wave into stair steps. Yeah, that's what we have to do Okay, so you're sending smaller and smaller stair steps the faster our iteration is And in terms of hitting new targets, what sort of speeds were you hitting?
In our industry, you don't want to go over 1G force.
So the speed that you do, and there's tools you can use to measure the G force, if you go over 1G, F24, get guidelines by ASTM, require a restraint.
So that's kind of our limit is 1G.
Cool, thank you.
I hope that answers your question.
Thanks.
Hey, thanks for the talk.
I'm wondering when you're designing games for arcades, obviously you're going to be encountering a lot of first-time VR players So how do you strike the right balance between fun gameplay and easy to pick up?
Yeah, easy to learn hard to master right? It's our ultimate mantra It's tough. Something like the Spongebob game is great because um it's really intuitive to just lean like you're on a motorcycle. And we have a very very brief tutorial uh in the beginning that just shows up on screen. There's no way to skip it but we do try our best to make it at minimal. Um and in cases like hair, that game I showed you earlier, we actually have a tutorial that only pops up if you fail to start playing it the way we anticipate.
So people that repeat the game never actually see any GUI overlays, but the people that just sit there and don't pull the triggers to fire their weapon, they'll have indicators coming out of what you should do.
So that's just kind of a way we try to eliminate it for those that have come back to play again.
Cool, thanks.
Yep.
You're moving floor, is that moving in response to the user's input or is it all scripted on Rails?
So the hyperdeck is on rails, meaning we create the script that moves it.
It's the same every time.
Now that said, when the players fire their weapons, there is haptic feedback in the floor that responds to that, but it's not a lot.
It's just enough to feel like a gunshot.
With the SpongeBob game, it's the driver in the front leaning left and right that ultimately dictates the motion.
I have often wondered how you'd be able to simulate that.
Have you ever experimented with something like a vehicle where you want to?
the player accelerates and then you can actually do the tilting and making them feel.
So one thing we do that I would say is different than our competition is that we use 6 inch stroke meaning actuators can move 6 inches.
Most people use inch and a half or 3 inches.
But the interesting thing about the GeForce simulation that I talked about is that if somebody's rolled to the right as far as they can go, well then there's really no resolution left because the actuators are maxed out.
So with our six inch actuators, we actually only dedicate three or four inches to the player motion.
That still leaves a buffer for us to add effects and do those GeForce kind of tricks and not max out the actuators, if that makes sense.
Yeah.
Yeah, thank you.
I'm curious, is there a target duration that you go for?
At what point does the experience become too much?
That's a really, really great question, and one that has changed a lot over time.
Has anybody ever heard of zero latency?
It's like a free room warehouse scale experience.
You know, they were pretty early to the scene, and somebody we looked up to, and they were doing zombie games.
It took like 45 frickin' minutes.
And people, uh, VR gurus out there were saying, the longer you're immersed, the better, the more money they'll pay. And uh, so early on with the HyperDeck, we were targeting 15 minute games. And as soon as we started putting it out there, people didn't like that at all because there's a lot of standing around waiting. Uh, they felt like they weren't making as much money with a faster throughput. So we ultimately lowered the HyperDeck games to 8 minutes.
and even that is a struggle, and we're releasing a new title soon that's gonna have a short five minute option.
The SpongeBob is actually adaptable from three to six minutes, and I would say most operators prefer around five minutes.
So it really just depends, your throughput, what you can charge, you know, the cost per minute, but giving your operators flexibility is really the ultimate way to do it.
All right, well thank you so much.
Appreciate it.
