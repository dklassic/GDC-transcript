I'm Yves Jacquier. I'm heading the production services studios at Ubisoft in Montreal and in particular Ubisoft La Forge which is our R&D department and in which the different prototypes that I will show have been created by a very talented multidisciplinary team.
Thank you. So unless you've been intentionally not following the news last year you have heard about AI.
But the word AI means many things.
Generally, we use it in place of NPCs.
So it's worth setting some vocabulary here.
AI represents the concepts of machines that can learn, reason, and act for themselves.
Machine learning is a subset of AI.
There are programs using statistics to find patterns in massive amount of data.
and use those patterns to make predictions on new data.
Deep learning can be seen as machine learning on steroids.
It extracts layered features, or learned from complex data, in order to make a prediction.
And because it analyzes the data through many hidden layers, it is called deep learning.
Don't worry, I will explain more in detail what it means later.
People often refer to AI disruption.
In reality, the most recent developments deal with deep learning.
The hype of deep learning is at its maximum.
And because it's still exploratory, we live a time of excessive expectations followed by excessive disappointments.
So what I hope to accomplish today is to provide with a more concrete view.
of what machine learning really is, can, and can't do.
And most importantly, how to include it in our production process.
I will first show a handful of examples to explain why it has the potential to shake the way we work.
I will also try to briefly explain what it really is.
and why it requires to rethink many parts of our production, which is why it's not only a technical aspect that needs to be considered when talking about machine learning.
Then I'll try to assess the maturity and pace of machine learning applications and finally we'll explain how Ubisoft decided to lead the change.
The first part of my presentation is powered with examples of prototypes that have not shipped yet in an announced game. And the second part of my presentation will show concrete examples that have been applied to real productions from last year. So let's start. How disruptive is AI? We've been making video games for decades.
And AI has been at its core, whether to shape the players' interactions or in our production processes.
So why are we here to discuss about AI?
Why is it considered as something new or disruptive for many domains, including our industry?
Let's start with a hint.
This is how we made the cinematics in Assassin's Creed Origins two years ago.
Come here! I found a hyena cave! A real one, yeah!
Ah, go ahead.
You're gonna love it. There's like 16 of them.
And it's so dark and scary.
Well, you know what? I'd rather go home with my papa.
You always get too scared.
Hey.
Let's go on a real hunt.
Huh?
Alright.
Come, come.
So as you can see, this requires capturing a lot of data and many people from many different crafts.
Logistic of such traditional methods is expensive and not flexible.
Think about that, for example, each retake requires a lot of efforts and mobilization from many different people.
So can AI have a concrete impact that shakes the foundation of our pipelines?
Let's ask to someone who has been heavily impacted by AI last year.
Bayek, can you explain to us how disruptive AI is?
Hello, everyone.
Creating in-game cinematics requires many skilled professionals, such as motion capture, animation, and dialogue experts.
One year ago, it would have involved hours of manual work to record and animate this dialogue.
Now, what if I told you that everything about me is driven by artificial intelligence?
My voice has been generated from a simple text file.
which then drives my lips animation.
It's totally automatic, takes just a few minutes, and soon will work in real time.
And the best thing, it works in any language.
Par exemple, je parle le français avec un accent canadien.
I'm not sure what the limits are, but it gives you an idea of the incoming magnitude of changes for many professions involved in video games, such as animation and dialogue experts.
Another example, Assassin's Creed is a franchise recognized for the quality of its open worlds, and in such games, diversity is key.
However, the size and the richness of a world leads to some technical trade-offs.
As an example, you can see here that the characters feel a bit on a rail, if you pay attention.
Is there a way to create more diverse and organic animations while simplifying the production process?
What if instead of creating animation data offline, we were able to generate motion on the fly based on some high-level context?
This is an example of data-driven animation, or in other words, a system that generates the right motion animation.
It works in real time, and instead of creating animation, clips, and rules to play them, the AI decides what to play amongst all the data.
So not only does it require less production effort, it will also offer a more appealing feel for the player.
In the next example, still from Assassin's Creed Origins, please pay attention to the characters who want to sit down.
The transitions between different animation systems, like motions and stations, are difficult to manage, and it leads to animations that feel not really natural.
We usually blend clips that were captured with mocap.
So what if we did not have to switch between animation systems and generate transitions?
In this example, the same system.
just the same as before, generates more believable animations in any context and in real time.
We have a lot of fun with our characters.
So what is machine learning?
The part of artificial intelligence that has recently evolved exponentially is called machine learning.
I will try to explain here the core concepts of machine learning.
There's nothing technical here, but it is important to understand the data-driven application and approach of machine learning because it's key in the change we have to lead in production.
Just raising hand, how many of you are already familiar with those concepts?
Okay.
So half of you will have to bear with some simplification that we'll have to make to explain what machine learning is.
But I think it's important that we are all on the same page.
Here is a simple prediction problem.
If I'm asking you the value of f, your brain will analyze the data, decompose it, and generalize.
an approximation, this is a generalization step.
And then extrapolate, which is a prediction step.
This very simple example illustrates two key concepts.
First, the principle of a given data set that illustrates a desired behavior.
And a learning algorithm that uses this data set to create a function that enables generalization to new inputs.
And this is what machine learning does.
But we use it for a problem a bit more complex than drawing a straight line.
It uses three dangerous ingredients.
First, a data set that represents the desired outcome.
A neural network, which is a transformation function, basically a set of matrices.
And also learning algorithms that parameterizes the transformation function, basically fill the matrices.
So the data set is used as a set of input and output examples for a neural network.
The algorithms measure the difference between the network output and the desired output, or in other words, what we call the ground truth.
The process is obviously iterative in a loop that is called the training phase that can last hours, days, or even weeks.
And based on those examples, it sets the weights of neurons, which means filling matrices, or in other words, parameterizes the neural network.
Somewhat, the machine learns based on examples.
The neural network is then ready to generalize as a predictive model.
So a new input provides an output.
But because machine learning approximates the ground truth based on its observation.
The output always comes with stats, like precision, confidence, recall, and et cetera.
It is also important to note that simple data sets for simple input treatments have been used for decades.
For example, for handwritten characters recognitions.
So what if we use complex data, like images or sounds, or even what is apparently the biggest challenge on the internet, which is?
which is recognizing pictures of cats.
The principle is the same, but the models to extract features or generalize is different.
The key idea is to decompose complex data into smaller manageable features.
And because there are many hidden layers, it is called deep learning.
What is interesting though is that the mathematical methods behind deep learning are not new.
However, the first applicable results of deep learning, real applicable results, happened in 2010.
The missing link was computing power.
It works exactly the same way.
The algorithm extracts features from the data and then populates different layers of neurons.
Each layer represents a step in the feature extraction.
When the neural network sees a new picture, it predicts whether the image is a cat or not by extracting the features from the input data.
Simple data sets require simple machine learning problems and models.
Complex data sets require more complex algorithms to populate hidden layers that serves as feature extraction.
And this is why we say it is data-driven.
Instead of implementing a specific outcome or behavior, if this, then that, we focus on the right data set that represents this behavior.
And because machine learning always makes a prediction when new data is shown, it is extremely important that the data set reflects the future usage of your network.
or it will lead to very unexpected results.
If the neural network learns from pictures of ducks and beavers, showing a platypus, believe me, will lead to interesting but likely unexpected results.
Now, why is it important?
Because as game developers, we have many types of interesting complex data, like sound, animation, textures, models, which means we have a lot of data that is relevant for deep learning, and many possible usages for predictions, like asset classification, behaviors programming, or even asset generations.
It works for simple or complex datasets, but now, what if we just...
don't have the data, which happens often.
Well, we have simulations, and we can use some specific kind of algorithms called reinforcement learning.
The idea is simple. An agent is given a set of actions, goals, and rewards, when it finds a way to reach its goal. We also set punishments when it reaches some specific outcomes, when it fails.
Then, the agent tries many different things in the simulations or in the game to maximize its rewards.
After a while, by trial and errors, the algorithm finds the right strategy.
The strategy populates the neural network. This can be seen as creating the right data sets that map states to actions. So when a new situation is given to the neural network, it predicts what is the best action to take.
So here are the main things you should remember for this section. But the most important part is that more than a technology, it is a new way to think.
It's less about programming a behavior.
It's more about choosing the right data set that illustrates the behavior with the objective to generalize it.
So I hope you get a better idea now of the implications of being data-driven.
It is not something that happens behind the scene or under the hood or only for technical people.
It's really a significant shift in the way most of us work, and it has strong production implications.
Traditional approaches require a lot of programming.
They provide with complete control in a very manageable environment.
However, they are difficult to maintain and to scale up.
This is a very simplified version of a tree.
If you worked with animation trees, you know what I mean.
Conversely, data-driven approaches lead to less programming and offer less control.
Huge amount of data are passed through math and intuition, which requires to juggle between hard science and some sort of alchemy.
But the rewards.
is significant, as they lead to unprecedented capacities to scale up with very low maintenance efforts, because it relies solely on training data.
If you think about that, when you want to implement a new behavior, it only requires to add new data and retrain the model.
Concretely, instead of focusing on creating data and rules, people will focus.
on finding the right data to feed in a system that generates a desired behavior.
Let's see how concretely this applies to some of well-known trades.
Voice designers. Today, voice designers use a script to record actors, apply sound treatments, and associate each sample to a predefined action in the game.
Being data-driven.
Voice designers create the right voice inference that will generate voices on the fly based on dynamic scripts.
Programming.
Traditionally, there's a lot of if, this, then, that code that is written to program a desired behavior.
But with data-driven approaches, the program learns the desired behavior from a database of examples.
For example, to generate code or even detect potential bugs.
and even predict online failures.
Testing requires to follow a test plan that documents the desired in-game behavior or even techniques like smoke tests to assess robustness.
But soon it will also mean operating automated test platforms that will generate tons of scenarios overnight and will analyze stats and logs to point out undesired behavior.
I'm now going to show some concrete examples for people who are in charge to craft NPC behaviors.
Creating living city with traffic is difficult. Programming all situations and exceptions, if this then that, that's difficult. And maintaining them, that is daunting.
So what if we used reinforcement learning? Here in our case, we give an AI agent access to a steering wheel, brakes and accelerator.
And we give some rewards when it succeeds in following a trajectory or stop at intersections, and punishments when it fails.
And then the AI will try and learn to maximize its reward, thus developing a strategy to drive.
It saves time on programming and maintenance, for example, for new vehicles, new behavior or specific behaviors, and even new weather conditions.
So it works for characters or vehicles, but we can also find the same kind of techniques for crowds or traffic.
On the left, we have a traditional type of pathfinding algorithm.
Each agent tries to optimize its own path.
On the right.
We have developed a new type of algorithm called Swarm that works like a shared, decentralized, intelligence think-flock crowd swarm. And it results as more fluid and believable behavior, hence providing a richer experience. I'm not saying here that one is better than the other.
I'm just saying here that it opens new possibilities.
Here, we trained an agent with a specific behavior, which is to drive at high speed in a city.
So not only does it benefit our production capacity, it also increases the quality of the driving to make more believable worlds.
This approach can also be applied as an assistance to game designers.
Guaranteed hits, or what we call exploits, are difficult to chase, and especially when they involve specific patterns or combos.
Often, our community discover exploits before ourselves.
But they open automated testing opportunities.
Reinforcement algorithms can be used to let agents explore all combinations to check if there are some holes in complex designs.
This is particularly important for games as a service, where you need to make sure that new content works well, but also does not break existing content.
These are only a couple of concrete examples.
There is a technical challenge, but more importantly, it represents a huge change in the way we work, and this for all trades.
And this is why we should care.
We covered what deep learning is and have seen how it has the potential to profoundly change all of our trades.
Now, let's see how deep and how fast the video game industry is likely to be impacted.
Many breakthroughs arise at academic stage that are spectacular, but not still ready to reach a production stage.
For example, AI physics-based animation worked well in a sandbox.
but are still forgies with real-time interactions.
Still, I can't wait to play a game with such advanced features.
Some of those breakthroughs seek to simulate a player and even beat pro players, as you might be aware of, like Deep Blue did for Kasparov more than 20 years ago, if you remember.
However, is it robust or even simply a fun opponent?
Not yet.
The game is only used as a sandbox to measure the decision quality of an algorithm against the quality of the decision of a human.
Bottom line, it serves only some specific research breakthrough of the AI field.
Games are used to test those research elements.
Which means that, even if it's spectacular, there is still a lot of research to be done.
Conversely, it goes way faster than even experts expect.
This is extracted from a paper from 2016.
Hundreds of machine learning experts were asked when AI would be on par with humans for various tasks, and you see here the results.
And for example, they said that Go would be solved in 10 years-ish from 2016.
And it was solved in 2017.
Let's talk about asset generation.
Here are generated pictures using a technique called Generative Adversarial Networks.
As you see, academic results were not that appealing for us a few years ago.
And now they are.
and they are exponentially. Think about that. None of those faces are real.
And in 2018, not only did it generate pictures, it now generates videos.
We're entering an era in which our enemies can make it look like anyone is saying anything at any point in time, even if they would never say those things. So, for instance, they could have me say things like...
I don't know, Killmonger was right.
Or Ben Carson is in the sunken place.
Or how about this, simply, President Trump is a total and complete dipshit.
Now, you see, I would never say these things, at least not in a public address, but someone else would.
Someone like Jordan Peele.
This is a dangerous time.
Moving forward, we need to be more vigilant with what we trust from the internet.
That's a time when we need to rely on trusted news sources.
May sound basic, but how we move forward in the age of information is going to be the difference between whether we survive or whether we become some kind of fucked up dystopia.
Thank you.
Stay woke, bitches.
So it's fun and impressive, but still not in real time.
So now the question is, do those techniques transfer to our industry?
I'm talking about the technique.
As you can see in other fields of application, these techniques yield impressive results.
It's far from being perfect and does not work in all situations or in real time.
But this is where we are now.
Given the present pace of academic research.
I'm positive that next year I should be able to interact more naturally and combine more emotions.
Let's extrapolate.
Here is what we expect from the recent developments.
It goes fast.
Three years represent the ballpark production of one AAA game.
The question is now, how do we speed up our innovation capacity in this field while making games?
Disruptive means the capacity to shake established rules, often leading to newcomers.
Think of Nokia versus iPhone a decade ago.
It is less of a technical challenge than a transformation of the way we work.
And the development of opportunity it creates also.
This is why it is important to discuss it not only in technical tracks or from a technical standpoint.
but also at a broader level.
What are the challenges we must overcome to benefit from this in our productions?
Every technology or process has a life cycle.
First, it takes time to provide convincing results.
Then most problems are overcome and the recipe is improved over time before reaching a plateau.
And then… a new technology emerges like deep learning.
Let's be clear.
Today, it produces results that are globally less performance than our well-established recipes.
But the question is, how much time will it take to be on par?
We think it's going to take two to three years.
Don't get me wrong, I'm not saying that deep learning will replace everything we're making by hand or with our current pipelines in two to three years. What I'm saying is that it will take significant parts of our pipelines in two to three years.
So how do we explore this area? Because we can't build and pilot the plane at the same time.
The nature of machine learning brings very uncommon challenges.
First, it goes fast, very fast.
Most of our processes and production life cycles hurt our innovation capacity.
It requires data, expertise, but also valuable applications.
And very few companies have the three.
It produces results that are industrially interesting, but they mostly show up at academic level.
Therefore, it grows in a culture of openness and publications that, let's be honest, goes against most of our industrial habits.
It goes against most regulations, or at the very least, requires to create some, because it raises important questions, like the authoring of generated assets.
Who is the creator?
Data ownership or even usage, like voice imprints for text-to-speech or data privacy.
And did I mention it goes fast?
I mean, since I started talking, a relevant paper probably hit the internet.
So, how do we address those challenges?
There is no one-size-fits-all solution.
We all have different production realities.
So I will try to share now a solution that worked well for Ubisoft, and maybe some elements might be useful to your own context.
This is the type of open world we create at Ubisoft.
We offer rich interactions for the player, and all of this requires tons of data, textures, animations, models, but also AI to drive the world's components behaviors.
Those simulations offer appealing technical and scientific challenges, but also interesting assets to solve them.
We saw that as gaming industry.
We have two great assets.
First, we have our game engines that can be used to train or test artificial intelligence.
And second, we have a lot of very specific data, such as mocap data, textures, dialogues, models.
Creating or using this data is key to the development of deep learning.
So how do we make it happen when AI, machine learning, developments is still essentially.
at academic level.
This is a path of innovation, and this is a scale of love.
Love being whatever you want, depending on your values, money, recognition, attention, investments.
A good researcher is known by the quality and quantity of his or her research publication, which means that the academic world puts a lot of love on the left side of innovation.
At Ubisoft, we focus on creating amazing experiences.
So when we try to collaborate on academic topics such as deep learning, there is in the middle what I call the terrible gap of wasted ideas.
And almost three years ago, we decided to bridge this gap.
Ubisoft La Forge is an open place where we bring in our people and researchers to work on prototypes that serve both interests, make greater games while creating public knowledge.
Researchers at La Forge have access to everything like our employees do, our data, our experts, our technologies, our facilities.
Laforge was created in Montreal three years ago, and now spreading in other Canadian studios.
Just to give rough numbers, we're working with eight universities regularly, hosting at each point in time 20-ish active projects.
So let's pretend now we have a prototype.
Then the main challenge is to match irrelevant AI results with a real valuable application, not only a stunt.
The key is to create prototypes in parallel of production cycles and make them target a well-defined scope.
So in other words, be production plan B.
All my previous examples were prototypes that are not implemented in an announced game.
I'm now going to show concrete prototypes that were implemented in production without being initially part of a plan.
Next is a prototype from last year, based on Assassin's Creed Origins.
Unlike my previous example, it uses real actors' voices.
It was a new machine learning-based technology called sound matching that animates lips based on voice, and these for any language as well as barks.
Why waste time with politics?
I say to my boss, you're going to the Zambians.
Where to?
Dictatorship!
My ships are coming.
It seems that your Roman needs protection at the end of the day.
Oh la la la!
So the Assassin's Creed Odyssey team decided a few months before Goldmaster that a prototype was worthy to implement it.
It decreased costs while increasing the localization quality.
And the game was praised for the quality of this localization, amongst other things.
Here is a short seconds taken from the game.
Cassandra, it's you!
Phoebe!
I promised I'd see you again, and here you are!
I told you to stay away from trouble.
I did!
Well...
I tried.
How did you get here, Febe?
I did some drag, working for Marco.
You paid someone to take you to Athens?
For Honor is a sword fighting game that relies on many different opponents, which are regularly added to the game.
So in this game, we prototyped an automated testing feature to find exploits.
It helps designers to fine-tune the balancing also.
Here, the smart bot in orange tries to beat the regular in-game warden in blue.
And as you can see, the smart bot developed a kiting strategy by itself using reinforcement learning.
Trades are changing, but the way they work together also.
Traditional programming pipelines involves many stages to test the code and find bugs.
With large teams or for quick turnarounds like continuous integration, it can become daunting.
What if we leverage the data of past bugs and corrections to estimate the probability that a new portion of code includes a bug before it is tested?
Last year, we unveiled a prototype called Commit Assistant that does exactly that.
It has been first implemented on Rainbow Six and is now reaching other productions worldwide.
On Rainbow Six, there are still 30%-ish of false alarms, and this should decrease over time as the system continues to learn.
Is it magical?
No.
Still, you need to add some alchemy to the science.
As we saw before, the output depends on your data, and your data sets, and your algorithm.
And crafting all of this requires a lot of intuition and the involvement of experts from different trades.
As an apprentice alchemist.
This is the kind of results you will often get.
At least, that's what we got.
This is the kind of results you will often get.
At least, that's what we got.
Bye!
So now it's time to sum up the things we covered.
More than a technology, machine learning represents a shift in the way we program a desired behavior.
It focuses on the data.
and raises questions of quantity, diversity, representativity, curation, variety, usage, etc.
It is deeply changing our industry, both because it requires to think differently and because all crafts and processes are impacted.
Creation assistance is often a good angle to accelerate a pipeline while in production and not miss the train.
It goes fast, and it's still exploratory.
I suggest not planning for it, like you would for a feature.
Conversely, I would advocate you to find your own prototyping pace, and a research model that is linked to your production within your reality.
Being production plan B is probably good idea when playing with such disruptive elements.
Thank you.
I think we have time for questions.
Are you shy?
Or...
On the mic, please.
So that everybody can hear it.
You mentioned that you...
in a kind of deep relationship with universities in Canada.
And it's understandable how academia benefits the company, but how the company benefits academia.
What kind of, what you're giving back to academia.
Excellent question.
What I didn't mention is that Ubisoft La Forge has, few rules, but one of it is extremely important, which is collocation. In other words, researchers come in our studio so that they have access to everything. So as a researcher, think about animation. You work in...
in deep learning on animation, there are very few data sets that you can use to make your research.
So when you come at La Forge working with us, you have directly access to the tons and tons and tons of data that we have. So that's one aspect. But also, we are pushing for publications.
So each researcher who comes at Ubisoft La Forge is incentivized to publish and share what we discovered.
Actually, if you go on our website, lafourche.ubisoft.com, you will see many papers or links to many papers, including the commit assistance, so the AI thing that's, you know, try to catch bugs in the minds of programmers.
Hi, excellent talk.
Thanks for doing this.
I have a question for you.
So it seems, and maybe it's my perception of this.
that you have a focus on this tool, on machine learning.
Can you speak of what is your perspective?
Because there are, to me, two ways of having an R&D group.
You can believe in a tool and then try to apply it around, or go around and shop for problems and then find the best tools for those.
And sometimes we say, you shouldn't use a hammer and then try to, you know.
But what is the advantage that you see in this?
Yeah, excellent question.
La Forge is not a machine learning department.
La Forge is an R&D department.
Apparently, in the academic world, most of the most interesting applicable results that we have revolves around machine learning, deep learning, reinforcement learning, which is why it's something that we should take care of as a gaming industry.
But actually.
We work exactly the way you described at Ubisoft LaForge, which is we bring in problems, suggestions, and then we try new things, whether it's machine learning, biometry, or even social sciences.
Hello, my name is Martin Klima.
Thank you very much for your talk.
I have a very specific question.
I was very impressed by the quality of the generated voice.
Can you please expand on this?
When do you think this will become a viable alternative to actual actor recording?
It's a tough one. It really depends.
This is an opinion.
I think that we will need actors.
We will need artists to add that extra layer of emotion.
However, there are many situations where you don't need to put a lot of effort recording artists and managing the data and post-processing, etc.
So I think that it's going to be something that will happen gradually.
In other words, today I know that some games already use text-to-speech.
for some voices that are not that important, just you add more diversity in their worlds.
But then when you need more emotions or to convey more complex information to the player, maybe it's a good idea to keep real humans.
And this will happen gradually, I think.
Hi, so one of the biggest challenges with machine learning is debuggability.
Do you have any insights for the things that you experimented that improved the availability of machine learning models?
The believability, you mean?
The availability, diagnosing or understanding if the model is actually working or not.
Not really, because I'm not an expert, I would say.
But definitely what I would say is it offers less control.
Definitely.
Now the question is more to try to assess, is it important or not?
And that's where we need.
are experts from different trades.
If you are, there were some very interesting talk about usage of, very specific usage of machine learning on boats, on animation made by Daniel as an example.
As you can see, the models are never exactly predicting the ground truth.
Now you need this external eye of a real professional, a real animator, that will say, hmm, is it important in that case?
So maybe you want to generate a crowd, and maybe, you know, it's okay, it works well to the eye.
But conversely, if you need animations for some specific gameplay, fighting as an example, then using deep learning techniques or machine learning techniques.
might be more tricky because you might have more difficult time to tweak things and try to explain how the system will react.
Hey, thank you for the talk.
I guess my question was kind of related, but given the potential unpredictability of a lot of these systems, do you have a standard evaluation pipeline to get it to a point when you're comfortable putting it into production?
The most standard evaluation pipeline we have are called people, actually.
We're not, Ubisoft La Forge is not meant to create products or services.
We create prototypes.
So we're very far, when something goes out of La Forge, it's very far to being something that is plug and play for production.
What we try to do, and because all of those questions of testing, reliability, predictability, and et cetera, what we try to do is we have a prototype that works well, that proves solving a real problem.
We bring this prototype and then hand that off to productions who will adapt that to their pipeline.
So as an example, we were talking about the commit assistance, which tries to address the probability that some code that is submitted contains bugs.
What is the right level of reliability or probability that you want to reach?
Is 70% enough?
Only a programmer can tell, right?
So we work with them.
And working with...
people from the trade, programmers, animators, is always a good idea because they will decide what in which usage it helps them, it augments them, and it's not like an additional burden, an additional, I don't know, dashboard that they received or things like that.
So we are also learning with that a lot.
Any more questions?
I guess it's a no.
Thank you very much.
