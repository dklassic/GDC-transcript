So, hi, I'm Chris Brown and I'm giving a talk today, Fighting Legos, Audio Choreography for Battle Design.
What that really means is discussing the change in how we record what I call vocal sound effects or omnis or onos, kinds of the sound effects that you're going to hear when you're playing battle design.
So, it means...
if this works correctly.
Using voiceover sound effects as a game mechanic.
We have a lot of, we used to, on carts, right, you'd have to cut everything down to its minimum thing.
You'd only have a binary choice, something like this going from this, where we're enhancing a moment, somebody gives a punch, somebody receives a punch, it's just a small sound that lets you know, oh, okay, they've given or received a punch.
We're gonna move now more into a world, this is a still from For Honor, where that voiceover sound effects that you're hearing back from the game are actually helping you to learn how to play the game and to confirm for you that you are playing the game correctly.
Why so why does it matter voiceover sound effects help you play the game? Well isn't enhancement enough?
For me. I'm always looking for ways to help people understand the world better When I want to bring a change to the table People why why do we have to change? Why do we have to do it that way doesn't it?
You know if it ain't broke don't fix it So we kind of always go back to this. What's the purpose of sound design when we're finding?
why we're gonna make a change, is it gonna serve our greater mission?
For me, the greater mission is always providing the information you need to know to interact optimally with the world.
And again, this talk is audio bootcamp, so it's made for people who are coming into.
sound design, which is why we're gonna just do a brief overview.
When we talk about getting the information that you need to understand and to interact optimally with the world, we're looking at things that provide feelings and context for you.
It helps you comprehend the world, it helps you be motivated.
For me, when I hear drums starting, I get fired up, I'm ready for battle.
You have kind of these classic archetypes, right?
Your minor chords of danger and loss, strengths of drama, your brass of victory kind of.
The things that are the standard language that we use in audio to convey certain emotional feelings to people to let them understand that this is what's going on in the game in the moment and to help them be motivated to move forward.
When we look about ambiances, when we talk about ambiances, this is a still from Red Dead, as I'm sure you know.
you think about the desert, this feeling of desolation, this feeling of loneliness, this aridity, this kind of you'll hear a lone coyote howl.
It's always reflective of Marston's psychological state, this feeling of being sort of the lone person out there, maybe the only one who understands the world, maybe the only one who understands the grim realities, the mechanisms of how the world truly functions.
It helps to convey the sense of being very kind of lost also.
When we think about imbiances, we think also about bio shock, feelings of you'll hear the creaking, you'll hear the water.
It's very haunting.
And you don't, players don't really.
sit back and say, why am I feeling creeped out all the time?
You know, you've got these sounds, you've got the splicers coming at you, you have the, you know, big daddy groans, you have these sounds that are individual sounds that are giving you a feeling, but underneath it all you have this bed of the actual pressure, not only of the moment, but the pressure of the ocean on this thing that at any second could break through.
So we talk about sound, we talk about music, providing you feelings, context.
We talk about ambiences, providing you feelings and context.
When we talk about non-voiceover sound effects, we talk about actionable tool info, right?
So you're looking at the Lancer, you are hearing it, you're hearing its power, it's kind of exciting, it's kind of grindy, you're like, how much can I F people up with this?
It's very.
exciting and fun and not that I'd like to do that but So right here's your garrote Agent 47 doesn't make any sound which is important you have Oh my gosh, why am I blanking on the Warthog?
Okay, my favorite vehicle because it's small, it's light, it revs at a slightly higher pitch, it lets you know, oh, this is more nimble, this is not heavy as a tank, this is gonna let me go up and on crags and on rocks, and it's all things that, again, without the player really thinking about it, it lets them know, these are the rules of the world.
These are things that are at my disposal that help me understand the mechanics of the game design itself that help me move around.
So in that way, your sound effects are helping to fill out level design.
It's pretty neat.
When we think about voiceover sound effects, binary enhancement, right?
Give a punch, receive a punch, this is super punch out.
which is super fun, but it's not telling you really anything other than that you gave a punch that was satisfying, but it's not helping you really bond with the mechanics of the world.
As we moved...
further along in game design.
We have now, again, because I'm doing mostly AAA, kind of battle design, you have your assassination.
So here's the strangulation.
You have your kills from Red Dead, and then again the satisfaction of killing splicers.
satisfying in Red Dead, in particular, the kill sounds that you hear can be so dramatic and so pathetic, meaning that you kind of feel like an asshole for killing these people, which contributes, again, to his psychological state.
So you are, it's an enhancement, it's deeper, it's moving into creating emotional states for the player, but it is not yet.
helping the player to understand that the particular feedback that they are inputting into the engine is being reflected back to them.
The way that we used to record these types of voiceover sound effects, we would record them as what we called a variety pack.
So we would make diverse sounds for a single action.
They were kind of catch-all, sort of an imprecise response.
They're non-customizable in engine.
You're not sure that, you know, let's say you have a bank of 20 sounds coming from a script like this, 20 strangle to deaths.
So you have, maybe some wet ones, maybe some short ones, maybe some long ones.
And the engine is going to randomly call them from the sound bank.
And it's not necessarily always, some people will key it to the art, but that's pretty complicated from an implementation standpoint.
It's not necessarily always going to, it's.
Not really going to happen that much.
It's a bank. It's going to pull from a bank.
You're going to get whatever kind of strangulation art that you're going to get.
You're going to get a random strangulation kind of sound that you're going to get.
Maybe they're going to match. Maybe not.
But it's great that we used to do it this way because we didn't want to tire the player's ear.
So we would always say we want to do a huge batch of a lot of different things so that the player doesn't feel...
tired by hearing the same punch sound all the time, the same strangulation sound all the time.
And we did that mostly due to space limitations, engine limitations, processing limitations.
So now, as we're moving forward, kind of a year or two ago, with this particular game as an example, but with a lot of other games, you'll see that people are able to create what I call bespoke or custom tailored interactions.
So we'll have something where it's not just a punch, but it's a combination of things that the player is putting in and then the game engine is reflecting back.
So the player is saying, well I want to kill this guy, it's not just that I'm stabbing him, it's that I'm kneeing him in the crotch and I'm hitting him with the elbow and then I'm beheading him.
Or some variety of...
Does it sound like I like my job?
So, yeah.
So anyway, so what we want is we want people to learn how to play the game in a way that is supported by the sound design that we are giving them.
So we want to create a sound bank that is going to have a highly, highly specific, very small sound that is going to tag exactly to the animation that they're going to receive.
So when you have this, let's say you're going to elbow someone in the neck.
It can't be what we used to do with our variety pack.
It can't be like 10 or 20 different, well, maybe I'm elbowing in the neck and it's wet.
Maybe it's dry, maybe it's raining, maybe it's, you know, all these different things.
We had to figure out a way to create a really, really specific script that our actors could do.
So then every one of those individual pieces in the engine would, would be consistent and would always reflect back exactly what the art was going to do.
Again, why is this good?
Because believe it or not, we did have to have these discussions.
Looking at haptic feedback or looking at gyroscopic feedback as we're moving into VR.
It's awesome, and it's great, and it gives you information, but it doesn't give you the kind of finely tuned information that I want to provide to the player so that the player understands exactly what they're doing and they're learning through sound.
League, amazing.
The art is fantastic.
It helps you, but we could do better.
And that's what I'm always looking at is how can we do things better?
How can we support the player so that they are understanding what they're doing and having a more satisfying experience?
accurate, immediate reinforcing feedback between the player and the game, right?
You have, here's your instruction set.
You wanna make sure that when you are giving an instruction, the engine is saying, yes, I understand.
You wanna make sure that what you're gonna get back is this, not that.
So how do we do that?
We talked about voiceover sound effects, creating audio pieces.
A script is this kind of sample.
And it was interesting.
I used For Honor as an example.
There's a couple of other games coming up where we've used the same model because.
we have so much more processing power and so much more customization available to us.
The actors are really accustomed to Variety Pack because we've been doing it for so long.
So it was really hard for them to kind of be reminded at every take, no, you have to do it the same, the same, the same, every time.
And they're like, ugh, it's so, okay, I'll do it the same.
And they would, and they would do it.
And what was interesting, and this is a conversation for another time, but the Western kind of European language model, because it's not a tone-based language, and it's not dependent upon absolute perfect tonal consistency every time, what we learned in doing this is that the actors...
even if they're doing the same specific length for the same tiny thing, there will always be a tiny little micro variation in their voice.
So it doesn't tire the ear, and when you paste everything together, it actually worked, which was really, really neat.
And as we were watching players playing the game, they would say, like, there was one particular person I was watching, and they said, oh.
That's a move.
I'm like, yeah, that's a move.
They're like, oh, well, wait.
And I can do, and now, and to watch them learn and watch them learn through sound was really exciting for me, and it made me feel as though we could give them a lot more to work with and help them understand their tools.
So, very short talk.
Each element is a building block.
Enough building blocks grant you infinite customization by mixing them up.
And it creates a more responsive world.
It creates a greater bond with the world, which is the thing that I'm always after.
And the greater bond is greater satisfaction and happier players.
That's why we do what we do.
Yay.
That is my talk.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
So my talk is super, super short, so if you guys want to talk about anything else, I can answer your questions or you can all go get coffee.
All right.
Coffee time.
Oh, wait.
You have a question.
Oh, yeah.
Great talk.
Perfect length.
Could be longer.
Then I would like to come up with two questions.
How has this changed your casting?
Because a lot of, are you looking at actors who maybe can't do a hundred, 10 very similar variations of a hundred moves, or do you try to train people into it?
Or is there a point where you're sort of like, okay, we have to try something different when we're sending out sides or auditions?
Oh, that's a great question.
So the question is, how has this changed my approach to casting?
Am I having a difficult time with people who are unable to conform to the kind of new?
It could be perceived as a limitation, or it could be perceived as greater freedom.
It hasn't really changed my approach to casting, but it has changed my approach to working with the actors in the studio.
It is definitely something that I need to train them into, and it's a little bit difficult because they are, depending on, you know, some actors are trained to do three in a row, some actors are trained to, for every.
one in the three in a row, they're trained to give you something different.
Some actors are like, I'll do your three in a row, each one will be different, hopefully it'll be something that you like.
Then you have other actors who are more method style actors and they'll say, I'll give you three in a row, each one is aiming for a particular level of emotional truth and I'm just trying to get there.
So for this item, because it is really simple, we train them.
Fantastic, thanks.
Yep, thanks.
you Actually, continuing that question, in the VO session, do you have strategies for getting to that point?
Would you go through a bunch of different variations until you hit the thing that you want, and then do that 10 times?
Or how do you handle that?
Oh, that's super smart.
That's a great question.
So the question is, continuing on to that, when we are in the recording studio, if we are training someone, an actor, in how to do this correctly, or how to do it in a way that gives us material that we want.
I'm trying to think of how to phrase it.
Do we have them try it until we get something that we like, and then we have them do that thing that we like 10 times?
Or do we just kind of let them go?
And we have them do it until we get the thing that we like, and then we have them do that 5 to 10 times.
Thanks for your talk, it brings up a lot of questions.
We've had the same issue as you, we're looking for consistency or repetition.
So what we started doing is actually writing out onomatopoeias and a bunch of them.
So like who, and ha, and he, and same thing with case, and same thing with...
V's or even write up silent onomatopoeias or closed mouth.
And so we have this list that we've been using on multiple games with all of these written out onomatopoeias, which makes it really easy for the actors to repeat that one specific onomatopoeia.
And once all of that is done, then we'll go through them and see what we recorded applies to what action instead of being action-driven onomatopoeias.
That's a great approach.
So I was wondering if you had tried this and if it worked because I've constantly been wondering should I go more for... when I tell an actor to kick I get that same problem that you've been getting. They do whatever and then it gets really hard to get consistent acting.
Yeah, I think that's a fantastic approach. I haven't specifically tried that, writing out the onomatopoeias on my stuff.
I've seen, there is a great, I don't know if he's here, there's a great sound designer at Ubisoft, who I've seen do some similar things like that.
I think it's a fantastic approach. Restating, he is actually writing out the onomatopoeias on the script, and then gathering a library of specific sounds.
and then seeing where they fit the art instead of doing it the way that we've been doing it which is to kind of look at the art and then try to have the actor create something.
So he's kind of out ahead of the process.
I think that's super, super awesome.
It works really, really well.
And just to add something else that I do is what we do is we write all of these on a shared screen.
So that's on our recording console computer.
We share the screen in the vocal booth.
So as they're doing what they're doing, if they do something quite different that sounds like an onomatopoeia that it can write, I'll add that to my list.
So I keep track of all the written onomatopoeias.
And sometimes when they go randomly, I'll take notes of exactly how it sounds.
It's much easier to track.
So it's just an idea I'm throwing out.
I love this idea. It's wonderful. Yay!
Do you guys want me to restate it, or you guys all heard it?
Yeah, okay, great.
Yeah, that's fabulous.
Thank you so much.
Hi, I'm an audio student at Cogswell and I actually had a question.
What percentage of game audio requires the use of JavaScript?
Because I'm learning a little bit about JavaScript and I was wondering if I should really pursue like the, you know, learning how to script, you know, more advanced.
That is a fabulous question and I wish that I knew the answer to it.
Oh, okay.
Um.
I'm sorry that I don't.
The question was what percentage of game audio requires JavaScript?
And is it worthwhile for a student to spend a lot of time learning that so they can use it as a tool?
And I'm really, really sorry, but I just do not know the answer.
Thank you.
So I'm pretty new to game audio and everything and it's especially unfamiliar with voiceover and everything So you're talking about getting real consistency and everything into the voiceovers And I would imagine like say in a fight scene for example or the fight sequence You'd have a lot of like you get hit in the same place But you would have a lot of variation because they're not gonna grunt the same way. So why do you want that consistency? Oh I'd like the consistency so that, well there's always going to be, because again, we're not working in a tone-based language here in the production that we're doing in the U.S.
We want that consistency, so then the player, this is a fantastic, so the question is, why do we want consistency?
If somebody is getting kicked, why are we moving away from the concept of a variety pack?
And the answer is, because we want it to always be the same sound.
So that little portion, it's like saying that we're going to, let's say we have a particular set of moves, we want the player to understand that that is the sound of a kick.
So that is what a small kick sounds like.
So then when the player is doing the particular input on the controller for a small kick, they hear, oh, I did the controller right, the engine understood that I wanted a small kick and the engine is giving me a small kick.
So it's more about the player input opposed to player feedback and experiencing that?
It's so that the player understands that, so it's basically so that the engine is telling them, I received your command correctly.
It's basically just an echo back.
And in order to, if it was, if we were still working in binary, like if we were doing super punch out, and it was the same thing all the time, like, oh my God, it would be super boring and sucky.
This only works when you are working in sort of a for-honor environment or an upcoming environment where you're creating or stitching together bespoke things. It would not be awesome if you were working in Super Punch-Out because it would be super boring. Thank you.
Hi, thanks for your talk.
So it sounds like you're talking about shorter asset length?
Correct.
Yeah, absolutely.
That flow together and sort of fight combos?
Exactly.
Not a button masher kind of a situation.
But how do you feel that that changes, like if something needs to get changed in terms of an animation, like the timing needs to get changed or something, do you feel like that makes it easier to kind of roll with those kinds of changes?
Or is it?
That's a great question.
The question is, what happens after you record all of these teeny tiny sounds that are going to be pieced together and make your little Lego dragon or your Lego Millennium Falcon or whatever, and the animation changes?
I don't know that it necessarily makes it easier or harder.
I don't think that those things, I think you probably are faced with a re-record.
Okay.
Which sucks, but that's.
Sure.
If you wanna do it right, yeah.
Okay.
It's a good question.
Thank you.
Thanks.
Hi.
Hi.
So one of the things I really appreciate about what you're talking about is the implicit accessibility advantages.
Anytime that what the player does corresponds uniquely to what they hear has inherent advantages for any blind or low vision gamers who otherwise aren't getting that reinforcement from what they're playing.
So, a little bit of icing on the cake.
That is amazing, thank you very much.
The comment is that this really helps accessibility for low vision people or people who are blind who are playing the game.
That, I hadn't even thought of that and that is an incredible thing to say.
Thank you. It's a really good thing.
Hi, so I was kind of thinking, I did see that the direction that you had for some actors was, you know, like, we're going to do the same sound with variants 10 times, but also at the same time with consistency.
With the advent of middleware now, you know, like really running inside games in particular, you know, like, especially at the AAA level.
how often is it, because I'm sure that, you know, like not all 10 assets are going to be used.
So how often is it that, you know, like, you would put like a randomizer in terms of like pitch and volume to substitute out and kind of get rid of that monotony?
Well, I think that for this particular, it's a good question.
So the question is, if I'm understanding it correctly, would we then use middleware in order to try to create variance?
Is that in order to create variance to avoid sort of audio monotony in the particular sound?
For this specific practice, I don't think that we would.
Because we rely on the actor's natural kind of organic, tiny variation in order to do it.
So yeah, I'm not sure that we would.
Some other people might, and it might be amazing.
For us in practice, we haven't done that.
But it's a good question.
Thank you.
Great.
Thank you so much.
Hey, thanks a lot.
So the question I have is does this approach change at all for working with creatures or more monster type and less humanoid creatures?
Wow that's a fantastic question.
Gosh I don't know.
I guess it would depend on if you were playing the creature.
I think if you were playing the creature as like some sort of giant thing that would have multiple moves that would be stitched together.
where it would be, where the player would need to understand what the direction they've given to the creature.
I think if it's a playable creature character, God, that would be fun.
So, yeah, that's a big, pardon?
It was a devious laugh.
Yeah, that is a great question.
I think if it's playable, sure.
Cool.
And I did get the five minute thing, so thank you very, very much everyone.
I really appreciate your time.
