I'm Gautier Boida, working at Square Enix Advanced Technology Division as an AI engineer.
And today I will talk about driving emotionally expressive NPC animations and behaviors with the Designer-Friendly Pipeline.
So first I would like to thank all the people that work with me on this project.
So thanks, a big thanks to them.
So as of today, relationships between users and characters has been mostly unchanging.
It is often one directional from player to character.
And at Square Enix Advanced Technology Division, we believe that the realization of deeper communication between users and characters will bring a completely new gameplay experience.
Our research efforts on character interaction already brought some fruits with our experimental emotional pipelines that I introduced at GDC 2019.
This pipeline allowed our NPCs to be more aware, expressive, and lively.
Since that time, we started a new project named Wander, where the philosophy was, gods do not play dice.
The meaning was that AI-based game design should not rely on random value.
All the decision-making should be as natural as possible and make sense, allowing the growth of the agent.
As such, it naturally suited the project to have this emotional pipeline to allow NPC to have emotions, mood and have personalities, allowing them to be livelier and enhance the player experience.
But this time, the challenge was to bring this pipeline to production.
And today, on top of explaining it, we will cover its adaptability to any experience and how to balance and debug it depending on the needs of the designers, but also on the experience.
So first, what are emotions, mood and personalities?
Depending on the paper you are looking at, there are many definitions.
In this presentation, we define them in the following way.
Emotions are short-term feelings that evolve quickly over time, like joy, distress, and fear.
And mood is a much more long-term feeling that evolves slowly but smoothly over time, like exuberant, depressed, and afraid.
And personalities overall define the agent.
Depending on the experience you create, it may be either fixed or very slowly evolving over time, like curiosity, shyness, and laziness.
So now, why would you want your NPCs to have dynamic emotions, moods, and personalities?
What would this bring to your experience?
So first, let's take an example with our prototype game Wonder, but without emotion, animation, or personality and mood.
So in this experience, the player is a little fairy that you can see on the bottom left and give orders to this character, Pino.
Here, we ask to use the book.
And Pino will try to use it in the way he thinks is good.
However, he did have a short into it, so it was not a good use case.
And the player told Pino about that, but was not quite happy about it.
In this game, Pino will learn, basically, thanks to this interaction, if it's a great use case or not, and being able to solve quests and other things later.
Now, we'd like you to focus a bit more on the character itself and the way he's expressing the different things happening around him.
You can see that the walk is always the same, there is not much variation, and the face is just a little smile, not changing much.
I mean, some little, of course, animation for the action, but nothing really outstanding.
So now let's have a motion, animations, mood and personality on for this demonstration and do the same thing.
We can already see that Pinot is moving much more energetically thanks to this personality he is into.
Here he was hitting the book which is not correct and we can see that the reaction is also making more sense now.
Now I try to use a stick and we will be able to see a bit more this personality motion like he is very in the exuberant kind of feeling now.
You can also see at the same time that the speech is changing based on this mood and personality.
He is quite happy about being able to actually hit a ball with a bat.
Overall personalities are a thing that evolve very slowly in this game, like about 5 to 10 minutes we may be able to move to one personality.
Because it's very slow, I am now going to use the debug UI to quickly change the personality of the character and show the little variation we have added based on the different personalities the character is into.
Here is a bit more reserved kind of personality.
And we are going to do mostly the same kind of actions this year.
A little variation. You can see already that the little reactions, the way he's expressing all the little smiles that he may have on his face when he's encountering objects that he likes or dislikes is very different from the previous personality. And if you take a bit more attention, you can see some differentiation based on the mood he's into.
It's a bit maybe cuter with this personality than before.
Here we try to use the dumbbells this time.
And I think it's quite an OK use case normally.
But yes, the player, for some reason, said it was neither good, neither bad.
Lastly, we move to another personality.
And this time, we are going to show the mood.
The mood is basically here affecting a little bit the mood for the animation of the character.
It was not super easy to see during the demonstration.
So we have used the debugger to show a little bit more easily.
But I will come back to that later.
So, now that you have seen that, let's try to explain to you what is this emotional pipeline with the different modules it has.
So first, the emotion module.
It is based on the revised OCC model from the paper The OCC Model Revisited.
We have chosen this model because of its simplicity and compatibility with game development, which is not the case for a lot of these models. For instance, here, event is replaced by game event and then it's just tree exploration based on conditions. It is also a very well-known infamous model that works really well with other mood models that I will explain later.
So, for our prototype Wander, we are actually not using the whole graph. We are using only the upper part of this OCC model.
So let's take an example with a proper game event.
First, we assess if this game event is going to be a positive thing or a negative thing for the agent.
For instance, if he is hit by a ball, it's going to be a negative feeling, except if he is a masochist.
If he's eating a delicious cake, it's going to be a positive feeling, except if he has allergies.
Then, based on the category of this event, we can have consequence of events, like for instance, window broke because of a ball, or my clothes are wet because of the weather, because it's raining. We can also have action of agent, like my own actions or the action of someone else.
And we can also have aspect event, which is about hearing, smelling, or seeing something.
And lastly, we'll have a list of emotions on the last row that we're going to generate based on the branch we went into during the analysis of this game event.
Now, with a proper game event, so the player this time has been hit, no, hit the ball with the bat successfully.
So the agent is looking at the player and is feeling happy for the player.
So it's a positive feeling.
because it's the action of another agent.
And we are going to expel this agent.
We express annihilation towards the player.
Let's say now that we have a window that broke due to the ball that has been hit earlier by the player.
And this time, it's going to be the consequence of the previous action of the player.
And the consequence is something bad, we think.
So the window broke.
So the agent is going to express distress towards this window.
In this way, emotions are going to be generated in our experience.
This model can support up to 24 emotions in total, depending on how much of these three you want to support.
Emotions can be expressed in a lot of different ways.
It can have voice sound.
It can have facial blend, as I am showing here on top of other animations, like shame, or distress, or pride.
We can also have special animation and special speech when we are actually expressing these emotions.
Of course, this emotional module can be adapted to any experience, as I said before, even if it's quite big.
What you have to start with is actually the very basic and minimum version of this model that we think it is.
These three branches with actually eight emotions.
And from here, you can actually add branches depending on what you want in your experience.
For instance, if you are dealing with a non-object to which your agent is able to guess a liking or disliking based on the item features, then it can be interesting to add this unfamiliar aspect branch to have interest and disgust as emotion.
If interactions between AI agents themselves or AI agents and the player are one of the key of your experience, then we recommend adding this related consequence branch.
It's basically what we call a consequence of an action of an agent.
So I will take an example to explain a little bit in detail what it is exactly.
A window, for instance, earlier, we said that the window broke due to the ball that has been hit by the player.
And at this time, we express distress towards this broken window.
Well, we know, the agent knows that this ball has been hit by the player earlier, so that's the player's fault.
So we are actually going into this related consequence branch and express anger towards the player.
And thanks to this, actually, you can also have relationships evolution between your agents themselves, or the agent as a player, based on these emotions that are being regenerated.
Lastly, if your AI agents are able to prospect based on something happening around them, the addition of the prospective consequence branch will give great feedback.
So, let's take an example.
The AI agents hear some noises in the stairs in the middle of the night.
The agent will feel fear that maybe an intruder may be in the house.
So the agent is courageous and decides to check what is going on in the stairs.
So he checks and sees that actually his cat was playing with the balls and one fell off the stairs.
So he feels some relief or some kind of...
The actual consequence of this phase is something positive.
If we follow this model, it's going to be joy, but it's not quite relief.
So we advise you, in this case, to actually add these four little branches below.
That will add the necessary distinction.
For instance, belief, in this case, will be expressed because it is confirmed prospective and desirable consequence.
However, when it comes to perspective in game, it's not, it's actually a very complex thing to do.
In Wunder, we are mostly using it on simple examples where it's easy to guess what may happen in the future.
For instance, prospecting from weather-based events like clouds are getting darker and darker.
So maybe it's going to rain, or a player taking an apple and going in the direction of the agent.
Maybe it will feed the agent in this case.
So overall, this model offers a lot of flexibility and allows the designer to basically adjust it depending on what they want to create.
While we have covered emotion generations, there are still two unknowns.
One is emotion parameters computation, and the second is how to assess positivity of an event.
As your experience may already have many game events, the Emotion module will actually listen to a few of them that you have listed up in the data table.
Here we are listening to EatFood, EatByObject, and ObjectVisible.
They will have their event category, a way to compute the emotion intensity, and a way to compute the duration of these emotions.
And based on this intensity function, we'll be able to assess if this event is going to be a positive thing or a negative thing for the agent.
For instance, hit by object is going to be negative because it's minus the hit speed and multiplied by the item weight.
And for HitFood, it's going to depend on the liking of the items that he is currently trying to eat.
Speaking about liking, we also have this like-dislike system in our game, and we are actually generating liking and disliking at the same time that we are generating emotions.
So here, the agent has been electrified by a fence.
So we are generating distress towards this fence, because it's not a pleasant feeling.
And at the same time, we are going also to add this negative effect to the fence object.
And it can have an intensity and a memorable duration, if you want it to be forgettable after some time.
And on the top right, you can see that currently our agent seems to like very much red apples.
OK, so now I'll move on to explaining the Mood module, which is a PID model.
So the PAD model is a 3D space with three axes, P, A, and D.
P for pleasure, F for aversion, and D for dominance.
So how pleasant is an emotion, how intense is an emotion, and how much control and influence the agent may have over situations.
These 3D models we have inside all the emotions that we are generating before are mapped.
And one octant of this model will represent one mood.
In this case, where shame is, we have the mood afraid.
And we are supporting eight different moods as you can see on the left.
In the center, we have our default mood position.
And that is a little point that will move freely around the space while all these emotions are generated.
And that's basically the PID model.
So we, despite the complexity of a 3D space, we chose this model as it has one of the few that works really well with OCC model, and simple at the same time.
It allows a lot of expressibility and wide variations of mood and expression.
And it's simple enough.
So, as I said, 3D may still be a problem, so we'll come back to that later.
So regarding the updates of this PID model, when an emotion has been generating, like joy, depending on the intensity, this point will move towards the joy emotion quickly or not.
And then when there is no emotion anymore, the agent becomes bored.
So the default mood point will go back slowly towards this default mood position as it got bored and bored and bored.
Now, expression.
Mood can be expressed in a lot of different ways.
It can, for instance, be expressed inside the decision-making, for instance, having specific goals for specific moods, also having specific set of actions.
It can also influence the way the voice, we can manipulate the voice a bit based on this mood that we are currently doing in Wonder as well.
And we can also have a variation of base body animation.
So here I am showing a single frame of our animation.
And we can see that based on the mood, it's actually changing quite a lot.
And now I'm going to play the full animation, and we can see a bit more in detail what are the differences between all these modes.
So right now he's in a frightened mood, so he's a bit not super confident in his hit.
Now he starts with giving a big hit on the ground, and when he's exuberant, he's actually jumping and hitting at the same time.
And for this side, it's just a little tap on the ground, very gentle.
So these animations give a new taste to the base animation that we had, but they are not too strong variation at the same time.
So they can play well together.
So the 3D and 3D model have some pros and cons.
And when it's come to adapt it to your experience, you may want to get rid of 3D.
While 3D gives vast variations of expressions, the more dimensions, the harder it is to debug and to balance.
Depending on the mood expressions, also assets can go quickly out of hand.
Asset cost.
So we have to, in Wonder at least, we have to cut it down to 2D.
And what to choose between these three combinations?
So inside this model, there is one key axis, pleasure.
Pleasure is basically the separation between what is a positive emotion and what is a negative emotion.
So it's a very important axis to have a nice variation of our game in expression.
So we are actually going to look at casual or dominant and choose between one of them.
And to make the choice, once they have nice expressibility in their ways, we are going to take a look at our generated emotions list.
What we can see in Wonder's case is that most of the emotions are actually in the arousal positive space.
So we are going to have a really hard time to go into the negative part of the arousal space.
In this case, we think that arousal is a less important axis and then we decided to keep pleasure and dominance for our 2D space.
But it may not be the case for your experience.
We had to adapt, of course, these mood names, mostly keeping the A plus names.
And here we are.
We have our 2D PID model.
So it has now become a DPE model.
We still have to put back our emotion from 3D to 2D, so we check the official list of positions for this emotion inside the PID space from the paper.
And what we got is this location in the cubes, in the 2D space.
We can see that most of them are overlapping and not well positioned.
The position of them is not very well balanced in the space.
Well, it makes sense for psychology and all this research to represent exact humans or this kind of thing. But when it comes to game, the most important thing is to have a lot of variation of expression and to have the overall experience balanced. So we decided to actually push all this emotion to the border in the square and that's our new mood space. We could have done also in a circle around the center if we wanted to.
And here now I'm showing our experience with the UI, showing the current mood, how it evolves based on the different emotions that has been generated.
We can also see the emotion model at the top of the model.
And we can see that right now it doesn't feel super happy.
It is in a hostile mood, especially because the player is actually not super nice to him.
I think it's going to be visible there is a way he's walking now.
It's not there.
super friendly. However, based on now, he did a successful action and the player was happy, so now we are able to go back a little bit inside this exuberant mood.
So that's how this mood and emotion generation happens in our game, and we hope it was nice.
So now, personality module.
As you can see, it's a very simple structure.
It's just UDT parameters between 0 and 1, like laziness, curiosity, and honesty.
And while it's super simple, it can have, actually, a broad way of expressing expression inside your game.
You can have different goals available, depending on the personality.
Or the way the actions are done are a bit different.
Or the action available can also change for the planning phase.
For animation, we can also have strong variation. For instance, in our walking cycle, based on the personality we are into, right now, the animation is changing quite a lot.
The way of speaking, as I said before, is changing based on the personality it is currently into.
And as I've told in GCC 2019, we can also have this default mood position that changes depending on the personality you are into. Like if you have an angry kind of personality, you may want to put your default mood position more in the hostile mood so that when the agent got bored, it will go slowly back towards this hostile mood.
Now, when it comes to personality and you want to add personality to your game, we advise to first actually choose where you want to express them and where they will have influences. If it's just in the decision making, like in GDC 2019 for my talk, any number of personalities should be manageable as it has only design costs and majority of the cases is not going to be asset related normally.
But if it's about giving influences to animations, speech, or asset-related applications, then it can quickly go out of hands, and that's the case for Wunder, actually.
In Wander, we have 8 different personalities, and that's quite a number.
Personalities influence both base animation of walk, idle, or reactions, but also the way the agent is speaking.
So that's a lot of assets to create.
For instance, we have 8 personalities with 4 modes.
and one base animation as well. So this makes a total of 33 animations to create.
That's a lot. That's way too much for what we can handle, so we decided to at least try to cut this number down a bit. So we decided to create what we call personalities principles, four of them, that will group actually a few of these personality parameters together. And thanks to this, we're able to reduce the number of animations from 33 to 17.
And for us, it was enough in our case.
Of course, decision making can use these personality principles if it wants, but it can also use these eight personalities as before, so there is no problem with that.
Okay, now let's move to troubleshooting and speak about our different debug tools and tweaks and the balance tools that we have created.
So the first tool we have is basically personality debug.
We can just click on this UI and set the character in a specific personality right away.
So if you want to test something very quickly, it's very useful.
In a similar manner, we have this mood space, that mood UI, where we can click into and set our character to be in a specific mood and specific personality whenever we want, so that we can test all the possibilities.
We can also see, weirdly right now, but a mood heat map that is updated during the world experience, allowing you to know, basically, how the users are playing your game, and if...
For old players, for instance, the moon is always in the same area.
It's not able, actually, to move in all the space, which is something you may want to know and try to fix.
We also have personality history that allows us to know when personality changes happened, what is the source, and how they evolved.
We also have emotion history that will list the different parameters this emotion had, when they occurred, and from what source.
And at the end, we have the most important tool that I will explain now, the emotion of all information that basically computes the influence score of each emotion on the mood during your playthrough.
So that's the table you can see at the bottom.
So for each emotion, we have the number of occurrences, the average intensity, and the average duration it has had during the whole playthrough.
And from that, we are going to compute an influence score, which is just the sum of this intensity multiplied by duration for all this emotion.
So how can we use this tool?
In one specific case, one of the most known problems, or difficult to balance problems, is the mood is always in the same area.
No matter what player plays, it's always there.
It's very hard to get away from it.
Well, if you look at this table now, we can get a lot of information from it.
We check, for instance, first what is the highest influence score emotion, and we can see that joy is actually influencing at least twice more than the other emotion, the mood.
So maybe it's too much in this instance.
In this case, we are going to investigate joy and see what may be the problem.
We can see that the number of occurrences of this emotion is actually almost double to the other emotions, so maybe we can try to reduce this number of occurrences.
But sometimes it's not possible because it makes sense in a game design point of view.
So we can try this time to reduce this average intensity so that it better use this range from 0 to 1 instead of always being very high.
Sometimes it's still not enough, it doesn't make sense, so you can do a similar thing with the duration and try to lower it a bit so that it has less influence on the mood overall.
But if everything makes sense for your design, then maybe the other emotions, the counter emotions, are not influencing the mood enough.
In this case, you want to try to boost either the number of times they are apparent, or the intensity, or the duration of them.
And at the end, yeah, if you're able to get an influence score that are mostly balanced between all your emotions, or a bit more positive, or a bit more negative, you can do it easily and understand easily thanks to this.
debug tool. But you have to aggregate your data with many players as players have different personalities and ways of playing. So that's it for me today. Thank you for watching, and if you want to contact me, here are my information. Have a great GDC!
