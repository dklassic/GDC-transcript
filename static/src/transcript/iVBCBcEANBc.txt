all right. We have achieved a quorum up here for this. For those of you who have not ‑‑ are not familiar with our short form sessions, we have three of them this year. One of them, of course, being the rant session which is a perennial favorite.
tomorrow we have a new one that we're introducing AI disaster stories. That should be entertaining. But this is one that we started a few years ago that has gotten a lot of good feedback over the years. Basically what we're saying is what is the simplest AI trick in the book that you have used and gotten a lot of mileage out of? So let me change slide decks.
And I'm going to turn it over to our five guys. They have about five minutes each. Don't blink. Don't bother taking notes because these things go quickly.
Let's go.
OK?
OK.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
OK, my name is Steve Rabin.
And for my simplest AI trick in the book, I actually have two tricks I'm going to cheat here.
My first trick is agent reaction time.
And I kind of just wanted to ask the question, if an AI sees the player, how long should it be before the AI reacts?
I mean, intuitively, we know this should be like more than 0 seconds and less than 1.
But should it be a quarter of a second?
Should it be a half a second?
What should we really choose as our reaction time?
Well, psychologists and neuroscientists have been studying this for over 100 years, and we do have some answers.
So, there's several different types of reaction time.
So there's two I'm gonna talk about.
One is simple reaction time.
And this one, to start with, is just you're looking at a stimulus and the moment you see the stimulus, you say hit a button.
So in an AI context, imagine that we have the AI and they're aiming at a doorway and the moment anything comes to that doorway, they're gonna pull the trigger.
How long does that take?
How long does it take in a human?
So we're told by psychologists it takes about 0.2 seconds for that simple reaction time.
If you want to try this yourself, you can go to humanbenchmark.com and they've had millions of people try this and we see that the median time for them is 0.25 seconds.
Interestingly enough, this is for vision.
Audio, humans have a faster reaction time of about 0.15 seconds and fastest of all is touch.
and it's probably just due to the amount of cognitive processing that has to occur for each of those.
So the other type of reaction time we want to look at is go no go reaction time.
So this, let's go back to the scenario with the AI, he's aiming at the doorway.
Now, through the doorway, a human's gonna appear, now they could be a fellow teammate or an enemy.
So the AI's gonna make the go no go decision, do I pull the trigger, right?
Anyone who plays first person shooters games make this decision all the time.
How long does it take?
Takes more time than .2 seconds, doesn't it?
You don't want to make a mistake and shoot your teammate.
So psychologists tell us .4 seconds for the go no go.
So now of course, these are baseline numbers and it's always worse than that.
So if you want to model being distracted, you're going to add time.
Sometimes the stimulus is hard to identify and maybe you want to model that, you need to add some time.
Maybe you're also kind of, the AI agent also needs to aim and that takes time too.
So we just talked about kind of the simplest cases.
So you probably want to add time in addition to that.
OK.
For my second trick, it's just a simple C++ trick to correlate enums and strings.
So sometimes we have these enumerations, say these messages that the AI is going to deal with.
And we want to be able to not have numbers in our debug logs or on the screen for debugging information.
We want strings.
But we don't have to maintain these two tables.
This is problematic and stuff.
And yet, and then we don't want to just use strings because, you know, if you have a string compare in your game, I'm going to find you and I'm going to shoot you.
And it's going to be a simple reaction time.
OK, so how are we going to do this?
We're going to create a file called names.h.
And we're going to put our enums in here.
We're going to put the special register enum thing and then put our enums inside that.
And notice that this file has no semicolons.
So at compile time, we're going to read this file in twice.
one time to create the enumerations and another time to create the strings. We're going to use macros and let me show you how it's done. So to create the enumeration we're going to do text replacement macros to replace whatever is that X is with X and a comma after it. And so we can create the enum and it just actually just reads in the whole thing at compile time, does all the text replacement and boom we have our enumeration. Then a second time we define that register enum as something else. This time we have this hash mark.
X comma that's going to take the thing, put double quotes around it and then a comma after it and we can read it in, create a string table and now boom they match exactly and it will never be out of sync. So those are my two tricks. If that was too fast you can go to game AI pro.com and I put these slides up at the site. You can get them and they'll be there for about a week. Thank you.
Good afternoon. My name is Jonathan Adamchefsky. I'm a core programmer at Insomniac Games responsible for our navigation tools and engine systems. And my simplest trick today is to do with cleaning up navigation mesh for Sunset Overdrive. So Sunset City is the setting of the game Sunset Overdrive. It's a big detailed place.
There's a lot of buildings, a lot of geometry.
We take all those triangles, we feed them into our navigation mesh, the navigation mesh generator we use, recast, and it gives us back a great big mesh for the entire city.
One of the problems with this, or one of the details of this that becomes a problem is that this is made up of a number of separate islands.
So to illustrate that as clearly as I can, in this view of a building, there is an island on the awning here.
There are three islands on the roof.
And the ground, that big green area, is one great big island of NavMesh that spans the entire city.
The problem comes not with those islands, which we expect bots to be able to climb over to get up and down off the building, but inside the building, there are two more islands contained in there.
And it's these type of islands that are a continuous source of bugs.
We don't want these islands.
To illustrate again really quickly, shipping container, island on the top.
another island inside it. So the sorts of bugs that come from this include, uh, performance problems where, uh, a bot is trying to find a path from a connected island to an island to which there is no link. A disconnected island. And so we spend CPU time doing a path search for something that can never possibly succeed.
there are any number of game breaking bugs that can come as a result of these. So say for example an enemy is blown up flies through a window on a building which somehow ended up without collision on it. Ends up inside. Checks to say am I on nav mesh? Yes I am. Tries to find paths out. Can't find paths out. The player can't see the bot either. Can't kill it. Can't finish the mission. Unhappy player. It's a bug. So to clean up this problem In the past, what has happened is the design team has had to go through and by hand identify islands that were not connected and try to mark them up and to have them excluded.
That's a tedious process, that's buggy, it's something we'd love to do automatically.
And we were able to do it by saying, what do we know about the game world?
What do we know about the game environment?
What can we reason about to automate this process?
what we could reason about was markup we have. So take for example what I tried to start with which was spawn volume. So a spawn volume is a volume place that will find a random location on navmesh inside the spawn volume and put a bot there. And of course you want that navmesh to be there. And so you can use that as a starting point and flood fill throughout the islands from one to one following the links which you can see the purple lines in the image there show links between islands.
and you can find the reachable parts of the game.
The problem with that is that spawn volumes are sometimes really, really big.
A hundred meters or more, depending on the sort of setup you have.
And by the time you get that big, there's a really good chance you're going to capture some disconnected island and accidentally mark it as being connected and something to keep.
And so we used a less, in some ways, a more crude approach, rather than looking where enemies or where bots can come from, just saying what's been marked up as being connected and keep those things.
And that's a simple...
trick, a simple tool for marking this up. It's something that's easy to explain and to understand. It's something that's easy to reason about. And it meant that across all of Sunset City we had a big improvement in quality with a small amount of extra work. We were able to get rid of about 25% of the triangles.
uh, in disconnected mesh, reducing it from about 400,000 to about 300,000. So if you're using an automated tool like Recast, uh, I would highly encourage you to spend the time looking at what you know about your game and what you can apply to that to improve the quality of it, save time for your designers, save time, uh, give better information for your AI programmers to reason about and overall end up with better games. Thank you.
So my trick is a generic way to contain all types of data.
Hopefully everybody's familiar with blackboards as we use them in games.
I'm not thinking traditional blackboard architectures here, but the kinds of blackboards we have in games.
If you're not, there's a fantastic master class on AIgamedev.com with Damian Isla and Alex Champendard.
Go look it up.
And by the way, small trick, I keep two blackboards.
Well, really lots of blackboards, right?
So I have the global blackboard that all the entities can look at to share information.
But then each entity has its own blackboard where they can keep entity-specific information like the list of all the other entities that they can see, for instance.
But that's not really what I wanted to dig into today.
Why is that not advancing?
There we go.
All of my blackboards and also my entities, so I started out with blackboards that were sort of messy, right? I just had lots of hand selected values that were written on there. Um, and over time I wanted to be able to put things on them much more easily. So I came up with this idea of a generic data store, which is really just a hash table.
um, that stores key value pairs. My blackboards inherit from it, my entities also inherit from it.
Now I have the standard way to store data. Um, things that want to look up data or want to store data don't have to care where they're supposed to store it up. So in the configuration I can say go look up the value name such and such and look for it on the entity that you're gonna shoot at.
Right? See if that entity is an enemy, for instance. Uh, or whatever other value you need to look for.
The keys are just strings, so I've gone a different route from Steve.
Instead of using enums, I hash all of my strings, and then my string compares are just integer compares.
So that's another simplest trick to figure out.
The value can be anything. And this is the real power of it, right?
I can store ints, I can store booleans, I can store floats, I can store pointers to objects, I can store collections of objects. Whatever needs to get stored and shared and passed around, I can store it. The trick is that I need to make a custom data element. All of my data elements need to inherit from the same base class so that I can put them in my container together, because C++ is strongly typed.
So I just have a generic base class.
It has two functions on it.
GetDataType lets me check that the data type is what I think it is.
It's just runtime type checking.
And get is bool.
I didn't have this at first, but it turns out that it's really useful to be able to check a boolean value for anything.
Because often, I don't, you know, I have some consideration that doesn't want to look up an object or know what type of object it is.
It just wants to treat it as a boolean and know if it exists or not.
So if I can get a boolean for anything, that turns out to be really powerful.
Inheriting from that is a templated base class that just takes the type of object as a template argument and has the functions to get the data value.
It also has some functions that you can implement to set the data value.
Some things may be implemented so that you can't set them, some so that you can.
Some can only be set when you construct it.
So there's a canSet function that by default returns false and a setDataValue that by default asserts.
Inheriting from that is the simple data element, which just implements all of those functions.
So it stores a value.
When you set it, it just overwrites the value that it stores.
And then I can store integers, for instance, by just inheriting from that and setting the template argument to integer and implementing the getDataType function so that I know what type of data element it is.
Object pointers are a little more complicated, but really not much.
When I do object pointers, often I want to be able to have both storage for pointers that owns the object and will delete it when it gets taken out of the store, and also storage for things that aren't owned, because both of those turn out to be useful.
So I'll have a base class that specifies the data type, and then I'll have two different subclasses for owned and unowned.
And that's really kind of all there is to it.
Hi everyone, my name is Reg Graham. So I'm going to start by introducing the master of ceremonies, Caesar. Let's see if the sound is playing. No audio is playing. Imagine amazing audio happening. I'm not going to sing. There you go.
Hey, look at that.
This is nice.
It's moving.
That's all it's doing, folks.
I have my wonderful CA helper here, who is going to shepherd him along.
He may do sad and terrible things.
He's a very, very simple little robot that I decided to build in maybe about a week.
Can you hold him up and then set him down, maybe going up in that direction?
It's very, very simple.
Here, I will send that.
So at the end of, yeah, just let him go somewhere.
Somewhere not too complicated.
So at the end of The Sims 4, I was like, well, what do I want to do? I don't really want to work on another side project that's like another game. I want to do something completely different. So I decided I was going to try my hand at a little bit of robotics. This is incredibly simple. I use the Arduino Uno. It has a 16 megahertz clock and 2K of SRAM for those who don't know what it is. And this is what he looks like if you were to see him nice and up close. That's going to be a sad corner for him over there.
What he has is two continuous motion servos.
That's what lets him move.
He has two infrared LEDs along with two sensors.
If he completely explodes, you can turn him off by pressing the little back thing.
What happens is the IR sensors will, or the IR LEDs will send out infrared light signals. What that does is it reflects off of something and gets hit by these sensors right here. If he detects that there's something there, he'll turn. Now things love to soak infrared light, so we have whisker switches as well. The whisker switches, when he hits something, he'll hit it, he'll back up, he might be doing that right now. He'll stop, back up, go around because he's hit something particularly bad.
a slight spoiler alert in order to get him to even work in this room I had to put tape over these IR sensors because there's a hell of a lot of infrared signal happening in this room.
So he just freaked out. He just was afraid and alone. This is an incredibly simple robot. Oh I have two I have three debug LEDs. He has a blue light on right now which is his move forward state. This is this is your debugger if you've ever done anything in robotics you're lucky that you have that.
So I want to show you just the software side which is it's 1100 lines of basic C++ style code.
He has a simple state machine.
This is an incredibly trivial robot from anyone who's ever done anything with robotics.
This is like stupidly simple.
I did this in maybe a week including all the hardware.
So that's really all that he is.
But why am I talking about this?
Because for me it helped me learn what it's like to program in what I call the real world.
the actual world that we live in today, which is a much harder problem to solve.
There are, in fact, entire tracks of academia and in the real world about how to solve some of the particularly hard problems of navigating a room such as this.
He's probably exploded.
There's a switch that you can pull back if he's completely dead.
So, for example, this is his view.
This is all I get.
I basically get what is effectively the same as two ray traces and two collision detectors.
Those are on pins 13, 12, 4 and 3 which are either 5 volts or 0 volts which means I have a 4 bit world representation at this point.
Very very simple.
The key here is that there's no easy way to call get position.
We are all very spoiled by get position, get orientation, any of those things and that is one thing that creating this little robot taught me.
Where am I?
I have no idea.
I could very well be here.
And there'd be no way that I would be able to detect that that's there, except that, oh, my left pin is up, is 5 volts.
So...
That's, like I said, there's whole tracks to kind of do this.
So his performance in a beautiful specially designed room, which is my kitchen with all the doors closed, is 100%.
He happily navigates, because there's no errant infrared signal, such as there are in this room.
And all of the obstacles happily reflect infrared light, so he navigates perfectly.
He never really hits collision, his whiskers at all.
In the real world, he has maybe a one to two minute success rate.
Is he still going back there?
That surprises me.
He usually reaches some point of massive sadness by now.
Because he's very, very simple.
Let me show you some of his mortal enemies.
Here's one.
These are my girlfriend's shoes.
They're low enough that his sensors can't detect it.
So he'll happily go over, and then he'll just go.
and he'll flip over and then life is just terrible for him when he flips over. There are many ways to solve this of course. Here's the real, here's his real like the worst one.
This is my dining room table. That beam there is high enough that his sensors don't see it. But low enough that all the, if you guys saw the picture, all those electronics that are sitting there on that bread board get scraped off.
So that's not fun.
He's gone under there twice now.
And the first time I lost one of the infrared LEDs because it shorted and blew the LED.
The other time I lost a sensor.
So fun times.
So where am I going with this?
Well, let's take a counter example here, which is a Sims 4.
On the Sims 4, I have a Sim sitting here at a computer and there's a guitar to her right.
If I want to run an interaction that causes her to get up and use that guitar, it is actually really trivial to do that.
Because I know what my position is now, and I know how to walk all the way over to the guitar where it is, I know the exact offset of where I need to stand to play the animation to get up and start playing the guitar. I have no, my robot has no clue where he is. He's wandering through the grace of this wonderful CA who is watching him go. That's really the only reason that he knows where he's going. Someone's going to hit the little whisker probably. It looks like you're about to test him. Oh God. This is going to go well.
Yep, there he goes, see?
And he does that.
He keeps going, he's gonna freak out.
Oh no, he's still going.
So that's really it.
So our characters live in this perfect digital world.
And so what I'm saying is that you should go out and try and build an autonomous robot and try and see what it's like to solve this type of problem which I have quite unsuccessfully solved in my little one week of playing around.
Experience programming in the real world and except for designing the room, you don't really get to cheat like we get to do in games.
Thank you.
Hi.
Warframe is synonymous with space ninjas.
And nothing is more ninja than acrobatic parkour moves and wall running.
Wall running was added for the players quite early on in the closed beta of Warframe.
And it changed the game up dramatically.
Players can wall run on pretty much any near surface, any near vertical surface in the game.
And we support this through dynamic runtime sweeps and calculations to keep them glued to the walls, defying gravity.
However, this is still one of the more challenging maneuvers for new players to pull off.
Last year, we added specters to the game.
Specters are NPC-controlled bots that are kind of duplicates of players' warframes.
They have the same loadout and weapons and equipment and abilities that the players have.
Initially, they were limited to just a single type of mission in the game, where they would be the opposition for the players.
But soon enough, this feature evolved, and now players can actually craft their own specters to take with them as allies into any mission in the game.
So these specters have to be able to do everything the players can do, and they have to be able to keep up with the player as the player moves through the environment.
And that includes running on walls.
But how would you get an NPC to run on a wall?
Well, the animation and physics side is already taken care of for our players.
So the big challenge comes with identifying where the NPCs can wall run.
And this means having either specific bridge actions placed in the level by level designers to identify where these actions can be performed, or having some kind of nav mesh on the walls.
And these either need to be placed manually, or you have to come up with some smart algorithm to automatically detect these areas for you.
Our levels in Warframe are all procedurally generated, and we combine level chunks together at runtime to create the runtime level.
And we have a huge amount of level chunks already released for our game.
We've got hundreds of these things, and they're all just got their own special characteristics.
So it would take ages for level designers to have to go through and manually mark up all these level blocks.
And that would also be very error prone.
Our level geometry is also quite complex with the collision mesh, and coming up with a foolproof algorithm would have taken much more time than we really had to spend on it.
However, we do have thousands of active players playing the game every day, and they are managing to wall run just fine.
Well, most of them are, anyway.
So what if we could leverage our player base to teach our AI where it can wall run?
So that's exactly what we do.
Every time the player performs a wall run, we drop breadcrumbs from where he jumps off the ground, where he connects with the wall, where he jumped off the wall, and where he landed back on the ground again.
Since players can jump all over the place, we need to validate that we get a good sequence.
We need to know that a jump off the ground, connect with the wall, move along the wall, jump off the wall, land back on the ground again.
We need to then validate that our initial jump point and our final landing point are both on navmesh and not in some weird...
part of the level.
Once we've got the valid sequence, we can dynamically create an average for the NPCs to follow that maps onto that wall run action.
So we only need to do just some clustering and filtering to ensure that we don't add many multiple variants of the same link with just very slightly different offsets.
And now the players can follow the, the NPCs can follow the player.
Currently, we keep these bridges around for the remainder of the current session.
And we have a pool around the players so that the ones closer to the players we keep alive longer, and the ones that are further away we discard so that we don't waste our memory too much.
But since we're an online game, this feature will improve and evolve over time.
And we can then upload these links to a database.
And then we can either manually patch our maps afterwards and release them in the next update.
Or we could just pull those links down dynamically from the database at runtime and make these links persistent across multiple sessions.
So in the future, we could potentially have players teaching NPCs where to wall run so that NPCs can teach new players where to wall run.
And how awesome is that concept?
