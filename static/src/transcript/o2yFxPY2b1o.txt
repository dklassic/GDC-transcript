Enjoy your power. This is the big marketing tagline for Infamous Second Son.
This really applied to the visual effects team as well during development of the game, and I hope that the joy we had in bringing the visuals to you guys is really apparent.
Hello everyone, I'm Matt Vagno, senior visual effects artist at Sucker Punch.
Today I'm going to talk about how we created the visual effects behind Infamous Second Son.
There's not enough time to talk about all of the powers we created, so I'm going to focus on two powers each from Smoke and Neon.
Then I'll talk about the creation of a new tool set and the pipeline for Infamous Second Son.
along with the pros and cons from our new workflow and lessons learned attempting to make something new on the next generation of hardware. So let's get right to it and we'll learn about how we created some of Adelson's Smoke Powers. So for the Smoke Powers, what I'm going to cover is how we defined the visual language of the Smoke Powers, some of the game design behind the powers, and then I'll go over Smoke Dash and Smoke Event Travel, kind of show you how they went from concept to completion.
This is an early concept with a smokeable power.
So during pre-production, our engineers were creating the effects tool set, and the effects team itself, we were experimenting with third-party software to kind of get a sense for what we wanted out of our internal tool set.
The concept team was hard at work during this period creating smoke power concepts for all the various proposed power designs.
During this period, they had no idea of what our limitations would be, and that was a really good thing for us.
You know, it's always important to have people whose only thought is the final product and not the constraints of the technology.
These are some examples of what some ambient smoke emitters would look like for idle animations and things like that.
This was created during the production of our ultra-power, the orbital drop, and influenced the visuals behind the final blast wave created as Delsim lands.
By this point in the concept phase, we really had narrowed the look, so you can see the three common elements of our smoke power set.
Sort of the wispy smoke, the billowy smoke, and the ash and embers.
When we were given the task of creating powers based on smoke, we ran into a few major hurdles.
Our initial art direction was basically make it look like real smoke, or something you'd see in a pre-rendered cinematic.
Smoke by itself doesn't feel terribly dangerous.
You don't have a natural understanding of its weight and impact and force like you do a real object, say an arrow or a spear.
Smoke can also be hard to see in low light conditions, which really can impact the player's understanding of what's going on.
So analyzing real smoke reference resulted in a couple of observations.
Firstly, that turbulence and wind were going to be very important to look we wanted out of our smoke visual effects.
Secondly, lighting the particle system so that it sat correctly in the scene and didn't feel composited in was going to be both critical and challenging.
We felt if we hit these pillars, the smoke would be believable within the Infamous universe.
which opened up the ability for us to kind of stylize the effects.
It was just more important for us that our effects feel believable within the universe than completely realistic.
Early on in the project, like I said earlier, we spent time experimenting with third-party software, like Max and Houdini, to kind of help get a sense for what we wanted to do with our internal tools.
This is a little quick Houdini render we did pretty early on.
During this experimentation phase, we used a lot of turbulence and wind in our sims, and that kind of really influenced the direction we took with our real-time crawl noise functions in engine.
This is something I showed to Sucker Punch engineer Bill Rockenback, and he was kind of able to take this and use this as a guide for creating that real-time crawl noise.
After analyzing the reference, the concept art, and creating some initial VFX prototypes, we realized that to make the smoke feel dangerous, we would need to make smoke elements the contrail, you know, the leftover residue from a force.
We knew the power had to be visible in a bunch of different times of day as well.
So our decision was to make that force a storm of really hot, bright ashes.
It was driven by a simple analogy I had one day early on in the smoke dev process where, you know, if somebody blows cigarette smoke in your face, it's just annoying, right?
But if somebody puts out a cigarette on your face, that's really gonna hurt.
We knew we'd run into the problem of some players misidentifying this power set as fire, but it was really more important for us that the player could track and understand their abilities from a design perspective.
One of the game design elements that really makes an infamous game feel, well, like an infamous game, is the joy of traversal.
Smokedash was the first power we prototyped that really felt like it met that bar in terms of joy.
These are four different looks the concept team came up with and I ended up taking various ideas from all of them for the final power effects.
With Smokedash the core design concept was that the hero would dematerialize and pass through objects like chain link fences and path around objects like cars or short walls.
In order to help dematerialize the hero, we had to create a transition effect that would cover up the removal and addition of the hero's mesh.
To help with this, we spawned particles off a sort of low-res LOD version of the hero's mesh that we called Particle Mesh.
We wanted this action to be as smooth and as fluid as smoke really is, so we made it a pillar of the effect that the same particles that are spawned when this move starts are the same ones that form the hero at the end.
So one continuous motion from one particle system.
Once we had that element working, we added ribbons, smoke, and lights to help carry the directionality of the hero's motion.
So this is the concept we're working with and the end game.
So breaking down the smoke dash effect, there are different components.
There are ribbons, some soft smoke, astronombers, and dynamic lights.
So on the left is the base hero geometry without any emitters.
On the right, I've hidden the hero's geometry and turned on particle emitters that are parented to the previously mentioned particle mesh.
They're inheriting the color of the mesh and their normals are facing the same direction as the triangle they're parented to.
Using this technique, we're able to hide the transition of the hero's geometry being turned off and on.
This is a closer look at the technique.
I'm showing this at 1 5th speed to kind of help make the effect more obvious.
You can see here at the end, you can actually see the moment where his mesh pops back in and swaps.
Right there.
If you see it in real time though, it's really not noticeable at all.
Here I've added back in the ash particles that leave the hero at the disintegrate moment.
They kind of move around with curl noise before they're finally lurping back to the hero's position at the reform moment.
I've disabled the curl noise on this demo, which shows how the ash particles lurp between being on the particle mesh, being unlocked, or free in the world, and then back to the mesh.
If you notice, the particles spawn near the head.
They lurp back to the mesh position faster than the ones near the feet, and helps give it kind of a lurching, organic feel.
These curves here represent positional lurps between being world update and the hero's particle mesh.
When the graph's vertical value is zero, there at the bottom, the particles are unlocked from its mesh, and when the value's one, the particles are sort of locked to its mesh.
These curves are evaluated over the particle's normalized lifespan, so you can kind of see how the graph starts at one, and it goes down to zero, and it goes back up to one.
The graph on the left is marked A, and that actually represents particles that spawn from the top of the hero's head, while the graph on the right, marked B, those are the ones that spawn at the bottom of his feet.
I used an additional alert between curves A and B, kind of depending on where it spawns on the hero's body.
So during the dash move, Smoke Whisp flapped the hero and then sort of towards his final destination to help carry the relationship of the motion, or directionality of the motion.
This here I'm showing actually parent-child emitters are using for generating the ribbons.
And you can see that the entire ribbon has the same facing axis from front to back, if you look at the yellow ribbons there.
This prevents the twisting seen in a lot of ribbon implementations.
The blue line is actually the direction of travel of the hero, and the white line represents the ribbon facing vector in three-dimensional space.
The ribbon facing vector is created by taking the vector between the parent and the direction of travel and crossing it against the camera's view direction.
This is just sort of one simple example of ribbon facing that we could have used.
We're not really constrained to having a single vector along the entire ribbon.
We could actually have it twist or curl and set the facing to really any vector we want.
We actually do that in a few cases.
The hero's smoke float or the smoke missile has kind of a spiral to the ribbons.
So this is the final smoke dash effects.
You're able to dash while in midair, and you can also see how the player dashes through fences as well.
It's just really fun, really smooth.
That's another sort of pillar of Smoke.
Everything has to be smooth.
So an upgrade to the Smoke Dash is the ability to dash into a vent and travel to the top of a building, kind of bursting up out of a vent.
This is a concept for Smoke Vent Travel.
So the goals for this effect were to, you know, reuse the smoke dash dematerialize and send the hero skyward with a pillar of spinning smoke wisps.
The visual concept relied heavily on a smoke-driven feel, so the bulk of the work was gonna be getting that part right.
It was important for us that we capture the explosiveness at the beginning and the deceleration at the end to match the animation team's hard work.
We also wanted the smoke to feel carried away in the wind as the hero was falling.
So we ended up getting, I think, really close to the concept with this particular power.
So this is the final version of the vent travel effects.
It's comprised mostly out of these three elements.
It has pretty much the smoke ribbons, it has some soft, kind of billowy smoke, and a bunch of ash and embers.
So the first step in breaking down the shapes in the concept is to create the path spiraling the hero.
Because we're able to spawn particles from a position of other particles by specifying which particle emitter is the parent and which particle emitter is the child, it turned out to be relatively easy to generate this shape with our system.
I used a similar technique to the smoke dash ribbons combined with parent-child emitters for this.
Here you can see the parent particles are actually moving upward in red and they have the child ribbons attached.
I've set up a radius that's lerped between two different values and it's controlled by that key frame you can see kind of in the lower left there.
This basically creates the right profile that we want out of the column.
Once I have the parents rotating over their lifetime, you can see that the basic shape of the concept is starting to take form now.
So to make the ribbons feel more organic, I added some noise in the width of the ribbons.
You can see how the ribbons are actually getting thick and thin in places.
Sort of a 1D noise.
I'll talk later on the various ways that which curl noise functions can be useful for things more than just particle motion.
Here in this part, I've actually disabled the rotation of the ribbons to kind of help show the resulting noise patterns a little bit better.
So the noise and the width.
Again, just trying to layer different ways to make smoke feel more organic.
The next thing we're gonna do is add some curl noise and wind forces to the emitter.
And I'm using a couple different octaves of the noise on the ribbons to make, give them both large and small waveform patterns.
It gives it a really, another nice organic thing to do.
These noise patterns, they iterate over time, so each time the effect is fire, the patterns are different.
So this is a good time to talk about a simple way we get a lot of motion out of our billowy smoke emitters.
You can see how there's actually a downward motion as the smoke billowing, billboards move upward.
And this kind of makes it feel like the smoke is rolling.
One of our engineers, Matt Dersoff, he came up with a way to magnify the UVs on particles such that the UVs would scroll faster in the center than they do on the edges.
This results in kind of a spherical shape and it helps give the billboards more volume.
This is actually just a single billboard with scrolling UVs.
You can see that as I adjust the magnification values that the spherical form becomes a bit more obvious.
This is just one of the simple ways we got a lot of motion out of our smoke textures without using flipbooks, flow maps, or UV displacement.
I think we had maybe two animated flipbooks in the entire game.
Most of our techniques are pretty simple like this.
So here are the final event travel effects.
It's pretty useful for getting rooftops quickly.
You're also able to smoke dash into the tops of vents and get kind of a kicker boost, you'll see here in a second.
It's super fun to just chain these around the city and see how many you can get in a row.
So now that you've seen some of the smoke powers, let's take a look at how we created some of the neon powers.
So for the neon powers, what I'm gonna be covering is how we define the visual language of the neon powers, draining neon from signs, and how we created the neon dash effects.
Here's some visual language studies that were done by the concept team for the neon melee.
These concepts reference the idea of light writing, which ended up being one of the visual pillars of the power set.
Light writing being the photography technique where people use kind of flashlights and long exposures to generate really long trails.
This is some neon chocolate explosion concepts.
You know, at this point, you can see that we're still trying to find that kind of visual signature for the power.
We're testing with both angular and flowing lines, or some line symmetry and just different color ideas.
Just still trying to figure out what we're gonna do here.
So as you've seen, the art direction relied heavily on the concept of light writing complex lingering shapes.
Everything had to cast light, and everything needed to have some sort of accent volume in addition to light writing to give it the proper depth.
This accent volume ended up being kind of a faint neon gas that's present in the background in pretty much all the neon powers.
We just really wanted to think about neon as a plasma.
At the same time, we knew we wanted to fling, get, fling, fling, excuse me, fling waveform patterns, which our curl noise came in really handy for.
To get a different result than smoke, we ended up using much larger waveforms and less octaves of noise to kind of get a more flowing form.
We also clamped the noise patterns, in many cases, to create a contained look to the neon.
So if we spawn inside a cylinder, all the noise is contained within the cylinder or within a sphere.
It was really important for us that this power felt under control by Delsun and not wafting away like smoke.
That was one of the ways we were going to differentiate it from smoke.
During Neon Power's development, we had a lot more back and forth discussions with the concept team than we did during Smoke Look Dev.
A lot of the Smoke Power concepts came in pre-production before we had any tools to work with.
So once we had the visual language defined for Neon, however, we altered our workflow with the concept artists to have them provide more generalized form studies rather than detailed illustrations.
So these are some form studies for the Neon Float.
If you look closely between those concepts in the final game, there's inspiration from a few of those different concepts present.
So here's some form studies for the neon stasis grenade.
You know, as an effects team, our big take away during this part of development was that concept artists, they're masters of form.
This is what we should be using them for.
What you want to do is work with them so they understand your timing needs.
You have them sketch the iteration of form over time.
So even a simple example in the lower left here, like you can see from A to B, is more useful than a static form.
You help them to understand that the starts and ends are just as important as the middle.
A lot of concept artists, in fact most, will probably give you just the sort of middle section of an effect if you ask for a concept.
So let's talk a little bit about Neon Drain.
It was one of the first Neon powers I started working on, and we knew that getting it right was gonna be a challenge, but it would set us up for creating the rest of the Neon power set.
The design goal was to drain Neon from an in-game sign model.
At first, it wasn't really clear how we were gonna do this.
I mean, should we model splines over each sign and then render after those splines?
Should we drain from one end of the tube, like a string being pulled out when the hero drains from it?
Once we came up with our particle mesh solution for a smoke dash, though, it became pretty clear that we should try to adapt that tech for this particular power.
The basics of the effect is that at the moment the drain button is pressed, we spawn particles off of a particle mesh that's attached to the in-game sign model.
We kill the emissive values on the sign model to kind of turn off all the neon tubes, as well as any lights and reflections from the sign.
Finally, we swirl the effects downward toward the hero's hand where he sort of grabs it to absorb the power.
This is an early concept of Neon being ripped off a sign, and then the final in-game effect.
So here's another example of how a rough concept can go a long way to the final product. This set of roughs was done by Second Son art director Horio Dociu and the result is pretty close to this rough set of ideas. I like to joke with him that I really captured that Saturday night fever thing he's got going on, that last frame over there.
So this is the full version of Neon Drain. I'm actually adding back different elements here, kind of breaking it down. There's the wispy energy and some neon bits, some plasma gas, and some dynamic lights.
So this is an example of a Neon Science particle mesh.
Particles are spawned on a somewhat uniform but random position on the triangles of this mesh.
After being spawned but not drawn, they sample the color value there underneath.
And if the value is below a certain threshold, the particle tries to find a new spot.
So we repeat this up to about, I think, 10 times before we give up and the particle's killed.
This gives us the effect of particles being only spawned from where the emissive values are in the texture.
Doesn't mean we need to spawn quite a few particles to make this work.
You can see a lot of times we'd be sampling some of the black areas and not getting a valid position.
But thankfully on the PS4 we can spawn tens of thousands of particles, so this wasn't too bad.
So here you can see the color inheritance the particles have for the emissive shader a bit more clearly.
You can see how the red particles come from the red parts of the sign and the blue from the blue part and so forth.
I've trimmed the particle system down to some simple shaded billboards to help show the motion as well.
In this example here, I've offset the billboards from the normals of the particle mesh to help make it a bit easier to see.
I'll just show it in the video.
all the green dots are actually a position of lights that are spawned from the same particle mesh, and they're casting color from that same underlying pixel color.
So we found, or we actually used these lights at kind of a lower particle count than the rest of our particles, and it's for both performance and visual reasons, right?
We found that the results from sort of larger lights with softer fall-off gave us a better aggregated light look than tons and tons of tiny point lights.
This is how the Neon Drain turned out.
This was used in a cinematic in one of our trailers.
I just love the swagger Delson has as he comes up to drain.
It totally nails his character.
Neon Dash was another key power for us.
Not only because traversal powers are important in the Infamous universe, but because it's our test of how we could turn the hero into a light writing element.
This effect was gonna be used for both the hero and one of our main characters, Fetch.
The game design required very lengthy trails so that Fetch could be followed.
The other design requirement was that the hero could dash nonstop for as long as they held the button down.
This introduced a few technical constraints such as having to account for variable dash distances.
One thing this meant is that we couldn't use some of the same techniques we used for Smoke Dash, where the hero was reformed by the same particles that left him during the launch, because we didn't know the dash time beforehand.
This is an early concept for Neon Dash.
From an art direction standpoint, we needed to have the hero's form strobe as well as leave lingering neon trails.
We also wanted to make sure that the effect had some sort of lingering element after he came out of the dash.
We weren't really sure what that was gonna be at the start, but we ended up using a technique to crawl energy over the surface of his mesh as he leaves the dash.
I'll talk about that technique in a later slide.
This is another concept and how it turned out in game.
So here's the full version of Neon Dash.
It was composed mostly of sort of different elements like some kind of wispy energy trails.
There's the body ribbons on splines.
There's neon bits, plasma gas, and some lights.
You can kind of see an example there as he runs off screen of how the really long light running trails.
Those I think lasted like 20, 25 seconds like that.
So here I've isolated the ribbons that create the form of the neon dash here.
You can kind of see in strobe as I run around.
These scar lines here represent different spline positions that we created by feeding in a list of joints on the hero.
There's a spline for each leg and one for the torso and also one for the head.
A lot of cases we used rotation functions around some of these splines to kind of help create the torso shape, create a little volume shape.
The ribbons were actually created along these splines and there was some curl noise that sort of modulated their position as you can see right here.
So an element that we used on quite a few of the Neon powers was this lingering energy on meshes.
The intersection tests against the depth buffer are not exactly new, but our engineer Matt Durasoff thought, you know, why not expose this to the particle systems?
This is another little thing we can play with.
These billboards are screen facing, so the pattern alters as you move around, but we could specify facing on billboards so we could have created a more consistent pattern if we wanted.
You're gonna see here, I'm adjusting some of the different knobs, like the depth of the test and kind of the glow amount.
This feature turned out to be pretty useful for pretty much all of the Neon powers.
We used it for a ton.
The float, the stasis grenade, just a lot of different places.
It became kind of a signature of the power set.
So here's the final version of the Neon Dash.
It's just a lot of fun dashing around the monorail tracks, you know, just dashing anywhere.
I like to call our powers time thieves, because if you're not careful, you'll find out you've been just playing the game the last 15 minutes and not actually working.
Can be a problem.
You'll see some of the depth test stuff as he comes out.
So in order to make the effects I've just shown, we had to create an entirely new tool set for Second Son.
I'm gonna be going over the components of our tool set fairly quickly.
There's a talk this Friday at 10 a.m.
by one of our engineers, Bill Rockenbeck.
He's gonna talk about the particle system architecture.
It's gonna give you a more technical look at our effect systems.
So you should go to that if you're interested in that kind of thing.
When we started pre-production on Infamous Second Son, there were a few known quantities that kind of led to the decisions that we made on the tool set.
we had to be able to deliver what the game design required.
This meant designing a flexible system that could handle the many types of powers the hero would have.
From an artistic standpoint, we wanted the VFX to be another character in the story.
The goal was to make everything feel alive, as if the character who created the power was in full control of the effect.
This was a really important goal for us because the fiction behind conduits and superpowers is pretty clear that the conduit is just manipulating the power.
They're not merely summoning it.
In terms of production, what the effects team wanted was faster editing.
This would be a requirement for us because of the volume of work that had to be done within the short development cycle that we had.
This was basically a two-year and some change production cycle for us, and on new engine and new hardware.
We knew it was gonna be really difficult to determine if something was quote, an extragen or not, but our initial goal was to increase the complexity of simulations and combine that with accuracy in lighting and sorting.
We felt like doing these two things really well would be at least a good start.
Based on those challenges, we made some early decisions on what kind of tools, rendering techniques, and processes that we would need.
Knowing that we're designing a game with multiple power sets meant that we had to create a very flexible and powerful system.
This meant rethinking the way we traditionally think about particles simulation.
For example, in most particle editing environments, particles are basically fire and forget.
At any point in their lifetime, their position is based on parameters that are only set at a mid-time, things like velocity and gravity.
The SecondSon VFX toolset allows you to directly set particle positions at any point during their lifetime or by using externally driven user parameters.
The expression difference system was definitely the right choice for the design challenges that we faced.
Deciding to improve the shading and allow real-time editing and run the particles in the GPU were also key decisions that we made early on during development.
So this is the basic layout of our particle editor.
The outline on the left is the container for all the particle systems and all of its emitters.
The property editor contains all the various fields that we can edit with our expressions.
And most of these property fields can have graph data as a value.
So an example of this is shown on the right with a keyframe editor.
The particle editing environment is expression-based, as I mentioned, so it supports a broad range of inputs.
Vectors, floats, strings, random ranges, and more.
We compile static values into constants using a, PSSL, which is a PlayStation shader language, and Bill Ruckenbeck is going to talk more about that. But once compiled, these values can be edited live, even if the game clock is paused. Variables can be created on the system or emitter level, and these variables, which I'll call user parameters from here on out, they can be used in our expression syntax. There's only a few basic triangulation and shading methods, but we got a bunch of variety out of them just due to our expression system.
One of the areas that's not expressionable is emit functions.
We did add a little bit of flexibility there to add an emit ratio multiplier just so we could modify the emit rate externally through those user parameters.
Our tool set has separate emit and update spaces and this lets us do things like emit on a character's joint and either continue to have an update on that joint or be left behind in world space.
We can also convert and lerp between different spaces I showed earlier with the smoke dash.
This is an example of editing a particle system in our tool set.
So here I'm just editing a curve that is multiplied against the particle scale of the smoke.
Notice that I'm still able to make changes to these values even though the game clock's paused.
I'm also able to change the constant values as I mentioned earlier in expressions in real time as well.
You can see I'm just changing a multiplier on the billboard size.
Now all constants can be changed, you know, alpha, brightness, pretty much anything.
Random ranges are only evaluated at a mid-time, and because we're not able to change them at real-time, I typically kind of multiply in a constant value against a random range so I can tweak things live.
You can kind of see an example of that after this is done.
When I go back to editing the static value, you can kind of see there's a random range kind of in brackets that's multiplied against a constant.
Right here.
So one of the bigger strengths of our expression system is user set parameters.
These parameters come in two forms, system level parameters and emitter level parameters.
System level parameters are scoped for the whole system.
They can be referenced on any emitter and they'll return the same value on all emitters.
These parameters can be changed externally through either our scripting language or through code.
They can also be changed on instance level.
So specific place instances of an effect in the game world can have a variable attribute, such as color or scale.
Pretty much whatever you pipe that into, you can adjust.
Now, emitter level parameters are scoped within an emitter and evaluated differently per particle.
So an emitter that has a parameter for a random range for scale, that'll just return a different random number per particle spawned.
Our keyframe editor has proven to be tremendously powerful, more than I thought at the outset.
A huge part of this is that the power is that we can input and evaluate any other expression against the x-axis of the keyframe.
So here's a simple curve used on Particle Alpha.
I've set the input expression at the bottom here, just to be L.
And this is basically a shorthand way of us saying age divided by lifetime, which is just gonna return a value between zero and one over the particle's lifetime.
So being able to map input expressions into keyframes allows us to do things like lerp the color of particles by their position.
I've created a variable here called emitPos, and this creates a box that's 500 centimeters tall by 50 centimeters wide and deep.
I then created a keyframe with the input expression set to the z value of the emitPos variable.
You can see there, emitPos.z.
I'm just swizzling out the z component of that vector.
I've added a couple points to the keyframe, one at zero and one at 500.
I've set the output value at zero to be zero, and the output value at 500 to be one.
All this does really is return values of zero to one over the height of the emitter, which then I've referenced in a simple color alert function.
It's just one little basic way you can use the variable input expression.
This is kind of a more complex example of using keyframes.
I'm using a keyframe here to adjust the rotational speed of particles on a disk.
So if I use the radius of the disk as an input variable, the output is controlled by the keyframe that you can see there at the bottom.
These values are then multiplied into the rotation rate.
They make the particles move faster or slower based on the radius.
Here I'm using the same keyframe to control a color lerp to make the results a bit more obvious.
So remember, this is only a single emitter with a couple expressions.
If you layer and stack this sort of behavior, you can get some pretty awesome results.
So now you've seen a bit of our editing environment. I'm going to talk a little bit about the shading and lighting of our particle systems. We spent a bit of effort on this as well.
So with Infamous Second Sun, one of our overarching goals was to make particles fit seamlessly into the environment.
This was sort of a mantra for us.
We felt pretty strongly that particles really feel like they reside in the scene and that particles had incorrect lighting and shading.
They always felt composited in.
We didn't want to have anything feel composited in.
So we broke the problems down into sort of the following components that we felt like we would need to have.
We needed them to cast shadows, particles, I should say, cast shadows, receive shadows, cast lights, take balanced ambient, receive directional sunlight, blend correctly with haze, and use the same HDR particle rendering that the environment was using.
So with shadows, we felt that they needed to cast shadows to help feel kind of grounded to the environment.
And our engineers were able to create a particle shadow buffer and use kind of simple blobs per particle, and those added up to the whole shadow shape.
This is some of the features here, but I'm gonna show a demo of them in the next slide.
Here is a particle system that is casting shadows, and it's having its shadow strength turned up and down.
We're able to tune the shadow strength appropriately based on how much the material should occlude light.
It's kind of just an artistic adjustment.
So, you know, for example, we could turn down the shadow strength for water vapor or kind of turn it up for opaque smoke cloud.
Just another handy thing to be able to do.
So here we can see particle systems that are receiving shadows from the environment.
In this case, trees.
The shadows are variable resolution, depending on the distance from the shadow casting object.
But the results are still pretty decent.
As I move the sun direction around, you can kind of see a little bit better.
So all deferred geometry, when our game is mostly deferred, can cast shadows onto particle systems, whether or not they're static or dynamic.
The object, that is.
So a character flying through space will cast shadows onto these particle systems.
So like with casting shadows, casting lights ground the particles to the environment and helps them fit into the scene.
There's also a huge added gameplay benefit to this as it's easier to track them moving in 3D space.
The particle lights have the same expressions for position like regular particles and they affect all deferred geometry including other deferred particles.
The only thing we don't affect is translucent particles or anything forward shaded like some of our hair.
At one point early in development, I asked Sucker Punch engineer Bill Rockenbeck if I could just spawn lights off any particle.
Like, if any particle in the game, however many there are, could they just cast a light?
And I really thought he would say no.
I really thought, there's no way it's gonna work.
And he says, you know, yeah, yeah, we can do that.
And, you know, I learned a valuable lesson.
It really pays to be greedy as effects artists.
I just ask.
There's no reason not to ask.
So here I've isolated part of the smoke missile explosion.
Each parent emitter that you can see there, kind of towards the end, has a light, has a point light on it.
Now these can be tuned with, again, variable color, brightness.
There's some hotspot and falloff controls, and there's also some specularity controls as well.
So sometimes we want a single light to represent many small lights, or kind of an area fill.
We'll kind of blur the spec intensity over an area, essentially just turning down the gloss power of the light's reflections.
So another element we felt really strongly about was getting good approximation of balanced and local lighting on our particle systems.
So early on in our pre-production, our lighting team and graphics engineers had built a system to use spherical harmonics, SH probes, to help with general environmental lighting.
I'm not going to go into specific details about how SH probes work, since there's already a lot of information out there already.
But if you haven't heard of them, the basics is that these are probes that are placed in the environment, and they capture the surrounding light information.
This light information is actually baked, kind of like a light map or an environment map, and it can be used in a variety of ways.
Mostly this technique is used to capture bounce lighting for environments, so lighting that's bouncing off a floor or a wall.
In any case, since the probe data was already being baked and used in our environment, our engineers were kind of able to use that data on our particle systems.
This is an example of the SH probe system at work lighting our particles.
So as I move the particle system from area to area, the color from the local lighting is inherited by the emitter.
This provides another huge level of realism as the particle system kind of helps sit in the world correctly.
You see that our probe must be placed really close to the green sign right here because we're getting a lot of inheritance.
The accuracy of this system is pretty dependent on the density of the probes.
For, I think for Infamous Second Son, our probe density was around 1 every 3 to 5 meters.
So with MMS2, we had directional sunlight affecting particles, and for Second Sun, we improved this capability with a way to tune the strength values per emitter.
This kind of allowed us to simulate the correct light diffusion through different elements.
These three emitters demonstrate a few different values of directional sunlight shading.
On the left, the emitter is set to have shadows off.
In the middle, the strength is set to 60%, and on the far right, it's 100% strength.
Typically, we use this to lower the shading value on steam particles and kind of crank it for the smoke.
So because Infamous Second Son uses physically based rendering and HDR, this meant a drastic shift in the way we control the emissive properties and lighting of particle systems.
So anyone who's worked with HDR and physically based rendering has probably already figured out that it's difficult to work with relative to last gen as it relates to particle effects.
We found that rendering accurate exposure values for particle systems was not the way to go, and it's for a few main reasons.
Firstly, it's confusing in communicating the game design.
When, you know, powers feel...
dangerous in one time of day, but not another, that really detracts from the player's experience.
It also didn't entirely fit the art style of the game.
You know, it, basically it's a great starting point for environments, but it didn't really work for powers.
We wanted them to be much more stylized.
Thirdly, it's not what players expect.
Players kind of expect Hollywood realism from a game like, an action game like Second Son.
So when your powers impact enemies, it needs to be bright and over the top.
So this is an example of the Neon Bolt without exposure adjustments in different times of day.
So if you balance the particle HDR exposure values to the day settings on the right there, you know it's as bright as the surface of the sun at night in the middle.
It's actually so bright it's causing our dynamic eye adaptation to make the rest of the screen look black.
But if you balance the exposure values for night time, you basically can't see it at all during the day.
This is a pretty big design issue if you can't see your powers or when enemies shoot at you.
We chose to go with a simple exposure offset on the emitters. It just only affects the visual effects shaders, but it's tunable per time of day and it solves the problem for the most part for us.
It wasn't perfect, but it ended up getting the job done.
It meant going back through and tuning by hand when time of day has changed, but it was worth it to keep things mostly consistent.
For our next project, we're gonna look at ways to automate this and improve this process.
For our second son, we used quite a bit of real-time curl noise, and I thought it would be useful to kind of discuss some of the different ways we used it beyond just particle accelerations.
Our noise solution consists of a couple of different expressions.
One returns a float, and the other returns a vector.
Basically, these functions contain sort of an input position to evaluate against.
a frequency of waveform, so how tight the waveform is, and then a strength of waveform, and an iteration time that controls how frequently to iterate and change the waveform pattern.
So many real-time curl noise demos seen so far, they use undamped accelerations.
Like if you just kind of go out there and look at what a lot of people are doing, these particles are kind of gaining energy instead of slowing down due to air resistance.
During the production of Second Sun, I found that damping particles to slow them down and sort of lower an acceleration over time kind of led to a lot more believable results.
It's just something we tried to do.
I think that it's kind of all in context, right?
If we were doing a game that had a lot of actual magic power effects, undamped curl would totally be appropriate.
So there are a ton of uses for curl noise beyond particle velocities.
This example, I'm using a noise function on a couple spheres.
So the blue sphere has noise applied to its radius, and the yellow sphere has three-dimensional positional noise applied to it.
The shape results are actually quite different, as you can see.
I've used the same kernel noise function that's changing the shape to colorize these so it's a little easier to see what's going on.
This is the same noise pattern applied to a ring, and it kind of makes the differences between the two approaches a little bit more clear.
You can kind of see the yellow one is actually moving in three-dimensional space, while the blue is just only affecting the radius.
Another example is adjusting particle scale with curl noise functions.
The potential uses are pretty much limitless.
Anything that can be parameterized and turned into expression can be influenced by curl noise functions.
So if you guys are going to start using this, I urge you to just think of lots of different ways you can use it.
It's very, very flexible, particularly if you need to make amoeba.
So I'd like to wrap up by talking a bit about the pros and cons to our new tool set.
Let's start with the pros.
This is a big slide, so I'm just gonna go through them one at a time.
One of the major pros to our new workflow is the sheer power we have over particle sims.
The only real limit for us as effects artists is our understanding of math.
And I've had to learn a lot more math than I knew existed during this project, and it's something that my high school math teachers would find truly hilarious, considering I was a straight D student.
A benefit to having expression-based systems means that engineers just kind of intuitively understand it, right?
It means that they can make more contributions to the final assets.
And we're also speaking the same language now.
So that's been really beneficial just from a working relationship with engineers.
Using GPU particles, let us just use tens of times more particles than Infamous 2.
So a single smoke dash in Second Son is over half the particle budget for Infamous 2.
And you do it all the time in combat.
So this kind of gives you an idea of the number of particles, how many more responding in the second sun.
UDIN and GPU also let us create much more complex behaviors.
So this one is just a huge step upward for us.
Now, early iterations of the tool required compiles for all changes.
Even though its compile time was only five or six seconds, we found that any delay between making changes and seeing the results slowed dramatically.
Our engineers were able to actually come up with a system to make it real time, as you saw earlier.
I think they were surprised by the results and how much more they enjoyed editing particles.
I think a lot of it is it sort of just kills the joy of editing, right?
The reason that a lot of us got into art in the first place was the immediacy of it.
You put the pencil to paper and the line is drawn.
You don't wait.
So our sorting and lighting is hugely improved from Infamous 2.
So sorting was kind of inconsistent across the different techniques that we had.
We had a bunch of different shaders.
With Second Son, we have kind of one sort of uber-shader for all particles, which is, in effect, why our particle shading options were relatively limited, because we wanted to have that accuracy in sorting and lighting.
We also had no way to spawn lights at all in Infamous 2, through the particle system.
We had to actually use script and sort of Maya lights.
There's definitely some cons to our system, and here's a few of the big ones.
Particle systems can get extremely complex very quickly, which means that if you don't work on a file for a few weeks and come back to it, it can take some time to grok everything that's going on, kind of retrace every expression.
It's also difficult to work out another effect's artist submitters, especially if strict naming conventions aren't followed.
We set up a loose naming convention for minor names and texture names, but we managed to forget about variable names.
Oops.
You know, I think in the end it wasn't a huge deal for us because the visual effects team at Soccer Punch, we tend to work on specific areas of the game that don't overlap a ton.
You know, so one of us will work on enemies, another will work on missions and environments, another will work on the hero.
And, you know, I could see this being an issue if the team was larger, however, and we had a lot more cross work.
Without shader editing and custom shaders, it's just simply not possible to prototype different techniques.
We're limited to producing a shader using a third-party package and kind of showing it to engineers and having them implement it for us.
The turnaround is, any of you who've done this know, it's pretty slow, and you lose a lot of details in that conversion.
Using an expression-based system for creating effects isn't exactly artist-friendly.
With the way our tools are set up, it does take some time for effects artists to ramp up.
I think some may never hit their full potential due to the math constraints of our system.
I think it's just all around harder to sort of find people who are able to sort of work well within our systems.
So I suspect all effects artists going forward are gonna be running into issues with exposure in physically-based rendering engines.
I think it's just something, as effects artists, we're gonna have to adapt to.
So if anyone has any great suggestions in this area, I'd love to hear them, just email me.
Maybe someone already has a talk planned or kind of a paper they're writing about this, but I'd love to know more about it.
So when I started pre-production on Second Son, I really had no idea where we were gonna end up.
I didn't have any idea how we were going to hit the high visual bar the art direction team set for us.
And I didn't know how we were going to achieve the crazy designs the design team came up with.
Our designers are kind of zany.
So the biggest goal I had for the project was that I wanted to create something that I just hadn't seen before.
On a personal level, what this meant for me was that I need to focus less on how I'd solved problems in the past and focus more on never saying no.
It's one of my big things, just never say no, just say yeah, and then figure it out.
The idea was that I need to take on stuff that seemed impossible at the outset, because it would let me get further than if I shot something down early.
My motto was, if you know how to do it, that means people have already seen it.
And I think that's pretty valid for what we do as artists.
Another way I learned to tackle problems in a new way was to sort of start with the idea of first principles.
The idea behind this is that you assume nothing and you start proving out everything.
You want to make sure that you don't make any assumptions about your particle counts, how you can spawn lights, how you can spawn decals, because these assumptions artificially constrain your options.
They artificially constrain where you're going to end up.
The only thing you need to start by doing is asking, what do we need to communicate to the player right here, right now?
It's really the first step and one of the most important steps.
I think it's really hard to toss out all your old assumptions and start fresh.
I know I wasn't successful at it that much, well sometimes.
But it's totally worth it when it works.
Because when it does, you can do silly things like this.
Here I've made a particle system full of small fish models.
And these fish swim away from the hero using only simple expressions.
I showed this demo to one of our engineers, and he called them smarticles.
I think it's a good example of the kind of things you can accomplish with a flexible and powerful effects system.
It wasn't long ago people used AI systems to control this sort of behavior.
And lack of audio again, cool.
Oh.
That wasn't the one I wanted.
Sorry.
So any questions, just email me.
If you're interested in finding out more about the crazy people I mentioned at Sucker Punch, just visit our website or email one of our administrators, Sonya Jackson.
We're always looking for people to come hang out with us, come visit us, we love visitors.
Don't forget to see the partner talk to this one by Bill Rockenbeck at Friday at 10 a.m.
Bill's gonna go into greater detail, as I said, about the engine side of the particle system, so you'll wanna see that if you're interested in the technological side.
Thanks for coming, everyone, and I will have a little bit of time in the wrap-up room, which I believe is next door after this.
