My name is Corinne Scrivens.
I am a principal artist at PolyArc with eight years of experience in the games industry.
Previously, I worked at Arena on Guild Wars 2, and while at Bungie, I helped create memorable Destiny characters like Aeris Morn, Amanda Holliday, Hawthorne, and others.
In Moss, the player finds himself summoned to Helquil, a young mouse with dreams of greatness beyond the confines of a small and tranquil village.
Quill must embark on an epic journey, and she needs you there by her side.
Together you'll travel to forgotten realms, solve challenging puzzles, and battle menacing enemies.
Alone, no one can conquer what you're up against. But united, you may defeat even the darkest of villains.
Today, I will be going over how we created this story and how embracing constraints, whether it be from technology, team size, or schedule, actually helped lead us to finding even more creative solutions.
Today, I will be going over the processes that we used to make sure that these solutions fit within the constraints of our production while playing up the strengths of the medium of VR.
But first, some background on who we are.
Moss was the first game developed by Polyarc.
We're a small, independent studio dedicated to creating compelling characters and developing a world's.
For Moss, we had 15 employees, only 12 of which were full-time game developers.
And two full-time dogs.
Today, I will start with how understanding the medium led to designing our characters in a way that they could take full advantage of VR.
From there, I will cover how gameplay helped form our story and the approach that we used for building our world.
Lastly, I go over our process for finding how to deliver a story to players in a way that works well for both our medium and our production schedule.
But first, our medium and characters.
Like any game developer, you want to make good games that people want to play.
Creating for a new medium like VR, the first step is figuring out what even makes a good VR game.
This is why a postmortem about the story and narrative of Moss has to start with its medium.
And the reason why I'll be saying the word medium so much in my talk is because a lot of these principles could be applied to any cutting-edge medium, like AR, MR, et cetera.
To tackle these new challenges, we turn to these principles.
Deer.
The first part of deer is defining what is needed to achieve your goals, to find out how to create a good VR game.
This means taking the time to truly understand the medium, the current state of it, its strengths, and its weaknesses.
In early 2015, when we first started working on Moss, we took a look at the state of VR.
And one of our founders, Danny Bulla, observed that the state of VR was equivalent to the early 8-bit days of flat-screen game development.
Tracked head and hand headsets like the Oculus, Vive, and PlayStation VR, they hadn't even come out yet.
And most people never even put on a headset.
Everything in VR could be a new experience for players, like the 8-bit days of games.
We suspected that the newness of this experience would be engaging enough where we didn't need the complex gameplay systems used in modern-day games.
And I think you can see this nowadays in hits like Beat Saber or Tetris Effect.
Over time, this will probably change. I mean, compare Super Mario Brothers to Super Mario Odyssey, and you'll see that, yeah, the gameplay has become more complex over time.
But looking at the state of VR at that time, this was something that we thought we could use.
Because of this, our game's controls would mirror the simple controls used in 8-bit games.
This would enable our game to be accessible to as many people as possible, which was important in a new and slowly growing VR market.
We focused on first-time players because we suspected that whatever appealed to them would also appeal to any of the early adopters.
Next, we looked at existing games to find the strengths and weaknesses of this new medium.
In Portal Aperture Robot Repair, a drawer opens up, revealing a tiny Pocky universe of tiny office workers.
This showed us how enjoyable it is to look over a diorama in VR.
In Job Simulator, it highlighted how fun it was to reach out and physically interact with objects in the environment.
This research helped us define what we want to achieve in our game.
The first was creating our own tiny diorama world to interact with.
This identified the need for some kind of smaller character to interact with our player.
The second was forming the pillars of what would be important to our game.
The first pillar came from the games that showed us what did not work well in VR, and it showcased the challenges of this new medium.
Comfort. This was our number one concern because a person putting on a bulky headset for the first time is already in a position of discomfort.
To make this game accessible to as many people as possible, we had to make it as comfortable as possible.
Our research showed that couch scale games were the most accessible and that moving the player's camera was a bad idea because we would likely be making them sick.
Our number two pillar physical interactions.
Job simulators showed us that reaching out and interacting with objects pulled players into the world in a way that couldn't be replicated in non-VR.
And our third pillar, an extraordinary world that you want to be in.
The immersion of VR provides a unique opportunity to transport players, and we were really excited to take players to a place that they couldn't get to ordinarily.
By taking the time to truly understand the medium, we knew we wanted to make a couch scale game with simple controls and a tiny diorama world to look over.
Our focus would be on comfort, physical interactions, and an extraordinary world.
We revisited our friend, the deer, and next we embraced both our constraints and our strengths.
This ensured that our plans take full advantage of our team's strengths, while ensuring that we're planning to address any of the constraints that we might have to produce with it.
What were our constraints while we were creating Moss?
Well, a big one was no one knew who we were.
Polyarch was a little unknown indie studio that had yet to ship the title.
This meant we had a small budget to work with, which translated to a short development cycle of just 18 months.
And we couldn't afford to slip on our deadline.
A smaller budget also meant a smaller team.
Our team's background included three business and operations for character artists, three combatant and sandbox designers, three engineers, one sound designer, and one animator.
And if you're wondering how one animator did all the animations in our game, you can check out Rick Lico's 2018 GDC talk, Animating Quill, and his SIGGRAPH talk, Freeform Space Switching.
While small, combined our team has over a century of experience working on well-known titles.
This experience and the fact that most of our team is character focused were strengths that we knew we could use.
Looking at our research results, our short time frame, small team and our developer strengths, a third person puzzle action adventure game seemed like it might be a good fit for our first title.
Next was the second Ian Deer.
experimenting and exploring.
This is an important step, but even more so in an unexplored medium like VR.
Because we are a character-focused team, we decided to start with exploring our characters.
We knew we had a small character for a tiny diorama world, but who was this character?
Why were they so much smaller than the player?
The first idea was inspired by the third person perspective in traditional flat screen games.
What if the player was a giant and the character was actually normal sized?
We ended up not going with this idea because being a giant isn't a relatable experience for most people.
At that size, the world would feel strange and different.
Also, making a believable human character is hard, and it takes a lot of time.
A lot of time that we didn't have.
We decided our character had to be a smaller scale than the player.
How can we theme the visuals to explain this?
Toys could explain the size difference, and there's plenty of prior art for toys coming to life.
It's very relatable.
Nearly everyone has had toys or played with toys growing up.
However, concerns arose that because it was our first idea, that other VR developers could come up with the same solution.
Also important, not everyone on our team was excited to work on a game about toys.
The next idea was a little alien companion.
This also has plenty of prior art, and we could have more fun with the character designs.
However, there are concerns that it could be hard to get players to connect emotionally with an alien companion.
So we needed a theme that explained the size difference, was not an obvious solution, yet was relatable and easy to connect with.
What type of visuals could accomplish all of this?
The next idea, small animals in armor.
Cute animals are easy to evoke emotional connection with.
They are relatable, tapping into people's memories of having and caring for a pet.
And while yes, prior art does exist for this genre, Polyarch felt like it was a unique enough solution that it was unlikely another VR developer would come up with the same theme.
Also important, this was an idea that everyone in the studio was excited to work on.
Chris Alderson, the art director on Moss, did some concept experiments to see if this theme could hold up for multiple characters.
People wanted to go on adventures with the small, roguish mouse to the left.
So this became the starting point for our hero.
The next experiment was a gameplay prototype with this hero in a third-person puzzle action adventure game.
This gave us real production times that we could use to see if creating this game would fit our deadline.
Fun fact, it was this demo that convinced me to take a chance and leave my job at Bungie to join PolyArk.
I mean, where else would I get the chance to work on a game with a tiny, adorable, sword-wielding mouse in it?
To figure out if this was the type of game we wanted to create, we turned to the last letter of deer.
This ensures that we aren't making subjective decisions, but data and fact-based ones.
When working in a new medium like VR, playtesting is essential for challenging your preconceptions.
This can reveal unexpected paths for your development to explore.
Playtests showed the gameplay was a success, and they revealed something unexpected for our pillars.
People would talk to the little character, giving it encouragement if it missed a jump, even though it was the player themself that was either making or missing that jump.
They tried to high-five them after making it through challenges, and they spent way too long trying to pet them.
This revealed a fourth pillar and a new focus for our development.
Meaningful character relationships.
we knew that we had to make the hero a pillar of our game.
With our main character figured out, it was on to developing the player.
Our pillar of physical interaction meant that we wanted the player to reach out into a world to physically interact with it.
This took our game from a third-person perspective into a first-person perspective.
The player themself would be a character in the world and not just a camera.
To do this, we went through this process all over again.
We looked over a medium, which was a state of VR tech at the time.
Our third-person gameplay meant that we wanted a joystick, and the PlayStation Move controllers didn't have one.
But there is a joystick on the DualShock controller.
This gave the player two track points, one for the head and one between both hands.
Unlike the Move Controller, the DualShock Controller only has a small light bar on the front of the controller, and this could lose sight of the tracking camera, and thus temporarily lose positional tracking.
What this meant was, if we used a realistic in-game hand, it could give the disturbing feeling that your hand was detaching from your body.
So I started with this experiment.
This is a block model for a weird, stylized version of a hand.
The idea was your hand floating off into space might be less disturbing if it was themed as some strange energy undersea creature, as opposed to a physical part of your body.
And what we found was it worked.
It was less disturbing.
The downside was...
This hand felt weird.
The fingers would reach out and stretch towards objects to grab them.
This helped if we lost positional tracking, but we lost the physical feeling of reaching out into the world.
Having a non-physical hand felt good, but we needed something less alien-feeling.
So, I removed the fingers, and the next test was a simple orb.
A ribbon particle effect was added to make the hand feel like a toy that could be played with, adding personality to the orb.
Playtests showed that players thought of the orb as mischievous when it floated off, instead of feeling disturbed by it.
Instead of fingers, the hand used the idea of a stretchy hand toy to grab to objects.
The core of the orb would stay in place, and the outside of the orb would attach to the object.
The player then interacted with the object by pulling on it as if they were pulling on it with a string.
If you're interested in learning more about how we use this hand with our interactions in our game, you can check out Brendan Walker and Joss Dixma's 2018 VRDC talk, The Design of VR Interactions in MOS.
With the hands done, it was on to figuring out a face for our player character.
We did not have the time to create any type of convincing human face or any type of facial animations.
This made a mask a good solution for us.
While simple, it still does a great job of showing exactly where a player is looking.
With our limited schedule and only having two tracked points, creating a full body that felt good was also out of scope.
However, making a neck was feasible.
This helped turn the mask from a floating object into a full character.
By fading out the neck before it reached the shoulders, we didn't have to create a full body.
This led to the character being themed as some kind of non-physical energy character, instead of the typical physical character.
Giving the player a face lets us show them that they themselves are a character in the world.
When you meet our hero for the first time, players notice the reflection in the water beneath them.
Being a character in the world enables a stronger connection with the other characters, like Quill.
This adds to the immersion of VR, making this reflection moment a powerful experience that can't be experienced flat on a screen like this.
We used our understanding of the medium to design our characters in a way where they could take full advantage of the strengths of VR.
We combined this with embracing our strengths and constraints to help us figure out what type of game to create.
Now we know who our characters are.
But how do we make sense of a tiny mouse with a sword who is somehow partnered up with the mysterious masked energy figure with the orb for a hand?
How do we make a game out of these elements that feels well thought out and put together?
For us, next was developing the world and story that made sense of these characters.
We began with our hero.
We started with players expressing themselves by picking the gender that they wanted to play.
Problem was, this made the players feel like that they themselves were the hero, making any type of meaningful relationship between the two impossible.
Taking away this choice made the hero a separate character from our player, making our game not a third-person or a first-person game, but a new hybrid of the two.
Playtests showed that people either A, didn't care about the hero's gender, or B, they were really excited to see a female character.
And our team was excited about creating a strong female protagonist.
So we picked this gender for our hero.
And our hero had to be strong because gameplay showed it was more fun if the hero was capable.
She could attack to take out enemies.
and there are triggers in the world that only she could activate.
This established the player and hero relationship.
It was a partnership, and they would have to work together to succeed.
But how do we explain this partnership?
Why is this mouse being followed by a masked energy figure?
To figure this out, we look to our gameplay again.
The book was added to the gameplay prototype for the pillar of wanting to take players to a world they couldn't get to ordinarily.
By bookending this experience with the book, what happens is this book becomes the portal to a new world.
This book motif led to the idea of naming our player, the reader, and our hero, Quill, after the pen because it's through her actions that the story is written.
Next was explaining the connection between their two worlds.
The reader enters the world of Moss by reading a book within an old, mysterious library.
The book is the library's connection to Quill's world.
So what's Quill's connection to the reader's world?
The glass was created as a physical representation of this link.
She finds it while exploring the woods and is chosen by the reader.
Through the glass, you feel what Quill does.
You can see this from its brightness when Quill runs around, to the red pulse and sparks whenever Quill is injured, or from its soft glow to the pulse of Quill's heartbeat when reaching out to hold and heal her.
With this connection identified, Nex was finding the reason to adventure together, a hero's incentive that players could relate to and get invested in.
We experimented with a vague campfire story for the game.
Playtesting this, we found that everyone responded positively to the phrase, to save a loved one.
This pulled at people's heartstrings, and it made them want to help her succeed.
To find her loved one, we needed more characters in our world.
Argus was created to contrast Quill.
Where Quill is young and inexperienced, Argus is old and grizzled.
Argus is Quill's uncle and mentor, and the reason why she could use a sword.
He has seen plenty of battle and he wants to protect Quill from the dangers in the world.
This relationship, the connection between the two, is vital for providing our hero's incentive.
So when he disappears, it's believable that Quill would follow a mysterious ally to adventure.
And the journey lets us introduce enough interesting characters to showcase the variety and complexity contained within our world.
Now we needed something to save our uncle from.
Ideally, something that would let us avoid the trap of the larger Death Star, providing an organic and believable way of raising the stakes without reusing the same threat repeatedly.
This led to the idea of the arcane.
These enemies come in all different forms, each with different abilities, all powered by the same strange shadowy energy.
This lets us change the form of the threat to our hero.
To include beasts of monstrous size, like Sarfog, a giant snake who has destroyed the mice's old home and sent them running to the forest.
And who now has Quill's uncle, hopeless in its grasp?
With the heroes and scent to figure it out, we moved on to building our world.
To figure out how to approach world building, we looked to these stories.
The first Harry Potter book took JK Rowling five years to write because she was developing the world and she was planning out all seven books in the series at the same time.
Meanwhile, J.R.R. Tolkien took 10 years to write The Lord of the Rings, spending the time not only writing the book, but literal books worth of appendix material so he could understand his stories in the context of the world.
And George Lucas was known to have binders full of profiles about different planets in his universe.
These planets, they never showed up in the films, but they helped inform his story in the universe that they were within.
All this work developed worlds that fans wanted to spend more time in.
They felt like actual places, complete with history and rules.
Characters had factions with rivalries and friendships based off their past experiences with one another.
And any fantastical or magical elements of the world followed a set of rules that made it all feel more believable.
We, we did not have 10 years to build our world.
But these examples showed us the value of taking the time to create a world with depth and to plan for any possible future storylines.
So we invested our time.
And Chris Alderson created storyboards that covered this story as well as future storylines.
These were play-tested to help ensure that our story and characters would remain compelling throughout. And while none of us were professional writers, two of us wrote as a hobby.
Tam Armstrong and Shauna Perry.
They created documents developing the history in rules and moths, and short stories to see if our world and rules were generative enough to create within.
These were never going to go into game.
But they were a great source for quotes for last-minute marketing requests like cards, or for later in production when creativity might be running a little bit lower.
We won't directly reveal everything that we developed for the world of Moss.
But you see its influence reflected in its mystery.
The unanswered questions.
And the wonder.
Seen throughout it.
With the world and story built, the last thing was figuring out how to use virtual reality to deliver a story.
As with our gameplay, we created a prototype so we could track production times for schedule estimates.
This is still rough and unfinished, but being able to lean in and look around their small home and take in all the details was pretty immersive.
Watching the two interact was really charming.
And there's a lot of personality that could be shown in Quill's excitement to show her uncle the treasure she's found from exploring the local forest, or even like the subtle movements, like the way Argus adjusts his glasses.
And VR meant we could do fun things like make characters react or look at you.
This experiment showed us that watching a tiny stage play come alive in front of you really was as enchanting as we thought it would be.
And the scene is much more immersive in virtual reality than it ever could be experienced flat on a screen like this.
Creating this prototype cinematic taught us how creating sequences in VR differs from creating sequences in flat screen games.
The biggest difference?
The in-game camera is now literally the player's head.
A camera cut is teleporting the player around, and a panning shot is like sending him flying through space.
And you're probably making him sick in the process.
Because of this, directing shots becomes directing the player's attention, getting them to look where you want them to look, when you want them to look there.
Luckily, we found a few tricks to accomplish this.
The first of which comes from another medium that can't use camera cuts or pans, theater plays.
This scene uses stage lighting techniques.
The house itself is a stage with the player watching from the darkened area of the room, much like an audience watching a live play.
By lighting where we want the players to look, we can effectively direct their attention.
Movement. If you toss a ball towards someone, you can see for yourself how well this works to grab a player's attention.
Because movement draws attention to itself, it could also be used to direct a player's gaze around an environment.
In this prototype cinematic, Argus suddenly runs upstairs, his quick and unexpected movement grabbing attention and leading the player's eyes up the stairs and towards the library, and thus towards the book that he's grabbing.
Color is a familiar attention director for any artist.
Much in the same way a bright color can draw a viewer's eye to a section of an image, color can draw a player's eye to a section of an environment.
In the cinematic, the cool, unnaturally vibrant blue of the relic pops against the warm, fire-lit colors of the house.
This is why Quill's trademark bandana eventually becomes red instead of green.
Red contrasted a lot nicer with the green that was in a lot of our environments.
An earlier version of the prototype cinematic had the ambient sounds of a warm, crackling fire to help players feel how cozy and safe the home was.
Playtesting this, we felt the volume of the audio made players feel like the fireplace, it had to be important.
So they focused in on this area to the point where they would miss out on the entire expensive cinematic that we had playing out in front of them.
Audio, especially directional audio, is a really effective attention director.
If you'd like to hear more on this, our audio director, Stephen Hottie, has a GDC talk this year called Design Before Sound that is later on today.
The last is gaze detection.
Originally, the cinematic started when the level loaded.
But what we found was a lot of people actually missed it because they had their heads set up to listen to playtest instructions or they were turned around taking in the environment.
Basically, what we found was all the attention direction in the world won't help if your player's not looking at them.
This is why it's really important to be able to tell where your player is looking.
That way, you can start up your animations and sequences confident that they can see them.
If you take a look here, you can see all these attention directions in action in this introduction cinematic for Quill. Notice how the butterfly's bright orange color and its movement direct your attention over to the tree.
Once it lands, a glow and some directional audio draws your focus to the glass as it falls, bringing your eye line down to the same level as the bit of grass behind the tree.
The grass will make noise and shake until the gaze detection senses that you're looking at it, and if you aren't looking at it, you send the butterfly off to help draw your attention back to this area again. This makes sure that you don't miss when our hero, Quill, pops into frame.
Here, you'll notice some lovely character animation from Rick that really showcases her personality.
And we have a light shine on a key introduction moment, helping ensure that no one will miss it.
So, exploration done, right?
We had found the perfect delivery method for our story.
Well, the downside to this method?
Animations take a long time to create.
Our animator, Rick, has 18 years of experience, and he's optimized his workflow to the point where he can create 10 to 15 seconds worth of animation a day.
With figuring out the pipeline, it took six weeks to create this three minute prototype cinematic.
This time, it could be optimized, but Rick only had a three to four month window that he can spend on story animations.
Because of this, in-game cinematics were too expensive for anything other than key story moments.
The typical solution would be to cut all the story moments that we couldn't afford to create.
But while this isn't a major story moment, this scene is important because it serves two purposes.
The first is it introduces Argus and it shows a close relationship that he shares with Quill.
And this is vital, because our hero's incentive is to save a loved one.
The other thing the scene does is it introduces the glass, and with Argus's reaction to it, it shows the glass's role within the world.
This adds depth to our world.
Argus reacts because of his past with the glass relic.
This shows the central role that the glass has played in the events leading up to the game of Moss.
So we have scenes that contribute to our story's narrative goals, but we cannot afford to create the in-game cinematics associated with them.
How can we deliver our story in a way where it won't cheapen the player's experience, but it's cheaper to create?
To solve this, we look to our gameplay prototype.
Very early ideas for the game had the player spending their whole time in the library, reaching through the book to interact with the world the moss. As polyar playtest in prototype, the gameplay pivoted away from this idea. But the book itself remained.
The art style for the book was inspired by other media that used a book as his introduction and end.
Disney's Sleeping Beauty.
The film starts with video of a real book opening up.
And the backstory of the world is told through its text and images.
Until a zoom into the book illustration takes the viewer into the world of the animated film.
This fit perfectly with what we were trying to do.
And the art style worked great with our small animals and armor theme.
Playtesters found that the book format was really appealing and charming because it made them feel like they were entering a fairy tale.
This book seemed like a great way to bring more story moments into our game.
But what about our pillars?
Specifically, the one about an extraordinary world.
How do we take something as ordinary as reading a book and make it feel like something special?
Our first thought was, well, what if the images in the book moved?
Our animator, Rick, experimented with 2D animations.
He loves Frank and Ollie's style, so he went for the loose, sketchy feel of Disney's Jungle Book.
With this, we could use drawings for both the story and save animations for the important moments.
To create this, Rick started by animating the scene in 3D.
He then sketched over printouts at 15 FPS and scanned them into Photoshop for a quick color pass.
The entire process took three days for this two-second clip.
We probably could have made this more efficient, but it still showed that this method could be a risk.
And also, I had concerns that the style and feel of this didn't quite match the rest of our game.
For the next exploration, I created a simple looping flipbook animation in the book's material.
With ambient animations like this, even a non-animator like myself could help add some magic to the pages.
This test, as simple as it was, helped confirm that it was cool to see images moving on the page.
And this simple technique worked great to bring pages to life in the game.
Except if we wanted to build an emotional connection with players, we probably wanted some way of animating our characters.
Could we do this without requiring too much work from our one animator?
Around this time, I watched some tutorials on scene captures.
A scene capture is a camera that records a scene onto a texture, which is then used in a material.
Normally, this is used for things like mirror reflections.
But this got me thinking.
Could this be the solution that we're looking for?
This led to my next experiment.
On the lower left hand corner of the left page, you can see my test in the idle movement of the mouse soldier.
I was going for a moving concept art look that could be animated without animation support.
By cutting out the existing image and separating them out onto different planes of geometry, we could animate a character like this one, like you would a shadow puppet.
And the art style of this matched the visuals of the rest of our game.
However, its movement did not.
Animation worried that this method couldn't support the fidelity needed for a performance that players could feel emotionally connected to.
So I had to figure out a way to deliver our story with the high animation quality bar set everywhere else in the game.
But I had to do this without overburdening animation.
Like, how could I do this?
With the realization that if the scene capture could record a model like this one, I could use it to record our in-game models as well.
This meant I could reuse any existing animation for the book and save custom animations for key moments.
Even for pages without animations, it helped because I could use these poses as a starting point for the illustrations.
Not only that, but we could use screenshots of our in-game levels, like this one here, as a starting point for the book's illustrations.
By painting over these, we could help ensure that the locations in the book would match up with their in-game locations.
This also made it quick and easy to try out different camera angles or shots to see what would best sell a story moment.
Scene captures, they're expensive.
So we optimized the models used in our book.
This is actually an unlit model.
Developer Chad Taylor created a material that fakes lighting.
In addition to being super cheap, it helps add a painterly look to our characters.
This helps integrate them into the painted backgrounds of the book.
And if you're wondering to yourself, wait, wait a moment.
Does that mean when I'm in the library reading the book, that somewhere out in space, there's a whole bunch of models animating and being recorded by some camera?
The answer is yes.
Yes, it does.
You will actually get a slight performance hit from this if you turn all the way around from the book and face the wall behind you.
But so far, nobody has noticed or complained.
So I think we got away with this one.
With our visuals figured out, the next challenge was how to deliver the written parts of our story.
Our gameplay prototype had the words incorporated into the images themselves.
This works.
But our goal of accessibility meant we wanted to support as many languages as possible.
And incorporating the text for all these different languages would have been a nightmare for art and a lot to maintain.
We could have just used subtitles, but the thought was a narrator could add a lot to our childhood fairy tale vibes.
Luckily, our audio director, Stephen Hoddy, had worked with a talented voice actor on Destiny of the Taken King, and he knew that Morla had the range to pull off this role.
And personally, I was kind of excited to work with the voice actor of a character I created again.
So that was cool.
Out past the bell again, he scolded.
Quill, I've told you countless times.
I know.
Quill replied, crestfallen, I didn't mean to worry you.
A narrator, meant one voice actor, played the role of all six of our characters.
One voice doing multiple voices as charmed players by reminding him of fond, nostalgic memories of being read bedtime stories as a child.
In fact, Marla prepared for the role by reading our story to her son as an actual bedtime story.
With the narration for the book figured out, we moved on to play testing.
We discovered players would be so overwhelmed with the experience of being transported to the library that they wanted to look around and take the time to adjust to their new environment.
They wouldn't notice that there was a book in front of them to interact with, or that a narrator had started reading them the story.
Basically, we found that even when using a simple book format.
Effectively directing the player's attention is important to make sure that they can see what you're trying to show them.
The first thing we did was add an interactive glow that lit up whenever the hand was near.
Subtle directional audio was added to this glow.
This made the book feel magical and encouraged players to try interacting with it.
Next, we added a gaze target so we could tell when players looked at the book.
This let the player take all the time they wanted to look around the environment or get settled in.
The story would only start when they looked at the page so they wouldn't miss it.
The glow on the cover was added to the pages.
The page borders glowed to let players know which page the narrator was referring to and then pulsed when she was done talking.
This worked great with simple test pages.
Yet, as we added more images and animations to the book, playtest showed that players started to be distracted by the visuals.
They stopped noticing when the trim glowed.
People began turning the pages to early and could no longer figure out which page the narrator was referring to.
What we found was the more complexity there is, the more attention direction that is needed.
We fixed this by darkening and desaturing the images that the narrator was not talking about.
The color and vibrancy of the active page made it clear which page the narrator was referring to.
Next was controlling when animations played in the book.
By making sure any ambient or character animations only played when that page was active, we knew movement could no longer distract the player's focus.
With this additional attention direction, playtest went smoothly and players knew when to turn the page and which page the narrator was referring to.
We were free to experiment with other ways we can make the book experience feel even more enchanting.
Like adding a subtle ink effect to the fade in of the images so it felt like the book was being written as you're reading it.
And VR meant we could do fun things, like having book characters point at you and follow you around as you move.
Or let players see themselves reflected in his pages, drawing them even further into our story.
With virtual reality, we could do things with the book that couldn't be done in real life.
However, that doesn't mean that the book was a perfect solution.
We learned too late that we needed gameplay systems in place so Quill would react in a way that made sense with what just had happened in the book.
In this let's play by Salsa Ketchup, the player has just gone through a very emotional chapter with Quill.
Her first chance to take out Saurthog ends with her ally sacrificing himself to save her.
All she could do is run for her life.
She has failed, and her friend is gone.
Alone and hopeless, Quill wants to give up, until a gentle touch on her shoulder reminds her that you, the reader, still believe in her.
After a heartfelt plea from Quill, you can see the player wipe tears from his eyes.
He goes to pet his dear companion to comfort her.
and basically ends up getting waved away.
Attempt to wave to her also disappoints.
All the gameplay systems knew was that there's an enemy in the next room, so she's actually in combat mode here.
This could have been a great immersive bonding experience, and to be honest, watching this lost potential was a little hard for us.
However, the biggest downside to the book was how much less impactful moments like this felt like.
My friend, I need your help.
If we don't face our fault now, my uncle will die.
Moments like this felt much more amazing outside the book.
With no layer of removal, you're right in the middle of it.
The story happens epically right in front of you.
Yet, with all this said, we're able to deliver a game that we could be proud of.
One that accomplished our narrative goals within the constraints of our production, and all without killing one animator.
By exploring options, we're able to spread out the workflow and find creative solutions for these challenges.
To summarize, we did not start with the story when trying to figure out a game's narrative.
We started with understanding the medium that we were developing for and using that understanding to design characters that take full advantage of the strengths of our medium.
We then use these characters and gameplay to help craft our world and story, making sure to take the time to create a world with depth and plan for any possible future storylines.
Then finally experimenting with creative ways to tell our story, the ones that fit our production constraints while adding to the appeal of our game and taking full advantage of the unique possibilities of our medium.
We did all this with the help of Deere.
Deere ensured that we started with the question of how to even make a good VR game.
From there, we moved on to making sure that we're taking our team's strengths and our production's constraints into consideration.
We experimented and explored and made sure to review with playtesting, which made sure our decisions were fact-based instead of subjective, and which ensured that we weren't following any assumptions that could lead us astray.
These basic principles can be applied to any medium.
And we are lucky enough to live in a time where with AR, MR, and VR, there are multiple cutting-edge mediums full of unexplored potential, still at their early 8-bit days.
I mean, we had no idea that our game could have this effect on people.
I have been in the games industry for over eight years, and this is the first game I've worked on that has caused people, multiple people, to burst into tears of joy.
I have seen the toughest looking men break into a smile full of childlike wonder and joy the first time they meet Quill.
And we've gotten a lot of heartfelt messages from fans.
There is just so much.
And people feel so connected to our little hero.
None of us knew what type of game we were making when we first started production.
If we had followed the assumptions of flat screen games, there is no way that anyone would have thought making a game where you play a supportive character to a tiny swordswoman mouse was a good idea.
And this is why I am so excited to be here at GDC, surrounded by so many talented developers.
With all of these new mediums, who knows what's possible?
I hope you take some of what you learn here to do your own experiments, free from any preconceptions or assumptions, to see what exciting things that you can discover.
I can't wait to see what engaging stories you all come up with.
This has been my postmortem on the storytelling of Moss.
Thank you all so much for listening.
I'd like to take a quick moment, a big thank you to the entire team of PolyArch and my advisor Amy Hanig.
This was my first ever talk at a conference, so I'm very grateful to have had everybody's help and advice.
And a small plug for our other GDC talks this year, audio director Stephen Hottie will be going over the sound design of Moss later on today, and our composer Jason Graves had a talk going over the music of Moss yesterday.
And we have six minutes, so I could take any questions if anyone has any.
Congratulations on your first talk.
That was great.
Thanks.
You talked a lot about how you discovered these things through playtest.
Did you, how formal and structured were your playtests?
You have informal playtests.
Formal ones, how did you collect the data?
I'd be interested to hear about that.
Oh, that's a great question.
The question was about our play tests, the structure of them, and how formal they were.
Basically, a small team of 15, right?
So, we did a lot of internal playtesting, where near the end, like, there were departments that had less work near the end, so they spent their entire time obsessively playing the game and seeing who could get, like, the fastest times.
And then other than that, we also invited people in to playtest the game.
And because we're so small, we just did friends and family.
We just made an effort to make sure that we're constantly doing it during production.
But other than that, it wasn't more structured than that.
Thanks, great question.
Hi, thanks for your talk. Excellent game.
I just wanted to ask about if you could talk about your decision to split the initial meeting of Sarlog with the confrontation later on and having that chapter in the middle.
I was a little surprised to kind of see that violation of the show don't tell.
So interesting.
Okay.
The question was why we decided to show Sarfag earlier before the big confrontation.
And I can say that the writing team, like no professional writers, right?
So what we did was we actually did a whole bunch of research into how to write a good story.
And we also looked a lot at common story structures and the structures of how to make an engaging story.
And one of those is looking at the classic hero's journey.
And so basically, the reason why we decided to do that was our research into story structure showed us that that would go really well, that the hero had to meet a low point.
before that it she takes on her greatest challenge and overcomes it so that was why the decision was and it just kind of Raises the stakes and makes our fog even more intimidating. So okay, I was just wondering you know, why the Player didn't have the character escaping which I was kind of thankful for that gets really intense at the end of that chapter So thank you for your answer Yeah, I think I echo a lot of the audience.
This is a great talk and I think you knocked it out of the park.
So my question is on reflecting on this.
I think a lot of this is postmortem reflection, right?
But was there a few assumptions that were super challenged and some people really wanted this to happen that just really completely fell apart once you play tested?
Okay, so the question is what assumptions did people feel really strongly about that fell apart during playtesting?
I do know, well, this is slightly different than what you're asking, but I do know we weren't expecting people to feel so connected to the hero, so that wasn't an assumption, but it was something that kind of caught us by surprise, yeah, from playtesting. And then a lot of it was...
I mentioned it briefly, but the original idea for the game was you open a book and you interact through a world, through the book, and then you're in the library the whole time.
So we actually went through a whole bunch of different ideas and we just kept pivoting based off of feedback from playtests.
And the great thing about playtests is it...
if there are disagreements in the studio at all, it makes it really easy to deal with them, because then the decision isn't subjective.
It's not like, I feel this is the right thing, so we're doing this.
It's, hey, the data and facts show that this isn't as important as we thought it was.
We should move on to the next thing.
So that's, yeah.
Maybe as a follow-up to that, just real quick, how could you fit a lot of that loop going through assumption, build, prototype, playtest?
That seems like a long loop to fit in an 18-month cycle.
So did you have something unique?
Or how did you tackle going through those iterative cycles with such a tight schedule?
Basically, with the prototyping and playtesting, just making really rough versions of the game and testing it out.
And we had, I think, yeah, that's basically how it is.
We started really simple.
And even from when it was just a vague story, like even when it was just words, we were testing that out and play testing with people.
So very early on, every stage we were.
And it does take a while, but I think the game is stronger for it.
Cool.
Thank you.
Thank you.
I really loved the talk and I loved the animations in MOS and I was surprised to learn there was only one animator.
My question is, did you guys consider using mocap data and cleaning up mocap data to make cheaper animations as opposed to like hand keyframe animations?
So the question is if we considered using mocap to help with our one animator.
And so...
The answer is like, we had a very small budget.
Well, there's like a lot of mocap, I was referring to like mocap libraries and...
Oh, mocap libraries and stuff.
Doing your own mocap.
So we actually have looked into that before, and the thing is, the interesting thing is, because cool is a mouse, right?
And what we found is if you put...
mocap date on her, she instantly looks like someone in a mouse costume instead of actually a mouse.
So yeah, and it was just so important to the game that people be able to relate to her and stuff, and that's why we want the keyframe now.
Oh, I guess until they invent mouse mocap, we'll have to do it hand-painted.
Yeah, yeah.
Thanks.
Cool.
Sweet.
So.
Thank you.
Well, that's all the time, but I'll be hanging out in the hallway if you wanna talk or anything, so.
Thank you.
Thank you.
