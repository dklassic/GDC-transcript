Welcome to the Rick and Morty virtual reality VR lessons learned with Alchemy Labs. Don't applaud yet. It's just downhill from there. My name is Alex Schwartz and I'm the CEO of Alchemy Labs. I'm Devin Reimer. I'm the chief technology owl at Alchemy Labs.
So we are makers of Job Simulator. It came out on the HTC Vive, Oculus Touch and PlayStation VR. Most recently we launched Rick and Morty virtual reality which we'll be talking about today.
So I want to talk about the origin story of how this project came to be, how we ended up kind of working on this IP. And first as a disclaimer, there's going to be a lot of swearing. There's going to be spoilers for the game because we're going to talk all the way through development from beginning to end. And the show itself, you know, has a mature rating and therefore the game has a mature rating. Therefore the talk has a mature rating.
So this should be fairly straightforward.
So we were mid‑development on Job Simulator when we noticed that the co‑creator of Rick and Morty, Justin Roiland, was tweeting madly about how much he loved Job Simulator and was freaking out. So as huge fans of the show, we clearly had to contact him and say, hey, we should get together and show you what we're working on with the new levels. We ended up kind of DMing back and forth and figuring out a time to meet up in person.
Now, we had this plan to pitch Justin on the concept that what if the interaction methods and the game itself of Job Simulator were existing in a totally different world in Rick's garage in Rick and Morty.
And our plan was to go there and kind of lightly pitch it.
And it turned out when we got there, he also had a similar idea.
And so we were showing him some of the Job Simulator levels and here was 10, 15 seconds of him reacting to seeing new Job Simulator content.
you guys shut up oh it's like fucking flappy bird like the same kind of shit in rick's garage just like you guys said are you fucking kidding me so clearly he enjoyed it and in a short amount of time we were actually headed down to William Street to go pitch the heads of adult swim on the concept that we had talked about and after that pitch it was a big thumbs up, game on, let's make this thing. So let's fast forward to the end of the project.
This is the 30 second TV trailer that we made to kind of show you kind of what the end up game looked like.
What is this, Rick? It looks like some sort of crazy video game about us or something.
It's not just a video game, Morty. It's a virtual reality game.
I sold our likenesses to some video game publisher for a lot of money, Morty.
I mean, who's gonna play this?
You're gonna play this, Morty.
What?
Oh my god! Y-y-you killed it! I mean me!
I mean- VR for everyone!
Everyone with a box on their face, Morty!
It's raining money here in VR land!
It's raining money!
Ha ha! Wubba lubba dub dub!
So in working on Job Simulator, we ended up building this underlying tech that we called Alchemy VR. This governed all of our interaction systems with the world itself. So we ended up having this baseline to start work on top of, which was great. But we knew we needed a ton of new features and needed to do some serious refractors to completely separate Job Simulator from the underlying tech.
We knew, as Alex mentioned, that Rick's Garage was kind of the key tenant to this. In Job Simulator, we ended up building these environments so that they were built around the gameplay themselves. So if you play Job Simulator, you know that in the convenience store, the convenience store area is built around that one play space.
We knew in Rick's garage that it was bigger and there was no way for us to scale the entire garage down to the size of your own room in your house because otherwise it would be Rick's garage would end up being a phone booth. So we knew we needed some method of locomotion because we couldn't change the garage so much because essentially it was very iconic to the IP.
People that have watched our talks before know that we are not fans of artificial locomotion. It is very important to us to not make people sick. We want to make people feel comfortable and we want people to come into the content knowing that it's going to work for them.
There is many different methods of solving the problem, getting from one location to another in VR.
In our opinion, some existing teleportation methods aren't that great, at least for the content that we're building.
The method of pointing at a specific location and going to that spot is something that we refer to as granular teleportation.
You pick an exact spot and then you end up going there.
This can lead to many issues.
One thing that we've noticed is that people stop physically moving around in their own play space. They end up standing in the middle of the room, their feet planted and just pop around. This ends up having some huge issues because we've discovered that this ends up leading to more fatigue. People that actually move around a little bit in their space end up playing much longer because your legs just aren't designed to be locked in one position for a long period of time.
also it ends up sometimes causing the problem where you have an item that you can see but you might not be able to get to it because you're real world physical bounds. This causes this process to have to run in the back of your mind all the time of, oh, am I going to run into trouble with my real world space? And this is something that we don't like. We want people to get into VR and kind of forget about the world around them outside of VR.
So the method that we came up with for Rick and Morty was something we called zone-based teleportation.
So we ended up dividing the garage into these multiple zones that end up fitting your play space.
So what you end up doing is you look in the direction that you want to go, and you hit the button to teleport, and then you go to that space.
That's as simple as it is, but it's not that simple to end up implementing.
Yeah, so when it came to with Job Simulator, we really wanted to make sure that our content worked on every platform and every room size that you could possibly have. So a really big living room, a really small room. And so we ended up building this method to build customize handmade different versions of the layouts of each of the rooms.
And now with this new zone-based teleportation system, you end up having to redesign each teleportation zone to be fitting within your own customized room scale size.
And so we ended up building, hand building three custom 360 degree track sizes, and then two custom 180 degree track sizes.
which you can see here in our editor we're flipping through and it's not just changes to positions of items or scales because you can't really get away with scaling things down like that.
It's hand-authored new desks and new replacements for washers and all these different kinds of swap-outs to make it really feel right.
And so when you take a top down view of the room, it's really important to note, so anyone who's really, really hardcore about the show, when they look at this, they might notice something slightly off, which is that the shelf is actually located down on the bottom part of the room. And so everything else is essentially the same. But when we ended up going and looking at the design of the room and wanted to start to accommodate 180 degree tracking spaces, we realized that the shelf was the only interaction point where you had to face completely backward.
So if you take a look at what each zone based location, if you look at the three arrows, those are kind of the, in a 180 degree tracking setup, the way that you can face forward and still have interaction with your hands without being occluded.
And so moving that single shelf allowed us to have a space where you can face to your right, down in the bottom right, to do laundry.
And you can face forward and left and right at the desks, and you never have to do hand-based interactions behind you.
Now, that's actually because of the IP and the way that it's been built, we were able to take some creative liberties. So we actually put scratches on the ground where the shelf is located now and where it used to be, kind of like a faded area where it used to exist. I think that's what's great about this IP, it's almost anti‑canon and you can make those types of jokes. In fact, right when you start the game, most people probably don't notice it, but Rick delivers a line, he's like, Morty, I rearranged the whole garage to make this happen. So we just kind of joke our way out of that and move on.
So zone based teleportation, we're a fan because essentially it takes the mental overload off the player itself.
But from a game design standpoint, it can become very challenging.
So here is that top down layout.
We have these zones that we don't want people to stand in.
So when you end up teleporting to another zone, you're at the mercy of the exact location that you were in your room scale space when you end up doing the teleport.
So on the top left quadrant here, we have the, the shelving unit which we don't want people to stand within. In the top right quadrant we have this desk that kind of wraps around you and then on the bottom right we end up having this washer and dryer. So how do we end up handling this? The way that we do this is we take every zone that you can teleport into from another zone and we do an overlay method.
and so here's the actual overlay of the worst case scenario of zones that we don't want you to stand within because if you were standing within that zone and you teleported into another zone you could be inside of another piece of geometry. And so why we have no method of actually forcing someone to stand in a particular location, from a game design perspective we can go and lay things out in different ways so that people don't generally stand in those zones.
And then the zones that we do take up, we try to make them as narrow as possible.
So if you are slightly inside of a piece of geometry, generally what people do is kind of move their head back a little bit and it won't feel like they're inside that piece of geometry.
So one huge thing that we clearly had to tackle was the concept of portals.
So in Rick and Morty, in the show, it's an iconic part of the entire IP.
So it would be so awesome to be able to step through a portal in VR.
And so it also enabled us to have some way to get out of the garage as the base area.
But all the technical and design challenges that were presented, I want to talk through how we approach those.
So first we actually got this massive IP Bible from the Adult Swim team that said all the rules of how portals work and they said, okay, a portal can only be shot on a flat surface and when you emerge from the portal, you can have it kind of appear in open space. But when it gets shot first, where you go in has to be against a hard surface and flat. So the challenge is how do we even get a flat, large surface inside of your play space on demand? You would think, okay, use a wall, but.
the walls are by definition going to be at the edge of your play space. So imagine jumping through a portal and jumping directly into a wall. So what we ended up doing is this video ends up showing it in the best way possible, is that clone Morty right here is going to walk through this portal from the garage and notice that the area that he is in is taking up about 66 percent or two-thirds of the available space.
Once he goes through the portal into the bathroom, he's in that one‑third left and so has enough space to get in without hitting a wall. And then when the portal actually goes down into the ground and comes up in a new position so that you could then turn around and go back through. So it avoids all these issues like, number one, if you go through a portal and then move back a millimeter, you might accidentally re‑portal backward. So this helps solve that because you closed the portal behind you. The second is a little magical little thing here. I don't know if my mouse will show on the screen. It does.
there's a lever that you pull to open the portal wall. And that's very specifically placed because you have to grab that portal, sorry, that handle and that means that you're standing in exactly that spot at the time that you do it. Thus ensuring that you're in the right spot so that when the portal comes up you have enough room to go into it because you wouldn't want to teleport over and then be behind the portal wall or something crazy.
So now that we've figured out kind of from a game play standpoint how this is all going to work, the next challenge was how to do this visually. So one of the first things we ended up doing was starting working with render textures to try to figure out how to render a portal out correctly. In VR this is really challenging because essentially you can get really close to things and in the case of a portal you're actually walking through it. And we don't want any popping, we want essentially a seamless transition. The problem with using things like render textures is that you're set to a certain resolution.
So as you get closer to the quality goes down, so we needed to come up with a different method.
Our end result was a very complicated system that is unable to describe in slides alone.
But essentially we ended up using a method of multiple cameras and depth masks to essentially layer the world. So we ended up doing things like stepping through the remote world sky box and the remote world then your local sky box, then your local world and then have to do a ton of other things like handling items that you've grabbed that are close to the portal and making sure that they're rendering at the highest quality in the exact correct position.
So as I mentioned, being in VR makes portals extra challenging. Because essentially unlike traditional portal games where you can just walk through the portal and that's the interaction mechanism, you can actually reach out and grab things through a portal and pull them back into your world.
This ends up leading to a lot of really, really challenging things because essentially the garage in this example in the space are located in two physical different spaces within unity. So how do you end up handling the fact that your hand goes through a portal that is in different part of the world grabbing and interacting with an item?
This was a ton of work but the end result ended up being that we ended up having to essentially bring objects between both worlds and then essentially get the physics force to apply correctly when you toss across. So here, for example, you go and throw something from a zero gravity world into a world with gravity and having it drop correctly. The end result was really awesome and we see this all the time. People play like open a portal to the bathroom and they won't even step all the way into the bathroom. They'll just reach through the portal in the bathroom, grab something off the sink, and then continue on playing.
Now that we ended up having this all working, the next thing was perf. Perf in VR is really hard to begin with and now what we've ended up doing is doubling our renders. So this ended up being a very time consuming thing to resolve. So we ended up having to do a whole bunch of magic tricks here. So essentially when you end up standing in front of the portal, and you start looking through it, we do things like caching local shadows, turning off certain light sources in your local space when we know that the portal is taking up a certain amount of your field of view. So as you can see here, as you turn towards the portal, the portal is generally the very iconic spinning thing and as you turn towards it, the world fades in. So this has two fundamental reasons why we do that. The first one is if you're walking through a surface that's completely opaque, that feels really bad. If you can actually see where you're going, that helps with that. But also from a rendering standpoint.
By us turning those on and off, when we turn one off we can turn some other things off in the other world and vice versa because we know it's taking up your field of view.
Another challenge from a VR specific thing was that now that you end up stepping through portals to go to all these fantastic places, there's no loading area, there's no fade to black that now we can kind of mask some of this loading.
And so we started doing a whole bunch of looking into how to handle this.
In the end we determined that asynchronous loading was just not reliable enough to keep frame rate at a particular quality bar. So we ended up doing was actually loading the entire game when you end up starting it. This was a huge challenge to keep performance of the loads in a good spot. But the end result was that you end up as soon as you load the game you can just play the whole game with never stopping.
Then it comes to mirrors. So because we're gluttons for punishment, there was a mirror that we really wanted in the bathroom because looking at yourself is really, really cool in VR. But now we have a situation where you have a portal in the bathroom and a mirror. So you have the portal doing the double rendering plus you have a mirror doing a render of that world. We spent a lot of time with this and a lot of creative placement and tech. What we end up doing is as you end up looking ‑‑ between the worlds and twisting your head from the portal towards the mirror, the mirror will start showing and as you twist your head towards the mirror to the portal, the portal shows. I ended up putting a whole bunch of tech to make sure that everything lines up but I'm pretty confident that most people who played the game didn't even realize that was actually what was taking place.
So a couple game design challenges to talk through.
One is the concept, the touchy concept of having the player die in VR.
And so death in a VR game is a little strange.
So the thing is we wanted to have this happen as part of the mechanic.
The player could die at any point in the game, but they could also be in any physical position or location at the point of death.
And so when they go, it's like a teleport, essentially.
How do we deal with all of that?
And we also don't want to.
have anything feel punishing for the player. In fact, it's very comic violence ways that the person can, the player can die. We also don't want to take away control from the player. A lot of games we've seen, they try to do something where I'm no longer in control of my own body or I'm disassociated in some way. We didn't like the feeling of being disassociated.
So I'm going to give you a quick example here. This is just someone innocently throwing a glass bottle into this death pit.
and then a piece of broken glass just went and hit them in the face and killed them.
And so notice that they got brought into this new world, Purgatory.
So what happened here from the design standpoint is we did an instant cut to a completely different visual location. So it's dark, it's a different color from every part of the game. And so being in a completely different and empty world makes it a little less jarring than having to figure out what just happened.
what just happened. And we actually teach it in the very first few minutes of the game that the player gets shot by Rick, spoilers, and then you have to go back to that death world and you learn that you understand it. So, but in that world we wanted to have some interaction and some way to get back.
and we're thinking, okay, if we put like a desk here, then you might be standing inside of it.
It's very strange.
So we ended up with this design of a very small death phone on a small pedestal.
And so it's small enough that even if you kind of are standing right on it, you look down and you feel like you're standing in front of it and you're able to pick up the phone.
You get the devil's secretary who tells you that you shouldn't be here and you need to come back to life.
And you have the ability to have your own agency as to when you want to come back rather than be on a scripted timer.
So the next decision we had to make was who you were from a player standpoint.
In Job Simulator, you're a human, so essentially you end up playing yourself.
In Rick and Morty, we got thinking about, are you Rick, are you Morty?
We really wanted Rick and Morty to interact with one another, so we needed to determine who you were as a character.
Well we ended up settling on was this concept of a clone Morty. So Morty's very iconic so we're kind of just like leaning on that. But it ended up fixing some problems and some challenges in VR. So first off you're a silent protagonist. So this worked with that. The limitations of VR ended up turning into some of the jokes. So we ended up making a lot of comments about you just being a clone Morty that's just a floating head and hands.
That ends up feeling really good.
And then on top of that, because you're a clone Morty, you being dumber than Morty is totally cool, and now Morty can kind of make fun of you.
So kind of that teaming up against you thing ended up working really well from a narrative standpoint.
So we have our player who is a clone Morty and now we've decided, okay, you need Rick and you need Morty to exist in physical space, fully rigged and animated at full size right in front of you in VR.
And so this was a pretty big challenge, in fact, one of the biggest challenges of trying to do the development of this game.
So first off, there was no 3D reference for these characters because it's a 2D cartoon and no one had really brought these characters into 3D yet, so that was kind of on us.
We got some reference from the character sheets, turnarounds and things like that.
So we had to kind of go from there.
You can see some pictures of some of the blend shapes of all the crazy faces.
Notice there's like a burp visual right around bottom left where the mouth gets wider than the actual head as far as the geometry.
So going from a 2D cartoon where that's fine to 3D poses some interesting challenges.
Some of the rigs you can see here with the controls in Maya.
And so you've got these characters that are fully rigged and animating in front of you, obviously trying to make it feel natural that you're standing with them and not creepy is part of it.
So feeling present, if they don't look at you, it actually feels weirder than if they do.
And so getting a character's head to automatically look at the position of the player means that they actually pay attention a little more, depending on your height and all that, we do that automatically.
And then we also learned that dynamic pointing at objects when describing, hey, pull that lever, is so much more, almost 100% of people will find that item and go right to it, versus the concept of, pull the green thing on the blue shelf, and people just spin around wondering what's going on.
Plus the added benefit of spatial audio, when they go, hey Morty, turn around, and you're looking at him and then he points, and it all kind of comes together.
So that's what happens in real life.
And so we got to the point where we had these characters sitting there and then the funny thing that happened when we were play testing is that everyone wanted to instantly push the boundaries of this simulation. And so everyone tried to slap Morty or Rick or push on them or throw things at their face.
and nothing happened and it was really disappointing for everyone so we knew that we had to implement something.
So we implemented Puppet Master and it's, you can see here it functioning properly.
But it had a ton of perf overhead because it's essentially doing like a rag doll on demand and trying to estimate to a pose and get back to its pose.
So even if it's in the middle of jumping or animating or whatever, if you hit it, then it can like kind of blend out and back to it.
It's just a, it's a big system.
but, and it introduced a ton of weird physics bugs and things that broke in the game.
We ended up putting this in late stage and having to fix a lot of things.
But we feel like that didn't work out as well as we wanted because we really needed to go deeper down the rabbit hole is that we didn't have great responses from the characters.
When you did hit them, you would want dynamic VO and reactions to exactly what you were doing.
Like stop hitting me in the face, stop hitting me here.
And like all these kinds of real things that people wanted.
And so you got halfway there and we, we ran out of time. So it would have been good to add more dynamic element there. So writing in VO is a huge part of this. So you've got the characters, but then they need to talk. And so that was a big challenge. We've got Justin, I didn't mention this before, but Justin does both Rick and Morty in the actual show when it comes to the VO.
but we can't just ask him to do every single line and then come back and need to iterate a million times. It would just take forever. So Andrew, our producer on the game, developed a really good Rick impression. And so we would do the temp VO, that would be step one, is record temp VO. So I'll play Andrew's version of one of the lines here. Claw Morty, you must have done a shit job when you tried to fix the car. We broke down and we need you to help us get out of this mess. Open up the portal wall so we can bring you here.
So that's Andrew. And then we would play test that and see what connected with people and whether they missed, they were confused here and then we realized, oh, you need to change this word around and we'd do it again. And then we'd send it over to Justin and he would re-record that line with his extra flavor slash mishmash of improv. Hey, clone Morty, you useless piece of garbage. You must have done a real shit job when you tried to upgrade the car. We broke down and we need your help to get us out of this mess. Open up the portal wall to the new location so we can bring you here.
So essentially the same, but funnier, but also a lot longer.
And so we had the challenge of having VO that ended up getting longer and longer when you add more improv and stuttering and pauses for comedy.
So that was a big challenge.
And we actually end up talking about all of that challenge in a talk that we gave, where we talk about the writing process, directing focus in VR.
What happens when you have really lengthy sections of VO that you didn't trigger on your own and the fatigue that comes with that?
interactions with characters and all that.
And so that was spatial storytelling, which is on the GDC Vault.
When it came to game design, in Job Simulator we had a really strong premise for the game, but there wasn't really a full linear story.
We knew Rick and Morty needed to be different.
It needed to have this real linear narrative.
We wanted it to feel like a full episode arc of a TV show.
So we decided to end up going with a sandbox that people could play around with, and then using gated puzzles and experiences to drive the story forward.
So I want to talk about a few different case studies in the game. So in the Rick and Morty universe there's a character called a Meseeks, which is one of my personal favorite characters. We really wanted to get it into VR. So the way that a Meseeks works in the show is you end up hitting a button on a box and the Meseeks appears and you explain what you want and then the Meseeks does it.
this is not really possible in VR at the moment, because essentially you can't really verbalize to a character what it wants and that character can't just figure out from what you're saying and do that thing. So we needed to determine what strengths and things that we had available to us to be able to interact with Meseeks. And we realized that we can kind of direct and we can use our hands to solve some of this. So we ended up developing this character called the Youseeks. So you grab the Youseeks ball.
when you throw it to a destination and it mirrors your movement one to one. This is pretty funny but it also allows you to solve puzzles and do crazy things like grabbing things out of side of your play space and tossing it to yourself. This was a very big success. It's a lot of fun to play around with, particularly if you throw lots of them into your space.
It did present a big challenge that we ran into for a long time before we ended up finding all the solutions for it. And it has to do with your personal play space bubble.
So people have a personal bubble and even in VR, like this becomes very, very concerning when something enters it. So because you're mirrored with the U-seeks, as you walk towards it, it walks towards you.
So we needed to come up with a ways to resolve this. We came up with a whole bunch of different methods. So the HMD on the head of the U-Seeks is pull offable and as soon as you do, the U-Seeks explodes and goes away. Also if your head ever interpenetrates or gets close enough to the U-Seeks, the U-Seeks explodes. So I'll show you a video of how this ends up working here. So in that particular example, I actually used own motion towards your own face to pull off the U-Seeks own head.
hugging embrace. But that's way better than clipping through geometry, that's for sure.
So I want to talk through the design of the watch. So one of the first things we prototyped actually in Rick and Morty in the early days was to build a watch where Rick would talk to you out of it. And it turned out we threw it out. And it was deemed to be pointless, annoying and really hard to use. And for some reason we were using a hand interaction where you had to grab on to the watch and pull up.
like a, he would kind of emerge out of there and there would be a 3D hologram of Rick talking to you. And so very late stage in the game, we ended up having all these problems and we're talking about we have people who are getting stuck and they need like an info drop, like they were playing around with something on the shelf and then they forget what Rick said, the last thing that he said and they want to kind of go back to that or get a hint or get a status update and it turned out we implemented ‑‑ I don't know how we forgot about the watch but we implemented a speaker on the wall in the garage that the idea would be since Rick was not in the room at that time, he would kind of come through the squawk box and say like, you got to do this and that. And we're like how do we trigger that?
audio and then we realized, oh man, we should just go back to the watch and in redesigning it we changed it to gaze based so you just look down at the watch and that's the action you do and it turned out that was much more natural and very easy to use and it didn't have that location dependency where what if you teleport to or portal to the, you know, some location far away, you would be away from that speaker but now it's always on your body so it's just weird that.
in the first 10% it was there, then 90% of the way of the game it was gone and then it finally came back at the end. And so it also solved this problem that we found in job simulator, again late stage, which was everyone felt like they were enjoying the game up until a point where they felt like the game had become their life now and they were just being told over and over do this thing, do this thing, do this thing, and it felt like monotony.
and then we changed it so that there was user agency. You had to pull a ticket or flip a switch or pull a thing and that would be the way that you'd start the next task and just giving people that agency to start the next task meant that they stopped to smell the roses more and played around and felt like they weren't being rushed and had more fun playing the game. And then once again, we forgot about that in Rick and Morty and then we said, wait a minute, that's how we did it in Jobsim. Well, let's just use the watch again and so the watch ended up.
solving that problem of instead of them barking VO at you for the next thing you have to do and the next thing you have to do we put in a lot of like all right when you're ready like look call me back on the watch and then that led people to feel calm and relaxed and able to play around with the space and then at their own time call back Rick and move forward with the story.
Another strange one was the microverse machine. So if you guys remember the episode where there's a microverse as a battery and inside of that battery is an entire universe where people are peddling to power the battery.
really wanted to make the joke and go into a tiny scale and do something inside of a small world and so we built this Petri dish that you end up loading and you get shrunk down and you do something in the Petri dish but we just didn't know what and we experimented and spent so much time on this weird cellular based like you pull out some weird Rick and Morty mitochondria and you move them together, I don't know.
and we just kind of floundered for months trying to figure out what happened in there.
And then we realized, okay, we wanted a revisitable play space.
We want something without punishment that has some skill-based element to it.
Something you could take back from that little world and bring back to the bigger world.
and the peddling of the characters in the show, we don't have feet, and so what's the, like the translation is let's use our hands to do something interesting in that regard, and so we ended up making a machine that would generate a universe, and you could see, most people probably didn't even notice what was going on, but there's like a sun and a earth, and it's building an entire universe, and that gets charged into the tiny battery, and so you get batteries that you could then use to solve puzzles in the rest of the game.
So, again, it took us a long time to figure out, you would assume, oh, they made a puzzle and that was the first thing they came up with, but no, many months of not this.
So for people that played the game, there's this combinator. It ended up being the best and worst thing that we built in the project. We had this concept of doing crafting.
So we have all these different items in the world and Rick is always kind of putting things together so it seemed to make a lot of sense in this universe.
In our games in particular, we think that everything in the world needs to be interactable. So if you can see it, you can interact with it. This means that we have a huge amount of items. In traditional crafting systems, a lot of them hinge on the fact that there isn't that many items to combine.
because in a lot of crafting systems, there's a lot of failure state.
It's like, oh, here's the few things that do the thing, but most things end up not doing that.
In VR, this is really problematic because you're actually doing physical effort to combine these things.
You go find something cool, you take it back to the thing, you put it on the thing, you hit the button.
And if the end result is either nothing or something that's like the failure state, it ends up being like, oh, I guess this thing doesn't really do too much and you don't go back to it.
And it ends up being physically exhausting for no actual gain.
So the conclusion we came to is that instead of being like a crafting system, it needed to be more like a combinator.
It needed to combine every single item in the whole game together.
So the very first thing you do is you sat down with a spreadsheet and wrote out every single object in the entire game and started to determine how we would end up handling this.
just kind of a scale factor here. The first order combination, so any item in the game with any other item, yielded around 30,000 combinations. Every item ended up having some property to it that would be the effect of a combination. So, for example, it would change geometry, material, interactive properties, yield a different object.
But because you're combining two, what we ended up doing was ranking these on a hierarchy of kind of how cool they were and what you'd expect. So essentially we'd grab the one that was the highest on the hierarchy and then go and combine those. But just because you can combine every other item doesn't mean you can't then take those things that you combined and combine with other things. So this can kind of spiral pretty quickly.
example here of depth, if you end up taking a carrot and combining it with something made of glass like a beaker, you end up getting a glass carrot. Now if I take this glass carrot and combine it with a hammer, now that glass carrot ends up being a glass carrot hammer with a carrot on the end of it. Now if I take that glass carrot hammer and combine it with a ball, Now the U-seeks ball when you throw it spawns a U-seeks with a glass carrot hammer for hands. And so the cool thing is that this ends up yielding lots of different things but the uncool thing means that when we had QA process we ended up writing out things like this to make sure everything yielded something cool and then you had to go through them all and make sure that something always happened.
don't know if you should clap. At one point we were like are we doing this wrong? And somebody on Twitter from scribble nuts tweeted this thing about how everyone thought scribble nuts such a fantastic game. There's some AI and it was data driven and we just always figured these things out and they're like, no, it was just so much manual work and the same conclusion that we came to, it was just a ton of manual work to make sure all of this worked and ended up from a player standpoint just seeming like magic and we wrote some AI to essentially solve this. Why it was one of the worst things I said that we built, the payoff was just so great.
Essentially people would spend so much time playing with this to see what kind of interesting things would come out and there were so Many let's plays of people going down the rabbit hole this person went down the rabbit hole of poop for example Just like what can I do with that?
And that ended up making the game feel a lot more alive So I want to talk about the, previously the elephant in the room, which was, we have to address Roy.
So people who have seen the show, there was in blips and chits, the arcade, there was a machine where you put on like a VR headset.
And then when you put on the headset, you live the entire life of a human being from birth to death and make every decision that they made.
And it's a huge branching life narrative.
And then when you take the headset off, you get your score as to how well you lived a life.
So clearly we needed to build that in our game. Well, we really wanted it from the beginning to address it somehow but clearly it's a scope nightmare and then the fans had spoken. If we don't do something with Roy, we're screwed. So we came up with this really funny outcome which was to build the intergalactic ripoff version called Troy.
And so Troy was under this kind of like knockoff brand constraint where everything was on a cardboard cutout and was like poorly animated and then voiced really strangely from like one character. So the constraints led to this great result where it was a ton of fun and you had ‑‑ we actually were able to build in, because it was super fast to author content, a ton of branching scenarios. And so when you start your life, you get to choose what toy to start with. And then as an adolescent you choose whether you're going with a sports team or going down a path of doing drugs with these kids and then you do a lot of drugs and you get, you know, like you're in a bad medical spot and you could die early and then you die at the age of 50 or whatever and so like this whole thing happens and people play it once and they're like, oh my god, how much of this exists? And you could play it over and over and over and there's a ton of branching and so we actually used, we made a game called Discourse a few years ago that was all about a ton of branching narratives all put together and choice based narrative. And so we used some of our, you know, what we learned from that game in putting this together and I think it ended up working out pretty well. So a fun development fact there was that one developer essentially did most of this and in doing the temp voices, he just voiced every character with an absolutely awful like oh hey Troy, and then everyone loved that voice so much and that it fit with the like kind of crappy quality of the whole thing that his voice is every voice in Troy with no edits from the like prototype version so it was pretty fun.
The other issue just to bring up was the concept of using a secondary input on VR controllers. And so we got all the way through job simulator while somehow boiling down all of our input to a single trigger. Yet there were a lot of mechanics where we really wanted a second trigger or second button where you could pick up something with one button and then use it with a second.
So, for example, there's a fire extinguisher in Job Simulator and then we redesigned it so that when you pick it up you use your second hand to push down on the top like a button and it would shoot out the fire extinguisher.
And then, like, for example, the mouse was another one that we thought we clearly need a second button but then we devised a solution where once you get your hand into the mousing area on the computer, your trigger gets utilized for clicking.
and then when you move your hand out of that zone, your trigger's back to using grab like it is in the rest of the game.
And it ends up that everyone, it was super smooth and no one kind of really even noticed it, it was very natural.
And so we got through Rick and Morty, or we're working on Rick and Morty, and we said, okay, now we really need a secondary input.
And both of our examples were guns.
That was the point where we really needed a second input to shoot.
So the first one was Rick has this laser gun that's very prominent in the show and we have it laying on the counter and we're like do we have to remove it? How do we make it work? And so the joke that we have on that one is it's tied to his fingerprint and so if you pick it up, it's got a reverse safety. So the joke is that he's got a laser gun and he's so it just starts shooting madly. And that was a joke, but then when we got to the point where we wanted to do the actual shootout scene, we thought again, okay, now we're going to need a second button somehow. But we designed our way around it in the sense that you go to this, you go through a portal into this scene thinking you're going to have to fix Rick's car and then you end up getting trapped, spoilers, and you have to shoot down all these grumple mites. But what happened, and most people probably don't notice, is that the portal behind you closes and never reopens.
and then you put your hands on these areas to get guns into your hands, which I'll show you right here. So right when you put them there, boom, blaster hands. And then the only way out of that scene is to die. And so you never have to deal with the dropping of guns and when you die you're back in the other world with your hands back so we don't have to deal with the secondary input so we're able to once again work around that.
So on some tracking solutions in VR, grabbing things at floor level becomes very challenging.
So sometimes things fall on the floor and you won't actually be able to reach them.
So we needed to come up with a solution for this.
In Job Simulator, what we ended up doing was we ended up having a tracking volume on the floor that kept track of objects that fell in there, and then we respawned them onto surfaces.
In this game that became very challenging because there wasn't always a surface that we could spawn things onto. And the counters ended up becoming very cluttered. So we wanted to try to figure out a way around this. A way that we ended up seeing this implemented a lot as of late is like that force grab, that Star Wars, I put my hand towards the thing and then I hit a button and now I've got the thing in my hand. In games that we design, we think it teaches the wrong lessons because people generally just like the The teleportation solution end up standing completely still and just pointing at things at a distance.
It makes the world feel a lot less real, so we don't want to essentially encourage that.
So, what we ended up doing was, we ended up implementing this levitation system, which I'll show.
So when you end up putting your hand near something on the floor, like above it, what it'll end up doing is it will levitate up towards you.
It won't levitate up into your hand. It's still up to you to physically grab it, but the object will kind of levitate up.
And this prevents a mismatch where it's like, oh, things on the ground do one thing and things somewhere else, like on the counter, why won't that come towards me?
It's all ground-based, so it's like coming up towards you.
We ended up implementing this on Oculus 180 only.
But we're currently experimenting to determine if there's a good way to bring this into all content because like from accessibility standpoint and a fatigue standpoint Reaching things on the ground a lot can become fatiguing and possibly not possible So we're working through kind of solutions to make this better and maybe implement this overall So we mentioned, Alex mentioned earlier about all these different custom play space sizes that we ended up developing. This makes testing really challenging. A bug that we discovered after ship because a couple people messaged us was that they said I can't beat the game, I can't high five Rick.
So there's one point near the end of the game where you have to high five Rick and the problem that they were having was that on certain play space sizes, Rick's hand was slightly behind the physical your chaperone bounds and so in their particular setup, their chaperone bound was set right at the wall and so physically they couldn't continue because they couldn't reach through the real physical wall.
So it became a progression blocker. The reason it went through QA is we didn't end up at that play space size, having a real physical wall there. So what ended up happening is because it's a high five and it's really quick, people would just go high five and not notice that they actually went and broke right through their play space bounds. So we're currently brainstorming ways to help with QA to make sure that things like that don't happen in the future and some detection of, hey, you went through play space bounds and recording that to make sure that we fix bugs like this before they ship in the future.
just like in job simulator you have full control over every object meaning you can just chuck things. In a game like Rick and Morty where there's puzzles, there's objects that are sometimes important and sometimes, and by sometimes I mean all the time, people will take these important items and chuck them out the window.
So we needed to handle this. So we ended up having a few systems to handle this. We ended up having recycling systems on certain areas that are outside your play space to record when things are now out of reach and sometimes respawn them in different locations. And then in other cases like this where you go and break this skull, we actually have a computer in the room that you can end up ordering new copies of items that you've previously got.
So one other funny one is that there's the age old issue of if you have a doorknob on a door, the affordance says that you have to be able to open it. Otherwise it's extremely disappointing. And so we had this issue where it's like the actual garage has a door with a doorknob but we can't model the entire Smith household. How are we going to deal with this? And so our joke way out of it was to make a show reference.
real fake doors. So people instead of being completely disappointed when they pull on a thing and nothing happens, they chuckle and then they kind of move on. And so it's a good way to kind of laugh your way out of the design challenge.
And so it was funny when we started development people had sent us messages like sometimes it can be difficult working with IPs so get ready. Working with Adult Swim was an absolute breeze and so fantastic and I think one of the great things was that the relationship was started at a really great level of trust. They trusted us in the VR space and we trusted them and they provided us so much support and it just worked out really, really well.
So when we set out to build this at the time, there wasn't really any big IPs that were in VR as standalone games.
And so we weren't kind of sure how the community would respond to this.
The response to it has been fantastic.
And one of the greatest compliments that we've ever got is the amount of people that have come to us and said, I played Rick and Morty Virtuality, and then I was like, I should watch the show.
And that is very, very great for us.
Yeah, so being associated with a show that we already loved at this level was really awesome, and we couldn't have done it without the team that we had at Alchemy, absolutely killed it.
So that is it, thank you, and we have tons of room for questions.
Super awesome talk. This is this was the talk that I imagined be like packed out the doors and you couldn't get in Thank you for sharing all those secrets And thank you for for really writing the canon of VR right like the the tomato effect is you guys, right? So imagine, I guess my question would be, now with Rick and Morty, you can mess with physics, right? You could play, you covered so much of what I was gonna ask, right?
Of where you get to play. Where is the, what fun have you had with physics in VR? What have you learned? What is the next tomato effect from this? Or maybe some of the other stuff that's unrelated, right? It may not be specifically associated with the title. But what is above and beyond all of this magic that you shared with us and also basically the performance in the second slide where you're just like yeah we built the pyramids by just building the pyramids. So totally magical of just solving that.
But what do you think in terms of where's the next tomato effect? What have you learned on top of that? And give us some Easter eggs.
answer the Easter eggs thing, we have a ton of slides after this slide that are just weird videos of things going terribly wrong. So if there's a pause in questions, I'll just flip through them. But do you have something on?
Yeah, so like, we haven't nearly got to the point that we haven't kept discovering new things. Like it is a continuous thing and I talk a lot about like every time we solve one thing and we open a door there's like a hundred doors behind it. And particularly in the space of like interacting with the world with your hands, it just feels like we're just barely scratching the surface even still. So I'm really excited for not only what we're doing but what everyone else is doing in this space.
So it's a cartoon that doesn't like, has a very like low quality of animation. It doesn't involve like shading or anything like that. But what I'm looking at the characters faces, they're, the light is like lighting them in like a shaded way. Did you consider an aesthetic that was more cartoon like, like a cell shaded thing or like something else and like did that work or not? I'm curious.
Well, so I guess two parts.
One is we realized that lighting and shadows are some of the most important depth cues that you have in VR.
And so really simplistic textures, but good lighting still means you can interact and have like a good spatial reference for what's going on.
Completely flat with no lighting, it leads to a lot of weird...
moments when you look at something you don't understand how far away it is because you don't have cues so Doing completely unlit has been problematic and we noticed that The we did though experiment very briefly with the outline shader, and it was a very hard. No very quickly And it just felt more natural in VR feeling like they were regular 3d characters Yeah, do you have anything to add there? Yeah?
we knew we weren't going to be able to match the style of the show exactly. And so we're like, okay, we're ready kind of biting that off. Let's see what we can kind of do that works best for VR. When we ended up showing it for the first time, we weren't sure how people were going to take this because people love this show so much. And then showing it at San Diego Comic-Con for the first time and then having this huge uncontrollable line and everyone coming out super happy was like, okay, we're kind of like, we can keep going with this. This seems to make sense to people.
Hi, first of all, great game.
It's the reason I bought a Rift, so dope.
And now I see that you guys put a lot of effort and thought into it, so thanks for that.
I just wanted to know generally how long it took, how many people were involved, what the role breakdown was, and if you were doing it again, if there was an area or a role that you would have focused on more from the beginning.
Yeah, I mean the the missing part in our talent pool at the start was having someone who had done fully rigged animated You know characters that could you know we got away with a lot with floating robots And so when you have rigged characters and lip-sync, it's just really difficult So we ended up bringing on someone awesome Ben Shore who had done a bunch of work on character rigging. Actually we were told there was no person that owns all the modeling, rigging, skinning and animation. That's three people just deal with it and we found a unicorn that does all three. Things we would have done differently, I mean, once you get through it, obviously the postmortem shows a lot of the man we floundered here, we should have done this, we should have done that.
Yeah, it was about a year and a half total.
We started on a very skeleton team, and then we kind of dovetailed into, I think we hit about 15 people on the project at the max.
And that seems to be our general project flow, is that if you throw too many people on it too early, it kind of doesn't work out too well.
You have too much experimentation you need to do, and you need to fail properly.
So keeping it small in the beginning was really important.
And also I should add, a lot of the failures were very important. Like that watch one, like it was, we threw it away, it was like terrible, as Alec mentioned. But when we started running into those problems, I forget who it was, they were like, should we bring back the watch? And it was like, wasn't this thing dead? And it was like, okay, let's revisit that.
So every kind of step in that process was very important to getting where we were.
Hi.
So you guys talked a lot about concern about having a secondary input.
Was that just to make it easier for you to port to different systems, or did you find that users had difficulty with a second input?
Did they find it confusing, or did you find it broke some of the immersion?
So both of those. Right now in VR we can rely on the fact that every tracked controller has tracking and a trigger. And in Rick and Morty we ended up using an additional button for teleportation. So that's kind of a base level guarantee that we have there. And then also kind of that mental overloading of kind of how things will work. And then we also like it becomes a little bit more problematic when you start adding secondary. It's like what is the secondary on things that don't traditionally have a secondary? And kind of like is that a squeeze? Is that whatever? And so we ended up going through the process and getting pretty close. Like in jobs we got pretty close. Oh, there's just a few things. And it's like maybe we'll just actually do the design work to make it more simple for a user to engage and one less thing for us to tutorialize to the user.
While we think of more questions, I'll scroll through some weird stuff. Really gross rigs, toilet Morty. Laundry issues with parenting. Let's keep going. I've got more.
really creepy Rick. More creepy Rick. That's the original micro verse. There's even more to it that we didn't show because we couldn't get video of it because I think it got built and then scrapped so quickly. We were trying to roll back and commit history and couldn't find it.
There's more. Here's a test of Rick and Morty in the top left with their dynamic rag doll.
Bottom right side is putting your hand through a portal and picking up the floor that you're standing on and moving it around Some weird stuff going on one more Top left is one of the earliest prototypes where we had some crazy Puzzle box that ate things and then it had a bug where it would literally eat everything itself actually Yeah, you have a question Yeah, so I was wondering how many different types of motion-based mechanics you experimented with.
There's a really cool one, it's kind of not really practical for the everyday user, I know maybe you've heard of the catwalk, and they have this really cool friction-based technology they talk about, it's a platform you stand on, and I was wondering if you could, if you have ideas of incorporating more fluid movements for players.
And I was also wondering if you were going to incorporate other content like the Citadel of Rix or Anatomy Park.
Yeah, that would be awesome.
But yeah, I guess we've been really, again, we mentioned how passionate we are about not making people sick in VR.
It's so important to us.
And we also don't, you mentioned some hardware, like we don't want to either price ourselves out or have custom hardware or custom needs to get people to play the game.
So again, the most comfortable solution that we found is teleportation, but there are issues that we covered that like, it brings you to a bad spot depending on the type of game and whether the environment is designed for teleportation or whether you're slapping teleportation in to a prebuilt scene that hasn't kind of been thought through.
So yeah, I mean, right now that's the best we've found at the moment with this kind of content is to do room scale teleportation with zones so that you can continue to move around freely and then you're just taking the agency of switching between zones on your own.
It's the early death phone. That's Rick. I don't know what happened to him. This is Rick's look at getting messed up. That's really creepy. That's really creepy. And then I think the plumbus got a bit knotted. Some dials. Any last questions? Otherwise, thank you, everybody.
