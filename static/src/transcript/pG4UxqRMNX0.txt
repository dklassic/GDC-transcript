Hi, everyone.
Today I'm here to talk about this game we made, Hi-Fi Rush, and more specifically, how we went about designing it and our methods for iterating on our gameplay loop to reach the result that we wanted for the project.
So as most of you know, this was a new challenge for us at the studio.
And we knew that we would be doing a lot of learning while developing.
But I think the biggest thing we came away with was how we basically completely re-approached development in order to design elements to make the game that we wanted to make work.
So looking back, it's strange, but we developed in a way that I would call backwards, hence the title of this presentation.
And just for reference, there are some musical terminology being used in here, but I don't think anything's too complicated.
But before I get into this, let me just give you a quick overview over who I am.
So my name is John Johannes, and I've been working at Tango Gameworks as a game designer for about 13 years now.
I joined when the studio started, and I had no prior game design or development experience.
So for me, everything was learning while doing.
And the projects I worked on this before were the Evil Within, which I did game and level design.
After that, I worked on both story DLCs we did for the game, The Assignment and The Consequence, where I was not only director on the projects, but I did story and script writing.
And then following that, I was the director on the sequel, The Evil Within 2.
And when that wrapped up, I began working on a project that we should be familiar with as Hi-Fi Rush, which I was the director on this title as well.
and to clear up what a director does at Tango, since depending on the studio, director might mean a lot of things.
For us, it really means a game director and a creative director all in one role.
Now that being said, I was pretty hands-on for this project for a long time, since we were quite a small team until sort of the end part of development.
So I did things, again, like I created the story and wrote the script.
I assisted in level design, even grayboxing things sometimes, putting together things in engine.
I had my hands in all parts of the game design with the game design team, including about half the game's boss fights.
And again, we were a small team for a while.
And because of the nature of this game, which I'll go into later, it required everyone to be extra hands-on and wear many hats.
So it wasn't just myself.
Most of the team members had their hands in multiple features, sometimes outside of their skill set.
So a quick look at what I want to talk about today.
The first is I want to go over how this project started, how we kind of came with our initial pitch, and then how we started developing it and determining our approach to developing the full game.
And then from that approach, I'll go over what we called positive gameplay loop that we discovered, and how we iterated on it to match our image of how the game should play ideally to the vision that we had in our heads.
Then I'd like to show how we took those early learnings from the project, this sort of working backwards idea, and incorporated it into almost all aspects of the game development and our workflow.
There'll be examples from just general gameplay, there'll be level design, and the sequences that we made around licensed music choices, and how we had to essentially reverse engineer those from what we would call our musical impact.
And then I have some takeaways.
While a lot of the methods on this project are very bespoke and unique to the type of game that this is, I think a lot of learnings that we took away from it are applicable to any project that's probably trying something new or outside of your safety zone.
And so for the first section, I'll jump into how this project, HiFi Rush, all started and our goals for the project, just beginning with the pitch.
So this is quite abridged, but I initially brought this game idea to the table after finishing The Evil Within 2 as a non-traditional game from our studio.
We knew that we were working on Ghostwire Tokyo Next, which is in the same sort of thread, and we were kind of being solidified as a horror studio.
So I pitched a concept that I was personally very passionate about, it was very different, and I'd been planning it in my mind for a while, and obviously it was like nothing we'd developed before, and I pitched something that I said was a colorful and stylish action game combining music, describing it specifically as a 3D action game where everything in the world, including your actions, syncs to the music, creating the feeling of a music video being edited around you.
And probably as surprised as most of you would be, the initial reaction to me pitching this was actually positive.
I expected them to walk out of the room laughing.
But that didn't happen.
However, there were a bit of concerns about the project.
While we as a studio thought it was cool, we did have no experience at all in this type of genre.
And obviously it was the complete opposite of everything that we had done before.
So we had our studio image, like I mentioned before, that was focusing on horror, as well as the games that Bethesda at that point was known for.
So just sort of pitching it on paper we thought would be an extremely difficult sell.
but we thought it had promise.
We thought it was a cool idea and we thought it had potential and we wanted to try something new.
And it was a good opportunity for us at the studio at the time.
So we decided to prototype the idea.
We wanted to prove the concept and if we could nail it, we could use it to kind of push the idea internally with less friction.
And if we did a good job, it could be the groundwork for when we actually started developing the project to kind of hit the ground running.
So when I pitched the game, I defined the gameplay as rhythm action, and I immediately got a lot of questions asking what that meant.
Was it a rhythm game?
Was it an action game?
And I had an image of what I meant with rhythm action, and I usually explained it by comparing it to both genres individually.
So to explain this, I kind of put both genres on a spectrum, both rhythm games and action games.
On one hand, we have rhythm games.
And this is a very general and extreme statement, but I defined it as where the gameplay is strictly matching your gameplay to an existing song.
So there would be low player freedom and limitations to gameplay, since essentially you're just matching to a music track.
But on the other hand, we had action games.
And again, this is very extreme, but these would normally be considered having a high level of player freedom and few to almost no restrictions to gameplay.
And for Hi-Fi Rush, I imagined it much closer to action games.
I wanted there to be a freedom of choosing your actions and that free-flowing action gameplay you expect from these character action games.
But there was a musicality to your actions, in this case, literally, as everything I wanted to be tied to the music.
And for that, I wanted specifically there to be no UI telling you where to play.
There would have to be a natural cadence to gameplay where everything would just work in tandem with the music.
The goal being that music coordination wouldn't feel restrictive, but actually enhance the action elements.
So, we went into this prototype phase, and I set the goal of the prototype to define that ideal form of rhythm action.
Make it not just that concept that I put on that chart, but actually a playable actuality, so people could understand what the game was supposed to be.
And so quick rundown of what we did to make this work.
We basically just had a team of two people.
It was myself and our lead programmer.
And we had some assist work from animation, sound, and VFX at various points.
And the whole dev time we took about nine months with to come up with a 10 to 15 minute playable demo which fleshed out the core concept, focusing mainly on combat but included some touches on the general tone of the game and visual nuances like how the world would react to the music.
But an important thing that we decided early on was that we intentionally included no art in this prototype.
So we can focus purely on this gameplay experience, the music and gameplay combination.
And actually, this was hugely successful for us, as it did prove the initial concept of Rhythm Action into a fun, understandable, playable experience, and helped us to get the project fully greenlit.
but it also did what I hoped it would do, which is kind of set up the fundamentals of how we could approach designing the full game.
And I have a short video here kind of showing you a little bit of what that prototype was.
So let's take a look at that.
Okay, so as you can see, and if you played the game, you know that this is actually extremely, extremely close to how the final project was in terms of direction and functionality in the gameplay.
So I'm going to jump back a little bit of talking about the sort of design fundamentals that we had when we were kind of planning out this prototype and then going into the full game.
So of course, what I imagined rhythm action to be was having gameplay actions synchronize their impact with the music beat.
And when I say beat, in musical terms, I mean a quarter note interval.
So in my mind, this made sense, having the impact land with the music, as it would basically make the impact feel stronger.
But not only that, having the beat interact with the impact as well would also reinforce synchronization with the music.
And honestly, I just thought this would feel really good in general.
The core idea was that you were the star of a music video, and if you look at any music video or movie or trailer that's edited to the music or does something similar, they always do it where the hit of the action lands with the music, giving it that extra power.
But we had a problem, because we weren't making a video or a music video or anything like that.
We were making a game.
And in action terms, gameplay, specifically technical action gameplay, we really kind of think of the gameplay in terms of your input.
And the gameplay response is usually the result of that.
And I was always looking at the result, that sort of impact of synchronization of music and action, as something that I wanted the player to feel.
And we had to figure out a way to make a game that somehow gave the player that feeling.
So what I designed with our programmer in the prototype phase was the foundation for the game, the sort of work backwards approach.
So basically, we started with what we wanted and then just figured out how to get there.
The solution we came up with was to interpolate all aspects of gameplay, regardless of when the player inputted their actions, to synchronize with the music.
We used the sound system Wwise to take the music data playing in the game.
We then converted the BPM, or the speed of the song, into a tick that the game would use to define where the beats or quarter note intervals were.
And then we would interpolate animation and actions to run in coordination with that tick, which was again, generally in quarter notes, to drive all aspects of the game.
And we called this, for us, we called it the Rhythm Synchro System, or RSS, which basically meant, you know, hey, don't worry where the beat is, we'll find it for you and we'll make it sync up for you.
So as developers, we're assuming that the player will not press the buttons on the beat and create a system that works backwards to ensure that we cover for player error so that they get the desired impact no matter how they play.
And I'll kind of show you how this works with an example.
That example being the player's one beat light attack, the basic attack that you do in the game.
So this is an attack that takes one quarter note, or beat, from inputting the attack to landing on the next following beat.
The goal being that no matter where the player inputs their action, the attack will always land on a quarter note interval.
So here's the extremely crude timeline for quarter notes and their subdivision in eighth note.
And in this situation, which I'm going to show you, we have just timing, which is what the attack was based around, one beat from input to impact.
So in this case, ideally the player would input their attack on the beat and the impact would be on the next beat.
And we don't need to do anything because there's no interpolation, it's exactly as planned, this is fantastic.
But we knew that this would never be the case because people will miss this or not play with the beat sometimes.
So let's say the player inputs their beat late, sorry, inputs their input late, which would be a little bit after the beat timing.
In this case, we speed up the animation so the impact will still land in the same place.
The animation is the same, it's just slightly sped up.
The same goes for if the player is pressing their input early.
The animation would be extended to land on the beat, but again, the impact timing is always the same.
And this process of looking for players' inputs and assigning the correct impact timing was constantly happening on the backend with our RSS system.
And this logic even worked for passive inputs, like the player just pressing the stick and having the player's footsteps interact with the beat, like running.
Okay, so we have our basic kind of logic with this RSS system and the underlying systems that we developed.
But now I just want to talk about how this kind of worked in our favor to finding our key core game loop, and then how we expanded on it to hit the intended player reaction that we wanted.
So the great part about having actions impact on the beat is that with our logic, we had actually inadvertently created what we called our positive feedback loop within the system that we made.
So this helped players play the music even without UI telling them to do so.
And again, we wanted to create a game that had natural flowing action without gameplay telling the player when they should play with UI.
So how did this work?
And I will use combat again as an example.
and it all starts with the input.
So the player's gonna input something, and in this case, it'll be an attack, which, just for the case of this graph, we're gonna assume it to be perfect timing if input on beat.
But again, we're not gonna force that on the player.
They can press the button whenever they want.
We only guide them to that.
So again, if they press an action, whenever inputted, the action will impact on beat.
And if you do combos by linking attacks and the impact is on beat, by just attacking again when the attack hits, it will then have the player responding in perfect timing to continue attacking.
And if the player somehow gets off beat, let's say they button mash or they miss something, they just need to look at their next action or attack to get back on and continue playing in rhythm.
So at its core, again, we essentially created a self-servicing cycle, which we called our positive gameplay loop.
So we had that philosophy that was working out great for us.
The general systems were working together to support the player playing to the music, but we wanted to feel even more special, because the idea is we wanted you to feel like a rock star.
So part of that approach that we took was focusing on these points.
The first being, we wanted you to have a positive reaction when playing to the music to encourage that type of rhythm action gameplay that we ideally hoped you to play with.
But at the same time, we wanted to not punish the player for messing up or not always attacking in rhythm.
The key goal was that this would be an accessible experience to those without a musical background, and that was constantly providing the player with a positive feeling.
And to do that, we needed to figure out ways to inform the player how to play, that they're playing well, and also not discourage them if they weren't.
And for you to be able to play in like a rock star without having, without playing musically, without having musical experience, you may notice this directly correlates to our protagonist and the narrative, who himself doesn't have a musical background.
So this is all sort of coalescing in this sort of a full package experience as we expanded on this.
So the main approach we used was making it clear when you succeeded, but downplaying if you didn't perform perfectly.
One of the basics of successfully playing in perfect timing was that we would have an audio response and try to make your actions feel more like part of the song.
So if you were to attack on beat, if you played the game, you know there's a vocalized hey or yeah that has an immediate response.
And in game, it looked and sounded like this, which you probably know.
Another example would be if the player was dashing.
It had a normal sound effect with it, but when done in rhythm, we would add a drum hi-hat to it to add a musical element to the dash effect.
So subtle, but these small things kind of added up to just sort of make it feel like more part of the music.
But we didn't stop there.
We had a lot of UI also respond to just timing attacks to give the player more feedback as if they were playing to the music.
So we had a visualization of just timing around the player with a note mark, as well as added VFX around your metronome-like hovering cat companion, 808.
We also had the health and score meter react similarly with vivid colors flashing when actions are timed correctly.
And of course, we did things like include physical feedback with the controller rumble when things were timed perfectly.
And then we had our score ranking system, which along with indicating just timing, like I showed you previously, also adjusted its rank dynamically, increasing more when the player played with better rhythm with bonuses and scores.
But the score system didn't penalize you for not playing in time.
It just adjusted the way the meter changed.
And then there was more of a secret element, but we added damage bonuses to just timing attacks, which made battles quicker when played in time.
And we specifically didn't show damage points in game to not make you feel like you're doing less damage.
So it's more of a subtle hidden feature where you just tend to feel like you're playing better when you're playing in rhythm.
And on the opposite, if you didn't play in time, we just didn't have any of these features show.
So the thing is that the UI didn't have additional effects, you wouldn't get that sound feedback, and the score system wouldn't have those bonuses, along with your damage being its normal level.
But your attacks still landed with the music no matter what, and our sound design had hits always play with musical audio all the time as well.
So overall, not having these extras didn't feel like a failure and wouldn't distract you when playing.
The only obvious thing was after battle we would give you a rank that reflected your performance to show where you needed improvement, but we didn't want to discourage you during combat.
However, there were clear game elements that when they were explicitly tied with a very specific timing, we did use UI to show the player how they were performing.
We did want you to know where there was room for improvement, when it really mattered in gameplay.
The most obvious version of this being the combo finishers, which we call beat hits.
So looking at from the perfect version on the left, in the game they have an explicit countdown, so performing in perfect timing, we're going to acknowledge that timing.
We show you specifically the word perfect will appear on the screen, and you can even see some screen effects come in to sort of support that as well to make it feel like you did a great job, as well as you can see the follow-up attack, the sort of two bursts of energy that appear on the ground.
Now, if the player performed what we would consider a good timing, not quite perfect, we would still count it as a success.
And the attack will play out as normal, but we do let you know that it wasn't perfect, of course.
You can see the good, instead of perfect, good is being shown.
And if you notice, there's even those sort of elements, the screen elements, sort of lines coming in on the side, those are not there.
Again, not too distracting that you wouldn't notice that they weren't there, but again, not as intense as if they were perfect.
And in this case, we actually do have a failure state.
It's technically a miss.
But the character still proceeds with their final attack, but they don't have that sort of bonus attack of those two energy things that are coming out after them.
And so while this is technically a failure, the final attack does play out normally and the player doesn't stall or feel like you can't attack, so it doesn't feel terrible.
And we try to downplay failure as much as possible.
You'll notice there's no negative UI, we don't tell you miss on the screen.
And the center two circles just sort of fade to red instead of just feeling like maybe put an X on it to make you feel like you missed your timing or things like that.
So clear enough so that the player could understand that the attack didn't proceed, but not enough to be discouraging was what we thought.
And again, when there was a key timing element that alters gameplay, we want to make sure that we were clear with UI information.
We decided to do this with some special attacks, which had rhythm game-like UI, or a rhythm parry system, which visualizes a call-and-repeat pattern.
Since, again, these were specific musical games with a success and failure rate, and we didn't want the player to guess on how their performance was when they were playing these sections.
So that combat system which I've just been talking about was arguably our biggest challenge but also our greatest strength as it was our key gameplay mechanic.
The iteration and small touches all added up to a positive experience for players that we felt and even got feedback that was informative on how to play but not overbearing, which was great for us.
But as we fleshed out how to make the rest of the game, we needed to take our learnings that were the foundation that led us to finding that core gameplay, that sort of working backwards from the impact idea, and ingrain it in everything else with the rest of the game.
So going forward, I'll use the word impact again, but you should think of it less of a physical hit and more of about the combination of a feature and music experience intersecting together.
So we had a system that helped things arrive at our impact points with the RSS system.
But as developers, we kind of needed to adjust our approach to make sure we knew what we were designing towards.
And to do that, we had to start essentially thinking backwards, adjusting our workflow.
So when designing every part of the game, I instructed the team to think of every aspect of the game as something that contributes to a world that is synchronized with the music, supporting the player experience.
We learned early in the prototype phase that designing a feature then adding in musicality afterwards didn't work to make the experience feel coherent.
Instead it kind of made it feel tacked on or sometimes even dissonant with the music.
So we applied the approach of thinking from the desired impact and then working backwards with the intended musicality.
and a much simpler version of this to explain it, is we would just basically think of where every action should hit ideally musically, and then we would create features leading into that timing.
So the music or beat would continue regardless of what the player would do.
Obviously, we can't change music.
We can't just stop the music and restart it when the player wants to do what they want to do.
That's going to continue regardless.
But we can change how the player could interact with the music.
So to do this, we had to kind of rethink how we would design features in the game and adjust our workflow.
So almost every aspect of the game was synchronized to the music, and we needed to know what musical timing we wanted to hit.
Sometimes it would be a single beat.
Sometimes it was the beginning of a measure of a part of the song.
And sometimes it was a specific part of a song, like a guitar solo or the chorus kicks in or something like that.
So everything in the game had an ideal timing of when it would occur.
So if the game is always moving with the music, and this was a constant sort of just a timeline that was always proceeding, we would basically identify what's the ideal timing for the feature's impact, the combination of the result with the music.
And then with that in mind, we then work backwards to know when things needed to start to get that desired result naturally in gameplay.
and just like in the combat example since the user defines the initial interaction we also need to know how to adjust or interpolate each feature to make it work So I showed you some very big things like the whole combat mechanics, but even very small things in the game were designed with this in mind.
For example, something that all developers can relate to is doors.
So for our game, doors not only just need to open, which is the ideal thing that we want doors to do, but they needed to sync up with the music, opening on beat, based off proximity with the player, so that it worked with the musicality of the world.
And I'm going to show you a video, and it's going to seem very, very subtle.
But you can see that the speed of this door opening, depending on when the player interacts with it, will either be faster or slower, depending on when the player interacts with it.
And that's so it hits its ideal musical timing, which is that the door should always open on beat to support the music of the game.
OK, very, very subtle.
But you also may have noticed we have a debug menu on the bottom.
And that helped us sort of see the game in a musical view and see is that impact timing where we ideally would want things to occur happening where it's intended to be.
And we would always check to make sure things were working correctly.
So that was something that we used throughout the entire game.
The doors were used in multiple levels and things like that.
But we also had more unique experiences.
and we call these kind of unique events or bespoke events.
And this one actually is another door, fantastically.
And this is one that we needed to sync to the first beat of a measure to transition musical tracks.
And I'll kind of let this video play and then I'll talk about it.
OK, so in this case, we don't know when the player is going to hit that button to open the door.
We know the final action will be on a beat, but we don't know what beat it will be.
So we did things like create an initial loop state after it activated to basically wait until the next measure would occur, where then we can then do the opening animation that transitioned with the musical element so that it would transition correctly into the next musical section.
And this all worked from, again, working backwards from when the song should change, to when the door should open, to what happens when the player interacts with it.
Always thinking backwards from there.
So these were small details for the levels.
But on the macro scale, the level design itself was also based around musicality.
Our approach to level design structure focused on musical peaks and valleys, which was a starting point before we even went into greyboxing levels.
And I have an image of what our game design document looked like.
And I apologize for it being in Japanese, but I just wanted to show you the original documentation.
But basically, this is the initial draft of a level design document for our game.
We had story beats and event beats that coincided with musical points.
We wanted to impact together in the level.
We would often model them around song structure.
For example, choruses were fights, and verses were the in-between platforming.
And these were kind of like mood graphs that gave us the sort of impact points in our level goals, which then we would lock in and work backwards from before we even started laying out the levels physically.
So all these features, both large and small, were designed in a fairly similar fashion.
We would plan them out, making a detailed timeline of how things would occur on paper in a way we could see things musically and gameplay-wise making sense.
Then we would build them out in a prototype or gray box form.
This was very important for us, but in this phase we would focus on getting all the key elements, especially sound design, in and functional as soon as possible to ensure that the proposed idea was working as intended.
So I'll come back to this in the takeaways, but this approach was immensely helpful in identifying what worked quickly and what needed to be adjusted.
So if adjustments were needed, depending on the severity, we would adjust them right there in the prototype phase until we got them to where we wanted them to be.
or if they didn't work, we basically returned and rethought the whole plan.
But if the early version was clearly the right step, we would lock in the timing and feature set and then build them out with everyone on the team.
It was important that we didn't leave features dangling if they would work out later on.
We wanted to identify those impact points that they were working correctly early, and then we could spend more time iterating and improving the quality of them.
And so those were just some ways that we approached the workflow, but then we had a very extreme version of this.
And this was any time that we were using the licensed music in the game.
And this was because of my stance on using the licensed music was that I wanted to pay tribute to the songs that we were using and not just use them as background music.
So these sections were essentially reverse engineered around the song so that the gameplay would sync up with it in all aspects.
We had boss fights where phases and actions were determined by the structure as well as specific rhythmic patterns of the songs dictating attacks or movesets.
And then we had full stages, which were, again, made completely around the structure of the song.
And these were by far the most complicated thing that we had to do in this game.
I have examples from both of these sections to give you a rundown on kind of how we made them work and the challenges that we had with them.
But first, again, when I say pay tribute to the songs, what do I mean?
It really means that we would literally design the entire sections around the song as if they were a music video.
We would break apart the song, we would analyze it, and bring gameplay and event beats into the song.
And this required an even more intense production and pre-production timeline.
And for a detailed example, I'll use the first boss of the game against a robot named QA1Mill, which we used the licensed song One Million by Nine Inch Nails.
So we always started with a general image or idea of what the boss fight would entail, including story beats, the visual, the type of fight we want to have.
But once we knew what song we were putting it towards, we followed these steps.
The first being is that we would take the song and we would break it apart.
We would identify its structure and just kind of lay it all out.
We'd identify parts of the songs that could theoretically be looped, which meant longer gameplay opportunities, and parts that could not.
And then we put it all in a timeline and start assigning where we think gameplay would be, where in-game events could occur, and things like that.
And we took our initial ideas for the fight, like general attack ideas and phases, and how we could match how the song feels at certain intervals.
Cutscenes and story beats were tied in with the music to not only be fun, of course, but to reinforce the connection with the song and make sure that they're musically connected.
And after we had that general layout defined, we would then go into the specifics of each section.
Creating cutscenes was comparatively easy because we were setting them mostly to establish lengths of songs, but it was the playable portions that had to be broken down to ensure that the song was always syncing appropriately to how you played.
So here's a visual breakdown, again, sorry for the Japanese, but this is how we just kind of wanted to show you the original documentation, where we created a flowchart based off how the music should change based off the player's progress.
To prevent the song from awkwardly changing, we identified sections that needed to play out, like the lyrical sections.
We didn't want to cut those off midway through a lyric.
So we did things like adjust the boss's HP so the song structure would be kept if the player was playing too well.
The opposite was if the player was taking too long, we factored that in with looping sections to keep the song in the consistent phase without making it feel awkward or feeling like a broken record.
And this page is just a visualization of how we broke down the lyrics and looping sections of one phase of one boss fight.
Each boss fight and each phase and each song was different, so they each kind of required their own unique take on how they would work, so we need to break down each one individually.
So then, once we had this kind of overall structure done, we would comb through the actual musical audio data, or what we call stems, looking for rhythms that can be used for certain movements or attacks.
So at this point, we had general attack ideas for how the bosses would fight.
But it's now when we would kind of finalize the rhythm that these attacks would come up with.
So in general, we followed the approach that any time an attack would be specifically tied to a musical part of the song, they should happen exactly when that section happens in the music.
And we would do that by dictating it with cues set up in the audio data, and then also determined by the enemy AI based how the player was playing.
And a good example is a video I'm going to show you here.
But because of cool music licensing restrictions, I can't actually play you the song.
But I can play the sound effects.
So it's close enough.
And I think it kind of helps with understanding what I'm talking about.
So let's check this out.
Okay, so if you play the game, you probably know this section and the song, but this boss uses, obviously uses lasers out of his hand as a sort of gameplay mechanic that we wanted to do, but it obviously has a musicality to it with this guitar riff that's included, this da da da da, da da da da.
and if you play the game and you know that song, that that guitar riff is constantly happening in the background.
And so we made it that obviously we want the player to experience this sort of attack as a way to play the fight, but we made sure that that attack was always happening in tandem with when that part of the song was playing.
So that was just one example of one attack sort of syncing up with the music.
And then once we had sort of the gameplay aspect done, we would then turn to non-gameplay related elements to tie to the song.
We would look at the environment design and start breaking it apart.
We would identify things that could pulse to match the song's BPM or speed.
Or maybe there were things that we could flash or move to specific melodies to make it feel like it's part of the song.
And then depending on the song's change in mood or volume, we maybe would change the colors of objects or the way things move just to match that.
And there were a lot of other things that just kind of tied to specific ways that the player interacted with the boss, things that the player could do, special attacks that the boss can do.
And this all was basically around the same concept, right?
If we were making a music video, we needed everything in the game to sync up so everything felt synchronized.
So that was our very basic approach.
Some stuff worked and some didn't, and we were constantly iterating to find what matched the song times and expressions perfectly.
But one thing that we kind of kept consistent was we rarely, if ever, changed the initial structure.
And this was just based off what I talked about before, is we were building it from an existing song.
We were not going to change that song.
But that final steps of adjusting the rules of each gameplay section, creating and adjusting actions and attacks to the movement, and adjusting the environment, were always to get it as close to the song as possible.
And this was constant, even to the end of development.
So realistically, it felt like it never ended.
There was never a clear cut, okay, it's good enough.
Probably one of the final things we did before even finishing sending the game off was adjusting the way lights flash during boss fights and things like that.
And while it was a lot of work, I would say that it wasn't that bad because the stages that we set to licensed music were much, much harder to do.
The idea here was that we wanted you, of course, to play to the music, but we wanted to keep the freedom of how you played and not feel like you were just on a linear path.
So to do this we had to find lots of ways to make the stages sync up with your actions.
Sometimes this required thinking of unique solutions for every section the way that the levels transitioned.
An example I have is a sequence very early in the game of an escape sequence in the level where we had to think of multiple ways for the player to re-sync with the song transition based off how they encountered it so they can change cleanly into the chorus or battle portion of the stage so the song didn't feel like it was changing awkwardly.
So remember that we always wanted the player to feel like these sections worked even if they were playing in a non-perfect way.
and I have videos of this.
And again, I can't play the original licensed song, but I can use the unique version we made for players who stream the game, which follows the same structure and gives that point across.
So, for now, I just want you to see how this section plays through.
But setting it up, if you haven't played the game, the player's running through a level that they're kind of free to sort of move around and do some actions based off, you know, how they feel about doing them.
But they're leaving this area, and we want them to transition to a battle which acts as a chorus.
And we want that transition to be very clean and match with how the song's supposed to play.
and the player is going to transition using these grappling or magnet points to eventually transition to a fight sequence.
So this is the official correct timing that I'm going to show you.
Okay, so that should have sounded like it matched the music.
So the issue here is we don't know when the player will start the sequence of events because they're free to play in this section.
But we wanted to transition correctly to again, match the song.
Again, we knew our desired impact point, but we needed to work backwards to figure out how the player experiences it correctly and adjust for their play style.
So for that part, we took two sections we could adjust to make sure you can match up with a song transition.
That being the magnet points and the landing animation.
So depending on what beat you grabbed the first magnet and how many beats were left until the song needed to naturally change over, we would adjust how many magnets you had to grab and how long the landing animation was.
And there were lots of mixes and matches.
For example, five magnets or one beat animation or four magnets or two beats of the landing animation.
And I think there were up to 18 different combinations in this case of how this can play out.
And all of this effort, ideally, you would never notice.
And it would just work.
But to show you that I'm not making this up, I will show you what some of these variations look like.
So this is a version where there's three magnets, and you'll have the longest three-beat landing animation to connect.
Okay, so that should still sound like it works, right?
And then for this version, it's when the game determines you need five magnets and the shortest one beat landing animation to sync up.
All right, and this was just one small part of a big sequence with a bunch of these type of situations.
There wasn't one answer that solved every problem, and we needed to approach each situation with a unique angle, but the development logic, realistically, was always the same.
We were always working backwards from the impact of when the player should land to start the course for this fight, for example.
So realistically, it was a lot of hard work and clever engineering, but the end goal was the same.
We just wanted the player to feel like they were playing correctly no matter how they played, even if technically the last two examples I showed were theoretically wrong.
Okay, so those are some very specific things showing how our workflow changed and how we approached design from a musical perspective.
But as I spoke before, this extended to almost every section of our team.
So each section had their own unique adjustments to coordinate their approach, which required section leads to rethink their methods and when they should get involved in features.
The most obvious example is something like music and sound.
They had to completely overhaul the work timeline to assist in features at a very early state instead of coming in later in development to finish polishing up things.
And all of this was on top of all the other challenges we had, like our attempt at a new art style that required animation, art teams, and cutscene production to learn all new techniques.
But in the end, clearly deciding the direction, having the whole team buy in early to the concept, and always reinforcing it from myself and section leads kept the team focused on what we were making.
And so now some takeaways.
And again, you may not all be making a rhythm action game like this, but some ways we approach this new challenge may work for you if you are thinking of branching into something that you or your team isn't quite familiar with.
And I'll preface this by saying that I realized this when I was writing it, that a lot of this seems like very basic common sense.
But it is frighteningly surprisingly how easy it is to forget these things when you're struggling to make sense of a brand new concept and figuring things out as you go, even for an experienced team.
So that being said, one of the biggest takeaways that I'll echo throughout this section is that we spent a good deal of time early on in the project finding a process and workflow that worked for the unique challenges that making this game required.
and a lot of these methods were almost the opposite of how we approach things on previous projects.
So realigning the team was both difficult as well as actually eye-opening since the techniques mentioned here we can see ourselves using on future projects going forward regardless of the content of the game.
So first, for HiFi Rush, we always had a final goal that was communicated to the team members, giving us a blueprint to work backwards from right from the start.
It's often in game development you have members working forward without a clear image of where things end.
You have things like scope creep.
But here, instead of making things abstract, we tried to make that goal post clear to avoid confusion as multiple sections work together to build features and scope to a finish line.
The next thing is that I discussed this earlier, but with our blueprint, we focused first on getting everything in and playable, especially our key features, which in our case were our impact points and how they work with the music.
The goal here was taking anything conceptual, which can be confusing, and in Hi-Fi Russia's case, musicality sometimes is, and making it real, so any lingering questions from the team could be answered in a gameplay form.
And this led to our next point, that by having an early version running with temporary, yet directionally close assets, iteration was much quicker and allowed us to adjust scope.
As we locked in ideas, polishing was easier to see and focus on, and direction was less likely to be misinterpreted.
But all this really meant was that the image of what the final product would be became clearer to the teams at a much earlier state.
This was in stark contrast to our previous projects, that finally the vision was kind of coalescing and seen at the end.
So here we were able to, in some ways, reverse that late dev worry of, is this all going to come together?
And instead just worry at the beginning of how complicated it was going to be.
And while we learned a lot and had a lot of great success with this project, it did not come without its caveats and challenges.
For example, there was this big production timeline before starting to dive in and make anything.
As you saw, the licensed music sessions were even the most extreme example of this.
Another was that when the game was kind of close to complete, it was hard or next to impossible to make big sweeping changes because of how closely combined gameplay and music was, which basically meant you would have to redo everything.
Another thing that almost every part of the game, even reused assets, had to be custom tailored to each section of the game.
So BPM changes, song nuances, those all kind of changed, even things that we assumed would be reused.
And that required a lot of hand adjustments, so game developers had to go back and constantly reiterate on things that theoretically were working but not perfect.
And this is something similar, but that there was just an insane amount of detail management making sure that everything in this game moved to the music and felt correct.
And felt is kind of like a theoretical thing.
Because obviously we did have things on a program side automatically sync to the music.
Sometimes music isn't always logical, and balancing gameplay and music required combing through every part of the game to fine-tune details to match with the music.
because the reality was that if it wasn't perfect, the game just wouldn't feel synchronized and the perception of, you know, this world being set to the music would be broken.
So how do we handle this?
Well, here's the thing, and I think this is an important point that we often forget.
Just because we have challenges during development doesn't mean that everything needs to be fixed.
Instead, it just needs to be recognized.
So any developer will tell you that there is no perfect way to make a game.
So we learned early that making this type of game was going to be A, difficult, and B, really annoying, even though we knew it would be fun as well.
So all those key issues that I showed you before, that we knew would come up with development, We basically just acknowledged them early and planned around them.
We could have spent time trying to find a fix for everything, but in a way, accepting the challenge and all the caveats let us focus on just making the content and quality of the game.
So all those challenges we faced, we knew that they were inherent to the game that we were making, and we kind of prepared ourselves for them, picking our battles based off what our team could do.
Because again, we weren't a big team and couldn't solve every issue that we would come up with.
But outside of the important lesson we learned about accepting the difficulty of the project, there's some strong points that I think applies to any project trying something new, which we learned during development of HiFiRush.
Again, all this sounds very basic, but it's amazing that even a professional team can forget these points.
The first is you want to approach your challenge like what it is, something you are unfamiliar with.
For this title, we basically told ourselves we need to relearn how to make a game.
We worked on horror titles for so long that we had to put all of that know-how aside and just focus on work for what Hi-Fi Rush was supposed to be.
We couldn't be overconfident, and we actually had to humble ourselves.
And we used all of our learned knowledge as reference.
And this helped us prevent the game losing its originality and identity in exchange for a safe and known experience by just relying on what we thought game design should be.
The next lesson was getting things running as soon as possible.
Once we planned everything out and the team was kind of aligned on goals, getting it running and playable while executing on the core idea allows for the team to align quicker on that final goal.
This provides everyone with a good way to give good feedback, which by good I consider constructive feedback that leads to achieving the goal of the game rather than just a personal opinion.
And then, for my final obvious point, but for Hi-Fi Rush, we took the time of really figuring out what the core of the game is and understanding what's necessary to build it.
We obviously had our core pillars as a project, and we acknowledged the difficulties, and we decided to work around them instead of fixing everything.
Since there is no correct way of making a game, it really is about finding a process that works for you and what your team is capable of doing, but most importantly, of what the game itself requires to be made.
So whatever it is, what you want to do is find that early and stick with it, warts and all, because it's immensely important to realizing your vision.
Just like we had to learn as we were doing it that sometimes to get to the end, we had to work backwards from it.
And that's it.
All right.
So thank you for listening.
Thank you.
Yeah, I hope this was useful and enlightening for you.
And if there are any questions, we do have some Q&A time.
I managed to finish in time.
But I must remind you, you must fill out the survey for this talk.
They actually won't let you leave.
If you're letting people leave, you can't leave until you fill out the survey.
That is very important, I was told.
Hi, uh, I just want to say I love the game.
Um, so what was the process for deciding which license tracks to use and like for which sequences?
So like one example, I really liked the use of the prodigy track in like one of the later kind of big fights.
And so like, what was the process for deciding which songs you wanted and when did you kind of use them for which sequences?
OK, the process for choosing licensed music was purely I just chose what I liked and then I put it in.
But I got some feedback from members about stuff that, hey, wouldn't it be cool if that worked here or that doesn't work as well, and then we adjusted some stuff.
For example, the prodigy section was something that was That situation was made, but actually wasn't tied to the Prodigy song.
And then a team member came back and said, what if we coordinate to that section?
And then we decided to make that sequence happen like that.
Thanks.
Thank you.
Thanks so much for the talk.
I was really impressed about how you all made something new and unique that you've never done before.
In your talk, you said you spent about nine months in the prototype phase.
But with it being something you've never done before, how did you decide on that timeline to be able to make a prototype?
Well, the nine-month timeline was actually just sort of what we were told.
It's like, you got nine months.
So there was a lot of panic.
But realistically, I think probably the first six months or so was like us figuring out.
Actually, this was our first time using Unreal as well.
So we were figuring out how to make things work as a game in general, and then figuring out what we can do.
But a lot of it was playing around.
Like all the stuff you saw with the environment moving to the beat, it was just me playing around with, hey, look, I made this cube move to the music.
That's cool.
And we just made it a feature.
But yeah, it was really just playing around until probably the final three months where we figured out what the gameplay was like.
And then we just got everything in and figuring out that loop and supporting it and working from there.
Awesome.
Sounds tough, but thanks for your hard work.
Awesome.
One of the key mechanics of the game is being able to summon other characters to do assist attacks.
What was the development process on that like and how did that affect the work backwards mentality?
OK, so the questions about the partner attacks and how the working backwards worked there.
So the partner attacks just mainly came from when we were expanding on gameplay ideas as well as story ideas of working as a team and more ways to add depth to the combat.
But for those, we decided, OK, how How can these attacks work from a musical angle as well as a gameplay angle?
So for example, like the Peppermint character, we said, it's hard for the player to play in triplets.
What if we had an assist character do that and add their own musicality to that?
So we decided, OK, so that should be the timing.
Whenever you summon them in, when should those triplets happen?
And it's kind of reverse engineered from that.
And each kind of character had their own sort of timing for that.
But it was all sort of based off the same concept.
If you're pressing a button that's on the beat, they'll come in on the next following beat.
The lessons we learned by just creating a simple light attack with Chai, we just kind of applied them to all the other characters as well.
All right, cool.
Thank you very much.
Thank you.
Hi.
Naturally, some people have bad or no rhythm at all.
Was that ever an issue in development, or was it just something that you guys kind of overcame?
Yeah, so if the question is, in development, if people didn't have rhythm, what were the issues?
That was a massive issue.
The biggest, funniest example being the original prototype was made with two people, myself and our lead programmer.
Our lead programmer had no musical knowledge.
So basically I was there instructing him, I was like, this is a beat.
This is a quarter note.
And I'd write all these diagrams and do all this stuff.
And then as people joined the team, some were more musically inclined, which you didn't have to speak to them.
A good example is our lead animator.
I still think to this day does not quite understand some of the musicality stuff, which is always fun.
But it's kind of interesting to see how people just naturally got into it.
But it did help us a lot.
Early on, when we were talking about making an accessible experience, if it was two people making this game who were very musically oriented, we probably would have made a game that was not accessible.
I was giving out ideas early on, and our lead programmer was putting them in and playing them, and he's like, I can't play this game.
Well, to me, it made sense.
So that was kind of another eye-opening experience of, OK, we need to take this down a level so that even if my lead programmer can play it, then it's more accessible to other people.
Does that play into the optional toggle UI for the rhythm mechanic?
Oh, so the optional UI toggle for rhythm was actually one of the final things we implemented as something that I was adamant about not doing.
But we realized that people did need that assist.
And so we put it as an option for them.
Yes.
Cool.
Thank you.
Hi, you mentioned haptic feedback, and I was wondering if you had any specific challenges with, like, controller rumble, especially spinning motor style rumble that takes time to spin up before you feel it, and syncing that with the music?
Yeah, controller rumble in general, since we were designing it with a traditional rumble, there were problems with that.
We tried to tie a lot of stuff to do these quick beats and things like that, and that was not working.
So that's why I think one of the first things we tried, which people still ask us, why did you not make the controller rumble with every beat?
It's because, realistically, it would never stop rumbling, because it's constantly going to be revving that wheel.
So we decided to time it only to the beats, the impact beats.
Yeah, so that's one of those things that we just kind of through trial and error figured out.
There wasn't a specific kind of final ideal goal for that.
We just figured out what worked.
Thanks.
Awesome thing.
Hey, as an animator, I did not use the UI toggle.
I got used to the rhythm and it was really nice playing the game.
So my question is, were there any specific challenges when, you know, you're faced with the animation team in particular with respect to the gameplay loops?
The language?
With the animation team as an animator, you know.
with not a lot of musical knowledge.
Because 15 frames was the idea of one beat.
So everything, no matter what they made, was made with beat intervals in their animation timeline.
And so we said, OK, if the attack is here, how do we make it so every 15 frame interval you have a feeling of a beat or an impact in the animation that makes it feel musical without making it feel stilted?
So it was very, very challenging.
But it also kind of, in a way, helped because they knew their limitations of how they built out animation.
I guess yeah, my question, I may have missed this because I showed up a little late, but What motivated the overall game design decision to make it so even if the player doesn't time an action specifically to the beat, Chai himself always moves in time.
Yeah, essentially like no matter what the player does, the game state more or less always stays synchronized.
And I guess I'm curious what motivated that.
The motivation for just making sure it automatically synced to the beat was kind of that initial idea that I just had in my head.
I love those character action games.
Anything that I saw that was a rhythm game, you have an immediate reaction.
It's the moment you press the button, the action comes out.
but if you want to have things like a wind-up or something that makes it feels like you're hitting a character you had to want to keep that in and so when we were iterating on the idea of how do we keep that in but keep the rhythm applied the idea of interpolating it so you still got the sort of the wind-up or the intro to the attack and then having it land with the beat just made it feel much more like a traditional action game but keeping those rhythm elements but it also in that way helped us define, so you couldn't be offbeat.
We could make sure that it always worked.
Right.
There was like a feeling of consistency, regardless maybe of your input, which might go back to being more forgiving of the player's timing and so forth.
Yes, yes.
Awesome.
Thank you.
Thank you.
Hi.
Thank you for the talk.
My question was, You said that you planned as much as you could and then you started implementing early.
Did you ever find yourself in a situation where something that you had implemented early had to be revised?
And how did you deal with it if you had to?
Yes, there was one stage.
to It's, we did it so no one actually noticed this, but we did it so it's when you're like doing one of those rhythm jumps, we actually secretly warp you to a, we skip an entire stage that we built and we finished and polished and everything like that, and we skipped it.
But otherwise there were no other sections that could be cleanly cut, so we said that's the only, that's the only way we can do it.
And everything else we just had, we just left it in.
So some of the criticisms we got that the stages were a little bit too long, Could have been worse.
Really nothing we could do with it.
That's at the macro level.
Was there anything at the micro level that had the same experience?
At that point, surprisingly, no.
A lot of that stuff was figured out very early, and I don't think anything later was cut just outside of, or adjusted outside of just chunks of the game that can clearly be just sort of removed.
But no features or gameplay features were kind of cut later in the game.
They were kind of locked in early.
all right thank you so much yeah and i'm being like waved at so that our time is up but i can answer questions apparently uh in something called an alcove that's on the other side of the the uh pavilion or west what what is it west pavilion somewhere over there that's exactly correct so i will i will proceed over there if if you want to continue asking questions i'll stick around for a little bit but thank you again for showing up