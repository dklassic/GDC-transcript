Hi, my name is Brianna Lindsay, and we are going to be talking about on Explosive New Spider-Man and creating visual effects for Marvel's Spider-Man Miles Morales.
I'm one of the lead effects artists at Insomniac Games and I got to work on this project.
And I'm really delighted to be here talking today with you about some of the effects that we made for this game.
So this talk has a couple of themes.
Some of them were, one of the ones that we intended right from the start was finding a voice for your hero through visual effects.
and really telling their story and making them unique.
An explosive new Spider-Man.
So an explosive new Spider-Man was one of the pillars of this game and it's something that the effects team really glommed onto.
We found a lot of fun in making Miles our own hero and finding ways to differentiate him from the hero of the 2018 game Marvel's Spider-Man.
Another pillar of this talk is technical tips and tricks that we learned working on a cross-generation game.
So there were a lot of things that we picked up along the way in terms of learnings when it comes to pushing next-gen visual effects, as well as working on a cross-generation title, working on something that had to be on both the PlayStation 4 and PlayStation 5.
And the last theme was something that kind of evolved as I was working on this talk.
And that one is really pushing forward through the unknown, taking risks and working together to create something new and great.
There were a number of effects that, you know, when we were starting to work on this game, we weren't entirely sure how we were going to pull them off.
And I really feel like we learned a lot by taking a risk, by challenging ourselves, and by pushing forward through the unknown.
And it was really wonderful to be able to work on that.
So I'm going to give you a quick overview of this talk.
During our time together, we're going to be talking about Miles's powers.
That includes his venom powers, so that's his bioelectricity that generates within himself.
That's also his camouflage ability, so his camouflage is when he turns invisible.
We're also going to touch on creating spectacle.
So spectacle is a really important part of this game, and it's something that we sort of had to work together as the visual effects team to push.
We're also going to be talking about the enemy powers, that includes programmable matter.
So Miles as his own explosive new Spider-Man needs explosive villains to be able to fight.
We're also going to be talking about his webs. So Spider-Man isn't really Spider-Man without his webs and I thought it would be important for us to talk about that.
We're also going to be talking about an all new accessible game.
We had a philosophy of anyone can wear the mask while working on Spider-Man.
And as an effects department, we were really able to make a big difference for players with visual and cognitive needs with our contrast options.
And lastly, we're just going to talk about challenges for new generation and some of the learnings and takeaways that we had while working on this project.
So let's get into it. Let's start talking about Miles' Venom powers.
They're central to the character and a pillar, a part of the pillar of creating an amazing new Spider-Man.
So this is our next generation shot that we made for the PS5 reveal.
And this is, in the scene we see Miles draining electricity from an overloading reactor.
And as the camera moves across his arm, we see his suit peel away as his arm flashes with electricity.
And as the camera continues, his mask eventually disintegrates as well, revealing who he is to the player.
And for these shots, we really had to figure out creating a soft body simulation pipeline, just so that we could get that suit disintegrating and coming apart.
We also had to figure out how we were going to get that X-ray kind of effect on his skin, so you can kind of see his bones and his viscera through that.
We also had to work on the glass particles flying at the camera, and of course the suit burning up.
So these were all challenges that we were eager to dive into as an effects team.
So when we kind of started on this, this was really just a pitch on paper.
We had this really beautiful script that was written for this that honestly sent chills down my spine. All we really had was this piece of concept art and the script. And, you know, in this script, we hear Peter Parker talking to the player and telling the player, you know, Miles, this is your chance to go be a hero.
And that script, it sort of described, we sort of see Miles put his hands into the reactor.
We see him absorb this power into himself.
And this is really his defining moment as a hero.
This is where Miles decides to save his neighborhood within New York City.
And it's a moment of self-sacrifice because as he absorbs this into himself, it's a really dangerous moment where he could potentially die.
So when I heard this script, I mean, it honestly sent chills down my spine.
This was a huge opportunity for the effects team to sort of push ourselves and to create something new and amazing.
However, I was also really nervous when I heard it because, you know, we didn't have the tools to pull it off.
We had to develop those along the way.
So one of the big problems that we needed really high-quality Venom electricity, so that electricity that crackles down his arm, that's something that we had to develop for this.
We have a little bit of electricity, it's biological, and it's something that comes from Miles himself.
And this really differentiates him from Peter Parker, the Spider-Man in our previous game, Marvel's Spider-Man, because his abilities are more technology-based.
We also had to figure out how to do soft-body simulations.
We didn't really have a pipeline to be able to do things like simulations of fabric tearing off.
So that was the question we were asking ourselves, was, OK, well, we really want to do this.
We think it's really, really cool.
How are we going to pull this off?
So just so everybody watching at home understands, when it comes to this shot, the effects team was responsible for a great deal of it.
When you remove the character from the equation, you can really kind of see the soft body simulation in question, as well as the glass particulates.
the electricity that kind of crawls down. We need to do that for both arms of course.
And you know, since I took the character out, you can't see it, but there's also that sort of x-ray effect that's going on on the character. So you can kind of see his bones and his viscera inside of his body, because it's really important for Miles as a character that this is coming from him.
So, some of the solutions that we came up with to pull this off, we ended up leaning on some current-gen techniques to start.
We painted vertex colors to drive that sort of slow reveal of the electricity.
Our artist, Jenna, did a pass on this and she did an amazing job on creating this electricity.
So one of the things we found was that we could afford more vertices on next gen.
And we really tried to use that to our advantage where we could.
By using more vertices, we were able to sort of push that fidelity on the next gen console.
And we were also able to use the, you know, everybody's sort of used this technique, I'm sure, where you use vertex colors, you color a vertice, like red, green, or blue.
In this case, I think we used red.
just to be able to drive that precise wipe.
So there's material nodes in our material editor, vertex color nodes, that we sort of lean into to be able to drive this.
This is kind of what that looks like in the particle editor.
So as you can see, we were able to get like a lot of precise control, kind of leveraging a current gen technique.
In addition to that, we also layered on some of those little particle quads.
So you're able to sort of see.
those additional tertiary lightenings at the ends.
So we did layer in some particle quads in addition to using meshes.
But I really liked that we were able to essentially model this out to get more fidelity for this shot.
Next up, we're going to talk about simulations and what we call our Anamvert pipeline.
So we needed to develop a pipeline for bringing in baked soft body simulations that really didn't exist in Marvel's Spider-Man.
Our solution for this was the Anamvert pipeline.
The Anamvert pipeline can support tens of thousands of soft body polygons.
So this is kind of what this ends up looking like.
This is something that our artist Matthew simulated in Houdini and exported out of Maya.
This is actually taken from Maya.
But we were able to support 29,000 verts, which I thought was pretty awesome and impressive for this next-gen shot.
And this AnimVert pipeline, we sort of had a prototype version of it, but we really fleshed this out and finished it out for our trailer.
And we really gained some useful new technology that we were able to leverage in other parts of the game.
So just a huge credit to our entire programming staff, especially our animation programmers who were able to help us flesh out this pipeline, because I'm really just impressed that we were able to pull this together for this trailer.
And then we also used paint vertex weights to drive the burning edges of the sleeve.
So it was really important for us when we were working on this shot to have the audience reveal and understand who Miles is while they're watching it.
So as the camera is moving, you're not entirely sure who it is until the camera starts pulling up closer and closer and you see, oh, at the end it's Miles.
It's who Miles is.
So what we did was we sort of used vertex color again here.
We just sort of painted using the red channel to drive that erosion.
So this is actually a GIF.
It moves pretty slowly because this shot took place over the course of a couple seconds.
But using that red channel, we're sort of able to erode out the simulated chunks.
And then also by using an additional color channel, in this case the green channel, we're able to erode out, we're able to put that hot burning erosion edge in addition to eroding out the alpha.
So that's kind of how we were able to layer those together to create that soot burning up effect.
Next, I'd like to talk about that X-ray skin effect that Miles has.
So this is a sort of a rotating GIF of his arm meshes and it sort of highlights his bones and tissue and viscera.
And these sort of reveal in that sequence, they kind of flash on at certain points.
And we drove this through something called Parallax Occlusion Maps.
But this was a really important part of expressing who Miles is as a character through visual effects, because this is really a power that's coming from inside of him. We thought it was important that, you know, the audience and the viewer be able to see inside of him.
So.
This is his skin texture that we use to drive those parallax occlusion maps.
This is sort of a current-gen technique. I'm sure many of you have used gray packs before.
I've also heard this called texture packing, but it's simply where you put different materials inside of your red, green, and blue channels because you really only care about that black and white information on those channels.
So basically, we use parallax occlusion mapping for bones and veins.
That's essentially kind of like a height map that doesn't displace the surface of an object.
We use it to fake depth.
It technically uses ray marching and it is expensive.
And it's sort of painted and authored like height maps.
But parallax occlusion maps, I mean, you essentially want to use these any time where you really want to get that sort of fake depth.
It's really good for kind of pushing downwards.
It's really good for craters, but we kind of saw an opportunity here.
This was actually one of our artists, Jenna's ideas, just to be able to use it to fake depth on a character.
So you can kind of see the inside of them.
So, at least when it comes to the material graph, the parallax occlusion maps are actually these UV modifiers that go into the UV texture.
So you can kind of see here the parallax occlusion information is kind of going into that UV channel.
And you know, on the blue channel, we're using that blue channel texture to drive just some of the cloudy noise inside of miles.
We're using the red channel to drive some of the squiggly veins inside of his arms and then the green channel is the one that's primarily being used for his bones.
And then...
This is just another example of this.
We're using more parallax occlusion to drive that squiggly look.
So we actually are using some UV translate in this as well, so that as it's moving, you get some additional motion.
So you can see that UV parallax occlusion, UV modifier feeding into the UV translate nodes on the bottom.
And this is a you know, just a really useful technique to kind of get some additional motion into the depth just by using some UV translate nodes to sort of get that additional motion.
Next, I kind of want to talk about Mega Venom Blast.
So this is sort of the penultimate venom power that Miles has.
And it was really important to us as we were working on this that it looked like the comic books.
It's also biological in nature, so this is something that comes from inside of Miles.
This differentiates him from Peter Parker, who uses more technical gadgets.
It was important for us that it felt web-like.
So this is something that is Spider-Man's electricity.
This is not, you know, Electro's electricity.
This isn't the electricity of some other hero.
It also needs to work in 360 degrees.
So we really need to be able to see this mesh in gameplay.
And this is really the ultimate in Miles's powers and the expression of himself.
And it really needs to support our game pillar of an explosive new Spider-Man.
So this was one of my favorite pieces of art of Mega Venom Blast from the Marvel Comics.
You can kind of see here it has that really nice sort of graphical look.
Spider-Man is just in the air.
And as he's letting this power out of himself, it sort of explodes into this web shape.
And this was a really powerful image.
And, you know, it's really a challenge when you're looking at something like this.
It obviously works really well in the 2D sort of graphic state.
But, you know, the question we have to ask ourselves as real time effects artists is, OK, well, This is wonderful, I love looking at this.
How do I get this to translate into three dimensions?
So this was the one that we ended up having in the end on our game.
As you can see, it goes out in 360 degrees.
We have a little electricity on miles and then he jumps up in the air and he does this mega venom blast.
It does have that kind of web shape to it.
We layer in a couple of different particle quads as well as this large venom mesh that we use to sort of drive that look.
So this is sort of what that looks like in our editor.
And as you can see, we use quads, sparks, we have an effects light on there.
I believe on the PlayStation 5 version that light is also a shadow caster.
We have all these elements sort of working together along with this 360 degree web mesh.
So when you look at the mesh by itself, when you isolate that, this is really the heart of MegaVenom Blast and that explosion.
And it's driven by this mesh that we used, and we found that we could use more vertices on next-gen especially.
But it's driven by this mesh, and it's driven by a material sort of coursing through it.
At the end of the day, I mean, it's a relatively simple technique, but what makes it effective is that we have more fidelity on this mesh than what we could have on previous generations.
So this is what that looks like in Maya.
This is just the mesh in question for Maya.
And really, we kind of fight on next generation platforms that we can utilize meshes more thoroughly.
And I'm really hoping that for anyone looking at home, you know, just wondering how can I push visual effects for the next generation?
you know, you consider just using more meshes, you can probably get more fidelity in your visuals that way.
The other benefit to building effects in this way is that it also sort of minimizes overdraw.
So, you know, when you have more of this negative space that's actually negative space and not, you know, just alphaing out on materials, it kind of saves performance in a different way.
I mean, it is more expensive on the vertices side, but you're not really paying those overdraw costs that you would pay if this was all quads.
Next, I want to talk about the venom sleeve.
So one of the things that we had to figure out was having electricity crawl down Miles' arm.
This was, and it was really important that it felt biological, that it was kind of, you know, inside of him, that it was coming from him.
So this is different from Peter's technical gadgets.
So Miles has his own Spider-Man.
He is sort of generating the power from within, whereas Peter Parker creates gadgets.
So we really had to ask ourselves, how can we get this Venom electricity that comes from within Miles Morales working on all of his suits?
And how can we get it looking good?
Because one consideration with the Spider-Man games is that the player can unlock different suits.
They all have different silhouettes and different shapes to them.
So, you know, we really needed something that would fit very, very closely, you know, basically be inside of the mesh.
as well as give us that fidelity across different suits.
So I think this is one of my favorite examples of the venom sleeve in action.
This is kind of right before that large reactor shot that we already talked about.
But here, Miles is absorbing that reactor energy into himself.
and we also sort of use color storytelling in here. This was actually one of our artists, Jenna's idea, but as Miles is taking this blue new form of electricity into himself, it changes into yellow venom electricity as he can train, gets mastery over it. Some other details in here that I really liked that we did, if you look closely at his rib cage, you might see like a bit of a silhouette of a rib cage in there. Also his skin is kind of flashing again with some parallax occlusion. You can kind of see hints at his skull just to sort of give that feeling of you know this is really affecting him and this is a really big moment in the narrative as his moment of sacrifice. So the way that we sort of did the venom sleeve We created this mesh that goes over all of Spider-Man's suits.
So it's something that our character team ended up modeling and skinning and implementing on all of the different suits.
Then we just sort of had a universal texture that a material set with different wipes is sort of applied to all of those same meshes.
We also worked with our gameplay team so that this suit isn't technically on.
all the time, mostly because we found that it got expensive to have all that alpha on the character at all times.
So our gameplay team very carefully, cleverly put this into look groups so that we were able to turn this on when we needed to and turned it off when we didn't need it.
This is kind of similar to the Parallax Occlusion maps with like the bones and the viscera.
We use a gray pack texture here to drive the different veins for the Venom Sleeve reveal.
So that was just really beneficial because as this was a cross-platform title, we found that texture memory is still a concern on PS4 especially.
But this was still a useful technique on PS5 as well.
So we basically split those different visceral channels out into, you know, we use our red, green, and blue channels separately.
You know, and here we have the mirrored texture kind of being split, and we can sort of select the left and the right side of it.
And then here are sort of the controls that sort of drive that wipe. The progression node in the bottom left, that's sort of the main driver that we use most of the time for driving this reveal over time.
It's supposed to be a gameplay team who has control over how fast or slow that needs to be, depending on when and where we're using it.
We also have some additional knobs in here for some key moments where we need to tweak the speed of Venom.
So another thing that we did within the venom sleeve that we found to be very beneficial was using a displacement, just a little bit of displacement to prevent clipping.
So that was kind of helpful to ensure that the sleeve works on all of Miles' suits.
So anytime he bends his elbow or deforms his shoulder, by offsetting a little bit in the material and by pushing it a little bit toward the camera, we're really able to prevent any clipping and to make sure that this is properly visible at all times. Another place where this is useful is also in the fingers, just because there might be a lot of clipping there. All right, so thanks for talking to me with me about Venom powers. Now we're going to move on to camouflage and invisibility, which is another one of Miles's key powers.
So this is an early piece of concept art. This kind of shows Miles turning invisible.
So there's a lot of things in here that we ended up...
using in the final version of Camouflage.
Things like the fact that he's tinted a little bit blue, he's invisible, of course, he has a fresnel on him, he has the chromatic aberration inside of his body.
We didn't end up using everything in here.
We didn't make the enemies red, we didn't really do a full screen effect, like what's in this concept.
But a lot of these early ideas did end up making it into the game.
And this is the in-game version.
So this is sort of where Miles turns fully invisible.
And this basically took us three different materials to pull off.
The chromatic aberration that was in that earlier concept is something that you can also see here.
So you can really see that the green and the red channels, especially if you look at the windows and the distance through Miles, you can really kind of see that those are a little bit offset from each other.
And you can also kind of see that a bit on the snow through his legs, but I think it's most prominent on those windows.
There's also that transition, so he kind of starts fully opaque, and he sort of gets that kind of like patchwork transition where he turns invisible.
So the way that we sort of pulled this effect off, we used some things called precomposite and postcomposite materials to drive that transition. Precomposite materials are materials that erode out of mesh, so these sort of tell the pixels to not be drawn. And those are applied, like if you think about your render order, those are applied basically before the materials are drawn.
The post composites are materials that apply after the main material is drawn.
So the post composites are materials that basically in the render order we draw everything we put the post composites on after.
So that's how you can kind of think about pre's before post is after.
That's why they're called pre and post composites.
In general, these materials are really useful because we can apply them over entire meshes without them being material overrides.
So they're reusable.
We can put them on all sorts of objects in the game.
You know, they're something that we utilize a lot in our workflows.
And the camouflage effect, it required both a pre and post composite shader where after the transition is complete, then we go to a complete material swap and take a sip of water.
So this is the precomposite material.
You can kind of see the alpha erodes out.
It erodes out the mesh before the pixels are fully drawn.
So with the precomposite, this is sort of a yes, no, is there, is not there kind of setup.
We don't really have like a shades of gray width and that's just sort of because of where it sort of comes in the material rendering order.
However, it's still really useful for cases like this where we want to fully erode out somebody.
This was the post-composite material.
You'll notice that the erosion pattern on it, this mirrors the erosion pattern in the pre-composite material.
So they're basically the same except the post-composite is inverse.
So as the pre-composite erodes out, the post-composite erodes in.
And it contains similar shading information to the main shader that has that chromatic aberration in it.
You know, it's blue, it has that fresnel.
The math is basically the same between those two, except the post-composite also has that erosion information because it's used for that transition between the solid and the invisible state.
Once the erosion is complete, we do a swap at that point for the main invisibility shader.
And the reason why we do that is because having the pre and post composite shaders is more expensive.
If you do that whole material swap, that ends up being cheaper, and that was more performant.
And because this was a cross-generation title especially, we needed to make sure that it ran in frame on the PS4.
And then this basically...
applies over the pre-composite when you do that swap.
It allows for the illusion where milestones are visible while also having solid parts.
So when we set this up, our gameplay programming team is wonderful.
They set up these configs for us so that we can implement our effects into the game using them.
So we did need some help from our friendly neighborhood programmers to make this happen.
And then, oh yeah, chromatic aberration.
So the chromatic aberration is really driven by offsetting the red and the green channels from each other on the frame buffer.
So you can kind of see we have two frame grabs there.
They're eventually being combined into one where the red is being combined separately from the green and blue of the other.
frame buffer. And then, you know, earlier on in the math, we're just offsetting one of them by like 0.01 and we're offsetting the other by negative 0.01. So those offsets are just a little bit, you only really need a little bit, and then that ends up being combined in the end to create some chromatic aberration.
So we also found as we were working on camouflage that we needed some special one-off variants.
So there were really some...
cases in the game where Miles had these emotional beats, and originally we didn't set up camo to really have any other timing except for that zero to one.
However, we really wanted to make sure that we were including these moments using visual effects to sort of help the player understand times where Miles was doubting himself or when he was scared or when he wanted to hide.
And this required a few custom setups to make it happen, but it was totally worth it to help Miles become his own explosive new Spider-Man.
So one such example, this is actually the first time that we see camouflage in-game.
In this moment, Miles is threatened by Roxxon forces, and we had to slow down the camouflage transition to really make this feed feel good.
So the transition is usually about a second long.
And it's basically that zero to one parameter material we just talked about.
But our programming team exposed some knobs for us in the cinematic so that we were able to really slow this down.
And I love showing this beat too, because especially when the camera is looking right through miles at those ROXON officers, you can really see that chromatic aberration there.
Another time where we had to do this was this moment where Miles, this is right after the bridge explodes, and he doubts himself as Spider-Man and he's not really able to control his camo powers, so his hand by itself turns invisible.
And in order to get this beat, the camo ability was sort of designed to go over all...
of the character. It wasn't really designed to go on one part of the character. So our character team sort of split that hand off to be its own mesh. And then we made a custom material, so the pre-composite material is really only eroding out his fingers. And this was really nice because it kind of gave Miles that moment where, you know, he's able to question himself before realizing that, yes, I am Spider-Man and I can do this.
This was another camouflage beat that we did where Miles tries to disappear.
This is right after he's captured and the Roxxon guards are hitting him.
And we had to speed up camo in this beat.
We had to make it really fast just so he could try to go invisible and then he'd get hit and then he would come out of it.
And this is sort of building up right to the moment before we do our first mega venom blast.
So it was a really fun beat to work on.
All right, next we're going to talk about creating spectacle.
So Marvel's Spider-Man Miles Morales is a game that really requires intensive spectacle beats so that Miles can demonstrate his heroic abilities.
So one of the challenges that we asked ourselves while we were working on this was, how do we up this for a new generation for what we accomplished in Marvel's Spider-Man?
One of the solutions to that was coming up with a new simulation pipeline.
So, AnimChunk is our new rigid body pipeline, and we developed it to replace the previous pipeline we had in Marvel's Spider-Man.
This new pipeline that we developed, thanks to the fantastic work of our core team, it allows us to get in high-quality large-scale simulations more quickly.
And a large part of why we developed this is because spectacle is overall very important to the game.
So a really good example of this new pipeline comes in from our bridge trailer and also our bridge mission.
So this particular sequence is in the bridge mission.
It's when the bridge kind of comes down and miles in this sequence is It's really sort of a moment where he develops himself as a hero.
And this particular simulation, this had over 250,000 vertices.
And I was really proud of our art team for working on this, including Matthew Bennett, Jin Choi, and Alex Heligo.
They were able to really push the next-gen fidelity and spectacle on this.
Next, we're going to talk about one of the simulations that we did for our Winter Break mission.
This is actually the opening mission to the game.
This particular sequence was a really good example of using both of our new simulation pipelines.
So this includes both the rigid body atom chunk pipeline that we just talked about, as well as our soft body atom vert pipeline.
So the soft body can really be seen on the streamers that fall down from this happy holiday sign, as well as the atom vert can really be kind of seen on those chunks of the sign as it comes down.
One thing that was really great about this sequence was that we were able to push the fidelity in terms of sparks and debris particulate coming out in this sequence.
on the PlayStation 5 even more so than we could on the PlayStation 4.
And this was a kind of a really great place where we were able to really leverage that hardware in terms of creating that spectacle. And then another sequence that I thought was really great that we were able to really push for next gen is a sequence where this power plant explodes.
The next-gen hardware afforded us the ability to have more particles, as well as shadow casting lights.
If you look at some of the lights on these explosions on the ground, especially in this part right here, it really added a lot of drama.
And the next-generation hardware was a place where we could really allow that to shine.
Next, I'm going to talk about Programmable Matter, which is essentially the energy weapons that Miles' nemeses, the Underground, use in their game.
So with Programmable Matter, Miles Morales, as a hero, we kind of needed to give him a really new enemy in order to complement him as an explosive new Spider-Man.
So this is where the Tinker and the Underground come in.
They used nanoparticle-driven weapon tech called programmable matter in the game.
And of course, we as VFX artists had to come up with a solution for that.
So we had to come up with new and different effects systems to be able to support this, to make it unique and different from what we accomplished in the original Marvel's Spider-Man.
So one of the first things that we did when we were working on programmable matter was come up with a list of rules for it, so that we sort of understood what it was and how it worked.
So we decided that programmable matter required nanotech printing.
It formed an internal lattice, so it had a support structure inside of it as it printed.
It was always printed from a source, so this never came from the air, it wasn't magical, it was always something that was tangible and came from a specific place.
It is technically a metal, so programmable matter, it is metallic, it's not plastic, it has metallic properties to it.
And it's always created by Finn Mason, who's the tinkerer in our game.
So this was an early pre-visualization of programmable matter that we did to sort of help us cement what this looked like.
And originally, programmable matter was green.
Of course, we ended up changing the colors while we were working on it.
But this kind of demonstrates some of those early principles that we came up with.
for this. So you can kind of see it, it comes from a source, it creates an internal support structure as it prints.
You can kind of see the particulate sort of spread over it as it comes into its final shape.
And this was a really kind of a great guiding pre-visualization for us as we work to translate this into real time.
One thing that we wanted to leverage when we were working with this was GPU particles, which is something that we didn't have on the original Marvel's Spider-Man.
So this is kind of what we had in game in the end.
So you can kind of see that a lot of that original pre-visualization made it into the game.
So we do have that internal structure that kind of prints using a material graph that is followed by support struts on the inside, which kind of prints the skin on top.
We leverage a lot of GPU particles with a little bit of noise on them to kind of help.
fill everything in at the end.
And then, of course, we also use particle lights just to sort of make sure that everything kind of ties into the scene correctly.
So the inside of the programmable ladder lattice is controlled sort of like a material wipe.
This is driven much like we drove our sleeves.
So this is driven with a wipe that is controlled by vertex colors defined in Maya.
And we use a lot more geometry for detail.
So one big thing about next gen is that, you know, you can use more vertices and leveraging vertex wipes really allows you that precision to kind of give you that really controlled sort of look you're looking for, especially in any kind of cinematic beat where you really want to have control over that.
The inside of these lattice models also contained an additional mesh.
So these were sort of the interior lattices that went inside of each of those segments as they sort of snapped into place. And we use this in the cinematic as well as the gameplay versions. So a lot of segments are sort of driven with the same sort of technique where you have the vertex colors controlling a precise wipe.
And then when it comes to timing that, this is just sort of a custom input value.
So we have the x in that custom input node.
That is something that is exposed to us and that we can manipulate and control and keyframe in the particle editor.
So we use custom input values quite a bit while we work, because it gives us more precise control over the timing of when those come online.
Another thing that we used quite a bit was GPU particles.
So a lot of the underground attacks are driven by GPU particles.
So you can kind of see, this is the gauntlet enemy's AoE impact.
When the enemy hits the ground, it creates this awesome shape.
They actually destroy their programmable matter technology as they do this.
So GBA particles were new to Miles Morales since we had a CPU driven system only in the first Marvel Spider-Man.
So because this was new technology, we really wanted, well new to our game engine, because it's something we hadn't had previously.
We leveraged it heavily when it comes to the underground attacks.
And we use them to help Parabola Matter feel more threatening and unique and different.
So this is the main gauntlet enemy attack.
You can kind of see that he jumps up in the air and he punches the ground.
He breaks his gauntlet mesh and he reprints it using one of those detailed material wipes.
And another thing that we used in here, if you look at this you can kind of see that it has a mesh that distorts and it creates some really awesome looking shapes as it...
spreads out as a shockwave. And it's really using GPU particles in this instance helped to make it feel a lot more unique versus what we had in our previous game. Next I want to talk about webs.
You can't really have Spider-Man without webs, so I thought it would be important to talk about that.
So with webs, webs are one of the things that make Spider-Man, Spider-Man.
Peter and Miles share webs, and we didn't really change these much from Marvel's Spider-Man.
However, it's still kind of worth reviewing how we did it.
Webs are a team effort between VFX and many other departments, including animation, rigging, rendering, and gameplay.
And it's one of the things that we get asked about the most.
So I wanted to make sure that I included it in this talk.
So the first thing I want to talk about are the traversal webs.
So these are the webs that Miles uses when he's swinging across the city.
So you can kind of see here, this is in the bridge mission where he's swinging around.
It's basically just those web lines that he uses to get all over the place.
These are basically splines. They're programmatic in nature.
On the effects team, what we do is we control the shader material that goes over the webs, as well as the web knots that are placed over the spline.
So with the traversal webs, the knots are basically meshes that are placed procedurally across that spline.
And then the webline itself is programmatic.
So we didn't really adjust this much from Marvel's Spider-Man, but I still think it's a pretty cool system and worth talking about.
Another web system I wanted to talk about are the web jackets.
So these are webs that the players can put on enemies during gameplay.
They serve a function in gameplay.
They allow the player to immobilize enemies.
And essentially because they are webs, they do need to be skin tight to fit over the character.
So with these kinds of webs, we have face webs as well as the body webs.
Each of these kinds of webs are skinned in Maya to each character model.
So we have to get that character in the proper bind pose, and then we create layers of meshes over it.
We do have our meshes set up in such a way that they play nicely with the UVs and materials in our engine for webs.
And the materials for the webs, they basically drive the terrain and the appearance.
So when these go on and off, they kind of erode in and out.
A lot of that is material-driven.
Next, I wanted to talk about the Stick Stuff Together web.
So these are the web cones and web tunnels.
You can kind of see them here where Miles is trying to stop this bus from going over the bridge.
He places a number of web tunnels on the bus.
And these are, we kind of call them Stick Stuff Together webs, but they're really sort of a collaborative effort between departments.
When we create these, they're modeled in Maya using a custom tool set up for creating them.
And the materials are then applied in engine to these.
And after that, they're rigged and animated by our tech animation and animation department.
So on the effects side, a lot of what we do is mostly just generating the initial meshes and then we'll generate the materials that go with it.
However, when it comes to controlling them and animating them and placing them, a lot of that is done by our animation team.
And webs are really a team effort.
So something that I thought was really important to touch on in this talk was accessibility.
Accessibility was very important for us for Next Generation.
And at Insomnia Games, we had a really big push to create the most accessible game possible.
So many departments, including visual effects, decided to pitch in and see what we could do to make this game one of the most accessible games we've ever made.
So we had this philosophy of anyone can wear the mask.
Basically, we thought anyone should be able to be Spider-Man.
And we wanted as many players as possible to enjoy that fantasy of being Spider-Man.
So released within the effects team, we sort of drove what we called contrast features in Marvel's Spider-Man Miles Morales.
And we found that we could have a really big impact on the game in this way.
And I'll get into what contrast features are in a second.
One of the things that we created for this was the high contrast background.
So that is designed to help low vision players enjoy our game.
This is essentially a full screen quad that we put over the screen that desaturates the world.
And then after we desaturate the world, we'll flag relevant effects for combat to draw on top of that full screen quad.
And we'll also add high contrast shaders to enemies and combatants and relevant objects to gameplay in order to help them stand out.
And this is kind of what that looks like in action.
This is, you can kind of see the skybox is darkened, the enemies get bright shaders.
relevant effects to the combat, drawn on top of that background. So this is a really beneficial mode for anybody who has vision issues, anybody that might have cognitive issues. They might benefit from this because it basically reduces visual clutter and visual noise and it tells the player...
you know, what is important for them in combat. And we found that this was very helpful for a variety of players. And part of why this is so important, I'm going to get a little personal with this, but this is a video from the original Marvel's Spider-Man, and this is the Fisk boss fight. So this is the first.
boss fight in that game.
And my fiance is a low vision player.
And when he played through this segment of the game, when I went to watch him play it at home, he was unable to get through this segment of the boss fight.
And the reason for that was because he was unable to tell the difference between the boss and the ads.
And looking at this as a visual effects artist, I know this is a problem that we can solve, especially as a real-time effects community. I think that it's something that pretty much anybody could come up with a solution for. So the solution that, well, this is just sort of a simulation of what that low vision looks like. So this is actually a simulation I did of my fiancé's sight. So he's losing some of his central vision.
So for a low vision player, you can imagine it's very frustrating when you're playing in a fight like this.
You're not able to really tell who's the boss and who the adds are.
But thanks to the contrast features that we added to Marvel's Spider-Man Miles Morales, my fiancé, I'm glad to report, was able to play through that game entirely by himself without assistance.
And part of that was because of these contrast features that we added.
And at least for me personally, I think this is probably one of the things that I thought was the coolest part of creating a next generation title, was really thinking holistically about game development and thinking about ways that we can make games more accessible than ever to new players.
And honestly, this is probably one of the things I'm most proud of.
So one of the tricks that we did for the high contrast background was basically making the skybox really dark. So in order to detect the skybox so that you can color it something other than skybox colored, you just have to compare the depth buffer to the far clip value and you can just do a lerp really easy. That darkens the skybox while keeping the foreground intact.
So another thing that we did for this title was develop contrast shaders.
So the contrast shaders are designed to be bright and easy to spot for low vision players.
They're also customizable, so players can select different colors for ranged enemies versus melee enemies versus bosses.
And it's really important to us, at least for our game, that players are able to distinguish those.
Of course, everybody might have a different solution for their own titles.
It worked for us in Spider-Man.
might not work for every game out there.
So hopefully you can kind of look at this and think about ways that you could develop a similar mode for your own game.
So the contrast shaders are sort of set up in a config file.
And this is driven by our gameplay team, who is wonderful and set this up for us.
And this ties into our UI for easy player customization.
It was really important for us that the players were able to pick different colors and customize their experience.
So lastly, I'm going to talk about some of the challenges we encountered for the new generation and some of the takeaways and learnings that we had.
So some of the challenges that we faced with this title was that Marvel's Spider-Man Miles Morales really needed to be a next-gen title while also at the same time being a cross-platform title.
It had to release on the PS4, too.
So one of the challenges we had was how can we make a game perform on PS4 while still finding ways to push next-gen quality?
One of the solutions that we came up with that was, I think, really helpful was that within our internal editor, we basically set it up so that we could split some of the particle emitters per platform.
So in this example, this is actually a smoke emitter, and the smoke emitter is flagged to be PS5 only, and that's because we wanted this particular smoke to cast shadows, and it's disabled on the PS4.
And there is a similar PS4-only emitter within this effects package that doesn't have shadows on it.
So this was a great solution for us to be cost effective in terms of not needing to re-implement some of these emitters multiple times.
And it really helped us out in terms of delivering that next-gen quality.
So with this system, with the PS4, PS5 emitters, it allowed us to selectively add a bunch of particle upgrades for the PS5 that might have been unperforming on the PS4.
Some of those included making more of our particles lit.
We were able to afford more particle lighting on this generation, which definitely added more drama to our effects.
More shadow casting particles, so those large columns of steam, we were able to have those cast shadows.
We were also able to have more shadow casting particle lights.
So those are for instances when you want to have a light inside of an effects package that casts a shadow.
We could afford more of those and switch between the PS4 and the PS5.
We were able to afford denser smoke and fires.
So, you know, in order to get things performing on the PS4, sometimes we couldn't afford quite as many embers or smoke as we wanted to, whereas on the PS5 we could afford more.
So we leveraged that system in those cases.
And we can also afford more GPU particles in some instances, which was wonderful.
Some other limitations that we ran into, the PS4 had more memory limits compared to PS5.
Part of that meant that simulations had to be smaller for the PlayStation 4, unfortunately.
We were able to afford more on the PlayStation 5.
Text to memory was more of a concern on the PlayStation 4, so we were limited to how many smoke maps we could use on that console versus how many variety of maps we could use on the PlayStation 5.
Loading times were also something we had to be mindful of.
So the PlayStation 5's solid state drive meant that we were able to load scenes very fast.
Unfortunately on the PlayStation 4, we had to preload in simulations a little bit earlier just so that we could have that play correctly on time.
Some other findings, the PlayStation 5, it had more memory in the solid-state drive, so that was a huge advantage. So we were able to load in our simulations very quickly on that platform.
The GPU, it definitely needed more space for ray tracing. So one finding was that although we could afford a little more GPU particles, that didn't mean that we could go crazy, right? You know, just because we have a great new hardware doesn't necessarily mean that we can, you know, go to 11 with GPU particles.
We also found that we still need to watch overdraw on next-gen, so alpha and overdraw is still going to be expensive.
That's one of the reasons why leveraging meshes with negative space worked out so well for us.
And one of the big wins was that we could afford more vertices on the PlayStation 5 versus the PlayStation 4.
And that was a huge benefit that we definitely leveraged.
And that allowed us to use more meshes where it made sense.
However, we still had to be careful to watch vertex density.
So whenever we had really small splashes, we couldn't put 10,000 verts on something like that.
We still had to be somewhat mindful of how dense the vertices got.
So some general learnings from working on this project, just the non-technical learnings.
The ambition of NextGen was a little nerve-wracking, but one of the big takeaways for me was that you can't create great things if you don't try, and it's definitely okay to be a little nervous.
When you're feeling a little nervous, it means that you're on the right track and you're going outside of your comfort zone and making something wonderful.
An example of this is when we had to build our Annenverte pipeline to make that reveal shot a reality.
Because the simulation, it was really important that we saw the fabric tear away so we could reveal who Miles was.
And if we hadn't really taken that leap of faith, I don't think we would have made a shot as great as that shot was.
And we wouldn't have developed this wonderful new pipeline that we can use in our engine.
We also took a chance on accessibility features, and we delivered a much more accessible game.
So one thing that was really wonderful working on this title is that, you know, I didn't really go into this title thinking that, you know, it was going to be the most accessible game ever, but the more passionate we got about it, the more excited we got about accessibility, and the more the studio rallied behind creating the most accessible game we could.
I feel like we really kind of pulled together and made something great.
And it was really personally satisfying to see someone I care about be able to play through the game from start to finish by himself, even though he is a low vision player.
And one of the benefits of this too is that we found all kinds of players, not necessarily just low vision ones, benefited from the contrast options.
We were also able to give Miles his own unique powers that were different from Peter's through visual effects. So it was really wonderful to be able to tell that story and to tell that narrative of Miles becoming his own hero and Miles having his own experiences through visuals.
Some other additional learnings, when working on new hardware, old techniques can be leveraged in new ways.
So using vertex blending with detailed color usage to drive material transitions.
So we were able to leverage more vertices and that was kind of new, but vertex painting, I mean that's kind of an old technique, but blending the old with the new was kind of a big discovery on this project.
I also learned that it's really important to thank your programming team for all the amazing work that they do to enable you to push toward a new generation of greatness.
So a lot of what we did and what we covered in this talk wouldn't have been possible without our wonderful programming staff.
They really enabled the visual effects team to do their best and be their best.
I also learned that over-communicating is good.
On this project, we really had to rally together to create something wonderful.
The more that we work together and problem-solve together, the better we were able to deliver this project.
And lastly, you know, I really love this project.
The people I worked with were some of the best in the industry, and I'm really proud of what we did together.
And I'm really glad that I was able to talk with you all about the effects that we did for this game.
And thank you very much. Let's have some Q&A.
