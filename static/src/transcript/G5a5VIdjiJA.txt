everybody. Welcome to the job simulator postmortem. We're going to be talking about the design, tech and business lessons learned from job simulator. My name is Alex Schwartz, and I'm the CEO and janitor of Alchemy Labs. And I'm Devin Reimer, CTO, chief technical owl at Alchemy Labs.
So first off, if anyone doesn't know what is job simulator, we're going to show an abbreviated version of the trailer for a couple seconds.
Time to jump.
This looks like it'll taste interesting.
Pistons in the engine, don't eat those.
Delicious!
You've been doing a really good job lately.
I think it's about time you got a promotion.
Hooray! It's five o'clock!
Woohoo! It's time to go home!
Yeah, I'm gonna have to ask you to come home.
Saturday.
So shout out to Kurt Garner who did the trailer on this that we cut apart for this part.
All right, so we're gonna talk about what went right, what went wrong, and the story of the conception of Job Simulator and what we learned throughout.
So who has 14 hours to sit in this room and go through the whole story?
No, we're gonna share some of the most relevant things that we learned and hopefully leave time for questions because this is such a expansive world of VR from all different topics, so we'd love to get some questions at the end.
So let's roll back in time to a time before VR, where we smacked rocks together, apparently.
So we at Alchemy Labs, we started the company back in 2010, and we've been working on PC and desktop games for quite a while.
We shipped Jack Lumber and Ah and Snuggle Truck and Discourse with a small four-person team before the days of VR.
And then the Oculus Rift Kickstarter happened.
When we received the DK1, we realized that VR was going to be a thing this time.
So we dropped what we were doing, which at the time wasn't a thing that we just did, drop stuff.
But we realized this was so important.
So we started work on a port of Ahh to bring it to the Oculus, and we called it Ahhculus.
And it ended up being the first VR game on Steam that wasn't made by Valve.
What ended up happening was we ended up doing this port and started thinking about what was next.
We wanted to make some more VR content, but we ended up running this problem as every one of our game ideas had this like, seemed like it needed to be compromised to fit into the form factor of VR.
Nothing ended up feeling right, and we knew that we didn't want to make a game with motion sickness at all.
We wanted to make sure that VR was a thing for everyone.
So that's the moment that we got invited to do Valve's room demo at Steam Dev Days 2014.
And it was like a religious epiphany going into that room and putting on that headset and realizing what it felt like to have.
sub millimeter tracking that you can move about a room. It really changed everything for us. And that was kind of the start where we said 100% of our efforts moving forward are to try to realize this vision in some kind of consumer product and build games for it. But at this time you've got stickers all over a wall. No one would ever do this. And kind of walked out of that room feeling disappointed because how would this ever happen in someone's living room? It seems so far away and academic.
and that's when we got invited to a meeting and Valve and HTC told us they would be actually productizing a thing called the Vive and said, would you like to drop everything you're doing and try to build some kind of show piece for GDC? By the way, we can't get you this hardware until a couple weeks before GDC so would you want to try to do something completely insane and build something for it? And we said, of course. And since we were all remote as a small company, we We decided to go up to Winnipeg for a couple reasons to Devin's house.
One was that Devin's wife was eight and a half months pregnant with twins.
And that, I don't know if anyone knows, if you fly at that level of pregnancy, it's like, you can't go anywhere, you're grounded, you're stuck.
So we all went up to Winnipeg in the middle of the winter, which was a fantastic move.
Yeah.
No, don't clap for that.
And so we went and we got this shipment of this early Vive dev kit, and we had one week together to try to build something for GDC.
So let's talk about how that went.
So when we said that we were going to go do this, we started thinking about what would be interesting in VR when you had hands and you could move around.
And the early idea was a WarioWare-like game, where it's like a whole bunch of different mini-games.
That means we could explore a lot of different spaces.
The first thing that we ended up doing, because when we got the hardware there was literally nothing for it, right?
So we just got this thing and we had to start building what we wanted to actually see.
And the earliest example we ended up doing was we ended up building three cubes and we put them on a table and we added physics to them so you could pick them up and throw them.
And instantly it was just this thing, it was like, whoa, this is super cool.
And we ended up feeling that kind of like, I am a small child and I'm manipulating objects for the first time and I'm stacking them and I'm doing lots of interesting things with them.
Like literally that's how it felt because that's what I was doing sitting on the floor here with some cubes.
So we realized that hands were the key.
They were the simplest input and when you added physics, things got incredibly interesting.
So once we kind of got past the point of, OK, we're going to be using our hands to do some kind of mini games, we continued forward with our thoughts that we should build a couple weird little mini games.
And so the first thing that we had a dock, and we were just listing bad ideas.
And so we thought, OK, a circus performer.
And so we started to build something where you could balance some kind of pole on your hand and throw a ball.
So we prototyped that.
We also prototyped a really quick version of a, you're a window washer on the 52nd floor of a skyscraper, and we thought we were super geniuses because we put two little levers which would move you left and right on the building and up and down, and then you'd pick up a little squeegee and you'd wash windows.
By the way, that was terrifying.
So we had some people buckle and just lay on the floor and start crying, can't do it.
And then we thought, okay, maybe you could be a chef.
and so we started prototyping a quick area of kind of like where a line chef would be doing their work.
We also modeled out and started prototyping a bartender simulation, and we thought, okay, it would be really cool if we have kind of slippery physics and we could end up pouring and then throwing these kind of glasses down the table, root beer tapper type of thing.
And so we started to see what some of the commonality was, is that near field manipulation, where you can physically walk over to something and pick it up and use your hands and grab within the range of where you can be, was extremely awesome.
And so we needed to build stuff where things are all around you.
And then we kind of realized everything that we were doing you are kind of doing a job.
You're assuming the role of a profession, so these are all kind of jobs.
And so I opened a Google Doc and I titled it Job Simulator as a temp joke name, and then we went forward with our bad ideas from there.
And the kitchen seemed to have the most promise as a current prototype, so we thought, let's just kind of not work on everything else and push forward on making some kind of VR kitchen and see where it goes.
And yeah, now we just have to kind of build a GDC demo now with what, four days left.
So what we ended up discovering very early on is that expectations can kill you.
We had a huge problem with the kitchen.
Everyone had preconceived notions of how a kitchen would work, how you made food.
And now we need to realize this in VR.
We realized that we needed to satisfy all these expectations some way or another, and realized that if you can't deliver on something, you either need to come up with something really creative, or you just need to cut it.
So two examples are the rolling pin and the knife we want to talk about.
So first, the rolling pin.
So this was an obvious thing to model, a rolling pin in a kitchen makes a lot of sense.
You can pick up an object.
You can interact with it.
But it had affordances.
And one of the affordances is that it could flatten things.
And so people would try to grab this thing with two hands and try to flatten objects.
And this was a physics nightmare.
So we ended up realizing that the rolling pin just couldn't exist, and we realized that every single object needs a purpose.
It's not just enough that it's pick-up-able.
Every single object in Job Simulator has some underlying purpose.
So the knife was an interesting one, and let's go into this.
So basically, everyone thinks there should be a knife in a kitchen, and so we put the knife in, and then everyone wants to cut something, so we said, okay, we need to add a cutting system.
So we wrote our own dynamic cutting system that would ray cast through cuttable objects, build the interior meshes on the thing that got split, create rigid bodies for all the pieces that got created, and here's the first thing that everyone did.
is they grab the knives and then they chop chop chop chop chop chop chop chop and so anyone who's done any work in like video game physics would start tearing up at the fact that that you've now got like 30 interpenetrating rigid bodies that are falling and shaking through the table and now your frame rate's starting to dip because you took a piece of celery and made it into 40 celeries and so it's this rigid body nightmare so we thought We are gonna joke our way out of this one.
We're gonna make awesome knives that when you cut, they shatter into pieces.
So, haha, we got you.
Turns out that's extremely disappointing.
And so, we ended up littering the whole area with lots of knives, because that was a good idea.
The goal is to have people cut less things, and people are like, can we just have more knives?
And it was like, oh, it's kind of defeating the purpose here.
It was just glass knives breaking everywhere.
It doesn't work.
And so then we thought, later on, hey, let's task one of our engineers with the concept of.
cartoonish rubber knives that bend away from items so they can't cut things. That was one of our worst ideas ever. And so this was during development. This is some problems. Yeah. And then this was the extremely creepy end result. It's like a rubber scythe.
Um, it was, it kind of like made you feel sick to look at it.
It was really weird in VR.
Everything feels different and it's just unacceptable.
So, uh, we ended up cutting the knife post GDC build, but that's kind of the story of how one item that you think should be in a kitchen can have all of these different affordances that we can't deliver on.
So we knew that we needed a character, someone that you could interact with.
So early on, we realized that with the amount of scope and time that we had, that we needed to simplify things.
So the idea of floating robots came up because that was something that we could easily move around an environment and have you communicate with.
This allowed us to not have to rig and skin complex characters.
It was very performance friendly because VR is very, very performance intensive.
and we realized we could actually yield some empathy through the basic facial structure of a robot. So we were in this process of developing this GDC build and we were a few days in and we realized that maybe we needed an intro. Maybe we needed to figure out where the person was standing, give them some stories so that when they ended up going to the kitchen they started to understand what this game was.
This is Jobbot's office in this early build.
And you see there's this pedestal in the middle with a bell.
The thought was this pedestal would come out of the floor when you were standing out of the way.
And then when you rang the bell, you'd be positioned in the exact right location for the game.
And then super early Jobbot here would come and tell you some stories about what this game was actually like.
And this also acted like a hub world.
We had VHS tapes on this table.
And you could go over and grab the Gourmet Chef one.
And then you could plug it directly into the face of JobBot.
JobBot had this VHS hole at one point.
So we ended up having that in an early build that we sent over to Valve.
And Valve was like, you do realize you have three minutes to demo this game, right?
And your intro is like two.
So we realized, oh, we need to cut this.
It should have been an expectation and realization that we needed to shorten all the game play and get rid of the intro and not build it to begin with, but it ended up being an incredibly valuable, one of the most valuable things that we ended up doing because it ended up leading us to the premise of the game. So a game about jobs, the original premise was that it was a training simulator for people to learn how to job, but why was that a thing that existed?
It ended up through that jobbot's office.
At the time, we were doing a lot of thinking about what the future of jobs looked like.
And we were talking about the singularity.
And it was a lot of things we were talking about, like, hey, what if jobs went away?
What would the world look like?
And then we started rolling that into the actual game.
And the premise is that it's the year 2050 and robots have taken all human jobs.
And that the job simulator is actually a historical recreation of what it was like to job. It was no longer the simulator trying to teach you how to job correctly. It was the robots trying to figure out what it was like to job so that future humans could experience the same thing. But with poor Wikipedia skills that they kind of skimmed and said, I guess that's how it worked.
And so having that strong premise meant that we could have a better process.
Well, we had a better design process throughout and writing process throughout.
So, for example, one of our first tasks in the kitchen was you have to make soup.
And so with the simplicity of what we were trying to do with picking up objects and throwing them, we thought, okay, why don't we just make it so that you toss a bunch of items into a pot arbitrarily?
and out comes a fully formed can of soup.
Because I guess the robots didn't know how a real soup making process worked and they saw the two pieces and put it together in their head.
And so that allowed us to be really creative in how we were able to tackle design questions.
Like we were able to use a microwave and kind of like label it as this elite cooking device that the top chefs would use.
And so you could make a fully formed cake.
by putting flour, bread, and something into, was it flour and?
Eggs.
Eggs.
But it wasn't really flour, it was like a flour, with petals.
So yeah, it's bad puns and combinations led to this.
So we got to the point where we're starting to think, okay, we have something that's fun, now how do we do this, how do we do this?
And it turned out, even the most simple things were extremely challenging in the early days.
So the concept of how picking up items and the affordances should work visually, what does the hand show when you pick something up?
What are the rules of all the physics interactions inside of VR?
And so in these days, people were mostly just showing the controller visuals.
and not many people had shown hand visuals.
And the thing is, like grabbing inside of an item and it interpenetrates and showing your hand going through something, it just didn't feel great.
And a lot of people were also building full arm IK on your first person view, so you'd look down and you'd see your elbow in a completely wrong spot because there's no way to really predict that data.
So it was kind of a mess.
thought that maybe we could just do a quick hack and try something where when you pick up an item, your hand just goes away to lessen the overlap effect.
And it turned out, we had no idea, it turned out it was an extremely effective way and it had this kind of mental process that we dubbed tomato presence kind of as a joke, where you have hand presence with your hand.
and then when you pick up an item and you remove the hand visual, the tomato acts as like a visual stand-in for where your hand is, and it's perfect rotation and perfect position, so you still have presence, it's just your hand presence turns into tomato presence.
And so since the tomato was the first thing you encounter in the job, that's why we named it that, and now we've seen a multitude of GDC talks over the past couple years that refer to the official hiding hand technique as tomato presence.
So write it down everyone, it's going in the textbooks, tomato presence.
And so room scale was kind of this big thing. So fun fact, when we got the first headset, there was no chaperone. No chaperone. So we were walking into things and we had no ability to tell where the walls were.
And so we thought, well, how do we make an environment that doesn't, that makes it so that people feel like they are in a space where they can access everything and that the room, you know, you could stay in a safe area but build something that affords the space that you have.
And you don't want Chaperone to be the thing that stops you.
You want the world to kind of exist in a way that I don't want to go forward because there's a table here or something like that.
So a lot of thinking about that was happening right now.
So as I mentioned, physics was a super, super important thing.
And we realized that once you end up having some objects that you can pick up, you want to pick up everything.
So there's no hiding that fact anymore.
If that thing looks like something that you can pick up, you need to be able to pick it up, which ended up taking a ton of time in Job Simulator, but it is now just the way that we operate.
So this is getting closer to the end of our week period.
And then we had our lighthouse fail.
And we only had one lighthouse.
So we talked to Valve, and we're like, we need another one ASAP.
And they weren't sure they could ship it through customs to Canada fast enough.
So we decided to fall back to a Razor Hydra.
So we ended up building this setup.
And long story short, it is not even remotely comparable.
So that ended up being a waste of time.
But luckily, we ended up getting a shipment of another lighthouse just in time for us to finish up the GDC build.
Thanks, Chet.
So this is the final result of the kitchen that we ended up shipping for GDC.
If you've played the actual kitchen, you see some of it's the same, some of it is radically different.
But this is everything that's basically interactable.
Some of our old sandwich making system.
That one definitely stuck around.
And so the same thing of like serving things on a plate.
So we ended up having that basic functionality of the kitchen that carried all the way through to ship of the game.
So, I mean, it looked very primitive.
And Job Simulator in the early days didn't show well at all in video form.
But people went into this first experience, and again, this was the first time that really anyone had had true hand presence in VR and was able to move around with real accuracy.
And so press came out of these GDC 2015 demos.
with their mind completely blown.
And a lot of people called out Job Simulator as this unexpected, the kitchen thing that I played, that I just stood there and I think it was Time that said, I never knew that the most compelling experience I could ever have in a virtual world was throwing a tomato at a robot.
And so it was blowing everyone's minds and it was an incredible experience to kind of be there at the genesis of this new hardware.
It was it was amazing and now it was time to just got to build the full game right. So at that time we had no idea whether this hardware would really ship what the price would be whether this market would be a thing and so it was one of the riskiest decisions we ever made was to just push forward with this high end VR game design for platforms we didn't even know would exist or not and just said that's what we're going to do whether it works or we go out of business we're just going to push.
And that was when our colleagues, friends, family, company advisors said, hey, we're not really sure about this whole VR thing.
Maybe you should mitigate some risk and build a mobile game.
You should build a mobile game.
That's probably a better idea.
And then we said, no, we're gonna do VR or we're gonna go out of business because we're that sold that this is the future.
So in our early thought process, we thought we're gonna make 10 jobs and we're gonna start prototyping them all simultaneously and we're gonna just go nuts.
Well, not all of them, but we're gonna go with three and push forward.
And so we started on the prototypes of a chemistry lab and a magician where you're in a backyard doing magic tricks for a group of small robot children.
and a space station repairman, repair person, which that was just, hey, that sounds cool to have low gravity, let's try something there.
So then we run into a problem.
Something was wrong.
Everything that we ended up making wasn't as good as the kitchen was.
Everyone loved the kitchen, but there was something that was off with everything else we built.
It just wasn't nearly as fun.
The humor wasn't coming through, the gameplay wasn't quite coming through, and we couldn't quite figure out why that was.
So we started thinking, what makes a good job simulator job?
So we ended up getting some advice and figuring this out, that the reason was familiarity, that you take your expectations of real life into these things.
So if you had some understanding of how something was supposed to work.
then we can play with that, then we can subvert that if we wanted or we can use that to our advantage to allow you to play the game more easily. The further we got away from something that you understood, the more complicated and weird and less funny things got. So for example, let's say you're in the kitchen and you're making soup and putting ingredients in and you get a can of soup. Everyone knows you're not supposed to get a can of soup and it's funny. But if you're in this chemistry lab and you're mixing chemicals together and then it creates a crazier chemical concoction.
Did you know what those ingredients were supposed to do in the first place?
Not really, so we ended up losing that humor.
So we realized that it was like that grounding, that familiarity that was the key.
Thanks to Patrick for that heads up there.
So that brings us to The Office.
The Office is what we ended up showing so many demos of.
It ended up being kind of the demo showpiece of the game.
Most people don't know this.
That was the eighth job we prototyped.
It wasn't even on our original list when we ended up laying out those first 10 jobs.
And right now, that seems completely obvious.
But at the time, it wasn't, because we were thinking about it wrong.
We were thinking about what's the most exciting job that you can do without thinking about what would actually be interesting.
So this is a very early prototype of the office scene.
So you can see that there's some elements here that definitely carried over into the final version of the game.
Staplers.
Yeah.
So we thought, okay, let's, again, let's move forward on this office.
So let's think of all the tropes we know about every office thing, think about office space.
We have to open with donuts and coffee.
There's no other way.
So we thought, well, I guess now we have to implement the entire stack of eating and drinking because we gotta make this, we gotta sell the joke that's now needed.
And we had avoided all edible.
tech in the kitchen because we're like, you're a chef, you don't necessarily eat the food you're making, dot, dot, dot, we don't need it. But now we really need to deliver on coffee and donuts.
So it turns out eating in VR is more complicated because you put things near your face a lot and making a simple trigger that once you get close to it, you start eating, becomes unexpectedly, you unexpectedly eat things by accident.
So we also needed to build multi-stage eating because you don't want to just completely.
bite the whole thing and have it be gone, you want to get halfway into it. So that meant our artists had to build bite states of every single object that was edible, including the sound effect of juiciness of whether that item was this kind of thing and that or the color of the particle effect and all that. So, yes.
It was very challenging. We ended up having one play tester early on that was taking things to the refrigerator and she was a bit shorter, so she was grabbing things. And every time she grabbed things out, she moved it near her face.
and she just was continuously eating everything she pulled out of the fridge and couldn't figure out what was actually going on.
So then we had to go through this whole process of building all these systems.
So liquid in VR, this makes eating look like a cakewalk.
So 3D fluid simulations are generally just not done in video games, let alone VR, where you have all these performance problems.
And with direct input.
I've seen some fluid simulations where I hit A, and they kind of pour something or do some sort of animation.
But you could directly impact the whole world in how the fluid is actually being manipulated in VR.
So this is an early tech.
We had this mesh that we were modifying and trying to get to work.
It looked interesting, and then just drastically broke down every time that you did anything even remotely complicated.
I built this terrible tech.
It was two bones rigged to a skin mesh, and it does not work in most cases.
So once you end up building liquid, all of a sudden there's these affordances that roll out of this thing.
You expect fluid to boil, you expect fluid to be conserved when you pour it from one vessel into another.
You expect when you end up combining different fluids that the colors mix correctly, that when you pour fluid into world elements, worlds interact correctly.
Then we had to realize, oh man, every milliliter needs to store things like its active temperature because it poured something cold into something hot, what the colors were of that, what the actual ingredients list of every milliliter of fluid.
And now I want to pour them into other volumes.
And now I need to be able to actually have fluid momentum in that.
And this was all to just show a cup of coffee.
So this is the final result of the system here.
Someone making a cup of coffee.
We actually had somebody remark that this part of Job Simulator made them really angry when they were demoing to people, because they were like, people go and they just make a cup of coffee, and they drink it, and it's cool.
And they're like, you don't realize how complicated that would be to build.
So if you're interested in more, there's an entire talk to this.
We ended up doing an Upload VR article on how 850 hours to make that cup of coffee.
So you can check that out.
So it turned out every new system that we would add to Job Simulator as we got through building a job or a task that required some new system, it would have fundamental backwards facing changes on everything else we had ever built.
So the implications on the game could be good or bad.
So now that eating and drinking was in, every food-like item in any job, especially the kitchen which is filled with them, needs to now be edible, which means all the bite states and all the art and all that.
Every liquid or liquid like or anything that produces liquid or you expect maybe liquid could come out of it through some means That needs to be tracked and drinkable and in the system And so you can't set expectations incorrectly You can't have one job where you could drink something and then you go somewhere else and it's no longer the case And so our process for finding those missing expectations, because we can't know exactly what every set of human beings in the world expects about the world, was play testing, play testing, play testing.
So, here's a first example.
We had a plant in the office, and once we added coffee, people wanted to water the plant with coffee.
And so, people would hold it there, and they'd hit the coffee, and then they'd wait, and they'd look at it, and they're like, ugh.
And so now we have to add that, right?
We have to live up to everyone's expectations no matter how absurd they are, because that's the joy of this world.
The photocopier was a perfect example.
Everyone would put something in a photocopier and expect an item, and then they'd get the item to come out, and then they'd put their hand in, and then they'd put their head in, and they would get a brain, and people would lose their minds.
every single time this happened, it was like an eruption of laughter. I remember the first time we were in our office and there were eight people standing around and everyone hushed because someone started to put their head in and everyone is like, it's not going to work. It's not going to work. And it was just pure silence. And then everyone started screaming when a brain flew out. And we've seen that on the achievement hunter video series that they've done. Everyone freaks out because no one thinks that the developer is going to be that insane to go that far.
Another good story was the earliest version of the kitchen.
We had those plates, and Beth was playing, and so she took a plate and she threw it on the floor and it did nothing, and she goes, this game sucks.
So it was, and it was like, okay, plate breaking is now the top of the list.
So it's just little things like that, is if your worldview is a mismatch between real life, that it just doesn't work for you.
So every bot is like a generic thing.
We made this generic thing, and we started adding costumes to them to make them more interesting.
And as soon as we did that, people were like, I need to be able to take the costumes off.
And then they're like, now that I have a pair of glasses, I need to wear the glasses.
So we actually had to go back through the entire game and re-architect all the costumes and all the tech to make sure that, oh, that bot comes in with a hat.
I can take that bot's hat off, put it onto that bot, and then put it onto myself.
So it's one of those things that as soon as you allow people to interact with things, everything needs to be interactable.
And people use that to tell stories, they're like, enjoy this cowboy hat, idiot.
For no reason, it's just fun.
So we knew in the convenience store that we wanted to have some sort of...
Today's not your lucky day, pal. Open that safe and give me all your cheddar.
We wanted some sort of robbery, but this is what everybody ended up doing.
There's plenty more where that came from, kid.
So that was a really challenging scene to make because we knew that we wanted some sort of robbery because it's very like cliche in a convenience store, but it's VR is super, super emotionally intense and we didn't want anybody being freaked out so we ended up having to go through and we have this you know, bandit bot that's kind of funny and he has this like gangster weird accent and he's using words that are just like not like very, very scary words and has a banana and then you can grab the banana and then keep doing that and he has so many VO lines to just like keep that funny.
Once you end up going through the process of making everything interactable, you realize that you now have to redesign the entire world.
It's like the giant, the biggest industrial design task.
A blender in real life is actually a really complicated thing generally.
They have lots of buttons and small interfaces which don't really work that well in VR.
So we ended up having to try to figure out how to solve the blender.
The blender was actually incredibly challenging to build because we didn't want this additional object that you had to snap into that with a lid that you then took off and then you poured.
And it needed to be pretty big to fit the objects, but it didn't have a knife to cut the objects up into smaller pieces.
So we had this giant problem.
And so we ended up going through and looking at things.
And you see there's like this spigot on the side that then you could pour fluid out of it without having to pick the entire thing up.
And then having like small buttons and small dials didn't really lend itself very well.
to VR. So we ended up adding this like slot machine arm onto the side of it and that ended up having some pretty great implications because as you pulled it it would go faster and faster and we could actually haptic in your hand as you were pulling it. It felt like the thing was blending.
Early on when we were going through this process and realizing that we needed to redesign literally every appliance ever made, I ended up going to toy stores and going through because what I discovered was that in VR right now at least, you're closer to the interaction level of a two year old or a three year old.
Just really basic interactions.
And so I would walk down these aisles and see how some designers would design toys for children because there's some things that definitely have some overlap here.
So as far as like how we were building at this state, being able to find our problems and, well, come up with a question and say, is it gonna work this way or this way?
We need to be able to prototype as fast as humanly possible to find whether it should be style A or style B or style C.
That was the ninth Blender iteration.
And every time we had a new play tester, we'd look at how they approached the Blender and whether they would know what to do or pause for a couple seconds and then we'd go back to the drawing board to try to make it better.
And so that meant that everyone who was building the game had to have a VR headset at their desk so that they could test in editor and iterate as fast as humanly possible.
And that we have kind of built our company around the fact that almost everyone at the company wears a ton of hats.
And so if you are.
working on this blender, you need to be able to do some light 3D modeling and some design and some programming and then do some testing and gather some feedback and then go back and iterate.
And so if you don't have to pass it off between people, then you can shorten that iteration time and kind of keep things rolling as fast as humanly possible.
So also the humor as far as how we've been writing the game, everyone at the company becomes a writer.
And so people come up to us and they're like, oh, who was the writer for Job Simulator?
That was really funny.
And we're like, no, everyone contributed because every single thing that goes into the game, every poster on the wall, every like the keyboard at the computer, it's all in this world of like, what would robots think?
How did the world work through the lens of their poorly done research?
And so everyone needs to be bought in on that premise and everyone kind of needs to be a writer in that sense.
When we ended up setting out and starting work on this, we ended up building for what ended up being like a 15-ish foot across size for GDC, because that was what we knew the booth size was.
But we realized that that was not going to work in the real world.
Not everyone has a huge space.
And how are we going to end up handling it?
So this is the final version of the convenience store in the what we call three meter size.
So it's three meters across.
So what we ended up doing was ended up redesigning each one of the spaces for everyone's different play space size.
So if we go to the next one, if you have a size that is 2 and 1 1‚ÅÑ2 meters or less, you end up switching into this size.
This is all transparent to the end user.
We take a look at what the actual volume bounds that they have available, and we automatically do this so that the user doesn't have to select any settings.
It just automatically happens.
And this is not something that can be procedurally done.
You can't just scale the world up and down and be close enough, because everyone understands what the size of an object actually is in real life.
So as soon as you scale it, it'll look off.
So we actually lay out things differently based on the available space and change the way that things work.
So if you go to the.
And so this is, if you end up having just that bare minimum size of 2 meters, this is what you'll end up getting.
And you'll notice that there's some things missing, like if you go back here, there's a freezer in the front, that ends up going under the counters and we end up moving objects or systems around and putting them in tool choosers and things like that.
But from an end user standpoint, they don't even know and need to know what's going on.
And we've had people comment.
They're like, I watched a streamer play the convenience store, and it looked different than my convenience store.
Did I have a different version of the game?
And it's like, no, that was the available space that you had versus the streamer.
So menus were another thing that we had no concept of how we should approach.
And we had nothing we could really draw from.
And we really felt like it would be a cop out to just make a 2D plane where you would interact with everything in the method that we've been using for the past 30 years in games and interaction.
So we thought, OK, how are we going to use in-world interactions, something that we already do as a verb in the game?
to do our menus.
And so we're thinking, okay, we hit a bell in the kitchen, maybe we could do something where you hit a bell and then you get the menu somehow, or you throw a mug at something, or maybe you smack some 3D button.
And so our first design was, let's hit a button on the controller, which there was a designated menu button.
We needed one additional button.
By the way, there's one button in the game.
You just pick things up.
That's it.
And so we had to have one more thing so that you could kind of pull up a menu.
And we thought, let's spawn this.
this thing and it would have buttons on it in all directions and you could hold it like a big Thor's hammer and you would poke it and something. It was terrible. And then finally the joke of what about a menu that's like a platter and then you eat the item.
in the menu and that's where the exit burrito was invented.
And so it was this perfect 3D representation of how do you solve for menus that don't exist in 2D.
And it also has this wonderful effect of having the two-stage confirmation, because we could use a byte state to ask whether they were sure if they really wanted to exit.
Otherwise, you could throw the rest of the burrito on the ground and continue going.
And so this ended up being something that was referenced through a lot of people's designs.
And again, we joked and said, this is going in the textbooks.
Everyone should exit their menus via a burrito.
And it's just silly enough that it seems to work.
I'm hoping it becomes a term, the same thing as a radio button, right?
It's like, exit burrito.
When it comes to menus, early we talked about that job bots office that ended up getting cut.
We knew we needed some sort of location that you could end up branching off into individual jobs.
And then we ended up coming up with the premise that the idea of a museum tribute to these past jobs was born.
But this ended up playing another role as a hidden tutorial.
So this is the progression.
So the job bot there, he floats over to you when you first start the game and passes you a business card.
So you're now learning how to play the game.
So you'll have to reach out and grab this card.
So we teach pick up.
Now we've teach that there's a small print on that, that people will bring it to their face and read it.
And we've told them some story and showed them how to actually interact with the world.
The next thing is options.
So we've got these cartridges that they can pick up.
We then teach attach points by having to attach it onto the console.
And then finally here we teach pullable levers and other things that interact from a fixed point.
And so through this whole process that's really quick and intuitive, we've actually taught most of the core systems inside Job Simulator before you actually even get into the point of playing.
And no one would treat this like a tutorial.
It's like, no, this is how you start the game, but it actually is at a fundamental level.
a tutorial.
So there's one more insidious little tutorial point that's hidden in there, is that when you get the card, there's no table around you to put the card down on.
And so people are like, hmm.
And then they usually just throw it.
And we're trying to get people to start breaking the rules right away, so maybe they'll throw it at JobBot, maybe they'll throw it on the ground, or maybe they'll do something with it because there's no outlet for this thing you just got and now what do I do?
So hopefully they'll start breaking the rules and start going nuts.
Performance and frame rate, as I mentioned, are a huge concern in VR.
From the very early days, we realized that an art style was going to have to be picked, chosen that would work really well with performance.
And that's why we picked the art style of Job Simulator, is so that we could build a game that was highly performant.
We were lucky in the case that we ended up building a lot of mobile games prior to this.
And so we did that with Unity.
And so we had learned all these different optimization techniques.
So if you're actually going through some VR stuff from a performance standpoint, it actually is beneficial to look at some of the mobile stuff that was done in the past, because some of those exact same optimizations actually carry over.
So if you're interested on hearing some more performance related tips, because that's once again another talk, we ended up giving a multi-platform VR talk at Vision Summit 2016.
That's up online.
So at this point, we had gone through the process.
Remember, we originally thought there was going to be 10 jobs.
It turned out we launched day one on the Vive, and were bundled with the Vive, which was super, super awesome.
And we ended up shipping with four jobs, because we realized that people wanted much more depth in the environments that they were in, rather than an incredibly wide variety or breadth of environments.
So that's just something that we found through play testing, is people wanted to go deeper and deeper and find more and more things in that world, rather than just have lots of worlds that scratch the surface.
We also launched day one on PlayStation VR. Huge challenge when it came to perf, especially being CPU bound.
There was a challenge of having to redesign play spaces like we talked about with the various sizes.
But we have now a very known camera frustum that we can calculate exactly where.
you can reach things and where you go out of bounds.
And so again, hard mode for us was we couldn't scale our world or do anything crazy like that because it's a real life place.
So hard mode was manually rebuild levels to be very specific so that everyone has an amazing, great time.
They never have to reach out of tracking or see this awesome, shiny object, and then they reach and they can't get it.
So a lot of work there to design around that.
And then, yeah, we did another whole talk on the process of bringing Job Simulator to PlayStation VR, which was at Unite 2016, which is up online and you can check out.
So PSVR was also a big risk for us in the sense that we were building for this high end of two track controllers and we didn't know at the time that we decided, yeah, let's go forward with PlayStation, whether move controllers would be packed in with all SKUs. And we knew that in general, a controller that's not shipped in the box is a subsegment of a subsegment of a market that's early. So it turned out that Launching on PlayStation was an incredible thing, and we're very proud of that.
But in the beginning, it was a really tough decision to make.
Are they even going to have controllers?
and so yeah it ended up that we were the number one selling VR game on the PlayStation Store in all of 2016, which was incredible and for us it was also like vindicating in the sense that with Job Simulator and Batman right at the top it proved that all of our prior notions of people want hands, people want to reach out and grab things and manipulate directly with their hands that that was true and that the numbers finally proved it so that was that was really cool to see.
And that's what I just wrote on the slide.
So Oculus Touch came next.
So we were also day one there.
You can see here we implemented fingers.
So you can do finger guns and pointed things.
It's pretty cool.
So this was our third launch of 2016.
And this ended up representing the trifecta being complete, that we ended up shipping day one all three platforms that we had targeted.
So these three platforms, we decided that we wanted to be everywhere that had hands, tracked hands and a tracked head, and we were very careful to not fall into the exclusivity trap and lock ourselves to one particular place, because we think it's super, super beneficial for the industry for as much content to be on as many platforms as possible.
When it came to marketing, it was very important for us to be there day one at launch, but it was just as important to make sure that we were ready to build demos for conferences.
Because all this hardware was so early and we were all on the bleeding edge of what was working, we ended up having to devote a lot of resources on a moment's notice to build demos for different conferences, because we realized that this marketing effort not only was beneficial for us, but it was beneficial for the platform.
and pushing the entire medium forward.
This meant that we had super short lead times on things and needed to be very careful in our development that we didn't all of a sudden run out of resources and weren't being able to ship the game.
We also ended up giving away the demo to all developers on Touch and on Vive.
And that was really scary because it was early versions and we didn't know what would happen and we're giving our game away to thousands of people.
But it was really good for a lot of reasons.
You know, that we ended up making sure that...
people could see the way that we were attempting to do things and we wanted to see the reverse.
We want to see how other people are trying to do things and sharing content was so important because when you get the hardware and there's literally nothing, it's really hard to know if there's any best practices, what are other people tried, and you could save time and not trip over the same mistakes as everyone else.
So when it came to actually showing the game in video form, that's one of the biggest challenges of VR, is that it's amazing on your face, and then in the 2D view, it's kind of hard to represent what's really going on and what's magical about it.
So it just looked like people inside of a weird job throwing things.
And so we ended up making these four mini-trailers before making the actual launch trailer.
And the mini-trailers, which are...
Basically, they would show super over-the-top gameplay with throwing physics around and juggling and trying to catch something in the air behind our back and all these things.
And that was very specific because the over-the-top physics madness read very well as kind of this frenetic, weird game.
Whereas, that's not how people normally are playing.
It's just, it's good on film.
And then, thanks to Kurt, we got the launch trailer with integrated mixed reality.
which was like a first of its kind.
No one had done this kind of stuff.
And so filming it with the fantastic contraption guys, it was a really big moment and it was really awesome.
And then from a...
Another like showing the game marketing standpoint, getting Let's Players started to attach to this game in an incredible way.
And so we built in spectator mode support so that you can get a third person camera and watch yourself externally, because when you look around with just the unwarped eye shown on a screen, it's really hard to kind of get the sense and people's heads move so quickly, it's hard to watch.
So building that in really helped people.
Adding built-in Twitch support was also really helpful for people in VR.
to understand what their Twitch stream chat was, what was going on in the chat.
So all of that I think helped contribute to the ability for people to show our game, which was our marketing, is make it as easy as possible for people to show your game.
The launch reception for Job Simulator was fantastic. People really loved it. The thing is, we got lower ratings from traditional game reviewers in the very early days. So the IGNs and game informers of the world. There was a lot of complaint about price in the early days. We launched at $40. We ended up changing it to $30 after a couple weeks. We didn't know what market expectations would be. What would people pay for content? Where's the ecosystem? Where are we in relative price to everyone else? No one knew. We didn't all get together and talk about our price.
We just had to come up with something and put it out there. And so the thing is, we were being compared to traditional PC games with 40-hour gameplay and $10, $20 million budgets or whatever they were, like all budgets. Whereas...
that that was the only thing we can compare to is only a couple of your games and so how else can you base your reviews you just go off of a previous medium and that's really hard to live up to that kind of uh... length of time and quality bar. The reception today, however, we were receiving actually higher reviews than we were at launch and there's little to no price complaints, just the expected amount of internet complaints that you get in a video game. And we're winning fantastic awards or have been nominated for them, which is awesome.
being early to market has incredible advantages, but it's also really, really hard because the developers are new to this, the press are new to it, and they have nothing to compare to, and consumers also don't really necessarily have expectations because who knows what's gonna happen when they get VR, so we're all just kind of learning together how this all comes together.
Our predictions in the early days were that because this was a PC-based VR system with the Vive and you needed a lot of expensive hardware, that this was going to skew towards a demographic that had a lot of expendable income, that PC gamer, which generally skews more younger male, was going to be the market.
And that market was very shooter-driven audience.
We chose to not target that market specifically and instead build our game for everyone.
But why did we end up doing this?
We realized that the year one use case for VR was going to be that the actual hardware owner, the person that went out and bought the system, wasn't going to be the player that was going to play our games the most amount of the time, that once you end up buying this hardware, no one's going to take the hardware, be like, this is super awesome, and then hide it in their closet from everyone.
Everybody wants people to come over and play and show their significant others and their families and their friends and hold parties and then spectate this and put it up on YouTube and all that kind of sharing stuff.
So we wanted to build the game so it worked for everyone because we think that VR is for everyone and we don't want this medium to fall into mistakes of previous mediums.
VR is truly for everyone and we have to work really hard to make sure that that actually becomes reality.
VR is the most accessible platform ever made.
In Job Simulator there's literally two buttons.
Everyone's been interacting with the world with their hands their entire lives, so that they end up getting that and it makes it super easy for them to interact.
So, the overall question of a post-mortem is, was Job Simulator a success?
And so from a financial metric standpoint, yes.
Pulling in over three million in sales in 2016 well exceeded our expectations, I think.
Getting great reception and being in the right spot and being super early meant that we were able to have a financial success.
The game's still selling well.
And so there's other metrics to success.
So, basically...
From an accessibility standpoint, we were able to deliver on something that everyone can play from the extremely young audience to people of all ages.
And that was, I think, one of our greatest successes that everyone's able to play this game and have a ton of fun all together.
I think we delivered on hands and physics because we focused so hard on that one particular realm of VR.
And I think from our standpoint, that was a success.
We could use this tech for our next game and we were able to set a bar for hand interactions.
From a getting there early and being prevalent, the name Job Simulator is widely known, and so we feel like that was a success, and one of our goals is to have something that everyone had tried in VR.
From a humor standpoint, we think that there's not many games out there, or companies still, that try to push really hard into humor in games and don't take themselves too seriously.
So we wanted to continue our trend as Alchemy to do things that weren't super, super serious.
So I think, hopefully, some of the jokes landed in Job Simulator, so we think that that's a...
reasonable success. And then from a shareability standpoint, I think we made it easy for people to share the game and show it to others because that's one of the biggest challenges in VR. And from a social standpoint, I think that we pushed in that direction and had some success there. And so very proud of that. Thank you. And we would love to take questions.
So there's mics on the left and right.
Hello.
I love what you said about the affordances and stuff you added with playtesting.
About what percentage of your development time do you think was, oh, players want to do this, we have to make that work? 100%.
All right, so plan a lot.
It starts with the developers saying, oh, I want to do this.
And then we get through as much as we can.
And then we go, OK, well, what else is there?
And then playtesters play.
I would say the second half of development was much more focused on reactionary fixes, because you want this process to be smooth for every person who plays.
So your task list of what you wanted to do kind of has to be second priority to what is coming up as notes through playtests.
So it's a trajectory of the end of the game development is all about what users are saying.
and the early part is what we think might be good.
So definitely budget a lot of time for that.
Oh yeah, like this is the first platform where you have super infinite amount of input.
It's not like, oh I'm going over to a table and I'm hitting the A button and I'm like, yeah, you could have the choice of an A button or a B button.
It's like, you have the choice of doing anything with your hands at any moment in time.
Yeah, and we didn't even get into the QA aspect, which would have, in our previous talks, took another half hour.
But like, we had people stick their face into a vending machine in the office and eat the items out of the vending machine.
Like, there's so many things you could do in 3D space that you wouldn't expect, that as a developer, it's like, I didn't try that, but someone did.
That there's so much you'll get from playtesting.
Cool, thanks.
Hi, congratulations on the game. You mentioned that sales are still strong. In the last, I don't know, maybe two months or something like that, can you say how much it's split between the platforms? Like how strong are you selling in like each, you know, PlayStation, Oculus and So there's so many NDAs when it comes to sharing sales numbers, it was actually really difficult for us to share any number.
Okay.
So we were able to aggregate all of our sales into that 3 million number, but we're not able to basically split it up or sub-portion it.
Okay, got it, thanks.
Yeah.
So, this has to do with playtesting and, you know, the challenges of getting your game out there to people because the VR market's so small. How did you guys, like, tackle...
getting a broad amount of information to analyze and kind of adapt your game based upon that input. Yeah, so basically is your question how did you take everything you learned from a play test and turn it into actionable results? How did you get your play testing out to a larger crowd to kind of get more data to effect.
So we, the VR hardware at the time that we were doing all this development, it wasn't everywhere.
We couldn't just send builds to everyone and say run this on your PC and let us know how it goes.
We had to have a constant flow of people coming into our office, and then we needed to specifically spend time and schedule blocks of time to sit there.
and not hire someone who was like the playtest coordinator.
We needed the actual developers and designers sitting there and watching the players go through these playtests because, yeah, you could take notes on person did X, but the one who developed that interaction.
if they watch someone interact with it and do something wrong or hesitate or the affordances aren't right, they have to be the one who says, oh, I think I get it.
They went here, they didn't look at this item, and then when they saw the slot machine arm, they didn't know whether they should twist it or turn it, and then they could use that to go directly make those changes.
So it just needs to be a very tight loop between developer and tester, such that they are the same person, and then just sit there and physically watch and take notes.
And even with the hardware being readily available, we still do a vast majority of our playtesting in-house, just because watching people and seeing their actual reactions is super important.
We ended up having some external playtests where they ended up playtesting and recording themselves play.
But we discovered that even then, we had to then sit down and watch an hour or whatever the playtest length of video anyway, so why not just have them in the office?
And the feedback we get from people playing externally is more challenging.
And one of the reasons for this, I think, is that, say, you're playtesting someone's game, at least when I do that, I have a notepad beside me, or I have some sort of browser.
And when I go in, I'm like, oh, man, that's kind of weird.
I go and write a note.
But when you're in VR, the process of writing a note is actually super painful, because I'm in the middle of a great experience, and then it's like, hey, take the headset off, put the controllers down, go over to my desk, make a note, and I find myself falling into the trap of just like, I'll remember that.
And you just almost never do, because the next time a new thing comes up, that erases the previous item.
So.
So there's a lot of sometimes someone yelling, someone open Trello, because they're in VR, and they were like, write down in the triage column that blah, blah, blah is broken.
And that's the only real, like, you could automate it or do something else, voice commands.
There's probably some tools you could build for that, but you just need to get it written down and our brains aren't good enough to remember all the problems that we play test through.
Thanks, guys.
Congratulations on your success.
I think maybe for a lot of us here, it's pretty impressive to see your early Valve demo that you did in a very short period of time.
Can you talk a little bit about, especially with completely new hardware and new SDKs, I mean, now we have like SteamVR, we have the Lab, we have a ton of stuff on the Asset Store that's available, at least in Unity.
Early on when you started the Valve demo and you said you had a very short period of time, can you talk about any of the support that you might have received from Valve?
And also, even more importantly than that, can you talk a little bit about what kind of things you think set you up for success for that demo, whether it's the team that you already had or how did you build your team, anything like that?
So, yeah, I mean...
basically just getting the hardware on time and having them put a lot of trust into us was the key parts of it. It really came down to the fact that this was, we had done many years of mobile optimization and we had built games as a team together. We'd been through that original IP cycle four or five times.
And so we could sit down and throw out everything we'd ever learned about game design and say, what works with this hardware?
And that was really the design process.
There's not much you could do to prepare someone for this because it took two years to come together and figure out what some of the lessons learned were and yet none of those existed at that time.
So it was just give us the hardware, give us some time, and see what comes out of it.
And that was their challenge.
Their challenge is we don't know who might do cool stuff.
It might be this lone person in their basement comes up with the greatest idea in VR of all time.
It's a really big challenge.
and just them getting dev hardware out to as many people as possible is probably the best thing you could do as a platform to solve that.
From our standpoint, the mobile and PC stuff we did before was super helpful.
But another thing that ended up leading to this was we never made the same type of game twice.
It was like every game, we finished it and we're like, what is radically different after this?
And this caused us to kind of always be in that mindset of just like throwing out your previous conceptions on things and kind of going at things a different direction, which is like super, super important.
important in VR.
Whereas if we had built four shooters in a row previously and that was all the design focus we'd had previously, it would be really hard to sit down and say, okay, let's make a game about blocks.
You just kind of want to go in a direction you've been comfortable with and our history has been removing comfort from our game design and just starting at new things all the time.
Cool, and what was your team size for the Val thing, just out of curiosity?
Four people.
Okay, cool, thank you very much.
And then we grew to 16 by the end of Job Simulator, and then since Job Simulator, we're now at 25.
Great, thanks.
I had a similar question to him, so I'll just thank you for the game because.
It's time.
Oh, sorry.
We done?
I think we're getting the time, but what was your question?
We'll do it like a 10-second version.
I was just gonna say thank you, because the first thing my four-year-old did when he played the game was pick up a bottle of wine, guzzle it, smash the bottle, and then try and kill the job bot with it.
So thank you for that terrifying vision of my child's future.
It was great, thank you.
All right, that is the end.
Make sure to fill out your evaluations, and thank you very much.
