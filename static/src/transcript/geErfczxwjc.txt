Hi GDC, thanks for coming out today.
We're going to get started on our talk.
This is going to be about the lighting of Ratchet and Clank Ripped Apart.
This is a game very near and dear to our hearts, and we're really excited to share just how it all came together.
So today we're going to run through a high-level overview of our artistic process and workflows, as well as talking about our biggest challenges and successes on the project.
We'll start with a general overview of what lighters are responsible for, and then we'll start talking about the role that lighting played in pre-production and the work that was done that laid the foundation for the game.
Then we'll dig into the really fun stuff of going through our artistic process and taking everyone through standing up one of the coolest levels in our game.
And then we'll wrap up some insight on how we spent the final weeks of the game really diving into the nittiest of nitpicks to polish this product.
But before we do any of that, let's do some quick introductions.
My name is Brian Mullen.
I have been with Insomniac for six and a half years.
I started way back on the early days of Marvel's Spider-Man as a lighting artist for the project, and I was moved into a lead lighting artist role for Ratchet & Clank.
Prior to working at Insomniac, I worked as a CG artist for TV and film, and I worked for a few years as a professional photographer, all of which laid the groundwork for a really cool job working on video games.
Hi, I'm Anna Roan.
I was a lighting intern at Insomniac and got hired after I graduated.
I've now been here for over two years, and unfortunately, not all of our incredible lighting team could be here today, but it's my honor to introduce...
Miki. Miki has also been an insomniac for over two years and has done some incredible work on Rift Apart.
Also, she's just a delight.
And last but not least, we have Oz.
Oz's years of work in feature animation helped round out our little lighting team into something fantastic.
Now you may be thinking, what is lighting?
That question comes up all the time.
You know what it is, but what does it mean?
Well, it's not just adding lights.
It's adding fog, weather, color correction, and anything else that makes a picture feel finished at the end of production.
In games, we have to wear a lot of hats, compositor, color artist, sometimes even matte painter.
Because of all this, lighting plays a huge role in the final look of the game.
As one of the final steps in production, it's our job to add that last bit of life into a piece.
Whether that's in a level or cinematic, we work on enhancing what's already there.
We make sure our characters are lit in flattering ways, we add depth to an already rich world, and we call attention to the best parts of a product.
Now, a huge responsibility of our job is to determine the mood of a space.
Not only do we need to make sure that the level is playable and visually appealing, but we need to make sure that it tells a story.
So much of that comes down to atmosphere.
Brightness, contrast, fog, color, all of these things make lighting nearly as vital to storytelling as the dialogue, which is why lighting can take an image from this to this.
Here we can see an approximation of what ripped apart looks like before lighting and after.
It might not seem like much, but all these individual tools I've been mentioning come together to impact every pixel on the screen.
When lighting is done well, it's not something most people will ever notice.
I've always said that you can build the most amazing environments and fill it with the most incredible characters, but if lighting's not strong, everyone's work suffers.
Like we said, it's our job to bring an image to the finish line, but let's start at the beginning.
We knew going into this project that we were going to have a big task ahead of us.
But as anyone who's been through pre-production knows, the only thing we can be certain of in the early days is that everything is going to change.
So this pre-production phase was focused on the things we knew we could control, identifying our pillars, our areas of concern, and making a game plan.
Let's dive into a bit of what that looked like.
I am going to start with a bit of a cheat here.
Our biggest hurdle didn't actually happen in pre-production, but it's hard to talk about anybody making a game in the past few years without addressing COVID.
It's...
We had a pretty small team, and it was forming right when COVID had started, and we were all just starting to work from home.
And it was a stressful and uncertain time.
No one really knew how all this was going to work, and frankly, work wasn't even really anyone's primary concern.
That said, we have an incredible IT team at Insomniac Games that did amazing work getting us all going really quickly in our work-from-home transition.
And it's hard to figure out how it could have gone any smoother.
As for the day-to-day work, we knew that every day wasn't going to be the most productive.
Some days were just going to be tough, and that was always going to be okay.
We knew the priority is everyone had to take care of themselves, and we needed to keep our focus on that.
But I also think I speak for the team when I say that this really colorful, silly, and super fun game was kind of what we needed.
It was a nice distraction during a really strange time.
Jumping back to our pre-production hurdles, one of the first big ones that we knew we were going to deal with was that this was a pretty sizable game, and we were going to do it with a pretty slim crew.
Small teams can present workload issues, and you have to work through giving people the right combination of folks in place.
to make sure that you're playing to everybody's strengths.
It's a challenge I really enjoy, and I really like working with a small team.
It gives everybody a little bit of an opportunity to handle different variety of tasks, but it is a challenge, and one that we knew we needed to take serious.
Also, the camaraderie and communication seems to be great when you have a small team.
Hurdle number two was a pretty big one, and it was one that I think anybody working in a launch title window can understand.
We weren't really sure how best to push forward on the PS5 because PS5 was still being worked on when we'd started.
So we needed to be wise about how we set our lofty visual goals.
We knew we were going to have caps.
We knew we were going to be able to push things, but we weren't sure exactly where our new baseline was going to be.
We weren't sure what kinds of things we were going to be able to afford now.
And we knew that we were going to have to establish where our limits were.
But honestly, one of the biggest hurdles that we dealt with really early in production was understanding that we needed to make a clear generational leap in quality over the last Ratchet and Clank game on PS4.
And that game was stunning.
It was lauded at the time for its amazing visual fidelity, and there was a real concern that we needed to figure out exactly how we were going to improve on an already outstanding foundation in a way that shows the promise of next-gen lighting.
So, where did we start?
We needed to start identifying exactly which areas we knew we could improve on.
First off, we wanted to make artistic advances to make the game feel more cinematic.
We wanted the player to feel like they were living inside of a movie instead of just playing a game.
Second, we wanted to showcase technical improvements in both reflections and indirect lighting to make the world feel more realistic.
And last, we wanted to expand on our post-processing to match that of feature animation levels of polish, further refining and implementing bloom, chromatic aberration, color correction, all that fun post stuff, just really to dial in the polish.
And while we had some ambitious goals here, luckily we weren't starting completely from scratch.
Insomniac was just coming off of the huge success of Marvel's Spider-Man, and with it came a lot of knowledge about best practices and workflows.
As I mentioned before, we're still learning the limits of what a PS5 can do, but we know what a PS4 is capable of.
So we started with that, knowing that we would be able to push things more as production went on.
We started from a foundation of making sure that we followed a PBR pipeline that had a foundation in lighting that could be measured in the real world.
we would make sure that our contrast ratio of direct and indirect light matched real-world measurements.
And a major lesson that we learned on Marvel's Spider-Man was that the act of lighting a space tended to have stronger results when we kept things simple, which we'll explain more in a bit.
So I've been talking about the pipeline.
What specifically does that mean for the Insomniac lighting team?
We'll get into the details in a moment, but essentially this is our roadmap for clean, simple, predictable lighting practices for our games.
By using these steps, we're able to pace ourselves, keeping polish for the last steps in the process, and instead focus on getting the fundamentals right up front.
The first place that we always start when we're lighting a level is exposure.
Exposure is really the foundation of everything that we do.
It affects everything that we do afterwards, and we need to get it locked down early.
Not setting this correctly at the beginning can be tricky, because the impact is not immediately obvious and can really start to become more obvious as production rolls on.
An improper exposure can cause inconsistency in glowing materials and visual effects and in the intensity of placed light values throughout the game.
It can also lead to situations where the player will walk into a really bright area and the camera doesn't adjust, or we walk into a dark area and it doesn't get brighter.
Essentially, we need to treat this step less like an artistic or an aesthetic step, and more like a technical first step that is consistent with values that we've set across the game.
What we're aiming for in our first pass of lighting is predictability.
Let's take a look at an example of the impact of different exposure settings can make on a scene in a way that isn't entirely obvious to the lighter when they're starting out.
We have a really simple hallway here.
The results in the right and left, if you're only looking at the lighting, are not really very different, but there is a very noticeable difference in how bright this green cube is getting.
The reason that exposure has such an impact on materials is because essentially we're brightening and darkening the entire scene, and it's bringing things like emissive materials along with it on the right.
Think of a good comparison or a good example to think of is like a cell phone screen.
If you open your phone up, you have auto brightness turned off.
If you open this up in a dark room, a movie theater, everybody's gonna look at you because you've got this really bright glowing screen in front of your face.
If you take the same phone outside, it's gonna be really dim.
We have to think about those sorts of things when we're trying to set our exposure.
Many of the assets that are going to go into our lighting may not come in for weeks or months, so we are not going to immediately see these sorts of things until later down the road, which is why we need to be predictable in the lighting that we set up.
We not only want our lighting to be predictable for us, we want it to be predictable for everybody across the game.
Once we have established our exposure, we are going to set our key light intensity.
Again, this is not a value that is set for aesthetics, but a value that is coordinated with the value of the exposure.
Throughout the work on the level, we like to treat these two settings as locked variables that the rest of the lighting work is balanced around, whether it be light intensity, fog brightness, god rays, you name it.
Everything's impacted by these first two things.
This ensures that we're working on the same baseline for the whole lighting team across the game and making sure we have consistency.
The next big step for us is to get a good ratio between direct and indirect lighting.
Almost all of Ripped Apart is taking place in large outdoor areas, and in every level, we're starting with a wide, majestic vista shot.
And of course, these are all alien worlds, so matching earth lighting ratios may not seem necessary, but I felt like after doing a lot of testing early on where we were just kind of eyeballing things and sort of trying to get in the ballpark, things weren't really clicking.
starting from a strong place where lighting matched what our eyes are familiar with and gave us better results quicker.
To get it right, we want to know what the real-world ratio is.
And this is a rather simple process if you have the equipment.
You'll need a digital SLR camera and a gray calibration card.
You set the camera to a fully manual mode so that it'll override anything the camera's trying to do for you, including shutter speed, f-stop, ISO, all that good stuff.
You can refer to a photography guide for best settings to use for the time of day that you're shooting in.
But essentially, once you've set your F-stop and shutter speed, you don't change it again.
So you're gonna go outside with your camera and you're gonna snap a picture of your gray card in direct sunlight.
And then you're gonna turn away from the sun and snap another picture.
You can also just go into a shadow area like I did in the image here.
And there you go.
Take these pictures into a photo editing software, desaturate it, and get an RGB reading, and figure out how many times brighter the sunlit card is than the card in indirect light.
And there you have it.
You have a direct to indirect lighting contrast ratio.
For a sunny Los Angeles afternoon, we ended up with roughly a three to one ratio here.
The next step is to just recreate this exact process in InGen.
We're looking for the same three to one ratio in our direct versus indirect.
If key light and adaptation are locked, this process should run rather smoothly.
If it's not, it might be a good idea to either brighten or darken your sky and rebake until you reach the expected ratio.
The next steps of the pipeline is actually placing our lights, prefabs, and probes.
The big goal for this project was to try to work simple and realistic.
Every light needed to have a motivated light source, and we didn't want to have any phantom lights on ratchet, or manipulate the bounce or strength of our bounce light anyway.
We wanted to be simple and PBR.
In this example of Rivet's Hideout, a majority of this room is lit by just a few very large lights.
While generally seen as a negative to have overlap of this extent, we found that this actually caused less performance issues to deal with, and it kept our setup simple.
After all, it's easier to dial 3 to 5 lights than 10 to 15.
And aesthetically, we got more realistic bounce light and more natural adaptation in our exposure.
From then on, it's an adjustments game, tweaking and rebaking until you get something that you're happy with.
It's important that you rebake continuously.
The game is in constant flux and other departments are always adding things to levels and you don't want any surprises midway through production.
So after you get it technically correct and in the ballpark artistically, it's time for the exciting part, post-process.
You don't want to do this step too early, because anything you're doing to add visual flourish now can actually complicate your initial setup and lead to technical mistakes later on.
But all that being said, the post-process step in production is where a project can really find its voice.
In Rift Apart, we were going for a more futuristic, colorful look.
We wanted lens flares that would make Star Trek jealous, and a color scheme that would make players excited to see more.
That meant adjusting the color correction to saturate the scene and push the contrast for a more cinematic feel.
It also meant adjusting the fog to soften the overall look of the piece to match the quality of feature animation.
We mentioned earlier that lighters are the finishers of an image, and this is exactly what we mean.
These final steps in the process can dramatically change the tone, style, and feel of a game completely.
And that's why it's so important that everything is done correctly.
Trying to polish lighting on work that wasn't built on a solid foundation is an immensely more difficult task, one that takes substantially more time and is likely to never hit the quality bar that we're looking for.
We have an example of exactly that.
This is a train station in Nefarious City that we've relit using a series of common workarounds and inefficient workflows.
To start out, there's entirely too many lights in here.
It's starting to flatten everything.
And because we have so many lights, I had to start making several of them skip shadow casting because we were running into performance issues.
Even that didn't help with performance, so I had to start having some of the lights only contribute to bounce light.
And then we still had performance problems, so I reduced the fall-off of the lights.
But because those lights were falling off so quickly, now I'm getting less bounce light.
So then I'm adding more lights to get more fill into the corners.
If this is starting to become our sound a little complicated and messy, it's because it is.
This is a weird foundation to start with.
And what we're doing is we're chasing our tails, trying to get a look that wasn't built on a strong foundation.
So at first glance, you may not be able to see anything truly wrong with this scene.
You can see the color tone and the mood we're going for, and most people wouldn't notice right away some of the issues.
But compared against a scene lit using the pipeline that we've talked about, the difference can be pretty stark.
When we light something correctly, it's just obvious.
This is the same train station lit using the pipeline we've been outlining.
This has fewer lights, somewhere around five lights, I think, are taking up most of the room.
Better performance and easier to adjust for performance.
If we needed to, oh, better performance, but if we need to dial those lights, we can narrow cones on four or five lights a lot quicker.
We have got better player pathing and the material's already better.
And bonus, it also just looks prettier.
Let's take a look at the details.
The image on the left is missing shadows from this platform.
In some ways, it's hard to tell that there's even a platform present because the contrast is missing, and it's making the image harder to parse.
One of the primary reasons we're losing contrast here is that the light above the platform isn't casting any shadows.
It's a common technique to move to in the ages-long battle with making sure a game is performant, and in previous generations of hardware, it made a certain amount of sense to do this.
In the past, we've all had to cut corners to keep the cost of lighting from impacting playability, sacrificing visual fidelity for performance.
But with the power of the PS5, we were determined to find other ways to get that performance back and not resort to tactics such as removing shadows from lights.
We lit scenes with the idea that anything that a light is touching is casting a shadow, and anything else, and anything less, and we're losing immersion.
The other issue we're running into here is player pathing.
The blue of this light is supposed to act as a beacon and pop so that the player knows where they're supposed to exit.
The image on the left does have this to some extent, but the colors aren't contrasting enough and the path to get there is less clear.
In the image on the right, we have a clearer sense of not just where we need to go, but we can see the platforms leading me to it.
And what about when we focus on our Lombax friend here?
By over-optimizing a setup, we have a character that is not doing the PS5 or the Amazing Character team justice.
Ratchet has lost his highlights, he looks extremely evenly lit.
When the cinematics begin to roll in, we really want to make sure that the level lighting was done correctly, or the cinematics will become substantially more difficult to handle.
The glowing mouth on Ratchet, on the left, is of major importance.
As soon as he starts opening his mouth in a cinematic, it's going to look like his mouth is glowing.
And there's not a lot that we can do in lighting to sort of bring that back.
We're all trying to figure out how to balance aesthetics and performance, and all too often we find ourselves making tough decisions with the amount of lights, the fall off of lights, et cetera, making sure that a pretty picture isn't creating a game that, frankly, no one can play.
But what we found is following the pipeline that we generally put ourselves in a good position to get a strong foundation of lighting that didn't have to make too many sacrifices.
Our simpler setups were easier to tune for performance.
We didn't need extraneous fill lights because our bounce light was done correctly in the first place.
And if you look at the images above, the image on the left isn't awful, but it didn't quite hit the mark for a game that we wanted to show the promise of next gen lighting with.
It's missing specular highlights and shadows and our characters and environment are suffering as a result.
But with all that said, we're still making a video game here and it's impossible not to run into performance problems.
To keep the game running smoothly, each department is allotted a certain percentage of power that we can use to affect the scene.
In lighting's case, that's about eight milliseconds.
Now that's not a hard and fast rule as different scenarios require different departments to take up more of that budget, but it's a strong place to start.
Taking a look at a differently incorrectly lit scene, we can see that lighting is actually at 25 milliseconds here.
That's three times the size of our budget.
The reason lighting is so high here is because the scene was flooded with smaller, unoptimized lights that were inefficiently placed and covering mistakes that could have been easily fixed with proper care.
That's why it's extremely important for us to tackle performance early and often because it affects the entire game.
But of course, even when we do our job correctly, not everything is as simple as lighting a static room.
If everything would have just sat still, our game would have been a heck of a lot easier to light.
But it's not.
And a big reason for that is because we were making a complicated game.
One of the main features of the game is the ability to open a portal and enter a completely different level.
That requires both levels to be open at the same time.
And if we aren't lighting efficiently, that's two inefficiently lit levels at the same time.
We built a game featured around fast loading, and lighting is one of the most expensive things in the game.
That's why it's ultimately so important that we are responsible for our own work, and then look for creative solutions afterward.
If you'd like to learn more about the incredible port of work in the game, you can check out Peter Kao's GDC talk, Shifts and Rifts Dimensional Tech on Ratchet and Clank Rift Apart.
Here's a specific problem that we run into with performance a lot, and it doesn't have an immediate answer.
We did all the things we just said.
We kept our lighting simple, we followed the pipeline.
There's only one real driver of light in this scene, and it's the sun, and we need the sun.
So if we've not gone crazy and placed a lot of lights, why is lighting double our budget?
What happened here?
Well, there's a few reasons.
First off, the power of the PS5 isn't just going to the lighting department.
Everything that lights are hitting in this game is getting more expensive to light.
Ripped Apart is known for its stunning environments, huge crowds, amazing characters, and active, vibrant scenes.
And we love them, but they come at a cost.
In this particular scene, what we are seeing is the cost of lighting a complex and dense environment without a lot in the way of optimization available for us on the lighting team.
But we did accomplish our goal here of getting this very lovely shot performant, and let's dig into how.
First off, our core team made incredible looking fur, but fur that somehow didn't tank our frame rate.
For lighting, we skip rendering shadows for the fur shells and only render the base geo for shadow maps, which makes the shadow map rendering much cheaper and unintentionally, but neatly, also adds a sort of subsurface scattering effect to the fur.
In the deferred lighting pass, we combine shadow maps with screen space contact shadows to pick fine shadows from the individual strands.
This is all to say that often when we're lighting, the most expensive thing that we're dealing with are the characters, and it wasn't a problem that we ran into very often on Ratchet and Clank.
And it's a really lovely game.
It's great seeing the characters look this good and not cost a ton.
For our second item, it's worth highlighting the gargantuan effort of our core team in exploring and implementing more and more refinements, optimizations, and improvements to our ray tracing throughout production.
Ray tracing was always going to be a major feature of this game.
Clank is, after all, a walking chrome ball, and you're seeing everything on him at all times.
But that it was done this impressively with this minimal of an impact on performance is the reason that this team was able to win best technology award at this year's Dice Awards, and also a tech award last night at the GDC Awards.
A major tip of the cap to this team.
And then finally, we can't stress enough the importance of the hard work that the environment and character teams did, not only creating some of the most stunning environments and characters imaginable, but by putting in the work to optimize and ensure that LODs were in place.
Circling back to this scene, lighting dropped almost nine milliseconds in a matter of a couple of weeks.
due in large part to the work of people that I mentioned in the previous slides.
I didn't really do anything here.
Lighting dropped nine milliseconds with minimal input on lighting because lighting is affected by everybody else.
We could have reduced shadow quality of our key light to make this work, but performance was really a team effort.
Not all solutions are gonna be immediately apparent and we don't wanna try to bring out the big guns too early.
So by working together, we're able to keep that incredible PS5 quality graphics look and run in frame at the same time.
Okay, so now let's dive into the fun stuff, making the art.
Following these rules and more allowed us to start with a good foundation for our lighting.
But our next step was taking on what we'd learned and putting it into production and bringing it into our levels.
Let's take a look at some of what we had to do.
It was a lot.
This was a massive linear game with expansive worlds.
And on top of that, we had over one hour of cinematics taking place on 13 distinct planets that all needed to have their own unique look, some of them requiring multiple lighting setups for return visits or alternate dimensions.
They each had to express a different mood and story while still feeling like it lived in the same universe with the same level of polish.
Developing a look can be a daunting process that takes a village.
From initial ideation all the way to the finished project, you're constantly working to hammer out the identity of a space.
To explain how this process works, let's take a look at one of the levels that exemplifies not only the process, but the pivots we had to take during production.
This is Blizzard, the level that underwent some of the most narrative and design changes throughout the game's lifetime.
At the beginning of production, Lizard's narrative concept revolved heavily around those green crystals placed around the environment.
Because of that, they wanted them heavily contrasted against a red monochromatic look.
It also took place underground, meaning that the majority of the light had to come from the glow of the orange lava underneath.
Most of our concept art was based heavily around mood and theme of a space, and it's up to us to interpret that mood and make it something usable for practical level lighting.
Early concept art, while helpful in finding a visual tone, doesn't always take into account player pathing.
That's the need to guide a player throughout a level easily and naturally.
And that's where things can get really tricky.
After we tried to match the concept art in the game, we found we were contending with multiple issues here.
We wanted the players to be impressed with the beautiful open vistas of the level, but we also needed them to know where to go.
Because of the monochromatic color scheme, it was hard for the player to understand where the points of interest were.
And without another source of light, it was difficult to point the player toward that next objective while still looking natural.
Through exploration, we quickly determined that we needed to add another color to break up the monotony of the lava.
We needed another source of light, but in an underground space, that can be really hard to come by.
So after talking to narrative and environment, we determined that changing the location of the space was necessary to get the look we wanted.
So we talked to our AD and concept team about possible artistic avenues.
We went back and forth, trying and experimenting with color and theme.
And eventually it was decided to knock out that back wall and get the key light and the sky contribution into the space to contrast nicely against all that orange.
After they decided on this general concept look, it was our turn to bring it into the game.
Like we said before, interpreting concept art can be really tricky.
Even though we had solved some of those issues with color scheme, we were still having those same player pathing issues.
The overall complexity of the environment and just the size of the space led to the player getting easily lost and frustrated.
Above, or to the side, are two examples of Brines and I's interpretations.
On first glance, they seem really similar. After all, we were following the same concept art, we were trying to address the same issues with player pathing, readability, and mood.
But this was one of the first times in productions where we had differing opinions on how to achieve it.
Like we said, we talked a lot on this project, from favorite types of pizza to level direction.
We were constantly in communication.
We talked back and forth with each other about how we should tackle this issue and more.
And there's countless Slack messages between us discussing every problem and every solution.
We can't really stress how important this was, both because we made a majority of this game from home and because it made our work stronger when we worked together.
So this was my first time leading a team, and I knew going in that I wanted to extend the same level of trust that I'd always had with our awesome art director, Grant Hollis.
Approaching feedback to this team was always a little bit less of a, this is how I need you to fix this, and a little bit more of us identifying issues and starting a conversation about how best to resolve.
In this example of Blizzard, it was very clear that we all understood what the problems were, and we're trying to solve it with lighting, and we know what the issues are.
This is a perfect example and a great opportunity to let someone on the team follow through on the vision that they wanted to do.
And it made all the difference, not just because this space turned out tremendous, utilizing our fog to create a strong sense of foreground, middle ground, background, and adding visible fixtures to add lighting that contrasted against the organic environment, but also because trust had been established and it carried through the rest of the project.
We both talked later on after the game had launched about how cool this moment was on the project and how much it helped us grow as a team.
Sorry about that.
With FLEAZAR really starting to take shape at a broad strokes level, it was time to start digging into making each area within the level feel distinct and exciting.
The different districts, the Honeycomb Mission, the Underground Lava Cave, the Grand Vista, they all work together to create a cohesive vision, but one with enough variety in the color palette and contrast that individual spaces were able to stand on their own.
And that leads us to one of the more exciting and challenging opportunities on this project, figuring out how to compare and contrast not just the levels with each other, but with levels that have multiple dimensions.
Ratchet & Clank is all about two things, blowing stuff up with crazy weapons and insane levels that encourage the player to explore.
Each new world you go to is a chance to see something spectacular.
And that meant after establishing one planet, we needed to make sure that it felt entirely different from the rest.
Each level had to have its own unique color scheme and identity.
In cases like Blizzard, we even had to compare some levels against their own interdimensional counterpart.
Doing these constant checks helped us make sure that each space felt like an entirely new alien world, as well as making sure that our lighting felt consistent throughout the game.
Something really special about Rift Apart was how much time we had to accomplish real polish on this project.
As many of you know, that doesn't always happen in production.
Whether that's a AAA game or a midterm, you're often running right up to the wire.
But because of our faithfulness to the pipeline, our constant checking of the game, and the dedication of the team, we had a little bit of extra time to make things as good as we could.
That meant we were able to go back to each balanced area and really dial in and explore what we wanted to do.
It was through careful planning and many slack threads that we were able to take something from good to great.
When you're deep in production, it's easy to get overwhelmed with design, player pathing, and technical work.
It's so much to keep track of that it all makes art take a back seat in your brain.
While the previous image was... it was fine. It wasn't where we wanted it artistically.
With this added time, we were able to dial in on exactly what our key areas of focus were and put in the work to fix them.
Sometimes that meant doing more post-process work, tweaking the color schemes of specific areas to make them feel more unique.
Other times it was fog adjustments to really dial in the mood of an area.
In this specific spot, we needed to make a more cohesive color scheme, which involved changing the emissive signs and the light they gave off for a more focused, polished look.
Later in production, many of our biggest cinematics started coming in, and it became a huge undertaking that needed a lot of quick turnaround and fantastic results.
It was at this point I decided I was going to have Oz and Miki, two incredibly skilled cinematic lighters, begin focusing on taking these major parts of the project to final.
They took on the significant role of not only lighting these cinematics, but like we kind of mentioned before, functioning almost as quality control for the final image.
This meant tackling a lot of things that aren't really associated with lighting, like making material adjustments, making fur that looked wet when it was raining, animating the fur to blow around if the characters were up high or in a storm, and always, always, always making sure that our two Lombaxes had great eye spec.
Meanwhile, Brian and myself turned our attention to wrapping up our level work.
We would regularly play the game, creating extremely long pages of notes for us to address, as well as items of feedback for other teams.
Then we'd split that work up, knock everything out we could, and do it all over again.
We did this repeatedly for the final month or so of production, and I think I can speak for Brian when I say that not only was this some of the most fulfilling polish work I've ever done on a project, but it was some of the most fun.
Nowhere is there a better example of collaboration really bringing a space to the finish line than Nefarious City.
One of the first levels that the player sees in the game, and a level we just needed to knock out of the park.
This was one of the biggest challenges in the game because it had to feel moody and atmospheric, but also full of life.
That's a lot of hats to wear for a level, not to mention that the player needed to be able to navigate through all of this visual noise.
One of the unique things about this project was the amount of collaboration that was done.
We spent months passing this level back and forth between us, building on each other's strengths, getting ideas from one another, and lending a hand too many times to count.
Closing in on the end of production, I handed this level off fully to Anna to bring home, and she absolutely nailed this space.
It went from looking like a great level to just an absolutely incredible environment.
Nefarious City is one of the things I'm most proudest of in the game, not just because it's a great level, but because of the challenge and collaboration it took to get there.
I started this project as an intern, and after I finished college, I was given the opportunity to come back and finish what I had started.
I learned more about lighting, teamwork, and the struggles of game development on this game in this very level than I ever had in a classroom.
To me, Rift Apart isn't just a great game, but it's a sign of the personal and professional growth it took for me to get right here on the stage today.
And it's something I couldn't be more happy to share with you.
So in the end, through a lot of communication and hard work, we were able to make something memorable together in challenging circumstances.
It took incredible buy-in from everyone to accept a task like this and to collaborate like we did.
This is, for me, the most pride I've had in a project that I've worked on.
And it's because of how well everyone executed across the board.
Environment, character, animation, VFX, core design, gameplay, it all comes together in something like this.
I think I speak for the both of us and the entire Rift Apart crew when I say that this was a career highlight and we hope that everyone has enjoyed experiencing it as much as we enjoyed making it.
So with that, thank you for coming out today, and we will open this up for Q&A.
Hello, wonderful talk, guys. Really informative. Really appreciate it. I'm kind of curious about you're talking about lighting and the materials. How closely did you have to work with the artists on the team to get better reflections? Or is it just like, thankfully, everything worked out like the PBR pipeline?
Sure, yeah, that comes up all the time.
We have to work really close together because as we said, this is a team effort.
So oftentimes we'll go in and light a scene and if we see something isn't responding the way we'd expect when we're working with the pipeline, we start investigating into the specular, the gloss, the roughness, all of those material channels.
And if we notice something seems strange, we'll reach out and talk to them about it if there's an issue.
Yeah, great question.
Thank you.
First of all, thanks for that fantastic talk.
I thought this is truly generation-defining work, and it is amazing.
So hats off, that's like once again.
The question I have is pipeline-related, but with respect to getting parity between SDR and HDR.
A lot of times, as we are in our phase of development, what we are seeing is that there is a push for HDR from manufacturers, but there isn't a lot of HDR devices out there.
There's a large chunk of SDR devices, but if you focus on getting the content across following the SDR pipeline and then later magically try to switch it to HDR, there can be all kinds of hell that can break loose with values and things like that.
So did you guys run into issues with respect to, you know, getting your HDR pipeline figured out and getting SDR at the same time to kind of get some sort of parity and, you know, just be, it wouldn't be just like flat, flat out washed out or anything like that.
So yeah, I don't want to get too much into the technical stuff because I'm afraid I'll put my foot in my mouth with what Core does.
But they do incredible work getting our work from SDR to HDR.
For us, the way that we do it, we're all working on HDR monitors.
But we have, at least for myself, I have an HDR TV that I'm launching the game on regularly, playing it.
Where we normally see most of the differences is in the really bright spots.
We have more room now in that top end.
So it's really just about validating your work regularly.
I mean, a big initiative in our studio is constantly playing the game, and it's important for us when we were looking at that HDR.
quality to make sure that we're not losing details or that things aren't looking washed out.
It was something that came up a lot on Spider-Man. So we kind of had hammered out sort of the issues of how all that worked going into this game already. Thank you. Sure.
Hello. I again really impressed with the talk. I love it when you break things down into half sort of the creativity of how beautiful the colors can be. And the other half is the engineering. And then there's a third element of guidance.
For people that don't have access to the top shelf talent.
How do we study lighting in a way with the amount of work that's out there on say DeviantArt or Pinterest for inspiration and then learning about how to tweak it in game?
Where's that fine tuning and where's that sort of autodidactic self-training, if at all possible?
That's a great question.
Yeah, so there's a planet.
You can get inspiration from anywhere, right?
You can go on Pinterest, just like you said, and just getting into the system, whatever you're using and kind of going crazy is a fun place to start.
Working together as a team is always wonderful to bounce off ideas of each other, just like we mentioned.
But yeah, one of the best things that I've kind of done to really get a feel for lighting is actually going out there with a real camera and just messing around with studio lights having a fun shoot day with your friends and your team and just trying different things and exploring different lightings, just to get a real feel of what it looks like when you're, you're really in there.
It helps a lot, at least for me. Do you have any?
Yeah. I mean, for me, I think when I was starting out, I would look at pretty pictures and I would go, I'm going to try to make that look.
exactly like this and I think that's how a lot of people start. I think Spider-Man's where I learned a lot about trying to slow down and like try to do things realistically with lighting that I could measure in the real world because the problem I was finding a lot is I would light like a dining room and it looked super cool and then I'd walk to the other corner of the dining room and I'd look back and it didn't look...
super cool at all.
So it was about trying to make sure that I do it right, get everything sort of set up, make it boring essentially, and then start trying to look at that stuff like from Pinterest or Google or whatever and start going, okay, so how can I start like nudging this closer to that instead of starting with trying to dive right into making it pretty?
So then second part, is there a point in studying cinematic lighting?
Yeah, I love cinematography.
I've got tons of books sitting behind me in my Zoom calls all the time because I like looking at that stuff.
For me, a lot of it is inspiration.
We use some of the practices that we have.
We're a little bit, you know, we're doing things in real time so we can't do all of the things that they do.
But yeah, it's definitely a huge help for me.
I like seeing how they use color to help with mood and to support narrative and that kind of way.
Yeah, absolutely.
Yeah, we did that all the time.
We didn't often do that as much for Ratchet.
I mean, we had a lot of things we wanted to pull from, sort of inspirationally, not so much direct artistically, but all the time when I was creating skies or trying to set up a general idea of what I wanted, we'd look up, you know, Star Trek and Star Wars and all the cool space stuff out there and we'd wanna make it as cool as we can, you know, just try and get anything we could to do, yeah.
Fantastic, thanks a lot.
Thank you.
Hi, so I was wondering, so for something like an effects that causes a large amount of light, like a large explosion, would that be more of your guys' department to kind of work on that light and how it interacts with the world or would it be more of the effects artists or be kind of like a combination collaboration between the two of you?
Great question.
It's both.
I can't see it.
Yeah, it's a weird domain because obviously, you know, they want to do their effects.
They want to make the most incredible, amazing explosions, which they did.
And then they have to give off a certain amount of light.
So oftentimes what kind of came out was either a collaboration or we, you know, just talk for advice or, you know, if we saw something that didn't quite match up for what we expected, we talk about it, see why, and come up with a compromise.
Yeah, it's all just about collaboration, but great question.
Thank you.
Of course.
Morning.
Kind of a similar question.
I was curious about the interplay between the design team and maybe when they're doing white box or anything.
Do they do lighting that they hand off to you and like this is gameplay critical lighting?
How does that work at Insomniac?
I think it kind of depends.
It depends on the designer and the lighting artist, but I think what I've seen is when we've moved to work from home is that it seems like in a lot of ways our communication's gotten stronger.
So I know just early gray box stuff now, I'm already talking to designers about what they want to do.
And if they want to place lights, that kind of works for me.
Generally, what my focus has been is starting with an atmosphere that kind of sets the tone and mood of what they're going for, so it can kind of help them sell the story that they're trying to tell.
And then we'll talk about where to place lights.
If I can do it, great. If they want to do their pass first, that's also great.
We also have a system where people can add annotations, so there's like little notes in the level, so I can see.
We have a cinematic that will play here, so maybe I want to craft some lighting around that.
Or I need them to go push this big red button over here, so I'll kind of try to help guide them in that direction.
But I don't want to speak for everybody, but I feel like I'm pretty flexible when it comes to how designers want to work with things.
It's just important for us to make sure we're talking a bunch.
Thank you.
Great talk, thank you all.
So I was just kind of curious, as lighting artists in the next generation, do you see any sort of emerging trends in lighting that's coming up?
Dynamic shift more so than static and light mapping and things like that?
I don't know about exact trends, but I can tell it's becoming more important, I guess, to the process.
Maybe that's the wrong way to put it, but before, lighting was something that had to be done to put in.
we didn't have the tech to make it something incredible.
And now, with things becoming a little bit better, we can really focus in on its own unique thing and make something really incredible with what we have.
So I've seen a lot of a big trend and people just paying more attention and trying to get the best details out of what we have.
But as for specifics, do you have any?
Yeah, I just, I think the big thing is trying to move more and more towards dynamic shifting things so that we're not baking quite as much.
It's going to take a while to get there, I think, but we're already seeing some really cool stuff across like with the Blumen.
And I think it'll just keep getting more and more refined.
But yeah, like Anna said, I think that lighting plays a pretty big role in selling sort of the visual.
component of next gen. And yeah, I just, I don't know, it's exciting. I like, I like doing this.
Thank y'all. Yeah. Thank you.
That was a great talk. My question is, as a lighting artist, beside deadlines, how you decide when to stop?
That's a really good question.
Because some things can always be better, right?
Like, does the art director give you a green light, this is right or wrong?
So the art director, did they give us green light, is what you're asking?
Yeah, so what we do is we'll get our concept, our initial sort of, this is what we're going for.
We'll start lighting the scene based on that. We'll have meetings with our director.
The way that Grant Hollis likes to work is he likes to see what we're doing and start doing sort of paint overs of where he thinks this thing could go for final.
And we just sort of do that back and forth throughout the process.
As far as when we know when to stop, the game has to ship at some point, I guess.
I mean, like Anna pointed out in one of the slides, we had all these notes, and it was great, because we had kind of hit a point in the project where we actually had time near the end, and it was sort of like...
okay, we don't have to stop. We can actually just keep going with this thing. And Anna was awesome because she just kept playing the game and writing down all these things. And yeah, I mean, we kind of worked up to the wire. I remember the day we went gold, too. We were just working right up to the time where they were like, okay, you got to stop now. Yeah, it was awesome. Okay. Thank you.
Okay.
Well, if there aren't any more questions, we can go ahead and wrap this up.
I think we're going to be hanging out at the wrap-up room.
I think it's across the way.
So if anybody wants to stop by and say hi, that'd be cool.
But yeah, again, thank you for coming out today.
