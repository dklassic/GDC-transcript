Good afternoon, everyone.
Thank you very, very much for coming to, which is essentially the last session of the conference, sort of time schedule-wise.
I'm sure a lot of us are excited but exhausted and a little bit low on energy.
I actually did a talk in this very room on Tuesday as part of the boot camp, and I was full of energy, and it was a high-energy, exciting little session.
This one's going to be a little bit more low-key, I think, for all of our sakes.
So, the...
Postmortems are actually a fairly common and popular thing as part of GDC, because one of the best ways that we can learn is to go back to the things we've done before, analyze them to a point, but sort of consider certain aspects of them.
In this particular case, what I've done is, it's going to be a bit of a very fast session, because this is only a half-hour session.
I'm going to go through three VR projects that are very different.
And I think if there's any takeaway I want to have today, it's that.
One of the problems we're sort of getting at the moment is everybody going, oh yeah, VR.
And we just, VR, dump it in a bucket, that's what it is.
It's not.
There are so many different things that VR is already, and I'm still very much of the belief that none of us yet really have any scope of where VR is going to end up, because I don't think anybody yet has worked out the exact best language.
to use to present VR.
We're having to relearn cinematography.
We're really having to relearn how we approach the audio of it.
I've looked at a lot of VR projects recently, and I don't want to be nasty about it, but the audio in a lot of these is frankly really very ordinary.
They're not doing a very good job of conveying the sense of presence of being in a place.
We can't use just common stereo or mono, and even HRTF, which is the sort of new spatial format, is not a magic bullet.
HRTF is just another thing, and in one of the ones I'll talk about today I'll go into that in a little bit more detail.
So this is called immerse, impact and inform.
And the reason why is because if we think of it in a triangle and we've got those three elements in a triangle, you will tend with your projects to sort of lean a little bit more towards one than the other two.
Or you might, if you're dead set, you might equally have all three elements to a certain degree.
These are the three projects I'm going to be talking about and each one focuses on one of those specific.
elements at the reduction of the other ones.
So we have VR Regatta, which was on the Vive, Oculus Gear VR.
Outbreak Origins is a location-based one.
You've all seen these sort of ideas of people running around in a warehouse.
They've got a backpack on with a computer, their VR headsets, their headphones, and they're carrying a plastic gun.
Then there was actually a military training simulator that I worked on for the Australian Army.
It's basically the same sort of technology as Outbreak Origins in that they can move freely around a training area with the equipment on it, but obviously a military training simulator has a very, very different purpose than anything that's sort of a game-based idea.
So as I said, VR is not a single thing.
So VR audio must respond to the specific needs of the project in the same way that we treat it.
The audio that we would do for a film, we would treat differently to the audio that we would do for a television series or a Netflix series.
And then we would treat game audio differently again, or a podcast.
So just saying it's audio for media is a very broad term and we have to approach each of these things differently.
In VR, I think it's possibly the same way that you might say that, well, the audio that I would do for an FPS is going to be different to the audio that I would do for a strategy game.
We have to accept that that's the same for VR, depending on what the purpose is.
And yet, again, the reason why I've done this whole talk is because I've observed that some people are not quite understanding the possibility of this yet.
So, VR regatta.
is one where the immersion is the critical aspect of the project.
Outbreak Origins, it was the impact.
And the military training simulator is purely about informing the personnel who are training with this.
And so each of them will have, I mean, obviously you've got to inform somebody.
So in the VR regatta game and in the Outbreak Origins, there's still some level of informing the audience or the player what's going on.
But it's probably much lower down the list than it was in the military training simulator.
So, VR Regatta was a lot of fun to work on because it was a fixed position.
You were sitting in a boat.
You weren't walking around, you couldn't get out of the boat, you could move around the boat a little bit, but this actually allowed for a really, really curatable experience.
I knew that you were always in a boat, so you were always surrounded by water, which means I could place the water, and I could really work on tuning the water and making it really lush and lovely.
Same with the wind, and the wind was very important because sailing boat.
So that limited scope of in a boat, on a water, meant that I could polish the elements that I did have far more than if I'd had to make 50 different levels with 5,000 monsters and 20 different weapons and all this sort of stuff where you've got, you're just spending all your time putting content in, I had the luxury of really being able to polish this quite highly.
Now, it was a small scope.
I mean, this was a very small team, an indie developer in Australia, and a small team.
They didn't have a lot of time.
They didn't have a lot of budget.
But again, that meant that because it wasn't...
One of the things about a lot of simulators, like if you've got spaceship simulators and airplane simulators, often there's not a lot of, you're not rendering lots of trees and stuff like that because you're up in the air.
Same sort of thing with this, you're in the water.
So there's no AI.
So there was not a huge demand on resources for the rest of things going on, and not a huge demand on the audio system from the point of view of not lots of environmental sounds and monsters and AI.
So I could put everything into the few things that mattered.
Now, you might be thinking, well, that doesn't work.
Like, I want really good wind in my game, but I've got lots of things to go to deal with.
That's still possible.
You then just need to set up how priorities work, or you can extrapolate some of the things.
I mean, as you can see there, it's like 24 channels, which I've used for the wind.
Well, you could probably get similar effects by starting with that and then cutting down and working a balance between your resource needs and what sort of sound you want.
But again, you can also achieve this by using a priority system where it's like, Yeah, so I'm using this many channels when there's not much going on, but when monsters start coming in or whatever, I can start to reduce the use of some of these to allow these things to come in.
So those of you who are not used to working with audio systems, there are lots of ways in which you can balance out the need to juggle needing lots of channels and only having a finite number of channels to work with.
All right, so I'm going to go through this bit in a fair bit of detail.
So you can see there a representation from above of the boat.
And the camera would normally be sitting in a boat, but I moved it across just for clarity.
So the camera there is the standard camera you'd have in Unity.
And what I did was I created an array.
So where that says ambient array, that is actually a series of.
sound emitters placed around the camera, kind of north, south, east, west, and each one of those would basically play a looping wind sound.
Why did I do that?
One of the key things with VR is the ability to turn your head within the environment.
Every one of us right now are literally sitting within a sphere.
of the world, like we have air all around here and that air is basically what translates the sound into our ear and it doesn't just come in from here and here, it comes in from all directions, bounces off our ears, etc.
And so What I was trying to do was sort of create in some ways a little bit of that bubble.
And so by having wind coming out of each of these and each of those wind sounds is just slightly different, it achieved what is in my mind one of the most important things to achieve with audio for VR, a point of difference.
When I turn my head, I feel like there's something there and something there and something there.
I feel like I'm turning my head within a bubble of sound.
Whereas with stereo, you've got this here and this here, but if I turn my head, it's like, well, what's there and what's there?
And then these other ones are the fixed ambiences, which are placed out, actually end up working essentially like an audio parallax layer.
So I've got my array here, and then kind of in the gaps, but at further distance back, and all of these have got attenuation on them, so they're all sort of dropping off.
Those ones at the back just sort of sound like wind over there.
And so when you turn your head, you've got this really nice sort of, you know, dome of wind around you.
I actually also, the array also had one above as well.
So if you did that, there would be wind above you.
And you could do as many of these as you wanted to.
This is the balance that I worked with, and I really liked how, the result.
I then have a mono emitter over here, which is a 3D emitter, and that is actually the source wind.
So that will actually, all these other ones are just a really gentle atmos, like almost like a room tone.
Super, super subtle and soft.
Right?
They're just there to make you feel like the air is there, like the sort of sound you would have in a completely empty room.
It's subtle, but it's noticeable.
Whereas the mono 3D emitter that was over there, it would always be...
sort of 20 metres away from the boat, wherever the wind was blowing.
So if the wind changed to over there, it would be over there, and it literally just was, it was the sound of the wind, but you'd be like, oh, the wind's coming from over there.
Then I did something else.
I played around with it a lot, and I was like, okay, so, but I know that in real life, when the wind's blowing, when I turn my head 90 degrees into the wind, the wind blows directly into my ear canal.
and it actually reduces.
So I actually put in a parameter so that when you turn 90 degrees into the direction of the wind, the volume of the wind would drop a little bit and it would filter a little bit.
And I thought, yep, this is getting closer.
But then I was like, yeah, but there's that thing of when you look directly into the wind, it's blowing past your ears and you get this really blustery effect over your ears.
Now, that's a problem.
for HRTF because HRTF is quite good at giving us a spatial sort of elements all around us up to about a metre.
Once you get inside a metre in the near field, HRTF just goes bleh, I don't know what to do.
And I was struggling, I'm thinking how can I get this effect and I started listening to some sounds and then I found a really, really nice stereo recording of wind blowing past my ear.
It literally has that, you know, you can feel it rustling around your ear, the shell of your ear.
I'm like...
you know, that's a stereo sound, you can't use stereo sounds in VR because it'll track with the head and etc.
And then I thought, except, I added it in.
And it does play, it's a stereo sound, it's right past your ears.
But it is playing at zero volume.
anywhere around the 360 degree arc, except for when you get within three degrees of that's where the wind direction is, it starts to fade up to full volume, it's full volume relatively.
So when you're looking directly down to where the wind is, you get this nice near field blowing effect past your ears, and as soon as you go three degrees off in either direction it's faded down to nothing.
So a stereo sound that's locked to my head is working because it's only triggered at the exact right time.
Binaural sounds is another one that would be really good.
Binaural are really good for that whole creepy thing really close to the back of you, but of course, binaural if I turn my head doesn't work.
But if binaural is a really short thing, like think we're playing a horror game, and it's a little girl's voice that says, hello.
By the time you've heard it and reacted, it's stopped.
So I can turn my head and it doesn't matter.
And so the whole time, there's this little voice on my shoulder behind my head giving that creepy feeling.
But as long as they're really short, really, really short things that by the time I've reacted, they've stopped playing, so I'm not going to notice them sort of swinging around with me, binaural can be super, super effective.
Because binaural recordings are really good for that new field thing.
So you can see here that there's a whole bunch of layers there.
And the thing that is really important here.
is HRTF is not a silver bullet.
HRTF is one of many layers that you use to create the effect of what you want with spatial audio.
So the fixed ambiences and the ambient array were sort of basically HRTF.
The stereo one I was telling you about with the wind is just a stock standard stereo sound.
The mono emitter was a mono 3D sound.
In other areas I think I used just a mono sort of drone sound.
So layering mono, stereo, binaural, 3D, standard 3D sounds with HRTF is how you get this.
Any of you working on VR, any of you who have audio people working for you on VR.
really understand that just switching on HRTF is not enough.
And I've seen some projects where they have just done the normal 3D stuff, switched on HRTF and gone great.
And I'm fairly convinced now that with this, I reckon even if I turned off the HRTF aspect of it, all these other layers would mean it would probably still sound better than just doing the 3D sounds with HRTF.
So just be aware of that.
All right, so I've got a lot to get through.
So with the water, same sort of thing.
We had emitters for the water all around the boat.
Then we had a bow splash when the boat started to move.
The actual sounds would change.
They would be manipulated as we increased in speed to make it sound like more of a whoosh.
And they would actually sometimes crossfade to another sound of more water movement.
Right.
side emitters for port and starboard.
But I had multiple sounds, and what I did with the side emitters was I had something to get an increase in resolution.
Because this game was on the Vive, you know, you're sitting there, you can actually lean your body down to the water.
And when you did that and got close to the water, it wasn't just that I ramped up the volume, or the volume ramping up automatically through attenuation.
I actually cross-faded in.
So you've got your normal just white noise, whoosh and whoosh.
But when you put your ear right down, I would raise up like literally a bubbling, sort of gluggling water sound, because you could hear the water going along the side of the boat and the turbulence there.
And so again with VR, in VR I can put my head really, really close to something that I might not be able to do in a normal game.
And so having all of those different levels of intensity, etc., really, really brought this project to life.
So, the narrative.
It's basically just the audience's experience.
There wasn't a lot of narrative for me to work with.
Audio supports that narrative by surrounding the audience in the sonic elements.
There were people who were giving feedback, saying this is glorious.
I feel like I'm out on a boat.
And people talking about the idea of setting up a fan so they've got wind blowing into their face to enhance it.
But a lot of people really, really loved that they felt like they were outside.
They felt like they were in the open air.
They really, really loved responding to the wind and actually being able to tell which direction the wind was going in just by turning their head and listening.
Dynamic nature of the wind and water sounds are less about the mechanics of a racing boat and more about the interplay between the audience and their environment.
And that's the point.
It's not feedback of the boats going fast.
It's feedback of you are in this virtual world.
I'm trying to convince you that you're in a believable world by basically giving you elements that really, really enhance that immersion.
By immersing the audience in a virtual world, they can believe in all the other elements of the experience and become more convincing.
And this is the point.
If you get the audio right, it will provide so much support for the other elements of being in a virtual world.
Doesn't matter if you've got the best graphics in the world, if your audio is not up to scratch for VR, it will undermine the entire audience experience.
Alright, Outbreak Origins.
True freedom of movement.
Literally, you can run around a warehouse.
Very linear experience, room by room.
They literally move on from room to room because in a warehouse they've got like 15 minutes to do it.
It is linear, it is timed, etc.
Hugely immersive experience.
Because of this format of you're running around with a gun, you've got everything on, you've got freedom of movement, it is actually a very immersive experience.
Broad audience.
This is like going to the cinema or to any other sort of thing.
This is designed to be, you know, family friendly.
Sure, you're shooting zombies, but it's supposed to be family friendly.
People from all walks of life, poor people, rich people, people who are into games, people who are not into games.
In fact, one of the biggest audiences is, you know, a lot of males from sort of young adult through to middle age who have never played video games.
And they go out for a party or whatever and come along and try these things out.
So you need to be very, very careful with how we approach this, because it wasn't typical gamers.
Shared experience as well.
People, like, they're playing as a team.
It's like, I think, four people.
Two groups of four.
They were playing together, but they were moving through in sort of two different groups.
Unique environments as you move through.
Each had its own reverb.
I'll get to that in a second.
But the transition points were really easy.
You start off in the bunker, and it's a concrete military bunker.
And to end that level, you walk into the lift.
There's just a line in the sand across the thing.
You walk across that line.
I switch off the bunker reverb.
I switch on the lift reverb.
Again, point of difference.
Doesn't matter if the reverb is 100% exactly right for that bunker or that elevator.
The average audience is just going to go, hey, the sound changed.
And in fact, no, sorry, they're not.
The average person is just not even going to notice that the sound changed.
They're just going to go, I walked into an elevator.
And that's the point.
If we do our job properly, they shouldn't notice that sort of stuff.
And the zombies was a familiar narrative, and so that was kind of good to work with because people's expectations were never really challenged too much.
So here's one of the examples of one of the points of impact.
So we've got our trigger line.
So A is our elevator.
And we've got this sort of trigger line.
And when the door opens, so they can fire their guns in the elevator for the one, two, and it goes bang, bang, bang, and you've got the hum of the engine in the elevator.
And that's all got that reverb.
When the door opens, there is an emitter just outside the door of the elevator that's basically whoosh, wind, really, really loud.
And it just feels like the door opens, there's wind.
But in the elevator, it's still just that close space.
As soon as they step across the line, once again, one of those ambient array things kicks in.
But this time, it's really, really quite strong wind.
And they are up on top of a 40-story building on top of the city.
And that transition point of being in this nice, cozy elevator to I'm now up on a thing, and it's open, et cetera, was really quite impactful for people.
Now one of the other things I did was, as I said, there was reverbs applied for everything, so you fire a gun in the bunker, it goes bang, you fire a bunker in the elevator and you get slap echo.
When you got up onto the roof, I did something a little bit different.
I got all the gunshots that had nice long tails and I literally went chop, so I had about that much of the gunshot.
that was attached to the gun. Bang, bang, bang, bang. Really, really dry.
The tail was attached to an emitter that was about 20 metres in front of them and as soon as you pulled the trigger it would basically, you go bang and the tail would start there and then randomly either travel in that direction or that direction. And so what it was was bang! And it was that echo off the mountains moving The echo was over there and it was moving off in a direction randomly like that.
The difference that made to standard gunshot sounds was massive, especially with VR and stuff, because you'd shoot and move like that and you'd still be hearing the echo trailing off as you were moving around.
And it was just really, it really made a massive impact.
It made all the guns, etc., sound really quite exciting when you're on the roof.
Then what happens is after you've killed some zombies, this helicopter comes along and you can, you know, 3D model helicopter comes in, that's fine.
And there's another pressure plate.
You walk over the pressure plate into the helicopter and it basically switches off that ambience array and gives you one of basically the interior of the helicopter.
Now there's a couple of things that's going on here.
You could sort of wonder, well, you know, you're sort of jumping really quickly between these reverbs and doesn't it sound a little bit weird?
Not in most cases, no, because people are concentrating about stepping into the elevator and with the helicopter, even if you are at the top of a 40-story building, there's about that much gap and the helicopter's there and you've got to step across that gap.
And I will tell you, even in VR, I had tested this time and time again and I know I'm in a warehouse but there'd be times where I'd just be going.
Yeah, I am in a warehouse, aren't I?
Yes, good.
Like, literally, the vertigo and sense of threat you get in VR, your brain is filling in the gaps going, what on earth are you doing?
You are on top of a building and you're about to step over a really dangerous gap.
And it really freaks you out.
If you haven't tried these warehouse experiences, they're really worth it for that.
And so again, you're in the helicopter now, you've got the helicopter interior, but I'm playing helicopter exterior in the doorway.
So you're getting a blend of both of them.
So there's a whole bunch of things going on here with arrays and mono sounds there and stereo sounds there and 3D sounds there and all of these things layer together to give a really significant impact.
And we, for this particular company, they approached me at one point and said, so we, whenever we build these, we actually get regular focus groups, you know, when we're getting close to the end and just to sort of get some feedback and things we want to change and we've never had anybody mention the audio ever.
And we had a couple of people go.
wow, this experience is like three times more impactful than the last ones, or spooky, or whatever the adjective they used.
They said this was so much more immersive than their previous ones.
And in a couple of cases, they did actually mention the audio.
I'm unsure whether it's a good thing or not, because the audio, when it does its job properly, shouldn't be noticeable.
But I think in this particular case, it was a set group of focused people who had played the experiences before.
And they were like, this one is better.
And they were asked, why do you think so?
And they'd sort of said, well, because of the audio.
So in that particular case.
Weapons were all dry sounds.
Environmental reverb added, and tails, as I said.
Subtle environmental details had a huge impact.
This is one of the other things I do.
In the bunker.
There's computers and stuff everywhere, et cetera, et cetera, but over in a corner there's like a pipe there and things over there.
And I thought, well, people are going to be standing around, this is when they're all coming loading into the level one by one and sort of testing their guns, et cetera.
And I thought, let's reward the players for investigating.
So the pipe that was over in the corner.
I basically put a gurgling sound in it.
But it literally, you only hear it when you go right up to it and you're within a couple of metres of it.
And so all of a sudden it's like, you know, and people are like, hey, this is cool.
And they'd call their friends over to say, check out this, it's a gurgling pipe.
Because it was like just a mini little prize for taking the effort of going over into the corner of the room.
And that's another thing that we can do with sound of like, you know, you've got this big area, it's like, I mean, if we were modelling this room.
There's no real sounds going in this room, but if we were going to, to make it interesting, we could add all sorts of things to basically reward our audience.
So the general concept, understand that your audience is likely curious.
Give them things to investigate.
Create things that add life to the environment.
I think audio should always reward for investigation.
You don't have to be really overt about it.
You don't have to put it absolutely everywhere.
But just in general, I think there's things that we can do with audio where there doesn't have to be an animated object.
There doesn't have to be a physical thing there.
We could put a sound in that corner there that basically sounded like maybe there was somebody having a conversation on the other side of the wall.
There's no assets needed other than audio.
We can add to narrative and stuff like that as well.
So as I said, the player who takes the time to walk to the unremarkable corner discovers a gurgling pipe.
Not much time.
All right, I'll go through this very quickly.
The military simulator was quite different.
Very specific audience and purpose.
This was to train people to save lives.
Serious purpose.
They believed they knew what they needed, and that was probably the biggest takeaway from this one.
So, very specific audience and purpose.
Limited scope was helpful, but a very high level of expectation.
They were like, oh, this is serious.
This is very, very important.
And initially it was daunting.
But they, as I said, the client missed some opportunities for improvements.
And I'll give you an example of this.
Again, the array for the wind, etc.
But I said to them at one point...
What about the enemy's guns? This is training for you guys to walk around and I've given you the correct, I've recorded the military weapons and I've given you the correct sounds and all this other stuff like I did with the tails, etc. that was all good.
But I said to them, what about the enemy's weapons? What are the enemy, you need to have the sounds for the enemy's weapons? And I'm like, oh we don't care about those. I'm like, sorry, what?
you don't, this is not a game.
They kept saying this is not a game, this is not a game.
Actually, what they should have said is, the honest truth was, and I don't mean to be nasty, but the honest truth was, we really don't understand what we need and the game industry could teach us a whole bunch of stuff.
Because from my point of view, I've spent five years in the army, I know people who have been in combat.
And from a survival point of view, if you can't tell the difference between a sniper rifle that can kill you at two miles and a submachine gun that can only kill you from 20 feet.
you're not going to last very long.
And especially in this case, we were adding reverb to all sorts of things.
So you hear the sound of an AK-47, ah that's an enemy's gun.
Was it close where it's a threat or did it sound like it was a mile away where it's irrelevant?
Did it sound like it was coming from a building or the streets?
Where do I need to look?
So I was astounded that they just like, oh, we don't care about sound.
And there was a level of arrogance there, which I was the client of their client, so their choice.
But I think I actually wrote a blog post about this afterwards and put it on, not specifically naming them, but putting this on of like, underestimate the importance of audio at your peril if you are creating simulators.
The way we audio our sense of hearing is our critical danger sense.
So I think in this particular case, in this argument, you will always have all three elements.
The weighting will change per the needs of the project.
So VR regatta was probably immerse, then inform, then impact, because we need to inform where the wind was going for sailing purposes.
Whereas Outbreak Origins was impact first, immerse them in the thing, inform last of all.
There's a zombie over there, that's all you really need to know.
Whereas the Military Simulator was inform, immerse to make it a realistic environment, but impact, not really, it was a serious purpose project.
So I think in that regard, it was quite interesting that when I started doing this, I realised, oh wow, this is the perfect trio of projects to explore this sort of concept.
So, it is important to meet the needs of a project, but the project will often define what is possible and feasible.
You know, if the client's saying, that's our scope, doesn't matter whether it would be awesome if I could do that.
Just, you know, we've got to work within that.
We've got to understand that.
Our job is to serve the clients.
It can be tempting to add cool things because it's cool, but does it really add value to that specific project?
Some cases yes or no, you need to consider that.
VR requires a new language, and I sort of started with this, to communicate with our audience.
Evaluate the importance of the elements of immerse, impact, and inform and tailor your audio to suit.
So work out, if we consider this our new language potentially, then maybe which dialect are we using for the specific audience for that specific purpose.
And so that's the last slide.
We have a couple of minutes left, and the organizer sort of generously said we could probably go a couple of minutes late with questions because we've got that bit of time.
So we'll have some questions if anybody has them, but otherwise, thank you very much, everyone.
applause Hello, thanks very much for the talk.
I was just curious on that point about adding value to the specific project.
A lot of the stuff you were describing, like on the boat, putting in the level of audio detail is something I as a sound designer would absolutely adore doing.
Was there any point in these projects or others that you've worked on where you had to kind of scale that back because you're doing too much cool audio stuff and the project was not supporting that granular level of detail?
No, I understand what you're saying.
No, for the two creative ones, I pretty much met what was needed.
I mean, I probably did a little bit more than the client was expecting for the zombie one, but they were delighted for it and they were like, this is great.
The military one was the one where they kind of went, nah, we don't care, so I just stopped.
Right at the beginning, they pretty much said, we don't care.
So I went, alright, well there's your gun sounds, there's your ambience, there's a couple of booms in the background.
And I just went, yeah.
They've literally said, we don't care.
And so my client, who was the one making the thing, said, yeah, they don't want it.
Don't waste time on it.
So it was lucky that they said it then rather than at the end after I'd done a whole bunch of stuff, and they're like, oh, take it out.
So that was good at least.
But the Vow Rigatta one was.
really about the experience.
The people who made it were people who sail boats.
And they said they wanted their players, their audience, to really, really, really like they were sailing a boat.
And the overall feedback from that one was people just going, we love how this sounds.
So in these, I know exactly what you're saying, and I think, yes, there is a risk of doing that.
Perhaps I was lucky that in this case, I went just far enough.
Thank you.
No worries.
Hey, Stefan.
I have a question about using when you split out the ambiences as separate emitters instead of just having one bed.
Are those stereo, or are they like left mono splits and you're using the left on the right?
So you're talking the array thing?
Yeah.
Really good question.
So.
If I had the option, I would potentially use a quad microphone array or an ambisonic microphone.
Like if I was going out freshly to record it, I would do that and then I've got my nice sort of things.
If I had stereo, what I would do is go, oh look, I've got a 60 second stereo file of wind and I go chop.
30 seconds, bam, bam, bam, bam.
But it actually can even work with mono.
Like, I went through some of my lines, and one of the wind sounds that I had that I wanted to crossfade to, I went, this is a really lovely wind sound, but I only recorded it in mono years ago.
But I went mono, mono, mono, mono.
Because of course, again, if it's two minutes long, 30 seconds, 30 seconds, 30 seconds.
We're not doing true stereo in the nice panny way.
What we're doing is we're setting up emitters that are playing a sound within a 3D world that has all the attenuation, etc.
So even mono, and in fact over the years I've used mono for creating most of my environments because you chop it up and position it, etc.
So you can pretty much use any format you want.
What I would say is, grab some files, throw them in, and then, you know, add salt to taste sort of thing.
Just play around with it until it gets to where you want it to be.
Cool, and just adding on to that, since there are no more questions.
No, go for it.
Do you ever use the waveform of the audio to move the sound around?
For example, if a sound has a Doppler effect, or if, for example, like a wind sound might have on the left channel it swells and then on the right channel it swells and then kind of, you know, alternates.
Do you ever split that in left and right channel and then use the sound to move the positioning of the sound?
So what you're saying is, if I don't have a, so if the wind is actually moving rather than just being a static rain, or if the rain instead of just being rain it's like...
of rain, so there are actually, so there are kind of accents within, if there are accents within the files that I'm using, do I use those to determine what's going on?
Like if there's two, if you have two static emitters, and then you know pretending like the sound is coming from left to right, instead of manually, you know, having that scripted, you know, as a moving sound.
What I would probably do is I would probably use those separately.
I would probably still set up my array with my really, really subtle, fairly flat ones, and then what I might do is set up those ones you've just talked about with a surge, I might have them as a...
a nice clean fade in, surge, fade out, so they're clean at each end, and then might have them so that they trigger on specific points.
So like, if I turn my head at a time, trigger one of those somewhere, because it's just sort of, again, it's highlighting that point of difference.
Whether it's actually realistic that me turning my head affects the wind, and we know that it's not going to in that way, it's just that perception of, oh, I did something and something happened.
So there are kind of examples of that.
I mean, one of the best examples is the film wasn't very good, and I watched it many years ago.
There's a film, I think Ben Affleck was in it, that was like the Pearl Harbor film where they, you know, the Japanese attack and then the Americans, you know, two American pilots beat them off.
And what was really interesting about that was, With an airplane, if an airplane is just sitting there and you're recording it, the airplane just goes brrrr, you know, loudly or whatever.
The nyeow sound only happens when you're here and an airplane passes you and it's that Doppler effect.
And yet, when you watch that film, it's showing scenes of...
the camera, like here's the aeroplane, here's the cockpit, so you can just sort of see a little bit of the aeroplane fuselage, the cockpit and the guy sitting in it, right, and they're showing you as though it's a fixed camera.
So the plane's flying like this, the camera, and the whole time you're just seeing the dude in the cockpit, right, and yet the sound, half the time, every time they showed one of those things, you're getting a sound going, and I'm like...
doesn't match what's going on visually at all.
It really doesn't.
It's completely wrong, because it should be a bypass left to right.
What we should be hearing here is just a constant brrrr.
But obviously, Hollywood looked at that and went, wow, yeah, but a constant brrr is not going to really work.
So we'll put something in to represent that the plane's there and the plane's moving.
So it is technically absolutely the wrong sound for that scene.
And yet, who noticed that?
So what I'm getting with this is that there's a whole bunch of smoke and mirrors we can do with sound and 99.9% of the people, I would argue, that a whole bunch of sound designers who went and saw that probably didn't even notice it. You know, we just go, oh, the plane's moving and that's fine.
Our brain is great at filling in gaps. And so I like the idea of what you're saying but I would use it just to know I turn my head and there's a swoosh sort of thing because it would just enhance that whole sense of...
I'm doing stuff and the world's interacting with me.
I mean, it's a great idea, and I'd almost be tempted to go home and open that project.
I'm just throwing one of those in to see what the effect is.
Is it too big?
Do I need to make it more subtle?
Yeah.
Final question, on your car example, if you're inside your car from the previous talk, how would you set up your emitters so that if I'm hearing the engine from inside, that it's coming from the entire...
panel, you know, the wall of the car instead of like...
I might even put two emitters there so there's sort of, you know, one, or make the emitters big, wide, so they fill that whole area.
Obviously filter it a lot so that you've got the inside the car sound sort of stuff.
But I would definitely position it there rather than on me here because it's there in the car.
Yeah, cool.
Awesome, thank you.
All right, this probably should be the last question but...
Great talk. I see from your bio you've been doing work in AR as well. I was wondering if you had any insights on blending real world sounds with AR.
Fantastic question. That's almost a talk on itself, but I'll try and give you some information.
No, no, no, you're absolutely right. And this is one of the big problems with AR is that we need to be able to hear it, but if â€“ I'm a Star Wars fan, so let's just say we've got an AR R2-D2 there, there's a couple of things that goes on.
R2-D2 needs to sound like he's there, not here, not here from mono.
And quite often a lot of the HRTFs, this is a struggle.
I mean, down on the expo floor I was looking at people going, oh, we've got this audio solution and I'm like, sure, it sounds like it's swimming around but it never sounds like it's there three feet in front of me.
And so you've got that aspect of really trying to nail where it feels like it is.
Really judicious use of reverb might help that a little bit, but technically if R2D2 is there and goes beep, I should get a direct signal to me here, and then I should get a bounce signal off there, and that's part of what tells my brain R2D2 is there, and all the other reflections and stuff.
Unless you're going to do lots of ray tracing and stuff, you're not going to get that.
So again, smoke and mirrors.
You just have to kind of pretend.
If I had the ability to sort of do this, one of the things I would probably try to do is, if you had the tech to do it, is, you know, you've got your HoloLens or your Magic Leap, and it's got a built-in microphone.
I'd want that built-in microphone to basically go, I'm going to listen to the environment that I'm in, analyze that, and then use that to convolve the sounds that's coming out of that, at least to try and guess.
the sort of space that I'm in, but generally I would have it be mostly flat, like no reverb, etc, etc, and if I couldn't do that, maybe I'd just do a best guess.
Again, I'd get the cameras that are built into these devices to go, hey, what does it look like we're in?
We're in a big space, cool, apply big space reverb 6 preset.
It is super hard.
The other problem is that if R2-D2 is in this room...
and you're all talking, you know what I mean?
It should sound like, well, R2-D2's sound is blending with yours, and maybe, if I'm looking at you and you're speaking, I can focus on what you're saying.
If all of you are talking really loudly and I look down on R2D2, I'm now focusing on that.
And there are most of the sorts of audio apps and stuff have focal cone sorts of things where the thing that you are looking at will be slightly louder than everything else.
But again, that takes a lot of tuning because it's like how wide, what's the angle of that focal cone and then what's the difference in volume between that and what's outside it and there's a whole bunch of other things.
So again, it still comes down to smoke and mirrors.
And I think as much as the technology is critical.
I'm still placing smoke and mirrors as being a better solution than the technology right now.
Or at least, sorry, let me revise that.
smoke and mirrors supporting the technology whilst the technology is developed and evolves further and maybe as the technology evolves further we can relinquish its reliance on the smoke and mirrors and dial those down a bit.
But then again, I'll leave it on this point, I mean any Hollywood movie that we look at is so devolved from a reality.
I mean the handguns sound like Howitzers.
you know, something the size, you know, a dragon the size of my palm makes a noise the size of a 40-foot dinosaur.
So if you're wanting to make, if you're trying to convince me that something's there, that's fine.
If you're trying to convince me that there's something that's heroic Hollywood that's there, that gives you a lot more carte blanche to have R2-D2 all of a sudden sound like a giant T-Rex.
Thank you.
No worries.
All right.
Thank you very much, everyone.
