Hi, so we have a little bit of business before we get started.
I'm supposed to ask you to pretty please mute your cell phones so they don't go off, and also to make sure to fill out your surveys when you're done, or when we're done.
They're super helpful for GDC to figure out who they should invite back, and they're also super useful for me to figure out if you liked the way I presented and you like what I presented.
So please take a moment when we're done to do that.
All right, that's the stuff out of the way.
Let's get started.
So my name is John McDonald.
I'm here from Valve.
And today I wanted to come and talk a little bit about how we've been using deep learning to effectively combat cheating in CS Go.
Spoiler alert, it works pretty well.
We're pretty happy with it.
So that's a bunch of stuff.
We have a whole hour, so we're going to cover a lot of ground.
I'm going to spend a little bit of time, probably, fair warning, probably about 15 minutes, kind of talking about the state of CS Go with respect to cheating, other things that we do in this space.
And then we'll dive into sort of the pitch that I was making to folks around Valve in 2016 for why we should maybe give this a try.
We'll dive into results, and then we'll talk a little bit about how you train and utilize deep networks.
We'll talk about some ongoing and near-term work, and then we'll finish up.
One thing that's probably worth mentioning is that notably absent from this list is deep learning.
I'm not actually going to try and teach you deep learning in an hour because I don't believe that I can do it.
But i will point you at the end towards resources so that if when we're done you feel like oh, that's something that maybe i should try You, know, where to get started and good news it's actually pretty straightforward to to learn All right, so let's talk a little bit about CSGO itself first.
CSGO, if you're unfamiliar, I think most of you probably are, but it is a succession of Counter-Strike.
It is a competitive multiplayer game.
It's fast-paced action.
We have bullets that are extremely, extremely lethal, and when you're dead for a round, you're out.
The combat engagements in CSGO are very, very short.
The average engagement time can be like one to two seconds.
And all of this sort of matters because it impacts our cheating problem.
CSGO has 12.4 million monthly uniques and three million uniques checked back in every day.
So we're pretty happy that our player base is so rabid.
Finally, it's the 10th title that shipped on Source Engine and we'll see how this plays into our cheating problem a little bit later as well.
One of our most popular modes for CSGO is the competitive mode.
It's a 5v5 game mode.
First to 16 wins.
And each round is about 2 minutes and 57 seconds.
When you sign in for matchmaking, we ask you to agree that you could be signing up for a 90 minute commitment.
The average game is actually more like 40 minutes.
65% of our players check back in with this mode at least once a month, and there are 600,000 of these matches every day.
It varies depending on time of day and, sorry, day of week and summer.
There's a lot more matches, school's out, etc.
It turns out college kids love to play video games.
I don't know if any of y'all knew that.
But so let's dive in and talk about cheating, because that's kind of why we're here.
Back in 2016, I was sort of figuring out what I was going to work on next.
I had finished up some other CSGO work, and I was trying to figure out what I wanted to do.
And usually when I'm in that space at Valve, I just kind of try and sort of figure out what the community wants.
Because I figure any time you sort of pay down some debt in the community, that's a pretty good investment while you're trying to figure out.
a sort of larger problem to work on.
And it turns out, I couldn't do that, because the only thing the community was talking about was cheating.
It was this just deafening conversation, and we saw this, and of course, like this information is all anecdotal, but we saw it on Reddit, and we saw it on our own CSGO team feedback alias, where players mail us directly.
And, you know, the feedback alias in particular I had some data on.
It was like 90% of the incoming mail was people saying, your game is filled with cheaters.
And that's, you know, that's really frustrating.
But we weren't sure whether or not the problem was sort of a perception problem or whether there was actually a cheating problem.
Except it turned out that VAC bans, which we'll talk about in a little bit, sort of supported this conversation.
Like, we had a lot of VAC bans that we were handing out.
And we think that CSGO has sort of two main components that lead to cheating being such a significant problem.
And there's a third aspect we'll talk about in a little bit.
But one is that the design sort of, the design is this very satisfying combat experience where almost any weapon in the game can be a one-shot kill.
But that does also sort of fail to disincentivize cheating.
On balance, we think that's a good trade because players really enjoy this, but it does sort of make us a juicy target for cheating.
Similarly, since the engine is so old, and about 75 to 80% of the code in CSGO is actually unchanged from Half-Life 2, that means that if you have a cheat that somebody wrote back in say 2005 for Half-Life 2 Deathmatch and then they posted it on GitHub a couple years ago on a Lark.
That thing probably actually works on CS Go with a small amount of changes, like maybe five to ten minutes of tinkering.
Now the good news is we do actually catch pretty much all of those cheats.
Like if it's on GitHub, you're going to get banned for using it.
But that just means that there is just this availability of cheats that we don't see in a lot of other places.
There are two main sort of cheats that are prevalent in CSGO.
There's a third one that we're not really going to talk about today, but it also is just this very minor sort of issue.
And the primary two are probably the two that you might be used to if you're familiar with cheating in your games.
And that is basically something that helps you aim better and something that gives you information that you're not supposed to have.
And you can sort of, so the aim hacks or aim bots tend to make it sort of much, much easier for you to communicate, headshot that guy, because in CSGO, if I see a target and I want to headshot him, I need to identify him, I need to decide that he is an enemy, or she could be, decide.
that they're an enemy.
I need to move my mouse over.
I need to place it ideally on their head, push the mouse, and then start dragging it down to deal with recoil.
Or I could have a cheat that does all of those things if I just press the X button, including not shooting if that person is actually a friend of mine.
And so that communication of intent, there's a big delta between the intent of the action and the actual action.
And information assistance hacks are exactly what you would expect while hacks, you know, substituting materials or what have you.
But it's just giving you information that basically you shouldn't have.
And then there's sort of this scale that we sort of think about hacks on.
There's the subtle cheats where somebody is trying to basically pretend that they're a better player than they are.
And those are actually pretty hard to detect and not what we went after first.
And then the scale kind of ramps up in obviousness until you get to what we call rage cheats.
And the purpose of a rage cheat is not subtlety.
The purpose of a rage cheat is to make you pissed off that I am cheating and there is nothing you can do about it and all I want to do for the next 40 minutes is ruin your day.
And so we decided that seemed like a pretty good target to go after first.
Now, cheating, because of the 5v5 nature in CSGO, you can sort of think about the cheating problem as it relates to an individual user.
So if I'm going to play a competitive match, given that I am clean, even a low base rate of cheating, like if 2% of players are sort of cheaters and they're randomly distributed, then two out of 10 matches that I play are gonna be dirty.
And if the rate is of, if the base rate of cheating were 7%, like half of the matches that I get into will have at least one cheater.
And that is, again, assuming that I'm a clean player.
Because there are nine other opportunities for a cheater to land.
The other thing that is, maybe mildly, that's slightly even more irritating about that is that given that you were a clean player, you are more likely to play against a cheater than you are to have a cheater land on your team, because there are only four slots for them to land on your team and five slots for them to land on the other team.
So that makes it an even more irritating problem for our sort of good actor players.
Now the good news is, I'm gonna spend a minute here sort of in a digression.
The good news is that we don't actually just randomly distribute our players.
We released this system in 2016 called Trust Score, and this sort of mitigates the damage of cheating a fair amount.
And the idea is that we sort of pay attention, we train the model based on how you interact with CSGO and how you interact with Steam, and we use that to try and predict how likely it is that you're gonna go on to receive a ban of some sort.
And then we basically use that trust score to match as an additional factor when we're doing matchmaking, like in addition to your skill and what map you want to play and sort of other things.
And that lets us sort of put known good actors in with other known good actors more often.
And so as a result, our known good actors run into cheaters way less often.
And this can sort of be more easily visualized.
Like imagine this is just a population of players.
Don't count them.
There are 50 dots here.
And so we need to set them into five 5v5 matches.
And because it is way easier to do with PowerPoint, maybe we set our matches up like this.
And so now we've created five matches.
And let's find out how we did.
you have this sort of concept that we're going to introduce called the rainbow of trust.
And we think that blue players are very unlikely to go on to receive bands, but red players are very likely to go on to receive bands.
Now you might be asking if the red players are likely to go on to receive bands.
why don't you just ban them?
And the answer is, because they haven't cheated yet.
Like, we don't know for sure that they're cheaters, they are just more likely to go on to be cheating.
But, let's assume in this case that five of the red players are cheating, you can see that in the worst case here, like all five of these matches now have cheaters.
And what trust lets us do is basically say, hey, when we're trying to build matches, if we assume all of these players are sort of, that any subgroup of 10 players here would form a reasonable match, we could draw our matches like this instead.
And now we've created four good matches, and the players who we're most certain are not gonna go on to cheat are very unlikely to run into cheaters.
So, we have a bunch of data that shows that trust works really well, but I kind of prefer the anecdotal version instead, and that's that we actually launched trust about six months before we announced it.
And during that time we were gathering feedback and looking for people that sort of like had bugs, like just general feedback, right?
They didn't know that we were running the experiment.
And so what would happen is you'd see a thread pop up on like the steam community forums where somebody would say CSgo is filled with cheaters And then you'd see somebody else reply and usually quite a few someone else's who would reply and say I don't really ever run into Cheaters anymore. I don't know what you're talking about And at this point, we had sort of been public about some of the other anti-cheat work that we were doing, and so the player base assumed that that was why they weren't seeing cheaters as often.
But we would go and basically say, like, hey, let's go figure out what this person's trust score is.
And we'd go and we'd look at the OP, and you'd be like, this dude is tied to 50 accounts, and 49 of them have bans for cheating.
I don't care that that guy runs into cheaters.
He should run into cheaters, because he's definitely going to cheat again, but maybe he hasn't done it yet.
So that's pretty much all I kind of wanted to say on trust.
I did want to mention, though, a thing that's cool about trust is that it doesn't really reduce the rate of cheating, but it reduces the blast radius when people decide to cheat.
So let's dive in and talk about a couple of the other anti-cheat things that we do.
So probably the main thrust of work that we do is just mitigating exploits.
We just fix bugs when they come in, and that goes away.
Somebody reports, hey, here's this problem.
We investigate, we figure out what the problem is, and we fix it.
And so one of the canonical examples for this was this speed hack.
It turned out that players realized, some malicious players realized that if they, this part's a little bit technical, I'm sorry.
But they basically realized that if they lied to the process, they lied to CSGO about how fast their clock was running, they could convince the game client that basically it was running 10 ticks at a time.
And so then the game client would faithfully be like, hey server, here's 10 movement packets.
And that would effectively, and then the game server was like, for reasons that client authoritative feels awesome.
we would, the game server would just go, yeah, okay, looks good to me.
And it would just process all 10 movement packets in sort of a single server tick.
And then the results of that is that that player would just sort of appear to just teleport around the map effectively at will.
And so the fix was basically as brutally simple as you imagine it would be.
It is that the server is like, I'm, you know, modulo some latency issues.
I'm only going to accept one movement packet for each client per tick.
And the problem just goes away.
Now, this is, like I said, this is sort of our primary form of mitigating exploits.
It's always an option, it's always ongoing work.
And the thing is, is that as we do that work, like, bad actors continue to probe and try and find new areas.
And this sort of evolutionary behavior on their part results in this treadmill of work.
And we don't mind doing the treadmill of work.
It's important, valuable work, but it is a treadmill that we're sort of signed up for.
The other primary form of anti-cheat that we utilize is VAC, Valve Anti-Cheat.
And VAC basically is a system of client-side detections.
So I'm going to pay attention to what's going on in your system.
And then I'm going to anonymize that and scrub it of anything that might be personally identifiable.
And then I'm going to hand it up to the server.
And now that VAC is only active when you're connected to VAC-secured servers, and if you receive a VAC ban, it only prohibits you from playing on VAC-secured servers.
But that is about 98% of servers, so you're pretty locked down at that point.
And then the evidentiary standard for VAC, meaning like when VAC takes an action, we're 100% certain that you had your hand in the cookie jar.
with a caveat.
And the caveat is that sometimes we make mistakes, but when we make mistakes, we rectify them clearly and immediately.
There's a blog post, there's a clarification that this was the thing and it was wrong and we fixed it and we're very sorry.
And as a result of this, our community has very high confidence that when VAC takes action.
that we are punishing cheaters, which is borne out.
But interestingly, I know that a lot of devs actually struggle with the opposite problem.
They have an anti-cheat, and their players believe that their anti-cheat really gets cheaters, but they're not actually certain that the anti-cheat isn't also punishing innocent users.
We definitely don't have that problem.
We're very happy about that.
Okay, so.
We don't talk about VAC very often.
And the reason that we don't talk about VAC is that talking about it makes it less effective.
And in particular, talking about detections just stops them from working.
So for example, if I got up on stage today and I said, hey guys, here's a detection.
What we do?
is when somebody has a process and their process is scribbling into CSGO's memory, we go identify all of the binary parts of that process and then we go find the executable code that loaded that process from disk and then we MD5 sum it and then we send it home and we figure out if that is a malicious actor or like OBS or something instead.
When I tell you that that's a thing that we do, I just lit that thing on fire.
Like, it doesn't work anymore.
Or at least by the time this hits Twitch in, you know, three seconds, it definitely won't work anymore.
The good news is that we actually have thousands of detections that are sort of various sophistication and we write more every day.
But again, every time we do this, our bad actors evolve and the treadmill continues.
All right, great.
So let's get to why we think deep learning might be an effective component in our sort of anti-cheat strategy.
But before we do that, let's talk a little bit about deep learning.
So if you're not really familiar with deep learning at all, or you're just familiar with the buzzwords, then I'm going to give you the 40,000 foot view.
And the basic concept behind deep learning is that deep learning can help you basically just automatically build a function that maps inputs to outputs.
So if you're familiar with algebra notation, you're probably familiar with y equals f of x.
And we're just saying like Y is the result of applying some F to some input X.
And the cool thing about deep learning is deep learning says if I have enough X and I have enough Y, I can solve for F.
And that's pretty powerful.
It turns out that then you can take that F that you have just built and you can apply it to sort of never before seen X values and get actually pretty sensible Ys.
And if you don't use deep learning, then engineers are writing your F values.
That's that treadmill of work that we were talking about.
And that lets you make this trade that at Valve we're really excited about.
That lets us basically trade data and compute for engineering time.
Because at Valve we are always, always short on engineers, but we have a lot of data and we have a lot of compute power.
So if I were to take this analogy, if maybe you don't follow along with the algebra, and I were to take this into the real world, maybe you would imagine that...
if I had a bunch of cubes of meat, and I had a bunch of hamburger patties, and I had enough of them, that, and I told deep learning, hey, build me the thing that will convert these cubes of meat into delicious hamburger patties, it's gonna give me a meat grinder.
And so that is the analogy that we're going to stick with a little bit through the talk.
And I apologize to vegetarians, I'm really sorry.
We workshopped, what else could it be?
And it's like, this one works really well.
So I'm sorry.
Now, you might have noticed that I said that we're only building a possible function that maps inputs to outputs.
And the reason is basically a data starvation problem.
you could if you had enough x and y like there is a closed form solution that is sort of the best possible f that converts that x to y but the thing is is that you would need so much data so so so much data like quintillions of examples quintillions and quintillions of examples even for very simple functions so the reality is that like you're not going to do that you're going to get just one of the myriad of possible solutions Now, deep learning is actually really good at pattern recognition.
It's really good at things that you're already familiar with, like, is there a cat sitting on the sofa?
The answer is yes.
And also, if you have a computer, the computer in your pocket, if you have interacted with Siri or Google Assistants, deep learning is made use of to transform the words that you say into text that then translates to commands that then is used to sort of do fuzzy lookups.
And it's used.
in so many pieces along the way.
Now, deep learning basically operates in two modes.
There's sort of training time where you're like, hey, I've got a bunch of cubes of meat and I have hamburger patties and I wanna build a meat grinder.
And then once you've built that meat grinder, it's like, great, now I wanna take these cubes of chicken and I wanna turn those into a chicken burger because that sounds like a thing that might be good.
Deep learning works in these two modes that we call, like I said, training and inferencing.
Now I might during the talk accidentally say machine learning because we actually do a fair amount of machine learning at Valve as well.
And the simplest way to talk about this, for the purposes of my talk, if I use machine learning you should just assume I mean deep learning.
But if this sort of red circle represents deep learning, then this orange circle represents machine learning.
Like deep learning fundamentally is just a subfield of machine learning.
And similarly, when people are talking about deep learning, what they're really talking about is neural nets.
So if you learned those 30 years ago, it turns out they finally work.
Spoiler alert.
The solution to get them to work was to have a million times as much data and a billion times as much compute.
And then they work great.
All right.
So let's get back to our elevator pitch.
We were, basically, we were looking at like, how do we attack this cheating problem?
We tossed around a ton of ideas, but I really didn't want to sign up for the treadmill.
And so looking at this, it was like, well, you know, humans, when they watch matches, they can tell that cheating is occurring, and I think that's probably because they're detecting a pattern of cheating.
And deep learning is really good at detecting patterns.
So like, shouldn't deep learning be able to detect cheating?
And as I mentioned before, aimBots seemed like both the largest, the biggest problem because they're not subtle, at least a lot of them are not subtle.
And they're also this sort of really loud signal, at least it seems like.
So it seemed like, well, we should go after those first.
Because if we can't do those, then we're definitely not going to be able to do the things that are more subtle.
Now, if you recall, I mentioned that deep learning is trying to solve y equals f of x for f.
The problem was, like, if only we had a source for x and y.
Good news! It turns out we had a source of X and Y.
For years, CSGO has had this system called Overwatch.
No relation.
Which is a jury review system.
But basically, what we have is we have players, they watch cases, and those are our X values, and then they decide guilt through some process that I don't know, I don't know what their process is, and then they render a verdict.
And they do this in this way where they go through this process.
Players report other players and then a sort of central coordinator selects cases.
By the way, that is a computer, it is not a person.
There isn't like a guy at Valve that is like, I am the coordinator.
That would be kind of cool, but it's not a thing.
And then the players adjudicate those cases.
Other players basically decide, is this person guilty?
And they do that through a process where they're sort of presented with an evidentiary window.
The evidentiary window is eight rounds long, and they're asked like, hey, watch, and the play time is anonymized, so you don't know who the players are.
You watch basically a demo of eight rounds and then at the end you're asked, did this person use aim assistance?
Only convict them if you believe there is evidence beyond a reasonable doubt.
And we ask that for aim assistance, movement assistance, information assistance, and other assistance that we're not sure about, and also griefing.
And if you're guilty, you get a BAM.
And if you're not guilty, there's no punishment, right?
So it works kind of the way that you would expect it to.
Overwatch uses naive Bayes to basically look for a guilty threshold.
That's a bunch of mathy stuff I'm not really gonna go through but the point is that according, we have a model and basically the evidentiary standard is that 99, that it needs to be 99.8% likely as decided by your peers that you were cheating.
Now the actual rate that people get convicted at is usually five nines.
Like usually convictions in Overwatch, the jurors are super, super convinced that that person is a cheater.
So, as I mentioned, the system had existed for kind of a while.
So back in 2015, we decided, hey, we noticed this trend.
We did some work, and as a result, it increased participation in Overwatch.
And it's probably worth explaining a little bit about this graph.
The gray line at the top is the sort of total participation in Overwatch, and the blue line is basically the number of cases that were dismissed.
The red line is convictions.
And so we noticed this great trend.
We're like, hey, this is awesome.
As more people participate in Overwatch, we get more convictions.
So we should probably get more people to do Overwatch.
That would be awesome.
So we did.
Come on, come on.
PowerPoint, you can do it.
Oh, are you serious?
Come on, you did it earlier.
You can do it.
So this graph, it just shoots up in participation.
It's amazing.
There's so much participation.
It turns out the conviction rate doesn't move at all.
Like, the number of convictions is stone dead flat.
And then that is a trend that we see continuing.
On this graph, which is also amazing, and I will totally make sure that those are fixed when we post.
I don't know why they were broken.
I'm very sad.
I'm sorry.
Okay, so the thing that we found in those graphs that you guys totally loved is that Overwatch really helps us with latent cheaters, but it doesn't handle subtle cheats as well.
And that it turned out that increasing participation, like incentivizing participation and increasing participation, didn't help at all.
Like, it seemed like the problem was basically that we were failing to properly select cases.
Now, the bad news is that as players got convicted in Overwatch, they would sort of evolve their behavior.
But the good news is that jurors evolve as well.
Like, they're not fooled by your new, oh well I'll just turn 75 degrees of frame instead of 78 degrees of frame.
Jurors are like, no man, that's still cheaty bullshit.
So the elevator pitch for VACnet was born.
The idea was that basically we would use this Overwatch as a giant pool of labeled data and we would train VACnet from Overwatch.
And then we would build a cluster of machines that would monitor matches with the model that we built.
We would use VACnet then to submit cases, and then humans would ultimately decide whether or not the person was a cheater.
So back to our sort of Overwatch pipeline, all we have to do is slot in VACnet kinda right here.
Okay, so how did we do?
Man, I hope my graphs work over here.
Oh boy.
OK, good.
I have a later graph that I see is totally good.
So we're just going to skip ahead.
Great.
Oh yeah, hey, hey, here's the period.
I'm sorry, I know I said I wouldn't move.
Here is the period where we had increased participation, right here.
And you see, this conviction rate just doesn't move at all.
It was just horrifying.
And again, throughout here, our participation fell, and it just didn't impact the conviction rate at all.
Sorry.
All right.
Okay, so we deployed VACnet.
We deployed VACnet in early 2017.
And during this time, participation sort of doesn't really change.
Like maybe it's going up a little bit if you squint at it, but most likely what's happened is it's sort of just asymptoted down to the level of participation that we expect.
It looks a whole lot like sort of any game launch ever that has sales, right?
So here we deployed VACnet and you can see, hey, we started getting more convictions.
That's great.
And we deployed a really simple model.
We didn't quite have enough data yet, but we were like, hey, this thing's doing pretty good.
And the conviction rate overall for VACnet started to go up.
And then a little bit later, we had the opportunity to sort of train with more data until finally in December, early December, we hit the crossover point where now we actually get more convictions than non-convictions in Overwatch.
So yay, the system works great.
So how great does it work?
So human submitted cases, when a human submits a case to Overwatch, the likelihood that they get a conviction is only 15% to 30%.
And that sort of varies on a bunch of factors, like the factors might include the time of day, the day of the week, the time of the year, is the game on sale, is it spring break, spring break.
There's a bunch of things.
But the point is that human convictions are very low.
And VACnet convictions are very high.
Like, VACnet gets a conviction, when it submits a case, it convicts 80% to 95% of the time.
And it varies pretty much on the same factors, with one exception.
And that one exception is that whenever we retrain VACnet, its conviction rate is like nearly 100% for a little while until cheaters adapt and start to react to it.
All right, so hopefully I've convinced you this is kind of a cool thing and it works pretty well and I'm good at Excel.
We can talk about how we train a learner.
And we're only going to spend one slide on this because I really just wanted here to give you a pointer to Keras, which is like if you're new to deep learning, Keras is great.
But the sort of main sort of thrust of training a learner is that you need lots of X and Y data, and at least for supervised learning, which is the thing that we've been sort of talking about here, you need lots of X, Y data, you need to fit it, and then sort of you just repeatedly ask, hey, how are you doing? Hey, how are you doing?
You have some measures that you pay attention to, and you're like, how are you doing?
Are you doing good? Are you doing better? Great.
And then when it stops getting better, you're like, okay, hold the phone.
I've got my meat grinder.
And then, like I said, you want to take a look at Keras.
So we're going to jump ahead and talk about how we actually feed this thing.
So you recall the metaphor.
The metaphor is that we have this meat grinder.
And all we need to do is feed it cubes of meat.
And the problem is that as a game developer, you don't have cubes of meat.
What you have is a cow.
And that's not a commentary on your engine.
My engine is the cowiest of all cows.
But what you have is not the thing that you need.
And the good news is, well, if you think about it, like the bulk of the work of like, how do I turn this cow into a delicious hamburger?
You're like, well, the overwhelming majority of the work.
is how I turn the cow into cubes of meat.
Like, that is the work.
And it turns out, it's actually like 95% of the effort that you're going to spend.
And all of that effort is basically effort that you already know how to do.
It is just bog standard engineering work.
There's no sort of magic box around it.
Only 1% of the effort is actually kind of around deep learning.
turning, you know, in our metaphors, turning the crank.
And 4% is cooking, I don't, the metaphor breaks down a little bit here, so we should probably just leave it there for a little bit, maybe we'll come back.
If you have a game, to sort of be a little more concrete, there are some pieces that you really want to have.
And I think the most important is that you want to have a replay format.
We call it a demo format.
Other engines call it other things.
But the sort of salient point here is you basically want to have a record that you ideally recorded from the server or from a third party observer.
Like you don't want the client to record this thing because they will just lie.
And you want to be able to play that thing back later.
And then you need all of the sort of infrastructure around storing and fetching those things and transmitting them.
And you're going to want to manage metadata so you can say, like, which player was in this match so that you can evaluate them.
And ideally, and this is the big ask, I know.
you need a data labeling service, ideally.
Now, I do actually think that there is a way to attack this problem that doesn't require a data labeling service, but I haven't proven it yet, so maybe I'll see in 2019 and we can talk about it then.
And I wanna switch gears a little bit now and talk about sort of our data herd.
So I mentioned before that we have roughly 600,000 5v5 matches per day.
And for each of those 5v5 matches, to evaluate all 10 players, there's roughly four minutes of work that we have to do.
And so if you do the math, you figure that is 2.4 million CPU minutes of work that we need to do every day.
And somehow we need to fit that into 1,440 actual minutes, because that's how many there are a day.
And you can do this by just using a bunch of processors.
We need about 1,700.
So that's what we did. We bought a giant farm of machines.
And this is actually only used, this is not used for training, this is only used for running the inferencing sides of things.
And this is actually only half of the farm.
The other half is in a different data center.
This is our actual farm. I took this picture.
I went out with the DevOps team when we got them.
I was like super excited. I'd never been to the data center before.
And it was like candy trip, it was great.
And then I was like, wow, it's really loud in here, and it's really cold on this side, and it's really hot on that side.
But it's totally worth going.
You should go if you get a chance.
Anyways, what we're looking at here is basically these two chassis.
And each chassis basically has 16 blades.
Those are the things that are sort of vertical.
And each of those blades has 54 cores and 128 gigs of RAM.
So they're pretty beefy.
That's about 3,500 processors total, and we bought basically 2x what we needed so that we would have room to expand, and we'll maybe talk about that in a little bit too.
Like I said though, this is basically only used for inferencing time.
This is like, I've already built the meat grinder and now I need to actually watch all of the matches.
And like I said, 95% of the work is basically around turning a cow into meat.
For us, 95% of the work is like cracking the demos and then building inputs out of that to feed into the learner.
And then it's like 1% of the work is the part where it's like, by the way, does this look like a cheat?
The part that we do the training, the part where we actually build the meat grinder, that part is just run on commodity 1080Ti's that sit under our desks.
Like, it's totally normal hardware.
Okay, so now I want to talk brass tacks.
I want to talk about, like, what goes into the cubes of meat that we're feeding our models.
Deep learning has sort of these specific input constraints.
In our case, we've said, it's a cube of meat.
And that means that the meat needs to be sort of uniform and fixed size.
And if you're uncomfortable with the meat analogy, and maybe you're familiar with SQL, then you can kind of just think about like, this thing just needs to be fed with a database where all of the columns are non-nullable.
And every time you run a query, you always make sure you ask for all of the columns, and you ask for the columns in the same order.
And deep learning needs to sort of...
Deep learning algorithms need to be fed in that way.
Now, if you recall, we decided that we were going to specifically target aim assistance first.
That was the first thing that we were going after.
And if you think about when somebody is cheating using an aimbot, they're going to basically use...
they're going to express that cheatiness when they're firing bullets downrange.
And so we basically did some manual feature work around that.
So here we're going to sort of have this atom on the right and we'll fill the atom with stuff.
And the first thing that we decided to stuff into the atom was like, what weapon is the person using?
Are they using an AWP? Are they using an AK-47? An M4A4? Because no one uses anything else.
They're using one of those.
And then...
It's cool.
There are other guns.
They're great.
You should try them.
Then we want to know, basically, what was the result of that shot?
Was it a head shot?
Was it a hit, but somewhere else that wasn't the head?
Was it a total miss?
And we want to stick that thing into our sort of atom of stuff.
And then we want to know, like, hey, given that I actually did manage to get a hit, because I don't have the answer otherwise, how far away was the target if it was a hit?
And we have a sort of special value that we reserve for the cases where we're like, I don't know, it didn't hit.
And the learner is fine with that.
And then this one requires kind of a little bit more unpacking.
What we needed was basically the sort of delta view angle pitch.
And so what that means is like for about a half second before the shot and up through every tick until a quarter second after the shot, we basically say like what is your delta pitch on this tick versus the previous tick.
and we just repeatedly do that.
And a half second before and a quarter second after were sort of chosen purely capriciously, but we take all of those and we stuff them into our atom.
And if you've been watching the atom, you might have noticed that like, everything lands in the same place every time.
Like we make sure that all of the data lands in the same place every time.
Because deep learning doesn't really care where it is, but it cares that it's consistent every time.
Like that is a necessary property in order for it to learn.
So then, with the delta view angle, sorry, I probably should have clarified, and I will do that right now.
The view angle is obviously just like the way that you're kind of looking around.
And before, we were looking only at pitch, which is basically your up and down.
So we were like, hey, you looked up one degree, hey, you looked up two degrees.
And then we need the same thing for yaw.
So we want to know now right to left, how much did your view angle adjust right to left, but only as expressed as a delta against the previous tick.
I turned right one degree, I turned right two degrees, and we're only doing this in the windows around when you take a shot.
And so we do this again, half second before and a quarter second after, and this was sort of picked purely capriciously, and then we stuff that thing into our atom of stuff.
And so we have our X, right?
Well, not really.
Because if you recall, our training data is not that this particular shot came from a cheaty demo and this particular shot did not come from a cheaty demo.
Our data is labeled where it's like, hey, in this eight round window, something somewhere in here triggered a juror to decide that this behavior was cheaty and convicted.
And it, sorry, it convinced a bunch of jurors that this behavior was cheaty.
So we can't just use one atom, because this is only the information about one shot.
We need a sequence of them.
We need a big sequence of them.
And in fact, actually what we want is 140 of them.
Or at least that's what the model uses right now.
It's also sort of purely capricious.
And I will make a slight apology, because...
This is a cube of meat to go with the metaphor we've been doing, but actually it is just a serial representation of 140 shots.
We just take the 140 out of an eight-round window, and we stuff those into the model, and then we're like, hey, if you were to present this sequence of 140 shots to a juror, what is the likelihood you would get a conviction?
Okay, so I spent a bunch of time early in the talk talking about how we can't talk about anti-cheat because talking about anti-cheat makes it not work anymore.
So did I just spend 40 minutes like lighting this technique on fire?
It was like a year of work overall.
I mean, we deployed it in like four months.
We're pretty excited about that, but like, did we just light this thing on fire?
And the good news is no, no, we didn't.
It's great.
Let's talk about why we didn't light it on fire.
So if you recall, my original sort of elevator pitch was like, hey, we're going to train data from VACnet, sorry, from Overwatch, and then we're going to have it monitor matches, and we're going to submit cases, and the players are going to determine guilt.
And the reason that we didn't like this thing on fire is because we're actually going to do that thing in a loop.
We're just going to do it over and over and over and over again.
And because we're using Overwatch and we didn't actually replace all player reports, we just supplemented player report behaviors, that means that the learner is getting the opportunity to evolve along with human jurors.
So as human jurors identify sort of new cheat behavior, the learner has the opportunity to do the same thing.
So you can think about this a little bit, like imagine that you're a cheat developer and there might actually be one in the audience, I'm not sure.
But you're a cheat developer, and you're like, aha, all I need to do is make my cheat look cheaty three quarters of a second before a shot, and then look totally normal through the half second, and then get the kill, and then move on.
I think that's extremely improbable in the first place, but it actually won't work anyways for two reasons.
And one is that human jurors will just be like, yeah, dude, I don't care.
That looks cheaty.
Like, boop, conviction.
And then the learner will retrain, and they'll be like, I don't know why locking on in this particular way is considered to be cheaty to humans, but in order for me to do the best job I can do, I need to label that as cheaty.
So it will just learn to think.
And the other reason is that even if that didn't work, Retraining like we chose half a second before and a quarter second afterwards just totally capriciously We could just make it three seconds before in two seconds afterwards and the model would be just as happy it doesn't care it would effectively Result in us saying like oh we need to retrain So let me take the five seconds to find the command in my command history and press the button to start the retraining And then that'll run for six hours and when it's done Now it's happy with looking at stuff and for that one.
All right.
So I think we're mostly the way through.
Let's talk a little bit about sort of ongoing and near-term work that's going on around this.
We're doing, so one of the things is, like I mentioned, like right now, when we retrain, we still sort of just go and look at, like we basically just look at, like, how is it doing?
And then we decide, like, okay, now seems like a reasonable time, I'm gonna go retrain.
And I don't think that's actually the right answer.
I think the right answer is to just totally get us out of the loop and instead basically just say, hey, like on a cron job, this should just once a day retrain.
And then if it's convicting more stuff than the previous version, then we should just deploy that one.
And we should just make that heuristic base and get totally out of the loop.
The other thing that we're kind of working on is basically new learners.
And The learner that we built, the features that we built, are sort of based around catching aim bots.
But we actually think, and part of that was because we didn't have enough data yet that we were willing to sort of go whole hog on this.
But we think that a better approach is actually instead to just sort of build a first person narrative for each of the players in the round and say, like, I don't know what matters in here at all.
And I don't want to do any input engineering.
I just want to basically say, here is a first person narrative for this player.
If you take eight round windows of this first person narrative, does that look more like a cheaty first person narrative or more like a non-cheaty first person narrative?
And we think that that model is much more likely to be able to attack the other types of cheating that we see, so like wall hacks.
and so on.
The other thing that we've been kind of working on is generalizing BACnet to other game modes.
So we deployed to, we have a 2v2 competitive mode that's pretty popular, and we deployed to that a few weeks ago, and the conviction rate in that mode was like 99% for a while.
It was great.
Cheaters didn't get the memo that we were doing it, and players were super happy, and we were just busting cheaters left and right.
It felt so good.
Finally, we're actually looking to generalize VACnet to Steam.
We think that both the model we have and the model that we're moving towards should actually, with a relatively small number of examples, should generalize to other initially first-person shooters, but then later to just other games in general.
And we're definitely looking for partners to make that happen.
So if that's the thing that you're interested in, we should talk.
All right, let's finish up.
So basically, I think, hopefully, I've maybe convinced you a little bit of this, but our sort of opinion at Valve is that deep learning is just this sea change technology for evolutionary behavior.
We think that it is really actually helping us get developers off of the treadmill without impacting our customers in any way.
Like, our customers are seeing fewer cheaters today than they have been, and the conversation around cheating has died tremendously compared to where it was.
before we started this work.
Like I think the volume, and I'm sorry to give a crappy anecdote, but I think the volume based on CSGO team feedback and sort of eyeballing the Steam forums and Reddit, it's like the volume of the conversation is probably 1% as loud as it was.
before we started this.
Now we're applying deep learning to a bunch of problems at Valve.
There's anti-cheat and anti-fraud.
Dota hero selection uses deep learning and it shipped a week and a half ago.
There's some other Dota stuff that's more complicated and I don't want to explain Dota so I'm not going to talk about it, but that stuff shipped using deep learning as well.
And there's a bunch of other work going on as well.
So I mentioned before, I would not try and teach you deep learning, which I successfully avoided.
And instead, I would point you at some resources.
The foundational work I would sort of suggest, this Udacity course is really useful if you are a super high-level user.
and you do not give a crap about how the insides work, the Udacity course is actually great.
Like, you will come away with an understanding of, like, sort of how to build systems that use deep learning, but you will definitely not understand the guts.
Meanwhile, the Coursera course, the machine learning course, will help you really, like, actually build the pieces from the ground up.
So if you're kind of more like me, where you're like, no, I need to see how the sausage is made at least once.
I recommend the Coursera course.
They're both about, they're each about 30 hours of study, you know, that you can do sort of at your own pace, and they're both great, I recommend them both.
Additionally, once you've done that, and I point you at the machine learning courses because it turns out everything that you, or at least most of the things that you learn around machine learning will be super, super helpful at understanding deep learning.
But once you've basically done either of those, I suggest basically jumping into either the Coursera course that's deep learning.
specific on Coursera, or the Stanford course, CS231N, with Fei-Fei Li.
All of the material is online, except for the lectures.
Good news, they're a bootlegged version of all of the lectures on YouTube.
I highly recommend the ones with Andrej Karpathy, but they're all good.
And so you can go through basically the whole course.
All right, so hopefully people have some interesting questions.
If you have questions, please walk to the mics.
I did want to mention that sort of the whole thrust of the talk is like how we can sort of increase value that we deliver to customers and deep learning is an important piece of that.
But like the other way is like to just get more awesome people at Valve.
So if you thought this was interesting, you should definitely apply at valvesoftware.com slash jobs.
And also while it's hard, one more thing is please fill out the surveys.
Pretty please.
Okay.
I'm going to go first, but I'm not positive.
you Oh, so I ain't a vegetarian.
But OK, I'm fine with that part.
Anyway, so there's a project I heard people working on.
That was the Unreal Tournament, where people were actually using machine learning to train robots to play like a human.
So do you actually see that as a concern in this problem space?
I see.
So the question is, am I concerned that somebody will basically counter my deep learning approach with a deep learning approach, trying to play like a human?
So no, that is a really good question.
Maybe.
So there might be a little deep learning specific, apologize.
There's maybe an attack with GANs that might sort of yield fruit, but I don't know for sure.
That's definitely something that somebody would have to spend a lot, a lot, a lot of compute time on.
So that translates to them spending a lot, a lot, a lot of money.
And otherwise, they just don't have the data.
Like a slide that I didn't have up here, but that's sort of fascinating about deep learning, is that it turns out that the algorithm you pick.
in deep learning and machine learning, it doesn't matter.
The thing that matters is more data.
Like, more data wins.
And so the problem is, somebody is going to either need to outspend the amount of data that I have, because I have lots of data.
And also, I could just do the same thing.
Or they're going to need more data than I have, and they definitely don't have that.
So that was a good question.
Thanks.
Yeah.
When you showed the rainbow slide, you said that...
Rainbow of trust. Let's go back to that one.
That you weren't sure about any of the players, but you were more sure that some of them were more likely to be cheaters, right?
That's right.
So, in order to make a better experience for the blue guys, Yeah.
Five of the red guys who aren't cheaters, but for some reason you mislabeled them as untrustworthy, because they're not cheaters, you just think they're more likely, you're going to ruin their experience, like, completely, right?
Aren't you worried that you're going to make them churn in order to make the others have a better experience?
Yeah, so that's definitely a concern for trust.
That's definitely a thing that players are concerned about.
But we haven't seen it actually bear fruit.
That model also tends to be very conservative.
So we're actually, despite what I'm showing here, we're actually more likely to accidentally slip somebody who is a cheater into blue than we are to get somebody who's red to accidentally qualify somebody who's orange is red.
So you would recommend using this if you're really sure that they're cheaters?
Yeah, you want to be sort of very...
You want to be certain that they are very likely to go on to be cheaters.
Like most of the people that get caught there are actually in the situation that I gave the anecdote about, where they have many accounts, and most of them have been backbanned.
Okay, thank you.
Hey, yeah, um, so I'm a big fan of you guys using cat humans in the loop to make sure you don't have false positives. Uh, but how are you planning on extending this layer for it for like, for example, you're asking for partners for this and those partners may not have the level of community participation that that, uh, you, that valve does.
Yeah, that's a good question.
We haven't thought that far yet.
I think that probably it's possible that the actual feature would be the whole thing, like Overwatch and everything.
That's one possible approach.
The other would be to use something like this maybe instead to.
Basically to feed into something like trust score where you're like I'm not taking as nearly as harsh in action Like I'm not banning you and taking away your stuff instead. I'm just like yeah, I don't quite trust you as much So I'm gonna stick you with other people who I don't trust quite as much So I think like soft punishments might be a better choice for a smaller partner. That's good question. Thank you Hi.
Hi there.
Are you seeing an increase between the overlap of cheaters that are really bad players and actual legitimate good players?
And how do you deal with those scenarios?
I'm not sure that I understand.
Can you rephrase that?
So at some point, a very good player is going to look like a cheater.
How do you deal with that scenario?
I see.
It turns out, so Overwatch, so the question is, how do you tell the difference between somebody who's just really good at the game and a cheater, right?
And it turns out, that the things that Overwatch is good at catching are not, like Overwatch doesn't catch subtle cheaters.
Because we ask players, like, don't convict if you're not sure.
And so they're like, that is plausibly just a player that's really good.
And so they just take the not guilty button.
And we've sort of hand verified that tons and tons of times, that like, hey, let's spot check convictions and make sure that people are still not convicting things that they shouldn't be.
And we haven't found a single case of it.
That's not to say there hasn't been like one case in all of Overwatch, like there probably has, but we haven't seen it.
Hi.
Are you at all concerned about the possibility, now that your secret is out, of cheat developers polluting your data pool by putting ringers in your jerrys?
Am I worried about... So am I worried now that I've basically shown everything about cheaters polluting my data?
They'll try.
I'm not really too worried about it, because humans should be able to tell the difference.
Like, that's kind of the fundamental premise that we're going on.
And so if humans decide that that behavior is cheaty, then the learner should decide that it's cheaty as well.
But it's possible.
Like, it's definitely, we'll see.
Maybe I'll be back in GDC 2019, and I'll be like, don't talk about cheating ever.
This was a terrible mistake.
But I don't think so.
That's a good question, thanks.
Hi.
Great talk and great analogy.
I really like the...
Yes!
One for and one against, all right.
They remind me of the burger I had yesterday, the SuperDuper burger.
Good, good, good.
I have two questions.
First one is about the actual data shape.
Like you showed it, the cube-shaped data, but I don't think that is actually cube-shaped.
No, no, it is not a cube.
Yeah, so I was wondering, is it like the one user represented as a long vector or a matrix of...
Yeah, so what it is, is it is actually, it is totally sort of serial data.
It's just serial data doesn't look very good on a slide.
But it is basically just like, here's all of the information about a shot, and then repeat it 140 times.
And if a player, I didn't really talk about this at the time, but like, if a player shoots, say, 200 times in an eight round window, then we just build like 60, 140 shot windows, and we ask to inference all of them.
would any of these result in a conviction.
But there are, yeah, like it's like you could just sort of imagine a timeline where somebody takes a shot, every single time they take a shot, and then we're like, great, let's look at, like that is our whole timeline, and then let's build sliding windows of 140 and see if any sliding windows will result in a conviction.
I see. And my next question is about the deep learning architecture.
Oh, I have a slide for this.
Let's, here, I'm just going to, oh wait, maybe I can, no, I'm sure it won't.
Sorry, maybe I can skip to the PowerPoint.
I'm so pissed about those graphs.
So I actually have the slide for exactly what our architecture is.
Bam!
I'm so glad I kept this one in.
So we use an RNN.
I'm sorry if you're not a deep learning person.
We use an RNN because we have sequence data.
And the only sort of weird thing is we're actually using GRU and ReLU activation actually works better.
Most of the time, ReLU occasionally, when we're training a model, it'll just be like, I just can't converge.
But actually, most of the time, it does converge, and it does significantly better than tanh.
So that is surprising.
And otherwise, this stuff is all just totally, purely capricious.
Like, we just searched, we just did like a grid search, and we treated all of the architecture like a hyperparameter, you know, like a set of hyperparameters as well.
And that is like the thing that currently works the best.
Could change tomorrow, but that's what it is today.
I was wondering if you have also tried like one-dimensional convolutional neural network, which...
It is high on my list of things to try.
Thank you very much.
Yeah, cheers, thanks.
Hi.
So as a person who does a lot of Overwatch cases, it's kind of interesting to see how you're using this data.
Wait, hold on.
Thank you for your service.
Yeah, no problem.
OK.
So I'm kind of curious about the more subtle cases, because just speaking purely as a person who does Overwatch cases is there are a lot of times when you aren't certain.
And I think the language is actually really good about really convincing you that you really have to be.
very sure. Evidence beyond a reasonable doubt. It's very, you know, we're very precise. Yeah, legally precise. Except when we get talks. So I'm kind of curious about how you go to approach the subtle case and if maybe you could talk a little bit about how to tackle that, if it's going to be like an unsupervised approach that maybe bears fruit there or?
Yeah, so I think an unsupervised approach is going to have to be the answer. Like I think If, again, sorry, deep learning, a little nerding, I'm pretty sure it's gonna need to be an unsupervised approach, and I think probably it'll be around outlier analysis, but I haven't done much work on it yet.
But I think that's probably the only thing to do.
The thing that's a little trickier for that is actually the policy decision around it, instead of the, hey, given that I make that thing work, Now what do I do?
Because humans are not convicting that.
And I would need to have extremely high confidence that a person was cheating in a subtle way before I would be willing to take action against them.
Because I'm putting a black mark on their Steam account.
I'm taking their stuff away.
They don't get to play on back-secured servers.
So we need to be very, very careful around what we do punitively in that situation.
But it may be that you feed it into trust and then you're just like, hmm.
I think it's also interesting, have you done experiments with how tick rate affects this?
I'm sorry, how what?
How tick rate affects...
Oh, tick rate.
Because you have a relatively high tick rate at 64, which gives you sort of a lot of moment-by-moment data, and I don't know if having a higher tick rate or a lower tick rate evaluation of this has any impact.
So overwatch cases are actually handed down only at 32k.
They're already stepped down and so we actually just work on that data.
Okay, cool. Thank you.
Cool. I think I have like time for one or two more questions probably, although we're the last people in the room.
So maybe we can go a minute or two long, maybe.
Okay.
Cool. Kind of dragging on ahead, I love Counter-Strike by the way.
Yay!
I play it a lot and everything.
going on with that, right, definitely I think the data part will always win. You guys always have the data and you can always get the data so I'm sold on the machine learning part. But when SteamOS came out, I was actually hoping, you know, we've got Twitch going big and we've got people making entire livelihoods on this now. And it made me wonder why, you know, we have secure boot, we have all these systems now.
couldn't we create, you know, in addition to this, could we not create a, a secure system in such that it's like for contestant play, you have to boot the sort of encrypted images that are a whole lot more secure. I mean, this is a whole nother conversation. But it allows you to do the things like, hey, did he actually move his mouse physically? Like, did I get XY input from that? Hey, did the DLLs exactly match, you know, I'm doing checksums and, you know...
So we've thought about this and like I actually, that was kind of the approach I ran down initially and there are sort of a few problems around it that kind of led us to go, ehh.
I think the easiest one is like, that feels super invasive.
right, like as a user, like I'm like, hey, what you need to do is play my game on like my OS and you need to see.
And like, I don't know, like, and the problem is ultimately at the end of the day, if the user has access to their system, physical access, there is nothing I can do to determine for certain that they haven't tampered with it.
Like, cause any query that you're like, well, you just asked them this.
I'm like, so what I do is I hijack that function and I lie.
Because I did that.
I've done that.
It works great.
It's turtles all the way down.
It is.
Ah, but it may not be, and maybe we should talk later.
Right, right.
Cheers.
Oh, yeah.
Hi, great talk.
Quasi-related, because you mentioned Reddit in the forums a lot, at any point did you develop something to sort of scour those in terms of watching trends for like...
No, we haven't.
Maybe we should.
The question is, do we have tools to scour Reddit and quantify things better and other forums?
We don't, but maybe we should.
That feels like a thing that actually, and performing sentiment analysis, in particular being like, hey, is there a new topic that is currently lighting the internet on fire?
That might actually be a pretty valuable thing, but it's not a thing that we have right now.
Yeah, that would be great, though.
I have two questions.
First, great talk.
Thanks.
So firstly, how long does it take to train the data?
And how much data do you use?
So we have about 700,000 labeled pieces of data now.
And it takes about six hours to train on 1080 Ti.
On one 1080 Ti.
And we're actually working on parallelizing it and feeding it to a bunch of V100s.
So we'll bring that down to.
10 minutes or so, pretty soon.
Cool.
And the second question, have hackers tried to play the Overwatch system and ads on people who just pass everything?
No.
Well, sorry, maybe.
Maybe they've tried.
But one of the things that we do in Overwatch is we pay attention to how good you are at Overwatch.
Like how often you go and agree with the consensus.
And so somebody who is just like, not guilty, not guilty, not guilty, not guilty, and they do that repeatedly on cases that get convicted or the other way, like they try and pollute it the other way, they get basically to the point where we're like, you can keep doing cases, but I don't believe you anymore.
So, have a good time?
Yeah.
Okay, cool. Thanks.
That's a good question.
Hey, um...
I think these are probably the last two, just so we're...
Thanks a lot for the talk.
Now I really know what your next game is going to be.
It's a VR simulator of Meat Grinder.
That's right, Meat Grinder.
Sign me up for that.
That's right, that's right.
But, uh...
I have a question from a different point. Obviously you're talking about real customers, the real players playing and that's why you have created that system. I work for competitive play so we see lots and lots of games happen when people play for actual money and I think CSGO is the biggest game in this amount in terms of volume. So many tournament organizers running so many tournaments, so many games are being played.
And the level of cheating there is slightly different.
People are using enhancement drugs.
They can throw matches.
And I'm just curious, is there a way for a deep learning network to try to sort of siphon through that thing?
Or we, as tournament organizers, should look elsewhere?
Obviously, we are doing it physically when LANs happen.
Everything is secure there, but I'm more curious about online qualifiers.
So the question is basically how do we do this for pros, right?
Or how do we do this for, uh, as tournament organizers?
And, um, I think that there probably is an approach there that works, uh, but I don't have enough confidence to talk about it right this second.
Um, but it is definitely a thing that we're thinking a lot about.
because we think the integrity of the pro scene is super important.
Like it's really, really important.
So it's definitely a thing that we're thinking about, but I'm not quite ready to talk about exactly how we think it'll work.
Yeah, thank you.
This is a great question.
Last one.
Hey, I'm wondering how many of your players have to weigh in on an Overwatch case before it is closed one way or another, and how many Overwatch cases do you close every day?
So I can't comment on the second one because the team agreed that it probably was not actually that useful to talk about.
The first question, how many players need to weigh in?
So it varies.
I'm trying to answer and not be hand wavy.
But it kind of depends on how long it takes to converge.
Like cases can be sort of.
Rejected like if you get if you just happen to randomly hand the case out to a bunch of people who it turns out are Like they're always right. They always go with consensus then maybe it takes as few as seven of them to agree that That a person is you know this thing is super guilty or this person is definitely not guilty.
It might take as many as 50 or 100 if it's something that's like a little sort of less certain or if, you know, there are people that are new to Overwatch and we're not sure, you know, about how good they are at identifying the conviction rates.
All right, thank you guys so much for sticking around through the graveyard shift.
I really appreciate that.
It's great.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
