effects for stylized games.
The format is micro talks, so there are about 11 minutes each, there will be four speakers, hopefully time at the end for questions.
The idea is that there's four completely different projects from different companies, all with different visual styles and goals, and hopefully I'll come away with different approaches to stylized effects.
So why are we here?
A lot of times effects teams for games can be short-staffed and you've got a lot of work to do, so you're often left to do a lot of the art direction on your own, and you don't usually get a lot of concept art and iteration in that way for effects.
So, games with a more realistic style often is a lot clearer to understand where you're supposed to get to.
With unique art styles, it's a little bit harder to find the path to the final result.
So we've got myself, Jeremy Mitchell from Double Fine, Shin from Motiga, Bill Kladis from Epic, and Brianna from Volition.
So me.
My name is Jeremy Mitchell.
I'm a senior VFX artist at Double Fine.
I've been making games for 10 years or so.
Here's some games I worked on.
And today I'm gonna talk about Headlander, which is a side-scrolling action game from Double Fine.
And just so you know what it's about, I'll play this little clip from a trailer.
It's not a whole trailer, just a short clip.
Just been revived, but they're just ahead.
Living in a helmet that is a scientific miracle.
With this helmet, our hero can thrust through the air, remove those pesky heads, and duck into their neck holes and take the wheel.
Headlander!
Yeah, that's good. Okay.
So, as you can tell, Headlander has a pretty unique visual style, it's based heavily on themes from 70s sci-fi movies.
So, the goal of the game was to capture the look and feel of these movies.
So, the point of this short talk is about my approach and thought process when trying to do effects for this game.
So, since we wanted to look like they were plucked straight out of a 70s sci-fi film, we looked at a bunch of classic films, like the ones you see here.
to reference themes and ideas for just the overall design of the game.
And for environment art and the general art in the game, it was pretty clear that you'd use 70s sci-fi sort of design inspiration, but for effects it was a little harder to tell exactly where we should go.
So when I was watching these, I noticed a few key points about effects in these films.
The first is that there's two types of sort of styles for VFX.
The first is sort of standard Hollywood practical effects.
These are things that are shot on set, filmed with real lighting in the real world.
And there are generally 2D hand animated.
rotoscope effects that are done through film process after the fact.
And these generally tend to sit on top of the frame and not integrated well with the background.
And there are a few artifacts that give this away.
So you can see here, this shot from 1979's Black Hole, these laser hits, not integrated with the background at all.
You can see these little sparks that come off of them, they're clearly hand animated.
But then there's these blue flashes that are definitely shot on set, practically.
So the things that give it away are like a lower frame rate, the lack of.
lighting influence on the environment, and often the hand animated effects will drift or stick to the camera in strange ways, which is an interesting point for a 2D side-scroller game where you kind of want the gameplay-centric effects to be separated from the background.
So the idea was to extract these sort of artifacts and wield them for stylistic direction.
So this was sort of a loose rule set going forward is that any effects that would be real world, if it were a film, would just be done with traditional like fluid sims and textures and all that, nothing unique there.
But to keep the film metaphor alive, anything that would have been done in post with sort of a chemical process or hand animation, I would try to play up the cheap 2D effect to capture some of that vintage artifacts.
So I'm not really going to talk about explosions or any of the traditional VFX stuff because that's Well trodden ground, but I'll move on to something more exciting in my opinion, which is bad animation So when I first got started I did a handful of like somewhat detailed like hand-drawn animations The problem with this is I'm not an animator. This is probably the best stuff I've ever done so I It was kind of an uphill battle and I didn't think that I would be able to do hand animated assets for the entire game for every effect.
But I liked the look of it so I wanted to figure out some kind of solution to get to that point faster.
Here's a few more examples of it.
So when I was looking up reference for this stuff I found this video from 1983.
It was a...
the making of the HBO intro sequence.
And they had this really cool dynamic like starburst effect you see there.
And when I'm looking at it, I would have assumed that was just hand animated like every single dot.
But it was actually, as you can see here, it was just two transparent screens run across each other to create this sort of slit scan effect.
It's like super cheap.
And the thing that I learned from this was that when approaching these sort of effects, even the experts cheated and that you should try to do the same thing.
So this was the first effect I did.
Probably one of the first things I made for the game.
It's sort of like our Star Trek transporter.
You'll see it probably hundreds of times in the game.
It's all over the place.
And it's actually just like this little cheap 32 pixel small frame animation.
And it worked pretty well.
My thought process with this whole thing was that I would establish a rudimentary structure with these tiny animations that I could do quickly and then just slather it in post effects.
So this was pretty much how I did most of the effects on the game.
Here's a charged slide attack done the same way.
You can see it's just a handful of tiny frames covered in channel splitting and blur and all that stuff.
Here's another example of a similar thing.
Using just a couple of assets mixed together, it looks a lot more complicated than it is.
So another thing I did a lot of was screen space effects, which plays into the sort of film post-process sort of stuff.
This was a reference from a Foxy Brown 1974 film.
It's not exactly sci-fi, but...
This sort of cut out silhouette effect was used a lot in the 70s.
So we tried to do something similar.
This was a mock up done in After Effects and then here's a version of it in the game.
Yeah, so the point of this one was that clearly the effects stand out from the background but it totally sells the 70s aesthetic.
Another example is these shield effects.
So when the character's powered up with the shield, this is what happens.
So originally I'd done it with a pretty traditional sort of mesh with a fancy video game shader on it, but it never seemed to really fit in the world.
Didn't really get that separation of like...
fake effects versus real effects that I talked about earlier.
So, if this were done on a film, this would have been like sort of hand rotoscoped every single frame, run through some multi-chemical bath process and lit from the back and all this crazy stuff.
But in video games, we just render to a separate buffer, run a ramp shader on it, and it's done.
Similar, there's another example of a crazy guy.
use it here as well, this was a terminal that you need to disable the shield before you can use it.
And originally I had a very complex, crazy mesh with a shader on it and this was just a bunch of spheres and you set them to render to that buffer and then you get this weird sort of cheap post-process effect.
I use it all over the place.
This was some particles, I could just tell the particles to render into that buffer, and it did a lot of crazy stuff.
Use it in the intro sequence, just absolutely everywhere in the game, because it looks really cool.
So final thoughts for my section of this.
Not every game, obviously, can be intentionally cheap, right?
And not every game is set in 1970s science fiction.
But the key point is that you should approach your work from every direction and you should not be afraid to try completely different workflows than you're used to.
Because the effects that work for one game probably don't work perfectly for another game that you're working on.
So you should try to distill your art direction and inject that directly into the creation process and you might be surprised with what you do.
So, there you go.
Shannon is up next.
Hi, I'm Shen Ming Spurgeon.
I'm a senior effects artist at Motega in Bellevue, Washington.
And I'm here to talk about the way we think about our effects and the process we have when we are creating our effects.
Gigantic is a MOBA, and a third-person shooter with five-on-five PVP action.
Players choose from a huge roster of characters, and those characters have lots of unique weapons and abilities, and you're fighting against the enemy team to take down their guardian.
So you'll power up your guardian by using creatures that you summon, and hopefully you'll just kill the other guardian.
We believe in, for character design, we believe that personality takes precedence over realism.
So we think about what is that character about?
How do we describe that character?
one or two words or maybe a sentence. Uh, the character up here is HK206. Uh, his design says robot, firepower, clunky. Uh, in our game HK is a jittery bucket of bolts and he roams around shooting missiles and spraying bullets everywhere.
We have another principle that we also adhere to for characters, and that's shapes being the first priority, and then we look at anatomy second.
So Uncle Sven here, he's very inaccurate as far as anatomy goes.
He's basically a water balloon that walks around.
And so his big shapes take priority over realistic anatomy.
And if a character has thin stick-like arms, for example, we keep the shapes in mind, and we try to fill the anatomy into them later.
So strong shapes are gonna define that character.
So how does this fit into effects?
So on the right, we have what we do, and then on the left.
Yes, no, that's incorrect.
Other way around.
We have one realistic fire here, or one realistic explosion here, and another stylized one.
The unrealistic one is obviously gonna work a lot better, just because it fits in with the characters more.
But the principles are important because we need to make sure that feeling carries over to our effects.
A realistic explosion is also not gonna be very dimensional for for our work just because it's going to be on a billboard.
So how do I simplify this explosion or a muzzle flash?
One of the things that we do is pay attention to those shapes and the choices we make, and we try to imbue some sense of personality into the effect.
But that doesn't mean we don't fill in the gaps with exaggerated realism.
So this diagram represents who the stakeholders are when it comes to creating characters.
Some studios structure their teams where only certain people are influencing the visual and gameplay direction of the game, and that only allows people to experience a very particular vision.
For us, we start to incorporate a lot of the employees, even down to QA.
You'll see that we don't have an art director.
And that's been a fairly positive experience for me.
It's new, but just different.
The limitations force us to seek out information rather than letting it just come to us.
And so, at the end of the day, from concept to playing the character in game, we're left with a character that we feel is the right move for our roster.
And that's it.
That's how you make a bunch of stylized characters and effects in The End.
So super easy.
No, I'm just kidding.
So actually, I'm not done.
What happens is now I have to figure out what I'm doing.
I have to get the character, see its animations, figure out who she is.
This is Beckett.
She's our professional adventurer.
She's mobile.
She's got a jet pack, and she's armed to the teeth.
And I need to figure out what her visual effects are going to look like.
So I explore what her personality is.
Is she fun-loving?
Is she scholarly?
Is she a bit of a gearhead?
What sort of role does she fill in the game?
Is she offensive?
Is she a defender?
Does she work paired up with another person?
These are all things that slowly develop the effects because it's not just making a muzzle flash and calling it good.
So what kind of weapons does she have?
For her specifically, she has guns that transform and...
a jetpack that she flies around with.
But we've also got to figure out like, how does magic, how does that look for magic fit in with more ballistic effects?
So on the left we have HK's fortified minigun.
And on the right we've got Charnok's meteor.
In Gigantic, our characters need to feel unique from one another, and their weapons and mode of transportation also need to feel intentional, as if they've always belonged to them.
On the right again, we've got HK's grenade and Beckett's grenade.
And I really wanted the two to be distinct from one another.
While existing in the same world, they need to feel again, unique.
So I made her grenade to be more of a gas explosion type instead of a concussion or shrapnel grenade.
What you're also seeing for Beckett is an older version.
So we'll dive into what it looks like soon.
So we've asked who Beckett is, we've considered her weapons, and now I've got to think about what that visual language looks like, and does it share anything with anybody else?
Is it whimsical, is it dark?
I need to ask these questions of myself so that I can get to that point of making them for her.
So let's dive into the tools.
We use Unreal 3.
You guys might have heard of it, but Unreal 4 is out now.
We also use Photoshop for textures, 3D Studio Max for mesh creation, and then Rayfire for any destructible stuff that we need to do.
So these are the high-level goals that I try to keep.
I wanted to avoid drawing anything, so that was going to be really time-consuming.
and also doing any sort of 2D effects was also gonna be limited to camera-facing billboards.
So I removed all that and tried to focus on like using just meshes, because you can observe those from 360 degrees.
Let's see.
We have a lot of characters and we need to make sure that the characters fit the character, but they also need to not take away from gameplay.
When you start making a bunch of unique effects for like 16 plus characters, you start to get a lot of effects noise and you need to make sure that gameplay is not impacted by that.
On a personal note, my own goal is to create an effect that I wanna see over and over again.
Audio artists have to think about what sounds will be like over and over again, and sometimes that can get grating, and effects is the same way.
You don't wanna see something silly over and over again if it doesn't feel right.
These are the restrictions that I've had to enforce on myself.
So again, it can't just be specifically sprites because that's not going to work when I run around in circles.
I need the effect to work on uneven terrain, so I need to think about the environmental considerations for that.
and possibly even have it disappear quickly or just sink into the ground.
And lastly, performance is the big thing.
That's really going to determine how much I put into this.
Because we have the potential to have two beckets in a match, that's going to double the cost of meshes that are being utilized.
And because Unreal 3 is a forward rendering engine, meshes can be really expensive. Surprise.
So we're gonna go on to how am I gonna turn this into 3D?
This still is from the Jinx video that Riot made, and it looks super cool, super stylized, and this is just like one of the many references I pulled to make this explosion.
And so I need to think about where I'm getting my information from, and then what do I want it to be in our game?
I look at the assets that I also have available to me, what I can reuse.
So I've got like sparks and flashes.
But ultimately I want this effect to be a visual landmark.
So when a teammate sees this explosion, they can determine whether or not they wanna go to that team fight.
So when you're doing your research, take note of the shapes that you're gonna be working with.
Because that will help you simplify what you're doing when it comes to making geometry in 3D.
These are all my prototype meshes that I'd worked on.
Some of them are simple, some of them, actually they're all simple.
They're all just geospheres.
And each mesh represents some variation on the visual that I was trying to achieve.
Ultimately I learned that volumetric meshes were just the best way to go.
They give the dimension that I need to the effect and they can also be vertex painted so I can do cool stuff.
So the one on the far right is vertex painted and I'll show you what that looks like with the material.
It's a mask material and it uses a myriad of different textures to give the unique erosion look.
The color for the mesh comes from a parametric vector in the material instance, and the material's erosion comes from the color over life module in Cascade.
I use the mesh vert color node in the material so that I can separate that color information, basically allowing me to use it like another dynamic parameter just with the color over life.
I can't take all the time to explain how the material works, but I'm gonna burn through some GIFs that show what that color over life module does.
So on the left we've got the zero, everything's zeroed out, but then when you go from zero to five on the red, it makes the color black point in, and the green channel, when going from zero to five, will make the material black point out.
And then with all three in use, the blue will make both channels black point out, but then the red and the green will be black pointing in, blooming it, and then black pointing out eventually.
So on the left, we've got a wireframe of the meshes isolated.
So all that orange and gray stuff are those meshes.
And this is just to demonstrate that there's nothing being done to the meshes themselves.
It's just spinning and scaling over time, and then adding in the velocity-oriented bells and whistles later.
So the final asset looks like this.
And it used to have that giant pillar, but I changed that.
I wanted it to be more of a concussive radial.
have that look to it.
So the material in particular has allowed me to focus on the effects art style, and it's given us a lot of versatility with just that material alone.
We can drop it on a mesh, and it pretty much works out of the box.
I'm able to reuse that material and the mesh that I made originally for this airstrike that Beckett has.
Again, the intent was to let people know if they wanted to go and help or not.
And then this is one of our guardians rampaging through the map.
The smoke cloud from his exiting and entering is made up of two different meshes, but this is just another example of what that material can do and how versatile it is.
It's a different use of it, and we've taken that material and just duplicated it, adding a few extra components that are unique to that smoke.
But ultimately it's still the same material.
We utilize this material in melee swipes as well and a few other uses like ribbons.
So it's got a lot of versatility and I wish I'd showed more examples of that but that gives you another reason to just go and play the game.
So in conclusion, here are some rules that I think are pretty important.
The first one feels obvious but it's, sometimes ignored.
Some games keep doing the same thing that they did in the last title, mixing and matching effects, and sometimes that just doesn't integrate well with characters or environment.
So you gotta ask yourself, does the environment effects need to be more obvious than the character or vice versa?
And think about the rules that you're establishing.
Should we have transparent materials?
Should we have just opaque materials?
You'll wanna define your shapes, break down your effect into as many simple shapes as possible, that'll help you know where your visual noise is coming from, and it'll also help you focus on your solutions just by performance needs.
You wanna take some time to immerse yourself in as much stylized imagery as possible.
The more you consume, the more you'll have to pull from, and it just gets you more excited.
This is an official endorsement of Pinterest.
So please use that.
Always get feedback from people.
It's easy as an artist to hide yourself and just silo your work sometimes.
But you definitely need that feedback.
And you also need the feedback outside of the effects department.
Because the effects department's always gonna look for very nitpicky things, which is good.
But you also need to know if people outside of your department are understanding the work as well.
So talk to QA, talk to engineers, talk to people who don't do the same thing as you.
And lastly, just push the effect towards weird stuff.
Just get weird with it, make it bigger than you think it should be.
You'll end up with results that you'll be really surprised by.
So that's it.
Thanks.
Next is Bill.
Hi, everybody.
That's loud.
So thank you for coming.
My name is Bill Kladdis.
I'm a senior visual effects artist at Epic Games.
And today, I am here to talk to you about Fortnite.
Well, what is Fortnite?
It's Epic's upcoming survival sandbox game.
We're going to team up with other players to loot, craft weapons and traps, build forts, and defend against monsters of the storm.
So the image on the right here that you can see is 100% in Engine.
and it helps establish our visual style for the game.
It's bright, it's colorful, and in the styles that's kind of inspired by big studios such as Pixar or DreamWorks.
So what is the art direction for the effects inside of Fortnite?
If I had to try to map it out.
somewhere against the gradient.
I'd put a little bit in between anime and like a Pixar film, right, a little more of a bias towards Pixar.
We have contrasting elements, right, so we have things like smooth shading and fluid movement for things like smoke or the storm or stuff like that, but then we have like really hard edges and staccato timing like you would see in anime for like damaging and impactful effects.
And it's all, you know, they're bold, but they're not like overdone and they're not, you know, in terms of color and value.
So we can see a small taste of the different effects that embody this range and contrast that we have inside of Fortnite.
And the focus of this talk, I apologize, it's gonna be a little more technical, but we're gonna be talking more about like mesh particles and materials techniques and how we use them to achieve this style within Fortnite.
And you might be saying, you know, well meshes, why talk about meshes specifically?
Because they're not new, we've been able to spawn them for a long time within particles.
But we've got some new tricks and new abilities that we can do to make them even better.
Some of the things that we can talk about are, The advantages are that they have superior volume and shading over traditional quads or sprites.
They allow us to break away from flipbooks as the standard for what I call intra-particle movement, and that means movement within an actual single particle or sprite.
And in a stylized art environment such as ours, we can actually have some significant performance advantages in certain situations, which we'll talk about shortly.
So, like I said, we're just going to do some brief technical high-level overviews of some of the stuff that we've done.
So to start, we need to talk about the vertex animation tool because we use this a lot inside of Fortnite.
And in a nutshell, this allows us to animate with traditional rigs, deformers, fluid sims, you name it, and bake down that data into textures.
So on the left, you can see what I've made inside of Maya, which we're going to talk about here in a quick process.
And then on the right, we can see it used inside of Cascade.
So that's not a skeletal mesh.
That's a static mesh, and the movement is being updated through the material.
So how does it work?
Is it magic?
It feels like it when I get to use it because it's really empowering.
This was a tool that was made by John Lindquist.
He's a technical artist on our team on Fortnite.
And it uses two primary methods, and method one is the one we use the most is the texture-based method.
So it takes either an animation or a frame by frame snapshot of meshes, and it bakes down the delta, basically, which is the difference between the positions of the vertices in world space, and then their vert normals.
And it bakes it down to these two textures here.
I'm going to move the laser pointer so you can see.
This is the vertex position, and this is the vertex normal.
It looks like a weird kind of barcode.
And then it uses world position offset in the material and the normal input, and it just pans those frame by frame.
You can see that right here.
And it's updating the mesh as we go.
So it's all done through a material function.
We can get explicit control through a dynamic parameter inside of Cascade, a scalar, multiply against time, however you want to do it.
There's some really key advantages.
There's smooth interpolation between frames.
So when you slow-mo it or time dilate it, this isn't shown well in this example here, obviously, because it's going frame by frame in Maya.
But if you do it slow-mo in Engine, it'll actually smoothly interpolate between those.
And there's a lot of wiggle room that you can do.
Eventually it'll break down.
But we don't get that staccato frame by frame with regular flipbooks.
But there's disadvantages, right?
We're bringing in two texture calls, and memory, and material instruction count, and all that stuff.
Last thing is that it's a single mesh, so that means the topology has to stay the same.
So where I'm putting the laser pointer here, this is actually the first frame, and then it's being updated frame by frame after that.
So we can't change topology.
Excuse me, so how does this work?
Well, first we need to establish what we're trying to make and I've put together, or I grabbed a piece of reference for a like, I'll call it a smoke swish.
This is something that like when a character quickly runs, they leave like a swishing trail behind them.
So what I've learned is that working backwards actually is really powerful and it's a good place to start.
So to start with that, that means we need a model and I've modeled the final shape that we're going to animate in.
So on the left here.
I made a hysterically embarrassing layout of different spheres stretched out, and then I just brought it inside of ZBrush.
And I used two things.
I used Dynamesh and ZRemesher.
If you don't know what those are, Dynamesh is kind of just like a Boolean operation.
It just combines it all into one mesh, removes the stuff on the inside, so you have like a solid whole.
And then ZRemesher does magic, because I have no idea how it does this, but it gives you this awesome layout of quads.
that are really easily deformed and it'll move nicely when you deform it against a skeleton.
So it gives us a slider, we can adjust how much density you want.
In this case, this is probably pretty low in terms of ZBrush standard polys, that's only 1,030 hertz.
Then we need to be able to move it.
So I say, you know, model like it's 2D and animate it like it's 2D and even rig it like it's 2D.
So we wanna make rigs that support the intended motion and final movement, or final shape, excuse me.
So this has a very precise level of movement, right?
The swoosh that curls around.
Trying to do this with a fluid sim, I'm not gonna say is impossible by any means.
I think it would be difficult to arc control, right?
If your art director says I want it to curl a little more, a little less, or something like that, I think it would be very hard to do that.
So doing this manually by hand is really the choice, especially for us on Fortnite.
So what I did is I just made a spline and constrained those joints on the rig to the spline.
So you can see upcoming here when it loops, you can see as I move the joints right there, they're actually constrained to that spline and it gives us the curling motion.
And make sure you utilize everything, right?
Like I'm showing here, like scale, rotate, squash, you know, secondary deformers and things like that.
So, we need to bring it inside of the engine, and we need to be able to draw material on it.
So, what techniques can we do to self-style and preserve performance, right?
Because anybody that's an effects artist in here knows that we can break performance the easiest.
So, we're aiming for a stylized smoke, right?
This means simple shading, a three-color self-shaded highlight, which we'll talk about shortly, and like a hard erosion edge that you see in anime, where it kind of curls away from itself.
So masked materials inside of Unreal 4 are an excellent choice.
So on the left, you can see that's the master smoke material shader that we use.
And on the right, it's the same shader, but it's made into lit translucency.
And ignore the fact that it's a little darker.
I think just with some value pushes, you can get them to match.
But you can see some clear advantages.
The one on the left just has so much more volume and body because of its shading.
It's casting much nicer shadows.
And the way it's eroding is a lot cleaner, too, for our style.
But take it a next step and look at inside a shader complexity mode, and you can really see how this shines.
Deferred rendering is our friend.
As Shen mentioned, meshes can get expensive quick, especially in Unreal 3, because it's a forward renderer.
We're now using a deferred renderer.
It looks like it stopped.
Let me see if I can get that to play.
There we go.
Since it's a deferred render, all we're really doing is the camera casts down and hits the first surface, and it doesn't need to go past that.
There's no sorting, it doesn't have to draw anything behind it.
So it's really clean, right?
There's still a one-bit depth test cost, but it's kind of minimal in comparison.
So in addition to that, we want to make sure that the material feels kind of grounded inside of this.
So we have, Fortnite is dynamically lit, right?
There's no light maps or anything like that.
And we want to make sure that it kind of reacts to time of day changes and that means shading and color.
So the time of day manager is something that's like in blueprints and code.
It's writing to what we have, what's called a material parameter collection.
If you don't know what that is, material parameter collection is this like laundry list of vectors and scalars, right?
And anybody can write to it and then...
The cool thing is, tons of materials can all read from one point.
So you update that one value and all the materials on the fly update with that value.
So the time of day manager is writing the time of day and the light vector.
Light vector is just, if you imagine my hand, this is just the way the direction of the light that's moving, which is going to be the sun or the moon.
So all we have to do is take that light vector and do a dot product between that and the vertex normal, and we get the results on the left here.
Let me turn the laser pointer back on.
So you get the result on the left here.
And you can see as the time of day changes, that highlight changes with it.
We can just do some simple math to round it out to three steps.
And then in addition to that, we can take a standard Fresnel and dot between this and a standard Fresnel.
And what this allows us to do is it gives us highlights that are a little more biased towards the camera.
Excuse me, so what that means is sometimes you might get highlights that are behind the mesh because the vector is coming towards you, right, so you can't see anything anymore.
And it kind of makes the meshes feel flat.
So if you mix, I put a value here of .55, it's roughly halfway, you get a little bit of that push forward so that you always see a highlight no matter where you are.
In addition, we can do artist-derived highlight colors.
So if you look here in the examples in the back, this guy, this guy, and this guy, those are all using the same exact three colors, no matter what the time of day is.
It does change a little bit.
You can see, especially at night, there's a much more blue shift towards it.
But if we use our own functions to be able to change those colors based on the time of day, you can see this example here and this one.
And this one, you can see you can get much more artist-friendly control, and you can give it a lot more style and feel to make it feel romantic or anything like that.
So how do we get our materials to disappear?
I've seen other games do stylized smoke like this, and they just simply shrink it to a point, and scale the particle away.
I'm not really a big fan of that.
I want it to kind of neatly disappear and end the style, right, that anime style of smoke eroding.
So we have mass materials.
We've got the one bit opacity that we talked about it, and we're stylized, so we can capitalize on this.
So all we do is we just take a standard Fresnel, And then we're just going to bias against this.
Bias just means adding, or if you want to subtract, you add a negative number.
So on the right here, we're just doing an example of biasing from 1 to negative 1.
And this gets fed into Opacity Mask.
So you can see that the mesh is eroding away neatly based on the normals.
And it'll change based on the camera angle.
So you get unique results.
based on angle or particle rotation.
So all that put together, you can see our little small smoke swirl.
When she runs, she's got a big trail of mesh particles and traditional particles, and there's a big swish that kind of gets lost from this angle.
But when she starts running, you can see the swish, it's a little bigger, so.
Cool.
So how can we get even more out of our materials and meshes?
And the answer is explosions.
So the master smoke material inside of Fortnite has a static switch to enable heat for explosions, right?
So I use the term heat and explosion, or I'm sorry, heat and density.
Heat would be like the emissive part of a material.
Density's gonna be the smoke after the fuel is spent, right?
So we can use these same techniques applied for a secondary transition.
Oh, it looks like the video stopped playing.
PowerPoint doesn't like me.
So to get that transition from the hot to the dark parts of the smoke, we can use the same techniques, right?
We can take a Fresnel, invert the Fresnel, round it off, and then just bias against that so we can get our transition.
We can use our same three color cell shading highlight for the emissive part, but we can use an artist drive light vector, because it doesn't really need to accept light direction, right, explosions, they emit, they are emissive by definition, so.
So with explosions, they're complex, right?
There's a lot of motion, movement, undulation, all sorts of things and shapes.
And we can do this hand animated.
In fact, that's how I started with a hand animated mushroom cloud.
But if we really wanna get that sense of believability, that sense of Pixar reel is what I call it, right?
We can use our existing tools and combine that with fluid sims.
and the vertex animation tools.
So again, we can capitalize on our existing smoke and material explosion style that we've talked about, like volumes with meshes, erosion, and retopology.
We can take that fluid sim that I showed you in the previous slide and convert that to a series of meshes.
So we take, again, working backwards, we take the last frame.
turn this on one more time.
We take the last frame right here of the fluid and convert it to mesh.
You can see it's really nasty in terms of density and topology, right?
It's not going to be usable.
We can bring it into ZBrush and re-topologize it.
We do lose a little bit of detail here.
I think it's kind of like a serendipitous thing, though, for something like Fortnite, because with our stylized material that I've showed you, it kind of like rounds things out and it looks a little smoother.
and then now we can just work backwards to be able to get this to animate.
So this guy right here that I'm highlighting is the last frame.
What we do is something called a shrink wrap, which just projects all the vertices in and we collide with the frame previous in the explosion.
Then we just go back to that and then, you know, project in and we just go frame by frame.
We can automate it somewhat, but it doesn't really look that great in all areas.
So that means that we have to do some hand painting to fix certain areas.
So it's a little bit of busy work, but once you get it in, you get the end results.
This is just showing it in like a debug loop, right?
So you can see it going from start to end.
And then inside the airstrike, you can see it used as a core, obviously used with a bunch of other traditional particles, right?
But you can see it being used with like some trails and some camera shake and some stylized flares and stuff like that.
So.
That's work in progress.
We're going to make it even cooler.
Before we leave the vertex animation tool, however, there is a second method.
I told you we primarily use the texture method, but there is the model sequence method, which basically allows us to take any arbitrary amount of meshes with varying topology and just flip through them like a flip book.
So there's some key advantages there, right?
We don't need continuous topology, like I said.
We can have any arbitrary amount of frames.
Good for complex shapes and things like that.
There's no textures, no expensive material function.
There is a material function, but it's a lot cheaper.
But some key disadvantages are these mesh assets get really big really fast, so you can end up with a 10 meg static mesh if you're not crazy.
And there's no interpolation between frames or anything like that.
And good luck UVing 70 frames of meshes.
Yeah, so.
The takeaways matches are excellent, right?
They provide excellent volume and shading.
They allow us to do 3D movement and use in conjunction with Blueprints and Unreal Engine 4.
They are an exceptionally powerful tool for VFX and tech art. That's all for me.
We're going to have Brianna Lundsie come up next.
Thank you.
That was a pretty Unreal talk, Bill.
Hi everyone, my name is Brianna Lindsey and I'm a senior VFX artist at Deep Silver Volition.
If you're not familiar with Deep Silver Volition, it's been known for developing a lot of titles over the last 20 years, from Saints Row to the Red Faction series, and our most recent IP is called Agents of Mayhem, and I'll be talking to you about the VFX of Agents of Mayhem today.
So Agents of Mayhem, just as a little introduction, it's a 3D third-person open-world game.
And Agents of Mayhem's art style is heavily influenced by 80s cartoons.
We define our art style as 80s cartoon nostalgia, drawing largely from classical cartoon animation for inspiration.
And for us in real-time effects, this presents a unique challenge.
How do we render these retro style effects in a fully 3D world?
For the overall artistic vision of Agents of Mayhem, the art director broke down the vision into three visual pillars for us artists to interpret.
I'm going to talk to you about these three pillars.
My talk focuses a lot more on art direction than the technical side.
And I'm going to talk to you about how we approach to applying these pillars to our VFX.
And I'm going to talk about where we failed and where we succeeded in applying this direction.
Our pillars are simplified.
Here, meaning feeling clean and bold, yet still belonging in the cartoon world of Agents of Mayhem.
We focus heavily on silhouette, gameplay messaging, and readability for our simplified effects.
Vibrant.
Here, meaning colorful, intensive, and snappy.
We focus heavily on color, timing, and layers of complexity to get vibrancy across in our VFX.
And lastly, theatrical.
Here, meaning over the top and dramatic.
Think wow moments and showstoppers when it comes to our VFX.
With good staging, camera work, cinematic destruction, and presentation.
So our art directors, they gave us this poster of a breakfast sandwich to help us visualize and break down our artistic pillars.
You know, it kind of fits into that whole cartoon theme.
Having a good understanding of these pillars helped us to apply and deliver these real-time effects that fit into the gameplay needs and artistic expectations of the IP.
So when we first rolled onto Agents of Mayhem, we asked ourselves what do 80s cartoons look like?
And how do we tap into that nostalgia?
In order to understand this, we ended up watching a lot of older shows for reference.
so we can better understand our source influences.
Artistically, G.I. Joe was one of the many pieces of source material we looked at.
And one of the key takeaways for me was that in order to get that retro cartoon look, we had to start thinking about how the VFX were constructed in these classical cartoon shows.
The VFX in all of these examples were not done digitally, but they were painted on animation cells by hand, meaning that there wasn't any opacity thing going on in the effects work.
All of these shapes had to resolve and kind of break apart in terms of their shapes.
And these G.I. Joe references play heavily into the first pillar, simplified.
So, as we get into simplified, I want to talk about one of the things we struggled with the most when it first came to making simplified and readable effects.
Blood.
So, with blood, how do you make blood something that isn't a staple of these classical, stylized, retro cartoons fit into your open world city games with a shooting mechanic?
It's kind of hard.
So early on in the project, we tried using fluid simulations and flip books.
And I think we kind of did this just because this was something that we were used to when it came to generating liquids, but it didn't really give us a result that worked well with our art style.
So this resulted in blood that we considered to be out of style.
Our blood looked like it didn't belong in the rest of the world.
It felt way too noisy and it didn't hit our artistic pillars.
We felt it was unsuccessful in meeting our artistic expectations as well as messaging effectively for gameplay.
It didn't read very well from far away and it lacked the silhouette needed for a simplified effect.
So we had to go back and think about what made good-looking stylized blood.
80s cartoon effects are hand-painted, meaning that they have a more simplified look to them.
So going back to our GI Joe example, we re-approached this idea process to our VFX.
And to achieve this kind of look, we decided to hand paint our blood material textures instead of using flip books and heavily utilize alpha crush in our particle materials to get that retro look we desired.
And when I say alpha crush, that's just the word we use at Volition to mean alpha erosion or alpha clip.
It's the same sort of technique that, you know, I know that Bill mentioned it in his talk too.
Same idea, different word.
This is our blood alpha crush material in our in-house material editor.
Importantly, with the way the tool set works, the scalar values over here are externalized into our particle system.
And we can kind of control, we have a finet control over how much crush is out and where.
So what you see here, it's a really simple shader.
You know, we take the camera world position.
and the world position where the blood is playing.
We get the distance between those two, and then we just divide that by the distance we want that to happen at.
So this is about 15 meters away.
And doing this with an interpolate between the...
the near alpha crush and the far alpha crush, it means that I can control how much is crushing out at a distance, which means that I can have the blood look more, I can get a bolder shape at a distance.
And that was really important for us to get readable effects that read well far away in the gameplay.
And this is kind of the final example of that.
So what we see here is one of our agents of mayhem.
His name is Hollywood, and he's shooting a bad guy called a Hell Trooper.
And you can see the heavy use of Alpha Crush on his muzzle flash.
So those are all just hand-painted textures, as well as on the blood impact, which is also hand-painted.
And just like you'd see in these older stylized cartoons, the textures kind of break apart rapidly and in succession.
And this later attempt at creating a stylized effect was a lot more successful than our earlier attempts, which relied heavily on flip books.
So our next pillar is vibrant.
So what does that mean?
What do we mean when we talk about vibrant effects?
And what does that look like in a stylized cartoon?
And how can we get a similar feeling across in Agents of Mayhem?
We went back to our source material again and looked at classical 80s cartoons to find examples of vibrant cartoon animation.
And some of the commonalities we found with vibrancy was that the animation had a strong, snappy sense of timing, layers of depth and complexity, as well as saturated and contrasted colors to help draw the eye.
So with vibrant effects, color was one of the things we focused on.
We intentionally used bold color palettes with our VFX and Agents of Mayhem.
This is an example of one of our agents.
Her name is Fortune, firing off her cannonball ability.
We kept a lot of her effects in a more saturated range.
Generally speaking, we tried to keep the saturation and emissive levels high for all of our agent abilities to get them to pop out from the environment.
And this also helped to maintain the bright and vibrant tone of our reference material.
So layering was another thing that we focused on in constructing our vibrant effects for Agents of Mayhem.
And when I say layering, what I mean is breaking down the explosion or particle system into smaller, more digestible layers for you as the artist.
One of your layers might be your initial blast wave that goes off when your explosion is first taking place.
It might be the fireball and the smoky after effect.
It might be, you know, like a secondary layer of sparks that kind of happens after the effect goes off.
Or it might be energy that kind of comes in as the effect is still building up and charging up.
And thinking about your effects in layers is a great way for you as an artist to build your effect, and also a great way for you as an artist to deconstruct reference.
And layering feeds directly into timing.
So when you combine all these layers together, you get this.
And this doesn't look very good, and it doesn't really meet our artistic expectations for vibrancy.
It could look a lot better with a timing pass.
And by timing pass, I mean thinking about your animation principles, your 12 animation principles, especially some of your principles like anticipation or secondary action.
Our medium is a medium of motion, so you need to be thinking about these things when you're building your effects.
So before a timing pass, this kind of looked a little more jumbled, but with some variation of start points, you can kind of feel like energy is coming in and building up and then discharging, and it draws your eye a lot more effectively.
Timing not only makes your effect more readable, but it also delivers a more vibrant and impactful effect for the player.
And it also fits in with the vibrancy and snappiness of a retro cartoon reference.
So our last pillar is theatrical.
What does theatrical mean for us in this 80s cartoon nostalgia game?
Is it the moment when Lion-O appears in a magical teleporting pyramid?
Or is it the moment when the Autobots ship is attacked?
For us in VFX, it's all of those things.
Theatrical brings a dramatic element to the game.
We had to stay true to that in our visual effects.
We tried to carry over these dramatic moments into Agents of Mayhem.
So why do we need theatrical moments in our stylized game?
We need theatrical moments, we felt it necessary to deliver big moments to drive the narrative.
Much like in a stylized cartoon show, this helps to finalize the moment when the players succeed.
Theatrical moments also help the player feel rewarded and accomplished when they complete a mission.
And lastly, well, it's just fun to blow up stuff, and it definitely fits in with the spirit of our reference.
So this was our first attempt at kind of delivering a big scale cinematic.
And it required some additional passes and iteration.
This is a large spaceship, which we called a Hell Barge for Agents of Mayhem.
We had difficulty lighting such a large set piece and getting it to load in memory in real time.
Our first attempts didn't succeed in achieving the quality we wanted, and it was certainly causing massive performance problems for us.
The ship was the size of about 40 to 50 blocks, so it was a huge technical problem to get it loading in real time.
We had to...
take a second to re-approach it and to achieve the performance and quality bars that we had set for ourselves.
So we decided to do some iteration.
We did another pass on the camera cuts and simulated the destruction in RayFire, which is the 3ds Max destruction plug-in we use at Volition.
Once we got the RayFire simulation loading in the editor, we layered in particle effects and used scripts to call them in our custom timeline tool.
The camera work and explosions had to be scripted, using place keyframes to get them to go off at the correct time.
This was our final result.
Eventually, we had to video capture the real-time effects going off in Engine, and then break it into a pre-rendered cinematic, mostly due to performance constraints and memory.
It was way too expensive for us to have this loaded in the world, because this was just a unique one-off asset for the cinematic, and it definitely pushed us over our memory limit.
since we had to make a video of it anyway for performance reasons.
This gave us a second chance to do an After Effects pass on it and layer in some additional electricity and glares.
Our final result was a lot better than our first attempts at delivering theatrical destruction-focused moments.
So what did we learn from creating an 80s cartoon nostalgia-style effects for Agents of Mayhem?
First, start with breaking down your artistic source material.
Reference is gonna help you derive a stronger vision for your game.
Your first iterations might not be very good, and it might take you some time to figure out how your VFX fit in with the rest of your art style.
If it doesn't look right, don't be afraid to try something different.
And lastly, stick to your fundamentals.
Timing, layering, color, and a dramatic presentation are going to make your game's art style a lot more memorable.
And we should be ready for questions pretty soon.
Before we wrap up, I did want to put in a plug for my coworker, James Taylor.
He's doing a talk in this room a half an hour after this talk is over at 3.30.
He'll be talking about PBR and surfacing shaders for stylized games like Agents of Mayhem.
And I hope you can make it.
Thanks.
If you have questions, feel free to come up to the microphones and ask.
I mean, we're totally ready for any questions you might have about stylized effects.
Hi.
This is for Bill.
You talked about sometimes creating the final frame and working backwards.
And one of your examples was you did a fluid sim of a big explosion, and then you somehow backwards morphed that smoothly into a small core ball, I assume in-engine with the material?
Or how did that actually work?
How did you reverse final frame to first frame for that explosion?
Yeah.
Is this working?
In fact, we've got to turn it off.
Oh.
There you go, you can hear me now.
It's done in Maya.
I think Max has the same process.
You take all the frames that are baked from the fluid sim, and that gives you your shapes, like your targets, right?
So you have sculpts of every frame of the animation.
And then in this specific example, you have a big explosion at the end, right?
It's always expanding.
outwards. So then you can take that final frame and that shrink wrap that I was talking about is projecting inwards and it's colliding with the previous frame. Does that make sense?
So frame 50 collides with frame 49 and it kind of adheres to the previous frame. And you can duplicate that and go from 49 to 48 and you just keep shrinking in and it's like – it's literally like a shrink wrap, right? Like you put a dryer to it and it shrinks around it. Does that make sense? Does that answer your question?
And then are you exporting that into that texture vertex data?
Yeah, so I'm constantly shrink wrapping the same mesh, because it keeps the same topology, and then duplicating it, and then shrink wrapping it again.
So you end up with the same mesh in a sequence, and then you bake that to the textures.
I see.
Does that make sense?
Yeah, that's great, thank you.
Thank you.
No more questions?
Cool.
Thanks a lot.
If you have any other questions, we'll be around outside, so thanks, guys.
Yeah, thank you, everyone.
