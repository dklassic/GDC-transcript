All right, so let's get started. My name is Ethan Redd. I'm here to talk to you guys about low poly and achieving a sense of style through economy. So let's start with an introduction. I'm sure you're all wondering who I am. I'm working on a game called Blazing Legion Ignition. It's in a retro sort of Sega Saturn-y looking 3D style. And it's currently in development. Mainly just me and two audio guys.
And I've released a game called NEO1, which also is in that same vein, a full 56,000 square meter explorable island. Yeah. That's up for download on my itch page. And this other game, Rad Road Rally, which is about that vroom, vroom sound you make when you're six playing with Hot Wheels. Just like fun ode to childhood, basically. It's one of my first games, kind of janky, but a lot of fun.
So yeah, just getting right into it.
Oh wait, actually, one more.
I worked on one of the scenes for the Dome video at Panorama, this concert series in New York.
Did that last year.
A lot of fun.
I worked on two scenes.
One of them actually made it into the video, which was super cool.
You should look that up on YouTube if you can.
Now actually getting into our topic, what is low poly?
Low poly is what I like to call quantifiably qualitative in that there's no hard definition for it, but I like to think of it as the discipline and aesthetic of surface economy.
So basically describing 3D or sometimes 2D surfaces in as little geometry as necessary to get the idea across.
And low poly is essentially a low fidelity art. So we're thinking about efficiency more than we are fidelity. We're not trying to accurately recreate objects. We're trying to get the idea of them across. And again, it's subjective. There's no hard poly limit where you are or aren't low poly. But generally for me I like to think around 8K per asset is where you cross the line. If you can see angles along curvature, that's probably low poly.
And we've seen sort of in 3D and evolution, right, of moving more towards high fidelity graphics, especially in 3D, because we can, basically.
Especially at the higher scales of AAA development, we think of higher fidelity as better.
Up until recently, where we are seeing sort of like a renaissance in low-poly art, for one big reason, I think, money, right?
Independent developers, we don't have the same resources that AAA devs have to play with.
We have different schedules, there's less of us working on a project, we have tighter time constraints, like things are different, and it's a bit hard to go for high fidelity looks when you are worried about literally everything else.
So low poly has a place in modern development besides just a last second optimization step for bigger games.
So modern benefits.
First one being productivity.
Low poly has what I like to call a lower existential barrier than other ways of handling 3D in that you can get your idea out and across much faster than you can like a high res sculpt.
Excuse my computer.
Faster than you can a high res sculpt or just generally richer asset.
And you can get up and running faster, which is great, especially if you're into prototyping or trying a lot of ideas.
And being quicker produced allows us to increase our scope as smaller developers.
If you're trying to make characters that are completely, fully realized, photorealistic, like actor duplications, you're gonna spend a lot of time on that.
Where if you're an indie developer, maybe your time is better spent making more assets and spreading that detail across, and making more instead of making one thing and like really digging into it.
And a big way that we accomplish that is in our workflows.
What I tend to use is the one at the top, which I call low poly first, where the low poly aesthetic is sort of baked into how the game looks.
So the first run of the asset sometimes will be what I use in the final production game.
But if I miss, it's quick to iterate on, and I can try out a bunch of new ideas and keep moving, and then even if I want to, go on to a high poly asset at the end.
What you usually see with low poly is we'll start with a high res asset, and then there'll be a manual reduction of it, or someone will run a decimate operation over it, which is bad.
Best case, if you run a manual reduction and you go and make a separate mesh, you can clean up a nice, smaller mesh for it, but you did the work twice.
And if you're gonna end up using the low poly mesh, sometimes it's better just to go with that first.
The worst case scenario is the bottom, which I call afterthought optimization, where you want the high-res asset, and you realize that you can't really use that, so then you go and run a decimate on it or whatever, just to clean it up, and then you realize that's trash, and then you have someone come back and make a low-poly asset from scratch.
And you've done three steps.
when you could have just done one to get to that asset.
And this is even worse, because if you don't like the result of all that, when you see the final silhouette of the low-poly asset, you'll have to go back to the first step and make a new high-poly one to change that, and then you go through this whole chain again, and it's completely inefficient.
So, low-poly first thinking is a great way to save time.
And then on the other end, we have computational efficiency, which isn't existentially necessary these days because we do have hardware that you can just throw a million verts at and it'll run and run smoothly, but that's only when you're working for, let's say, desktops or newer consoles.
If you're producing for small screens, efficiency is still very much a consideration and you want to keep that in your mind when you're designing things.
Also, for audience purposes, if you want to reach the next billion users, like emerging markets or reaching people who don't have access to new technology or are playing on older computers, that pop-up is annoying me, if you want to reach people playing on lesser hardware and just generally broaden your market, low-poly is a great way to lower the threshold for who can access your game.
And then lastly, having less overhead.
If you're rendering things twice, for example, for VR, or if you are doing AR and then you have other processing going on graphically, having less geometry to worry about saves the GPU to worry about other things and you can spend that computational time on just other stuff.
So now that we know why we want to use low poly, we want to start thinking in low poly, basically.
And there's four principles to this, I think.
One is stylistic compatibility.
If you want to make a game that looks like real life, this is probably not a good match for you because fundamentally, low poly is about reduction.
It's about taking out the details that aren't necessary to get your idea across and leaving and accentuating the ones that are.
So if you're working with something that's angular, or generally sharp, or even something like woodblock paintings, or I don't know, cubism, or origami is a very classic example.
These are things that translate to low poly very easily and naturally, and are sort of like a leg up in your design process.
You can break away from that, but you're cutting against the grain.
So this is something to consider at the onset of your project.
The next pillar is resolution consciousness.
And this is where I think a lot of people slip up with low poly is we sort of just will think, oh, just reduce it as far as you can, or reduce it till we get to our benchmark and then you're done.
But when you do this.
there's no human touch to it, and your viewer will pick up on that, and the general look of the game will suffer.
By having a sense of consistency through how you handle the polygons that make up your mesh, it allows you to push the style of your game.
And we'll get into this in detail.
The third thing is considering silhouette at all times.
Now if you're already a 3D modeler, this is something that's already baked into your brain because you know you need things to read like they are from all angles.
But with low poly this is even more important because again, we're stripping away detail.
So we need to make sure that the overall is very strong.
And ultimately we're approximating things.
We're going to dig into this in just a minute.
So we don't really need to think about conveying things as they are.
We want to convey them as what's important about them.
And then the last pillar is either supplemental or old school rendering tricks that just sort of help you sell the style.
You can fake things through particles, shaders, textures, or even incorporating other lo-fi or NPR techniques. And that allows you to achieve those looks we talked about earlier, like looking like origami or woodblock painting or whatever. So starting with resolution.
The easiest example for explaining resolution actually came from calculus, believe it or not, when I was looking for examples, which surprised me.
So for example, our data that we wanted to portray was the red area under the blue curves, and we wanted to show that red data in a series of finite...
bars. If we had an infinite amount of them, we could actually show the data as it is, which is the leftmost graphic. As we reduce the number of bars, generally we see that we're approximating rougher and rougher. With 32 of them, we can sort of get the idea. If we added them all up, we have sort of closest, like a close representation to the data. And this is high fidelity. This is when something is very close and good enough to represent something.
If we cut that in half, we notice that there's a lot more white between the blue and the red, and that's sort of showing a margin of error.
But we still understand that that's a curve, and we still can see generally what the data is.
So here we have a low fidelity representation of the area under the curve, but it's still good enough.
We get the idea.
And then if we move further to the right than that, we notice we just don't have enough data and we have garbage.
This is what we want to avoid.
So it is possible to reduce too far and it is possible to present too much.
With low poly, we want to find a happy middle ground between the 32 and the 16 example.
So extending this concept to shape.
If we instead of think think about the cuts instead of as a verts around a circle like we're trying to approximate a circle here 16 vertices is indeed enough to show that it's a circle like we don't even really have like a name or a common name for A shape that's 16 sided When we go over to the right we have an octagon which you know it's kind of round, but not really You go further, it's a hexagon, and now I'm really pushing it.
And then when you go further than that, it's a square.
So at that point, we've reached insufficient data to represent our circle.
But from the hexagon upwards, we kind of have enough data to show our viewer that we're portraying a round thing.
If we go to three dimensions now, and we think about rings cutting along our sphere that we would like to approximate, 64 rings pretty much look smooth.
I didn't smooth any of these models.
64, you can't really even notice that it's polygonal.
32 is indistinguishable from 64.
So if we wanted to, just for optimization's sake, we can cut out half of the verts.
Well, half of the rings, that'd be more than half the verts.
of this model and the end viewer isn't gonna notice.
We can cut it in half again and end up with 16 rings and it's still sufficiently smooth to show that we have a sphere.
And then once we get down to eight, we're starting to see the banding and then once we get down to four, it's no longer round.
But I think this illustrates the concept that you hit a point with a curvature that's good enough and you've made your point.
Once we get down to three, it no longer has any semblance of being a sphere.
without context.
Which then brings us to the topic of what I call atomic size.
If you notice, all of these spheres have the same amount of rings as the examples on the last screen.
But these all have a rigid atomic size.
That meaning, the smallest polygon on each of these models is the same size.
Which then leads this scene to have a sense of scale.
And it allows us, if you notice all the way to the right, I'm using that janky 3 and 4 ring sphere, and it looks more round in this context simply because we're communicating that there's a finite amount of detail that we're spending in this scene.
And once we get down to smaller scales, there's less to work with.
And this has a lot of uses, and it's one of the best ways to give your low poly art a cut above a lot of what I see, is by having this sense of order and cohesion.
And when you're rigid like this, it kind of sells it when you're working with looser approximations of objects.
But you don't have to be completely rigid with it.
In this example, you see that the largest sphere actually has the same amount of cuts as the next sphere to it, because the atomic size is more of a lower bound.
And that takes me to my next point of each model can have its own local atomic size.
And you can play around with this as a compositional tool.
And I illustrate this here with two scenes that both have 800 triangles in them.
And the triangles are basically just spent differently.
So if you think of detail as more of a commodity than just something to shoot for, we can start playing around with it art-wise.
And the first thing you'll notice as a difference between these two is fitting, or how loosely or tightly we're approximating this data.
The dispersal scene on the left is a very rough fit of the scene.
And the accumulative scene on the right is more accurate, in that we have more detail in the individual elements of the scene.
The way we do that while keeping our poly count the same is by playing with the atom size.
The atom size in the dispersal scene is global, where the accumulation scene has a local atom size usage.
So the rock has different size polygons throughout it, then the grass, then the tree, then the leaves.
Where on the left-hand side, generally we try to keep the size of the polygons comparable.
This ends up allowing us to do different things in the two scenes because on the left hand side, it's very dense and rich and lush.
This is great for if you want to have a forest scene or you want to do a city and you don't necessarily need detail, you just need lots of things to look at.
The sparse density of the scene on the right allows you what I call innate composition.
where the scene on the left is more muddy, which isn't necessarily a bad thing.
That lets your eye have something to look at at all times.
No matter where you look at the scene, there's some grass or there's a tree or there's a rock, whatever.
On the right-hand side, we have clarity, which is great because it naturally draws the eye places.
And you can use this in level design to draw the player to areas where you want them to go without using text or dialogue or whatever.
or you can use it just as a way to convey story if you have things where you want to have the player look at and read or whatever.
And it's something you can play with on a design level.
And it's something I use here.
This is a prototype I worked on for like, I don't know, two or three weeks or so.
But it was like a generative space game where there's 200 star systems.
And each star system has up to 12 planets with each having up to three moons.
And each planet has its own distinctive flora.
that could easily become a huge project, but by using dispersal techniques and having the models composed, I was able to make these rich environments very quickly, which allowed me to play with big ideas on a very small scale.
And then I do sort of a hybrid approach with my game NEO1, where I used accumulation techniques on the hero assets, like the big trees and the cliffs and such, to sort of draw your eye to the interesting things.
And then I use what I call breadcrumbing by having more detail sort of hot-spotted in areas where I want the player to go because I didn't want to have any sort of text or dialogue or whatever guiding the player where I wanted them.
And then on the other end, I use dispersal techniques to litter the environment and populate it with stuff because you're in this lush alien forest.
I want it to feel like there's plant life everywhere.
So just having a tree here, a tree there, and a rock, that's not gonna do it.
I wanted to have small polygonal grass everywhere.
There's little flowers, there's berries, there's little gems or whatever.
And it gives you something to look at no matter where you are.
And also, by using dispersal techniques, a great benefit of modern game engines with this sort of look is you can catch light and shadow.
So it makes the ground of the forest look much more interesting because it catches that nice moving lighting and just overall adds a little bit of detailing to a sparse world.
So going on to silhouette.
Silhouette consciousness is key to good low poly because things need to make sense, right?
If we're constantly removing details and things that we would identify objects by, we need to leave what's important to recognize them by.
So the first thing you wanna consider when modeling something and trying to be conscious of the silhouette is how legible is the overall shape, both on its own and in context?
The second point you'd want to think of is how should light and shadow interact with your object.
A really great example of this is actually the chairs that you guys are sitting on, where you can represent these chairs a bunch of different ways, but if you want to accurately sell the shape, you're going to need to use geometry instead of textures or alpha to model the bar that's holding the cushion.
So that way shadow will shine through it.
Or maybe you could use planes with a texture of the bar with alpha that allows light to pass through.
But this is something you want to consider because light interacting with the form of the object is crucial making the image work.
And then the last thing you want to think about is are you over or under selling curvature?
It's really easy, especially coming from a sculpting or hi-fi background, to think that round things need to be really round.
But again, like I showed earlier, there comes a point where you've done enough.
And maybe a couple 30 degree angles is enough for a turn, instead of actually subdividing that.
And then on the flip side, you don't want to get too reductive to where you're just making really blocky things that shouldn't be.
An example of this is a hand from the cockpit of Blazing Legion, and the 800 tri version is the actual asset.
And this was made first, not the high poly one.
By using clean topology, or relatively clean topology, you're able to subdivide and get a high res asset if you want it.
But if you don't, by considering what's important about the model, I can have different striations that I can use to reduce if I need to for performance reasons.
So if I wanted to convey just this is a hand in a glove with a sleeve over it.
I don't necessarily need fingers for that.
So when I step down to 400, I can block off the three fingers and still have the one index finger available for trigger activities or whatever.
while still keeping it more or less deformable.
If I don't need a trigger finger, maybe for the other hand, where it's just like holding a joystick or something, you can actually get rid of that other finger and then reduce a couple of edge loops out of that, get rid of some of the detail in the sleeve, and now you've cut it almost in half.
And now if you know the hand doesn't need to animate, you can just lock it into a fist and cut even further from there.
So by thinking about what's important about the shape that you're modeling, you can make smart decisions and stylize it so that it makes sense.
Now, a bad example of what you'll see a lot is just people decimating a model when they need to get more efficiency out of it.
And this is ultimately, I think, a bad way to do it.
Because as we decimate further, we notice that our geometry gets harder and harder to work with and maintain, and also gets less and less deformable.
The 256-try example, if you tried to rig that, would just have horrible results.
The 172, I really hope you're not intending on moving that at all.
From here, you can still subdivide up, obviously, because it's the same mesh, but I really want you to pay attention to that.
This is bad, right? This isn't really doing low poly, in my personal opinion.
There's got to be a personal touch to it because it's holistic.
We need to decide what is and isn't important.
We want to think reductively about what we're portraying and make a decision about it, not just cut down based off of angles and numbers.
And this is sort of like a lightning round of tricks that I like to use that help breathe life into these techniques and also give a bit of authenticity to the look.
So something that really compliments low poly modeling, in my opinion, is low resolution rendering because the two sort of came hand in hand with each other back when there was less.
computing power to work with all around. So these are two prototypes I worked on. On the left is actually a prototype for Blazing Legion that was made in like a week or so. And rendering really, really quick bad models at very low resolution really helps to hide the errors and general lack of detail if you make any. On the right‑hand side is sort of like a star‑foxy shmup type deal.
And it ends up looking more like a SNES 3D game.
And it forgives the pop-in that you see at the end that's happening with the level generation because it seems like a hardware constraint.
Because your eye knows to interpret those things together.
So this is one of those techniques that just kind of goes well with low poly.
If it works for your art style, I'd say at least experiment with it.
Another one that's also kind of popular these days is using color palettes as textures.
Sort of my signature with a lot of my work is I use the Sega Master System palette because I just really like the colors. But also this is a really great way to batch materials because a lot of times I'll actually have two or three materials in an entire game because they're all using the same colors.
And that saves a lot of rendering time, especially when paired with a reduced polygon count.
So that's something to consider.
And it's a nice stylistic touch, especially if you're going for an unlit look.
You can get a very nice sticker vibe out of it, like the little dude on the left.
Then playing with normals is also something you can do.
It's great for doing a cheap glass or fluid or anything that is semi-transparent and you see like the back of.
I use it here for like showing a glass jar and a prototype I'm working on.
And another prototype.
It's the helmet of this little astronaut dude.
And you can combine these techniques with this one.
This is scrolling UVs, which is another thing you can do that's cheaper than shaders sometimes, and you can also batch this.
But anyway, by combining these techniques, you can get effects like this, where it's like a really Sega Genesis, Sega Saturn, 3D-looking atmosphere around a little planet.
Just by scrolling UVs and having flipped normals for the atmosphere, this whole planet, I think, is under 500 tris.
So when I'm rendering a whole system of these, it's ultra cheap.
So yeah, takeaways, I want you to consider stylistic compatibility.
Make sure the look you're going for is compatible with low poly and lends to the aesthetic of it.
I want you to approximate instead of duplicating objects.
Think about what's important and reduce to that.
Be consistent with resolution.
Either use it uniformly to create the dispersal look that I showed, or play around with atom size intentionally and get the accumulation look.
Develop strong silhouettes so that your shapes actually make sense and stand out in context and alone.
Cheat hard when possible, and please don't hit decimate.
So yeah, thanks for coming.
That's the end of my talk.
Yeah.
Thank you.
Thank you.
Thank you.
Thank you.
So yeah, I think I have extra time if anyone wants to ask questions.
Two minutes?
Hey, yeah.
Questions?
Yeah.
Yeah, so you mentioned not wanting to break those specific hands.
Right.
Okay. So is there like specifically for organic or for mechanical things? Okay. So to repeat the question, he was asking about what to consider when rigging low poly models. It's generally the same as high poly models. You want to make sure there's enough geometry to articulate. So if you have a joint, like for example a finger, you want to have a little bit above the joint, a little bit below the joint and something in the middle so that way the bones have something to catch on to. So he was asking about what to consider when rigging So that's if you have continuous geometry.
Something I use a lot is actually just intersecting geometry where things aren't even connected, and then you can just assign that directly to a bone.
That's a great cheat if you're doing something like robots or anything mechanical, because nobody really cares if they're connected or not.
Any other cues?
Yeah.
Yeah.
So, human eyes are really good at pattern recognition and it can really easy to pick up the same model if you repeat too much.
Right.
So I think that.
Low poly can really synergize with random generation.
So do you think how we can work, like maybe not for the models which you need to rig for animation, but for like environmental assets like trees and stuff you can.
So how can we approach this if we want to say randomize generation and tree model?
Okay, so just to clarify, do you want to know about how can we provide a little bit of variation in smaller assets with low poly?
Yeah, and I think it can also save time for you.
And save time?
Yeah.
Yeah, so that's where I'd say is a good use case for dispersal techniques, where you make really small coarse assets and you can just make a ton of them because they take you 30 minutes each.
And then you just vary those in your generator.
So just generally approximating loosely, working quickly, and just make a ton of variations.
Thank you.
Any other questions?
Yeah.
Hi, and thank you for the talk.
It looks like this year at GDC, the subdivision services are finally coming to game engines.
And at least in my experience it looks like low poly modeling is a really good starting point.
Like even old box modeling is like the perfect starting point to get elegant control cages for subdivision.
And I'd like to ask if you've played around with any of that and have anything...
Subdivision control cages?
Yeah, really, like when you make a...
low poly character with just a few hundred polygons, but you use edge creasing.
The resulting subdivided model is a really, really elegant.
shape for...
Oh yeah, I see what you're saying.
Like subdivision modeling.
Yeah.
Yeah, definitely.
Low poly is great.
Like I was saying in the beginning, it's a great way to leverage up, you know?
So like, working on a low poly cage, as you're calling it, doing that first, you can reap the workflow benefits of being able to iterate on Silhouette very quickly.
And then once you subdivide after that, you can hang on to the low poly model in case you want to make changes that are like drastic to the Silhouette.
like for example you want to change shoulder width or hip height or something and then subdivide and then you can go over that again with a sculpting step.
Thank you.
Yeah, thank you.
The other?
Yeah.
Hi, so this might seem kind of anachronistic since low poly is, I mean...
older consoles like the PS1 didn't have normal mapping support.
So I'm curious what you think might be the potential role for more advanced rendering techniques that newer engines like Unreal and Unity offer in regards to PBR and more advanced kinds of materials in stylized low poly.
Right.
Um.
Thank you.
Okay, so the question was where do I think low poly could go with ‑‑ I'm actually out of time. If you guys want to ‑‑ I'm so sorry. If you want to talk more, I'll be at the little room that they provide, I forget what it's called. Thanks for coming.
