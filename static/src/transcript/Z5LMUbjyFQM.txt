My name is Lerna and I'm a programmer at Paradox Development Studio, which is based in Stockholm.
We do strategy games.
Christian down here, he told me that this is going to be the shortest Paradox experience ever, and I think that's true.
I've worked in the Stellaris team the past two and a half years, and I came in quite early into the team.
We were like five people at that time or something.
And I worked mostly on the AI.
And this talk is about how to break down like a massive universe of complex elements into manageable variables to create emergent NPCs in the game.
Before I start, I just want to ask, how many of you are designers?
Okay.
Like a third or something.
And programmers?
The rest.
Okay.
Right.
So the agenda.
Well, the background of this presentation is that we make really complex games in terms of the amount of input and the dependencies that the AI needs to process to create a human-like behavior.
So it's really about how we use data-driven design to solve this and make complex AI simple.
What I will be covering today is a presentation of the game, why data-driven design is used in the AI, some concrete examples of how we do this, and a few things to keep in mind with this method.
And finally, I will summarize it all, and hopefully we'll have some time for questions.
So Stellaris is a grand strategy game where you play an empire managing your resources, economy, politics, or diplomacy.
and military in order to survive in space and hopefully expand.
Unlike our other games, Stellaris is a non-historical game.
So the AI is quite different, but it still follows the general theme of our games with high replayability, depth, and subject matter.
So here you see the galaxy map in Stellaris.
Every colored circle on this map is an empire with a different set of behaviors.
What's important to understand about our games is that the AI needs to do exactly the same thing as a human player.
So it needs to last throughout the game.
And this creates a very different challenge compared to other games where the AIs might be obstacles instead of opponents.
I prepared a short trailer for you to see.
Pegi 12.
Ever since the dawn of our civilization, we've been reaching for the heavens.
Our first man rocket was a crude device.
far more advanced vessels would follow.
But for two centuries, we stared longingly at the vast ocean of stars beyond our solar system, fearing them forever out of reach.
Then, in one swooped stroke, the invention of the warp drive changed our world.
A new frontier loomed, and the start of an intense race to colonize the far reaches of space began.
We named her Nepsis.
9,000 brave souls heading toward an issue.
The star most likely to have an orbiting planet suitable for our first colony.
Four months, two weeks, and five days into the mission, we received NEPSIS' final message.
Panicked voices broken by static.
An alien message impossible to decipher.
Then nothing.
Our first generation of warships would lead the rescue operation.
When we arrived, we soon located the remains of Nefsis floating in the darkness.
And approaching us, a fleet of alien warships, their technology far beyond ours.
Using salvaged technology from Nefsis, these alien entities had managed to decipher our communications.
So they recounted the story.
A large, unidentified ship had entered their system.
Despite repeated warnings, it would not change course, and a trigger was pulled.
It is a galaxy full of danger, but also opportunity.
There are an untold number of species, border disputes, political tension, and betrayal.
Not that different from home.
All right, so now you should have a decent idea about the game.
So let's go into why we chose to use data-driven design.
Some of the benefits of this method, which you're probably familiar with, is separating the data from the logic, making the data accessible to scripters and designers.
It's also a good way of controlling state changes from the input data rather than in code, as well as a modular way of building features.
These are general benefits, but I want to go more into depth about why Stellaris benefits from this model.
First of all, we make content-heavy games.
To the left on the picture, you have a list of the current information that the AI needs to process to output certain behaviors.
As you can see, our AI needs to handle a large set of data.
And it needs to process each of these elements differently, depending on the dependencies that they have.
So for example, a policy can be locked by a technology, which you need to research.
And whether the AI wants to have that policy or not can depend on the empire ethos or government type or something else.
If we would use the concept of state machines, behavior trees, or decision trees for the AI, we would need to go through all the combinations that these elements in the list can create with each other.
And not only would that be time consuming, it will cause probably massive performance issues and still result in a rather predictable AI, which is the opposite of what we want.
So in short, there are multiple valid options for AI to make at each decision point.
And we want to pick the ones that are most reasonable rather than the best one every single time.
It's also worth mentioning that the term utility AI has been thrown around a lot these days.
And this is probably something that falls under that category.
All right, so secondly, our games should have high replayability.
This is one of our game pillars.
This is important because we want our players to be able to play the games for a long time.
One example of how we satisfy this condition in the game is by having randomly generated galaxies, including random AIs.
We don't really know what qualities the AI will have until we've started that particular session.
So working with data-driven design in our way enables emergent behavior for the AI.
And it can basically make decisions in situations that the designers or the programmers or anyone else for the matter in the team hasn't foreseen.
It also creates that sense of uniqueness and unpredictability that you want to have when playing against NPCs.
Another thing is that our games have long lifetimes.
Crusader Kings was released in 2012, and we still make new content for it today.
And this is not only because we want to keep our fans happy.
It's also to be able to release.
grow our player base, sorry.
And I wanted to give you some numbers here, but since our IPO, we've been really secret with all the numbers, so you just have to take my word for it, but we've like massively increased our player base since we first released Crusader Kings until now.
To be able to add content years after release, we need to have a game that is easy to add new content with little support from programmers, because we have really small teams at Paradox.
And the teams are even smaller after release.
We also want to be able to rebalance and scale the game.
Worth mentioning is that Crusader Kings only has one programmer at the moment.
So just imagine if he would spend all his time on the AI.
Finally, we want our games to be moddable.
This is one of my favorite mods where you can determine the shape of the galaxy, in this case, the PDX logo.
By being mod-friendly, we enable ourselves to create a strong connection to our community.
and to learn from people outside the studio.
It's part of our mission to make games where the players can create their own stories, and this is one way of doing that.
So to sum it up, the NPCs in Stellaris need to be scalable for new content, moddable, be able to transform a large set of data to different behaviors, and be unique in order to support game replayability.
Now you know the why, so let's go into how it's implemented.
Alright, so the tools for this is really, really simple.
We have a trigger, in this case we have an hasEthic trigger.
that checks if a certain scope, for example an empire, is militarist or not, which is an ethos or ethic.
And this trigger returns true if that condition is satisfied, else false.
That trigger we can then use to put a certain weight on one of our objects in the database.
And most of our elements are objects in a database, like buildings, traditions, ascension perks, policies, edicts, and so on.
So every building has an AI weight.
There is a base, say 10 in this case, and then we add a modifier where we use that trigger to check if this is militarist, then we will multiply it by a factor of two.
And later then in code, we use all these weights to randomize which of these we're gonna use.
So say we have three options, A, B, and C, and they have the different weights of five, five, and 10.
Then we have a total weight of 20, and the chances for each of these being chosen is 25, 25, and 50%.
Here are some other examples, because we don't have to randomize the weights every single time.
We can, for example, just use the weight that is highest, like we do with policies, for example.
We can also have an allow trigger that we use to not even add that object to the list of weights.
So we basically just skip it.
And the final way or example that I'm going to tell you about today is that we can use it as fractions.
So say you have unlocked the tech for cruisers, and you only want the AI to build cruisers from now.
Then you just set the weights of corvettes and destroyers to zero once that tech is unlocked.
And every time the AI will build a new ship, it will just build a cruiser.
All right, so all of these tools are great, but if they're just used independently and randomly, it's really hard to create that sense of good game balance and a human-like AI.
So we want to be able to expect a certain behavior.
And similar to a human player, it should have a certain style of playing, but still have room for some unpredictability.
And for this, we implemented personalities.
Going back to this image that I showed you earlier, every colored circle represents an empire in our game.
And each of the empires that are played by NPCs have been assigned a personality.
And this will be like their backbone of their behavior.
The personalities are visualized in the game in the diplomacy screens and every interaction with the AIs will enhance that experience through the dialogues.
And it's really important here to actually connect the dialogues and the way of communicating with the personalities to get that realistic sense.
So a quick description of how we choose the personalities.
It's really, really simple.
We just start off with, say, around 20 personalities.
And each personality is weighted differently depending on traits, ethics, government type, whatever you add in script.
And once we have this, we can then randomize which one.
First, we actually will get two options, maybe, or more, that will render weights above zero.
And from those two, we will randomize which one it will pick.
And the personality then has a set of behaviors that is connected to it.
So this is a way to make choices without having to randomize and calculate the behavior for the AI every single time.
And it's the part of the AI that is predictable.
In this case, for example, we have that hegemonic imperialists will enslave, they will not purge, they will build robots, they will conquer planets, they will vassalize, et cetera.
I can also add that even the AI personalities are objects in the database that you can use for your triggers.
OK, so one of the benefits with this model is that it's really easy to keep your code simple and clean.
For the coming expansion, we added two features of traditions and ascension perks to enable more empire customization and to add more interesting choices for the player.
And it's two fairly big features in terms of content.
I'm sure our content designers will agree to that.
But in terms of code, it was less than a day's work.
So basically what we do in this code is we go through the list of ascension perks, we list all the weights, store them, and then we use a random weighted algorithm to choose which one of these we actually want.
And then finally post a command to do it.
Exposing as much of the AI as possible in a script does not only make the code easier.
When you separate the AI design from programming, the programmer can focus on what she does best and will also have more time to allocate to other tasks.
You also empower your content designers.
Maybe I should add that content designers at Paradox are scripters and designers by enabling them to script the AI behavior independently from us.
Similarly, it exposes the AI to the modders, which means that they can do a lot of cool stuff.
As a side effect, though, they can easily introduce bugs or crashes into the game.
We can, of course, reduce this by having good tool descriptions and adapting the code so that we can handle script errors.
But the second part is easier said than done.
Another benefit is that you will save a lot of time by being able to balance and tune the AI in game.
I don't know about you, but I spend quite some time compiling, so I rather not do that.
One thing that you need to consider though when you do this is that By moving a lot of things to script, you will also force the content designers or scripters and designers to actually be aware of stuff that they usually aren't.
So.
By setting a lot of the AI's behavior in script, we also move the performance issues there.
So we need to make them aware of how to use the script efficiently.
And the code also needs to be designed for performance.
And this is something that I wished we had focused more on early on.
Finally, debugging of the system needs tools.
And I don't know how many of you saw this panel discussion on the Monday, but it was a very good overview of the most common issues of debugging AI, including Stellaris.
But for Stellaris specifically, I think the AI is fairly easy to write and debug.
The part that is difficult is that the behavior is unexpected sometimes, which we want in many cases.
But to be able to see when it is doing something that it shouldn't, we need to play the game a lot.
So we basically have to play the game.
I think one of the guys said it really well at that discussion.
Like you have to try to break the AI.
Yeah, future improvements for this would be to build better tools than what we have today.
So to summarize, our design will enable you to create unique NPCs with complex semi-unpredictable behavior.
It's a good way of processing high amounts of input data and dependencies.
You can tune the AI in-game.
It's mod-friendly.
It's scalable.
It's modular.
And the code will be kept simpler and cleaner, which means that your programmers will be happier.
To finish off, I would like to quote our game director.
It's a very robust system.
You could basically redesign almost the whole game without having to redesign all of the AI.
And that's something that is really good.
I'm now open to any questions that you might have.
Thanks.
No questions? Okay.
You talked a lot about I guess my question basically is, if you were going to do this system over again, what is the one change that you would make?
What is one area for improvement in the system that you see?
What was your name?
Andrea.
Andrea.
Yeah, I listened to Andrea yesterday, and I think she said something that is really good.
Sometimes when you do stuff, you get blind, and you think that that method is the only thing you should use.
Right.
What I would do differently is actually evaluate when we actually need to use the system and if there are parts where we can use something else.
I'm not saying we're using data-driven design for everything.
We have pathfinders.
We have nav meshes, whatever.
But there are some places where I think maybe behavior trees would be better, for example.
Hello, I was hoping you could elaborate on what kind of things would be good to automate in AI testing as opposed to not automating and possibly how to go forth with the quality assurance of an AI, unit testing or any kind of strategies that you have found that work in your field.
Yeah, some, the question was what kind of testing.
is it that would help this style of game design or code design.
Some of the tools that we use is all of our objects have IDs, which we can see in game.
So when we debug, we can easily break point with that ID and find stuff.
We have like console commands where we can just in game do stuff.
We can play as an AI in game.
We can add populations to our planets.
We can own a new planet.
So we can basically create those situations that we want to test.
But we've discussed unit tests at Paradox a lot.
There's probably some way you can use it, but I personally feel like this system requires you to play the game a lot.
And you can't really get away from that.
I'm curious to know more about the scripting of your AI.
From what you showed, it looked like it was very limited what the designers and scripters could do.
They could just set parameters and flags, I guess, that influence the decision-making of the AI.
But how much can they directly force the AI to do something in the event of a trigger?
Or maybe another question would be how many commands are there in the scripting language that they use?
There are much more stuff that they can use than what I showed you today.
Like they have triggers, they have effects that they can trigger.
They have on action events that you can put in code at special, like say a planet is changing on Earth, then you can trigger an on action event for that.
There's lots of stuff you can do in script.
And basically we.
We do as much as we can to support them, because they have a really important job at Paradox.
Like, I usually tell people that ask me, like, I personally believe that the content designers make our games.
Like, we're just there to help them make that.
Thank you.
Hi, thanks for the talk.
I'm one of the few designers that put their hand up, I think, so.
Probably following on from that question, how do you feel that the content designers work with this process?
Do they come to you with a lot of requests, or do they find that this is very limiting for how they work?
Or do they feel empowered with this systems-driven approach?
I think it's both.
I know that this system enables them to do much more than if we would do a lot of stuff in code.
But at the same time, of course they want better tools.
Of course they want more, be able to do more cool stuff.
And that is something that we are working on all the time.
But it's not like.
It's not like they want to do something and they can't, and then we just ignore it.
Then we try to figure out a way to do it.
So do you find that almost the modularity that this provides is a good prototype process for the designers to come to you with new ideas for functionality within the code?
Can you please elaborate?
How do you mean, like, functionalities in the code?
This could.
A scripter could quickly prototype with the modularity of the system to come up with a whole new thing that you might want to implement in the code that is better suited in the code rather than in script.
Oh, yeah.
So the question was if there are stuff, if the scripters or content designers can come with.
ideas about how to implement stuff in code instead of in script.
Yeah, they can and they do that.
And when it's better to have it in code, we do that.
Sometimes for performance issues as well, it's not optimal to have it in script.
That's probably more based on that the code is not optimized for performance, but still, we have to adapt.
Thanks for the talk, it was great.
I have, I guess, in a way, two separate questions, so you can choose to answer either or both.
I've dealt with a bunch of the problems that you described several different times in my career, where we've both developed AI and also designer scripting-based systems and encountered many of the same kinds of problems.
And I'm wondering how, if you encountered some of them, and also how you dealt with them.
One of the things that you didn't touch on was, sometimes when you introduce the opportunity for designers to implement individual scripts such as that, one of the things that doesn't show up unless you have a really extensive amount of testing is to have...
global interactions or combinatoric interactions between some of the entities that aren't visible within the scope of a given script.
You know, he's scripting something for one entity and you don't really notice emergent behavior until you start playing it out in the entire system.
And so designers can code things that look sane from the standpoint of one entity's behavior, but it turns out to be something that's exploitable.
in the global system or it can even break things or something like that.
I was wondering if you encountered any situations like that and and or if you found ways to prevent that.
So that's kind of one category thing about behaviors. On the AI testing I was wondering if you had implemented anything in your system around, it's partly tied into the question about unit tests, but around being able to force behaviors in different directions such as always choose this weighted option or always choose the eccentric option of behavior, you know, either on a global level or on a personality, by personality basis to be able to exercise sort of different vectors within the AI behavior.
Yeah, so I'll start with the second question.
The question was if we've used the script to actually have a set behavior for the AI.
Right?
Sure.
Something like that.
Yes, and we do that.
But that is one of the places where I think maybe data-driven design isn't the best option.
If you already know that you're going to pick the best option every single time.
then you might as well have a tree, for example.
But yes, we do that.
The first question was basically if the content designers have put in events or scripts where it breaks the AI without us really anticipating it.
Yeah.
One version of that is, like you mentioned, you can break from a performance perspective.
In Unreal, somebody can write a blueprint that iterates through all actors of a class.
And if that's not used really carefully, it can have a terrible impact on performance.
But you can also break other things besides performance.
Yeah, of course.
Break behavior.
I mean, we do.
We do break the AI all the time.
Like every single time we add something, we probably break something.
Because the challenge in a system like yours that has as many separate entities and different interactions between all of them, like technologies and policies and all that, is that anything you add can potentially have kind of a combinatoric interaction with the rest of the system.
You know, it could have interactions with everything else, and everything else can have some form of behavior that depends on that thing that you added.
Yeah, usually we don't have that many dependencies.
But let me think.
So it kind of depends on the touch points between the behaviors and the data.
I mean, if I say it like this, it's really simple to break the AI.
So basically what we have to do at each point is to like go through what we are planning to do and then actually thinking about how might this break the AI and is there anything we can do about it.
And sometimes we find those issues before we implement it and most often there is always something that we missed.
So basically what we do then is to try to find a solution to it.
I mean, I think it's the same in code, really.
It's just that our games are super, super complex.
Like, they're even complex for a human player.
Like, we've added now a personality of hive minds where you don't have to think so much about politics and don't have to think when you actually want to purge all the alien pops and stuff.
And I think Martin implemented that for me, because...
I got tired of thinking so much.
Like there is so much like you can do in our games and that's one of the things that we want but it's also one of the biggest challenges.
Thank you.
Hi, thank you for the talk.
I think you mentioned the word unpredictable AI at one point.
So the objective is to have a more engaging experience for the human player.
So when it comes to unpredictable, which methods do you employ to make it unpredictable?
Is it just randomization of?
behaviors and traits based on the content that you add?
Or is it there's any learning from the human player, whether their aggressiveness or how they collect resources or how they build structure?
Does the AI learn and choose different paths of behaviors based on that?
So the question was if the AI learns from other players or if it just bases its unpredictability on randomization.
It bases it mostly on randomization and it cheats a bit.
I mean, the AI has access to all the data.
So is it data gathered of the users as they play or is it data that you've pre-populated?
No, it's not.
It doesn't learn from the players, but it can see stuff that the players can't see.
And it's not like I deliberately put in stuff so that the AI actually cheats.
But it can use that data.
Like, if it's going to start a war, there's no point of starting it if it has one ship and the enemy has 1,000.
That would just seem dumb to any human player.
So we just avoid that by actually knowing that, OK, you can actually see that in game as a human player as well, like the ratio towards an enemy.
But anyways, we use that data in order to limit the AI's behavior.
to make it seem more human-like.
Yeah.
Thank you.
Okay.
Yeah, so we're out of time, but come talk to me if you want to discuss this more.
