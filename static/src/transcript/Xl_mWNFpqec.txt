My name is Daniel Perry.
I am the emperor of sound waves, aka the audio director at Alchemy Labs.
And welcome to the talk about bringing VR experiences to life with the magic of music.
I know it's a mouthful and a long talk name.
I hope to fill your expectations with this talk.
At Alchemy Labs, we worked on Job Simulator, Rick and Morty Virtual Reality, as well as the recently released Vacation Simulator.
And this talk, I decided to divide this talk specifically into four sections.
The music system requirements that you may want to consider when you're creating your new experience for VR.
I'm focusing on VR specifically. A lot of it can be translated to some specific AR segments.
So, consider that as like...
because I know we're in a mixed reality conference.
Okay, so music system requirements, music driven by VR specific data, enhancing game elements with musicality and creating music instruments in VR, like.
The talk itself will have a lot of examples.
We're listening to this talk through mono, unfortunately, so some of the specialization will be lost.
But I think the examples will still be able to give you a good idea of what we've accomplished with those examples.
And the talk is about inspiration, mainly, so there's no...
The code involved or things like that is just about the ideas that you may want to consider when you're working on your new experience.
So, let's start with music system requirements. First thing, when you're thinking about your music, would you want to make it diegetic or non-diegetic? Diegetic meaning emanating or coming from an object that exists in the real world rather than the 2D ethereal music that no one can actually see and spatialize properly.
I think VR specifically lends very strongly to the diegetic approach and at Alchemy Labs we specifically focus on the diegetic.
utilizing diegetic music as our main thing, but that being said, we never take things for granted.
We have explored and in our experiences we do use the combination of both, so making a system that supports both will be very helpful.
So we know that VR specifically is consumed by our users by stereo, not mono, stereo headphones.
However, because of spatialization, we have a really cool ability to...
create more than just the stereo sound coming out of our space of our headphones we can utilize mono sounds that are emanating from specific areas in the 3d field And in this case, I mean I wrote mono stereo surround and stems But basically those are old concepts in VR specifically we were thinking about everything as multi mono um meaning even if I have a stereo file we basically I basically would want to separate that into like two monos and place them in the virtual environment in a way that makes sense to my experience um and because uh like VR is such a cool um If you want to get more detailed experience, we can definitely utilize weird setups.
The concept of surround doesn't really translate to VR, because I can create as many audio sources of those mono sources as I want and place them wherever I want, so I'm not bound to 5.1 with the .1 being the sub, or things like that.
So that's definitely something to make sure that your music system supports.
And the last thing is making it responsive and interactive.
Obviously, all of those requirements, those are not requirements, those are more like, or if you have them in your experience, you will definitely be enhancing your experience significantly.
So, like specialization, no, specialization is mandatory.
Directionality or directivity is, if you're thinking about a speaker, there's a cone of how the audio outputs from it.
And when the listener listens to the audio, it's a cone of how the audio is coming out of the speaker.
So, if you're thinking about a speaker, there's a cone of how the audio outputs from it.
From a different angle of that cone, some of the sounds will be filtered accordingly.
And that's what directionality means, occlusion behind walls and things like that.
And costume attenuation, since we are addressing a virtual environment, we are not bound to the physics or the way the normal physical world would emanate sound and attenuate it.
And we definitely want to utilize that to properly mix the experience.
So, unlike a keyboard and mouse experience, the music system has to support all of those to be able to properly mix in the environment.
What you see here...
is a top-down picture of the beach in Vacation Simulator right here.
The black circles depict where the player can land. We have very specific interaction areas where the player can be at, so the player can't just move around to wherever they want. They have it's a room-scale experience, but these are the rooms that the player can be in. The red circle here, and if you can see here, the tower, This is where the speakers are placed. Again, because we subscribe to the diegetic experience, we definitely wanted to have the speakers located somewhere so that they can emanate from, but it had to be a very where the player can see visually where it's coming from so that the specialization is not wasted on an environment that the player can't make sense out of.
But that also brought the other interesting things like the directivity or directionality because the player can land behind.
uh the speakers and uh the occlusion where the player can actually land inside the um the dock shop in this case uh let's see a short video of uh all those elements come into play so you hear how the it's filtered right now open Oops, coming right up!
So other than the occlusion and the directionality, the other thing that existed in this example was the responsiveness of the music system, because it starts from those speakers that are behind the player, but when the player gets to interact with the sports, the music has a subtle, it disappears subtly, and then the next music is actually coming from the new experience, so the direction of the music.
is different in this case, and the music system had to support that specifically.
This is another example from Rick and Morty Virtual Recallity from the San Diego Comic-Con demo.
This was only shown to a small amount of audience, only the Comic-Con participants, so you can't experience it outside.
It's a five-minute or ten-minute demo where...
At the end of it, the player goes through the portal and into space, basically.
And there, I wanted to create an environment that feels grandiose and giant and interesting.
And for that, I utilized a multi-mono 6-channel that are kind of in a circle around the player.
So that it's not just stereo coming out of the headphones as an ethereal thing, but still, it's non-diegetic.
But it still gives the player the ability to look around and kind of sense how I decided to mix the different instruments in this environment.
So check this out.
It's a game through the portal.
Yeah, you gotta get out of here quick!
That's right, we're making a VR game!
Ha ha! Wubba lubba dub dub!
We're doing a regular futuristic, old-timey VR game.
The 100 years Rick and Morty VR games.
100 years, we're all gonna die, Morty.
We're all gonna die in 100 years, don't you get it?
Calm down, Rick!
You're gonna frighten people off!
Shut up Morty, you don't know nothing about my VR system.
I'm making a VR system.
You're gonna live in your headset.
You're gonna die in your headset.
You go away with your little thumb sticks.
Rick is a big advocate for VR, if you didn't know.
Yeah, so that's another example. Again, Alchemy does design with non-diegetic as well.
It depends on the experiences that you want to create for your player.
But I would definitely urge keeping it in mind when you're prototyping and when you're thinking about designing your system.
Music driven by VR specific input data.
So, first thing, what can we use?
The nice thing about VR is that it lends into getting a lot more information.
So, we can utilize head rotation, position, gaze direction, hand rotation, position, point, and interaction.
Different gestures potentially can also trigger music changes if you'd like.
Because VR is a virtual world we try to simulate physics a lot.
Usually most of the experience are physics based experience.
It would be great to utilize the physics information to drive music as well.
There are a lot of opportunities there that can and should be used when you're prototyping and creating your experiences.
Considering how to do music and literally everything because of that.
That's game mechanics, that's objects position in the 3D world and so on and so forth.
I want to show a quick video from an early prototype of Vacation Simulator where again we used non-diegetic music stereo to drive a surprise factor in gameplay.
Let's just check it out.
I'm not sure what the meaning of this is.
I don't know.
I don't know.
I don't know.
I don't know.
I don't know.
I don't know.
I don't know.
So obviously lighthearted humor with the power of music, very easily achieved and enhanced, utilizing the head rotation data.
Here's another example of a prototype that I've done in the weekend so you'll recognize the steam hands in there and all that.
This is a very basic educational game that has buckets and it's an addition.
You put the cubes in the buckets and in this case I'm utilizing music to gauge success.
So there are two things that are happening.
Actually let's look at it and then I'll talk about it a little bit.
Okay, very simply used, again this is a prototype.
There are two really cool things that are happening here.
A, the music helps the player understand if they're doing right or wrong and then the farther away they are from like achieving their goal the music just sounds bad.
I could have gone with more extreme but that was the...
The concept of trying to prove how far you need to go to make it extreme.
But the other really cool thing is a game interaction or a way to interact with the world that you cannot really do with a conventional game, and that is to use your head to create focal points.
For example, in this case, you looked at one bowl.
It cleared off all the sounds from all the other elements, and the only thing you were hearing is the sound of the ball.
That was why the music transitioned while the player was looking to the right, to the music of the ball to the right.
And I think it lends to another cool game mechanic that I would definitely encourage to explore, which is utilizing a stethoscope or a microphone to point at different areas of the world.
to focus on those specific areas.
Enhancing game elements with musicality.
By that I mean turning objects in your world into musical instruments.
Why would we even want to bother?
We've got a, well, first thing, it can be a determining variable in the viability of the design itself.
Meaning, in the prototype stage, when you first create your object, and we'll see an example later on.
You may want to toss away your prototype just because you haven't experimented yet with the additional factor which is the sound and music, musicality in some cases.
If you, if you add the musical elements into it you can add life to the environment and bring more feedback and responsiveness, because after all VR is a...
like if you do it right it's a very responsive environment and should react to anything you do, whether it's surprisingly or in a measured way.
It offers a creative outlet for the player who are after all here just to have fun.
And it can strengthen the emotional atmosphere of the scene.
For example, if you're doing a bike experience, you'd be able to have an object that has an electric guitar sound coming out of it as a menu, for example.
What are the things that you may want to consider when you're doing something like this?
And again, I feel like I'm talking to the right crowd here, because specifically, I don't want to talk to the audio people, to the audio department.
I want to talk to the designers, to the people who are creating the experiences.
Stay. I'm kidding.
Just because these are things that need to be considered early on and prototyped on because they can make a significant difference in your experience.
So, okay, so things to consider are a potential problem between the background music and that element.
Scale of that element does not fit the background music. You might create kind of a cacophony. So instead of creating something that Would be comfortable for the player to listen to you actually are making the opposite just on specific chords. So that's something to consider You want to choose the right scale and harmony. That's again. That's on the musician, but but still It's something that you know, you can demand for example The If you have a Middle Eastern experience, you can go with a harmonic minor scale, and it will sound a little more to that genre.
I will lend to it a little bit better.
And then you want to design around the UI. So because we are, again, VR is a very interactive experience. You have Buttons and knobs and levers and they all respond in a very different way sometimes stretchy objects that you may want to turn musical So there's there's a lot of challenging there in the implementation as well That you may want to consider early on because those are Implementation this this is basically audio audio physics system Which is not obvious in any system that was created.
We're fighting hard enough against the real physics simulation, but this is another aspect of the physics that needs to be taken care of.
And then you want to consider solutions that work into infinity.
Which means you can't predict when a gameplay will end.
You may want, like the player may continue forever.
So in VR specifically, you might have to end up with other solutions.
And we'll talk about it a little more later.
Let's see an example from Rick and Morty Virtual Reality in the microverse where you're charging a battery.
So I see this as a wonderful example for the viability of the product depending specifically on sound design and in this case ramping up the the speed of it depends on musicality as well.
The first thing that ended up happening when we were prototyping this, if you look at kind of the size of this board, when we started prototyping and we tested that specific interaction, The player had to continuously scan the board left and right to find out where the player needs their attention.
This game was literally unplayable until sounds that came out specifically from the light bulbs helped.
And again, we're listening to everything from mono, so I don't know if you can hear.
But the concept is clear.
The player knew exactly where to look at right after I added the spatialization.
But even better than that, even without, if your sense of direction is not that great, which can happen with people, the additional help was the pitch.
So when the player looks to the left of the machine, they know, or when the player hear a lower note, they know they need to look at the left side of the machine.
And when they hear a higher note, they know they need to look at the right side.
And it intuitively becomes kind of a habit relatively quickly if you do that interaction a few times.
Similarly, this device had two modules.
So there was the clever solution that I've had with five modules and then three was using the minor pentatonic scale here.
Which, no matter how you randomize the notes, usually it sounds like a nice melody.
So that's kind of nice for that side.
And then, without those modules, it just becomes the first three notes of a major scale.
Which also made it very easy to listen to all the time.
This is another example of again turning an object into a musical instrument.
And this is the avatar customizer in Vacation Simulator.
I'm specifically starting in this example from the elevator so that we can hear kind of how the environment also responds.
The music changes from room to room in a very subtle transition.
That doesn't sound like off-putting or doesn't sound real, like it does, it sounds very realistic and natural.
And also how you can still hear the elevator from behind you after you walk out of the elevator.
Let's listen to this.
Let's listen to this.
And also the music is diegetic here.
It's coming from those speakers.
What's the next phrase?
So I really love this example because it really shows like how you can get a menu to become a real musical instrument.
You can improvise on it as you as you saw.
So an outlet to the player and how it adds to the emotion of the room and the environment.
This is the bathroom where you customize your avatar and it feels very.
Calm, relaxing, soft, and in this specific case, I wrote the music specifically for, like, to work with this new instrument, so there are no wrong notes at any point. You can, no matter what note you play, it will sound good with the music.
So that's definitely worth checking out. Now, this is an example of an infinite interaction.
Just so you can see, I sped it up in the middle of the way so you can get a little more sense of it.
So basically this will go on forever.
The player can keep playing it as long as they don't fail, they'll continue to hear it rise.
And we all know that that's impossible to make happen.
So this requires a specific trick that you can utilize, it's the shepherd's tone.
The shepherd's tone is usually used for a single long pad, an infinite pad that rises.
But in this case I used it for mallet sounds.
What you see here are basically the four volume automation of four different channels that run at the same time.
Obviously this is all baked. What we're looking at is the recording application.
Where and in the lowest note the notes are barely audible and it ramps up as you get to the meat area and then on the high notes the or high octaves the the notes gradually disappear and about here is where this track jumps from the highest note to the lowest note and so it basically creates an illusion of where The sounds infinitely rises while in fact the higher harmonics slowly disappear, the lower harmonics gradually comes in.
That's like a great effect that can and should be used for those kind of experiences to keep it musical and again a musical music scale.
Let's talk a little bit about designing musical instruments in VR.
So, first thing, things to consider.
Our perception, our hands for example, are very, very delicate and perceptive.
We've got pressure in each corner of our finger.
And when we're playing a guitar, for example, we have the ability to vibrate the guitar, the strings in very subtle ways to make them sound natural and nice in the way we like to hear the music.
This is simply not possible in VR in its current stage.
Not even when the hand is being tracked with all four fingers, because it's not as precise and as delicate as the...
As the real world simulation, because we all know we live in a simulation, so as the real world simulation is able to respond to our fingers and our hands, one day we might be able to get there. The other thing is because we're in the real world, we're bound to the physics system. If we think about the trumpet, for example, it has the three The three valves at the top here, the buttons that you click on, and it's kind of not sequentially to rise up.
You actually need to create different combinations to get the notes to rise up in a scale.
We don't have to. We are not bound to physics.
We are not bound to the length of those tubes, meaning that we can make instruments that are more intuitive.
So it lends to limitations, but it also lends to.
like creating cool things.
The last thing is, well, I'll take a shaker and, or a.
Well, a shaker, for example, which is an instrument that sounds like it's easy to imitate in the virtual world, while in fact it is very, very complicated to get it right.
And I'll talk a little bit about it later, but the granular versus global approach, because we have a lot of grains inside that shaker that if we want to emulate right, we have to really, really think about how we want to.
Create that emulation simulation so let's talk about guitar a little bit or an ukulele in the case of Vacation simulator there are a few things that we want to consider for this medium first thing How do you measure a strum and in this case?
We went with a single strum for all strings. You cannot do each single string How do you represent the instrument's response?
Because everything needs to be visually responsive.
You don't have to rely 100% on audio.
And you can see here how we made it kind of like a graphical toy approach.
And the strings only come out from here to here.
Will it respond with one hand?
And Alchemy specifically does a lot of work to try to make the games accessible to everyone.
And in this case, we sacrificed the second hand choosing harmony or changing the notes with basically a toy approach.
If you see the lights right here.
It kind of chooses the harmony or the chords for you.
Again, we're working with a lot of limitations, and we're trying to make the best, best possible experience for our players.
And then how precise is your interaction?
Well, do you want...
We wanted the plane here to be huge or small.
And again, because we have a lot of precision situation here, the hands doesn't actually need to touch the strings to play them in our case.
Because we found out that a lot of players will just find it so frustrating that the design is too precise for them.
So again, accessibility is in our mind.
Here's a small video I wanted to show.
That'll look nice in your garden.
Okay, so well in this case, I just wanted to show that in our game you can shrubify a ukulele.
and then use a shrub to shrink it.
And when you shrink it, the harmony actually changes pitch according to the size.
Like, we went as far as to make sure that the world responds to the instruments in the way that, well, the player can't expect to shrub a ukulele or shrink it, but if they can do that, then the world should respond accordingly.
And that's something that...
One of the reasons why it's worth adding in the prototypes, because then you can respond to it properly in your experience.
Harmonica is an interesting problem because it's a breath instrument.
You have to put breath to be able to interact with the harmonica.
While a microphone does exist in most of our headsets, blowing on a microphone is not a reliable way to get any data.
It's kind of...
It's a random noise generator, basically.
You're not going to get data that you can drive music out of.
And so you've got to think of other ways to do that.
In this case, yes, there are interaction areas.
And then things that you want to consider is how big, how far you'd want to put the harmonica in front of you.
And in our case, we chose it to be far enough so that the player can see a highlight on whatever area that they're interacting with, so the player can actually make a choice.
The other thing is about the player's mouth distance from the headset, because again, we don't have that information.
And we want to be inclusive.
There are people with...
Long heads and short heads and we want to address all of them So we kind of got to pick a size that works for everybody and then how many interactions area become confusing and that also lends To how we feel the instruments because when we're using a harmonica in the real world The fingers can feel the screws that are in the harmonica You'll really know where you're you're holding the harmonica and you utilize your lips and your tongue to really feel On which hole you're about to blow So that you don't have to look to be able to play Harmonica properly, which just will never work in VR.
The last thing again, the shaker, the maracas, which, why is it so complicated?
Well, first thing, even if you choose the approach of a single impact point and not full grains inside the shaker how much gravity will you put on the on that thing really depends because it can be different from reality and and bounce The very interesting effect that you can get from the shaker is the rain effect if you just rotate it or if you turn it in a circular motion.
Because those two are different sounds by themselves of rain that you can generate from it.
These have to be custom implementations of recognizing those type of gestures.
And then, obviously, the physics aspect of it, of what velocity will equal what volume.
So, to sum it all up, music gives you the ability to embellish interactions and intensify emotions in your game.
Consider music accents in your experience early because again this can change your final product.
And prototype to find the best solutions for your experience. Make sure to support the audio team with the systems and implementation solutions that will allow you to perform all the necessary tasks because it does require more programming power to be able to to solve. And with that the final thing.
Yes, so thank you very much.
We do have some time for questions.
I just had more of a comment than a question, which was when I was at Magic Leap, one of the first things we, it's the difference between VR music and AR music.
One thing we discovered quite early was that if you have non-diegetic music too loud in your AR experience, it immediately masks everything else that becomes VR immediately.
Music in AR, if you want to mix with the real world, has to be kind of way in the background and very soft and not very attention-getting because if it's a regular game music, it'll just mask everything in the room and you won't be able to talk to anybody, you'll see their mouths moving. So it's a different kind of experience between AR and VR. Absolutely, and I was only talking about the music today, not the sound design, but if we talk about sound design in VR, there's a lot of details that you want to...
Make sure you're not obscured by the music either because then you're detracting from the experience as well.
Yeah, thank you.
Hi, really great talk.
Nicole Lazaro from Xeo Design.
This is fun to talk on the headphones.
This is great.
I had a question about, well, great presentation.
I have a question about three-dimensional sounds, like getting a little bit more depth.
We just did the Bose AR game jam a couple months ago.
And we created a choose your own adventure, where we actually did audio escapes.
And you interact.
You're using audio to determine, make your choices.
You don't have to even look at your phone.
I was curious in terms of design, are we going to get there?
It's sort of like, Stereo seems to me like Flatland, where it's just between two points.
Right.
But we have your chicken fairy godmother at two o'clock high, and then the frog she's talking to down low.
It just creates a much more interesting volume, not just a, kind of a 360.
How do you talk about it being 3D, but not, I mean, but being additionally 3D, where you can actually walk through a space?
So first thing, this is what I was talking about when I meant spatialization.
And the main function is HRTF, head related transfer function.
This is the official term and there are like quite a lot, like I think four or five big, like bigger companies that already make really great spatialization tools.
Yeah. We use the resonance plug in. Resonance is lovely. Yeah.
And Resonance, by the way, have their activity built into it already, which is also kind of nice.
So there's a lot of solutions, they have many things, but yeah, like it's ready for everybody to use. I'm not sure what else.
Like in terms of...
Like I see it as a mandatory tool to create... Are you asking if I think...
Like this is enough to create an experience, just the spatialization.
Well that's definitely true, I think it already is.
I tried a lot of the Bose experiences, I feel like they have been missing out a little bit because I have heard better spatialization in VR.
It's probably because they have to have a lot of compromises in terms of processing.
because like the Bose headset...
It's on a mobile phone.
It does, it does it on the mobile. Actually, you're right.
So I'm not sure why it didn't...
I couldn't pinpoint to the exact area like I do in VR.
I can close my eyes in VR and point where the sound is coming from and I would mainly be right.
After I open my eyes, I look at it, this is where it's coming from.
In Bose, I didn't feel like I was able to do that when I was looking around.
You should try your experience, but if there's a, there's sort of like a 2D, in terms of art, because it's helpful to have language around this.
So in my mind, and I could be completely off base, but you know, it's 2D.
You then have 3D, so almost 3D kind of audio, and then you have 6D.
Yes, of course.
Where you can actually move through it.
Right.
The difference between what ambisonics, for example, can perform to what the 3D spatialization can perform.
Like you have a single location area and a sphere around you, or you pick where you put it in the 3D space.
I mean, I think it has a lot of potential and a lot of future for sure.
Yeah, you can just walk through like a marketplace and all the sounds pass you as you walk.
That kind of thing.
Thank you.
Yes.
Yeah, thank you.
I'll be really quick. Thank you. That was awesome.
Quick question. What's your favourite process or planning tool that you use to communicate with your production team?
Well, first thing, at Alchemy I'm also a programmer, so I do a lot of the prototypes that I want to do, and we have a very interesting language inside the company.
It's kind of funny because at Alchemy they're like, Daniel, make the sounds.
They bring me in early enough that I can ask enough questions and that we can iterate and go back and forth just like any other prototype.
And I think that's the main thing.
It allows me to improve over time, understand the vision of the specific experience, and well, the unfortunate consequences is that, you know, just like any prototypes, let's say anywhere between 30 and 70% of it will go to the trash.
And what if you were working with a remote team?
How would you manage that?
We do have some programmers on remote capacity.
And it's a lot of video conversations, just the ability to see and sense what's happening, and constant iterations.
That's all I can say about that, really.
Thank you.
Thank you.
Hi, in working a lot with VR, people still get motion sickness because primarily because they're moving their heads too fast.
And when I'm standing over them, I can go, hey, pretend it's a video camera.
Quit jerking around.
Have you considered or tried any kind of auditory feedback that's the equivalent of slow your head movement down in order to avoid that thing, which is still huge in the industry?
Yeah, I haven't found a solution audio related to that.
At Alchemy, we see that as a...
Yes, it is a problem with the speed of the head.
Of course, the faster you'd move, the less the frames would be able to respond properly.
But that's why on PC experiences we have such a strict hard limit to make the performance of our games work at 90 frames.
The higher the frame rates of the game are, you can improve the feeling of that sensation of motion significantly.
The frame drops are what really causes the problem, as far as I can perceive it.
So it's more about solving that, really, the performance.
You can't get the user to hyper down?
Well, I wish, but it also kind of defeats the purpose of the freedom that we want to give the players.
If we can solve it, then on our end, without restricting the player in the way they interact with the world, we will work really really hard to solve it, and it's worth it.
Thank you.
Okay, thank you very much.
