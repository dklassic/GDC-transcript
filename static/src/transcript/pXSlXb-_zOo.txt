Thank you.
Hello.
My name is Seth Rosen.
Please shut off your cell phones.
Try to squeeze towards the center so people who are coming late can find a seat.
And do remember to fill out your GDC surveys that you'll get in your email after you've checked in.
All right.
So as I said, my name's Seth. I'm a systems designer. So this is a level design workshop.
Why is there a systems designer up here? Well, for a couple of games that I've worked on, my focus has been on AI behavior outside of combat. On Bioshock Infinite, I was part of Liz Squad, which is the team primarily responsible for Elizabeth, who's our companion character.
And on that project, I was kind of more of a character designer. I was using level design and systems design to make Liz feel alive.
And right now, on Mafia 3, I'm working on what we're calling the living world.
It's the population and activity of our version of New Orleans in 1968.
Alright, let's dive in. So, games are interactive, right?
We're not in the business of throwing something up on screen and just letting the player observe it.
We want to draw the player into this experience and make them believe in it.
Believe that this space is part of a larger world.
And environment art is a really huge part of this, but it's static and it mainly deals in history.
So how can we add some dynamism to this experience?
And one solution is, the solution I'm personally most excited about is to add life to your level.
Actors inhabiting the space who interact with their surroundings and react to changing conditions and, you know, just generally exhibit lifelike behaviors.
Now, the lead actor, of course, is the player.
And they're probably really the only actor that can actually be considered to be full of life, but we can create the illusion of life for other characters in the world.
And ultimately, that's what I'm talking about when I say life in your level.
Or, to put it another way, a performance of life.
Characters, whether they're humans in life or AI in games, are performers.
The person sitting next to you, no matter how well they know you, has no idea what's going on in your head by default, or for that matter, that anything's going on.
Without performance, we're empty shells.
And gaming AIs definitely start out as empty shells.
It's up to us to fill them up with that yolky goodness and create that illusion of life.
Fortunately, humans have a pretty good sense of how to perform life.
And on top of that, there's actually only one person that we really need to convince that our AIs are alive. It's the person holding the controller.
And that's important, actually.
Game AI, above all else, should be player-facing.
If the player doesn't see their performance, they might as well not be on stage at all.
And that's where the bad news comes in.
If the performance ever falters, the audience's suspension of disbelief just evaporates.
So right out of the gate, scripting an AI's behavior and reactions is pretty much an on starter. And believe me, we did try on Bioshock Infinite. For a long, long time, Liz existed as an AI that was really only functional in the most basic sense of the word. She would follow along and take cover and that was about it. It was painfully apparent that we had a long way to go before she was a really believable and relatable human character. So We picked an area of the game that would serve as her crucible. It was the beach in Battleship Bay.
And our first attempt consisted of a series of triggers that when the player hit them, Liz would go to her next mark, and at each mark she would play an animation.
The results were abysmal. Terrible.
The biggest issues were how few things she had to do in the space, how poorly she reacted to any moderately irregular player movement, and how much additional scripting we would have to do to make her respond to anything going on.
So after demonstrating to ourselves that, yeah, there's just too many rules to being human for scripting to be a vile option, we decided that the only path forward was systems.
Right here, I've got a video of Liz making use of some of these systems.
I'll get into the details of them a little bit later on.
But we could make suggestions to her and let the systems decide what she was going to do rather than being prescriptive about her behaviors.
And this is better from a production and robustness standpoint, but it also maps pretty directly onto real world examples of life and humanity.
Our lives proceed according to a series of rules and patterns.
And humanity is born of these things.
It's a collection of tiny hints to others.
We can create a set of systems that act on a character, and these systems describe these rules and patterns, and then these systems continually offer options to the character for the options that they have to do in their behaviors.
The result is a performance of infinite duration.
And that's kind of what we're going for, because we'd never want that performance to fall apart.
So the next step was to figure out exactly what patterns of behavior we wanted to give Liz, and how we were going to spotlight her performance.
And as we were figuring this out, our main reference materials were theater, Disney animation, and our own everyday lives.
To organize my thinking when I'm kind of figuring out how to give life to a character, I break their behaviors down into five categories.
Activity, Idle, Conversation, Locomotion, and if it's in the game, Combat.
I break it down this way because there's not one single thing that we're going to do to convince our players that our AI is alive.
It's this wide array of behaviors and actions that all sum together communicate life.
Now, when our goal is to breathe life into an entire city, rather than a single character, the activity and idle categories kind of blur together a little bit.
But I think the categories are still useful for kind of figuring out what your approach should be.
All right, let's talk about activity.
An AI's activity are the behaviors that demonstrate that they take an active interest in their world.
They belong in this world, and they have desires and intentions of their own.
For Liz, we call the system Smart Terrain.
On Mafia 3, it's called World Interactions.
But it's basically the same thing in both cases, and it's probably something you may have encountered in your own work.
There are smart objects that are basically a big ball of data, animation, code, art assets, sound effects, VO, and visual effects.
They're game objects that have instructions for the character and conditions for use.
Okay, let's look at a few examples of Liz's capital A activity.
Let's do a show of hands. For those of you who have played Bioshock Infinite, who remembers when, after waking up on the beach, you find Liz dancing on the pier and she invites you to join her?
Most people. So that was scripted. 100% of players who got that far saw that moment. Now, who remembers Liz trying to pick up a medicine ball or skipping stones on the beach? Way fewer. And that's actually what we want.
These were entirely systemic but they feel almost scripted.
They have VO and you probably only saw them once.
They're high priority smart terrains and they have long cool downs and they're either placed on the critical path or have pickups near them to entice the player to walk over there.
Okay, last example.
Who remembers Liz making shadow puppets in the lamp light in Soldier's Field?
Even fewer.
Great.
Again, this is entirely systemic but it's a little bit off the beaten path and lower in priority.
And these are all great little moments, but ultimately they're fleeting.
So, how can we keep Liz engaged over longer periods of time?
Well, we just cover the levels in these smart objects.
And then we let the systems decide how to strike a balance between active and idle.
This is a video that shows the smart terrain placement in a level of Bioshock Infinite.
All the green meshes and diamonds are smart terrains.
So, wait a second.
We're just going to saturate our levels with smart terrain and let Liz decide what's going to happen?
Yes.
If this is going to work out at all, you have to be comfortable with a little bit of uncertainty.
Not everyone's going to see everything, and for each of these smart terrains, sometimes Liz will use it and sometimes she won't.
You just have to be okay with that.
A guaranteed scripted moment is the enemy of interactivity and variety.
And those are the things that are really going to prop up an AI's illusion of life.
That doesn't mean that every single action the AI makes has to be left up to the system, but overall it will be a more convincing performance if the majority of it is.
And I think as a player, you really do feel the difference between a scripted setup and something that happens opportunistically.
Something that the character decides to do, and decides to stop doing, too.
Liz will dance for eternity if you let her, and after a few minutes you kind of stop believing in her as a character.
You remember that she's just an AI in this game that you're playing.
But if you stumble upon something like the skipping stones or shadow puppets, it feels like a stolen moment. It's private and special in some way.
And that subconscious notion that not every other player saw what you just saw, I think, makes it even more personal and makes the character even more real.
Fortunately, whether or not a given player sees any of these systems-driven moments isn't just dumb luck.
Liz is not picking things at random out of some weird, invisible smart terrain hat.
She's using systems, but that doesn't mean that we're surrendering control in the name of robustness.
It just means it requires a different approach.
The system had rules for which smart terrains to consider, and each smart terrain has data on it that factors into that decision.
How desirable it is to use, what direction it can be used from, and how long it goes on cool down.
Combined with the actual placement of these objects in the level.
uh, the character is able to make the most natural decision possible in all instances for what activity to perform. And by setting up all this data and tuning our selection criteria, the system drives the character's performance across the entire game, skewing it closer and closer to that ideal of a polished, hand-scripted sequence. For Liz, all of this decision making was built into her brain. But she's really only concerned with picking the single best option at any given time.
On Mafia 3, we're dealing with a whole city, so we need, again, a little bit of a different approach.
The interaction manager is our equivalent to Liz's AI.
It's a big brain in the sky that collects all of the world interactions in the city, and based on similar types of data, picks a bunch of world interactions to turn on and populate with people from that neighborhood.
Once the manager chooses a world interaction, it checks how far away it is from the player and assigns it to one of two buckets, out of sight or in sight.
Out of sight is for interactions that are far enough away that we can spawn an AI directly into it and the player won't notice. And in sight is for ones that are closer to the player.
They'll try to capture people as they're walking by.
And often we'll restrict an interaction to be only available as one or the other.
If we say something's out of sight only then it allows us to bring in large groups of people or large props like a band or a second line in the street.
We can also use out of sight interactions to put AIs in places they can't or shouldn't walk to, like a balcony or a porch.
On the other hand, when we limit something to being in sight only, it gives the player a chance to actually see this moment before it's complete.
This is for things like buying drugs, or, well, trying anyhow.
Uh, the manager load balances the relative density of out of sight and in sight interactions, making sure that there's always some of each happening in a given space.
the out of sight interactions ensure that when the player gets there there's already some level of activity happening there you never get that moment of, oh, the player's here, quick, everyone do something so then the insight interactions again give that player that opportunity to actually observe people acting with intentionality and behind the scenes the manager's running timers in the background periodically telling people to move along so that we see more intentionality and get new slots open for the interactions to fill with new AIs doing new things.
Because, you know, if you arrived at a location and nothing changed around you after standing there for twenty minutes, all the people around you would start to feel like animatronics.
Disney rides deal with this by forcing you to move out of the scene and into the next one.
But with the player in control of the camera and their movement, we don't have that luxury.
So instead we have the manager systemically create a changing scene around you.
Unless of course we need a static scene for gameplay reasons.
Unfortunately, we found out that just having all of these activities available isn't quite sufficient.
if Liz reacts to seeing a songbird toy. It doesn't do anything to make her feel alive if the player doesn't see it. Staring at a wall. It may as well not have happened. Our AIs again are performing. They need to be on stage. And for games that means in the camera frustum. But we don't want to grab control of the camera just to make sure that they see these moments. So how can we encourage the player to notice these actions that the character is taking? Well, we make them noisy.
When Liz spots something exciting to her or for the player to pick up, she'll call it out.
And when she sits on a bench, she sighs with relief.
This can be applied to open worlds too. Like in Mafia 3, you hear a protest leader's VO ring out above the din of the city.
And when we hear a sound, we just naturally want to turn and investigate the source.
But, worst case, if for some reason the player doesn't do that, we're adding some life to the soundscape.
Alright, let's talk about Idle.
idle behaviors are not terribly sexy but oh my god they are important. Uh when an AI is idle is probably when they're at the highest risk of not feeling present in the world. And if those quiet moments don't work there's just no sense in bothering with the splashier stuff. So we need our AIs to stay present by constantly implying that there's something going on inside of their head.
They can examine their surroundings, find a place to rest, fidget, or just generally exhibit their internal state with their body language.
By saturating our levels with smart terrains, we are able to ensure that Liz never has to go too far to find something to occupy herself.
And when she does decide to go and sit on a bench or lean on a railing, she'll look at the thing that she's moving towards.
Because when you're intent on something, you look at it.
It's just a reflex for humans.
But we have to remember to build little things like this into our AI's behavior, because those are the things that make them feel alive.
And when she's not using smart terrain, Liz has a look tracker system that kind of kicks in and keeps her present.
She will survey the space and pick an object to look at.
And the system boils down to a pretty simple guiding principle.
What do humans look at and why?
And for that matter, what does Liz specifically look at and why?
Like so many other human behaviors, this principle can be described by a set of rules. We tend to look at things close by and we won't look at things that are really, really far away. We don't look at things that are behind us or way above us. We do look at other people, especially if they're talking, but we won't stare at them. We look at things that make us feel something. And unless it's totally fixating, we tend to not keep looking at the same thing over and over again or for a very long time.
So with these rules in mind, we decided that we would make these look-at markers and place them all over the levels and attach them to characters and sound effects as well.
Each marker, the eyeballs you see covering this painting here of Lady Comstock, had two bounding boxes. One that described what part of the object Liz could look at and one that described the area that she had to be inside of to be able to look at it.
In addition, it had three important pieces of data.
how interesting it is so that that's both how high priority it is to look at and how long it should hold her attention for uh...
how long the cool down lasts and how she should feel while looking at it happy sad angry etc so by covering this painting with all these eyeballs we're basically telling Liz hey you should be pretty fixated on this thing So in addition to emoting when she's looking at stuff, Liz actually had a like full body emotion system that would allow us to change her animations and body language based on the narrative events as you progress through the game.
These are just a few examples, but you can kind of see how they change her expression and her base pose and her fidgets and also how willing she is to look at the player. If she's pissed at you, she's upset. She's looking off to the side.
By making a motion variance as well of some of the really common idle style smart terrains, we're able to expand this reflection of her internal state to include some of her actions. Like if she goes and sits on a bench in a huff, she's pissed. Alright, so what does this idle category look like for an open world game like Mafia 3? Well, it doesn't. Kinda. Let me explain. I mentioned earlier that activity and idle blend together for this sort of game.
I just don't really find that it's worth drawing the distinction between activity and idle for the characters in an open world game. It's not that we don't want characters doing idle behaviors, it's that you're not spending enough time with these characters to really see the difference. If you were to take a horizontal slice of Liz's behavior across the entire game of Bioshock Infinite, that's basically what we want our city to look like at any moment. So, active, idle, whatever.
We do need the more mundane stuff so that the more interesting stuff shines, but on an individual basis, AIs basically need to show up, do a micro-performance, and be on their way.
By the time you come back to them, they're probably gone.
And our goal here is to make the city feel alive.
Bustling, in short.
Now we have probably a hundred or more AIs in the space, and that means that we can't exactly afford to have like a super intense AI brain helping each character decide if they should be doing an active or idle thing.
So we approach it from the other end by having objects seek out subjects.
Billboards will broadcast a look at me event, and nearby AIs will evaluate whether or not they can do that, and if so, turn their head.
World interactions spawn people directly into the interaction or check passersby to see if they can find the right person for the job.
And there are global factors that are affecting this search for a participant as well.
If it's raining, for example, a reading newspaper interaction will just stop looking for someone, because you don't read a newspaper in the rain.
We have global cooldowns as well to kind of keep the city from becoming a broken record where you have racists harassing you constantly or a busker every five feet on Bourbon Street.
So, Idle gets a little bit blurry for characters in an open world game but I think it's actually crystal clear on a neighborhood level.
A neighborhood idles by having an identity, a specific population and type of activity that goes on there.
For each area of the city, we're setting up data to determine the demographics there.
Race, income, age, gender.
The density of pedestrians and what types of people they should be.
Office workers, tourists, junkies, hippies, you name it.
The type and frequency of props that we give to pedestrians.
Office workers should have a briefcase, maybe.
The density and types of world interactions that can appear, which is all the activity and sort of...
active idle stuff. And last but certainly not least, whether or not pedestrians have a chance to spawn drunk. As you're moving through this area, droves of civilians are drifting past you and you're seeing enemies doing criminal activity or whiling away their day. You just kind of gather a sense of what sorts of people are hanging out there and why.
And regardless of whether a given AI is using a world interaction, they still need to be present and reactive.
Our AIs are constantly sending messages back and forth to each other and evaluating whether or not they should run some reaction behavior.
These reactions range from saying hello to someone they're walking by on the street to freaking out because the player's waving their gun around.
And a large portion of these reactions are aimed at the player and the actions they take because those are inherently higher visibility, which, again, they're performing and we want them to be on stage.
But that said, a neighborhood's pedestrian population and the reactions they have, especially amongst themselves, is also important because it creates this murmur of life behind the activities of the neighborhood.
Without this background noise, we run the risk of the player feeling like Truman, everything constructed for their benefit.
All right, conversations.
When we're in a city, conversations contribute to that background noise.
But they're also an important moment of performance for our characters.
Firstly, characters should focus naturally when they're in conversation.
And humans basically have two modes of attention when we're participating in a conversation, one for when you're the speaker and one for when you're the listener.
When you're listening to someone speak.
you spend almost all of your time looking at their face.
You only let your eyes dart away briefly and every so often so that the intensity of your gaze doesn't become awkward.
Your intent focus communicates that you're engaged in listening to their words.
But when you're the speaker, you actually spend most of your time not looking at the other person.
You look near them or past them, but you'll only periodically actually look at their faces to kinda clue them in, yeah, I'm still listening, I'm still talking to you.
or sorry, still aware that they're listening and that you're still speaking to them.
So besides getting their attention right, we want to make sure that their movements are synced up with their VO.
And the best solution on both projects has been to give the characters a very neutral base pose and then tag the VO with animation.
It's faster and more flexible than full animation, and these gesture animations are also opportunistic, so they can drop away if a higher priority animation needs to play.
If the character needs to start moving, the gestures fall away and the head tracking remains. Show goes on.
For open world games like Mafia III, there's actually one more piece of conversations that we really need to be worried about, and that's the content of those conversations.
Variety here is key.
If you hear the same dialogue over and over and over again, the whole city plunges into the uncanny valley.
And of course, there's some hard limit on the number of lines that can be written and recorded and mastered and implemented.
So we mix and match.
The player's going to be spending a lot of hours.
And in all likelihood, they're going to hear the same line twice.
We just can't beat those odds.
But.
if we structure our dialogue as AB style conversations, then we have a pretty good chance of at least having a different response the second time they hear that line.
So, by organizing our ambient conversation lines into these two buckets, where A lines are statements and are categorized by the types of responses that are reasonable to have for the other person, positive, negative, neutral, or laughter, and then the B lines are played based on which bucket of A line we selected we're able to get a little bit better variety, a little bit better bang for our buck.
Locomotion.
Locomotion is mainly an issue for characters that you're going to be spending a lot of time with.
For more transient characters like pedestrians in an open world game they mostly just need to not look like idiots.
as long as they avoid other people and avoid obstacles and stop to wait before they cross the street we're pretty much golden however for companion characters like Liz where you're going to be spending upwards of ten hours with them it's a little bit more complicated uh... alright so for that kind of character we need to get them on stage right locomotion provides the backbone of getting them onto the screen Initially, we had Liz following the player everywhere they went, but in early playtests, we were finding that the player would lose track of her basically immediately and then spin in circles trying to find her. And we didn't want to just teleport her around to keep her reliably with the player. That creepy Watson effect kills her as a living, physical thing immediately. We would still teleport her if she got super behind, but it was kind of a panic button.
So instead we figured out how to get her out in front of the player.
And you'll see that system here in this video.
Our solution was to calculate a golden path between the player's current position and their goal.
Because Liz had this advanced knowledge of the rough path that she would have to take, she was less tightly bound to the player.
She could be a little bit more tolerant of changes to direction or speed, and she would always know where to go if she needed to walk out in front of the player and wait for them.
We called this approach her goal-side behavior and found that in addition to keeping her on screen really effectively, it turned her into an implicit quest arrow, which was a nice side effect.
But more than that, the goal-side behavior allowed us to pick really good candidate smart terrains for her performances.
And as you can see in this video, if a smart terrain is close to Liz or it falls inside of that cone, then we can be reasonably sure that the player's going to see her use it.
Now, smart trains outside of that cone can still be used, especially if they're high priority.
But we're trying not to distract her too much from her efforts to stay goal side, because that's priority one.
Because the player is facing forward, they're generally going to be moving towards their goal.
And at worst, if the player is speeding along and Liz can't stop and use a smart train, she'll stay alive by looking around at the various look at markers in the space.
All right.
This final section is probably also the most familiar to a lot of you.
Combat.
And there's a ton to talk about with combat AI, but I'm short on time, and there are definitely AI programmers who could do a better job. So I'll just talk briefly about non-combatants like Liz. At first we were also trying to keep her on screen during combat. She would run through the line of fire just to take exposed cover. She just seemed completely unaware of what was going on around her.
Quickly though, we realized that during the fight, the player doesn't really care about where Liz is.
They're way more interested in putting bullets into their enemies.
So we changed her behavior to just kind of get her safely out of the way above all else.
That doesn't mean she's off the hook though.
The danger is real for the player, and she should reflect that.
the way that we got her to kind of reflect this sense of danger was she would sort of peek out from cover periodically, flinch if gunshots landed nearby and if her position got compromised she would leave it and run with her hands covering her head trying to protect herself She also had a few functional combat behaviors.
She would call out dangerous enemies and toss ammo and health to the player at critical moments.
She had your back.
And better yet, we were actually finding that players would invent stories about what Liz was doing when she was off screen.
She was scouring the battlefield and finding resources just to help them out.
Never mind that she wasn't doing any of that, her performance was overall convincing enough that people were augmenting it of their own volition.
Exactly what we want.
And the final piece of Liz's combat performance actually comes after combat is over.
We were finding during development that the combats were lasting long enough that all of her smart terrain cooldowns finished and she would just pop out of her cover pose and saunter over to some world in her, or sorry, smart terrain.
Totally not phased by the carnage she just experienced.
So to address this, we created a special motion we called After Combat Emotion.
It would make her a little bit somber and prevent her from using smart trains for a little while.
Much, much better.
All right.
Quick recap.
If a world without AIs is a dead world, then so too is a world with AIs that don't convince you of their humanity.
And humanity is not a declaration.
It's a collection of hints taken in aggregate that make it apparent to others that we're alive.
To figure out what these hints should be, observe your daily life. Notice the ways that your attention falls as you're in conversation or looking around your room. Notice the way that you move with purpose towards your goal. That you always find something to do, even when you're doing nothing at all. And each of these individual behaviors, whether they're in action, in idle, in conversation, in locomotion, or in combat, can be described by systems.
And these systems communicate to the player through body language, vocalizations, and a strict adherence to the laws of physics. The player develops a sense that they're surrounded by living things. These are the systems that are the heart of your life and your level. And they never stop. If an AI's performance ever falters, they die in that moment. Always be performing. Alright, that's it. Thanks everyone for coming.
If you do want to see some other really great talks that are about similar topics, check these three out.
They're all about an hour long.
They're really solid.
And thanks to John Abercrombie and Sean Robertson, to the guys up there, for sending me their old Liz videos.
Have a great ADC.
