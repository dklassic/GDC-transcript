Hi, everyone.
Oh, good.
Mic's not working.
So yeah, I'm Sebastian.
Thank you, Dave.
Thank you, Dave and Steve, for inviting me to come talk at GDC.
Like the big text over there says, I'm a senior designer at BioWare, and I was most recently the lead combat design on Dragon Age Inquisition.
And a lot of my time I spent working on the AI for the game.
So before we get really rolling here, can I get a quick show of hands, who here has played Inquisition? Okay, good, good.
And who's played some of the other Dragon Age games, DA2, Origin, okay, lots of fans in the crowd. And also this is my first time at GDC, and I'm just curious, who else is here for the first time, are there students just trying to get in?
Okay, we're going to have some fun today.
Great to see everyone here. Still a few people coming in at the back. A disclaimer, because this seems to be a tradition, a lot of the screen shots and art that you'll see in here are scratch or they have debug renders in them and are not representative of shipped game. The game shipped almost a year and a half ago now. So I don't know if that's a big concern anymore, but it seems to be a thing that people say when they do these presentations.
So let's talk about Dragon Age Inquisition. It is a fantasy RPG from Bioware. And the big thing about Inquisition for us is that it was our first title on Frostbite.
which is a really neat engine that's an internally a technology.
We moved from our classic Eclipse engine that we used to make DAO and DA2.
And yeah, Dragon Age Inquisition is the first RPG on Frostbite.
It's our first Bioware title on Frostbite.
And...
Who here has been through an engine transition before? Show of hands. Okay. So yeah. Yeah. So you know what that's like. So big challenges ahead. When we started working on this back in 2011.
It's also the third game in the Dragon Age series, which meant that although we were starting fresh with tech, we had already established a world and a story and characters that players already knew and loved, and so we had a lot to live up to with this game.
And we also knew that we were going to be shipping on five platforms, not just the PC and the Xbox one and PS4, but we were also going to be targeting the Xbox 360 and the PS3, which meant that everything we were going to do was going to have to scale. So...
a lot of constraints, a lot of things that sort of, you know, influenced us when we were starting development. And from the player's point of view, the biggest change that we made for Inquisition was that we were adding open exploration to the game. So that was going to be a big change for us when we were developing the game.
as we learn to make the game deal with these big areas.
And that's going to feature prominently in the challenges that we talk about today.
So, when we talk about building the AI for Inquisition, the first thing we talk about is building creatures.
Dragon Age has a huge variety of creatures.
Big ones like this dragon, and giants, and big, big creatures.
We also have a lot of little creatures like this cute little nug.
Lots of little wilderness creatures to fill out those big open areas.
Some creatures will fight by your side.
These are some friendly templars.
But most of the creatures we talk about, they just want to eat your face.
So.
We also need to talk about building AI for party members.
And this is going to be another big theme that we talk about today. We have a variety of roles and capabilities. Dragon Age has always been about the party that you travel with. You don't go alone. You have melee fighters and you have ranged snipers. You have mages. You have indestructible tanks. A huge variety of capabilities and powers. 90 some different unique abilities.
And just like in the previous games, the player has the ability to switch control between any character in the party at any time, meaning that from the system's point of view any character can go from being player controlled to AI controlled in the space of a heartbeat. And that's a particular challenge we have to deal with from the system's point of view. Additionally, the player can pause the game, pull the camera out, move around the battlefield and give direct orders to any of the characters in their party at the same time and watch how that scenario plays out. And we'll talk about how the A.I. accommodates that kind of control as well.
And when we're building, because we're starting on a new engine, in addition to building the content and the creatures and the party members and the abilities and the combat system, we also had to build up our tools and workflow. As developers, we know that iteration speed is key to improving quality. The faster you can see your changes in the game, the faster you can evaluate them and see whether you need to improve further or whether you've achieved what you're trying to hit.
So we knew that we wanted to take advantage of the engine's data-driven pipeline to be able to do live tweaking in our tool set and see those results in-game as we were playing and editing and iterating on gameplay.
For our AI, there were two related workflows, actually, that we were working on.
One is for combat designers who are working on building out.
the AI for creatures and party members and building all the pieces. And we also needed to worry about work flows for our level designers who had to shape the AI behavior in the environments that they were building and the plots and stories that they were trying to tell. So today's focus in this context.
is going to talk about two big themes, as I mentioned. One is adapting to big open areas for game play in a way that we've never done at BioWare or on Dragon Age before. And the other is looking at how we built up the party AI systems to support our complex and customizable party members so that they can support the player.
And this is a retrospective. It's been, as I say, almost a year and a half since we shipped Inquisition. So I'm going to try to tell the story of development and some of the roadblocks we hit and the way that we crossed some of those challenges.
So hopefully by the end of our talk today, you'll be able to take some of these solutions to solve your own related problems and maybe cut out some surprises by taking advantage of the trial and error that we went through bringing this game up.
So we got a big box labeled frostbite. We cracked it open and what was inside? Well, thankfully we knew that we wouldn't have to solve pathfinding.
We got a path finding middleware called nav power that came with an integration into frostbite. So we have path mesh and navigation for our characters. You can see that big sea of green polygons over there on the display. So that gave us a really good starting point. We could get characters moving around and following each other around without having to do any of that base level work for ourselves.
On the other side, we also were able to take advantage of another EA team who had built a decision tree architecture.
And this is where we would build the vast majority of our logic from the combat design side.
It came with a nice visual node editor that we were able to use.
And we, as a game team, as a combat team, we built out a huge library of conditional evaluations to test things in the world and to be able to give our AI the information it needed to make interesting choices. And also a set of interfaces to drive game systems. And that's primarily in our game where am I going to move, how am I going to move there, and then what abilities do I want to use? Well, what's an ability?
And ability is a concept that we brought forward from past Dragon Age games that gave us a consistent approach to defining gameplay actions. So for players and party members, abilities are explicit. This is something that you buy as you level up. You go and you buy abilities with points, you put them on your bar and they're something you can use. And over the course of the game, you're getting new abilities, you're upgrading them and these are the things that you do in game.
We also use this, in addition to using it for party members, we also use the ability framework to define our NPCs. So everything that an NPC character does is also defined as an ability even though it doesn't have that player facing interface in the level up GUI with the ability trees. So this includes, as I say, obvious things. I'm going to throw a fireball. I'm going to taunt that guy over there and get his aggro. I want to dodge out of the way. Those are all active abilities.
But some things that aren't player facing as abilities like jumping, drinking a potion, twitches that NPCs would play, I'm going to yell at you from across the map, those are all implemented as abilities under the hood. So this gives us a consistent approach to how we define gameplay actions. And this is going to be very important when we talk about ability choosing. So...
We've got our pathfinding system.
We've got a decision tree.
We've got a framework to build our actions and abilities on.
Now we need to actually tackle making all these things go.
We'd never made a game with these Frostbite tools.
We'd never had open our exploration areas.
We knew that we had a big scope, lots of things that we had to build.
And so we wanted to make sure that we had a consistent approach to the way that our AI evaluates and the way that decisions are made so that everyone on the team had the same idea of how things were going to work at the most basic level. And we wanted to make sure that, you know, even across creatures and party members, because everything is running under the same AI system, we wanted to make sure that everyone followed the same basic set of rules. And this is what we came up with. So we'll walk through a little example. So I'm going to run AI in our example here on this character who's standing in front. And those four glowy purple fellas in the back there, those are our enemies. So the first thing our AI does in the core evaluation loop, the first thing we're going to do is pick a target. So that guy. That guy right there.
The next thing that's going to happen is that we're going to choose what ability we want to use. So we picked flanking strike down there in the right-hand corner. That's a melee ability, so we know that we're going to have to move, because we're going to use our daggers, we're going to have to move in order to be able to execute that. And...
Once we've moved into position, then we can play the animation, apply the damage, do all the fun stuff of actually using that ability. So that's the core decision-making loop and action loop that every AI-controlled character in the game basically follows. There's a few exceptions, but typically you pick your target, you pick your ability that you want to use, you move if you have to to accomplish it, and then you execute it by firing the animation, and away we go.
So with this in place, as a team, as a development team, we have a consistent approach to AI evaluation, supports both party members and creatures. Between party members and creatures, how they do that choosing. For example, Party members have a player customization element that they can use for how they're going to pick targets. Whereas creatures use an aggro system to determine who they're targeting. But despite having minor differences in how they do these steps, everyone follows the same basic logic pattern.
Now, not every ability, not everything you want to do, can be accomplished by directly moving to your target and smacking them in the face, as we did in our previous example.
The pathfinding layer, as I mentioned, gave us move to point and follow leader.
So with that, as long as we know where we want to go, we've got that solved.
But a lot of our creatures and our party behaviors need more complex movement.
We wanted to be able to create more interesting patterns, both to give life to our creatures and fill out the big open spaces that we had in a way that meets player expectations, and also be able to create interesting gameplay challenges without requiring designers to hand-build specific location picking and movement behaviors every time.
So we wanted reusable abstractions.
We came up with a system we call Movement Behaviors.
So these are reusable, parameterized, you can see a big example from the editor over there on the screen.
Parameterized chunks of behavior that a creature can run one at a time and that gets, excuse me, that puts them in a position to be able to do interesting things in gameplay without having the designer to manually specify how they're going to compute their targets and the move positions every time.
So, an example of one of these is stay at range, you can see over there, and it's parameterized so that the designer can say, that's the guy or the thing that you want to focus on, and you're going to pick a position.
somewhere around that object or that character and hang out there even if that target moves. And it gives the designer the flexibility even to say, okay, I want you to be in a flanking position. So you're going to try to move around into the back arc of that character. Or I want you to, you know, sort of shuffle around and be a little more dynamic rather than picking a point and sticking in it.
Additionally, we have a movement behavior that lets characters find cover objects that have been marked up in the world so that, for example, some of our ranged creatures can respond to their environment a little more and feel like they're living in the scene without level designers having given them specific movement commands.
our prey flee behavior is implemented in the same way where even if we have a creature, one of those little nugs who's fleeing from three different predators, the creature just needs to run the flee behavior and it goes and it looks and finds the right path that's going to take him away from those predators regardless of where their positions are in the world.
And even hold position.
which you'd think would be pretty simple, it gets a reusable parameterized movement behavior so it can sit in that slot and we can do things with it like tell someone to stand in one place but track a target even though that target might be moving around the level. So with this system in place, we now have tools that allow creatures to move around in ways that are both interesting for game plays for game play. And also ‑‑ meet player expectations for wildlife. Predator prey behaviors, aggression, circling wolves, that kind of thing. The next problem we had to deal with is around the nature of these big open zones themselves. In our past games, combat tended to happen in fairly enclosed spaces. If there were hostile creatures where you were, there was going to be a fight, and that fight was going to end with a stack of bodies on one side or the other.
and open exploration zones change the rules. In DA2 in this example here, there's no walking away. That train coming over the hill, they're going to chase you forever until you run into the area boundary and then you're going to fight them and there's going to be a stack of bodies on one side or the other. However, when you're in a big area like one of our explore zones, The player often has the chance to try to walk away from a fight, either because creatures, you know, they're just defending their home. And they'll leave you alone if you walk away far enough. Or perhaps you don't even want to get involved in that fight. You need to be able to walk up and determine whether you want to even engage that battle or not.
In addition to those sort of gameplay facing concerns, we also had very pragmatic technical reasons for having to assert more control over where fights could happen. Because we had to stream these big giant areas. And there's a risk if the player can kite those hurlocks all the way from their origin point, then they're going to get streamed out because they belong to that part of the terrain where the player was. And now we've streamed them out. We've even streamed out the terrain underneath where they came in.
We could also get into bad situations where if you can manage to taunt enough creatures on to you and attract the attention of enough of these encounters, then you could run out of memory budget. And remember, we're dealing with Gen 3 memory budget here. So things were pretty tight.
before we had a solution for dealing with this.
And in addition to being bad for performance, as I say, this could lead to really frustrating gameplay situations and we needed level designers to have tools to be able to control and build the specific kind of experience that matches the themes and the story and the gameplay challenges that we're trying to create.
So.
Here's an example of a very simple encounter that we built in our level. And there's the tether volume that the designer has dropped in on top of it. So on the AI side, inside our tether system, we have three simple rules. And the first rule, as you can see, is that you can't leave. Any creature who's attached to a tether, their movement behaviors are aware of that tether zone.
and they won't pick points. They'll never pick a destination point that's outside that tether box. So the creature should never be voluntarily moving outside its tether zone. In addition, any target inside my tether box is better than any target outside the tether box. The aggro system is aware of tethers. So that a creature is able to choose targets that are less likely to drag them out of their target box. And if they know that the creature that they're looking at is outside their tether zone, then they can choose to do things like walk home rather than continuing to engage or chase a creature who's outside their area of operation. And the third rule is that if you ever end up outside, you can't do anything.
whether it's because the designer changed your active tether box in game play or if you got knocked out of your tether zone by a combat effect. If you ever end up outside, stop what you're doing and run home. Run back toward your spawn point or your tether point until you're back inside your box before you can do anything else.
And so with these rules in place and the editor tools to support them, level designers could build encounters with reliable expectations of how creatures were going to behave and how they were going to move around.
And related problem we had was where tether volumes solve the problem of where creatures are allowed to go in a really broad stroke sense.
We had hazards where creatures shouldn't go.
that despite being pathable, despite being things that you could run through, you really shouldn't be standing in those areas. You want to avoid those fires on the ground, barriers, traps, all kinds of stuff that in inquisition with our big organic environments, we had a lot more of this kind of ambient hazard.
In DA2 we didn't really have this kind of thing happen a lot.
If there was a fire on the ground it was usually there for one of two reasons. One is because it was a specific gameplay challenge that you as the player were expected to deal with.
So don't stand in the fire. Well, if your guys are in the fire, pull them out. And the other reason or the other possibility was that it was something that you had placed down that creatures should be standing in and taking damage rather than very smartly running out and negating your AOE attack. So...
The other twist with inquisition where we have more of these organic hazards is sometimes they can appear spontaneously.
Things can catch fire. The dragon can light areas of the ground on fire in combat and something that was safe five seconds ago, a good place to stand, can become somewhere that you really don't want to stand for an extended period of time.
So we needed a way to keep AI creatures out of these areas.
The first thing we did was add a pathfinding obstacle. So You can see that big yellow chunk superimposed on top of the bright green nav mesh.
And that kept creatures from ambiently wandering into the fire and going, ow, hot, ow, hot.
And that was OK.
It meant that creatures wouldn't discretionarily walk in, or they would avoid it on their way around the world.
But we needed something a little bit stronger because as I say, these things could appear under your feet and we needed a way to motivate the AI to actually move if they ended up inside one of these. And so we created this tool we call a fear zone. And the fear zone, unlike the tether zone, only has one rule. If you're in the fear zone, go somewhere else. So inside the prefab editor for our ground fire here, you can see we drop in a fear zone, which is just a spherical bubble.
that says to the AI, if you're ever inside here, run out.
And you can see in the debug draw there in the middle of gameplay, it shows up as a kind of a blue sphere.
Hopefully it's contrasting enough on the display that you can see.
Varek is standing in the middle of the fire there and the AI is giving him a cue telling him that he should move out of that fire rather than standing in it despite me having ordered him to go in there five seconds ago for the purpose of demonstration.
So with fear zones, designers have a tool now to motivate creatures under AI control to move away from some area of danger. And this actually works using the same movement behaviors as the prey flee behavior that I talked about earlier. So we have a consistent set of tools for saying, okay, anything that you're trying to get away from, here's a way to pick a point and move away from that direction.
And as it turned out, this fear zone tool was also very useful for our open world game play in that it gave us a tool to drop down around, you know, camps and settlements to keep ambient hostile wildlife from wandering through the middle of the village.
And this created a problem that I call standoff in bear town.
So this is going to require a little explanation, a little background. For those of you who have played inquisition, you know that bears are tough. And the reason that bears are tough is that bears are balanced for a four on one fight. Because the bears have to stand up against a party of four rather than rolling over like most of the other creatures that are designed to be encountered in groups.
And there's a corner of the hinterlands explore zone that is just packed with bears. I called it bear town during development. And there is luckily there's an inquisition camp. There's a rest and resupply area in that part of the map where you can go after fighting a bunch of bears and getting slapped around and, you know, revive your party members, resupply your potions, get healed up.
And the bears are kept out of the camp by the fear zone that we drop in around the camp. So you can see there's a big 30 meter bubble around the camp area in the level editor there that keeps the bears out. If they try to come inside, they hit the fear zone and they leave.
but the problem with this is that if they're actually trying to actively move into the fear zone because you're in there, then they ended up bouncing off the edge of the fear zone and oscillating and wobbling back and forth there. That's no good.
Meanwhile, the player, as long as that bear is there and hostile, he's not going to be able to move into the fear zone The player is not allowed to interact with any of those resupply items. They're not allowed to do anything interesting in camp. So they're stuck there. They're inside. The bear can't come in, but they can't leave. They can't fast travel. There's no way. So they're stuck. So The first thing we did was we changed the AI so that the AI is blinded to anyone who's in a fear zone that they're responsible for. So the bear now can no longer see you. The bear wasn't trying to bounce off the fear zone anymore. You just sit there. Staring at you. Waiting. So we changed the AI We ended up having to clarify the game rules so that the party was allowed to drop out of combat.
Even if there was a hostile bear there, as long as he wasn't actively targeting somebody in your party, that you would be allowed to use the camp facilities despite there being a bear sitting out there waiting for you to come back.
And by solving these problems, we were able to achieve a pretty good game play balance between having aggressive, threatening, dangerous wildlife and basic player survivability. We had to give them a way out. Now, let's talk about a problem specific to our player party path finding.
Relative to our previous games, we have a much more open and permissive movement model. You can jump over gaps. You can jump onto obstacles. You can scramble your way up onto things. And in some cases, you can find your way off of path finding. So you can see an example here, that bright green nav mesh.
sweeps around and everyone else in my party down in the right hand side of the screen is standing on the nav mesh, but I managed to jump my inquisitor in the left hand side up there on an island where there's no path finding data. Which is good because it means that the player isn't stuck.
trying to use physics movement to jump up on to obstacles and get to somewhere that it looks like they should be able to get the player's movement isn't constrained by the AI parameters. But this is a problem for us when we're trying to get everyone else in the party to follow you. Because the player can go places that the AI just has no way of going. And so this led to a couple key scenarios that we had to solve.
Here's another example. You can see I'm controlling the inquisitor there in the middle. And you can see I'm up on a rock in the middle of the screen where there's no path finding data. If I switch to another party member, like iron bull over there on the side, then I can grab control of him, I can drive away, and I can leave my inquisitor up there on the rock.
And well, they have no way of getting naturally back down off that rock because there's no pathing data. So what happens in our game is when you switch characters, whenever a character becomes AI controlled, they get teleported. And for the sake of player experience, usually this gets covered by the camera transition or in really severe cases, there's a fade through black to cover that teleport up.
and if you played the game and you never noticed this happening, success. But this gives us the reliability that we need to know so that even if I move and switch characters, no one in my party is left in a situation where they are off the nav mesh and stuck. So whenever a party member becomes AI controlled, teleport to the nearest point on the nav mesh and ideally the player never notices this happening.
The other situation that we can get into involves traversing terrain that the AI can't cover. So you can see in this example, I'm down there at the bottom of the screen. I've just jumped off the cliff. And I left my party members behind.
And what this means is that when I land at the bottom of the cliff, if you could see them right now, they're up there, they're behind the cliff wall, they're going to start taking the path that goes around and coming back down the switch backs to get back to where I've just gotten to.
I mean, you probably shouldn't jump off that cliff.
You probably take damage.
Hurts when you fall.
But.
still I'm now in a position where I can get a really big head start and if they get stuck on other path finding data or if the path is long enough, I can outrun them and I can potentially run far enough away that they're outside the streaming chunk and then the ground streams out underneath them and they're in for a world of pain. So...
If the player ever outruns the AI, we have a leash distance teleport that we implemented. Party members have a maximum distance that they're allowed to be. We teleport them in. And again, when that happens, we try to cover this by bringing them in behind the camera. Because if I'm running, I'm in front of the camera. Everyone else, if they're following me, is probably behind the camera anyway. And so this happens.
Again, if you never saw this happen in the game, success.
And in some situations, we disable or we expand the range of the tether. If it's a puzzle area that relies on separating your party members and positioning them in different parts of the level, typically we know you're going to come in and go out through a known access so we can gate and say, okay, it's safe here to turn off the tethering because we know that you're in this specific area. And in combat, to give more flexibility for positioning your characters and giving you more tactical options, we grow that range.
change. But at the end of the day, with these fail safes in place, as in elegant as they may be, if you notice them happening, we had confidence that party members couldn't get stranded by technical weaknesses in the path finding system. The other problem that I want to talk about here about party in the big open world is our party aggression rules.
Our party when we started had fairly opportunistic targeting.
They would see somebody who was fightable, based on the rules from our previous titles, if they're fightable, if they're in a hostile faction, I'm going to fight them. But, again, we wanted to give the player control over how they would engage in these kind of situations without your party necessarily picking a fight that you weren't interested or ready to take part in.
in a fairly target rich environment. There's wildlife everywhere. They're all fightable. You can go hunt nugs if you really, really need nugskin leather. But what you probably don't want is your party running off and hunting nugs on your behalf when you were trying to accomplish something.
So that's more obnoxious than punishing, bringing the bears down on your face. But the party shouldn't be spontaneously attacking things. We need to put that control back in the hands of the player. So we came up with some rules for party aggression.
which says that you're not allowed to engage. You're not allowed to take the first swing or use an offensive power until someone in the party has done damage. And you can see I can't do damage until somebody has done damage, which means the player has to be making that choice. Or if somebody in the party is taking damage, which means that the fight is already on me, I've been jumped, and the party is allowed then to engage spontaneously without waiting for a go order.
There's another test that takes place here to only target creatures that are targeting someone else in the party.
because again in inquisition, especially in hinterlands if you play this, when you go into that zone, you see groups of other creatures that are both hostile to you. There's mages, there's templars, there's bandits and they'll be fighting each other. There will be bandits fighting bears, et cetera. And they're having a little fight out in the distance.
And previously the AI would go, yeah, they're hostile. They're in combat.
going to go at them. And we need to make sure that even if you were allowed to engage, even if you were allowed to pick a fight then once that fight was over, your party members wouldn't take off and go bloodlust on that group over there if you weren't ready to engage them. And so with these rules in place, the player now has the control that they need over how their party members under AI control engage in these open world zones. Now, I want to talk about how we solved one of the biggest challenges with our party AI in Inquisition.
around ability selection by creating what we call the behavior decision system or BDS. So if you hear me talk about BDS, behavior decision system, same thing. And the challenge is that we have a lot of abilities on these creatures.
The party members can have up to 30 some different active abilities per class and they can have up to eight of them mapped and loaded on any given character at any given time.
The player is unlocking these as you play through the game.
We're adding and removing abilities from characters.
And when we started building our static decision trees for building out our party AI, we realized that we had a couple problems. First, we had a technical problem. So you can see here, this is an example of something we would have started with where I have a sequence and I'm going to choose and I'm going to say, OK, can I do long shot?
Yes, I can do long shot. Long shot is a good idea. Second choice, can I do stealth? If I didn't want to do long shot, can I use my stealth ability? And so on down the line. Which, again, we had a technical problem in that we couldn't add and remove abilities from this data structure in a really good way because things had to come in in an order and they had to be somehow slotted into the hierarchy.
So we tried this next. We said, okay, let's add all the abilities. So there's a master rogue ability table that says, you know, that has all of the abilities that this character could have ever. And then we're going to conditionalize them so that when they, if they're not loaded, then we're just not going to take those paths. But we still end up with a conceptual problem where Long shot might be a good idea.
It might be a good, you know, it's reasonable, the right range, whatever.
But we might be in a situation where throwing blades is actually a better choice to make at this point in time.
And so either we have to be very specific, we have to build the evaluations in this structure so that.
they're very specific and I'm only using long shot when it's absolutely the best thing I could do and it's not potentially worse than anything else that could happen down the line. Or we need a different approach. And we thought, well, what we'd really like to be able to do is say, okay, we're just going to evaluate all of our abilities. We're going to bring everything in. We're going to rank everything. We're going to find what the best option is. And then we're going to do that one.
But this required changing our architecture.
And thus the BDS was born.
So the behavior decision system splits our AI evaluation into two phases.
The first thing we do is evaluate all our options.
And then the second thing we do is execute whatever the best choice was.
And so this means that every ability itself specifies two sets of logic. One is the evaluation, which says why or when it's a good time to use this ability. And it also specifies a chunk of execution logic that says, okay, once I've chosen to do this, I need to move or not to get into range and then execute.
and we'll walk through an example here. So this is the evaluation tree taken directly out of the level editor or the rather the game editor for that long shot ability. And there's some preamble stuff off to the left-hand side that basically says is this a viable ability right now? Is it off cool down?
Is it disabled? Is there any reason why it's a bad idea to use this right now? Okay. We've dealt with that. So we're going to give ourselves 20 points. Right up.
in the first slot there. We're going to give ourselves 20 points because this is a pretty good ability to use right now.
Now, the next thing that we're going to check, because long shot in the game rules says that it's better the further away you are from your target when you're using it. So we're going to check and say if I'm at medium range for my target, I'm going to give myself five points. And if I'm even further away, then I can give myself another five points so that I give a full 30-point score for this ability. And we'll talk about what that means in just one second. And then I'm also going to be able to give myself an additional 10 points.
if my target or rather if this ability has been set for this character by the player to be something that they prefer this character to use. So.
Once that happens, we score that ability and we realize that we needed a set of rules as we were building out these evaluations so that we could be consistent in how these things are being applied. So you can see passive movement, things that just move me around the battlefield are the lowest priority. Basic attacks are always sort of, you know, they're always a pretty good idea. If I can use an ability, I should use that over a basic attack.
support abilities get a bonus score. They get a little bit of a priority bump. They start at a 25 baseline rather than 20 because typically they're things that either need to respond to a bad situation that's come up or something that I want to use ahead of combat at the start of things to repair. And so they get a little bit of a priority bump to make sure they come out first or they come out when they need to. And then we have reaction abilities that really need to be used on time and we'll cover those specifically. But those are things like blocks and dodges that have specific frame requirements around when they need to be used in order to be useful at all. So you can see this is kind of how things get ranked and rated and we build all our evaluation trees in this framework.
Then we break down inside those ranges 10 points, that 10 point range, 5 points for medium range, 5 points for long range, for long shot, but we have 10 points of dynamic range for context, is this a good time or a bad time to use this ability, and then we have that 10 point tie breaker where the player can put their thumb on the scale and say I want this one more often.
which means that we have a 20 point range for pretty much all of the categories of ability. And we've completed our evaluation now. We've gone off, we've run long shot, we've run a bunch of other things that we have on this character. Basic attack comes in at 10. Poison weapons, we ran our evaluator, it came back at 25. Caltrops came back at 22. And full draw.
is in our ability list, but it's on cool down right now, so it just evaluates out. It gets clipped by that preamble. Healing potion, we evaluated it and it just said, no, I don't need to use this right now. I'm at full health. It's okay. So we can have evaluations that just punch out early on without even returning a score. But when we look at the scores, we say, okay, long shot is the best choice right now.
So let's use that. So we move into execution. So the next part of the AI update, we start running the execution tree for long shot, which handles the movement and execution part of that AI decision loop. We've picked our target, we've picked our ability, and now we're moving and executing. So we're going to test to see if we have range.
And if we have line of sight to use the ability, and if we don't, we're going to move until we get those.
We're just going to move towards the character, assuming that at some point we're going to achieve line of sight, and we're going to get into the right range.
Once we get those, then we fall all the way through to the end there, and we're able to actually fire the ability itself, play the animation.
fire the projectile, do the impact, all the good stuff that comes with actually using this ability.
And then in the bottom right hand corner, we just make a note to set ourselves to hold position so that we don't keep moving toward that character once we've achieved line of sight and the appropriate range to use.
And it's important to note that while this is running, if I didn't have line of sight and range when I started, while the execution tree is updating and moving me toward the target, I'm still able to run that evaluation. I'm constantly reevaluating all my choices. So if something even better, if some better option comes up off of cool down or if I end up in a situation where I need to react quickly, as long as I haven't actually triggered the animation yet, I'm still in a position where I'm able to react to those changing circumstances and start evaluating a different execution tree for a different ability on the next update.
So, let's see, where are we at here?
And an added benefit of the way that we implemented BDS as a general system for scoring behaviors is that we can also add movement to the priority evaluation. We can use an evaluator to check whether the character is in combat and apply different movement parameters by using the behavior tree controls over movement.
and for example in exploration characters have a tighter follow so that they stay closer to you so they're there when you need them whereas in combat characters can hang back a little more and spread out so that your melee character can lead and your ranged characters and your casters can fall back behind.
The other way that this works that was a big advantage is that we were able to use this for things like tether and fear zone where those behaviors can come in and they can override in the priority system anything else that character is doing.
They can come in at priority 100 and just stomp anything else that that character is doing until their conditions are resolved. Until I get back inside my tether, I'm doing nothing else. Fear zones, as I say, work the same way. So recapping, behavior decision system.
I can add and remove abilities now at run time.
And I can do that without having to pay attention to the evaluation order, because we've come up with a scoring system.
that means that the right ability can be scored regardless of whether it's the first or the last thing that gets evaluated. And we've done it in a way that leverages the existing library of functionality. We get a big win because we've built this library of decision tree evaluators and task nodes and functionality to build really complex logic and we can still use that in the exec parts. And we can also, you know, we have a whole set of target picking.
stuff that happens just in every AI update. So this integrates directly into the decision tree architecture that we've built.
So we have a powerful tool for AI decision making. It allows party members to effectively choose between a whole array of very situational abilities and make pretty good choices.
I did say that I was going to call out reaction abilities specifically because they had an extra piece of logic that we needed to build for them.
We introduced this new class of abilities in Inquisition.
We didn't really have these in DA2 or in Origins.
And their active reactions to damage that's coming in that allows you to actively counter that before you take that damage. And so there are things like parries, which are a reaction that gives you an advantage from our point of view. So I'm going to get a hit back out of it. A block is a reaction that's going to counter that damage, but it's still going to leave me in place. And then the most extreme is a dodge where I'm going to react by actually getting out of the way of that hit.
before it lands, but it's the most costly in terms of it loses my battle position and now I'm going to have to reposition and collect myself. So we want to be able to use the right reaction for the right kind of incoming hit.
but we still don't necessarily know where that hit's coming from. So we had to add what we call attack telegraphs. So this is the actual combat collision that we're looking at here, that set of green spheres for our canary spearman for one of his spear thrust attacks.
That's the combat collision that happens on, say, frame 20 of the attack. And about 10, 15 frames before that happens, we drop down a really broad collision box in front of him that allows him to notify any other character who's standing in the area that's about to be hit.
that there's a hit coming and it's something that you could maybe you could block it but not necessarily parry it. And in addition to sending that information, it also includes the positional data about where he's standing so that the character who's reacting knows which way to point.
their reaction, so their block or their dodge, which way they need to be moving to get away from the incoming damage. And these reactions, as we saw on the priority slide, they come in at extra high priority. They override anything else that that character can be doing. And this was very successful.
it was too successful. Because we put this on, for example, our tank characters who have a nice active shield block, it completely nullifies most incoming attacks from that front arc and they were able to use it with frame perfect precision against big nasty enemies in the game.
and defeat them over a period of time because they had to get their parries and counterattacks in between guard. But the AI was able to defeat really tough enemies without taking any damage. Which sounds great.
We win. We win at AI. My robots are best. But the problem for the player is that this really incentivizes the player to let the robots do the fighting instead of participating in the combat and sandwich sales go up because people put their controllers down and walk away. So what we ended up having to do is we added a shared cool down so that every AI controlled party member.
When the AI is choosing to do these things, there's a two second wait that they have to do between using one of these high priority reaction abilities to level the playing field and to give human players a reason not to just let the AI do what they're doing.
This is an AI specific cool down. It doesn't affect the in game cool down system. It doesn't affect a player using these abilities. It just gives the AI a little bit of a disadvantage. They're still able to react quickly, but they can't get into that toe-to-toe perfect parry, frame perfect blocking situation. So the AI is able to use these reaction abilities without outclassing the player and creating negative play patterns.
We also need the player to be able to customize their party AI.
We've created a pretty good baseline experience, where the party, as soon as you give them an ability, They're able to use it fairly competently.
But we want to make sure that the player is supported by their AI characters in the way that they want, and that when they customize the AI, the decisions that they're making, the choices they're making, are going to be observable.
So we wanted to give them big, chunky levers that we could use so that they can see those results in the game and know that they're making a difference and getting them to play the way they want.
And so the first level of control.
as I mentioned, is just what abilities do you put on the character. You can choose which abilities you map and the AI is only going to use the ones that are mapped, which is a change from our previous titles. Those abilities are available both to the AI and to the player's direct control. So as you're switching between characters or going into TACCAM, you can use all of those abilities on the character. And then we give you an additional layer of granularity that the AI is able either disable.
so that ability is still available to a player who's controlling that character or available to take as an order in TACAM, but the AI is never going to pick this ability for themselves. So if it's something on a long cool down that you're saving for an emergency or something that consumes a depletable resource, you want the AI not to be spending that on its own discretion. Enable is the default choice where the AI is going to evaluate it in priority sequence as we just went through.
And you can also set it, as I mentioned before, you can set it to prefer.
And that just puts the thumb on the scale so that that ability, rather, is going to be executed more often, it's going to come out at higher priority in the evaluation.
And in some cases, it also widens the AI's rules for when that's an appropriate ability to choose.
So if an AOE ability perhaps says that I need three targets around that character in order for this to be a good choice, it might drop that to two enemy AI characters in that area of effect. So that ability is going to come out more often. It's going to be used because the player wants them to use that ability more often.
And the other interesting setting I want to talk about is the targeting behavior that the player is able to customize.
Again, choose target, choose ability, move, and execute.
Those are the four important steps in our AI evaluator.
And so the player is able to influence how the AI follows, or how it picks targets, rather, by choosing between either following a character.
because we want it to be supporting, typically when the AI is running, it's supporting a controlled character. So we can either say, track some character's interactions, either the controlled character, whoever the player is controlling, chase them around and beat on their target, or look into the aggro system and defend a specific character.
and counter threats, whoever is targeting that character, we're going to pick them off in priority. So with these settings, the player can set how the AI is picking their targets and picking their abilities in meaningful and visible ways. We also needed to support the TACAM orders that the player is giving when they're giving direct commands to their party followers. So...
either as I say direct commands, use that ability, move over here, or giving them behavioral orders that modify how the AI works underneath. So in the direct commands, move here, use ability, these have a fairly simple execution.
They just run that ability as though it had been chosen by the AI and the AI decision making is suspended. When the player gives an order, we're not constantly running the evaluator in the background. The AI is just going to be hard on target to follow that ability up until it completes successfully.
The other side is that we have these behavioral commands that modify how the AI works under the hood, like attack this enemy. If you give this order, as bull has in the example there, it overrides the entire target picking set of their AI and says that's your target, every frame, every update, get that guy until he dead.
hold position is more complicated because it has to affect both the target picking and the ability picking so that the AI doesn't get stuck trying to use things that would violate the rule that says they have to stand here. And it also adds a little miniature tether behavior so that if they get knocked off of that spot that you told them to hold in combat then they'll try to regain that position before doing anything else.
And we also have an order that allows you to basically implement the defend targeting that I talked about a moment ago on the fly so that you can adapt to situations on the battlefield. And it works in exactly the same way. These commands give the player control over party behavior without having to micromanage every action, including situally overriding the way that it picks targets in the big AI hierarchy.
Now...
Having implemented all of these things, we've put all this stuff together, we've built out our behavior decision system, we discovered something that was actually a big win for us.
Behavior decision system wasn't just good for Party, it was also great for our creature AI designers.
because we didn't have to manage an AI hookup table for each creature and we didn't have to necessarily come up with the right evaluation order and manage each creature's AI individually, we could iterate much quicker on how each individual AI ability.
prioritize itself and how it executed itself. And we could also focus on giving the creatures interesting abilities and moving them around between characters without having to maintain a master AI setup. We could pull an ability off one creature and either add it or remove it from the other character and swap them around much more quickly using BDS.
Because the AI hookups for that ability come with the ability itself.
And we were able to create creature variations.
We were able to use this a lot in DLC where we'd taken a creature archetype that we'd shipped in the game and we'd give them an extra ability as a little bit of a bonus.
It also meant that we were able to support really complex creatures like our dragons.
And dragons in our game are big.
They touch every part of the combat system, including parts of the combat system that aren't used by anything else. They fly.
They do all kinds of crazy stuff. And I'll show you the in-game debug from the behavior decision system. So you can see there's 58 different abilities. There's 58 different options that the dragon is evaluating.
at any given time. And some of them are grayed out because they're just not applicable. There are things that are state specific. There's special movement in there depending on whether they're in the ground or in the air. There's things they can only use when they're flying. And we were able to use BDS to manage this complexity and break it down into chunks that designers could work on without having to necessarily eat the entire dragon shaped burrito all at once.
So BDS gave us a consistent data driven way to prioritize behaviors across the game from simplest wildlife creatures to massive complex dragons while also supporting the complexity we have for our party members and giving them the ability to support the player in combat. And on that happy note, that's my talk. I want to thank everyone here for coming out.
listening to me go on about inquisition for almost an hour now. And I also want to thank Dave and Steve specifically for putting this whole AI track together and inviting me to come talk here. I want to thank the combat team back at BioWare in Edmonton who came up with so many of the things that I have the honor of presenting to you folks today. And, yeah, thank you.
Inquisition is a very big game. And there's more material in here than I could ever cover in an hour. We've got two minutes for a couple of questions and then I'll be happy to talk to people outside in the hall after the talk is over. Over here on the right-hand side, please, sir.
Have you considered using the player's direct input while they're controlling that character? Have you considered using the player's decision while they're controlling that character as waiting in the decision tree later on when it's being driven by AI?
We hadn't considered that specifically, but it sounds like a great idea.
Do you guys do any kind of load balancing of AI behavior selected decisions get calculated over frames or is everything always happening frame by frame?
That's a good question. Regarding whether we do load balancing. And yeah, the AI evaluations are sliced over frames. Each creature evaluates their AI I think once every three frames. So we split it up and some creatures get sliced down to five frame evaluation.
One more question here over here in the yellow shirt, please.
Okay. This is a question about the leash distance and teleporting the party members. So I was just wondering about the scenario where you outrun your party and you have your camera pointed back towards where you came from. Does it look like the party members outran you?
They come in behind your direction of travel, I think, in that case. So if you're pointing back in your camera and we can't solve for a good place behind the camera, then they will pop in behind your direction of travel. So it still looks, you know, silly, but it is the unfortunate reality of dealing with that and making sure that we have to account for their potentially getting lost behind.
Thank you.
