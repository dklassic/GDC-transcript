Welcome to the OpenXR panel. My name is Yuval, I'm CEO of Sensix.
Sensix makes special purpose HMDs, you know, arcades, military, medical and so on.
We also created the OSVR software platform, which was useful in OpenXR.
And we have a great panel for you here today to discuss OpenXR, a...
the path that we're taking on converging on a standard for AR and VR.
So let me introduce our all-star panel for you.
At center, from Colorado State University, at 6'5", we've got Joe, playing for Valve right now.
Kay Mason plays for Google.
Paul Padreana for Oculus.
And Nick, I think it's okay that I put you as power forward for Epic Games.
The reason we're excited about this panel is that first, all five of us are very active in the day-to-day formation of the standards, whether it's the weekly conference calls or the face-to-faces and so on.
Nick and Kay also have formal roles.
Nick is the chair of the OpenXR working group and Kay is the spec editor.
which does all the grunt work in merging the standards as it goes together.
I would like to start by just explaining what is the standard, what are we trying to achieve, what is the problem that we're trying to solve, and then open it up fairly quickly for questions from the audience.
Don't worry if you don't have questions, I have plenty of questions for my colleagues here.
I like to say that great works of art, I don't know if OpenXR will be a great work of art, but great works of art start from misery.
If you think about Mozart or Van Gogh or Tolstoy, they had difficult lives and then they sort of poured their misery into their work.
So OpenXR was born out of some misery.
The misery is that...
If you don't have a standard for VR and AR, then every time a game developer wants to support multiple platforms, they have to learn multiple APIs and then keep chasing these APIs as they evolve.
If there is no standard, then a hardware vendor, if you make eye tracking or or an HMD that's not mainstream or some other peripheral, then you basically have to sort of beg the engine companies or the content providers to support your hardware.
And the biggest misery of all is the end users, who are not really sure.
If they should commit to a particular piece of hardware, a particular solution, because they don't know how long it's going to last.
Now, standards seem to be sort of boring, but think what would have happened if there was no standard for gasoline on cars.
You know, if there were Ford gas stations and Chevy gas stations and BMW gas stations and you'd have to drive miles and miles just to find the right gas station for you, that would be a problem.
So the fundamental issue that we're trying to solve is to say, well, without a standard, we're wasting all this time that could be spent on creativity, on reaching new heights in VR, and just, you know, grunt work of making sure that my game works with his device, and so on and so on.
And the situation today is you've got most games work through engines, then they work through various run times, whether it's Steam or Oculus or SVR or Daydream and so on, and then some of these run times support multiple devices, some of these run times support just a few devices, and there's just this mess.
So what we're trying to do in the OpenXR working group, which is part of the Kronos organization, Kronos is the organization that brought you OpenGL and now Vulkan and others, is to standardize on two layers.
One is an application interface, which says, okay, this is how applications talk with VR runtimes.
And then a device interface, which basically says, this is how the runtimes talk with the devices.
And if this works out the way we intend it to work, then when you write a game or another VR or AR experience, you'll be able to run it across multiple devices very easily.
And then on the flip side, if you have a new piece of hardware, a peripheral, an HMD, or something like that, then you could...
basically connected to existing run times and run existing applications.
And we believe that this will also help drive user adoption because they're not going to fear of, well, if I buy this device, will the content really work on it?
next year.
So in terms of sort of an architecture, you know, marketing architecture, you basically have two open interfaces. One is the application interface and the other is the device interface. And in the middle there's a vendor-specific runtime. So, and we'll ask the panel a little bit later, you could envision an Oculus runtime that implements OpenXR or a Valve runtime or or Google Runtime and so on.
And basically, the devices would connect to the runtime through a well-defined interface and they would pass, you know, row poses, controller and peripheral state, the runtime would do whatever they want with it and then pass it on in a normalized way to the application.
The application would then figure out what to do with it, what's the action that the user is taking and what to draw, pass it back to the runtime.
And then eventually it would get to either the display or the supported devices.
So that's sort of the dream.
The it turns out that the pain that we the suffering that we spoke about was felt by a lot of companies.
And so here are some of the companies that have sort of publicly committed to the standard that have agreed to put their logo.
in support of the standard.
So you see, of course, all the panelists here, Oculus and Valve and Google and Epic and Sensex, and also, you know, Tobii and Sony and Intel and LG and so on and so on.
So plenty of companies are working on the standard, are supporting the standard.
And of course, we invite all of you individually and collectively to join us in making sure that the standard is a good one.
and that we do it quickly.
So, I think there's sort of...
I'd like to start off with some initial questions.
You know, what, when, you know, when will it be ready, what's in it, what's not in it.
But one challenge that we have with the standard is because the inner workings of the standard are not public yet, there are some things that we can say and some things that we cannot say.
So let me ask Nick, the workgroup chair, the first question.
He promised to be my shield during this conversation.
So what is it that I should not ask?
What is it that we're not going to be able to talk about today?
So basically we can talk about our individual companies or individual opinions on these matters but as far as declaring something is or is not in the standard above and beyond what was already shown on the slide, we can't legally talk about yet.
We're excited to share it all but there are some IP licensing implications and whatnot that require us to be transparent.
So, we're pretty cagey about the exact specifics of the standard.
But, I think we have a diverse enough panel up here that we can safely say what each of our companies cares about.
And, that I think will be a good indication of the kinds of problems that we're thinking about with the standard itself.
So, you're saying the standard doesn't have head tracking?
No head tracking at all. It's not an important thing.
No head tracking, no display interface, just a generic middleware.
Connect your ERP to something else.
It's just an API to implement for fun, basically.
Very good.
Thank you all.
OK, so for the record, Nick cannot confirm that head tracking is going to be in the standard.
But very good.
So the other thing that I wanted to ask, and maybe Joe, you can take this one.
When you look at the logos of the companies, two companies that don't show up there, at least in the logo slide, are Microsoft and Apple, which is why I'm using a Chromebook today.
Will they be or are they part of the standard?
And what do we think about their products and the standard?
So Microsoft and Apple are two examples of companies whose logos are on that slide.
There are other companies whose logos are on that slide, too.
And whether or not you're on the slide doesn't necessarily say anything one way or the other about whether or not you're involved because there are companies that are involved that haven't chosen to publicly announce their involvement.
as we're building the spec is under NDA.
They don't have to announce that they're involved and that's just fine.
They can contribute to the standard, contribute to the IP pool, and be part of this process without having it be a marketing thing.
What I will say is that everybody's welcome to join us.
So if any of you in this room want to come participate in the standardization process, you can individually join Khronos, your company can join Khronos, and you can...
I'm going to go ahead and do what we did all week, which is we had two full day meetings in Chicago on Monday and Tuesday.
So you can come and join us at those, join us on the once a week calls and start working on the spec.
So if you want to work on this, you're welcome to. And encouraged to.
So join OpenXR and see the world, right?
Because we were in Vancouver and in Seattle and in Chicago, and next time we're in Taipei and so on and so on.
You skipped Amsterdam.
Amsterdam was really nice.
Yeah, you're right.
So Kay, you're doing a phenomenal job in merging all the requests to the standard, but could you tell us when the standard will be ready?
So again, this is a thing that we can't exactly say when it will be ready.
We can say that we released our statement of work in January of last year, and we can say that previous standards have taken between 12 and 18 months from that point to be done.
So 12 to 18 months from January.
That's right.
Okay.
So let's assume a standard is ready, and it's ratified, and it's now made public.
So let's sort of go around the table, and maybe I'll start with Paul.
Will your company support OpenXR standard?
Will Oculus support the OpenXR standard or are you just in it to sort of figure out?
For the travel to Chicago.
For the travel.
I'm just in it for the Taipei trip next year.
Oculus intends to fully support the standard to the extent possible.
And any extensions that exist that are reasonable and rational will also support.
Oculus, as you know, has both a mobile and a PC division.
And we intend to support it to the extent possible on both sides of that.
Okay. And Nick, will Epic support the standard?
Yeah, absolutely. We were quite keen on it because one of the biggest things that people ask, as you kind of alluded to in the beginning, is people have either a new device or a new device that's looking for content. And the process of bootstrapping a plugin in the engine right now, between the engineering development and the QA time and kind of the maintenance of that, especially while APIs tend to be pretty flexible and malleable at this time and changing, it was kind of a giant pain in our ass. So that's why we really wanted to, uh, So, basically, I'm starting to write a OpenXR UE4 plugin as we speak and trying to keep up with the header.
Are we allowed to say ask, by the way?
What?
Oh, yeah.
That one's fine.
That one's fine.
Okay.
So, K, will Google support OpenXR standard?
I don't know.
I don't know.
I don't know.
I don't know.
I don't know.
I don't know.
I don't know.
I don't know.
I don't know.
I don't know.
I don't know.
I don't know.
I don't know.
I don't know.
So we haven't made a public statement about that, and I am a programmer.
But what I can say, and point to, is the fact that Google is extremely committed to open standards.
We have Chrome, we have Android, we have...
We've already open sourced some of our audio stuff for VR, too.
So we think a standard makes sense. It completely makes sense to have a VR standard.
And we'll be making decisions going forward.
And you're also the API lead for Daydream, so I think you're much more than a programmer.
That's true, that's true. But I don't think there are people above my pay grade who get to make those decisions.
So the other guy on the panel that his job title says programmer is Joe, so will Valve support OpenXR?
Well, in my case there are no people above my pay grade. We don't really have those things.
But I intend to write code that causes OpenXR to be supported in SteamVR.
So...
Okay.
So that's good.
And just for the record, Sensex will also support OpenXR.
But let's sort of go back the other way.
So let's assume that I'm a developer right now and I'm using OpenVR, you know, the Valve API for VR.
And now there's OpenXR.
So will I have to redo my applications?
Will the OpenVR calls be deprecated? Will they coexist?
How do you see that happening going forward?
Well, I imagine Paul has an answer of his own, but in my mind, we kind of see OpenXR as sort of the next generation of OpenVR.
We always kind of expected OpenVR to morph under an open standard in some way, and it turns out this is the way that that's happening.
So I don't know exactly when that will happen or exactly what the transition will look like.
Probably both will be supported for a period of time.
But eventually we think everything will be OpenXR based on our site.
Paul, do you want to answer that as well?
The answer for Oculus is practically identical.
Our long-term goal is to dump both our mobile and our PC APIs and use OpenXR exclusively.
There will, of course, be a transition period.
which will be some undetermined amount of time.
It has to do with backwards compatibility with applications that are in development or applications that still need the old API.
But while applications written to the older API will need to continue to run indefinitely, the publishing of an SDK for new applications to start development on will eventually switch to an OpenXR-only API.
That's a good point.
I'm not going to stop working.
That backward compatibility is important and it will be maintained indefinitely.
And Nick, will OpenXR be essentially just another target that you could publish to from Epic?
Yeah, we kind of go through great pains to abstract the platform differences as much as possible between the vendors right now.
So our hope is that we can start bootstrapping this OpenXR plugin and then people can just use that and then as Steam and Valve.
Or Valve and Oculus, sorry.
Steam and Valve.
Steam and Valve.
The Steam Valve.
Get up and running that transition should be abstracted behind all the frameworks and stuff in the engine anyway So we hope on the application side It's basically people just wake up one day and have access to a lot more platforms and in unity is also on the working group Right. I know they're they're not on a panel today The other Do you know what their plans are I I cannot speak for competing engine companies But I should hope that since they have contributed to the media very good of similar mindset And yes, I mean, OSVR API will also evolve to support OpenXR.
Kay, I wanted to ask you about mobile. It was brought up.
And by the way, feel free to answer the previous question as well.
Is it really possible to create a standard that works both on desktop and mobile?
After all, there are all these pretty substantial differences between what the device can do and what's important for the device.
How do you see that happening?
So just on the previous question, let me say that we also, as well as Daydream, our team supports EarthVR and we also have Tilt Brush and several other products that run on Steam and on Oculus Rift.
So if these guys are supporting OpenXR, I'm going to be writing support for OpenXR.
It's just so we can keep that going.
So in terms of that, I'm sure that's probably going to happen.
So in terms of mobile, yeah, there are definitely challenges on mobile.
Android has a very different permissions model than desktop does.
For example, I cannot, on Android, load a third-party DLL.
That's just not a thing.
I cannot go into system and load a third-party DLL, because that would be completely insecure.
And it would break Android's security model.
Also, there's some differences between our process and our implementation and Gear VR's implementation.
So we do all of our stuff cross-process on Daydream.
So our compositor runs in a completely different process.
And that means some things have to be different.
So we have to pass images across process boundaries.
And we have to pass all of this data.
And that can be challenging.
And it can be challenging on a mobile platform.
I mean, instead of dealing with how many watts of GPU, we have ones of watts of GPU power.
So that's challenging, too.
And it's really cool what we've made happen.
And the hardware companies that we work with are amazing.
And they do amazing things.
But there are different challenges.
Sometimes I feel like half of my job is trying to, half of graphics programming is really moving data from one place to another place.
So a lot of the challenges that we face are in terms of that.
And they're just different on mobile, fundamentally different than they are on PC.
And now I realize that because all of you are writing code, then the more panels we have the slower the standard is going to evolve.
That's true.
So maybe we cut it short, right?
Thanks for coming.
To the extent you can tell us, what happens in the workgroup in a situation like mobile, where there may be a set of different requirements or a subset of people who are particularly interested in a particular topic, whether it's mobile or eye tracking or ear tracking or something else?
Yes, so there's kind of a couple different paths depending on how much interest there is.
For mobile, I mean, that's a large portion of the market share right now, so we have representatives from Google, we have representatives from a couple of the other mobile guys, Samsung and Qualcomm, in there.
And really what we try to do is make sure that the core standard doesn't preclude either desktop or mobile concerns.
And there's been a lot of very vocal support for various issues on mobile to make sure that those are covered and we haven't precluded them from doing what they need to do to meet the memory model or performance characteristics.
When there are kind of more esoteric concerns that maybe aren't as broadly applicable, Khronos has what are called extensions and there's various degrees of extensions.
So if you're familiar with Vulkan, there's KHR extensions which we kind of consider to be ones that are potentially very broadly adopted but maybe not applicable to everybody.
There's ext extensions which we expect a couple people to implement but we still want to kind of standardize because we believe that there's some value in standardizing those and those eventually can be promoted up to KHR extensions if they become more widespread.
And then there's vendor specific extensions so if a particular GPU vendor or a particular phone vendor wants to do something that's very specific to their platform, they can do that and still work within the same ecosystem.
Between forming technical subgroups for mobile concerns or using extensions where applicable, we tried to make sure that everybody supported.
So with all the Google activity this week, I wasn't sure if Kay and Joe are going to be representing the same company pretty much.
I guess not.
But Paul, you guys have both a mobile product and a desktop product, and you have also a representative from the mobile side.
How do you see the sort of differences between mobile and desktop as it relates to OpenXR?
At Oculus, as I was saying before, we have a Gear VR group and we have our PC group.
And for the last few years, we've worked together to talk about our shared interests.
And so before even getting here, we had a lot of ideas about how...
an API needed to work to support both mobile and PC.
And a lot of that stuff has continued into the evolution of this, of the OpenXR API.
And our mobile guy, Cass Everett, he was there in Chicago last week.
Or actually, it was earlier this week, sitting right with us.
We think that it's entirely possible to support both at the same time.
We felt that a couple years ago.
I think that the way that the API is evolving.
is looking good to solve that.
We need to make sure that the mobile side has as much influence as the PC side.
Sometimes in our meetings, there's a little bit of a...
You know, some of the talk sometimes focuses on PC-centric stuff when mobile and stand-alone devices are a major part of the future of VR, especially in coming years.
I think we're getting there.
But, you know, Kay can speak a little bit for the mobile side with respect to that.
I can speak for our mobile side to some degree, but I would say this is looking like it's going to work out fairly well.
Okay. I'm going to ask one more question and then open it up for the audience.
I have two notes here from the conference organizers.
One is that they would prefer that people who have questions come up to the microphone so that your questions can be heard on their recording.
And the second request is that you make sure to give five stars to all the presenter and the moderator in the evaluation that you get.
Towards the end of this.
So if anyone has questions, feel free to start lining up next to a microphone.
But let me ask one last question for now.
So we spoke about Microsoft and Apple.
And it may be that they'll support the standards.
It may be that they're part of the effort.
We sort of can't tell.
But what if they're not?
Will OpenXR be able to run on a Microsoft HMD?
Who wants to take that?
So I will.
So let me take that, answer my own question.
I think that if we do our job well enough and it's an open standard and a well-defined device interface, then there will be someone, whether it's Microsoft or a hacker someplace, that very, very quickly writes an OpenXR device plug-in for a Microsoft device.
It may be sometimes that they may have to use some backdoor techniques or maybe they'll have to figure out some undocumented APIs, but I think these will pop up.
Super quick, I mean we've seen it in our experience with OSVR that there's a set of peripherals, a set of devices that we supported inherently, but then people all over the world started writing plugins for their favorite game engine or favorite device from 20 years ago or from two days ago.
And if you have an open enough standard in these devices, then that support just pops up.
That's really a market force, right?
You have a standard that's widely adopted enough in the market, and people who make devices are going to insist that people who are writing software support the standard.
People who write software are going to insist that people who build runtime support the standard.
And that pressure is difficult to resist once it reaches a certain level of.
critical mass. So our goal here is to get to that critical mass so that the question isn't really whether uh some this company or that company or this this product or that product supports a standard it's more that it would just be unheard of for them to not support the standard. Like like who's going to make a thumb drive that doesn't support USB? It doesn't make any sense. So I think we need to get to that point with with uh this standard and probably other standards um so that we're we're making it easy for users and software developers to understand exactly what's going to work with what.
And I think that's one of the reasons that the Khronos process tries to be so open, that everyone is welcome to create that critical mass so it will be almost impossible not to support it if you have a new device or a game engine and so on.
So turning it over to the audience, who's got the first question?
And if other people have questions, feel free to line up behind the first one.
I've got two. Hopefully the first one is easy. Is this a C API or a C++ API?
I don't know if we can say for sure, but it's a C API.
Laughter I know there are various official C++ wrappers but other open Khronos standards.
Is that something that you guys are likely to provide?
It's not a focus right now.
So the other one I guess is a little bit more general.
With a lot of these cross-platform type APIs, you can either have something that goes for lowest common denominator and everything else is extensions, or you can try and have something that covers everybody by including features that aren't available everywhere.
Like not all platforms have motion controllers, so are motion controllers a core thing, or are they an extension?
I'm just wondering if you can talk to how that balance is being dealt with.
Let me take that and then Nick maybe you can answer as well.
I mean, I think that what I've seen as the philosophy inside the working group is if a particular feature is supported by a large enough group of vendors, then we feel that there's enough experience around the table to say, okay, could we define a standard for that.
Other things that are less common, at least less common at the moment, tend to go more into either extensions or even vendor-specific extensions.
So...
If you have a unique piece of innovation that only your company provides, and you could still tie into the standard, then as it becomes more popular, it could work its way towards a Kronos extension or even a core feature.
Yeah, I think part of the governing philosophy there is, you know, we're kind of targeting devices that are either on the market or soon to be on the market and not precluding anything there, but trying to build our core feature set around devices that will be largely supported.
So motion controllers are pretty prolific right now, so I think it's safe to say that we will have support for them.
But one of the important considerations, I think, is how we make this a standard that won't be outdated.
And I think there's already kind of precedent for that.
I mean, OSVR has semantic paths, which are a pretty big part of it, and that's kind of an interesting way to future-proof yourself against changes in the hardware, trying to bootstrap new devices, while maintaining an API that provides enough functionality that you can actually make good use of them.
So I think there's ways to kind of satisfy both of those things.
But as a general rule of thumb, if it's out or coming out, it's probably, and the majority of devices support it, it's probably part of the core standard.
I think Nick just confirmed that retinal implants are not supported by the standard at this time.
It'll be an extension.
So I kind of think about it from the other direction, which is what does an application need to have available to it so that it can be delivered?
to the standard and not require vendor specific extensions to actually work on other platforms.
And that list is not as long as you might think.
And so that's the set of things that we're really focusing on getting in the standard, especially at 1.0.
Some things that you might expect to be in that set may end up as extensions right away, or maybe are not quite in the standard yet, depending on how commonly applications need them.
But really it's all about getting to the point where an application can be delivered against, where a single binary will run against the Oculus runtime or the SteamVR runtime or whatever, without needing to target a specific vendor's SDK, and then build from there.
And part of our discussion in the working group, at least this week, has been around MVP.
How do we get something that's useful enough to be in core, but then doesn't take us forever?
Because I think there seems to be a consensus that there's a need, a desire, to have this standard out.
Thank you. Yes, please.
Have you guys all engaged with the browser teams?
Or is this purely a native API?
So the question was with regards to the browser teams.
And for instance, we didn't mention WebVR as sort of an engine.
Kay, maybe you want to take that?
We have a pretty substantial WebVR team.
And we've announced what we're doing with WebVR.
And definitely we have our WebVR group participating in OpenXR.
We want to make sure that they have what they need.
Their needs are a little different because they're running in Chrome, and they have some requirements.
Like they want to be able to make queries without draining the batteries.
So these are kind of important to them, and we want to make sure that they're included.
And they've been involved since day one in the OpenXR standards.
And Mozilla's logo was on that logo sheet, and they certainly are participating in the process.
And existing runtimes, I mean, Valve, Oculus, OSVR, they run with WebVR today, so I think it's safe to assume that we would like an OpenXR runtime to run within the browser as well.
Thank you. Yes, please.
Hi, great discussion. Based on the vendor list and the panel, it seems like VR is kind of like a core and maybe the majority of what the standard would be about for now. Like when do you see mixed reality, augmented reality sort of joining more?
I can take that too because we just shipped our AR core a couple of weeks ago, so we are moving, I mean...
In that direction, it's extremely important to us.
We're going to make sure that the expertise that we have the Tango team at Google, who's been doing AR for years, we're going to make sure their expertise gets leveraged and that we're doing things that will, moving forward, that we'll be able to work with that.
And Nick, maybe you can also comment on the X in OpenXR.
Yeah, I mean it was intentionally made X to not preclude AR.
We would really like, there's a lot of overlap, right?
Tracking and display, a lot of the API itself is very transferable.
And we would love to, there is AR representation on the group right now.
We would love to get more AR representation.
I'm not going to call anybody out, but you guys know who you are.
We would love to make sure that...
I saw somebody with a t-shirt here yesterday.
At least one company that should probably be involved knows who they are.
There's several in this room, in fact.
Companies out here, especially San Francisco, which is kind of a hotbed for that sort of thing.
You know, we want to make sure that our tracking and our display and our layers and stuff like that are all able to handle both the case where you're kind of doing pass-through or you're doing AR or you're doing VR.
And I think we're pretty good there, but it always helps to have proof points and expertise, right, because the devil's in the details with a lot of this stuff.
Thanks.
Anyone else want to add to the MR discussion?
I mean, the one thing I would add is that VR devices are shipping today in quantity, and AR devices are still a little bit further out, at least for head-borne AR devices.
So from our point of view, it's important for us to focus and get the...
first version of the spec out, and that probably will be mostly about VR as a result, but beyond that, you know, what we're trying to do for AR versus VR and what devices are supported and what platforms are supported and whether or not you do things in the IPC style or the in-process style on mobile, what we're trying to do in all these cases is build the API in such a way that it's agnostic to that.
that the API can support either one and doesn't require that you go one particular way or another.
Because the whole point of having an open standard is that you have an interface where two different implementations from two different companies, probably at two different times, come together.
And on either side of that boundary, you just go hog wild and you do whatever you think is best.
And there's a lot of experimentation that happens on both sides of that boundary.
So we're trying to define the boundary to be as flexible as possible while still making it so that those things can interoperate.
Yes, please.
When the standard gets released, what do app developers need to do to certify that their application actually adheres to the standard?
And will you be giving them a stamp or a logo that they can attach to their app to say, hey, yes, I've actually met the standard?
Do you want to answer that, Nick, on performance testing?
It's kind of a, there's two different sides to that.
There's the hardware and runtime manufacturers and what they have to do generally.
We haven't announced what our specific plans for OpenXR are, but if you look at Vulkan, that's probably a pretty good precedent.
So on the hardware side, if you're writing kind of driver layer stuff, though usually a process for conformance testing where we have a...
A sample set of tests that it has to pass to prove that it faithfully reproduces the functionality in the API.
Applications themselves don't really have that same sort of barrier.
There's of course validation that you're using the API, right, but you're pretty much free to do with whatever you want with that.
But from the hardware and runtime side, being certified to be OpenXR compatible is basically gated by that passing of the performance test.
So, if every runtime supports OpenXR, how do you get differentiation between the vendors?
Why would the Oculus runtime be better than the Valve runtime?
Or will one be better than the other?
Because Paul is a way better programmer than me.
Obviously.
Ideally, the API allows some differentiation in the way that the runtime works.
While runtimes are essentially accomplishing the same thing, getting a VR display in front of the user, how they do it, I think, The API is a little bit different than the standard.
Hopefully the API and standard will allow some flexibility there.
If anything, just to allow somebody to go and do something, do some new great thing, and not be impeded by the API in doing it.
We have some technology at Oculus, ASW, if you've heard of that, and our goal is to make it so that the API effectively supports ASW, but also allows anybody else to implement their own ASW as well on top of that API.
Joe, do you want to talk to that as well?
I mean, there will be a lot of diversity in the implementations of runtimes, and support for things like ASW is one of them, support for different devices.
The user experience model, the way that, you know, room setup happens, like all sorts of different things can be points of competition.
And that, I think that list is going to grow.
And one of the benefits of having an extensible API as the foundation is that you can add those pieces on to the core API in a consistent way.
And if it turns out that we add support for retinal implants, let's say, to pick one that's definitely not in 1.0.
And we do it with a valve extension.
And Oculus had support for retinal implants, and they do an Oculus extension.
And they're not exactly the same, but they're kind of similar.
Then we can come together, and we can work on making an EXT or a KHR extension that supports retinal implants.
And then it's just part of the standard, and we both have an implementation of that, and it would work across the boundaries.
But as the technology's coming up.
We don't have to hash it out in a conference room in Chicago.
We can work within our companies, figure out what the right answer is from our point of view.
And then once we've got that out in the market in some way, then we can start to negotiate and figure out.
What the common set of functionality is between those things.
So surprisingly, when we do the word cloud of this panel, implants will be much bigger than I thought to begin with.
But one thing I wanted to ask about the standard is whether it also includes a standard for content acquisition, meaning the connection to the app store.
Or do you feel that that's going to remain sort of vendor specific?
Kate, do you want to address that?
I'm not sure.
It's kind of, our current API does not really contain any sort of interface for connecting to stores.
So I don't know.
that we would move in that direction, but maybe we would in the future.
I think currently it's kind of independent. I know Gear VR currently has a manifest flag, so when you create a Gear VR application, you have to add a manifest flag that connects to, I believe it connects to the Gear VR store or the Oculus store, but I don't think it's something that we do currently.
And I don't know, I obviously can't comment on Gear's plans if they're going to continue doing that.
I think it could happen. It's not in our current API, so we'll see.
The microphone is still available for questions, but in the meantime, I wanted to ask the panel, What to you is the most sort of contentious point in the discussions about the OpenXR standard?
And on the flip side, what was the most positive surprise that you had in these discussions?
Who wants to go first?
I can speak for the latter question pretty easily, and I would say the answer to that is that things are going fairly smoothly.
There's quite a bit of agreement on things.
A lot of these questions, like Joe brought up the eye implant situation and how in the future that's something that, you know, when that comes around we'll want to converge on that.
But in a sense, all the API development that's happening right now is a lot of that same discussions already.
The discussions around tracking, around...
How displays are identified and how input is happening.
A lot of it is us agreeing on things and realizing that there's a lot of commonality in our needs.
And as a result, I think the API is coming together pretty cleanly and pretty smoothly and fairly rapidly without a whole lot of... there's not a lot of bickering.
It doesn't happen like you hear about in other places sometimes.
I definitely concur on that. It's been a great experience. Everyone is, I mean, we have a lot of respect at Google for the other, for Oculus, we have respect for like Valve and the work that they do for sure. And it just seemed that...
But none for Epic?
No, no, no.
No respect for us.
They have respect for Unity.
Turn off for Epic.
Oh!
Oh!
Oh!
Oh!
Oh!
Oh!
Oh!
Oh!
Oh!
Oh!
Oh!
Oh!
Oh!
So it was really nice to see that coming back though.
But I think if I was going to say the most contentious point, I would probably raise what the audience member over there asked, which is about what should be in core and what should be in an extension, because I think that that is definitely like things that we think should be core and maybe Oculus doesn't think it should be an extension.
So I think there's always a lot of if something is important.
I mean you can see on the list of people who are involved in OpenXR, many companies have something that they work on that they feel is extremely important and it is important often for the future of...
And so, but making a decision as to whether we can functionally get that into core and make that out and like get 1.0 out in a reasonable time frame is always a hard decision and things have to get pushed into extensions that we don't want to push or that some people it's really important to them.
So I think that's a hard.
And I concur.
I mean, going into the first meeting, we didn't know what the atmosphere is going to be like, whether it's going to be sort of my way or the highway, or is it going to be, hey, we all have sort of the same, we all want the VR and AR market to grow.
To make that grow, we need the standards.
So let's sort of put our best ideas together and see if we can make something good happen.
On that subject, so if you have someone in the audience whose company is not.
Part of the OpenXR.
And they have an IP concern.
Are they giving up their IP if they contribute to the standard?
Maybe you can talk to that, Nick.
You don't necessarily have to give up your IP.
When you go into the group discussion, they have different rules on the IP.
If you attend a workgroup meeting, basically there are IP rules in place to make sure that company X can't put something into the standard that they have a patent on.
That would force everybody that adopted the standard to have to license that patent.
So there are provisions around there that say if you do put something, a contribution forth into the standard, everybody in the group, everybody waives their right to claim patentability on that.
So your contributions are, but it doesn't mean that you can't have secret sauce that you keep to yourself.
You can still make a runtime that does something if you had a patent on a completely hypothetical asynchronous space warp.
If for some reason that was a patent to technology, probably not.
But if you had a patent on retinal implants, you could still implement that in the run time and not have to give anything towards the common IP zone.
You just couldn't make something into the standard that you have a patent on, if that makes sense.
And how about the low-level graphics API?
I mean, so will this work with DirectX? Will this work with Metal?
I mean, will this run on a Mac? Will this support Vulkan?
So...
I can't, we can't answer any of the specific questions, but here's what I can say.
We support DX 10.11.12 Vulkan GL on PC.
We support Metal on OSX. We support GL and Vulkan on Linux.
And we expect all those things to be supported in our API going forward.
So if this becomes our API, then I would expect all those things to be supported.
I don't know if you have anything to say about...
mobile. One more thing I want to say is, you've always continued to ask questions because none of you are standing at the mic. Please go ask questions. We're happy to answer whatever you're wondering about.
Absolutely. Yeah. Go ahead.
Is there a group dedicated to documentation and examples or is this much more of a reference for the hardware vendors to build drivers?
Documentation.
What's that?
Examples.
I mean, you've met programmers before, right?
No.
One of the goals is Kay is doing a marvelous job editing the spec, and the spec is trying to be as verbose and self-documenting as possible.
So it has the header in there, but it also has little snippets of example.
code, the intended usage, what is the expected income and outcome, and the kind of API contract for that.
So there is that.
There is talk about whether or not we want to release a full sample implementation of it.
And of course, anybody that adopts it is free to make an open source implementation of the standard, if they'd like.
So that's kind of one of the ways we're looking to try to leverage that sort of stuff.
But we're not ready to announce anything specific.
But we certainly don't preclude anybody from releasing source to it.
So one of the things that's a little bit different between mobile and PCs is the thermal management, melting phones and so on.
Does the standard address some of the thermal concerns?
We can't exactly say what the standard addresses and not, but we currently have an API.
Actually, Android has an API, too, called the Sustained Performance Mode API, where you can switch and manage your thermal performance.
It's certainly important for the future of VR and the future of AR.
that we do that.
I mean, it's not just, I mean, if you heat up, so the consequence of heating up your phone, it's kind of an interesting, because the hotter your phone gets, the less, the less good it is at conducting, so the more power it needs.
So you're kind of, once you get hot, you're getting hotter at an exponential rate, because the more, the hotter you get, the more power you need, and so the hotter you get again, and then you're hotter again, and you need more power.
This is something that we need to manage and that all VR on mobile has to manage.
So any, us and everyone.
So I would expect something.
I mean, we already have stuff in Android that's not going away.
So, and I'd expect you there to be more in the future.
And I would say, sorry, go ahead.
I was switching the slide back just to make sure that Qualcomm is on the logo list.
So they are active in the group and you'd think that as a mobile processor company, that's one of the things they might care about.
I was going to say, as kind of a middleware engine provider, one of the biggest challenges that we see is people developing for mobile.
On one hand, it's one of the most accessible platforms, because a lot of people have cell phones that are compatible and it's kind of low cost to get into.
You don't have to have the whole PC.
But it's also one of the most challenging because of the thermal constraints.
And we see most people that fail at making mobile VR fail because they heat up the device or aren't able to optimize within the mobile perf and thermal.
requirements so that's one thing I would love to see I mean in the industry as a whole not necessarily even within the standards group more attention towards educating people on how to manage thermals what are the best practices what happens it because when you tell people about you know thermal runway runaway most people don't know that when you get hotter you start using more power and then you in turn kind of have this exponential curve and simple lessons like that once you tell people it makes sense but to me that's also partly a matter of education and not standardization And by the way, we're about 10, 15 minutes from the end of this session.
You should be receiving the email survey by now.
We're shooting for six stars.
But please.
So we support both Vive and Touch at the moment, and we found that the biggest headache in supporting both of them is less about API differences and more about how do we map equivalent actions between the quite different controller designs.
So I'm just wondering if the API tries to say, like, this is a grip button or this is a grab control versus this is button one, button two, and you just have to go through each platform and map those to, based on your own kind of design decisions.
Let me take that and maybe Joe you can add to that later.
I have no opinions on that subject at all.
So one of the things that we have in OSVR, in open source VR, is the notion of an abstraction layer where we basically allow you to define controllers and then map them into, say, a fire button or a trigger button or a teleport button.
And then abstract that from the game.
So a game could say, I want to use the teleport button.
And then at some lower level, the device manufacturer says, well, I think this particular yellow button is really going to work well for teleport or for a particular game.
And so we think this is one of the good features of OSVR.
And as far as SenseX is concerned, we're certainly pushing to have something like that in OpenXR.
And Joe, since you have no opinion, then go for it.
Here's my non-opinion.
So we think that this is a pretty important issue to solve.
And it's not even just limited to, I have a single application.
I want my single application to support Oculus Touch and the Vive controllers and upcoming Knuckles and the Windows MR controllers.
You want all those to work in the same application.
And the differences between them.
Are, you know, this button does this or the dead zone on the joystick needs to be this on this kind of controller.
And it's different when you have a trackpad.
And like those sorts of changes and the sorts of things you would have to do to adapt your game are important to address as a challenge, as an issue.
We also think that it's important to, from the Harper vendor side, to be able to add support for new controllers.
There are 2,000 VR-only games on Steam.
Games, some of them are games, some of them are not.
Applications, I mean.
And most of those are never going to ship another update.
And it would be a tragedy if they don't support Knuckles when it comes out.
So we think that it's important to build things in such a way that they're not just a game.
that future hardware can be supported, both because we think that it's not, we're not done innovating on hardware and figuring out what the right input mechanism is, but also because it makes a market for interesting new hardware devices that are application specific and because it enables accessibility for people who may not have the ability to use a standard controller.
And all these are things that we're very interested in solving as part of the standard.
And that's not to say anything at all about what the actual solution will be when it comes out in state two.
And the other side of this is community contributions, right?
Because you can say, well, the game developer thought that this is the right combination to do mapping between actions and buttons, but now the community figured out or some eSports champion figured out that if he does this other thing, and maybe he wants to publish his key mappings.
to VR.
So, we...
I gave a talk about getting TF2 up and running on the DK1 back in 2014 or something.
And what I said at that time is something I still believe, which is that we don't know what mouse look is yet for VR.
We don't know that it's WASD plus, you know, rotating the camera around.
for VR, for teleporting, for reloading mechanics, for moving around, for picking things up and manipulating objects. All of those basic verbs are still experimental right now.
As part of figuring that out, we have to try a lot of different things.
And that might mean that there's some disagreement, because there was disagreement when Mouselook was coming up as the way to do things.
So, having the community be able to communicate with each other and share configurations about, you know, this is how I think it should go, no, I think it should go this way.
Like, that's important.
It's a big area of interest for us with the Steam Controller system that we have to support a bunch of different games and a bunch of different controllers on Steam is sort of in that direction.
Trying to figure out how to make that remapping be a thing that can come from the community and not just from the game developer.
I just think on that note, it's not as simple as mapping button to button because for Vive we tend to find you don't want to hold down the grip buttons if you're using those to grab.
It's better to press and release, whereas with the touch it's very much designed that you hold the grip button the whole time you're holding the object.
You can't necessarily just do a button to button mapping for a lot of these things.
And it's not necessarily buttons.
I mean, even on a desktop interface, you can achieve, you can close a dialog box, or you can answer a yes, no question with a mouse click, or a keyboard shortcut, or a touch on the screen, or maybe tomorrow with a hand or a head gesture.
So I think there may be a need for a mechanism to say whatever the input mechanism is, we want to map it into some kind of action beyond the simplistic one-to-one mapping between a button and an action.
Thank you. Next question please.
Hi. This is a continuation a little bit on the last one.
How much into the user space application does this go? For example, with the SteamVR plugin for Unity determining between left and right controllers, you just kind of get the controllers and you do some sort of like positional determination.
Or with Leap Motion you have gestures. Are you looking to also go into that area as well?
Did I answer this Unity question?
First of all, I would recommend an engine change.
Laughter But in all honesty, what we want to do, that's kind of the perfect avenue for extensions, for things that come along that maybe aren't broadly adopted across all hardware, like gestures.
We would probably surface those via an extension, where applications still have a standardized ways to get that data, whether it's coming from a Leap Motion or Google Soli or any other thing that takes gesture.
Recognition is an input, and then surface that up.
There are kind of common interfaces for routing things to the applications, especially surrounding the input.
And we would probably make sure that there's a good mapping to there so that it fits into the ecosystem well.
And you can just check for the existence of that in your application.
And if it's provided, then you can do those in the same way.
From the engine level, me developing an application towards Unreal, it shouldn't change at all?
To you guys, the Unreal Engine guys implementing it?
Yeah, we would basically do the piping up through our input layer that we have in the engine, and make sure there's a strong mapping between that.
The hope is the end user, if you're using an engine middleware, be it Unreal or Unity, the abstractions that are already in place would just be wrapped.
They would hold.
One thing I can say about this is that the last couple of years we've already been working with Unity and Unreal, and...
The first one is that it's a game development transcript.
The second one is that it's a game development transcript.
The third one is that it's a game development transcript.
And of course, join the group and help us figure it out.
Next question, please.
I have a couple of things, actually.
As we all know, the VR user comfort and testing are pretty important components of the VR development.
So I'm just wondering what kind of considerations you have in those two areas.
What are you doing to make it easier for these VR applications to be tested across different platforms, because all of them run on different hardware and so on?
What kind of tools you're thinking?
And in terms of comfort, again, what kind of, how are you designing the API to make sure that there are tools to kind of measure and ensure some kind of a basic comfort?
So our philosophy about that with SteamVR and with working with HTC on the Vive was that we should build a platform.
where the platform itself is capable of being comfortable, that you can build an experience that does not get people sick, that doesn't cause any motion sickness.
And from there, it's up to the application developers.
There are people who are trying things that will get some people sick and won't get other people sick.
There's people trying things that they're actually deliberately setting out to induce motion sickness.
And that's fine, there's experimentation that's happening on top of the platform, but the platform itself is trying to be built in such a way that it supports comfortable experiences.
And I think that the, I guess I'm sort of applying that same philosophy when I'm participating in discussions about OpenXR.
The API basically is irrelevant for comfort because you can build a comfortable system and if the tracking system is good enough and the optics are good enough and the application is friendly to user comfort, then the user will be comfortable.
For testing I think it's a little easier with a single standard API because you can use the same binary against multiple run times.
So we've got time for one more question and then after that a quick question to Nick about is there...
A mechanism to preview at some point the standard before it gets published for people maybe to provide input if they're highly interested.
But we want to take the audience question first, please.
So related to that question, is the standard body defining any KPIs at each of the layers for both device as well as for the middleware and applications?
In terms of testability?
I think the goal is that you would be able to take a SteamVR or an Oculus Store application, replace the proprietary runtime with the OpenXR runtime, and then at the very least get the exact same experience on the native device, and then beyond that start getting very similar experience on devices that the game was not initially designed to use.
But maybe others have a different view on this.
Yeah, I mean it's kind of the same with other graphics APIs.
If you were a graphics card manufacturer and you wanted to support Vulkan, you could make a really bad implementation of Vulkan and it could be really slow and non-performant.
But the hope is because there's an open standard and ostensibly other companies will be implementing run times and drivers for this.
that people would naturally gravitate towards the best API or implementation of the API.
So we're really focused on making sure that we're not precluding anybody from making the most performant application in terms of latency and turnaround and, you know, where we block them and where we don't block them.
And make sure that that's very standardized and well-defined so that applications can theoretically write to a specific behavior pattern from a runtime and the runtimes can in turn expect the same from them.
And Nick, last question and maybe 20 seconds for the answer on auditing or being able to get a preview of the standard.
Yeah, so before we release the standard, aside from joining the Khronos organization, which if you join Khronos you have access to any of the working groups, OpenXR is just one of them, you can additionally, we're looking at starting a technical advisory panel where we invite people to take a look that might be either implementing run times that aren't part of Khronos or people that are implementing applications on top of the layer.
can preview portions of it in order to solicit feedback.
So that has to be voted on and ratified by the working group for each member.
So if you're interested in it, you can contact me through the Kronos OpenXR Working Group Chair email that's listed on the Kronos.org website under OpenXR, and let me know you're interested, and I can add you to the list.
And then when we go through and are ready to open up that tech advisory board, we can invite on a case-by-case basis.
So Nick, Paul, Kay, and Joe, thank you for joining me today and thank you all for...
