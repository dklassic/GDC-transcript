Hi, my name is Sanne Vrossen. I'm a senior engineer at Unity Technologies.
In my spare time, I work in two open source level editors that run in the Unity editor called RealtimeCSG and Chisel.
My talk is about an algorithm I'm implementing for Chisel.
Chisel, which is still in development, will be a successor to RealtimeCSG.
First, let's quickly go over what CSG really is.
First you need to understand the concept of Boolean operations.
You basically take some shapes, called brushes, perform a Boolean operation on them, and you end up with a new shape.
The most common operations are additive, subtractive, and intersection.
You can see here what these operations do.
So, to make a level, first you have a couple of brushes.
Then you use an operation on them.
and then you create a shape that is a combination of both shapes then you use that shape on another shape and if you do that with enough shapes you end up with a level and that's my talk, thank you for watching obviously there's more to it okay, a quick overview First I'll go over the history of constructive solid geometry and hopefully make the case why CSG is a valuable technique in the game industry. After that I'll describe the algorithm, how to do iterative updates, how to find intersections, how to generate meshes, how to categorize polygons to determine which polygons should be visible or not, and finally how to put it all together.
So first some history.
CSG is an old technique to build geometry with.
It originated from outside the game industry.
For instance, in the CAD industry, CSG is useful to determine the steps needed to cut shapes from metal.
In the game industry, Quake was the first game to use it for level design.
A lot of game engines, such as Valve's Source Engine, have been based on the Quake engine and inherited its use of CSG.
Other engines, like Unreal, were inspired by Quake and also used CSG for level design.
Most of the games made in these engines shipped with their level editors.
Modders quickly started making new levels, sometimes even modified these games into completely new experiences, which increased the popularity and greatly extended the lifetime of these games.
Several of these mods turned into retail games themselves.
Many of the people who started out as modders back then are now the same people who make the levels we all play today.
Some of them in their spare time still make levels for games like Quake, Half-Life, or Thief just for the fun of it.
CSG has been used in many classic games.
And even though CSG has been with us for a long time, it's still very much alive in the game industry.
All of these games and many, many more have used CSG somewhere in their development cycle.
Early CSG implementations all use binary space partition trees, or BSP for short.
The problem with BSP is that it's basically a monolithic bag of polygons, which are often split into multiple pieces.
Every time a polygon is added, it grows larger and larger, and more and more complicated.
The more polygons you add, the slower and slower it becomes.
Due to these scalability issues, it quickly becomes unusably slow, even after a relatively small number of shapes.
A second problem is that the tooling around CSG hasn't evolved much over time.
Unreal Engine 4, for example, still uses the original PSP code written by Tim Sweeney himself.
So some of you might be thinking, why would you build geometry this way in the first place?
in a word, workflow.
When you work with simple groups of primitives, as you add, enable, disable, and move around, you can very quickly adjust your level.
You don't like where this door is placed?
Just drag it together with its own hole in the wall, which would simply be a subtractor brush.
Those windows that you created here, do they interfere with your gameplay?
Just delete them.
And your windows, including the hole in the wall, are gone.
you can create and adjust things in milliseconds.
This makes prototyping and mocking a much more pleasant experience.
Now, you might've heard of this thing called Blocktober, which was started by Michael Barclay from Naughty Dog.
It's a yearly thing where in October, people in the game industry post images of the games they work on in an in-development state.
This is great because it shows how the sausage is made, so to speak.
Now, Naughty Dog doesn't actually use CSG, but some developers that do use CSG do post images at Blocktober.
For example, these are screenshots of a level made by Andrews Psycho, I hope I pronounced that name correctly, for the game Warframe.
It shows how the level was first blocked out in CSG.
The whole level is laid out in such a way that the game can be tested before any investment is made into making it look pretty.
It shows all the line of sights, all the places where you can take cover, everywhere the player and enemies can get to.
This is what the game looks like after pieces of the level are replaced with art.
These pieces are created in 3D modeling packages.
Another example.
These are screenshots from a level made by Alex Greiner for the game Apex Legends.
Here it shows how this level was first blocked out in CSG.
And here we can see the final result after replacing some brushes with meshes and adding props.
Here is another block interface example.
And the final result.
CZ forces you to consider the larger rough shape of a level before diving into the visual details.
With starting with rougher shapes, you can quickly start playtesting and refine your gameplay before you spend lots of resources on making it look good. At this stage, you should be more concerned with things like line of sight, where the player and other characters can actually walk, what the player and other characters can interact with, what the flow of your area is.
3D modeling tools on the other hand work on a much lower level, with primitives like triangles and quads.
It's a less forgiving environment.
And it's much easier to shoot yourself in the foot.
It's also much easier to get lost in detailing instead of focusing on the gameplay.
Finally, Constructor Solid Geometry is by its very nature solid, which is a nice property to have when you have to deal with physics.
You're not likely to have infinitely thin gaps between your triangles, which can mess up your collision detection.
It's not a coincidence that games that do not use CSG for their level design tend to usually not use complicated physics in gameplay.
CSG is also well suited for procedurally generated geometry.
All geometry created with CUT will always be solid by its very nature, and therefore even when a procedural algorithm fails, it will still end up with physically plausible shapes.
Your collision mesh will still be valid, you never end up with a polygon soup.
You can easily combine layers of geometry by adding and removing geometry, some of it hand created, other parts created procedurally, all seamlessly working together.
It's important to consider that level design is not the same as 3D modelling.
Level designers and 3D artists have different competencies.
The design of a level is not just what it looks like, and it really does help to have good tools for the task at hand.
After all, sure, you could mow your lawn with a scissor.
But is that really the best tool for the job?
Generic tools are often not ideal for most jobs.
Specialized tools are great for one particular job, but not necessarily good at other jobs.
CSG is obviously not going to be a solution for everything you'd ever want to do with geometry.
I would never suggest you build vegetation or characters with CSG for instance, but it's a really good tool for level design and architecture in general.
Sadly, CSG has perception problems.
Artists often equate CSG with BSP and old tooling.
The most common reason given to not use CSG is it's slow and blocky.
Yet it doesn't have to be this way.
It doesn't have to be blocky.
It can be used to drag and drop prefabs including holes.
Have tooling that allows you to create more complicated shapes like this.
This.
Or this.
Notice this image. It's a little scene with more than 7000 brushes in it and it's real-time.
Being able to draw on any shape and extrude allows you to quickly build your level.
And you can still edit brushes like in the olden days, but with real-time feedback.
Hopefully I've got your attention.
So, how do you implement a modern CSG algorithm?
Let's start by why this particular algorithm is interesting in the first place.
Now, suppose we perform CSG on a couple of brushes.
We combine those shapes together to create a mesh using a couple of Boolean operations.
Now, if we look at the contributions from each individual brush on the final shape, we can see that we only need to remove or flip the orientation of pieces of polygons that already exist in our brushes.
By determining which parts of our brushes need to be removed or flipped around, we can perform CSG per brush.
At the end of the final process, we put all those pieces together and we have our final mesh.
The biggest advantage that this gives us is that it makes it possible to have iterative updates.
That makes this possible.
So how do we perform iterative updates?
Take for example, when we want to move brushes around.
Here we only need to update the brush that was moved.
The brushes it touched before the move, and those it touches after the move.
All of the other brushes can be left untouched.
Since we can catch the results of our per brush CSG process, we can just reuse the previous results for those brushes.
It works the same if you modify the shape of a brush instead.
Another example.
If you delete a brush, you only need to update the brushes it touched before it was deleted.
And when you add a brush, you determine which brushes it touches and update those together with the new brush.
All of this essentially turns brushes into a unit of computation.
And we can easily split the work across multiple CPU cores.
The work per brush never gets too expensive and everything scales well with the number of brushes.
So, how do we find those polygon pieces?
Well, first we need to find the brushes that intersect with each other.
Then we find the intersection vertices between our brushes and use those to form intersection polygons on top of the surface of our brush.
Ensuring that our brushes are convex makes this simpler.
Just in case you're not familiar with or forgot what convex means.
On the left is a convex shape, on the right is a concave shape.
What makes the shape on the right concave is this inward bend into the shape.
In the convex shape, each polygon never has any vertices in front of it, they are always on the polygon or behind it.
Imagine slicing an infinitely sized cube multiple times and creating a shape this way.
Just like an animation on the slide, but obviously in 3D.
It could be a cube, a cone, or even a sphere, or a million other simple shapes.
This is essentially how Context Brush is defined.
You have a list of mathematical planes that bound the shape.
Now I'd like to just quickly mention it's not a requirement to use convex brushes.
It's possible to use non-convex brushes if you really wanted to.
But using convex shapes makes everything a lot simpler to implement and a lot faster.
You can still build any concave shape out of multiple convex shapes.
In case of our convex brushes, edges are where two planes intersect.
Vertices are where at least three planes intersect.
Take a cube for example. Each corner only has three sides touching it.
This is the most common case.
However, when you for instance have a cone as a shape, it could have any number of planes intersecting at the vertex that lies at its peak.
With these edges and vertices, we define polygons.
These polygons are sides of our brushes.
Each side polygon only has a single plane going through it.
Ok, with that out of the way, the first thing we want to do is find all brushes that touch our brush.
We can simply do this the moment we add a brush and store this, or update this information after a brush moves.
Keep in mind that when you determine if two brushes intersect, you can use this information for both brushes.
If A and B intersect or not, it will be the same as B and A not intersecting or not.
There's no point in duplicating our work here.
You could use an acceleration data structure like hierarchical hashed grids to find the most likely brushes that you might intersect with.
Then do a simple axis-aligned bounding box test and check if each of the vertices of one brush are outside of one of the planes of the other brush.
And there are probably better ways of doing this, but honestly this is not a bottleneck and I wouldn't try to be too smart about this part.
So now we find all unique pairs of brushes that intersect, and process each pair together at the same time, because there are lots of calculations we can share between the brushes.
For each pair we figure out which sides of which brush intersect with the other brush.
You can use an acceleration data structure like an octree or something else to quickly find the intersecting sides.
Since the shape of the brush is likely to be static, this data structure can be created at the creation time of the brush shape, which could also be shared between multiple brush instances.
Now what we want to do is find polygons on top of our side polygon that are formed at a boundary between the two brushes where they intersect.
Since we know these brushes are convex, we know that these intersections, if they exist, are always convex themselves. So these polygons would be convex as well.
These intersections are also always bound by the shape of the side polygon they're on.
They can touch the sides, but they can never cross the sides of the polygon.
Before we create the intersection polygons, we need to find the intersection vertices.
There are three types of vertices that form these intersection polygons.
Vertices that are inside both brushes, vertices of the other brush that lie on one of our surfaces, or intersections between the edges of the other brush with a side polygon.
By calculating the intersections once and reusing it for both brushes, we ensure they will be identical on both brushes.
This prevents gaps.
Vertices on one brush that lie exactly on the other brush will be copied over to the other brush.
At this point we just have a bunch of vertices.
Some vertices we already know are only on one of the two brushes, like the vertices that are inside the other brush.
By keeping track which planes intersect with which vertex, we can find all the vertices per plane.
And by extension, their side polygon.
Because as I mentioned before, each side polygon has exactly one plane going through it.
I also mentioned that edges always have two planes going through them.
By finding all the vertices on our plane that also both intersect with another plane, we find our edges.
Since we store our plane indices, this is a matter of finding these indices.
Since all polygons we form are convex, each vertex will always have two edges that use it.
Connecting the edges by finding their common vertices allows us to create the polygons.
We might end up with a polygon where all vertices are going in the wrong direction, in which case we just reverse the order of vertices.
We can determine if it's facing the wrong way by calculating the normal of the polygon and comparing it with the normal of the plane the polygon is on.
and see if they're pointing in the same direction or not.
With each polygon we store which brush intersection created it.
You also need to store a category with each polygon you just created, which will be used later on.
This category describes what the interior part of a polygon is, relative to the intersecting brush.
We call this the interior category.
If all our vertices lie on top of a surface from the other brush, then a category must be aligned or reverse aligned with it.
Otherwise, the category is always inside.
It can never be outside since this polygon represents an intersection with another brush, so we already know there has to be an intersection.
The next stage is to find all intersection polygons that overlap, and find intersection vertices between the polygons where they cross each other.
When you find an intersection vertex, you need to insert it into both polygons.
Finally, when an intersection polygon touches an edge of the side polygon, we need to ensure that the vertex splits that edge on the side polygon as well.
Keep in mind that the edges of a side polygon are shared between two side polygons.
So you need to make sure the exact vertex exists on both of them.
By making sure that all the calculated intersections are copied to all the other brushes, we ensure that these vertices are identical.
If you recalculated them, then the order of calculations are likely different, which gives us slightly different floating point values.
And you probably end up with tiny gaps between polygons of different brushes.
As an aside, you might also want to snap the original vertices of brushes that are known to intersect.
After this point, we have all the vertices we need.
We don't need to add new ones anymore.
Now in our next section, in order to explain categorization, I need to explain how we generate the final meshes.
So we'll start there.
So in order to generate our pair brush meshes, we process each brush side separately, processing the side polygon together with intersecting polygons that lie on it.
We use a triangulation algorithm that supports polygons with holes.
So it only creates triangles for the areas of a polygon that is not part of a hole.
When we use each intersection polygon, we then add it as both a hole in the side polygon, but also as a new polygon itself.
When a new intersection polygon intersects a previously added polygon, we need to do a little bit more work.
If they intersect, we find the common area, which will always be convex if both intersecting polygons are convex.
Which they always would be if they were created by convex brushes.
And then, we add that common area polygon as a whole again, to both the overlapping polygons.
Finally, we also add this common area polygon as yet another polygon by itself.
So in the end, we end up with lots of convex polygons with convex holes in them.
We can then merge the holes at the end by combining all edges and removing all the overlapping edges.
And when we combine the triangles from all the triangulated polygons, we end up with our final brush geometry.
Keep in mind that all polygons are triangulated using vertex indices.
All the vertices we need already exist in our mesh, so we can compare vertices directly using their indices.
All the vertices of all the triangles will match each other perfectly.
How do we figure out what to do with each polygon piece, if it should be removed or not or flipped?
This is the heart of the algorithm and the most complicated part.
To be able to determine what polygon will be visible, we need to categorize each polygon piece.
Now imagine the final solid shape we want to create.
If our polygon is inside it, it will be invisible and would need to be removed.
If it's outside of it, it's not part of the final shape and also needs to be removed.
If it's aligned with it, we want to keep it.
But if it's reverse aligned...
aligned but facing in the opposite direction, we need to flip it.
These are the four categories we need to determine.
But before we get to polygons, let's start smaller.
How would you categorize a single vertex against a single brush?
We simply compare the vertex against all the planes of our brush.
If it's outside any of these planes, it's outside.
Otherwise, it's inside or aligned.
It can be aligned if it's near one of the planes of our brush.
When I say near, I mean within a certain tolerance.
You can't use exact values here due to floating point precision.
To categorize a single polygon against a brush, it's a matter of categorizing all the vertices like before.
If all vertices are the same category, that's a category.
If some vertices are aligned, but the rest is inside or outside, then the whole polygon is inside or outside.
If some vertices are inside and others are outside, then the polygon will be intersected by a brush.
But since we already found all the intersecting pieces at the beginning, we know this won't happen at this point.
Finally, if a polygon is aligned, then we can compare the normal of the polygon with the normal of the plane we're aligned with.
If they both point in the same direction, the polygon is aligned.
Otherwise, it's reverse aligned.
Now remember this image again.
What we want to know is what each polygon piece is to the mesh we're generating.
What we're essentially trying to figure out is which polygons are part of the skin of the mesh we're building.
But before we get to how to categorize against a combination of all the brushes in your level, let's explain how to categorize a polygon against two brushes and a Boolean operation.
Now, when we categorize against a brush, we get a category.
If we do this for both brushes, we can look up what the output category for the polygon would be for a particular Boolean operation on both brushes using a table like this.
Keep in mind that this polygon isn't necessarily part of either of the two brushes we categorize against here, but we'll get to that later.
Now, when you look at this table.
If the category for either brushes is inside, then our polygon is inside the combined shape of both brushes.
So in this case, the final category is obviously inside.
If the polygon is aligned with both brushes, it's aligned.
If they're both reverse aligned, then our output category is, unsurprisingly, reverse aligned.
In this case, both polygons are actually still aligned with each other, just with both the polygons flipped around.
If it's aligned with one brush, but reverse aligned with the other, that means that they're facing each other, and we're pretending they cancel each other out, and we just consider that to be inside.
You wouldn't be able to see these polygons from the outside of our final mesh, they'd always be inside its interior.
When either of both brushes give us the category outside, we just take the category from the other brush.
If both categories for both brushes are outside, then the output category is always outside, since the polygon is outside the combined shape.
So that's our additive Boolean operation table.
We'll use this again later.
But for reference, I've added the other operation tables to the slides.
Here's subtractive, and here's intersecting.
You can look at these slides again later.
Now remember this slide from the beginning of the presentation.
This is essentially a CSG tree with each operation being a branch and the brushes being the leaves.
Together they define the final mesh we're generating.
Now here's an example CSG tree. We have a couple of brushes in blue, A, B, C, D and E. We have a couple of additive and subtractive operations in gray.
I'm showing this as a binary tree, where every operation has exactly two children, but in practice it's better to use a tree with an unbounded number of children.
It's relatively straightforward to work with brushes chained together in a strained line.
The moment you have deeper branches, things get more complicated.
But I'll elaborate on that later.
Regardless of the tree structure, we process each brush in isolation, and our brush will not touch every other brush.
So we want to build a CSG tree per brush, which would be a subset of the entire CSG tree.
To illustrate, let's assume that we're categorizing brush A and it's only touching brush E.
So we flag those two nodes.
And we go upwards from each flagged node, flagging each parent as we go until we end up at the root of a CSG tree.
All the categories for these unflagged brushes can be considered outside.
We don't ever need to iterate to the child nodes of the nodes that are not flagged, so we can just pretend they don't exist.
When we perform CHG with a node that is not intersecting with our brush, we can just safely assume that our polygon has the outside category for the sleeve or branch.
We can use our little operation table on two brushes, and this could be considered a simple CHG tree with two brushes and a single operation.
But this would be very limiting.
However, if multiple brushes are chained together in a single row, we can simply apply each operation table on each pair of brushes, hooking up the output category of the previous operation as the left category, and categorizing our polygon against the next brush.
We could just apply our Boolean lookup tables multiple times.
But instead, we're going to create a big table, which we call our routing table.
Here we basically insert all the operations we perform on each brush.
It can be considered an operation table for multiple brushes.
The routing table allows us to bake in our routing operations and perform optimizations on the entire table.
It also allows us to handle more complicated CSG trees, as you will see later on.
In practice however, you want to use numbers instead of symbolical names.
So here I converted all the categories into the numbers 0 to 3.
If you notice, at each row, its output becomes an index into the row for the next brush.
This turns the routing table into a simple indexable lookup table.
We'll be modifying the intermediate numbers a bit later on, and the intermediate values will no longer be convertible back to our categories.
As long as we don't modify the outputs of the last brush, we'll end up with values that we can safely convert back to a category.
When we categorize our polygons, we store our current category on each polygon we're processing.
We iterate all our intersecting brushes one by one, and we look up each row using the index in the polygon index column.
At the same time, we determine what category a polygon has for a particular brush.
We use this category to find the column.
I'll go into more details about this part later on.
The value where the row and the column intersect is our output category.
We then store this category on our polygon and proceed to the next brush.
To illustrate, let's assume we have a couple of categories for each brush, which we got when we categorized our polygons against their brushes.
In the top right corner, you can see the example categories.
At the beginning, our polygon index is always 0, so we start at brush A, and the first brush always has a single row, which is our row in green.
In this example, brush A has a category first aligned, which you can see here in red.
We find the final category 0, which, as you can see in the conversion table on the left, is the category inside.
This means that the polygon is inside the CG tree that our little table represents.
So, as I mentioned before, we're not going to use every brush in the entire CSG tree, and each brush only intersects with a subset of the CSG tree.
We need to create a routing table for each individual brush.
For example, say we're making a routing table for brush B, and it only intersects with brush A and brush C, only those brushes would be represented in the table.
And again, to reiterate, when we categorize the polygons of a brush, we'll be working on the polygons that belong to that brush.
We're determining which pieces to keep and which pieces to throw away.
So imagine that we've already cut up our brush into these pieces, and we process each piece individually using a routing table to discover what we need to do with it.
So we'll be using the routing table of a particular brush on the polygons of that particular brush.
In this example, the ruling table belongs to brush B, and when we categorize the polygons of brush B, they'll always be aligned.
This is simply because the polygons of a particular brush will always be aligned with itself.
And because of that, we already know that for every output of brush A, we already know the output of brush B.
So notice the pattern from top to bottom, 0, 1, 0, 1.
We might as well rewrite the outputs of brush A to have the outputs of brush B.
So as you notice, the 0-1, 0-1 pattern is now there as an output for brush A, and brush B has been removed.
Now notice that not all the inputs of brush C are referenced by brush A.
This means we can remove all the rows that will never be used.
Just so you know, sometimes when modifying tables, you'll end up with indices that don't start with 0.
Now we'll like all numbers to start at 0 for every brush and for every row to be sequential, otherwise we'd end up with holes in our table.
So we go back and change 1 and 3 to 0 and 1.
Now there is a problem here that has to do with deep branching. Let me illustrate.
We need to go through each of our brushes in order, building a routing table entry for each in turn.
Branches are not directly part of our routing table.
Now, say we started brush A and we get our current category.
Let's pick inside, for example.
Remember, we start its value on our polygon.
The next brush in our CSG tree is brush B.
So we find a new category here.
Let's use outside.
But we just skipped an operation and we have nothing to compare against since this is a leaf brush.
So what are we going to do with our previous category?
Maybe we could just overwrite it and continue.
So we continue, and we continue.
But now we reach the point where we kind of needed that category that we used to have at brush A.
So what now?
The solution is that the moment we determine that the next brush doesn't share the same parent, we start multiple paths to brush B.
Every possible path from brush B back to the parent operation of brush A will then have to brush A category built into it.
And when I say multiple paths, I mean four times.
Once for each possible category.
For each branching, we multiply our paths.
I can hear you thinking, are you crazy?
If we're going to duplicate these paths, then each time we have a branch like this, we could triple all paths inside that branch.
The routing table would explode in size.
It's not as bad as it may first seem.
I'll explain.
We don't have a lot of screen space and to keep things practical, I'll just put up a subsection of our entire CFG tree on the right.
Now let's take a look at the left branch of our top additive operation.
We create a small routing table for it, which has just one entry.
And imagine we build another routing table for a right branch.
If we combine them, we notice that not all output values of brush A lead to a row in brush B.
As I mentioned before, in order to do operations between brush A and the right branch, we need to encode multiple paths in our table from brush A to the right branch.
We need to duplicate all the output rows of brush A and the rows of the right branch.
Four times to be exact, once for each possible category that brush A could possibly have.
So we duplicate the values, and give each row a unique index.
And we add an offset for each output to ensure each output is unique.
So, in this case, we increase each output on each subsequent row by 4.
And we do the same for each possible path in brush C.
If the table contained more brushes, we'd add offsets to the next duplicated brushes here.
But considering the brush B is the last brush, we keep the values the same.
This ensures that the last values out of the routing table will always be between zero and three, can be converted back to our categories.
Notice now how for each output of brush A, we go to a different path to brush B, each representing a different category for brush A.
And then for each output path of brush B, we continue taking a path to brush C that has the brush A category built in.
Here you can see it for inside, aligned, reverse aligned, and outside.
Now consider the output values of our table.
Currently, all the output values are for this node, representing the output of the second routing table we combined into this table.
But we want them to be the output values for this node.
Now remember our additive lookup table?
We're going to use it again.
What we need to do is take all our built-in brush A categories on the left, and use that to find a column in our table.
Then take the output values from brush C and use those to find the row in our operation table.
And to make the output values of our routing table match the input of our additive operation table, let's turn those categories into numbers as well, so we can more easily use them.
Now, when we plug in the built-in categories from brush A and the original routing table output values, the operations would give us the values we need for the top node in our example.
But to make our routing table actually usable, we actually need to replace our values in the routing table with the output of the operation table.
We'll take a look at the route of brush C that would have been taken if we had the inside category for brush A.
Now, if you notice, every value in this column has the output of 0.
So we take those outputs and write them back to our routing table.
Now we look at the category for brush A, aligned.
As we take a look at the column, you notice that 0 and 1 stay the same, but 2 and 3 turn into 0 and 1.
So in our routing table, we change the 2's into 0's and the 3's into 1's.
Next, it's reverse aligned.
Here we can see that 0 and 2 remain the same, 1 and 3 become 0 and 2.
We write those changes back into our routing table.
Finally, when we get to the outside column, we can see that all the values remain the same.
So nothing actually changes for this part of the routing table.
So now the output values of our routing table contain the output values for the parent operation of brush A, like we wanted.
But we ended up with quite a big table for just a couple of brushes.
And we can do better.
Now, when you look at the output rows, there's actually a lot of repetition.
For example, look at all the rows where all the output values are 0.
So these outputs of brush B lead to the identical rows in the routing table section of brush C.
We can combine all the identical rows and go back and change the outputs in brush B to lead to just one version of this row.
So we find all the rows that are 0, throw away all but one.
Now go back to brush B to change all the duplicate outputs to the row we kept, in this case the row with index 0.
Next we can see that these rows are also duplicated.
We do the same thing for brush B again.
Then we find these duplicate rows, fix them up.
Finally we compact the row indices and fix those up in brush B as well.
And as you can see, after optimizing the routing table, everything is a lot smaller.
You can do these optimizations while creating the table, by just finding duplicates at insertion time.
Sometimes it's possible for brushes to completely disappear due to these optimizations.
Incidentally, this routing table can be cached per brush.
This took me a long time to figure out, but in the end, you get a nice simple table, very fast, very efficient.
And don't worry, you can always go back to the slides and go through them again.
There's one last thing I need to mention, that I left out to keep things hopefully a bit easier to understand.
If you have multiple brushes that are lined on a particular area, you'd end up with every one of those brushes keeping those polygons on that area.
In this slide you can see a brush with multiple surfaces overlapping, visible by the Z-finding artifacts.
This is because every brush will determine that its polygon area is part of the CSG tree, which is technically correct.
But we don't want every brush to keep the overlapping area, we only want one of these surfaces to remain.
What we want is that every brush in the tree overrides the previous brush and removes any overlapping polygons earlier in the tree.
We can easily fix this by creating a variation of all Boolean operation tables where we set all the categories in the middle section, which used to be aligned or reverse aligned, to outside.
We use this table instead of the original operation table after we pass the brush a routing table belongs to, when iterating over the brushes while creating the routing table.
This changes the behavior of the operation tables to remove overlapping polygons instead of keeping them.
This works because all polygons that have the outside category will be removed in the end.
Keep in mind you should only use this on brushes.
When combining two routing tables you should use the original tables.
Here you can see the subtractive operation table variant, and here is the intersection operation table variant.
You can look them up again in the slides after the presentation.
So finally, let's put everything together.
For each brush for processing, we use its own personal routing table and loop through all its brushes.
We do this for each side polygon of the brush for processing.
Remember those intersection polygons and how they're all associated with a single brush?
When we loop through all the brushes in the CSG tree, we use the intersection polygon associated with each brush and apply them one by one.
While we do this, we need to categorize our polygons to determine which ones need to be kept and which ones need to be discarded at the end.
Now remember that each intersection polygon has an interior category stored with it.
which we determine during the creation of the intersection polygon.
For example, let's say this intersection polygon of brush A has an interior category of reverse aligned.
For example, let's say this intersection polygon of brush A has an interior category of reverse aligned.
This means that the surface of this polygon piece is reverse aligned relative to the surface on brush A.
So when we look...
In our routing table at brush A, we only have one row and it intersects the reverse aligned column.
We then look up that the index of our polygon should be 0.
We then add this intersection polygon as both a hole to our side polygon and as a new polygon.
Everything outside the intersection polygon needs to be categorized as well.
So we look at the outside column in our table and we find the value 1.
In this case the side polygon is completely outside the intersection polygon, so we set it to 1.
When we add a new intersection polygon, we find it intersects with the previous intersection polygon.
So we find a common area between the existing polygon and the new intersection polygon from brush B.
We add that as a whole to both polygons and as a new polygon.
We also add the intersection polygon itself.
At this point in time, we give these two new polygons the same category as the original polygons they're on.
So the new common area polygon we give the value 0, and the new intersection polygon gets the value 1.
Let's say that the interior category is inside.
If we look at the area that's not overlapping, it has the value 1.
This gives us this row in the routing table.
We look up the new value in the routing table at the intersection between row and column.
Now do the same for the overlapping area which has the index 0.
We look up 3, set it.
The rest is outside our intersection polygon, so this includes the rest of the first polygon we created and our side polygon.
So we look up the value for our side polygon, which is 1.
And we look up the value for the other polygon piece, which is 0.
Now if we assume the interior category for brush C is aligned, we end up with these final values.
Converting 0 to 3 to inside aligned, reverse aligned and outside gives us this result.
Now remember that when a category is inside or outside, our polygons are discarded.
We only need to keep the polygons that are aligned or reverse aligned.
We flip those that are reverse aligned.
Keep in mind, even though holes are polygons, they are never categorized.
So don't throw those away.
The white polygons are inside or outside and will be removed.
This is what the surface looks like without those polygons.
We can also combine all the polygons that have the same category.
This can remove some unnecessary vertices.
So we combine them, and this is what it looks like.
Keep in mind, we only triangulate the polygons that we want to keep.
We should only triangulate after we merge polygons.
Also, reverse aligned polygons need to be flipped around.
All of this work leads us to this, giving us the ability to build geometry using Boolean operations in a scalable way.
The most important part is that we can now perform iterative updates.
Everything we can do per brush, we can cache per brush.
Since most of the work is done per brush or per brush pair, we can also easily split work across multiple cores.
And that's my talk. Thank you.
