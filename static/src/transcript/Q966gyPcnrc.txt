Good afternoon, and welcome to Realistic Performances and Games.
Fair warning, I have been told this talk is a bit chewy, so strap in.
There is a perception out there that the average game is mindless entertainment, with at best a thin story, cardboard cutout characters, and stilted acting.
But many companies have been working tirelessly against that stigma.
At Naughty Dog, where I've been for over seven years, we work hard to ensure our performances are believable, emotionally relevant to the player, and blend with our gameplay as seamlessly as possible.
I'm Ryan James, and I work at Naughty Dog in a somewhat unique position, as lead editor.
Aside from writing and directing some of our content, it's my job to keep the rest of the team, or to help the rest of the team create and maintain performances that feel like what you'd expect from an edited movie, even when they're fully interactive.
But what makes a realistic performance?
In Naughty Dog, it means a character needs to feel vulnerable, nuanced, and human, which means we're often focused on how natural every movement feels.
meaning how the character moves and how they speak needs to feel emotionally and physically relatable.
And of course, they also have to look realistic, which takes labor from everyone to get right.
Which is our entire goal.
Naughty Dog's games strive to intertwine story and gameplay so the player experiences a seamless performance, which we call the active cinematic experience.
We like to provide the player with emotional investment and motivation behind the moment-to-moment gameplay.
This is largely done through non-interactive cut scenes, but because we strive to keep the player in control as often as possible, a lot of those drama and character moments end up paying off on the stick, as we call it.
But figuring out which beats belong where and pulling off the execution of them requires a lot of iteration.
And at Naughty Dog, one of our biggest strengths is our willingness to retool or even throw away content, including captured performances, if it will make the player's experience better.
Even when deadlines are extremely tight, our company culture encourages people to speak up if they think something isn't working and take advantage of our tools which enable quick alterations to try out new ideas.
This means all of the narrative content that we capture is prone to changing, even after it goes into the game.
And sometimes, these alterations happen so quickly that their trickle-down effects get lost in the daily shuffle.
Thus, it is up to the editorial team to constantly chase change, tracking and managing each edited performance in its various evolutions over the course of development, in order to ensure that when the player gets their hands on the game, our characters' interactions still feel like the authentic human moments we'd intended them to be when we first captured them.
So today I wanted to share some of the techniques we've used and challenges we've encountered when creating realistic performances in games while allowing them to change over the course of development.
Oh, and just a heads up, spoiler warning for most of our games.
Here at Naughty Dog, we don't develop the story second.
Since we shoot and implement narrative material in small batches, capturing progressively with the actors for easily a year or more, our story in fact comes together right alongside design.
Of course, it takes many months of pre-production before we can shoot anything.
Our directors and writers first juggle developing story macros with design, overseeing the creation of characters that offer varied gameplay mechanics, and casting actors to embody those characters.
But, as soon as we have enough material written, we jump in headfirst with our actors to capture story beats via motion capture and dialogue recording.
Often, we focus on a demo of some kind, a small slice of the game that establishes our tone and explores the game's developing mechanics.
Right away, the game starts evolving because of these initial shoots.
Not only do they help our principal actors start infusing their personality into the characters, but their choices early on allow the team to adapt to discoveries we've made with the actors on the stage.
For instance, on the very first day of shooting The Last of Us, we began with a scene where Joel and Ellie are ambushed during their cross-country journey.
Ellie was originally pulled from their pickup truck and pinned helplessly by an enemy, making her a quasi-damsel in distress for Joel to save.
But Ashley Johnson, who plays Ellie, had the desire to fight back against her attacker.
So we shot it that way, leading our directors to go back to design and rethink the character's overall vulnerability for the rest of the game.
Though we wanted to reinforce the need for the player, as Joel, to protect Ellie from harm, it still worked better for her to become far more capable in combat situations than we'd originally conceived.
As we continue to shoot, cut scenes are initially our top priority.
Since these are non-interactive beats reserved for the more delicate and emotional character moments, they require as much animation time as possible to hit the level of polish required.
We've spoken about our capturing process before, but there's a couple of things I feel that are essential to capturing the best performance possible.
Because as an editor, if all I had to start working with was stale or unnatural material, there would only be so much we could do in post to make it better.
A lot goes into how we create scripts that give actors honest material to play, but I sadly do not have time to touch on that today.
However, I would like to point out one strength in that process.
Every phase the material goes through is a collaborative effort.
From the start, our creative directors encourage input from the team and our actors, either before the shoot or during our full-day rehearsals, especially with our actors.
We even do a table read to break down the script before we rehearse.
If something doesn't feel right, the director and actors work out what sounds the most natural and try that.
Sometimes when we're shooting, we try a variation over takes and see what we like best in the edit bay later.
When shooting a scene, we primarily capture it in one continuous take, unless we need to break it up for additional set builds or to accommodate a stunt.
Lighting, camera angles, we don't worry about any of this until post-production.
This lets us focus on getting that perfect master take with the actors, encouraging the spontaneity improvisation that brings life and genuine emotion to the scenes.
During the shoots, the creative director acts as the director on set, partially because that's who's worked most closely with design throughout the production process, and therefore, who can give the most context to the actors.
Meanwhile, the editor's job at the shoot is twofold.
First, staying aware of the director's notes, since then they can later be more helpful at personally executing or communicating to others the director's intention behind each moment.
And secondly, the editor ensures that we have the material we need to craft the dialogue performances later.
This includes noting which takes were the best performances on a particular line, as well as asking for a wild take to get a clean read of a line when the performance is still fresh, rather than trying to recreate it months later in ADR.
This is especially useful for efforts, those grunts you hear when the players exert themselves, which often get spoiled by set, prop, or suit noise while the actors are moving around.
Drake exertion.
Very good.
Marker.
Marker.
Great.
Alright, just give me a hand with this.
Come on, give me a hand with this.
It's some of the most ridiculous things when we have them do well.
Once the footage of our actors is in the can, the real work begins, breaking it into pieces for the design, animation, and audio teams.
Back at the office, the editor, lead animator, and creative director start editing as soon as possible.
We found that cutting together reference videos is the fastest and most efficient way to communicate the eventual shape of a performance.
After choosing which takes of mocap we want to use, we create four paneled videos called four ups that show the reference footage of the actors alongside intended camera angles.
As we experiment with cameras and massaging the blocking for the best composition, you end up having to watch them with a split focus, looking at the face here, the body and the camera there, sometimes even listening to audio that doesn't match up with the actor's lips.
This is because we can take advantage of the fact that this isn't live action.
We can swap different audio takes if we need to fix something, or use those wild takes to cover spoiled dialogue.
The facial motion capture is even ordered separately after the edit is locked and conformed to match.
So we truly have the freedom to change anything.
Like swapping only one actor's mocap for an alternate take to get a cool gesture they did in there.
or cutting between two different performances right in the middle of a shot.
Normally we hide these edits on camera cuts just like in live action, but if we can't, our animators then have to clean up the resulting pop in the mocap.
Or at the most extreme, grabbing the face, audio, and body all from different sources to cobble together a moment we don't have.
Usually that's because we discover something, a way something could play better in the edit, and since we didn't get it originally, we've got to fake it.
But usually, the most we do is swap reads of some lines to increase clarity or subtlety.
There's definitely magic in a performance that can easily be shattered if you stray too far from the source.
Once a scene's edit is approved, that 4UP reference video is funneled to every department that will be involved in the further translation of these performances.
This includes animation, props, environment, lighting, sound, and design.
but they all know the scene isn't picture locked, more like picture latched, because as I warned, these edits may very well have to change.
Sometimes a change is required because of a mistake in the edit.
Nailing the timing of a moment can sometimes be difficult, since you're essentially looking at mannequins in one pane and trying to sell an emotional transition that you can see on an actor in another.
When the facial animation is applied and we look at the scene full frame, some things might move just a little too quickly.
So we have to adjust, and then communicate these timing changes to all the affected departments.
Another change that comes up is that sets are often altered to accommodate gameplay revisions.
An entrance or an exit to a space had to move.
There's a wall in front of that camera, or a cover object sitting right in the middle of a character.
Usually these require minor animation fixes like moving characters or cameras, but at worst, the environment might need to be reverted by art and design.
The biggest changes that come in maintaining continuity is in maintaining continuity with gameplay.
Since the transition of characters entering or leaving a scene needs to feel seamless, their animations have to match what's actually happening in gameplay.
Design helps ensure this by creating pinch points that force a certain action from the player, like opening a door or vaulting over something, that will blend into the start of a scene.
And when it's over, we often blend characters' movements into regular gameplay animations to match on the way out.
But when gameplay changes, so do these entrances and exits.
Often this means recapturing, or at least reanimating, that portion of the material.
Like this scene in The Last of Us, which first had to have the camera corrected to not be behind the player, because that would be too similar to gameplay.
Then the level changed so that Joel would be in the lead rather than Ellie, so we needed a pickup to a new opening where Joel went in first.
As these scenes change, we have to keep careful watch so nothing slips through the cracks.
Sometimes, certain scenes linger in a partially done state for a long time, waiting on a character model or a set that didn't exist when it was shot, for example.
However, cutscenes are just the tip of the iceberg.
Since we like to keep the player in control as often as possible, we've increasingly relied upon methods other than cutscenes for implementing story beats.
One major way is through animations we call IGCs.
IGC stands for in-game cinematic, because until Uncharted 4, all our cut scenes were pre-rendered movies, so IGCs defined the distinction between animations that happened live in-game, versus more traditional non-interactive narrative moments like cut scenes.
Now that everything plays back in real time, the biggest distinction is that some aspect of the animation is usually interactive.
In the very least, the player might have camera control, but that all depends on the particular IGC.
Some are as insignificant as opening a door or walking into the frame at the start of a level.
Others are full-blown mini cinematics sandwiched between gameplay moments with no camera cuts, like during this puzzle in Uncharted 4.
IGCs are also a clever method we use nowadays to blend into and out of our cutscenes.
The first or last shot of some cutscenes on Uncharted 4 were IGCs, so the camera could blend smoothly, transitioning on a camera cut to the rest of the non-interactive cutscene.
There are hundreds of these littered all throughout the game and they will often change multiple times, being shortened, lengthened, or recaptured until design thinks they feel right within the pace of the gameplay around them.
Editorial, like with cut scenes, needs to keep up with any timing adjustments, moving parts of the audio around to match the animation as it changes.
But even though the interactivity of an IGC offers great advantages for gameplay, the way their audio works sometimes offers additional challenges.
IGC dialogue is similar to a cut scene in that it plays from the first frame of the animation until the end, usually containing several lines of dialogue and or efforts precisely timed to the animation.
However, that is where the similarities end.
Unlike cut scenes, which play back like a movie, where every volume level or perspective shift is crafted and controlled, IGCs often have to account for a real-time interactive camera.
So IGC dialogue plays directly from the voice box of each character in 3D space.
This creates different mix issues, because our camera is the listener, i.e. microphone, by default.
The benefit is that the position of the character's voice automatically matches what you're seeing on screen without any post-production work.
Instant realism.
But, the downside is that if the camera is really far away, and you want to hear the speaker clearly, we have to cheat how that line plays.
Or, if the camera cuts while someone is speaking...
Suddenly, the person you hear in your left ear is now talking on your right mid-word, which can be extremely distracting.
Like in this moment from Uncharted 2, we dealt with both problems.
It took a lot of trickery to make Nate's voice audible from across the ice cave.
But when that camera cuts across the space, you'll notice we quite couldn't fix the pop in Nate's voice as the camera cuts.
Switch on your side!
Yeah, yeah.
But wait, there's more.
Cutscenes and IGCs are only half the battle.
Our performances would not feel seamless without a lot of other systems that play in between them.
But before I break those down further, I would like to look at an example clip of what it all looks like when everything comes together.
During this beat of Uncharted 4, Nate and Sam are just starting the next leg of their journey, exploring the ruins of a Scottish monastery that their rival, Rafe, and the team of mercenaries he's employed are trying to excavate with dynamite.
The Drake brothers meet the shoreline mercs for the first time, learn the new dynamite gameplay mechanic, and solve the first puzzle of the level, finding a crate to climb past a section of ruins.
That is, until another team of mercenaries arrives.
That's a long drop.
Yeah. We need to find another way down.
Hey, this should hold.
Good call.
What the hell is all this?
Excavation equipment.
Shoreline?
What?
Look.
I thought they were just by the cathedral.
We're good.
Yeah.
Nice to meet you too, Shoreline.
Seems like they were expecting us.
And like they're searching away from the cathedral.
Which means we should get to that graveyard pronto.
Exactly.
What is this place?
The monks had several living quarters.
The main one being by the graveyard, of course.
Location, location, location.
More shoreline equipment.
At least no shoreline-ers.
Now, what do you bet?
Yep.
Dynamite.
Be careful with that stuff, huh?
I was very loud. Hopefully they didn't hear us.
Hopefully we just blend in with the other explosions.
Look, there's a way up through the roof.
That's too high for a boost though.
Well, let's find something to climb on.
Yeah.
Hey, we can use this to climb out of that building.
There you go. Take that, door.
You're pretty good with that stuff.
Well, I've blown a lot of shit up over the years.
I think we got away.
It's a mellow sequence, but there's actually a lot going on here.
And every single element that's happening is helping convey our story beats.
At a glance, these elements include IGCs when Nate uses his rope and later when he picks up the dynamite.
Animated gesture layers on Nate and Sam as they explore and converse.
Oh, and nice.
Still going?
Yes. Animated gesture layers.
Come on.
A, yes. A brief cut scene of Nate and Sam finding the Shoreline equipment before they're ambushed.
Systemic enemy dialogue from our Shoreline mercenaries as they attack the player.
Systemic buddy dialogue from Sam when the player successfully stays in cover.
Efforts as Nate knocks out the last Merc and then lands from a long drop near those ruins.
And of course, before and after all of this, there is also crap tons of story dialogue playing.
So, about that story dialogue.
Most of the dialogue you hear in our games are individual lines scripted by hand with specific timing.
We even have a designer and a scripter 100% dedicated to creating systems for hooking it up.
They can't complete an entire game on their own since by the time the game is finished, there's too much material for them to cover alone, but they are usually the ones triggering lines that play based on numerous conditions.
Some as simple as when a player walks through a defined region, others much more complex.
Rather than play with rigid timing, like cut scenes in IGCs, we cut our dialogue into pieces that can flexibly respond to the player's actions.
This also means we can adjust the execution more easily as things change during development.
These in-game dialogue moments actually make up a larger percentage of narrative beats than our cut scenes.
We feel this type of material is crucial because it carries the story forward by keeping the characters alive between those cut scenes.
It can justify practical and gameplay-driven goals within the context of the narrative.
Likewise, it informs the player of any changes in tension, like exploration or combat states.
And it's also a vital tool for selling the realism of the environment in the player's mind when the characters respond contextually to it.
Unlike the cut scenes in many of the IGCs, most of this dialogue does not come from the mocap stage.
That's because it primarily requires the character speaking while the player is in full control.
So, we record the lion's share of this content at an ADR studio.
The actors are usually paired up so we profit from their chemistry, just like at mocap.
Also, they wear the same type of microphones so that the audio quality matches that of the stage.
The scripts for ADR sessions come online rather late, as the levels they often reflect are still being locked down by design.
This means that most of the time, the actors are reading their lines without any time to prepare.
So we bring a video capture of the level in its most current state to give them as much context as possible.
And any time there is a cut scene that we've already shot and implemented, we watch those down with the actors too, to remind them of the character's emotional state that they need to match in order to keep the tone consistent.
Because the game is still in flux, we record a variety of material in anticipation of ways in which the game might change.
Gameplay conversations make up the bulk of our recording.
But these aren't always straightforward because sometimes parts of them are optional.
The actors will perform one version of the conversation all the way through and then pick up the other versions right away to keep the energy consistent.
Such as in that Scotland clip, different lines would play out depending on when the player interacted with that yellow crate.
How do we open this door?
Look, there's a way up through the roof.
It's too high for a boost, though.
Hey, we can use that yellow crate!
Sometimes we also pick up alternate versions of lines, alts for short, especially when the level is in a rougher state and we need to have multiple options as design locks things down later.
This frequently happens in puzzle spaces among others, since they require tons of specific VO and animations to cover what the player does and in what order.
On Uncharted 4, we even kept a wish list of alt lines that design thought they might need and tried to cover them all as pickups near the end of recording.
This resulted in much better coverage for the final game than we've ever had before.
We also have a whole category we call CYA lines, as in cover your ass, which are generic phrases like, hey, look at this, and come on, this way, which we record in multiple emotional states and contexts just in case we need them at a later date, either to help with gameplay changes or maybe to sell a character beat.
We record these with our heroes and all their buddy allies.
Just like in MoCap, our actors are also encouraged to improvise during ADR.
Sometimes this will inspire us to rewrite and re-record a new version of a conversation on the spot.
And at the end of most sessions, we also record wild passes of our levels, where the actors watch the playthrough video again and are encouraged to riff on top of it.
Though our writers try to cover everything we need in a given section of the game, this often provides alternate versions of lines or even completely new conversations that add enormous amounts of spark and character.
We extract these gems and use them whenever possible.
For instance, Sam's location, location, location line in the Scotland clip was an improv that Troy Baker threw in, and we kept it.
All recorded dialogue is then brought back to the office and stacked in time to the video.
This means we each take of line, this means each take of a line is edited in a Pro Tools playlist and arranged in columns so we can quickly listen down to all the takes of a line when making our selects.
These picked lines are then edited into individual files with unique names and uploaded into our dialogue database tool.
Editors also distribute scripts from the database to our designers so they have a list of what content they need to implement.
Along with the scripts, we also supply another form of reference movie.
Unlike our cut scene 4-ups, which are tied to motion capture data, these are instead exports of the very movies the actors ADR'd to, with dialogue placed to match the timing of the actor's original deliveries.
Hang in there, Joel.
Oh, shit.
Okay.
There's got to be another way.
These ref vids help show where and when the individual lines of dialogue should be scripted to play, so that it feels and sounds like a realistic performance.
Designers use it as a guideline as they translate all this cinematic pacing and subtlety into pretty much scripted math The goal is to include proper beats for a breath or a natural pause between lines Either for the speaker to have a new thought or for the companion character to actually listen before responding When we don't hit this the moment can feel rushed disjointed or flat-out confusing It sometimes takes several passes to get the timing right in game.
Designers can only use these movies as a guideline because often the video's timing was too fast or too slow and is not completely representative about how everyone might play the game.
They use their best judgment trying to keep three different potential play styles in mind.
Some players like to explore, taking their time, stopping to hear every lovingly crafted line so they don't miss a thing.
But if we were to time out everything to that play style, it would ruin the experience of more average players who like to enjoy the story but keep things moving.
Where we can, the simplest solution is just to have certain lines not play if the player is going too fast.
Like in these Scotland ruins, the line specifically pointing out that a ledge is too high for a boost doesn't play if the player rushes out of there before the previous conversation is finished.
Hey, got the door open.
That was very loud.
Hopefully they didn't hear us.
Hopefully we just blend in with the other explosions.
Look, there's a way up through the roof.
Oh, let's find something to climb on.
Yeah.
And then there's the speedy players who dash through the puzzles to get to the next combat setup.
We do our best to get our conversations playing naturally, but quickly, so they don't get lost, but sometimes it can't be helped.
Once in a while, we have an area too small for the amount of VO that has to play and end up shipping with moments that can feel like a string of lines back to back, depending on how quickly the player is going.
Like this moment in Uncharted 3 that just ended up a little too tight compared to the pacing of the cut scene that preceded it.
Well, who are we to argue with Sir Francis?
When you say we head down there and end this thing.
Once and for all.
Look at this place.
The whole city's resting on this cavern.
Doesn't look very safe, does it?
That's an understatement.
We've got to find a way down there.
If we get the timing right, it can convey subtlety without needing a specific body gesture or facial performance to sell a moment.
Like in this bit from The Last of Us, the pause before Ellie's oh line conveys a turn, her realization about Joel's darker past.
Her follow-up question then gives Joel an awkward pause of his own.
All of this emotional content managed to fit in one small stairwell, even if the player never stops.
Come on, let's get out of here.
How did you know?
Know what?
What about the ambush?
I've been on both sides.
Oh.
So, uh, you kill a lot of innocent people?
Yeah.
We'll take that as a yes.
Take it however you want.
That moment worked on dialogue timing alone.
But when we need more...
we now can dynamically add extra body motions to our story dialogue to increase physical and emotional realism.
In that Scotland clip, when you saw Nate waving his arm and actually looking at Sam while talking to him, that was an example of our gesture system.
In previous games, we've had all sorts of contextual move sets and animation that helped sell the reality of the hero's world by having him or her react to their environment, whether it be recoiling from fire, stumbling while exhausted, bracing themselves against walls, et cetera.
Our designers are also able to play additional unique animations on our AI characters to help bring them to life contextually.
That's what allows Sam to look around and dynamically check out the world around him.
But now we employ an additional level of detail, gestures.
These are partial animations that play on top of normal gameplay animations, like a head shake, an arm pointing, a shrug, et cetera.
The player can be running, climbing, or crouching, and these layers will usually still play.
In case you're wondering why sometimes an arm isn't moving in that clip, that's because it's not part of the animation's layer, meaning the player can be carrying a gun or another object while the rest of the body does the gesture.
One of the ways we sell these moments is by hooking up a specific gesture to a line of dialogue in script.
So when each line plays, the gestures play on top of whatever the character is doing.
Programming and scripting magic also helps the speaking characters actually look at each other dynamically when appropriate.
Since we don't record specific gestures for every line, the final performance isn't as rich as a cut scene might be, but the result is still an added level of life that doesn't restrict the player's movement as they roam around the game world.
Though we can also hook up custom facial animation gestures to lines in the same way, we usually don't go to the extra work, since the camera is normally behind the player character's head and far enough away from all other speaking characters.
By default, we employ a neat procedural system, which generates lip sync and facial animations using the audio file's amplitude and subtitle text.
This place, monks had several living quarters.
Main one being by the graveyard, of course.
Location, location, location.
Besides the story dialogue, we have another category of lines called systemic VO.
These groups of lines, or these are groups of lines with similar context that can play when triggered by AI-driven events.
This material helps to add life, reinforce character relationships, and provide feedback in various situations throughout the game, mostly during types of gameplay scenarios that use repeated systems like combat.
When an enemy spots the player, for instance, they have specific lines that they use to call that out.
There he is, I see him.
These buckets, as we call them, offer multiple varieties that can play based on the same situation, so the player doesn't just hear, I see them, over and over and over.
At the end of our Scotland demo, Sam called out one of his systemic lines to indicate the player is still hidden from the enemy.
The entire bucket consists of these lines.
I think we got away.
Hurry, Nathan, we lost them.
We lost them.
I think we lost them.
I think they lost track of us.
Looks like we gave them the slip.
This sort of dialogue serves a practical function in terms of player feedback, but it also keeps the characters alive and reacting to what's going on in the same way the storylines do, which is why we don't only use systemic dialogue for our enemies.
Any dialogue triggered by AI, rather than just script, falls into this category, including buckets for any major characters, the hero, their AI-controlled buddies, and, of course, all our multiplayer characters, since that mode is pretty much all combat mechanics.
The system is controlled by the global tension state, which we break down into four stages, unaware, investigate, search, and combat.
In Unaware, any threats nearby have no knowledge of the player or their companions.
Enemies can converse with custom story-based dialogue, like they did at the very end of that Scotland clip.
The player and his buddies, meanwhile, will likely be in standard explore mode.
This is the natural state of the game.
If they get close to enemies in this state, buddies and the hero will use whispered versions of their various buckets, so the characters sound like they're trying to stay hidden.
In Investigate, tension rises a bit.
The enemies heard or saw some evidence of player interference.
Then they try to uncover the source of the distraction, now playing their systemic buckets regarding what they saw, checking in if anyone saw anything, et cetera.
This is the first level of tension where the player would feel threatened and that they should either fight or get the hell out of there.
In Search, tension is near its breaking point because enemies saw the player, then lost track of them.
They speak buckets of lines so the player can audibly locate the enemies attempting to converge on their position.
Feedback from the heroes remains whispered, including buddies pointing out where the nearest enemy is.
On your left, behind you.
Or warning them if someone approaching is carrying a powerful weapon.
Look out, shotgun.
That sort of thing.
Combat is when all hell breaks loose, and in our games uses almost exclusively systemic dialogue.
But since we want it to feel as nuanced as any of the quieter story moments, we employ a lot of buckets to cover a variety of potential situations.
Enemies are aware of the player and actively trying to attack him or her with guns, fists, or whatever other means they have.
They have lines announcing when they are flanking, pointing out the player's exact location, or warning each other the player has a power weapon like an RPG or a Molotov cocktail.
Buddies continue to warn the player the same as they do in stealth, but instead of whispering, their lines are now shouted over gunfire.
We also have dialogue that helps emphasize their relationship to the hero, i.e. that they care about them.
Buddies ask if the hero is okay after they've been shot or stumbled by an explosion.
They shout out that they're coming to rescue the player if they're grabbed by an enemy, and say thank you to the player if they are rescued in return.
The hero also has dialogue to connect the player to their emotional state, like the stress of diving out of the way of a grenade would be, oh God, or stealing themselves up while reloading in cover.
Drake's is usually like, okay, here we go.
There's usually something that plays after taking down an enemy as well.
In Uncharted, it's usually a funny quip that suits the tone like, lights out, whereas in The Last of Us, it matched the world's grittier tone, just, okay.
Since systemic lines have a more functional purpose, they sometimes lack the subtlety or subtext that our longer conversations do.
But they always maintain the same personality as the character delivering them, so that the player doesn't become weary of hearing the exact same thing from multiple characters over and over.
For example, Sam calls our main character Nathan, or little brother in a lot of his systemic warnings, and is more ball-busting in his tone, while Sully calls him kid and maintains a more paternal tone.
Elena calls him Nate and has her own brand of loving exasperation with our hero in her pattern of speech.
Even with personality thrown in though, these lines could still sound somewhat repetitive.
So we have a shuffle system, which keeps track of every line said by every AI group, advancing the cue for any one bucket across the board when they speak, ensuring the same exact line will not be heard frequently.
If enemies spot the player, one might yell, I see him.
The next time that happens, rather than hear, I see him, again, the player will hear, it's him, or some other variant.
Not until the bucket has been exhausted by the shovel system does it reset to the top again.
We try to record 10 to 20 different lines per category that might be heard the most to avoid the player hearing the repetition in any one play session. Sometimes the lines are also written to be modular so they can be stitched together based on a situation. Not only does this allow for a variety in the simulation, but it makes the enemies seem alive and intelligent.
In The Last of Us, an enemy might say, hey, you two, go search over there.
Each of these is a separate bucket of lines that plays back to back, utilizing natural pauses to make them sound like complete, varied thoughts.
In another scenario, it might play as, hey, you, go check the alley, or some other variant.
One subtle way we keep things feeling more real is by avoiding repetition, not just in lines, but in the voices themselves.
Since we have a limited number of actors voicing our NPCs, we try to make sure they have different voice types, medium, low, et cetera, so that the player won't hear voices that sound the same over and over.
Also, as I mentioned, enemies are often initially encountered while they're having a story conversation, customized to that particular group or area.
We try to keep track of which actor's voice is being used in each conversation, then try our best to not use that actor in the next setup, further avoiding repetition.
A tricky situation that then comes up with these enemy conversations is how to interrupt these lines that are already playing.
If the player shows up in their vision cones, they have to switch to their systemic dialogue and go into combat.
So we cut off a line, wait a split second, and then just play the systemic dialogue as if the enemy had interrupted themselves voluntarily.
Take a breath. Who's dead?
The whole crew. The 76th...
For a long time, this rough method was the only way we had to interrupt conversations.
However, the addition of a drivable vehicle in Uncharted 4, which the player could exit at any time, meant entire sequences of lines might be skipped because the player wanted to explore a little.
This forced us to come up with a more elegant solution for interrupting and resuming dialogue between Nate and his buddies, ensuring conversations couldn't so easily be lost forever.
We recorded more buckets of lines regarding and responding to the player stopping the 4x4 and exiting, then attempting to resume the conversation upon return.
To keep things in line with our story dialogue, the tone of these interrupts had to be different, depending on the nature of the characters' current relationships.
In the plains of Madagascar, Nate is comfortably exploring with Sully and Sam, so his tone is more casual.
Avery was the most wanted man in the world, so if he was hiding something out here, it makes sense he'd need lookouts.
On the Libertalia island, by contrast, Nate and Elena's relationship is strained, so he's more subdued when he hops out of the car.
Well, Rafe is a good match for Shoreline. He needs their muscle and they need his money.
They do? They seem pretty well stocked.
Shoreline got involved in a couple of subâ€” Hold up.
Wait, what? You see something?
Okay, all done.
Yeah, so Shoreline got involved in a couple of civil wars that didn't come out.
To make it sound natural when the character stops speaking, we had the actors record glottal stops, the sound that a person's throat makes when it stops speaking.
These would play to cut off the lines in as natural a way as possible.
But...
Uh...
But...
Um...
But...
Solis were the best.
Sometimes, we edited alternate versions of lines that would flow more properly when coming out of an interruption.
This meant combing through an entire conversation and marking which lines needed alts in case the conversation resumed on that line.
In retrospect, we wish we had purposely recorded alternate versions to restart a conversation, rather than just edit the originals.
This system is still very new, and we are looking forward to building on it more in future releases.
There's one last category of dialogue to cover briefly, efforts.
Besides during those wild takes we get at MoCap, we record lots and lots and lots of efforts of various types with each of our actors.
Mostly because they give feedback to the player while also helping the characters come alive, selling all those physical situations like climbing, fighting, and dying that happen in our games.
Just having breathing from the characters alone, especially in situations that are tense or when they're fatigued, also helps give a sense of what a character's feeling without them having to state it.
When recording, we have actors chase videos of a player grappling, fighting, and falling, so they have context for the sounds they're making.
We often get different sizes, small, medium, large, of each sound and play the appropriate ones based on the intensity of the animation.
And as most efforts are vocally stressful, we always record them at the end of a session.
In fact, we do the same with any shouted material, so we don't blow out an actor's voice in the first hour.
So, as all of these systems and animations start coming together, that is where the glut of minor and major changes truly start.
A cut scene or a conversation might work in a vacuum, but it's not until we get these pieces into the game that we can truly judge what works.
It's about getting it right on the stick and feeling it out, and then making sure the performances remain consistent despite the adjustments.
We continually tweak, swap, and rearrange our dialogue and animation, sometimes over the course of years, all to improve the emotional connection between the player and what's going on around them.
First and foremost, not all the content we write and record works in the final context of the game.
Even if nothing changed in design or animation, sometimes an emotional beat just feels false.
If possible, we will alter that VO with an edit.
By adding pauses or stealing a breath, sigh, or laugh from somewhere else and cobbling it onto the line, it can really make moments sound more natural.
Our systemic dialogue might have similar problems when working in context.
Sometimes an AI bucket will fire in a situation that's tonally inappropriate.
Like Nathan Drake's bucket of quips he might spout off any time he knocks a dude out.
If the tone of the game at that point is more serious, our designers flag that area to suppress all the jokey VO until it's appropriate for it to play later in the game.
The same goes for all the buddies systemic dialogue.
Another possibility is that a small or not so small bit of exposition might need to change.
Sometimes it's contained in a cut scene, others it's a gameplay line whose context was altered by design.
Usually something this specific cannot be fixed with an edit, a new line needs to be recorded.
There are also times when a line is making things confusing, so it just has to go.
We hold many focus tests to determine where the pacing drags, augmenting or cutting as needed to hit the ideal amount of gameplay between story beats.
Since we overwrite our levels anyway, we can usually afford to cut part or all of an exchange and move another bit of dialogue in to fill the hole as necessary.
All these adjustments make the game better, but we also have limits on what we can change.
As the project draws to a close, the first hard wall we hit is localization.
Localization, for those that might not know, is the process of translating and re-recording all text and dialogue into dozens of language for international players.
Games at some point have to lock, recording no more new lines and writing no more new text so that all the existing material can go through this process in time for shipping.
The problem is, nowadays, the deadline for localization is not after the game is finished, it's at least a few months prior.
which, especially since recorded dialogue is often so hyper-specific to the actions happening on screen, leads to a greater problem when things in the game evolve after that date.
Because once we've reached the LOC deadline, nothing new can be recorded.
This phase is when those generic CYA lines become really handy.
We can use them to patch areas of the game that evolved after the deadline.
Need to direct a player's attention to a solution to a puzzle?
Hey, look at this.
Does a character shout out, this way, come on, but you want to sell that the buddy is following?
Add in a right behind you in response.
This type of dialogue has become so essential, we intend to record even more lines like it on future projects.
Like Uncharted 4, we didn't know if the kids' escape and the manor flashback would feel better as a tense stealth sequence or a balls-to-the-wall chase from the police.
We recorded dialogue to support both scenarios as time was running out, but most of it was for the stealth version.
Turns out, what worked better was the latter.
We ended up covering the majority of the chase using CYA lines.
But sometimes, CYA lines aren't enough.
We need something specific and have to borrow lines from another part of the game.
So we go digging through our database to see what we have that can cover the request.
When picking the line that will be duplicated, we take into consideration how far apart the new instance is from the original place the line plays, so that, again, the player won't notice a repeat.
Like this moment in The Last of Us that was covered entirely through CYA lines, reused systemic dialogue, and a storyline of Ellie's from earlier in the game.
There are even times we've had to change the precise timing of certain IGCs or cut scenes last minute, meaning the audio files returned from all the territories have to be re-edited by hand on our end.
Our localization manager keeps painstaking track of all these changes so we know which files need the extra love.
And by the way, tracking all of this madness by any means necessary is the biggest challenge of making things the Naughty Dog way.
The efforts of our minimal production staff and various leads are sometimes heroic.
But as we near the end of production, the biggest limit on us is just time.
At a certain point, we can only use animations that we've captured or lines that we've recorded.
If we don't have the material and can't make it up, sometimes that means living with tonal shifts or big cuts in material that was painstakingly shot and mocapped.
Back on Uncharted 1, design made a change to gameplay by inserting combat into a sequence that was originally just quiet traversal.
Nate and Elena casually walked into an area in the cutscene and discovered a jet ski.
They weren't out of breath or recovering from a tense combat situation.
But the gameplay needed a spike of energy for the player and it worked, even though it caused a tonal mismatch with the cutscene that followed.
Still, that late in the development process, we could not reshoot the scene.
So this was logged as an example of how we could improve maintaining tone when going into a cut scene in the future.
On Uncharted 4, we were working on an epic sword fight near the end of the game, and we had planned to introduce those new mechanics during the manor flashback with the kids.
We even mo-capped and recorded a whole bunch of material to make it happen.
But when we looked at the amount of work it would take to polish and script all those animations, and the time we had left to finish everything else in the game, our directors made a hard call and cut it.
So the player comes to the ending sword fight untrained, and can possibly be emotionally divested from the sequence as they struggle to learn new mechanics near the end of the game.
But if we catch an issue early enough, it has been possible to make the hard choices required to maintain consistent tone and performances in a sequence that needs adjustment.
Nearing the end of The Last of Us, one of our designers pointed out a big flaw we'd overlooked.
The Firefly Hospital culminated with a cut scene where Joel charged into the operating room to save Ellie.
In that scene, he kills the doctor and eventually Marlene right there, and we smash cut to him and Ellie driving away.
It was a great cut scene, and the performances we got out of it, as written, were excellent.
The problem was, as the designer pointed out, the player missed out on a big emotional payoff that we hadn't even thought about. After carrying Joel's daughter at the beginning of the game, the player was set up to expect an echo of that event.
that Joel would be carrying Ellie to safety at the end, redeeming him some aspect of his former loss.
So, with some hesitation, we looked at what it might take to salvage what we could from the existing cutscene.
By keeping the Marlene animation and just picking up Joel, now carrying Ellie, we were able to move the main story beats of the cutscene into the hospital parking garage.
This allowed for a brand new ending sequence where Joel, with Joel carrying Ellie past dozens of Firefly soldiers, who we were assured would refrain from shooting Joel because seriously he was carrying the cure for mankind.
So that is what we recorded all of our dialogue for.
And then after localization locked, it changed again.
There wasn't enough tension if Joel could just walk out of the hospital with Ellie, so the actions of the Firefly soldiers were revamped so they could attack him.
But that didn't match up with any of the dialogue we'd recorded.
It took digging through NPC material we had recorded for other parts of the game to make this moment and the performances in it feel as equally polished as others in the game.
ultimately was totally worth sacrificing some mocap and scrambling through folders of VO to create an experience that would capitalize on player empathy to that degree.
So we do a lot of crazy shit.
And I'd just like to emphasize, the way we do it isn't the only way or even the right way to pull off realistic performances, especially depending on your team size, budget, et cetera.
But the level of flexibility we allow for story and gameplay to influence each other during development is why we feel we're able to strike a balance that we're proud of.
And it's also why executing these performances requires constant collaboration and dedication from every discipline on the Naughty Dog team.
Writing, acting, rendering, audio, concept, character, programming, animation, design, lighting, production, even IT and ops, it takes a veritable metropolis of talented men and women to make the performances that the player can feel when the controller is in their hands.
It is a constant struggle, but if we can truly move you and maybe surprise you, then for us, that's art worth making.
Thank you.
