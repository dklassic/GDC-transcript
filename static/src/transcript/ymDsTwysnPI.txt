It's very gratifying to see such an extremely large turnout for math for game programmers.
This is great.
We've had lines up all outside today.
We've had great speakers.
My job is to scare everybody back out of the room by doing vector calculus.
A few reminders before we begin.
First off, if you have a phone, please set it to silent.
Second off, if you are here and your badge has been scanned, you will get an email.
And the email contains surveys.
Please do the survey.
The results go to me.
I will probably ignore them.
I did last year.
People said really nice things.
It was really nice.
So please say nice things.
All right.
So I'm Nicholas.
Today I'm going to be talking about iconic functions and mean value coordinates.
The official.
description for this talk says a bunch of things, but really what this is sort of about is the problem of understanding shape. Shapes are surprisingly difficult. Here is an example shaping computer graphics. It's the famous Stanford bunny. We see it all the time. And the question is, If we're working with shapes, say you're doing texture generation or modeling or procedural content generation is the big one that is going to be an up and coming thing, I think, this year, judging by the turnout in the procedural session at 3 p.m., then you need to be able to take shape and you need to be able to meaningfully tell the computer how to understand it.
And you don't want to do this directly, because the The mathematical framework of how you understand the overall structure of a shape, the global structure of a shape, involves a lot of heavy lifting from algebraic and differential topology, and you don't want to deal with that if you can help it.
We're also not going to be talking today about how you store the shape on a computer.
That's Gino's talk.
It's coming up.
I hope you'll stick around for it, because that should be really interesting.
So here is the idea of today's talk.
Instead of trying to understand a shape directly by looking at its triangles and vertices, we want to put a function on a triangle mesh, okay?
We want the function to have certain properties that are desirable for whatever the challenge is that we're facing.
We construct the function to have these properties, we put it on the mesh, then we can reason about the function instead.
And a function is a much nicer thing in some senses than an arbitrary triangle mesh.
So today I'm going to talk about two standard tools in what I do, which is geometric mesh processing, for doing this.
These are not original tools.
I have not developed these tools.
These are ideas from late 90s onwards.
The math itself goes all the way back to the 18th and 19th century.
Like a lot of stuff which I do in my academic life, it hasn't really been highlighted by the game development community, and so that's what we're going to do today.
So we're going to talk about two methods of working with functions on shapes.
The first of which is harmonic functions, and the second of which is mean value coordinates.
So, method one, harmonic functions.
So, let's talk about what we would like.
I give you a triangle mesh, M, and I would like to put a scalar function, which just means that it's just a float.
It's not a vector function.
That could be GDC 2018.
I have a scalar function on the shape.
I would like it to be smooth in this, you know, in sort of an intuitive understanding of that word for right now, and at some points on my mesh I would like to have some control over what the values of the function are.
So I define it in some places, everywhere else I want it to blend smoothly across the mesh.
You can think of the...
the following analogy might be helpful.
So here's a couple of bunnies.
You imagine that I have an infinitely cold, a thing that stays at a certain cold temperature.
I put it on the ears of the bunny, and you imagine that I have a thing that maintains a certain constant hot temperature.
It always stays, you know, 100 degrees, and I put it on the tail of the bunny, and then I wait.
And so over time, what happens is that areas near the hot point become hotter, areas near the cold point become colder, and heat transitions smoothly from hot to cold through the mesh.
This is the effect we're trying to achieve.
What basically happens over time in the real world is that you reach an equilibrium state.
And this is a course that's known as the heat equation.
This is an example of a partial differential equation.
It's probably the first basic one that you would study in a PDE's course.
So we want to create this effect on a computer with a triangle mesh.
So first let's talk about what we mean by smooth.
So, because this is a math course, we will use math to define what is meant by smooth.
We would like the function on the mesh to be continuous in the standard sense that you may remember from first year calculus.
We don't want any jumps, we don't want any point discontinuities, we don't want any weird transitions.
We'd like the change of the function to be smooth as well, which means that we'd like the derivatives of the function on the mesh to exist and to be continuous.
We don't want any...
huge changes over small distances in our function, and we also don't want to have any local maxima or minima, which is, for instance, a point that just randomly gets hot or cold for no good reason.
All of these things are sort of undesirable because we can't control them.
Defining by no sudden changes.
If you think back to multivariate calculus, you may have learned about the gradient operator.
The gradient operator on a vector-valued function points in the direction of maximum change.
So in our case, we aren't interested in the direction as much as we're interested in the length of the gradient.
And so saying that I don't want large changes means that I want to minimize the length of that gradient vector of my function everywhere on a mesh.
More formally, we can say, OK, how do I construct length over mesh?
I might actually try as well.
Each point on the mesh, I want to take the gradient.
I want to take its length squared.
Let's say that's fine.
That's given by that inner product there.
And over the entire mesh, every little bit of area on the mesh, I want to sum all those up.
And that's a surface integral.
And this is known as the Dirichlet energy of F.
I believe that's the correct pronunciation.
German speakers, pardon me if I'm wrong.
And This was one of the first problems that was studied in the calculus of variations.
I was going to say something here.
OK, I did say it.
Good.
Stating that we don't want any local maxima or minima in our case means that if we take the divergence of the gradient function on our mesh, we would like it to be 0.
The reason we'd like it to be 0 is because, If there's a point where the divergence is greater than zero or less than zero, it means that the function is curving into or out of a local maxima or minima.
If we actually write down what the divergence of the gradient is, you end up with this expression here, which is the sum of the second order partial derivatives of the function on the mesh.
This is known as the Laplace equation.
Typically, it is written with this little upside down triangle.
And if f has a Laplacian of 0 everywhere, then we call f a harmonic function.
So, very trivially, obviously, if this is zero and we integrate it, that integral on the previous slide is going to be a constant.
In effect, trivially, we can also say that if you have a constant function, it also trivially minimizes the Dirichlet energy because the gradient everywhere is zero.
There we go.
So by itself, Dirichlet energy is boring.
The Laplacian is fairly boring.
Where it gets exciting for us is if we do the following.
We take our triangle mesh, because we're dealing with a real object here.
I know this just seems like math for math's sake.
We set some points on the mesh to be some known values, a and b.
We'd like a to be less than b arbitrarily.
If you're a physicist or a mathematician, you will call these Dirichlet boundary conditions.
We don't really care.
They're just the points that we want to set on the mesh to control the behavior of the function that we are generating.
There's a famous result in mathematics called the strong maximum principle.
And what the strong maximum principle states is that f is a harmonic function everywhere except on its boundary.
And in this case, its boundary is just precisely where we took the mesh.
And you can imagine that we took a pin everywhere where we want to put one of these control points, and we punctured the mesh repeatedly.
Then the holes are the boundary, and everywhere else is the mesh.
So the strong maximum principle states that if f is a harmonic function everywhere else, then you can take any disk on the mesh.
And by disk, I mean you just draw a little circle on it.
And then the function will have its maximum and its minimum on the boundary of the disk.
So it won't ever obtain a maximum or a minimum inside the disk.
It will always be on the boundary.
You can draw that anywhere on the mesh, and that property holds.
This is a very, very, very strong thing we can say about a function on a mesh, which is why this whole strategy of analyzing meshes by looking at functions on them is so powerful.
So, in particular, what this means for our case is that if I have some maximum and minimum values A and B, and I have a harmonic function on the mesh, that has those points at the boundary set to what I want them to be set to, then it will only ever obtain them there, and it will smoothly transition between them everywhere else.
So, how do we find this thing?
We have a continuous thing, which means that it's defined on arbitrary surfaces, which is that the Laplacian of my function should be equal to zero.
The good news is that I went to last year's talk that I gave, because I was there.
And there is a well-known discretized equivalent to the Laplacian operator called the Mesh Laplacian.
It basically tells you how to construct a discrete version of this on a triangle mesh.
Then what you end up with is you end up with a system of linear equations, a very large one, but it's sparse.
You plug it into your favorite standard sparse matrix solver, and you find the solution.
I'm not going to get too much into how the discretized mesh Laplacian is actually derived because to be quite honest, what you do is you just, you do this with a cookbook.
And we don't want to get into any of the mechanisms that you can use to actually derive it.
It's enough to know that it exists and sort of have some idea of when and where you would use it.
I might put some notes in this on the slides to go up on the website because that just seems to be what we do.
So The way that you write it is you use this little fellow here.
And basically what it's saying is that if I take my harmonic function and I look at the harmonic function of every vertex on the mesh, then the Discrete Laplacian is given as a weighted sum of distances of the function across the mesh edges.
You choose appropriate weights for this to actually work.
It turns out that for this particular application, last year I said that you could use uniform weights, whatever.
This year you have to use what are called cotangent weights.
Cotangent weights come from the observation that if you have a triangle lying on its side, and it's got a base here, that the aspect ratio of the triangle from width to height.
is a function of the cotangents of the interior angles.
So here we're just taking an average of those with the height ratios when we're actually constructing this discretization.
Last year, we used the Laplacian in a matrix form, where we basically said, OK, I'm going to take the Laplacian of my mesh.
I'm going to construct this differential representation.
I'm going to take some anchor points.
I'm going to put them at specific locations.
I'm going to invert my matrix with anchor point conditions.
And then I'm going to do a least squares optimization in order to actually.
create a new deformed mesh that is smooth.
This year, we don't actually need to do any of that.
But it is important to remember from last year that if you have a least squares problem where you have some linear equation, say the form AX equals BA is a max.
is a matrix, B is a vector of known constants, and X is your unknowns.
And you want to come up with the solution where each the sum of the difference between X and B squared.
or sum of squared distances, rather, is as small as possible, then it is a well-known fact that you can do it by taking your matrix A, transposing it, multiplying both sides by the transpose.
The resulting linear equation is actually guaranteed to have a solution.
Furthermore, it is guaranteed to be a symmetric matrix, A transpose A. It's also guaranteed to be what is called positive definite, which means that you can use specialized of linear algebra packages to actually solve this thing.
Don't write your own linear algebra software kits.
Use, there's code out there that you can use.
There's trollmod, there's talks, there's a library called Eigen, which is compatible with most of the licensing needs we have as game developers.
I've had a few funny issues with it, and it is very templated.
Anyways, going back to what we're actually talking about, I said that we have a, We're trying to find this harmonic function that has known points, so points where it must hold water.
Using a solver of this type, this least square solution, does not give me any guarantee that it will have those boundary points that I so desperately love and need in order for this to work.
It will try to fit them, but it will do so by distributing error all over the place.
So we need to actually expand.
our least squares solver in order to satisfy constraints.
So there's two ways of doing this for this particular problem set up.
System one.
As it turns out, if you just construct the entire system of linear equations you want for the Laplacian and for the boundary conditions, you can actually get something that is solvable without needing least squares optimization.
The problem is that this is just a little bit numerically unstable, which means that if you actually try to run real linear algebra software on this matrix because its condition number is so awful, it will basically explode.
And then you're left holding a bunch of pieces and wondering what happened.
Not recommended.
What we do recommend, typically for this, is going back to another idea from multivariable calculus and another French mathematician.
When you have a function that you want to minimize, subject to some constraint at some point, what you traditionally use is you use what is called a Lagrange multiplier.
Maybe you've heard of this, maybe you haven't.
The idea is that instead of minimizing f.
such that some equality constraint holds is that you add a new variable, lambda, and then you try to minimize.
a thing in three dimensions here, which is x, y, and lambda are your unknowns.
And you're minimizing f, x, and y, minus how far off I am from the constraint that I'm trying to achieve.
And if you need more constraints, you've got more boundary points, you want to set specific things when you're doing a solve like this, you just add more lambdas.
You add one lambda per point.
And yes, your matrix gets larger and larger and larger, but who cares?
It's still sparse.
So, if you do this, what you end up with is you end up building a system of linear equations.
Top half says, all my discrete Laplacians, using the expression before, are 0.
Second half says, for each of my boundary conditions that I want to be true for these Dirichlet boundary conditions, I add a Lagrange multiplier.
Then you minimize the resulting quadratic energy by taking that big matrix, squaring it, no, sorry, finding its transpose, multiplying A by the transpose, multiplying the right-hand side by the transpose, dump that in your sparse positive definite matrix solver, and it will basically, for every vertex on your mesh, it will spit out a harmonic function, basically like magic.
So that's a lot of setup.
So here's what it actually looks like.
So here is a model from one of the papers that I referenced.
And this gives you an idea of some of the useful effects you can achieve.
And you can immediately see how this would be useful.
So here we have a couple of control points.
We've got one on the top of the head, one on the base of this statue of dancing children.
And at the top of it, it achieves its maximum, and the bottom achieves its minimum.
And you can see that it smoothly interplates the values everywhere.
So you can create stripe effects on meshes that are very intuitive and natural.
You can smoothly blend textures along surfaces that are very easy and natural.
So if you have an arbitrary shape like, say, a tank, and you want to put rust on the tank in some areas, that you can just imagine, well, your texture is going to obtain those maximum areas in the areas where I want rust and minimum areas where I don't want rust.
And you just throw the whole thing in the solver and it spits out smooth blending for the entire shape of your tank.
in whatever order you need.
And if you aren't happy with this pattern, another nice thing is, of course, is you can always add more constraints.
So here, if you put a constraint on the top of each of everybody's heads, then you can see you get the same stripe pattern you were getting before in this case.
But now you're getting all of the whorls, and you're getting all of the stripes exactly where you want them.
So it's a very powerful technique for smoothly and efficiently creating smooth functions on just arbitrary triangle meshes.
Here's an application which is very common in computer graphics, and this is where this originally started, is that if you have a mesh and you want to very quickly slap a texture map on it, how do you do this?
So one thing you can do is, okay, you cut it so that it is, the mesh is homeomorphic to a disk.
Basically, it means that if you had it and you flatten it, you can imagine it's made of rubber or paper or whatever your...
favorite material for topology is, that it has something which is deformable to the shape of a disk. It doesn't need to be a disk parameterization itself, as long as you can parameterize that edge. If you take that edge you created, you put UV coordinates on it somewhere in your standard 2D plane, those are your boundary conditions, one for each of U and V.
And then you find two harmonic functions.
And then what happens, shalomigyalomizoop, is that suddenly you have parameterized your entire mesh by magic to fit into the bounds of the texture map that you were trying to create.
And in fact, it's guaranteed to, in this case, be bijective.
So you can go from one to the other.
There are no inversions.
There are no triangles on top of each other.
As you can see, there's a great deal of uneven distribution of texture information.
The top of the camel's head, which is furthest away from the disk, has a higher concentration of checkerboards on it than the bottom does.
So it is not perfect for all things.
But this will basically get you up and running very fast.
So the sky is the limit here.
Second technique I sort of want to talk to you about today is mean value coordinates.
So many of you will have seen barycentric coordinates.
In fact, if you're in computer graphics, you must have seen them or used them at some point because they are the principle behind which basically all shading works.
And the idea is that if you have a triangle and it's hanging around in space, you can write any...
point on the triangle as a linear combination of the vertices of the triangle, such that all the weights are greater than equal to 0, and they sum to 1.
And in fact, at the corners, it's exactly 1.
And the nice thing for our problem here is that if you have a function at the vertices, like, say, color information or lighting, you can then.
smoothly blend that function across the triangle in order to define it on the interior of the triangle and that's basically how all of computer graphics works is this one thing.
We would like to generalize this to larger classes of polygons.
So for instance, ones that aren't triangles, like convex polygons, star-shaped polygons.
A star-shaped polygon is a polygon where there is one central point such that you can reach it via a straight line from any other point in the polygon, and it doesn't go through a boundary.
Even just simple polygons in the plane, or even just polygons of holes.
What the heck, let's just do them all.
So here's sort of what we would like.
We'd like to maintain this convexity property, which is that our weights should be positive when they're inside the polygon and negative outside.
We'd like it to smoothly interpolate data.
thing like colors. We'd like it to satisfy this Lagrange property, which is that at a vertex, only one weight is set to one, and it's the weight for that vertex, and the rest of them should be set to zero. Ideally, we would like it that all weights sum to one.
The first stab at this might be to take the cotangents previously used for the harmonic functions and just try to use those.
It turns out that those weights actually violate the convexity.
The weights that you want to use are invented by a very smart man.
Michael Floter, and they're called mean value coordinate weights.
And what he did is he took the harmonic map that we looked at previously, and he derived a piecewise linear approximation of it, and then did a whole bunch of trig.
And what happens is you end up with this weight in terms of the tangents, the angles around a given vertex.
for wherever you're trying to get to.
So you have a point in a polygon v0, and you're interested in weight i for it, which is one of the vertices of the polygon.
You compute that function.
This will work like a barycentric coordinate any time you want to linearly interpolate colors or whatever.
If you make a slight generalization, which is that you require the angles that you compute here to be signed.
And a signed angle in this case means that if you actually compute it by taking the cross product of the vectors in question, if you remember from linear algebra, the length of a cross product length is, I believe, length of u, length of v, sine theta.
If you actually take the sine of the cross product, it will tell you what the sign of that angle should be.
This lets you actually generalize it to an arc polygon on a plane.
The good news is also that the weight of a vertex in this thing depends only on three vertices, itself and its neighbors.
The other good news is you can do all of this in about 20 lines of code, provided that you have a function for computing the area of a triangle.
Here's why it's cool.
So here you've got a planar polygon, a bunch of layers.
You put color on points, and you can actually smoothly interplate all of these colors just by pretending that the entire thing is one big triangle and using these weights.
This is guaranteed to be smooth everywhere except at the vertices, where obviously you control the vertices.
You can screw things up as much as you like.
Other applications of this technique with these coordinates include for instance texture parameterization is if you have something and you can project its boundary to a plane in a meaningful way.
You can use mean value coordinates to get all of the interior points onto the plane, so you can move a big patch meaningfully from 3D space to 2D space, work on the patch.
You can generalize this to handle 3D polyhedra, which means you can then do things like cage-based deformation.
It's the same formula.
It's just more work to get there.
You can use it for smooth shading of 2D polygons, if you wish.
Again, possibilities are endless and it's up to you.
So what I'd really like everybody to take away from this, regardless of how comfortable you are with you know, Laplacians or mean value coordinates or whatever, it is a very powerful technique to be able to take a mesh and put a function on it and then look at that function instead.
This is just the tip of the iceberg.
The two methods which I have hastily outlined here and.
I don't expect everybody, you know, I don't expect you to be able to go code them.
I expect you to have sort of had a look at them so that you can now go and see, ah, okay, these are the things that I need to know in order to be able to understand this and to have some appreciation of what they can do.
Harmonic maps on a mesh are extremely powerful because you can define boundary conditions anywhere you want.
Fairly simple to implement if you're comfortable with linear algebra.
The actual math behind it is scary because it comes from work being done by mathematicians in the 18th and 19th century.
The implementation is fairly straightforward because we're working in a discrete case, and it's basically sums in a matrix.
Mean value coordinates, very simple.
Again, you just find your formula, you work out your weights for a point that you're interested in, and then you can linearly interpolate colors, texture data, whatever you feel like, over the surface of this thing.
I'll have source code for these next week, and I mean it this year.
Last year's source code is still not up.
I will try to rectify that next week as well.
Some references and useful material if you decide that you're interested in this.
The...
Michael Floater did a number of papers on mean value coordinates.
He started with just the convex case, then he did star-shaped arbitrary polygons in 3D and generalized barycentric coordinates.
Probably the most useful one for our purposes is called Mean Value Coordinates for Arbitrary Polygonal Polygons, which is a joint paper with Kai Hormann.
There are a number of papers on harmonic fields.
This is a recent example of one which also talks about the fastest methods for updating a harmonic field, harmonic surface, harmonic mesh.
might be useful to you if you are interested in doing these in a real-time context.
The setup for that is a little fussy.
There is a public implementation of a harmonic mapping function in a great library called libigl by Alec Jacobson.
It is MIT and BSD licensed.
It includes everything that you need to use to go, and it is header-based.
So you can try this stuff really quickly if you want to and get a feel for how powerful it is.
There's also a very good talk on Laplacians in general, which you might want to track down.
And finally, CRC Press has a select books on the expo floor.
This is a recent book by Daniel Cohen-Orr and a bunch of other very talented authors.
And it includes all the material here on Laplacians and the Poisson equation for image processing and a bunch of other useful stuff that you may want to have in your life.
So I would encourage you to track any of these things down and read about them.
Questions?
And I am impressed that you all stayed through the vector calculus.
Give yourselves a hand.
Quick question.
Is there sort of a ratio between the number of control points that you can set versus the number of points you have?
Oh, fun question.
Short answer is that what I would expect to happen is that, of course, you can over-constrain your problem.
And over-constraint can manifest itself in one of two ways.
First off, what might happen is that your Laplacian matrix may become numerically unstable in the sense that its condition number might simply be too high if you have too many points that are too close to everything else.
In which case, uh, A direct linear algebra solver will just explode.
An iterative linear algebra solver.
Linear algebra solvers come in two different forms, direct and iterative.
Direct basically attempts to...
crunch the math in the thing directly. And an iterative one attempts to work by finding increasingly better and better and better refinements to the solution. An iterative one will eventually make hay out of it, but it will be slow as heck.
And of course you may just create something where it's, it's meaningless, essentially. So there isn't, there isn't really a point at which it would explode, but I think I would encourage you to keep those control points fairly sparse.
Anybody else?
Nope. Wonderful. All right.
Thank you, nicholas.
