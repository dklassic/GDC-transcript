So welcome to For Cry 5 procedural world generation.
My name is Etienne Carrier.
I've been a technical artist at Ubisoft Montreal for about three years now.
And I joined at the beginning of the For Cry 5 project.
And, well, I haven't worked on any AAA titles before, but I joined, however, when I joined Ubisoft, I had a secret weapon in my sleeve.
And that is my experience with procedural tool development.
I've been passionate about that for about six years now, and before joining Ubisoft, I was working on indie games, and that's where I started introducing procedural workflow into my pipeline.
So today I'm happy to share with you the procedural pipeline we developed for Cry 5.
Well, quick reminder, turn off your cell phone, put it on mute, and avoid taking too much pictures.
If you do so, do it discreetly, because it can be annoying for people sitting behind you, seeing a cell phone or iPad up in the air.
So anyway, the whole thing's going to be available on the vault afterwards.
Before we start, this is the content we'll be seeing today during the presentation.
I'll start with an introduction part with some of the challenge we wanted to tackle.
And then the objective for the pipeline itself.
And then we'll take a look at the procedural tools that we developed for it.
Then all those tools are used from a user point of view.
And after this, we'll dive a bit more in depth into the pipeline itself.
And we'll also look at how the cliff and the biome tool are working under the hood.
Unfortunately, I didn't have enough time in my presentation to go in detail in every tool that we made.
But we'll see those two at least.
And then a quick section on things that we changed along the way.
And finally, a conclusion part.
So what was our initial challenge we wanted to tackle?
First, we had a Turing that was changing constantly.
This is the 4.5 Turing evolution over two years and a half.
So how do we manage our content when there are so many iteration like this?
We'll have the same evolution here on the smaller portion of the terrain.
We have a forest that has been applied manually, and its distribution is initially coherent with the terraforming.
And however, over time, it becomes really incoherent as the terrain changes.
So how do we solve issues like that?
It would be, for sure, tedious work to repaint the forest every time the terrain change.
Also, if this was done, and if it was managed by several different users, how consistent would the result be?
Should we lack terraforming early in the project to avoid problems like this?
I don't think so, because this whole iterative process is vital to the game quality in the end.
It is with those challenges in mind that we built a procedural pipeline.
Our first objective was to develop a macro management tool to fill up the world with uh natural looking content.
then this content needs to be consistent with the Terrain topology as well.
Here we have the same example as before, however, this time the forest distribution is adapting to the Terrain shape.
So as you can see, the result remains coherent with any of the terraforming change.
Then the whole pipeline needs to be automated as well.
We use Udini and Udini-Engine, as well as nightly generation on BuildMachine to fully refresh the world every night.
We have several BuildMachines that will process different parts of the world one by one until the full world is generated.
And this process ensures us that the user will have updated world data every morning.
Then all the data generated also needs to be deterministic, which means that the generation needs to yield the same result given the same inputs.
So by using different build machines, whether we bake the left or right chunk of the terrarium here, the middle part will always give the same result.
And this is quite important because for the nav mesh generation, among other things.
Well, we have the nightly build that makes the world map per map, so the junction between those maps needs to be seamless.
And finally, our last objective, we wanted the whole thing to be user-friendly.
Just the nightly build alone is not enough to ensure user have up-to-date data.
They need to be able to bake the procedural generation as they work as well.
So of course, we have all the tools available in the Insta.
Now, let's take a quick look at the available procedural tools we developed.
Initially, our mandate was just to tackle the biome distribution, develop a biome tool, but we ended up expanding way beyond that.
First, we have the freshwater tool that generates lakes, rivers, streams, and waterfalls.
We have a fence and power line tool.
We have the cliff generation on steep terrain surfaces.
Then the biome tool that spans all the vegetation.
We also have a fog density map generation that is then used by the fog shader.
And finally, we also generate the wall map terrain mesh along with the scattering of miniature trees on top of it.
But how is it like using those tools from a user point of view?
In this next section, we'll take a quick glimpse of how it is like to fill up an empty map with the procedural tools.
So first off, a user will terraform the terrain using the IDS2 tools.
And then the artist can lay down a freshwater network that is achieved by using curves and spline that will be used as input for the freshwater tool.
For rivers, we have control on the spline for the width.
And once we're happy with our inputs, the user just have to make the freshwater tool.
And this will produce a water surface as well as some tearing, texturing, and scattering of some asset underwater.
Then the user can generate the cliffs.
The tool is simply based on the terrain slope, so you basically just have to run the generation on the desired terrain area.
We also have a few extra controls, like exclusion mask and stuff, but we'll see more detail on this later.
Then the artist can add the vegetation.
So this is done using the biome painter.
Here we just select and apply a main biome to the terrain, then run the procedural generation.
So the main biome will naturally distribute the grass and forest sub-biome.
And the recipe will also react to water proximity, spawning specific asset.
It will also avoid spawning vegetation on the cliff erosion line that was generated by the cliff tool.
And also, in this case, altitude also affect how the recipe behaves, spawning smaller and sparser trees up in altitude.
So this is nice, but the user will certainly want to customize the location.
So what the artist can do is he can start by clearing out an area by painting a sub-biome like grass, then laying down a road spline.
So far, our result was quite natural.
But that's all we will bring, man's influence on the environment and override mother nature.
So once we're happy with the input, in this case, we bake the roads and refresh the biome.
And now we get our updated result.
The trees are cleared out of the road here.
And of course, there will still be some assets that will need to be placed by hand, like house, shed, and vehicle here.
Yeah, the level artists are not out of work yet.
Based on those, perhaps we need to readjust the biome painting a little bit.
So some biome brush that we have, they don't do any asset scattering, but simply apply a terrain texture.
So the user can use that to create some kind of driveway.
And then we can also add back some trees and forests using the forest sub-biome.
So we can apply that here and there.
So once we're all happy with our setup, we just refresh the biome here.
And we see that our driveway is not clear of any grass.
And we have our little patch of forest where we painted them.
And now, just to cover all our tools, let's take a look at how we can add a fence.
The input for that is once again the spline.
So the user will simply set the fence type he wants to generate on the spline parameter, then run the generation.
So here we get a nice wooden fence.
User can also add power lines network in the world.
The electric pulse will spawn on each control point of the spline.
In this example, we had three different types of power lines that will automatically connect with one another.
So we added a standard line, a single line, and then two house connectors.
We make sure to snap the splines together.
Then we run the generation.
And the tool will nicely add the transformer box where required.
And also here, the user didn't snap the splines together, but the system will do that automatically within a certain distance threshold.
Here we have a bit of a problem.
We've got trees in the way of the power line.
So easy enough to fix.
We just have to refresh the biome tool to take the power line into account and the trees will be removed because the systems, they can speak with one another.
So that covers up the tool from a user point of view.
So just to illustrate the non-destructive workflow, the terrain can be readjusted at any time.
The user will simply have to rebate the affected procedural tools.
So back there, I lowered the terrain quite a bit, and I'm adding an island in the middle of the lake.
So in this case, I just have to rebate the cliff and the biomes.
And voila, all the vegetation is updated according to the neuterine shape.
And we get our nice little island in the lake.
So now let's take a look at how this is working under the hood.
We have a Houdini engine implementation with our in-house engine and it's their Dunia.
And what is opening doors and possibilities with this pipeline really is the available inputs and outputs, the data exchange between the two.
And well, quickly, for those who don't know what Houdini is, it's a 3D software with a node-based workflow that allows you to develop tools that we call Houdini Digital Asset, or HDA in short.
Then those tools can be run in the Houdini Engine API when implemented as a plug-in with a specific application like a game instructor.
Some of the inputs are sent from Dunia to Udine through Python script.
So we have the world information, world name, the size of it.
Because we didn't have only one world during production, we also had a gem for testing purposes.
Then we'll send over the file paths also, because we can expect all PCs to have their stuff installed at the same path. And then the TerrainSector, which is basically just the area of the terrain we want to generate.
We'll see more detail about this in a moment.
Then the splines and shapes, along with metadata as geometry attribute.
For instance, the fence spline would have the fence type as a geometry attribute.
Then other inputs are simply extracted on disk and available to read from Houdini with the file path provided by Dunia.
So we have the height maps, the biome painter, PNGs, 2D terrain mask.
We also have access to Houdini geometry that might have been generated by specific procedural tools.
But the main input for the procedural is the terrain itself, because the generation is always linked to a specific area of the terrain in our case.
And so this is how the terrain is subdivided in the Edster for us.
Our smallest granularity is a sector, which is 64 by 64 meter, which means it is the smallest area a user can make.
What happens when someone wants to rebake the procedural data?
He will select his generation area.
So it's either all, basically everything that is loaded.
It's worth noting that in Dunia, the whole world is not loaded at all time in the editor.
The world is divided into several maps.
And when opening the editor, we select which map we want to load.
Then the other options are the local map section or sectors, the local being the one located right under the camera.
And our last option, frustum mode, where we will simply bake all sectors visible by the camera.
So now let's take a look at the data that Udzini can send back to the editor.
We have an NCT point cloud, terrain textures, terrain height map, 2D terrain data, either RGB or grayscale, and procedurally generated geometry, as well as terrain logic zones, which is basically just IDs on the terrain to specify environment preset and post-process.
then all all of these are saved as a buffer in a special format on disk and that gives time to the instructor to load the data at its own pace and uh that avoids sending one big buffer uh that takes a lot of memory.
Some quick specification concerning the NC point cloud, it could really be anything that has a position in the editor.
So vegetation asset, rocks, collectibles, decals, VFX, prefabs, could even be animals in their favorite type of environment.
The points will be exported with the object ID of the asset to spawn in the editor.
Then the exported data is also key to the tool's interconnectivity.
The procedural generation is sequential, so the build machine will always make them in this order.
So each tool can export data with the goal to influence the following ones.
So some tools only write new mask, and others will read mask generated by previous ones.
As an easy example, we have the freshwater tool that will generate a water mask that is then used later by the biome tool to drive the spawning behavior of some specific species.
So now for the cliff.
So the purpose of this tool is to generate cliff geometry on large terrain surfaces.
It acts as a detail skin on top of the terrain.
So this is quite a large section, so just to give an overview of the content we'll see in there, we'll take a look at the previous stack, the tool input, stratification, geometry shape, shading method, the terrain data, erosion, vegetation growing surface, and the exported data at the end.
So our previous tech, well, there was none.
On previous Far Cry, beside the end place rock, the cliffs were only bare terrain.
It wasn't there back then, but I was told that the world used to be designed to avoid having too much large cliff surface.
But now, uh, on Far Cry 5, I don't know what happened, but, uh, we suddenly had a world with, uh, like a large amount of cliff surface. They were, um, they were much bigger and, uh, than before and invisible from much further as well. So, that's the reason why we decided to develop, uh, a tech to improve the situation a little bit.
So this is a shot from the FC5 without the cliff deck and with the new cliff geometry on top of it.
So how does that work?
In Udine, we use the terrain slope attribute as a starting point and then delete all surfaces below a certain slope threshold.
And this becomes our cliff input geometry.
As an additional note, doing that is interesting as well, because it also serves as a visual cue for the player to know which terrain is too steep to navigate.
And this is exactly the right slope threshold that we use to generate the cliffs.
Since we start from the terrain mesh, we get stretch quads on the slope, as we see here.
So we get rid of those by doing a remeshing pass on the geometry to get uniform triangles.
And then there is an interesting phenomenon that we want to reproduce with the tool.
And it is the geological stratification, the visible horizontal lines that were formed by the accumulation of sedimentary rock and soil over time.
To create this effect, we have a tool that slices the input geometry into strata chunks.
Each strata has a random thickness.
And it will assign a strata ID to each slice, which we can use to randomize the strata color as a debug view, as we see here.
And then in the Inster, we also have a preset to control the strata angles.
The user will control them with this RGB input painted on the terrain, then Udzini will use that to drive the stratification angle parameter in Udzini.
As a result, we get the strata slice in three different angles here.
The angles that we chose were some that best fit the terraforming of our world.
However, just like this, the strata lines are a bit too perfect and unnatural.
So to break them up and bring some chaos, we do something else.
So we start by generating a noise that will be used to split the input mesh into two groups.
The noise is generated on a lower resolution mesh and then transferred to the iRES one.
And we do that to get larger and blockier patterns.
Using that noise, we split the cliff surface into two groups like this.
And then we run the stratification tool on both groups with just a different seed value.
So that breaks up the strata lines.
After this, the geometry is ready to get some volume.
So, uh, each strata is extruded at various thickness and displaced using a combination of a displacement map. Then at this point the geometry is still fairly rare so, uh, we, uh, do an optimization pass and we reduce the triangle count.
And before export, the geometry is also split into several individual mesh.
And that is one mesh per sector, to be more precise.
And that's for better loading and streaming in game.
So all these different colors represent a different sector.
Note that we actually don't cut the geometry at this step.
Each triangle already knows in which sector it resides.
So we just have to use that to split the mesh apart.
So that covers it for the cliff mesh part, but the cliff tool does other cool things as well.
And before going further, I kind of need to explain how the cliffs are shaded in game.
We use what we call the terrain shader.
Some of you might have seen the talk of my colleague, Jeremy Moore, yesterday on the terrain tech he developed for SC5.
If not, and if you're interested in, you should look it up once it's available on the vault.
Anyway, what the shader does is that it will render the object in the same path as the terrain.
So the cliff will use the same texture as the terrain directly underneath it.
So if we have grass underneath, the cliff will be partially textured with grass, too, as we see here.
So to avoid this, we need to make sure that the cliff, while we have cliff there in texture, right under the extruded cliff mesh as well.
So for that reason, we use the final extruded cliff mesh, and we recast down some cliff attribute back to the terrain.
So we do a cliff mask, and we transfer the strata attribute as well.
From the strata attribute we just transferred, we first generate a color layer that will create a macro tint variation in the world.
As an additional note here, this color could have been on the cliff mesh vertex color, but we didn't do that for two reasons.
First, because we want to maintain the tint on the terrain, even in far distance when the cliff mesh is actually unloaded because of the kill distance.
Also, at the same time, we wanted to reduce the cliff mesh memory cost as much as possible.
Plus, we already have the color modulation layer in our terrain tech on which we merge this color.
Then from the cliff mask we transferred to the terrain, we further extend the cliff by running a flow simulation.
The points scattered on the cliff surface will flow down the slope to create this erosion effect.
And it's worth noting that the origin strata colors retain on the erosion area as well.
Then using that erosion data, we also scatter crumbled rock entities on the terrain.
Those will be exported later as a point cloud to the edster.
Then from our mask, we generate the terrain texture IDs.
We also use noise to mix two different cliff textures.
And we do that just basically just to break out the texture tiling.
Another feature of the tool is that we can also scatter vegetation on top of the viable cliff surface.
In order to find which surface is viable, we isolate the polygons facing upwards and simply check if it's clear above or not using a recast.
And quick result in game of those cliff edge with vegetation.
And at the end, this is the data exported to the editor.
We send the cliff geometry along with their collisions.
And steep point clouds for the rocks and vegetation.
We send terrain texture IDs, cliff color, and a cliff mask.
And this is some interesting procedural cliff shots from the game.
Okay, for the biome tool now.
So the goal of this guy is to populate the world with biological content.
Bear with me here, this is probably the largest section of the presentation.
There's a lot of feature to cover, mainly because there's so much subtlety in nature and so many various phenomena to reproduce.
So the first step that we do in the biome tools is we generate the terrain from the right map, so easy enough.
Then, from the topology, we generate the abiotic data, which are basically the physical features of the land.
So we generate an occlusion, a flow map, the slope, a curvature, illumination, or sometimes it's called the slope aspect.
Then others, like the altitude, latitude, and also a wind vector map.
So something important to note here is that all those TARIN attributes will become the pillars to most biome recipes.
Then after that, we import other 2D data that Dunia extracted for us on disk.
So we have the biome painting done by the users, and procedural data generated by previous tools such as the freshwater, road, fence, power line, and cliff mask.
And then we're ready to roll with the fun stuff.
So first off, something really cool that the biome tool does is that it does not simply spawn forests where the user painted forests.
We have what we call main biomes and sub-biomes.
The main biomes are covering probably, well, most part of the world, probably like 75% to 85%.
And the main biomes will automatically process where the sub-biome should be based on the abiotic terrain that we just saw.
And it is this part of the tool that gives us this natural looking macro detail in the biome distribution.
And then this main biome also process other fancy things, like replacing forest with grassland where the user placed power lines.
After this process, we have our sub-biome recipes.
They're processed in chain, and each of them contains all the ingredients that define this recipe.
So trees, saplings, bush, grass, et cetera.
And at the core of the biome recipe, all of these nodes are the generate-tearing entities, HDA.
And this guy, among other things, do the vegetation scattering and can modify and create terrain attributes.
But a key part of it is that it defines viability for each species.
So each species is fighting for its ground to grow and thrive on.
The viability is defined by setting up a favorite terrain attribute for each species.
And the species that accumulates the most viability at a location will win over the others.
As an example, we have a species A here that likes to grow on this range of occlusion terrain data, as we see on the bottom left, with a power of 1.
And then we have a species B that likes to grow on this range of flow map with a power of two.
So the species B will win over species A, where the flow map value is high enough.
But to determine the winner, there is also a radius that is involved.
Here we have a species A.
a species A that has a higher viability than the species B.
So we see the radius in color on the terrain.
If species B ends up inside species A radius, it will be removed, like the one in red that we see here.
So this is nice.
We keep a desirable spacing between our tree like this.
However, what if we would like to allow bushes or grass to spawn underneath those trees?
We wouldn't want those to be removed.
So for this, we also have the priority with a priority radius.
The priority will actually be evaluated first.
And then if two entities' priority are equal, then we will then evaluate the viability instead.
The previous example has been extended here.
However, now our green tree priority radius is smaller than its viability radius.
All our tree are set with a priority of 10.
And we added the bush pieces in yellow with a priority of 0.
The yellow bush will be allowed to grow closer to the trunk of the green tree now, which has a small priority radius of 2.
But if we want to, we can still prevent them to grow too close from the blue tree, which this one has a larger priority radius of 10.
So we saw that viability has a big role in the vegetation distribution.
So now let's take a look at some natural phenomena.
Here on the left, we can observe that we don't have any vegetation growing on the flow lines in the steep slopes.
And on the right, we also have almost no vegetation growing on the south face of those mountains.
So while to mimic similar phenomena, we kind of need to be able to combine different abiotic-tearing data together.
It is by mixing various terrain attributes that we can create very specific patterns for species distribution and accumulate a fluctuating viability as well.
So here as an example, I multiply occlusion by a range of altitude.
And in parallel, we can also mix another set, multiplying flow map with a different range of altitude.
And then we can add the result of those two sets together.
And additionally, to create extra chaos, we can combine noises with the Turing data.
On the right here, well, this is a standard Perlin noise with control option for scale and offset.
However, it can also be warped by the Turing normal to create more interesting patterns, as we see here.
Then we would also bring in various exclusion masks generated by previous tool, such as freshwater road or cliff mask, and apply that on top as well.
And for this example, that's what we would use as viability for the species.
So as we see, combining Turing data is at the core of the biome generation workflow.
However, the viability also drives other effects, like the species size.
In previous production, the asset size was just, well, it was limited, but it was also just randomly selected.
It had no coherence with the terrain or the likeliness of for a species to grow in a specific area.
Now our tool can handle multiple sizes for the same species.
If we take a step back here, there is various things that can affect the tree size.
We'll have small and young trees.
They will tend to be at the edge of a forest.
And the tall and old trees will be more present at the core of a large forest patch.
There's also other factors that come in play, like the altitude that can affect the tree size.
So a quick example of that here.
So how do we manage our tree size in the tool?
Well, we link the asset size selection to our viability.
So here we have a gradient viability on the terrain.
And we start with one conifer of 50 meters.
And if we add the second one of 40 meters, 30 meters, and so on, we see that each size will be positioned to the proper viability range on the terrain.
And this will give us a nice tapering effect at the border of our forest.
However, we have one more problem, and it is some kind of a staircase effect.
So to get rid of that, we can allow each size to scale up or down by a certain percentage, just to bridge the gap between sizes.
And then as an additional option we can also play with a random scale if we don't want to mess with our viability too much to create more chaos. And of course two trees of the same size are not necessarily alike so uh we can have several variation. In the example here we have a living tree and a dead tree variation and we're just playing with the probability of the dead tree to shift the balance between the two.
Let's take a step back once more and look at another phenomenon, the forest canopy and the ecological succession.
As I mentioned earlier, young trees will tend to be growing at the edge of the forest and then the older ones will be deeper inside, but there's also young regrowth possible inside the forest.
So how can we achieve that?
We said how the viability can affect the tree size selection.
However, depending on the terrain data that we use, we don't always end up with a smooth gradient on our viability, which can result of having our tallest tree at the edge of the forest, for instance.
So for this reason, we added the h parameter, which is basically just a sign distance field generated from our viability.
And while we have various options to control how it will affect the size distribution, we can either add, multiply, or interpolate with the vital T.
So we can easily tweak the level of influence it has, like this.
And by adjusting the age maximum distance on the sign distance field, this gives us a nice control on how deep the border of our forest will be.
And as a bonus side effect, by using a ramp on the edge, we can also profile the shape of our forest.
There's there's another important thing we need to control and um that is the scattering density. If our density is uniform uh well we might have a good spacing between our our small trees however uh we can uh we will have a really bad overlap on our large ones. And also the number of asset we spawn is a matter of performance of course. Uh the small trees they don't have the same GPU cost as the large ones so it is really important to keep a tight control on that.
A sample ramp here will give us that control.
By default, the density ramp is based on the size of our species.
However, we also have other options to base it on the age or viability if we have a species that don't have several size variations.
Then we can also mix in terrain attributes, like illumination or slope aspect to affect the density of a species.
So an example of that here.
And uh example of the same thing in game. Jumping to another feature now, uh some of the biomes we wanted to recreate add a lot of color variation. Here the grass and bush color is varying a lot in this uh reference picture.
So to do that, without duplicating our asset texture or material, we have the option to tint the scattered instance individually.
So the input value that drives the gradient color ramp can be either viability, age, or a combination of any terrain data.
And here in this example, we're using the water sign distance field data just to give a rusted tint to the grass growing in our wetland biome.
And well, the result in game here, that's where this grass color variation comes from.
The scattered entity also needs to have their own specific rotation.
By default, they have their forward axis oriented towards the terrain slope.
And this is interesting, because it allows us to do things like having this grass asset that we see on the left here leaning toward the water.
And that's because of the slope.
So if it was on either side of the river here, the grass would be always leaning toward the water.
Another example is a pre-bended tree trunk that grows in slope.
Unfortunately, we didn't do that in our game, but I wish we did.
It's kind of cool.
But we could have the system would allow it.
We did other cool things, however.
And well, not sure if any player will notice that in the game if I was not mentioning it, but this grass asset that we see here, well, it is oriented on the wind vector map.
So this is another orientation option that we have.
The wind map is just based on the overall wind direction, but it is fluctuating slightly based on the terrain shape as well.
So it might be a bit hard to see here, but when blowing against the hill, it will tend to flow around it a little bit.
Then now just to finish with the rotation options, in all cases, the asset can be horizontal or aligned to the tearing slope.
That's controllable with a percentage.
And we have rotation jitter on all axis.
We use that a lot on all our vegetation assets.
Now we have covered most of the parameters to control the NST generation itself.
However, the biomes are not limited to the asset placement only, because the position of asset can also have an effect on some of the terrain properties and it can also have an effect on the surrounding assets as well.
Here in this picture, I see four different things that the presence of those trees influence visually in their surrounding.
First, the terrain is covered with pine needles, so the terrain texture is affected.
We have a slight terrain elevation around the trunk of those trees, so the terrain height map would be affected as well.
We have pine cones and dead branch on the ground around the tree.
For sure, the shadow provided by the trees might encourage or prevent the growth of other species.
To do that in our system, After the entities distribution is done, we have the option of transferring some data back to the terrain from the scattered entities.
And we use this process for four different things.
Terrain deformation, basically just affecting the height map.
Terrain textures, terrain data output.
which is a mask that can be used in following species, and then a terrine color.
This is just a tint that gets mixed in with our terrine texture.
And all four of these are independent from one another.
Let's start an example with the terrain deformation.
We can generate a mask from the scattered entity's position.
And then optionally, we can combine it with the available terrain data, as we saw earlier.
For example, I might want to mask out any terrain deformation close to the road.
So I'd be using the road mask in this case.
And once we have our mask, we set the displacement height for the terrain.
Here it will be raised by one meter, and this will deform the terrain accordingly.
So this is the deformation we get from a user point of view.
I think this is a really interesting feature to have because most of the time in games, the trees are just sticking to the ground, they don't have any effect on the terrain around them.
But in nature, the tree roots will be lifting the ground a little bit and also by holding the soil together, that will limit the erosion a little bit and then create shapes like this in the forest.
Now, let's take a closer look at those three routes.
We will want them to blend seamlessly with the terrain.
To do that, we can generate a matching terrain texture underneath.
Once again, we generate a mask from the scattered entities.
And we set the number of texture we want to generate from this mask, select the desired texture from the roll down menu, which will actually fetch the available terrain texture from the disturb via Python.
And Then our mask grayscale value will determine which texture is applied where.
And well, we said the second texture here to appear where the mask value is 0.5 and above.
Once the texture IDs are sent to its true, this is the same kind of result we would get.
And now our routes are blending well with the terrain underneath.
Next, perhaps we want to add extra ingredients around those trees.
So what we can do is generate a new terrain data attribute from our trees.
But this time, this mask will be actually stored on the terrain to be reused as viability by the following species.
Once we're happy with our mask setup, we're ready to go over to our next node, Forest Rucks, in this case.
So we define this asset viability by using the ponderosa mask we produced with the previous node.
And as a result, we get those assets scattered around those trees.
And so the position of those will always be linked to the position of the other species.
So that's quite convenient.
If we go back to our Ponderosa tree node, we can also output the age data for a species, which will allow us to, for instance, to spawn new ingredients just at the edge of the forest, for instance.
Or if you guys remember, as we observed earlier, we can also use that to create the young regrowth effect for the ecological succession.
Then we would just keep adding further ingredients to build a full recipe like this.
And on one map of one kilometer square in the game, that's over 600,000 entities generated by the biome tool.
And for FC5, we had about 70 maps in total like this in the world.
One last feature.
This is Google Earth picture.
And the phenomenon we're interested in here is the terrain humidity, the color variation between the dry brown and the lush green.
So as we saw for the cliff strata color, in the biome tool, we also generate a terrain tint here that will get mixed with our organic terrain texture distribution.
And this gives us further variation, and at the same time, limit the amount of terrain texture we need to use in game.
Note that the neutral color for this color layer is an average gray, which allows us to either darken or lighten the terrain texture.
And here just a zoomed out view of the terrain in game just to see the texture and color variation generated from the biomes.
It's also worth noting that all the terrine texture and procedural tint can also transpire through the grass.
And that is because the grass shader will pick up the terrine color.
And while the amount of color it picks up is also controllable with the mask of the grass asset itself.
So it can be either picking up 100% of the terrine color, or just as a gradient, or only on a specific part of the plant.
And at the end, this is the data exported to the editor.
NST point clouds, terrain texture IDs, terrain height map, terrain color, and also a forest mask that will be used later by the fog and the wall map tool.
So in this section, I want to share some stuff that we changed along the way.
While things don't always go as planned, some ideas might be fine on paper, but might not be so good in the end.
So a first example of that is for our biome painter.
Initially, the plan was to support like a gradient painting, uh, so that we could blend uh, blend the biomes together. It is, it is supported in the Udzni tool, uh, because the viability system would, would kick in to merge all the, all the biomes together. But uh, from an editor and a user point of view, it was not such a good idea.
Turns out we had so much biomes that could be mixed together, it would have been a nightmare to debug.
So on the left here, we only have three biomes, and it gets really difficult to tell all the surface on which the red biome is painted, for instance.
We could have a mode to visualize one biome at a time, for sure, but it was great for the user to be able to see all of them painted on the terrain at the same time.
And really, in the end, that cross-fade blending was not needed at all to get good results.
So here on the right, even though it looks strange, this is the input format that we use for the biome painter.
Another example is the Terrain abiotic data generation.
We saw that at the beginning of the Biontool earlier.
But it is actually used in multiple tools.
So at first, we had a separate button to generate that and cache it on disk.
And then if there was a terraforming change, the user had to rebake it before generating other tools like the Biontool.
But what happened is that people got confused about when it was required to bake it, and as a result it was not always rebaked after terraforming change, which led to a different result than the real final result given by the Bell machines, which was actually rebaking everything properly.
Well, the reason why we separated this process initially was really just to save a bit of time when baking these other tools.
But in the end, this was an extra step that brought complexity for the user and it was not worth it.
So we simply decided to incorporate that inside the tool that required that data.
That way we're sure it's always up to date.
Finally, a conclusion, some lessons learned.
With great power comes great responsibility.
Always wanted to say that.
Procedural tool can generate a lot of data.
This gives us great control over performance, but also over gameplay and art.
On FC5, the art direction, they wanted crazy dense forests.
However, from a gameplay, well, gameplay-wise, it was not interesting at all because the AI and the large animals, they could not navigate in the forest.
So on our side, with control over the procedural vegetation distribution, we had to make the right call and it was just to ship with the most density without impacting gameplay.
Another lesson, make sure to design elegant tools that opens up possibilities.
A good example of that is our biome tool.
It is a system that allows so much possibility.
Honestly, I think we barely scratched the surface of what we can do with that.
And that's good.
Then make sure to keep things simple.
Well, any new systems are often overengineered.
And that is because we figured out each element of that system at first.
But once everything's in place, we have a clear view of the whole thing.
And we can most likely do a cleanup pass, and a simpler, more elegant design can emerge.
Then make sure to listen and observe your user.
They might prefer to have manual control over an automated process.
And a good example of that is our freshwater tool.
The rivers, they could actually carve their own riverbed automatically.
But it was optional.
But actually, during production, almost no level artists use that at all.
They just prefer to do the terraforming manually and then place the river.
So which leads me to my next point, like make sure to be flexible.
Initial plans are not always the best.
And then make sure to keep a good balance between control and automation.
Too much automation and really things can get out of control if you have many systems that are independent from one another, and then just changing one thing here is actually affecting something else elsewhere.
That might be really bad.
And on the other hand, too much manual control and things can become really time consuming and difficult to manage.
And after all, this is why we're building procedural tools.
Just to finish, I want to give credit to all these people for their small or big contribution to the pipeline.
And well, I hope you enjoyed the presentation.
If you have friends that didn't get the chance to get in, or you think that they might be interested to see the presentation, I'll be giving the talk again tonight at the Ubisoft Lounge from 5 to 6 PM.
So thank you, everyone.
Any questions?
Don't be shy.
Hello? Hello? Okay, there we go. Um, can you give us an idea of um, the resolution at which you're storing a lot of these masks and terrain data, like the ecotopes for example? Yes. Or the pylons. So the the resolution of of the mask is uh actually one pixel per meter on the terrain.
So I think that's about half resolution of the terrain itself, right?
Sorry?
That's about half resolution of the terrain itself?
Yeah, exactly. The terrain height maps is actually 50 centimeters.
Okay, cool. Thank you.
Hey, testing.
Incredible talk, awesome stuff.
Thank you.
I had a question about the point clouds.
Yes.
Does that, what are you writing out of Houdini's like a big file full of like vector data and then the engine reads it in?
Yeah, well actually we have a proprietary format that we call GameX and it's used across different engine at Ubisoft and yeah it's just a file format which will store the points and the position and all the attributes required for the engine.
That's cool. Alright, thanks.
Hey, quick question about the users.
I was wondering if you had a system to compensate for the errors made by the users in terms of the terrain.
Let's say, for example, you were talking about those squares of like one kilometer, one kilometer.
What if I sculpt the edge there and I don't have the other check out, because I assume there's some source control.
What if I change the edge of this terrain and the other edge doesn't match anymore?
Or I put a river there or a lake and it doesn't match, like you rebuild that afterwards or what?
Very clever question.
Well, users tend to do this kind of stuff.
Actually, the tool in the Insta will prevent you to paint too close to the edge, just to avoid getting seams.
Let's say if you would just load one map and then raise the terrain, and then load the next map, and then you would have a really big gap between the two.
But actually, you're not allowed to paint to the very edge of the map.
OK, thank you.
Hey, can you give us an idea about how many people and about how long all this work took?
To develop the tools?
Yeah.
Good question.
Well, we were like one and a half person over like two and a half years.
Then at some point, the tools were fairly stable, but we just kept adding new tools over time because some were already quite stable.
And yeah.
Cool, thanks.
Hello, thank you for your incredible talk.
I have two questions.
One is about the cliff.
How did you prepare the mesh?
Did you have module cliffs, and then you input them into the cliff tool or something?
How do you make the cliff meshes?
Well, as we said, we just start from the terrain mesh and then just modify the geometry from there.
So, at first, the input mesh is just the terrain.
We delete some polygons of it and just keep the actual slope range that we want.
And then, by doing a geometry operation on that, extrusion, displacement, this becomes our actual mesh.
The detailed parts of the rock surfaces, those were all displacement, I guess?
Yeah.
Oh, okay.
Thank you.
And another thing is about the rivers.
When working with height fields, it intends to...
Rivers go from up to down, but then sometimes when you do the wrong path, it goes down to up.
Yeah, yeah.
How do you control that?
uh, it was up to the user to uh, make sure they, they set up the, the terrain properly to have like the, the, the water flow down in a, in a proper way. Uh, it was not a big deal if, well, we made sure that this, this, uh, didn't happen.
But if it was the case, it wouldn't break anything.
It would be weird on the flow map itself.
Then you would have a point where the water would be flowing down in two different opposite direction.
But yeah, we didn't have any check system to avoid this.
We just, like the level artist, they just did a good terraforming job and make sure it was always logical.
So it was basically like checking on the, like walking on the terrain and checking that nothing was really wrong.
Yeah, and we also had the debug tools to check the actual, well, to display the flow map direction so it would display arrows on the water so it was easy to visualize like if it was flowing properly or not.
Okay, thank you.
Welcome.
You spoke a little bit about avoiding locking in anything in the terrain so that the iterative process can continue.
Just wondering a little bit about artificial things like roads and buildings which require certain types of terrain to be placed.
How do you deal with that workflow and whether you need to lock in the terrain before adding those?
Yeah, uh, well, any, any terraforming, uh, was, well all terraforming was done in the Edster and yes the, the roads would also affect the terraforming, but that was like, uh, done in the Edster as well, uh, because we have the, the road tool that, it's actually an Edster tool. Um, but uh, then for the procedural, uh, the, the, the, the, the, the, the, the like the procedural tool would receive all the terraforming, well the height map would be extracted with the terraforming of the road and any like flattening for a location to set up a house and stuff like that.
So if you're planning a village, the planning would be completely different depending on the terrain location.
Would you plan the village after making sure everything is finalized?
Sorry?
Would you plan a village layout after you make sure that everything is finalized?
Um, I'm not sure I understand, uh, perhaps we can, uh, chat afterward, uh, more in detail.
Okay.
All right.
Well, thanks everyone.
