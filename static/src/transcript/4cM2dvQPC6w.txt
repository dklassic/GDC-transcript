Hello, my name is Ian Livingston. Thank you so much for joining us today.
Today we're going to be discussing UX.
We're going to start by just doing a brief introduction of who we are.
Actually, the panel, right? So, playing the middle.
This panel is about looking at how UX cross-cuts all the different disciplines within our industry.
So, it's about balancing the creativity, the design.
the business and the production as well as the science of experience.
So that's what we're going to be discussing today and we have a number of great panelists which are going to be helping us with this.
So let's introduce that.
Who am I?
As I mentioned, I'm Ian Livingstone.
I work at EA.
I'm the Senior User Experience Researcher up at EA Canada in Vancouver.
I manage a team of researchers up there.
We take care of all of the projects that are coming out of Canada.
To my right we have Cory May. Actually, let's start with John, sorry. John is from Warner Brothers. Warner Brothers Interactive Entertainment. Right. John is a user researcher, has a ton of experience and has worked on a number of different platforms and genres in the many years that he's been here. So you want to introduce yourself, John?
Yeah, hello. So yeah, I'm currently working out of Warner Bros. Montreal for Warner Bros. Interactive Entertainment.
I did a quick single decade at Ubisoft before moving over to Warner.
Working mostly, I spent a long time on Assassin's Creed with some of the other fine gentlemen on this panel, but did a couple of other interesting projects while I was there and now working out of Montreal on some other cool stuff.
And I'm here to represent the Games User Research...
side of this equation of the iron triangle that we're going to talk about.
Yeah, I think that's about it. Maybe it's worth mentioning that GamesUR, I think, as well as all the other problems here, they're not solved problems. And so I'm not representing all GamesUser researchers, I think it's safe to say. Other people will have different opinions on how they would approach similar problems. But I'll do my best to make those of you who raised their hands when he asked who the researchers are, I'll do my best to make you guys proud.
To his right we have Corey May. Corey May is a narrative director at 2K. Advocate for the player experience. Corey, you want to introduce yourself?
Sure. So...
Like Johnny, I spent many years at Ubisoft. I think 12 years.
Then I moved to a place called Certain Affinity, and then most recently I have started working at 2K up in Novato.
And Johnny knows I've always been a very big fan of user research, of user experience in games.
I think it's the language that we developers use to communicate with the players.
I believe it serves a critical function in game development.
I think too often it is ignored, and so I just want to let everyone out there know that people on the production and creative side do very much care about what you specialize in, and we want to find ways to work together better.
Next we have Alex Hutchinson, designer, writer, producer.
Freelance.
Yeah.
So I'm at the moment of, I guess as of Friday, a freelance creative director, which is one step up from homeless person.
Before that I was creative director for many years at Ubisoft on Far Cry 4, Assassin's Creed 3.
Before that I was a lead designer at Maxis, on Spore, The Sims 2, other games like that.
And yes, now I have a PR rep from Ubi staring me right in the face from four feet away.
So I will speak very guardedly.
Next we have Chris Lang. Chris joins us from Bungie.
So yeah, I'm a producer at Bungie. I did a short stand at Obsidian Entertainment for a while.
Then I transitioned to platform and services space at Microsoft on Xbox live, focusing on UR and data telemetry. And then I transitioned back to Bungie where now I'm focusing mostly on UI. So I produce a few of the UI teams at Bungie.
Okay, so just a quick overview of how we're going to go through this panel.
There will be time for questions at the end, but there's three topics that we want to jump into and dig on.
First one we're going to talk about user experience in games, understanding the player, and then finally feedback in the creative process.
So we can jump straight into that first topic.
So this is obviously going to be kind of a general topic.
We're going to talk about what user experience is.
Obviously, there's a lot of people who know what that is here.
But when you're looking at it from a different perspective, it can actually be quite interesting to see what user experience means in people's day-to-day.
So our first question that I'm going to pose to the panelists here, and I think, Alex, you would be a good person to kick this off.
What does user experience mean to you in your day-to-day?
Yeah, so I apologize in advance, this is probably the most broad answer that we'll give all day.
What is the thing we're talking about?
But for me as a creative director, it's really the culmination of all of the different disciplines that we have in the game.
So my job essentially is to try and get people who are much smarter than I am in different disciplines, who have great levels of expertise in different disciplines, to stay focused on the same idea and expressing the same idea throughout the game.
So that when the player touches it, when they experience the game, that it's consistent and it actually follows through on that idea.
So it's everything from, you know, if we do it perfectly, which we never do, but it's everything from, you know, the first boot up sound that you have in the game to the first button we ask you to press to the consistency of the controls to what actual interactions we give you in the game.
You know, something that always impressed me at Bungie, for example, on the original Halo was that sound, that sort of operatic, I'm not going to ‑‑ I embarrassed myself by doing it. But that sort of rising, you know, Christiano voices that starts at the start of the Halo games.
It meant you knew it was Halo. It gave you a sense of epicness, a sense of awe before you even started the game. And trying to get that feeling and whatever it is in your particular game and drive it through the whole experience.
So how important is feeling for user experience?
I think it's really important. I like it much more than, I mean we've got data people here so we should all be afraid. But I like the soft data as much as the sort of really hard numbers. The idea that you're driving for a human emotion and you want to get that back and it's very hard to prove that you have it with a graph. But if you can get it, you can see it in people's faces and you can feel it in their responses. And that for me is the most important bit in terms of picking features and picking elements.
I would definitely argue that both are equally important, right?
The joke that I said to some new people when they were coming on the team back in the day was just because people walk out of a movie and they're like, oh yes, I understood that plot doesn't mean that they enjoyed a movie, right?
So having both the hard and the soft, the qualitative and the quantitative, both contribute to the sense of validating your vision.
For sure.
I have a question for you. A lot of times when we do user testing or play testing, it comes down to numbers. They ask people on a scale of 1 to 5 what did you think.
If I had my way, I would take the numbers out.
And you can maybe keep them on your end, but I think any client-facing paper, like, would you be down with trying to get rid of the numbers?
I feel like we have the same problem a lot of times with review scores, right?
People just rush to the number, and they don't necessarily read the review, and I think that can sometimes happen.
When you compile this very well-considered, well-researched, well-put-together, thoughtful document, and everyone raises down to the number, and what the fuck do you do with the number?
It says 4.4. What's a 4.4? No one can do anything with a 4.4.
So I agree that there is sort of an important difference between formative testing and summative testing, right?
The idea of like giving a score versus, hey, what's, you know, in the general sense, how does this feel and where is it going and how do we move forward?
Yeah.
But I think Chris would certainly argue that having a number moving, you know, it's important as you push a product through to be able to see that there's some sort of evolution.
And certainly for us, an ROI on the service that we provide that says, well, this is moving up.
Absolutely in a vacuum. If you work very loosely with a research service and you only test once every six months and they show up and they go, You got a 3.9, it should be a 4.1. There's minimal value there.
But having some sort of summative result is useful, particularly let's say for example if you're comparing across items.
Then now you can say, oh, well maybe we need to invest more in this one or maybe we need to adjust that.
I understand your gut of like, but if everybody just races to that one fund number and then they throw the rest of the report out, that's wrong?
But that's you doing it right.
What is your in-game economy has a 3.8?
That doesn't tell me anything, right?
I want to look at people's actual responses.
So I would say it could point you in the right direction of where to look and say, okay, well, this is the lowest score of all of my systems.
And then you go and you continue to dig deeper and you can look at metrics and say, well, they're not engaging with the system. Or you can look at the qualitative and say, oh, they hate the system. And so at least it can give you some direction. But you're right. It shouldn't be a final answer. Nobody should walk around going, my game is a 3.9. I know, but they do.
The worst thing is it's like, don't, don't, don't do that.
Good discussion. We have other questions. Okay. So, Corey, kind of building on that, when you're In your opinion, who do you think is ultimately responsible for providing a great user experience?
So, originally, my answer to this question was it was the creative director's responsibility.
Whoa, whoa.
I've just, I, I, that said, I'm pulling back a little bit.
I think that, you know, since games are intensely collaborative, or at least should be, It's really everyone's responsibility. It's a shared responsibility.
Look, at the end of the day, you have to accept some responsibilities as creative director.
You get, like, all the accolades. You've got to, like, own some of the responsibilities.
We get mostly dance rights these days.
But I think that everyone needs to be working together to ensure that the user experience is a smooth one.
But yeah, you have to balance that against the other thing.
There needs to be some responsibility because if it's like a whole group of people, if there's suddenly like 12 or in games that we've worked on like 40 fucking leads, then the buck has to stop somewhere, right?
There has to be a person calling the shots and like making the decisions and assuming responsibility.
Otherwise, you run the risk of getting stuck with something that's like designed by a committee and I don't think anything good has ever come of that.
So it's a balance, right? There's no easy answers, I think, to any of this.
And like Johnny was saying earlier, I don't know that my answer is the right answer, or the answer that everyone should take, but I do think it's a shared responsibility by all the leads, eventually ending with the creative director.
Or if you work at other places, maybe it's the producer, actually, because more and more these days, and that's a topic for another day, I suppose.
It's a totally different summit.
It's a sad summit.
So, actually, kind of following up on that one, Corey, Chris, when you're sitting down and you're looking at what's coming in, how do you go about deciding where you need to focus the efforts of your team and where you need to kind of start sacrificing that vision?
So I think like...
Over the course of development, there's always going to be multiple things that are competing for attention.
And really, it's going to come down to what are the problems that you're trying to solve, and what are you trying to achieve with the product?
And that can be defined.
It's usually defined by creative leadership in some capacity, but the hard part is conveying that to the team.
And so part of my job is to work with creative leadership or creative directors.
and understand what is the problem that we're trying to solve and what is the responsibility of this team in that space. So for instance, like Bungie, we have a laundry list of features for the UI team. And I spent a couple hours or multiple hours I should say, talking with our creative director and just getting him in a room and saying, hey, why is this thing important? What is the why here? And that's going to frame the sandbox that the team works in. And so If you're making a tradeoff between two features or between two different systems, you're going to say which of these is more important for that ultimate goal.
And it's not always as black and white as that, but really it's going to come down to that.
There's going to be some compromise, but ultimately there's going to be one that's going to be more important to the experience.
So when you're looking at trying to figure out what's more important, do you have things that you're using to try and identify?
Absolutely. So we're looking at community research, user research, internal feedback, also from a protection standpoint, risk.
associated with different features like is this thing going to ship on time. So all of those things play a part of the conversation and ultimately it's the responsibility of the creative leadership to make the decision given the data that we can present.
Yeah, and I think it's really interesting in the current climate where there are a lot of projects that have very long life cycles that are alive for many years after initial release, that there's a different, I think, way to calibrate the features that you're building based on, is it a first product?
You know, are you making something new or the initial game? Or are you keeping something alive?
You know, like, I mean, there's been a lot of, you know, information, say, Valve, for example, or Blizzard, when you're maintaining a game over many years.
You deal with feedback from users and the situation much differently.
Sometimes on a new game, the argument is, I think, we've had this conversation many times, we think this would be fucking amazing. That's the logic, you know what I mean?
At the end of the day, you don't have data yet because it doesn't exist and we'll use people like Dankov or Ian to go through it and try and get some sense of it before we put it in the box.
But a lot of it, you know, having 20 people in a room every, you know, Every couple of weeks is never going to give us the same data.
Sometimes you have to back yourself to be like, no, I think this will be amazing.
A good example from Bungie is the controls for the vehicles.
This was testing terribly for years.
I remember Hamilton back in the day, the producer on Halo 1 and 2, saying, they hate it, they hate it, but it's right.
You know what I mean?
Everything in the game controls the same way.
It's consistent controls, it's consistent controls.
It worked in the end, but if you'd just gone based on user feedback, then you would have killed the feature.
I'm realizing we have a blind spot on mobile. We're all console guys but mobile also. I'm sure anybody in the room that's working on mobile now is like yeah, of course. We do most of our research in soft launch. That's where we get, like, you know, on mobile games that's where they get the bulk of the info. I mean, certainly they do usability ahead of time but there's a richness of data available to them where they're able to pivot very quickly once they're in soft launch that, you know, box products or software service can't really, can't track as quickly.
Cool. All right, moving on.
Let's move on to our next topic, understanding the player.
Okay, so as we know, players are both our biggest customers, obviously, but also our biggest critics.
And since I hope we can all agree that games are both art and entertainment, the understanding that we develop of those players is absolutely crucial to the overall success of the games that we're making.
So.
What?
This is the one on purpose.
Corey's going to make me mad.
Oh, okay.
Because Corey's going to answer this one first.
What?
Oh, right.
So let me ask the question.
Yes.
So this is just an abbreviated version.
So here's the full question.
What has contributed most to your personal understanding of players that you feel others most often overlook, misunderstand, or misuse?
So I think I'm answering this question right.
So.
The thing that's been big for me, and yeah, now Johnny will get mad, is that while I appreciate the process of user testing and user research, I feel like we are kept as developers away from the players, and so we never get to communicate with them.
We get a document that tells us what they thought. It doesn't often do a very good job at getting to the why. You'll get like a single sentence or a sentence.
I would love to be able to communicate with the players after the fact. So I won't be poisoning your data, but I'd like to sometimes get a better understanding of why they're making the selections that they're making or why they're responding to a feature or an aspect of the game the way they're doing. And they absolutely won't let me do it. And I don't understand why. I mean, maybe The game's user research is in the audience right now are cringing.
But why? Explain to me. What are you so afraid of?
Your instinct is right. Your instinct is I want more context for the answers.
Yeah, I want to understand my audience.
The point is there is a certain amount of rigor that is involved in the process that needs to be maintained.
And that if you roll in and you're like, hey, I'm Corey May, the guy that does all the cool stuff that you like, and they go, oh, never mind that.
You know what, actually I loved everything.
But that's not going to change your report though, right?
They've already shit all over the thing in the report.
If we were looking for a more context, and you talk to me ahead of time, like, hey, this is something that I really need to understand better.
Or if you get preliminary data and you go, all right, dig deeper on this, then we can work together on doing it in a way that is properly structured.
And then, because if you do it once with one guy, that's a single data point, then you fall into the trap of a question we're going to get to later, of like, doing it wrong.
No, and I know, and you know how I feel about that.
Then we can start to get, okay, well, if this is the question that you want, rather than one person, we can formalize the process of gathering the data that you're interested in and get you more substantive and more useful and reliable information on the topic that you're curious about.
But don't you think I'd be...
Rather than you rolling at me like, hey, I'm the guy who made the thing, tell me what you think.
I think that that initial conversation could also benefit you as you reshape the test.
We should have that conversation, not you.
Why can't we involve... your answer is like not doing it for me.
Because if I'm going to do it wrong, is the short answer, you're going to ruin everything.
But the reason you hire a games user researcher is to do that.
I'm just trying to add an extra layer of data, and your job is done at that point, right?
I'm not poisoning your...
If you still need more context, I would argue that my job is definitely not done.
If you're walking away from research results and going, I still don't understand what my problem is, then I have failed as a researcher, and we need to have more interesting conversations about what you're looking for so that I can deliver results that are more useful to you.
Or I could just talk to the people.
Even if you're not engaging with the community in a formal way, where it's like, hey, I'm the creative director, I'm the lead for this team, right?
Engaging with the community in an informal way, just playing your game, right?
In the case of Destiny, right?
Playing Destiny with everybody, it's a multiplayer game, that provides a lot of insight that, or context that you don't get just by looking at research results.
And obviously the idea of getting good guard is you have a lot of context in that space.
But I think there's something to be said for the organic nature of those interactions.
We could all wear a fedora and they wouldn't know who we were.
I can't stop you from going on NeoGAF. I know you're going to go.
But also another thing that kills me in this context is even with that, even when we have a feature in test and then we get data back and we can or can't speak to them, the thing that kills me is most of the time you're testing an unfinished thing.
So you're taking something in that you know is broken and then they're saying, this sucks and you're like, ugh.
Yes, you know, yes.
But the goal is to find why it sucks.
Well, I mean, if we showed the Marvel movies, everyone's watched those terrible YouTube videos of the Marvel movies without the special effects of like some, you know, mediocre buff dude jumping off the back of a utility vehicle, you know, and then like without the effects and the sound and all that sort of stuff, thinking, oh, this is the worst bit of cosplay that I've ever seen.
And, you know, like testing at that point is terrible, but we often get stuck in that point and we have no choice.
I think there's a happy medium there, right?
To both Kari and John's point that there's...
This is why I think a lot of user researchers will argue that having a creative...
in the room, well not in the room, but there when a session is happening, so that they can riff back and forward with the researcher and, you know, point out the things that they're interested in is something that is really important. And I think a lot of times this...
Alternatively, even the stuff not to be interested in.
Yeah.
You know, if a player gets stuck and they're like, no, don't, and they're like, okay, we'll just fix it.
Yeah, I think there's a lot more to be said about the overall collaboration on how it can be made more useful and still maintain that rigor.
I think one way to improve collaboration is to let me talk to the participants. I feel very strongly about this.
Okay. Moving on. All right. So this one, this one is to Alex.
Alex, should a game be built for a specific player base, or should a player base be built for a specific game?
I think you can discover new audiences, and that's one of the joys of a game.
You know, Spore, we built Spore.
We were in our hearts making a game for adults, doing adult things in adult-appropriate environments.
and it hit really hard with kids. And I guess that pre-phase, like a lot of stuff that happened with the younger audience later, but like the 12 to 14 set. So you can discover people as you go and that's amazing and I think that's one of the most rewarding parts of building a game.
Finding any audience is super rewarding. Sometimes you don't. But I think it's important to have in your head a clear target of who you want to enjoy it. And I don't mean on a, you know, males.
18 to 35, which is horrendous. Anything that's undirected or unfocused doesn't end up particularly going anywhere or trying to finish and express an idea properly. We often get bad feedback from the marketing department saying who is our target audience and they'll say everybody.
This is not useful information. So I think it's important to sort of know who you're, or at least along with what idea you're trying to express, who you think would enjoy that and then you can use a testing process to figure out if it works or maybe you found a new audience. Chris? Yeah, so I'm going to take the cowardly middle of the road approach. So I think, you know, I think if you look at it from a business perspective, like, you're obviously going to want to attack a preexisting player base because it's going to provide minimal risk, right?
You're going to, if I'm making a first person shooter, I'm going to target first person shooter players, right?
But I think the novelty of creative design is what allows us to define those new or create those new player bases that then lead to the longevity or the long-lastingness of our game. I think if you went solely with the we're just going to cater to this one or these few player bases, it's really easy for a competitor to step in and say, okay, well, we're going to do the exact same thing.
just slightly differently. But it's the novel approaches that help, you know, turn your new game or your game or move that preexisting player base into a new player base that then you don't have many competitors in that space and you can then ride that train for much longer. You know, I think I look at, you know, like Dota from Warcraft 3, right? Like that spawned a whole new genre, a whole new player base and now there's more competitors in that space but for a long time, like, yeah, that was the only competitor in the space.
So successful business model.
And so I want to take like the idealistic slash naive slash fundamentalist approach which is never mind all of that stuff and like if you believe strongly in what you're creating it will find an audience. And your mention of Dota is actually really interesting to me, right? Because I don't think when they were coming up with that there was any like consideration of, you know, they were like this is a cool idea.
It organically grew out of that. You can argue that Riot being the geniuses that they are took a look at that and shaved off the rough edges.
There is an argument ‑‑ I love League of Legends.
I feel like the genesis of that came from the heart.
It didn't come from a lab or a cynical consideration.
That's just saying the audience is me. They still did it.
They just said ‑‑ there were a bunch of dudes.
They did the strangely authentic 18 to 35‑year‑old dude.
Yeah, but I mean it was specific to them, right?
It was like, what gets me excited?
If this is getting me excited, maybe it will excite other people.
But also audiences evolve, right?
So everyone these days forgets, but The Sims was bought by guys, hardcore gamers first.
The first audience was hardcore gamers because they were falling on Sim City.
They were super into it.
Then they all went, it's kind of interesting, I kind of get it, but it's not really something for me.
They passed it across.
Then the audience went sort of, what it was at the time, but the hardcore female audience at that time.
Then it migrated across from them over time and ended up going down to a very young, majority female audience.
That's where it sort of ended for a long time, but that audience went through multiple phases over its life cycle.
It's also interesting talking about the role of defining your audience ahead of time or the creative. I would also argue that that evolves throughout production. There are certain points where you want to have a clear definition because it will help you in a different way rather than later on where...
The use of personas is something I find interesting, for example, where it can be really useful very early in a project. But I found most of the time when I've used it later on, like when it's like to try to find test markets, that it's like, okay, what, you're just giving me a demo information. Like it's not really a persona that you're using anymore. And so certainly the use of defining your UX audience varies from preconception through to like gold or even beta.
Cool. All right. Next question. This one's to you, Johnny. I like this question. I think this is one of my favorite questions. When has your knowledge failed you, causing you to miss something big or make a poor decision? And how would you avoid that now?
Right. I think I bring this one back to the idea of continuously maximizing context.
This is a mistake I made on one of the games I was working on back in the day. There was a system, it was like a den defense type system. And what game could that be, Johnny?
But the problem was I didn't fully understand the context of how it would fit within the game flow and I tested it on its own and this may come as a shock to some people but it tested really well. People enjoyed it. And so, you know, it got the GUR stamp of approval like this is a fun thing, cool, moving on.
And then it was only later when I realized exactly how it fit into the overall macro schematic of the systems where the way that it was sort of presented in the game, um, broke that down a little bit and the context of it broke it.
And so because, you know, if I had been testing it properly I would have had them playing the regular game and even though that system wasn't integrated I would have done a hard stop on what they were doing like do this now and force them that way because that was the way eventually it would be in the final product. And so just by lacking...
I ended up telling everybody something was fine and I got a very angry phone call when the reviews for that game came out of like, hey, why didn't you spot this?
So again, going back to making sure that you understand the larger vision and probably that was a conversation that if I had had earlier with the creative director on that one where he explained to me what his end goal vision rather than just talking to the designer of the specific system who was like, this is how it works. And I'm like, cool, I'll make sure that they understand how it works. And I never took that step back.
And so that was one of my big like whiffs.
So let me think. I think that once upon a time, there was a I would get defensive with some of the results.
I would be like, it's wrong, or they don't know what they're talking about.
I think this can be both a blessing and a curse.
It's just not in yet.
They'll understand later when everything's online and the game is more feature complete.
I think that that was a mistake.
I learned my lesson, which is to pay more attention to the data.
If you see a trend of people not liking something, or not understanding something, or not appreciating something, it's very dangerous to put it off.
It'll be better in the next test, they just don't understand yet.
And to be a little bit more proactive, to get in front of red flags.
and warning signs. The other thing, and I think Johnny would be okay with this that I've realized, is that sometimes you want to be a little bit more selective in terms of who the audience is that you're putting together for testing. So one of the things that Johnny and I had started developing at Ubisoft before we departed was something called the narrative review process because we found that user testing with kids off the street was not providing us with very useful feedback when it came to story testing.
We would basically get a thumbs up or a thumbs down, I like it, I don't like it.
And that was it.
And sometimes if you want to dig a little bit deeper, it wasn't going to happen with these kids.
So we put together something with the other writers and narrative people inside the studio where we were doing user research, but we were using people who specialized in the craft so that we could get more detailed feedback.
And so we had a very different looking...
survey that dove a lot deeper. Johnny actually let me talk to the participants in that particular instance. But again that was very targeted in special circumstances. Yeah, so.
And we found that it was.
It forbids you forever from speaking to your colleagues.
Yes. So he at least, you know, allowed me to do that.
And it was really interesting.
And I think we could have done even cooler stuff with it had we not departed.
But so that to me something that I think is at least worth exploring, I don't know if it messes things up, is to choose your audience for the test.
And I don't necessarily mean choose a sympathetic audience.
Choose an audience that can speak to the stuff that you're testing.
So you identified your target audience?
Well, I found people that could speak to the topic, not necessarily people that would like the material, right?
So it wasn't necessarily a sympathetic audience, it was at least one with a deeper understanding of the subject matter.
It's similar, for example, to when you're working on a sequel, you're obviously going to run some studies on people that are new to it and people that are returning from the previous ones.
So it's similar, yeah.
So we can do the same, right, which is like people that have experience with narrative design versus people that are, again, kids off the street. Because they're often kids off the street, aren't they? Not literally. Never mind. All right. Next question.
Okay. Moving on. Moving on. Just leave that one. Okay. So we've gone through our next topic. Feedback in the creative process. I think this is I think this is probably the most interesting one.
I think a lot of the conversations that we're having right now are kind of ending up on this topic, like how does feedback work?
And I would feel that I'm pretty safe that everybody would agree if I said that everybody on a production team has an opinion and there is a huge amount of feedback that comes in for a game while it's being worked on.
And this feedback can have an effect on the team's morale and it can also be really noisy.
It's hard to cut through and get to what's actually important and useful.
So my first question, and I think this one's going to Alex.
What is the impact of and what is the best way of managing negative research or data or feedback results on that development? I think it's...
central to the job of the whole leadership crew on the team.
It's probably the hardest thing that you can do because as Corey said, you need to be open. You're in this really vulnerable state, right?
You need to be open to negative feedback and you really need to listen.
You can't let it destroy you because then you go home and you don't make a game.
You know what I mean?
So you have to be in this horrible friction state of like listening and then going for a drink and telling Corey that it's okay, we're going to get there.
We're going to, we're going to be okay. And you know, we would have throw down fights and, and, and, and not in, not in an aggressive way, in a sort of upset way.
Do you know what I mean?
Because you're really trying to wrestle with the idea of, is it junk?
Have we made a really bad decision and we're making something poor?
Or is it unfinished?
Or is the audience not understanding it correctly?
And so everything we're talking about are these ways of wrestling with the problem of where, honest to God, I know I'm in this room, I'm probably very sympathetic to this idea, But honestly, it always fascinates me that the audience doesn't think that a game team is a bunch of people trying with everything that they have to make something cool.
And that the only people more upset than the person yelling at you on Twitter if it isn't good is the people that spent three years of their lives making it.
So it's just a puzzle when you see people.
It's horribly wounding. I've seen a lot of people have really difficult times after not just the release of games but after reviews of features and that sort of stuff. You need to still stay open to the feedback because otherwise you fail in the other direction and you guarantee that it won't work.
At a much more granular concrete level, I think one of the ways that some of us had solved this was really integrating user research into the processes of the dev team. Making sure that you are completely integrated. It's not a pull for the team to use your results. For example, we use JIRA at UB and we would All the results would go straight in, they would go to an approver who would look at the research feedback, leave a comment, put it into the next guy who was going to have to write about it, have to fix it and that would get sent to whoever and then go back to the research team. It was a much more integrated process rather than the way when I first started doing research ten years ago which is here I wrote a thing that says your thing sucks, bye, I'll see you in a month. I think hitting the second half of the point I wanted to make, I got a bit sidetracked by remembering people being upset.
is that you know that that's the job of this interaction with the user research group is to try and get some objectivity on it because it isn't just good if it's all emotion and all feelings and all response and your personal belief about something versus another team member's personal belief. You want to get some distance from it so hopefully you can be like Corey said I feel very strongly about this and then you have to decide whether you keep pushing on it or maybe you bow to the pressure of whatever feedback you're getting and modify it. But The job on the creative side I think of getting all this data is to try and bleed some of the emotion out of it so you can be objective and know where to make your stands and where to make it easier.
I also have a bit of practical advice for the people that have to put these things together so hopefully it will help is that if there's bad news, try and get it in front of people as quickly as possible.
If you hide that stuff and then it leaks out, it fucking poisons the team.
I've seen it less with user research because they've been pretty open, but mock reviews will happen at a lot of places these days, and no one talks about it, but I guarantee you they are going to find out.
And if it's being held from people, it will start to feel like a...
The publisher, the developer, whatever, management has given up on the team.
So you may intend to be shielding them from something, but if you hide it and it leaks out, it is interpreted as like you've abandoned us and everyone gets very upset, morale takes a terrible hit and people become nonfunctional.
A long time ago, it was best practice. That report goes to everybody.
Yes, I see it.
Because the idea that you think you can pretend that the people working on your game don't know the health and the status of the game, it's dishonest and it's a mistake.
Don't hide stuff.
It's a very, very big mistake. We can't address issues if we don't know they exist and if they're just coming up in whispers and we don't have a way to validate it, it's very bad.
So I don't know, someday some of you may have the ability to decide like who gets to see what and I think Johnny's right, err on the side of over sharing. It's necessary.
I talk about using research results as a platform for communication. Like even bad results as much as good results.
One of the things that Like I'll say the opposite of everything I just said, but I'll give like a six hour head start to a creative director or producer and be like, listen, man, this is cutting out.
Fair.
That's just I want to start to think about it.
And I want you within an hour of me sending these results that you can send a bullet point like of an action item list.
Like we got it.
Like we know this didn't work.
We have an action plan.
We're going to go into this.
That's going to be part of our next sprint.
Oh, this was great.
We expected that.
We worked really hard.
Thanks for this team.
And using research results as a platform for really open communication to drive the team can be super, super helpful rather than the opposite.
Where if you obfuscate it and you try to pretend like it's not happening, it quickly turns toxic and then you get a bad relation with your research team, then you have less data.
And then it's very quickly for that thread of the sort of internal consultancy relationship to disintegrate if you don't handle it nicely. I want to bring Chris in. I was going to say you were advocating for transparency with research data. Do you ever worry that like, because bad results do not always mean bad things. Do you ever worry that like transparently saying, or transparently saying, There's this piece of data and it appears bad and everybody is going to interpret it bad. That's the wrong thing to do because really it's not bad if you have more context.
You contextualize the results by saying, look, ignore this one thing because it was like the build was buggy, you know what I mean, versus, oh, don't worry about it.
It doesn't exist.
If they're like, it's going to be okay.
If they say this is a bad data point, here's a very clear reason why. You'll see on the next test it will go back up.
I think that's okay. Ideally you're working with people that are mature and responsible enough not to go into full on meltdown mode if they see a negative piece of feedback.
Which I know is sometimes asking too much and I have been known to spiral out of control. I know.
Obviously when that happens it's because I'm right.
Cory was a fan of standing behind my desk and yelling at me while I typed.
That was one of my favorite. It was only for about three years.
If he would just get a drink in me it would be okay afterwards.
That was just my way of saying I needed a break.
Assassins don't ride on boats. That's a pirate.
I still think it should have been a pirate game.
Okay. Moving on. It was entertaining. I'm sorry. Okay.
Next question. Honestly, this one could go to literally any of you and I'm kind of scared who to ask now. So let's go with Johnny. What's your worst that's not how you use data moment?
And let's keep this short, okay?
I mean, look, there are, and I think Celia's published a couple of things on how not to do it, of like, you know, cognitive biases that will impact the way that you interpret data.
And, you know, there's stuff like focusing on one bad data point, which I think we've all seen several times where somebody, you know, or the confirmation bias, there's a lot of these things that can come in when you're looking at how, like, oh, God, no, don't use that.
Don't, please don't do that.
Or like, you know, you guys have mentioned like, oh, if the data doesn't look right, throw it out. Is another one where it's like, no. If you don't agree with it, you shouldn't throw it out.
You should look at it harder. Sometimes the data will say something that a person doesn't want to hear. And rather than accept it, they're like, oh, you did it wrong. Can I tell a funny story?
Let me tell a story as an unemployed person. My favorite meeting of this and it involves Dankov. It's a happy story.
One of the beauties of a franchise is that you have lots of data points.
Usually on a game it's the first edition of a game.
Even if you get data of what people like and don't like, it's very hard to draw long-term conclusions.
Your sample size is small.
On big franchises, and Yubi has a few, we have many years of releases, often with evolving mechanics and different systems.
But one of the biggest challenges for me was when I saw Dankov present a slide where he'd gone through all the different mission types in a particular franchise.
And had gone over, you know, over like five or six years and seen, you know, the five or six different mission types that we often use and had pretty much, you know, a graph categorical evidence in one, you know, with enough sample size, enough data to say this particular mission type in this game, in this franchise is despised by all players all of the time.
It was like everyone thinks we'll use the horrible numbers but 1.5, 4.1 and then 1.
Across seven years.
It wasn't like a blip.
It was very consistent.
We were in the room and this is something that the teams, because we're talking about teams and data points, but there's teams and data points and marketing and publishing and all kinds of other fun people involved in this discussion.
The management looked at the graph and there was silence in the room because everyone else was just like, thank you.
Thank God we have the evidence.
It's like Watergate.
We have the tapes.
We can take it out.
And management leant forward, tapped the microphone and said, this graph is outrageous.
And I thought, it's amazing, the graph can't be outrageous.
You know what I mean?
Like, the interpretation of the data.
The sample must be wrong.
Yeah, it could be.
Well, actually, the sample is all of your players.
It's all of the people all of the time.
But you know what I mean?
So even then, even sometimes when you get great data, like your ability to institute change, even from within a development team, is really hard when there are fixed special interests in the company.
I didn't use any names. I'm glad. I think I come out unscathed.
Moving on. All right. So I'm going to direct this one to Chris. In the late stages of making a game, how do you balance high priority feedback with the need to ship on time?
I mean, I think it's pretty much just a straight tradeoff process between risk, reward and cost. You're always going to get research at different stages of the game or different stages of development and your tolerance for change is going to change as you move along.
Some people are willing to gamble a little bit more than others at later stages of the game and that's both good and bad. But a lot depends on who's driving the ship and what are the processes of the team. Is the team set up in a way that allows them to respond to change quickly or is that a more costly process? What is the state of other features that This new feature, this new UX might be interacting with. Is that going to create some unmitigatable risk to those other things or is it going to be sort of an isolated feature?
I remember there was a Twitter hashtag going around of like scariest thing you did in game dev. I think it was one of the designers on Mass Effect was like I secretly turned up all of the difficulty 20% like the day before we put it in the can. And I know there was a bunch of games user researchers that just responded with like sweaty emoji, like I can't believe you did that. That's the scariest thing I've ever heard. And then she, you know, she walked, she was like, yeah, she walked it back and was like, well, I had a really good plan and I knew what I was doing, but.
Yeah, it was certainly one of those where I was like, wow, that is, you know, on the riskier end.
Right.
Okay, we're getting close to the end, so I just want to touch on the last question before we open it up for questions here.
This one I'm gonna give to Corey.
Uh-oh.
How do you handle research that is completely against your design philosophy?
Booze.
Again, this is just my answer. It's not necessarily what you should do. All right. So, no, I think there's a way to be less fundamentalist about it. It comes back to I think you were saying this earlier is figuring out what's the actual problem.
Right? So is the issue that people have a A problem with the game itself or in fact asking you to make a different game or is there some other underlying issue that can be addressed to help solve the problem.
Now if someone is turning around and you're, you know, testing Gone Home and they're asking for more guns, I think at a certain point you need to have like...
the courage to say no, right?
Like this is wrong.
Like we're not doing this.
So you look and it's like, is this issue something that compromises the vision, that compromises the experience in a fundamental way?
Then you need to have the courage to say, I get it, you don't like it, this game's not for you.
If you fall into a, oh, well, I kind of want this person to link it to me.
We just like slip in one gun.
Like.
You know, put it under the pillow and you can maybe like go target practice.
Like don't, it's very dangerous to start playing the like compromise your vision game.
So I hope you'd agree with me, right?
That like if it's, if it's not the game you're making, then it's, the data is not that useful.
I like to think of games, it's, we're like.
Because eventually, if you're working on the game, you're going to lose sight of the trees.
And our goal is to be the lens that lets you see the whole forest again.
And be like, oh, okay, well, this is how it works.
But I mean, yeah, you know.
But for me too, also, I just popped into my head then, but we keep saying like, you know, as well.
And that's the weird metric.
It's like effective in a weird way.
Because sometimes you don't want someone to enjoy something.
It's a dark moment or a horrible thing or it's a pressured moment or something.
So they won't like it.
You know what I mean?
Like your test is, did you feel really under pressure?
You know what I mean? Or did you feel the urgency of this situation?
Or whatever it is that, you know, that you need them to feel is like, the test is ineffective.
Well, we don't test...
There's that opposing thing where we saw a lot on a game that we may have worked on, where like, the more story missions, when we asked them, like, did you like it?
They were never the highest score.
But then when you get to the end of a game and you're like, what did you like the most about this game?
They're like, oh, the story.
And so there was something wrong, I think.
There was a flaw in our methodology of, if you ask somebody a story-based mission, was that fun?
Well, no, it was engaging or it was, it generated an emotional response, but it's certainly, I think, a big question of methodology and how are you approaching the situation, what are you doing, because like or fun or whatever it is, whatever metric everyone uses, it can't be blanket applied.
I think you, and I don't know, you would know better, I think things like, are you engaged, right?
Did this evoke an emotional response?
Doesn't have to be a positive one, but like, do you keep, you know, does it keep you going forward?
Well we all know the Steam reviews, you know, like, you know, a thousand hours played, I hate this game, it's boring.
I know in car, in the auto industry, they have some form of putting electrodes on people when they watch TV ads and they're like, I hated that ad, and they're like, no, you loved it.
I think I was with you.
I was with you.
I want to be in your brain.
It can get very confusing.
I remember we were doing a very early test on a project and I think Alex was with me and there was a guy in the room that was like, I fucking hate this franchise, I hate this new game that you're working on, this is so stupid, you've just completely ruined it.
We're like, so do you think you'll buy it? I already preordered the collector's edition seven times and I can't wait to play it. I didn't know what to do with that. I hate everything you do but I own nine copies of it and of course I'm buying it. I don't understand.
I don't know what you do with that information. He owned it more than we did. That's what it was. He was more in it than we were. That's where you need your user researcher to step in and say this is what he really means. We just yell at the one way glass.
I just crashed through the one way.
You know that's not soundproof, right?
For a while I thought that was a guy.
This is really horrible.
Maybe, you know, remember we were going to put him in the game.
Yeah.
For a while we were going to put him in the game.
He's going to live under a bridge.
Every time you were successful in something he was going to come in and be like, eh, that wasn't really impressive.
I could do better.
You're terrible at this.
I just want to point out, because you mentioned, it didn't ship, whoever you are.
People are interested in that.
Ben is giving a talk at the end of the day on neuroscience.
He'll be talking specifically about that TV stuff as it applies to video games.
Maybe, I don't know actually what he's talking about other than the title.
Okay. We're coming to the end. So let's open it up to questions. We have about eight minutes, I think. Seven minutes. So questions. Questions for our panelists. Oh, and there's a mic just back there. If you want to ask questions, just line up at the mic.
Hi, my name is Christina Woodkey. I've been doing UX for the last 20 years and games for the last few. I'm an associate professor now. I spoke last year on UX. And I have a question.
Why did you decide to have an all male panel for UX?
That's actually a very good question. We didn't.
We didn't. We didn't. We actually had...
We approached a number of women. We actually had a woman on the panel and she unfortunately had to back out only a couple of days before and we struggled to find a replacement.
I have a website called women talk design. Call me.
Can I get your card afterwards? Thank you.
James Berg, user researcher. I work for Ian, so I have to be very careful with my question here. So question from the production side. What would you say is the biggest struggle or how do you approach the challenge of integrating the timing of research and how you get that into the game in an appropriate way? So I think it depends on, you know, how well your studio or how well your team is set up to both gather data and respond to data.
I think you can create a system that if you have the resources and the time you can create an infrastructure that allows you to collect data frequently and accurately over time and that will give you the data points that you need to make.
pretty frequent decisions. But if you're also over scoped in your project and you don't have a whole lot of flexibility, then you might not be able to respond to that data more quickly. So I think in the organization of your team, you have to decide, hey, like how important is data going to be for us in our development process? And there's a range there. It's not going to be it's not or it is, right? But you can set up systems or processes that are more conducive to responding to data than others.
Hello, my name is David Hooker. I actually do have a question, guys.
Oh, okay.
But it was more for the research side. How do you deal with or have any keys or tips for that kind of data where the consumer is obviously going to purchase the game like UGS just addressed, but their feedback is still sort of negative, so on one spectrum it's not going to work out, but on the other spectrum...
What the metrics for how many cells or copies or what have you is going to provide a contradiction.
Particularly in like pre-production. Sorry, the question is how do you reconcile people that are still going to buy the game but have opinions that are, like they want some improvements on some of the features.
And so I think that, you know, purchase intent is not always your most important metric when you're doing formative user research throughout a project.
So negative feedback is just another, it's another interesting data point for a thing that you need to consider as you're making the game.
If that negative feedback would prevent them from purchasing, it adds a little weight potentially, but I don't think mashing those two together is necessarily something that you would do throughout.
Particularly, up until I would say very late into the project, trying to douse purchase intent is a mistake from a games user research perspective.
It's not a thing that you should be trying to get out of that type of testing.
Are we out of time? No, we have a couple of minutes, right? We have four minutes.
Hi guys, I'm Leonard, how are you doing? I have a question about, because I never worked in an actual games company, so I just have a question. At the end of the year, you know, you go and you do your final report and you know you've done a good job and you know maybe there was some fighting between the designers and the user researchers but like how do you say you've had a successful output? Like what is...
How does your boss say you're doing a good job?
Because just hearing how there's a little bit of fighting and stuff, within the company, how is success determined?
In the company?
It's obviously not determined by...
You mean like on his performance review?
Well, I write a lot.
No, I don't.
Possibly.
I mean, for me, the subjective metric is always that if I...
You've probably heard versions of this, but on the dev team your job is to defend your vision and make sure it's getting through and executed.
Their job is to tell you when it's failing or when they have a better idea.
For me the success is when we've heard something, worked through that problem and you can point to something.
We had a lot on Far Cry 4 where at the end I was like, wow, that made it better.
That is a horribly subjective blobby metric for it.
In terms of hard metrics, if you're using some sort of, if you're integrated with the team and using their bug tracking software, you can extract everything that you ever said and look at, you know, did they take the feedback, did they throw it out as will not fix or can't replicate or whatever, or need more information. Need more information is a super interesting one because that means you didn't do your job well enough.
And that they saw what you're saying and they're like, I don't quite get it yet, and you have to go back for that.
And so looking at the breakdown throughout the milestones of the project of all of the things that you told them, and then tracking how those were resolved can be an interesting way to see like, am I being effective as a researcher?
Would you agree or disagree that at the end of the day, like the game, if it reviews well and sells well, you're given like a pat on the back?
And if it doesn't, you're in trouble?
Well even if you did, even if you were like, look I showed you all this shit was wrong, they're like, you're in trouble.
It would be an interesting arm wrestling match of who reads reviews more carefully.
between creative directors and games user researchers.
Because you guys were, I mean, we're both fighting at opposite, or well, we're fighting together, but on things that are kind of different.
My experience is...
But like, we go through with like a high level.
I think, yeah.
We're like, I told them.
Yeah, those fuckers, they're retarded.
I told them again.
Look.
Send it.
Sometimes he sends them to me, but physically, because he doesn't need to.
He just likes to.
I wrote a told you show report once.
It was very cathartic.
But I think, you know, we know.
So I, from my position, if you're going really high level, I think I measure my personal success is when...
At the end of the day, if I can talk to the team that I've been working with and say that they were not surprised by anything once the game was live, then I've done a good job. If they know everything that was wrong with the game before it went out and they accepted that and they made decisions on how they were going to deal with those things, I did my job.
When you don't get a call going, hey, you said this system was okay and it's not.
Maybe he's doing a better job than you, Johnny.
I've moved on. I've moved on.
I have Xanax in my pack.
I think...
Do we have time for one more?
Where's my...
Mostly what I hear represented here are AAA console type games.
And I know that one metric that's used a lot on the mobile side is just retainment.
And so I wonder if that's something you look at during a soft launch.
That's a lot more than even in console, it's all retainment.
Oh yeah, Johnny used to have a thing you could see where people checked out.
Like, it was like this mission, everyone was there, they didn't play the game anymore after this mission.
Or like, you'd see the places where people pop out.
Acquisition and retention are the key metrics for everything.
Do you find that you have to wait until...
Is there a certain point where it's too soon to talk about that?
You need to wait until a certain point for that to be meaningful?
It is tough to check retention in progress on a story game.
You can ask them, like, oh, is this the point where you would think about maybe quitting?
And they're sitting in a lab and they're there until 4 o'clock and you're like, would you maybe want to quit now?
And it's not the most reliable metric, but it can be interesting.
Haven't there been on occasion games where, like, during the test someone's like, you know what, I'm out, I'm not doing this anymore.
They're like, I'm going to have a cigarette and they don't come back.
Like, that could be interesting data.
So, so...
It does happen.
Usually you suddenly get a bout of sickness.
You'll have like 16 people and 4 of them will get sick.
There was something though, I won't be able to, but there was something where the guy was like fuck this and left.
Like once.
Not on anything I worked on.
There's a few we've rejected.
Just to be very clear.
There's always the ones we kick out for being too stoned when they turn up.
Has that happened?
All the time.
You look at me like, you're just like, oh shit.
You're gonna fuck up my data.
Get out.
But then again, I always think, though, but then again, that's your audience.
Like, you know what I mean?
It's like 50% of your audience, like maybe he should stay.
Maybe half of them should be stoned.
And then we would get realistic data.
Maybe in the new world we'll be allowed to, once Mr. Trudeau lets it happen.
Once marketing comes back to us and says that there's a stoner segment.
Yeah, exactly.
They know it.
Anyway.
We completely derailed off your question. We'll be in the wrap up room after if you want to ask.
Okay, okay guys, so we're out of time. A couple of things, please fill out the evaluation. You got scanned, so you should be getting an email with it. Good marks, please. And we'll be heading over to the wrap up room, which is in the West Hall level two, room 2022. Wait, 2022-2024.
Oh, okay, they just listed off all the wrap-up rooms.
I'm sorry, we're going to be going to 3022.
So 3022 or 2022?
No, no, 30.
We're going to 3022.
20, yeah, 3022, which is over there somewhere.
Just follow us after we leave if you want to talk to us more.
