My name is Anthony Giovannetti, and I am one of the two co-founders of Megacrit Games.
Slay the Spire was our first professional game, but in college I worked with my co-founder Casey Anno with on two smaller hobbyist level projects that taught us a lot about exactly what not to do.
Importantly, you should know that I'm a huge fan of card games.
I grew up playing with Pokemon cards and Magic the Gathering and later on I became so addicted to Netrunner that I created a large fan site for it.
In fact, I even managed a board and card game shop for a while.
So I really love card games.
So of course, I decided to make one.
The game we ended up making is called Slay the Spire.
For those of you who don't know, Slay the Spire is a fusion of roguelikes and deck building games that has players traversing a dangerous spire to reach the top.
Every time you play, you'll be climbing a new procedurally generated spire and assembling a unique deck of cards from what you find during your run.
Throughout early access, we received overwhelmingly positive review scores, and quite frankly, we sold way more copies than I ever thought imaginable.
In terms of development time, Slay this Bar was in development for two and a half years before we launched into early access, and then we were in early access for a little over a year before launching into 1.0 in January of this year.
Today for this talk, I'm going to narrow down my focus and talk specifically about how we thought about balance for Slay the Spire, some of the important tools we used to help facilitate that, and just our general approach to design.
So, as you clearly do when you talk about game design, I'm going to start by looking at one of Picasso's most famous paintings.
Now, I'm not much of a fine art person, to be honest, but this painting in particular has a few special properties that I think are really neat.
So for some context, this piece is incredibly famous.
It's featured in something like 95% of art textbooks that cover the 20th century, and no other piece comes close.
But what really interests me about it is the process.
You see, Picasso spent about a year in the making of this piece, and more significantly, he has the known record with over 500 preparatory drawings just for this piece of art.
Often I think of painting as something more spontaneous.
Kind of like Bob Ross, where you're painting happy little accidents right onto the canvas.
Conversely, this particular piece was a work of constant iteration.
After the 500th drawing, Picasso had narrowed down his masterpiece into exactly the final product that he knew he wanted.
This process is how I think about game design.
Iteration and testing are king.
Okay, so this sounds great.
It's common knowledge that playtesting is invaluable.
So if we want to create a good iteration cycle, how do we go about doing that, and are there any challenges, and in particular, as an indie, which I am?
Well, I think a good way to start is by thinking about exactly what your goals are.
In this case, what do I mean by balance for Slay the Spire?
By balance, what we mean is that every card should have its place.
And this extends to everything, not just cards, but the relics, the events, the monsters in the game.
But I'm kind of simplifying here.
Note that have a place is very different than everything should be equal to each other.
So, for example, some cards can be build-around-me cards.
These are cards that define strategies or archetypes.
Just having that in your deck really changes the nature of your deck.
Other cards can be staples that have a place in a lot of different decks, but maybe they don't stand out in any one deck in particular.
The important thing is that every card's doing something and that they're all reasonable to take a certain percentage of the time.
In this sense, I'm not striving for the impossible task of making every card equally good, but instead I'm shooting for a way more sensible target.
Additionally, I wanted to avoid content that had what I call a warping effect.
If something is too powerful and also too easy to set up, then the game can easily become just about achieving that combo or strategy.
What we're striving for, ultimately with Slay the Spire, is a diversity of strategies and play styles, so it is important to limit the overpowered effects in some fashion.
With Slay the Spire, we actually had two main advantages.
One, we're a single-player game.
And two, we're a roguelike.
Due to the nature of being a single player roguelike experience, I don't need to worry as much like Hearthstone or Magic about a single dominant strategy because you won't always get the required cards or relics to pull it off.
Even if you do pull it off, you're just gonna be dominating the game itself and not another player who's gonna have a bad time.
As long as anything too overpowered is rare and difficult to pull off, the game is still gonna function correctly.
As an example of this, players of Slay the Spire might recognize the combo on the screen of the card Corruption and the relic Dead Branch.
Dead Branch is an incredibly powerful rare relic that generates new cards whenever a card is exhausted.
Corruption makes exhausting cards really, really easy to do.
So in tandem, they create a ton of value together, and this is probably one of the more powerful combos in the game.
However, since we're not a traditional card game like Hearthstone or Magic, you can't just always put this combo into your deck and consistently play the same thing over and over again.
And so the Spire, not only will you often not see one or even both of these, but maybe in a run you saw Corruption early, thought, hey, this doesn't match my deck, I don't want it.
Later on in the run, you see Dead Branch.
Because you didn't take that earlier Corruption, it's not as impactful.
Because this is rare and often the player has to kind of actively seek it out, it's okay when they do assemble it and we're comfortable rewarding the player with a feeling of extreme power when they do pull it off.
So this is a really big advantage that we have.
But even with this in mind, we need to recognize that we had one big downside in particular.
Namely, we're a small indie team of two people, two designers, and we're trying to balance hundreds of cards and other content together.
especially when you start to get the crazy interactions between relics and cards acting in tandem, it can quickly balloon into a near endless task.
As a long time card game player myself, I knew that even large, experienced design teams working on established games with lots of resources mess up balance all the time.
So for us, balance was gonna have to be something that we worked on at an early stage and actually tried to scale up.
So what tools do we use?
Well, of course, we used the traditional methods.
We watched players play the game, went to events, played an unhealthy amount of the game ourselves.
We started internal playtest groups, but we also made a concerted effort early on to expand our playtest reach and ability to gather feedback.
To this end, we made use of a few specific tools to greatly amplify our efforts.
So let's go into those.
The first tool that we started using was an internal playtester slack that all the playtesters would use to communicate, get new game builds, et cetera.
We wanted to make things as easy as possible for the playtesters and us.
So we used a bot to collect all of the feedback, the bug reports, the ideas, or anything else into one easy place that we could look through.
I always hated filling out surveys.
I would playtest games for other people and fill out their surveys and not really like it.
So I didn't want to do anything like that.
So instead we focused on making the barrier to give feedback as low as possible.
As a result, playtesters could give as much feedback as they wanted at any time, whenever it was convenient for them, and it didn't feel like a burden.
Then we used my strong connections with the Netrunner community to invite some of the top level Netrunner players to provide high quality feedback and we encouraged them to break the game even when a lot of the systems weren't in place.
One of the reasons that this was sustainable for us is that basically every single day we were pushing out a new build of Slay the Spire with a changelog into a Slack channel that our play testers had access to.
The constant stream of new content, balance changes, and system overhauls meant that instead of testing something that got stale, there was a constant growing experience that people could keep coming back to.
We actually had individual playtesters who played thousands of runs just because their interest level was genuinely kept throughout the two and a half years of development.
The second tool we started using was absolutely integral for us throughout the life cycle of the game.
As a data-driven person, I wanted the ability to really try and test our assumptions regarding balance.
To that end, we built an in-house metric server that collects data from the players whenever they play a run.
On death or victory, anonymous data is sent back to us and collected for analysis.
We collect data on basically every single piece of relevant information we could think of.
We look at the enemies, the cards, the relics, the events, what choices the player's making at meow at the beginning.
how long it takes them to complete a run, et cetera.
This was incredibly useful prior to launching at early access, as it meant that even the quiet players that just played new builds and only rarely, if ever, gave feedback, they were still contributing.
Their data was still useful, even if they weren't giving any feedback.
And every single run done prior to launch had merit.
You can think of this as passive versus active playtesting.
Going out to events or using focus groups and watching people play, it's super valuable, and we did it, but it's very active.
It takes a lot of time, it doesn't scale very well, and it takes resources that we just didn't have.
Our metric server, on the other hand, is very passive.
Just collects data for us in the background, and then we can look at it to answer questions or generate ideas whenever we're able to.
This comboed very well with our internal Slack by allowing us to fully leverage the contribution of each play tester.
For us, using metrics was a completely invaluable tool in our toolbox, and it actually allowed us to be more objective in our decision making, even early on.
However, with all that said, as a note of caution, it's important to remember that metrics are just one tool in your designer's toolbox, and they should be used in tandem with other things.
Sometimes other factors can cause the data to lie to you.
A great example of this in Slay the Spire was the card Madness.
Now Madness is a good card, don't get me wrong, but one thing that we were seeing in our data early on was that Madness had a grossly disproportionate rate of being seen in winning decks.
Why was this the case?
Was Madness actually one of the better cards in the game?
Well, no.
The problem is that most players that had madness in their deck were getting it at an event that happened late in the third act of the game, before the boss.
So this was artificially inflating the apparent power level of the card.
So data is incredibly useful, but it can lie to you, deceive you, and it needs to be thought about before you act on it.
It's up to you, the designer, to figure out the truth about what your data's telling you.
Another cautionary tale we had.
that we discovered very early on when we didn't have a lot of playtesters was that we had two of what I'll call super playtesters, people who were already obsessed with the game, playing unhealthy amounts of it. And this is great.
You know, you're always happy to see early playtesters that love your game, especially when it just has stick figure art.
And it's great because we're getting a lot of run data on them, but it also meant that if we just looked at all of the data in aggregate and just took lined averages of things, We're basically just sampling those two people.
They were dwarfing the other players who were maybe less experienced, only played every now and then.
These are the kind of things that need to be accounted for when you're collecting metrics.
So, with those tools in mind, we launched into early access with two and a half years of development, refinement, and balance testing.
This is hugely important as we launched with what was already a very balanced product.
I see many titles that launch into early access that are quite simply unbalanced, buggy messes at that stage.
I don't think that really works very well.
And it's where early access gets a lot of its bad rep from.
Our approach instead was to launch an already balanced and near complete game into early access and then just keep expanding it frequently with more and more content.
So, launching into early access was a real game changer for Slay the Spire.
It greatly improved how valuable our metric collection was.
As the player base our metrics was pulling data from became way larger, it allowed us to see new patterns that we may have missed for various reasons before.
We were also getting a wider skill range in our player base, meaning that we could better get data on the less experienced card game players, or just people that didn't play very much.
Our release cycle during early access was also noteworthy and was influenced by our prior development cycle.
One thing that we had really learned as a takeaway from our internal play testing was that players love constant balance tweaks and changes to the game.
Since we saw that constant engagement from our play testers with our quick release cycle, we decided to do a weekly update schedule in early access.
The weekly updates were beloved throughout Early Access, and they established that things were subject to change at any moment one week from the next.
This meant that the expectations of our players were totally in line with our desire to constantly iterate and tweak the balance of the game.
Additionally, we had some great new tools available to us, namely Discord, our new Ascension levels, and streamers.
So we're gonna talk about those now.
Discord was set up to be much like our internal playtesting Slack, except orders of magnitude larger.
To better receive feedback from the thousands of new voices, we brought back FeedbackBot from our Slack into our Discord so it could easily collect feedback from the growing player community.
The Discord continued to grow and had a large number of people providing us with a never-ending stream of feedback.
In fact, at the time that I made this slide, it collected over 18,000 pieces of feedback for us.
And keep in mind, we basically read every single piece of feedback on there.
This was a lot.
We also created a beta branch that was accessible to players in early access.
Players on the beta branch.
We're getting essentially daily builds, just like our old Slack play testers were.
Even though these builds were buggier and often less balanced, because of how it was framed and the expectations that were set, we were able to keep up our fast iterations while having an almost layered approach.
Changes would get tested daily in the beta branch before moving to the main branch every week.
The beta branch was a big hit, and it let players decide on how raw of an experience they wanted.
Do they want to be right on the cutting edge, getting the new stuff, even if it meant a couple extra bugs?
If so, great, provide us with feedback.
Because we had these two different groupings of players, beta branch versus main branch, we created separate beta branch channels in our Discord to keep our beta players focused on feedback without spoiling other players of upcoming changes.
Additionally, one of the things that we developed in early access was ascension levels.
One challenge with balance is always how to handle differing difficulty modes.
We primarily balance Slay the Spire around the base difficulty level, but Slay also has 20 levels of progressively harder difficulty that we call Ascension.
Players have to unlock these one level at a time, meaning that as player skill improves, so too will they climb up the Ascension ladder.
Because playing Ascension is optional, but it offers achievements and a sense of accomplishment, players will naturally gravitate to the ascension level that makes sense for them.
As a result, we can actually sort our metric data by ascension levels to get a better feel for granularity in our data.
And it also makes targeted changes for more or less hardcore players.
Consequently, what we did is we actually turned difficulty levels from a challenge in design into a strength, not just in terms of metrics and data collection, but also in terms of our ability to balance for different kind of players.
Furthermore, our custom and daily modes also added additional ways to alter the difficulty of the game with unique modifiers that greatly change up play, usually to make things actually easier this time around.
Again, this gives further customization outside of the typical easy, medium, hard paradigm.
I really highly recommend experimenting with systems like this, as the Ascension levels turned out to be a big hit.
And in fact, streamers in particular really like them.
So, let's talk about streamers and YouTubers.
Streamers are incredibly valuable.
I don't think anyone questions that.
And they're not just great at promoting your game to others, but maybe surprisingly, they're also amazing for keeping up to date with the community and getting feedback about your game.
During early access, I would just often watch various streamers on an additional monitor while I was working.
This let me directly listen to what the popular voices in the community felt about various cards or enemies.
So, broad data's great, and sometimes just getting that strong, visceral response is actually more useful.
This acted as a good replacement for going to events or trying to get people to sit down in the same room as me.
I just didn't have time for it anymore in early access.
When you hear that dejected streamer making yet another sad meme about some item in the game, it's actually really telling.
It can help actually place an experience to the data that you're seeing.
Additionally, streamers are always talking to their audience, so you're getting their internal thoughts constantly.
This is very hard to pick up from random people at an event or a focus group.
Regular people aren't used to talking their thoughts out loud like that.
I've often found that you get better insight from a streamer than you do from just in-person watching, as a streamer is not gonna be afraid to say their mind or insult you.
They don't even know you're there half the time.
And you even get to see what Twitch chat thinks about stuff, and yeah, that's bad, but sometimes you get some good stuff out of it too.
So streamers are really, really great, and you should probably watch streams of your game.
Okay, so now we have all these great means of collecting player feedback and data.
The tricky thing is how to holistically combine it all together into a coherent, balanced whole.
This is where the early access model is so helpful, because you can always respond to the data, make a change, and then see how it affects the player base.
With that in mind, I really want to emphasize something.
Do not be afraid to break things.
As an example, when we launched our new daily mode, players were initially happy to have a new mode, new content, always good, but it was quickly becoming clear to Casey and I that the mode had a few flaws and it was probably not gonna be very popular for very long.
So we simply went back to the drawing board, and the very next weekly patch, we had completely changed the mode, made it more about these strange, weird modifiers that change your game up, instead of the original focus of trying to add an extra difficulty mode and compete with other players.
We already had ascension levels for things like that.
Now the daily mode was becoming increasingly popular, and it was a huge hit as we built upon it.
If we had been overly cautious instead, we probably would not have taken the path we did.
But because we had the freedom to constantly change and iterate, we could swiftly act to improve the game.
Because we were so directly tied into our players and what they wanted between the Discord, the metric server, reading Reddit and other social media, et cetera, I could already tell what was desired by the player base.
So, our approach paid off here.
Our iterative heavy approach also started to pay dividends when we began working on our third character, the defect.
The defect was our third character, and the only one developed in early access.
And we thought that the defect was gonna take significantly longer than the other two.
After all, we were busy working on a thousand other things at the time.
We had to constantly push out those weekly patches.
But surprisingly for us, Because we had already designed two characters at this point and also we had set up these improved streams of getting player feedback and metric data, the defect was actually the quickest character to develop.
We felt no hesitation at all at completely reworking cards from one day to the next day.
And in fact, then pushing it out into our beta branch.
We were able to hone in with great speed on something that we felt was very fleshed out and played completely differently to the other two characters.
This also really encouraged people to play and streamers to log in and stream the defect because every day cards were changing so their viewers were constantly engaged.
Overall, balancing the defect live in early access was a completely great experience and it was a huge success for our approach.
Okay, so in conclusion, here's some of the takeaways we had from developing SlaySpire.
One, iterate, iterate, iterate, Without change and experimentation, you aren't gonna narrow in on the good stuff.
Two, don't be afraid to make changes.
In the worst case, you're only gonna get more information to act on later, and ultimately, change is just gonna help you.
Three, lower the barrier between yourself, your playtesters, and your audience to get the best feedback possible and to get the highest quality of data.
And finally, update more often.
Your players are gonna love you for it, and you're gonna make your game better as a result.
Okay, so that was my talk.
Hopefully you enjoyed it, and now we have some time for Q&A.
Thanks.
Hi, so you had mentioned earlier about how Developing the game was a little easier in playtesting because as a game that is non-competitive that is single-player It's kind of more okay for certain powers to be a bit overpowered in certain situations and all that I was wondering like How did you make a decision between certain abilities being overpowered in a cool way later in the game or which abilities would be considered degenerate and which things would need to be reeled back from being too strong since you didn't have to worry about a negative play experience for an opponent?
Sure. So a big part of it is how common it is to get that overpowered thing.
It's like if we just had a common card that was way too powerful and you just saw it in every run, that's clearly no good.
So one, you need things to be rare or hard to get.
And then the other thing is just seeing how people play with it.
So in general...
that's a bit harder to get straight from metrics.
You would need that more from like feedback, like people posting things in a feedback bot or watching a streamer.
But strategies that are very, very slow and grindy, like For example, if we allowed players to just keep healing up over and over and over again, and in fact we actually had this for a while, you could like farm up healing powers and just keep playing them.
It takes a long time to do, it's optimal, but it's really, really boring.
Those are the kind of things that we wanted to nuke the hardest.
Instead of something where you see like a really big number on the screen, you feel really powerful, those are feel good and that's what we wanted to encourage.
Thanks.
I was wondering if you could comment on how you settled on your early access price, what kind of research you did and what factors played into that.
Sure, so how did we settle our early access price?
We looked to other games and we said, hey, Dead Cells is selling for $16.99.
They're kicking ass.
They're doing great.
These guys seem really smart.
And then we looked at other stuff and honestly that's how we did it.
You have two questions.
The first is, what were your thoughts around having you discard the rest of your cards that you didn't use per turn instead of allowing a player to keep it so they could plan a turn ahead?
And then my second one was kind of, yeah, so I'll ask the first one.
Sure.
So the first question is, why do you discard your hand at the end of turn instead of in a game like Hearthstone or Magic where you keep your hand?
So that's actually kind of a holdover from deck building games like Dominion or Ascension and board games like that, where in those games you would always discard your hand into the discard pile, and I just kind of kept that model when building Sleight of the Spire.
In general, what it does is it allows you to actually cycle through your deck and see all your cards, which is a property you really want.
So we actually have a relic in the game called Runic Pyramid that lets you keep your hand, and you can see how it totally alters the play style of the game.
It's more about holding onto cards and thinking about how you use them instead of being able to fly through your deck a lot.
Sure.
And so if you looked at the metrics around or feedback around that, did players like the former or the latter more?
So.
We never actually tested the game using the Hearthstone model of hand-holding because it was more based around deck builders, like Dominion, which is kind of the originator of the deck-building genre in board games, and in that game, you discard your hand.
So I thought that what they were doing made sense there, and even in our original design document, we had it, and we just kind of kept going with that.
Cool, and the second question, sorry, was have you guys thought about co-op, and if so, if you were to do co-op, how would you guys think through that?
We've thought about co-op, maybe in the future, but basically no comment for co-op.
First of all, thank you for the great talk.
And my question is, so Slate the Spy has a lot of really good enemies that challenge the different card archetypes.
So how did you go about enemy design?
Did that come after the card design or were they sort of in tandem or did you have the enemies first?
Most of the design for everything was kind of done in tandem.
Like we...
We created an initial set of like 20 or 30 cards and then started designing some basic enemies just to like make sure everything was good.
Like the original version of the game, it just had a little single character that bobbed up and down.
You had a couple basic enemies that were like zombies and slimes and you know, just stereotypical things.
And you had basic cards.
And then from there, we just fleshed everything out, started developing the world and we kind of just built organically.
Casey and I would often meet up and we would just have design sessions where we would just hash out hundreds and hundreds of ideas in like a huge brainstorming session and then go from there.
So we didn't just say, okay, now it's cards, now it's enemies, because everything's so interlinked.
And just a quick follow-up, how did you decide to, I guess, make very predictable enemy attack patterns?
Like, was that a conscious decision?
So, how did we come up with our predictable enemy attack patterns?
The enemy intent system and all of the, everything about that was actually a huge design process that took a long time to develop.
The initial design of the game, they were more like, kind of like a Final Fantasy enemies, where they just had like random move sets and they would randomly roll and move every turn.
And we actually had a lot of problems with this.
Players felt that...
It was too random.
There's already a lot of randomness in the game with all the card elements and everything.
So that extra element of unpredictability just didn't work.
And then also you didn't know, like how much block do I need on this turn?
I have no idea how much this enemy is attacking for.
I don't have a good sense of can I attack or not?
So we actually spent a long time and we went through a bunch of different systems on that.
I could do like a whole talk on that, yeah.
My question is about the unstructured feedback you're collecting.
So, it's great to see that you had those channels to collect that kind of feedback, but how did you go about filtering through all that and actually being able to leverage it as a two-person team?
Sure. So, one is you don't sleep.
The other is you actually get better at it as you start to go through it.
Honestly, we just had a manual process for it.
We thought about trying to automate that feedback, but it's very difficult because...
people can write the exact same bug into like 10 different ways, you know.
So you will go through and we would look through it and we would try to organize things into different slots.
Or we'd say, oh this is that bug I'm recognizing over here.
And we would chat with each other while we're doing it.
And honestly, we just did it manually and kind of developed that skill over time.
But there was no easy solution.
Cool, thank you.
Hi. Regarding daily challenges, are you creating those procedurally or are you hand-making them?
And how much balance are you putting on them?
Sure. So regarding daily challenges, are we making them procedurally or hand-making them?
I am absolutely not hand-making them.
Those are procedurally generated based on basically the date.
So we hit a time server, get a time stamp for the day, and then use that as the seed to procedurally generate everything.
And it's funny because a lot of people think that, you know, I'm sitting there every day, like on Christmas day, I'm like, all right, this is the, and I never did that.
But because of some of the patterns that emerge, players get that impression, which is great, because, you know, some people really like that, but I'm absolutely not doing that.
And are you spending any time balancing it or are you just letting it go?
No, we just let it go.
And what we do is, it's one of the things that we can use our metrics on to look at retroactively and see, like, we ended up changing and getting rid of Brewmaster, which was a daily modifier that ended up being no fun.
But that's the kind of thing where you just, you test it, you see how it's received.
It wasn't received well, so we modified it.
All right, thanks.
So you're drinking from the feedback firehose, and the emotional load of that, how do you deal with it?
Because I know, you know, sometimes people are toxic, sometimes they're not, but even if you've got the same piece of feedback 300 times about something you don't want to change, how did you guys manage that?
So I just want to make sure I got that right.
So how do we manage getting like 300 pieces of the same feedback?
So specifically the emotional load of it, because if you're getting a lot of feedback, even when it's polite, it's a lot of feedback.
And I know that can be challenging to handle emotionally.
Okay, so how do you deal with the emotional aspect of getting that feedback?
You just hit delete on that piece of feedback if it's trash.
I mean, it's really that simple.
You even get to the point where you're like, oh, it's this guy again.
I recognize the avatar, delete.
I mean, let's be realistic.
So, not every piece of feedback is created equally, and so sometimes we'll have some people that we really recognize, like they'll give big, detailed pieces of feedback, and so I'll be like, oh, it's him.
Okay, I'll make sure to pay attention to this.
But you just kind of get mute to the constant nonsense.
So it was just something, at first it was a little jarring, and by the 18,000th piece of feedback, you're like, whatever.
Thank you, great talk.
Hi.
Thanks for doing the talk.
I really appreciate it.
You mentioned the Brewmaster modifier, and that kind of leads to my question.
Through all the database feedback that you received, what do you think was the largest mechanic or system that got left on the cutting room floor that you based on a database decision?
So what was the largest thing that got cut based off of a database decision?
I mean.
That's tough because there were so many things that got changed or cut, but a lot of it is more...
iterative. The daily was the biggest thing that just totally did a 180 all at once. And then the other thing happened was more earlier in design with our intent system and how that worked out where, I mean, we literally went through probably 10 different versions of our intent system before we got to what it's like. We actually used to have a system in place where you could...
you would have detailed next move information on each enemy, and you would click on them, and there was almost like a sentence that would ride out and have the fluff and stuff in there.
And that was kind of fun.
Some people liked it, but it had a ton of problems, so we got rid of it.
Thank you.
I was wondering if you could talk a little bit more about the weekly update schedule that you had during early access.
It sounds interesting, but it also sounds grueling and like there would be challenges there with keeping build stability.
How did you get through that?
Sure.
So what were the challenges with the weekly updates and its grueling nature?
Yes, it was very grueling, and yes, there were sometimes some stability issues where you'd think, oh, everything's fine, it was good in the beta branch, and then we'd push it out and then we'd have to be hot fixing at midnight.
But by having just a consistent cadence...
where just every Thursday at this specific time we're doing it, we had a pretty good flow going.
And yeah, we were definitely working more than 40 hours.
Like, absolutely.
I would probably, in our next game, I would probably do biweekly updates just for our own sanity's sake.
And in particular, because you do waste a good amount of time.
Well, not waste, but you spend a good amount of time writing up good patch notes, finding community art and getting that all situated.
But in terms of build stability, that's where having our beta branch was kind of the savior of that.
Because if we didn't have a beta branch that was getting daily updates, then those weekly updates would become a lot riskier.
But instead, because we had that beta branch, we're already going through five new builds at least before you get to that weekly update.
Thank you.
Oh, are we out of time?
All right, we're out of time, but I'm going to go to a wrap-up room, so I don't know which one it is, but you can follow me there.
Thanks for coming, guys.
Thanks.
Thanks.
Thanks.
Thanks.
Thanks.
Thanks.
Thanks.
Thanks.
Thanks.
Thanks.
Thanks.
Thanks.
Thanks.
Thanks.
Thanks.
Thanks.
Thanks.
Thanks.
Thanks.
Thanks.
